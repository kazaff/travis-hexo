title: 重构团队的开发工作流
date: 2015-02-14 15:54:30
tags:
- code review
- git
- gitlab
- sonar
- 运维 

categories: 团队协作
---


靠近年根儿，手上的工作其实还有很多，不过还是要总结一下，展望一下，这就是人类。

在公司的年会上，我代表开发部做了一个简短的工作汇报，在PPT里写了很多14年的业绩和不足，也包含了15年的计划和方案。与往年不同，今年不仅是公司发展的一年，也是团队壮大的一年，也是个人成长最快的一年。
<!--more-->
其实自己确实有思考过很多，也收获了很多，找到了团队的痛点，也拿到了公司的授权，所以在15年初，要落实一些新的计划。想要强调的是，这些改革并不是我个人的主观意愿，并非我个人想为而为之的，而是包含了开发部各个层面的景愿的。我把我ppt中相关的一页截了个图，给大家展示一下：

![](http://pic.yupoo.com/kazaff/EqIBD7s3/medish.jpg)

你可能会诧异，这些都是围绕这工具的，是的没错，我们的团队以往一直都是靠人海战术来完成这些工作的，尽管团队也就才11个人而已。也许身在大公司的你觉得不可思议的是，没有这些工具，那开发人员要怎么活？项目质量怎么可能有保证？产品怎么可能如期交付？

这些问题其实在任何一家小公司，创业公司都很常见，像我们这种小城市的创业小团队就更习以为常了，我这么说并非妄自菲薄，纯粹是尊重事实而已！刚到公司，刚走上这个岗位的时候，也曾看过一些敏捷开发，摩拳擦掌想要试试，甚至激进的和大领导申请SOHO办公。

后来在InfoQ上看了一些关于团队协作的分享后，确实得到了很多启发，也迫使自己真的第一次思考了一下所处的真实环境。尊重现实吧骚年，妄想那些远在天边的不切实际，最终只是浪费青春。

废话不多说，我们回过头来继续聊主题，如何完成幻灯片上提到的那些点。



代码质量
---
深入思考以后，我把代码质量分为两个方面：

- 业务
- 代码本身

判断程序员写的代码的质量高低，以我们现在的能力和认知，从上述两个方面最容易做到。**业务**指的是程序员完成项目需求的程度，是否存在功能缺失，是否存在业务理解错误等方面，而**代码本身**则指的是程序员提交的代码是否满足团队的代码规范等相关要求。

可以看出来，前者需要有经验的人来检验团队中的其他参与者，有点像师傅带徒弟的模式，在我们的团队（我相信很多公司都如此），师傅带徒弟模式反而是一种非常高效的培养骨干的方式。

后者则可以交给一些现成的工具来完成，下面我就简单聊一下我脑子里的一些计划。首先要引入两个开源工具：

- [GitLab](https://about.gitlab.com/)
- [Sonar](http://www.sonarqube.org/)

前者是类似github那样的一个基于git的协同开发平台，提供了功能完善的web界面。之所以选择它，而不是直接使用git，是因为gtilab提供了许多辅助文档化的功能，比方说可以让问题和代码更好的关联在一起，具体做法，可以参见[gitlab flow](http://www.15yan.com/story/6yueHxcgD9Z/#show-last-Point)。

后者提供了强大的代码质量监督功能，不仅支持多种语言，而且也有很好的统计以及社交界面。不过也有些许的不如意，可能是用的不熟的原因吧，具体问题可以看[这里](http://segmentfault.com/q/1010000002553887)。

这两个工具都支持与持续集成套件协作，这就为日后的工作提供了衔接。

在借鉴了一些成熟的work flow后，结合我们团队目前的真实情况，我草拟了一个工作流，如下图：

[![](http://pic.yupoo.com/kazaff/EqOi8ovp/medish.jpg)](http://pic.yupoo.com/kazaff/EqOi8ovp/j8VYL.png)

有兴趣的童鞋可以留言一起讨论哇~

只有解决了这些问题，才可以为PPT上后面两项最好工具基础。




自动化测试
---

还在我写垃圾网站的那些岁月了，我就已经对持续集成这个概念热血沸腾了，不过那个时候更多的只是被其逼格所吸引。随着团队的壮大，项目的成长，慢慢觉得持续集成不仅仅是搞个工具，定个流程那么简单地问题。这玩意儿是需要很多理论支撑的，需要团队成员有相当的职业素养和扎实的技能。甚至也需要其他部门的大力配合，毕竟是一件有得有失的事儿。

我们团队目前的痛点集中在测试环节上，他们已经被手工测试作业折腾的苦不堪言了，更不要说每次修改完bug后的回归测试了，那感觉简直就像是被轮奸，特酸爽。

当然，也不是说自动化就意味着能够把测试完全交给机器来做，凭借公司现在的实力也不可能像模像样的成立一个专门的测试部门，而且我比较认可一个观点：己所不欲勿施于人。如果只是因为程序员不喜欢做测试，而把测试工作交给别的部门来做，那问题依然存在，其他部门也会恶心于这份工作的枯燥乏味。

那么如何能够增加测试的趣味性呢？这个恐怕真的很难做到，不过倒是可以让测试变得不再那么枯燥，引入测试驱动是一个很好的方法，不过这其实并不是减轻了工作量，从某种角度来看反而是加大了代码量，毕竟测试代码也是要交给程序员来完成的。

优势在于回归测试，如果上升到理论的话，程序员还会因为这种思维模式而在编程思想上得到升华。omg~~

自动化测试中包括的关键词有：单元测试，代码覆盖率等，早在以前我也花了一些时间去了解这些玩意儿，不过一直没有投入使用。15年要迫使自己带头推行测试驱动开发。

**测试又要分为：前端，后端。前端又分为：交互，兼容，逻辑。**当然，这种分类是源于我个人的粗浅理解。至于使用什么具体的工具来搭建自动化测试平台和工作流程，目前无解。

目前目标锁定在：Junit，Jenkins，Mockito等框架。

哇哈哈哈哈哈哈哈哈~实践后再来补充吧。





运维监控
---

这里想说的主要还是监控预警，至于日志分析什么的，并不在这个主题下。我也不曾做过运维相关的职位，也没有太多使用云平台的经验，在这个主题下，我只能说自己的认知很片面，停留在架设一套开源运维监控系统来搞定，目前目标锁定在：Nagios。


至于应用的监控，可能会尝试花一些时间看一下：kafka，flume，kibana等工具。




---
好啦，这篇算是个伏笔吧，等在上面三个方向上尝试过以后再来补充。