{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/landscape-plus/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/sidebar-bg.png","path":"css/images/sidebar-bg.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/low_contrast_linen.png","path":"css/images/low_contrast_linen.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/hoffman.png","path":"css/images/hoffman.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/content-bg.png","path":"css/images/content-bg.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/brickwall.png","path":"css/images/brickwall.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/board-bg.png","path":"css/images/board-bg.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/binding_dark.png","path":"css/images/binding_dark.png","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landscape-plus/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"source/favicon.png","path":"favicon.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/CNAME","shasum":"ce6830b5bcc828d16df2918c29a11469979652a1","modified":1463211980000,"hash":"ce6830b5bcc828d16df2918c29a11469979652a1"},{"_id":"source/_posts/@Scope(prototype)的正确用法.md","shasum":"94edc5822711262fa96316b57749817a4741380c","modified":1463211996000,"hash":"94edc5822711262fa96316b57749817a4741380c"},{"_id":"source/_posts/Avro的三种序列化与反序列化方法.md","shasum":"86a421b5ca7c5cf29d0ca7c6e18a9e8a95fa7856","modified":1463211996000,"hash":"86a421b5ca7c5cf29d0ca7c6e18a9e8a95fa7856"},{"_id":"source/_posts/JDBC的超时问题.md","shasum":"11c53064abd3ae912b42a3c3f7b129a9779dcd61","modified":1463211996000,"hash":"11c53064abd3ae912b42a3c3f7b129a9779dcd61"},{"_id":"source/_posts/Jedis异常Could not get a resource from the pool.md","shasum":"1f8b9195bc24b0f012b53b2e0b668d12a36b3651","modified":1463211996000,"hash":"1f8b9195bc24b0f012b53b2e0b668d12a36b3651"},{"_id":"source/_posts/Kafka+Avro的demo.md","shasum":"a3bd45b6ac72c2f320019100ea00ab36e7edcba5","modified":1463211996000,"hash":"a3bd45b6ac72c2f320019100ea00ab36e7edcba5"},{"_id":"source/_posts/Mac配置Apache的权限问题.md","shasum":"fd0ca3520bd734e759c347a57a834088b4e912c6","modified":1463211996000,"hash":"fd0ca3520bd734e759c347a57a834088b4e912c6"},{"_id":"source/_posts/No WebApplicationContext found no ContextLoaderListener registered.md","shasum":"843e05045b5e35f6ff474ccb7133d191b6ba7437","modified":1463211996000,"hash":"843e05045b5e35f6ff474ccb7133d191b6ba7437"},{"_id":"source/_posts/React和flux初尝心得.md","shasum":"07cd593159d77779e2842c4b2faf4e6c00fe9adb","modified":1463211996000,"hash":"07cd593159d77779e2842c4b2faf4e6c00fe9adb"},{"_id":"source/_posts/ReactNative的Image.md","shasum":"2d3940a21af74a9fc5c0295d7e0f2b8799d4b45d","modified":1463211996000,"hash":"2d3940a21af74a9fc5c0295d7e0f2b8799d4b45d"},{"_id":"source/_posts/RequireJS导入CMD模块.md","shasum":"f04a8d6410fa895d073f5fb767f6e19a7aee6512","modified":1463211996000,"hash":"f04a8d6410fa895d073f5fb767f6e19a7aee6512"},{"_id":"source/_posts/dubbo中SPI的基础--Cooma微容器.md","shasum":"e46e6ec185b8e8cce7a8f5fa0ae27cc3dadfa9b8","modified":1463211996000,"hash":"e46e6ec185b8e8cce7a8f5fa0ae27cc3dadfa9b8"},{"_id":"source/_posts/dubbo中服务暴露的细节.md","shasum":"542399f79dee7394fe3ca7d26bb3077d0c369149","modified":1463211996000,"hash":"542399f79dee7394fe3ca7d26bb3077d0c369149"},{"_id":"source/_posts/dubbo-admin与多注册中心.md","shasum":"d245df60c1c9b60cc4c305daba96a9a088901c3a","modified":1463211996000,"hash":"d245df60c1c9b60cc4c305daba96a9a088901c3a"},{"_id":"source/_posts/dubbo协议下的单一长连接与多线程并发如何协同工作.md","shasum":"15f7d220f781b903c2a110f14ec6abcd65863138","modified":1463211996000,"hash":"15f7d220f781b903c2a110f14ec6abcd65863138"},{"_id":"source/_posts/dubbo的拦截器和监听器.md","shasum":"06807f98cfd735cadc4bcc8b1ecb097ba2afefce","modified":1463211996000,"hash":"06807f98cfd735cadc4bcc8b1ecb097ba2afefce"},{"_id":"source/_posts/dubbo的服务发现细节.md","shasum":"f899bd0875d395c187444e3c8970721d88859654","modified":1463211996000,"hash":"f899bd0875d395c187444e3c8970721d88859654"},{"_id":"source/_posts/dubbo的服务治理细节.md","shasum":"4861faf271260f4f25e7e6b44b7f73e0fa3ea0fc","modified":1463211996000,"hash":"4861faf271260f4f25e7e6b44b7f73e0fa3ea0fc"},{"_id":"source/_posts/dubbo的缓存实现.md","shasum":"5eb1e681f4ea250d03932bd578bbfce5e7d846f9","modified":1463211996000,"hash":"5eb1e681f4ea250d03932bd578bbfce5e7d846f9"},{"_id":"source/_posts/dubbo的编解码，序列化和通信.md","shasum":"5812075b7125082310e6ff6eee2223274a2ac993","modified":1463211996000,"hash":"5812075b7125082310e6ff6eee2223274a2ac993"},{"_id":"source/_posts/dubbo的通信模型.md","shasum":"3126b534444161870285e815d8475e031399a34c","modified":1463211996000,"hash":"3126b534444161870285e815d8475e031399a34c"},{"_id":"source/_posts/hello-world.md","shasum":"6b5fc5a24ecd3bbf8243fd241a772d75baaa6896","modified":1463211978000,"hash":"6b5fc5a24ecd3bbf8243fd241a772d75baaa6896"},{"_id":"source/_posts/java web中的session新手向.md","shasum":"4b84c61b72eda8456e9ea2277a5d690f2d5f39d2","modified":1463211978000,"hash":"4b84c61b72eda8456e9ea2277a5d690f2d5f39d2"},{"_id":"source/_posts/javaEE部署项目新手向.md","shasum":"74368c5312f14d5ac942f2688a53cf134d42396b","modified":1463211978000,"hash":"74368c5312f14d5ac942f2688a53cf134d42396b"},{"_id":"source/_posts/logstash整合kafka.md","shasum":"c8d55ea2584771f729eb39bcb1b6243977a6580b","modified":1463211996000,"hash":"c8d55ea2584771f729eb39bcb1b6243977a6580b"},{"_id":"source/_posts/dubbox新增的REST协议分析.md","shasum":"e8c9ee58fd68f49332ecc8b4eb04110e62d1c4a4","modified":1463211996000,"hash":"e8c9ee58fd68f49332ecc8b4eb04110e62d1c4a4"},{"_id":"source/_posts/https情结.md","shasum":"4a01ff6c820f069a8c6f521aa55a621d9a6b3442","modified":1463211996000,"hash":"4a01ff6c820f069a8c6f521aa55a621d9a6b3442"},{"_id":"source/_posts/php页面白屏.md","shasum":"7bf3b45eb2c58c9f820cab600ed412321ccd2458","modified":1463211978000,"hash":"7bf3b45eb2c58c9f820cab600ed412321ccd2458"},{"_id":"source/_posts/nodejs操作redis.md","shasum":"44eb5ca6f86bbf3fdb0dbea929a0302db464c42c","modified":1463211978000,"hash":"44eb5ca6f86bbf3fdb0dbea929a0302db464c42c"},{"_id":"source/_posts/rabbitmq的认证.md","shasum":"fbc5c245cc5c24362de654eeac031a898c191416","modified":1463211978000,"hash":"fbc5c245cc5c24362de654eeac031a898c191416"},{"_id":"source/_posts/rabbitmq的一些概念.md","shasum":"6b7aca13a634676c0daf3ea91ecbf3d706818bab","modified":1463211978000,"hash":"6b7aca13a634676c0daf3ea91ecbf3d706818bab"},{"_id":"source/_posts/screen命令.md","shasum":"21725187465c019cb34003c12d2a45cb648873f7","modified":1463211996000,"hash":"21725187465c019cb34003c12d2a45cb648873f7"},{"_id":"source/_posts/java命令行运行参数.md","shasum":"3d6892c596567e0048cb4c08df6b97ffee347949","modified":1463211978000,"hash":"3d6892c596567e0048cb4c08df6b97ffee347949"},{"_id":"source/_posts/rsync和inotify配置.md","shasum":"6abe99b8a68f50ef3aa94669be993f011c201877","modified":1463211996000,"hash":"6abe99b8a68f50ef3aa94669be993f011c201877"},{"_id":"source/_posts/twemproxy安装问题与不支持的操作明细.md","shasum":"ac6b1daf9b6c746179ab725d64686fd551906348","modified":1463211996000,"hash":"ac6b1daf9b6c746179ab725d64686fd551906348"},{"_id":"source/_posts/redis中坑爹的pattern参数.md","shasum":"0efe5ed32924596f0915874610e52d34fb9e02ee","modified":1463211979000,"hash":"0efe5ed32924596f0915874610e52d34fb9e02ee"},{"_id":"source/_posts/关于redis集群和事务.md","shasum":"754cc2402327e7d3640f8e72064db759bce85366","modified":1463211996000,"hash":"754cc2402327e7d3640f8e72064db759bce85366"},{"_id":"source/_posts/到底积累什么才是最佳选择.md","shasum":"ef30f0a9752cc8320c3dc5a4a5cdfedbdee13348","modified":1463211996000,"hash":"ef30f0a9752cc8320c3dc5a4a5cdfedbdee13348"},{"_id":"source/_posts/又一次新气象.md","shasum":"5dafd2f2af8ab747874811b371cdb88532fa0b28","modified":1463211979000,"hash":"5dafd2f2af8ab747874811b371cdb88532fa0b28"},{"_id":"source/_posts/在无图形界面的Centos6.5下使用OpenOfiice4.1.md","shasum":"e4b717f078731850cd0c7efc983090306e54a25c","modified":1463211996000,"hash":"e4b717f078731850cd0c7efc983090306e54a25c"},{"_id":"source/_posts/基于REST的接口文档.md","shasum":"3b6516f707329a11f70e254ebae932048d07d549","modified":1463211996000,"hash":"3b6516f707329a11f70e254ebae932048d07d549"},{"_id":"source/_posts/基于dubbo的文件上传.md","shasum":"bfa7a98a9c2ba8368aba54e7d8490ad859b1b989","modified":1463211996000,"hash":"bfa7a98a9c2ba8368aba54e7d8490ad859b1b989"},{"_id":"source/_posts/如何把java项目打包为可执行的jar.md","shasum":"510be6477b8ec5dbc5422c3cd2bab799f91484df","modified":1463211996000,"hash":"510be6477b8ec5dbc5422c3cd2bab799f91484df"},{"_id":"source/_posts/关于Flow.md","shasum":"8d90a3fefa0f237ac510eaff9eef521a954fceee","modified":1463211996000,"hash":"8d90a3fefa0f237ac510eaff9eef521a954fceee"},{"_id":"source/_posts/如何把项目soa化系列之二：业务梳理和服务发现.md","shasum":"f5acc7afba825c334563c7cbd6340a9585d48abb","modified":1463211996000,"hash":"f5acc7afba825c334563c7cbd6340a9585d48abb"},{"_id":"source/_posts/如何把项目soa化系列之三：架构设计.md","shasum":"a115ae481aebe6381015b5156fb9c093f33b9a0d","modified":1463211996000,"hash":"a115ae481aebe6381015b5156fb9c093f33b9a0d"},{"_id":"source/_posts/如何把项目soa化系列之一：计划.md","shasum":"f46da48eb78fca444939b088831b29c6840d245f","modified":1463751853000,"hash":"f46da48eb78fca444939b088831b29c6840d245f"},{"_id":"source/_posts/日志.md","shasum":"4dbad09c4b75b969d3de6c840ef6d8568fd97ea5","modified":1463211996000,"hash":"4dbad09c4b75b969d3de6c840ef6d8568fd97ea5"},{"_id":"source/_posts/日志收集架构--ELK.md","shasum":"a631fa0af98871547afbcc1edc783731fe43e737","modified":1463211996000,"hash":"a631fa0af98871547afbcc1edc783731fe43e737"},{"_id":"source/_posts/所谓协议相对URL.md","shasum":"4514eed851592eae90238d705caf9c3138ee282a","modified":1463211996000,"hash":"4514eed851592eae90238d705caf9c3138ee282a"},{"_id":"source/_posts/数据库中间件的比较.md","shasum":"282aca70d29421be0ec708aa59b4537ad2b0254a","modified":1463211996000,"hash":"282aca70d29421be0ec708aa59b4537ad2b0254a"},{"_id":"source/_posts/搭建排查tomcat内存溢出问题的调试环境.md","shasum":"00a1fc74f9b8d875cf703d6e2e68171db975a69d","modified":1463211980000,"hash":"00a1fc74f9b8d875cf703d6e2e68171db975a69d"},{"_id":"source/_posts/是什么系列之Avro.md","shasum":"23eca1c95f494c3873b7e16705cc9c5473c569e6","modified":1463211980000,"hash":"23eca1c95f494c3873b7e16705cc9c5473c569e6"},{"_id":"source/_posts/是什么系列之RMI.md","shasum":"d055c67f35d5f5891a399d2312e0b1f4d0edd985","modified":1463211980000,"hash":"d055c67f35d5f5891a399d2312e0b1f4d0edd985"},{"_id":"source/_posts/是什么系列之Servlet.md","shasum":"96ae52b27163be39e756f3bc0c7eb9c8b3fbe2b1","modified":1463211980000,"hash":"96ae52b27163be39e756f3bc0c7eb9c8b3fbe2b1"},{"_id":"source/_posts/是什么系列之Thrift.md","shasum":"d5e1e9b7fe3af7ffcf38955b3c461e47e8360631","modified":1463211980000,"hash":"d5e1e9b7fe3af7ffcf38955b3c461e47e8360631"},{"_id":"source/_posts/用nodejs实现一个小小爬虫.md","shasum":"80088520ac656209cadf8d7db3efc8ff7aafe265","modified":1463211980000,"hash":"80088520ac656209cadf8d7db3efc8ff7aafe265"},{"_id":"source/_posts/解决springMVC4下使用@ResponseBody的中文乱码.md","shasum":"016eb5de9df0e2ff730d699324ad0d7b567f9580","modified":1463211996000,"hash":"016eb5de9df0e2ff730d699324ad0d7b567f9580"},{"_id":"source/_posts/聊聊大文件上传.md","shasum":"d69c781f518e9233b0388951ba5f475f6bbe51ac","modified":1463211996000,"hash":"d69c781f518e9233b0388951ba5f475f6bbe51ac"},{"_id":"source/_posts/重构团队的开发工作流.md","shasum":"2447fc4822aff04a787ed769ad0c5690cab96416","modified":1463211996000,"hash":"2447fc4822aff04a787ed769ad0c5690cab96416"},{"_id":"source/_posts/看看RESTEasy.md","shasum":"1d5890a58c39ef1eb7792591b900bd15a92c46d8","modified":1463211996000,"hash":"1d5890a58c39ef1eb7792591b900bd15a92c46d8"},{"_id":"source/_posts/dubbo如何一步一步拿到bean.md","shasum":"7b3751f9a44238f6cd1437f68d8f3b7c33a1012b","modified":1463211996000,"hash":"7b3751f9a44238f6cd1437f68d8f3b7c33a1012b"},{"_id":"themes/landscape-plus/Gruntfile.js","shasum":"412e30530784993c8997aa8b1319c669b83b91c2","modified":1463211986000,"hash":"412e30530784993c8997aa8b1319c669b83b91c2"},{"_id":"themes/landscape-plus/README.md","shasum":"fb7118d0d8c18e181eb05ce5545fbeb2c6c6e0e4","modified":1463211986000,"hash":"fb7118d0d8c18e181eb05ce5545fbeb2c6c6e0e4"},{"_id":"themes/landscape-plus/LICENSE","shasum":"82ce1e15ddeabeaaca60e2186b5a3ce42b1a9c49","modified":1463211986000,"hash":"82ce1e15ddeabeaaca60e2186b5a3ce42b1a9c49"},{"_id":"themes/landscape-plus/languages/default.yml","shasum":"c5d6bfab3a28b0f2db9af20181ab9b08f9986361","modified":1463211986000,"hash":"c5d6bfab3a28b0f2db9af20181ab9b08f9986361"},{"_id":"themes/landscape-plus/languages/zh-CN.yml","shasum":"c5b161bca2f8b28bf6b6d2e5348da635672c72b8","modified":1463211986000,"hash":"c5b161bca2f8b28bf6b6d2e5348da635672c72b8"},{"_id":"themes/landscape-plus/languages/zh-TW.yml","shasum":"68e25769af0944e5a78824f5f4d4d9e7fdecb57c","modified":1463211986000,"hash":"68e25769af0944e5a78824f5f4d4d9e7fdecb57c"},{"_id":"themes/landscape-plus/layout/_partial/after-footer.ejs","shasum":"da3131670f54a80be9e5525d6c5a6bcac06f1014","modified":1463211986000,"hash":"da3131670f54a80be9e5525d6c5a6bcac06f1014"},{"_id":"themes/landscape-plus/layout/_partial/archive-post.ejs","shasum":"5062c723721d8497eebad372f57092ade45041f4","modified":1463211986000,"hash":"5062c723721d8497eebad372f57092ade45041f4"},{"_id":"themes/landscape-plus/layout/_partial/archive.ejs","shasum":"290edd64257723f1dbc3dc226973b27ed8e0653d","modified":1463211986000,"hash":"290edd64257723f1dbc3dc226973b27ed8e0653d"},{"_id":"themes/landscape-plus/layout/_partial/article.ejs","shasum":"9078a58801857aacc823789e4c6fe97421891c11","modified":1463211986000,"hash":"9078a58801857aacc823789e4c6fe97421891c11"},{"_id":"themes/landscape-plus/layout/_partial/footer.ejs","shasum":"0c103fb7a75da3d98e1568b9b1c0393a83a3e35d","modified":1463211986000,"hash":"0c103fb7a75da3d98e1568b9b1c0393a83a3e35d"},{"_id":"themes/landscape-plus/layout/_partial/google-analytics.ejs","shasum":"ade81710027f55371b1229548fee0754e09b07b6","modified":1463211986000,"hash":"ade81710027f55371b1229548fee0754e09b07b6"},{"_id":"themes/landscape-plus/layout/_partial/head.ejs","shasum":"51d776d74045b8f26ce32e71b5e74ba6761fb8fd","modified":1463211986000,"hash":"51d776d74045b8f26ce32e71b5e74ba6761fb8fd"},{"_id":"themes/landscape-plus/layout/_partial/header.ejs","shasum":"3b4b0c4656e1a7cbf7805a34aa88f398c72a3950","modified":1463211986000,"hash":"3b4b0c4656e1a7cbf7805a34aa88f398c72a3950"},{"_id":"themes/landscape-plus/layout/_partial/mobile-nav.ejs","shasum":"7907a34f30f33ccb66c814539c90c5f6c02b5331","modified":1463211986000,"hash":"7907a34f30f33ccb66c814539c90c5f6c02b5331"},{"_id":"themes/landscape-plus/_config.yml","shasum":"94ce5b335d3b70627d493f76d14b86db996ca3b6","modified":1463211986000,"hash":"94ce5b335d3b70627d493f76d14b86db996ca3b6"},{"_id":"themes/landscape-plus/layout/_partial/post/date.ejs","shasum":"2d4dfd2943c8326bf9f69198ca06e681053097a6","modified":1463211986000,"hash":"2d4dfd2943c8326bf9f69198ca06e681053097a6"},{"_id":"themes/landscape-plus/layout/_partial/post/category.ejs","shasum":"16128d2422645e18d1b6882d4c4df17d895bd76e","modified":1463211986000,"hash":"16128d2422645e18d1b6882d4c4df17d895bd76e"},{"_id":"themes/landscape-plus/layout/_partial/post/gallery.ejs","shasum":"ad5652a1c282db42e40e799a92edb28fba555895","modified":1463211986000,"hash":"ad5652a1c282db42e40e799a92edb28fba555895"},{"_id":"themes/landscape-plus/layout/_partial/post/title.ejs","shasum":"f43f2273bcf525cd97950ab8a5fac3999ece1fd9","modified":1463211986000,"hash":"f43f2273bcf525cd97950ab8a5fac3999ece1fd9"},{"_id":"themes/landscape-plus/layout/_partial/post/tag.ejs","shasum":"694b5101bcc44c9f9c1cc62e5ad2fdfb4b7c7a07","modified":1463211986000,"hash":"694b5101bcc44c9f9c1cc62e5ad2fdfb4b7c7a07"},{"_id":"themes/landscape-plus/layout/_partial/post/nav.ejs","shasum":"8e6a1e227403f7b1b7c8efdea7708a651144bf25","modified":1463211986000,"hash":"8e6a1e227403f7b1b7c8efdea7708a651144bf25"},{"_id":"themes/landscape-plus/layout/_partial/sidebar.ejs","shasum":"c70869569749a8f48cce202fa57926c06b55fdab","modified":1463211986000,"hash":"c70869569749a8f48cce202fa57926c06b55fdab"},{"_id":"themes/landscape-plus/layout/_widget/category.ejs","shasum":"864d6db41f5f9a653fd0f1f244a29cd45c73473b","modified":1463211986000,"hash":"864d6db41f5f9a653fd0f1f244a29cd45c73473b"},{"_id":"themes/landscape-plus/layout/_widget/archive.ejs","shasum":"3e07880f560b1c8462b19bc5003aaf67756edf09","modified":1463211986000,"hash":"3e07880f560b1c8462b19bc5003aaf67756edf09"},{"_id":"themes/landscape-plus/layout/_widget/links.ejs","shasum":"405a10a963fbf190af3d7b1a43c29277ae6355a5","modified":1463211986000,"hash":"405a10a963fbf190af3d7b1a43c29277ae6355a5"},{"_id":"themes/landscape-plus/layout/_widget/recent_posts.ejs","shasum":"b31b217c46fc4644d00c8ad368c73ba1122fd44f","modified":1463211986000,"hash":"b31b217c46fc4644d00c8ad368c73ba1122fd44f"},{"_id":"themes/landscape-plus/layout/_widget/tagcloud.ejs","shasum":"7259c179aa0c41c02e467ad892292e90430aaabc","modified":1463211986000,"hash":"7259c179aa0c41c02e467ad892292e90430aaabc"},{"_id":"themes/landscape-plus/layout/_widget/tag.ejs","shasum":"20639d8b9bdb8dc0292a359125587aabb7f9575a","modified":1463211986000,"hash":"20639d8b9bdb8dc0292a359125587aabb7f9575a"},{"_id":"themes/landscape-plus/layout/archive.ejs","shasum":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1463211986000,"hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b"},{"_id":"themes/landscape-plus/layout/category.ejs","shasum":"765426a9c8236828dc34759e604cc2c52292835a","modified":1463211986000,"hash":"765426a9c8236828dc34759e604cc2c52292835a"},{"_id":"themes/landscape-plus/layout/index.ejs","shasum":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1463211986000,"hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8"},{"_id":"themes/landscape-plus/layout/layout.ejs","shasum":"cfc5ef5b799907ff4e1ec941f74ab41a4b824c7c","modified":1463211986000,"hash":"cfc5ef5b799907ff4e1ec941f74ab41a4b824c7c"},{"_id":"themes/landscape-plus/layout/page.ejs","shasum":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1463211986000,"hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b"},{"_id":"themes/landscape-plus/scripts/fancybox.js","shasum":"4c130fc242cf9b59b5df6ca5eae3b14302311e8c","modified":1463211986000,"hash":"4c130fc242cf9b59b5df6ca5eae3b14302311e8c"},{"_id":"themes/landscape-plus/layout/post.ejs","shasum":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1463211986000,"hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b"},{"_id":"themes/landscape-plus/layout/tag.ejs","shasum":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1463211986000,"hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e"},{"_id":"themes/landscape-plus/package.json","shasum":"5e1d9691a353097490e79c632563f1381c4a7b45","modified":1463211986000,"hash":"5e1d9691a353097490e79c632563f1381c4a7b45"},{"_id":"themes/landscape-plus/source/css/_extend.styl","shasum":"71b4fc4d12fdd7a7f66a68ab0e9c832d2fa85ec1","modified":1463211986000,"hash":"71b4fc4d12fdd7a7f66a68ab0e9c832d2fa85ec1"},{"_id":"themes/landscape-plus/source/css/_partial/archive.styl","shasum":"e8bc29ccf4718280005529ae5b98c99ce482b3b5","modified":1463211986000,"hash":"e8bc29ccf4718280005529ae5b98c99ce482b3b5"},{"_id":"themes/landscape-plus/source/css/_partial/comment.styl","shasum":"2834870661e490775f9154d71638bfdc72e640a6","modified":1463211987000,"hash":"2834870661e490775f9154d71638bfdc72e640a6"},{"_id":"themes/landscape-plus/source/css/_partial/article.styl","shasum":"c33d3faab90d76f23b749c312938a61448126778","modified":1463211986000,"hash":"c33d3faab90d76f23b749c312938a61448126778"},{"_id":"themes/landscape-plus/source/css/_partial/footer.styl","shasum":"6f7aa810f296d6a1a4486637b5a853d35a198938","modified":1463211987000,"hash":"6f7aa810f296d6a1a4486637b5a853d35a198938"},{"_id":"themes/landscape-plus/source/css/_partial/header.styl","shasum":"c34047bc9aed3247a1bb390cd81b5ff49eeff10b","modified":1463211987000,"hash":"c34047bc9aed3247a1bb390cd81b5ff49eeff10b"},{"_id":"themes/landscape-plus/source/css/_partial/highlight.styl","shasum":"9c7197a42380d56b41f08df9b338e0b735fa7c6b","modified":1463211987000,"hash":"9c7197a42380d56b41f08df9b338e0b735fa7c6b"},{"_id":"themes/landscape-plus/source/css/_partial/mobile.styl","shasum":"f6080db2c3b8f7600963f8f7c41b3ff92abf00e9","modified":1463211987000,"hash":"f6080db2c3b8f7600963f8f7c41b3ff92abf00e9"},{"_id":"themes/landscape-plus/source/css/_partial/sidebar-aside.styl","shasum":"2d3d264a34bee86abbefafd07e57beae415d28d5","modified":1463211987000,"hash":"2d3d264a34bee86abbefafd07e57beae415d28d5"},{"_id":"themes/landscape-plus/source/css/_partial/sidebar-bottom.styl","shasum":"f6023861b2fbd858946e2108438b5f8f17586179","modified":1463211987000,"hash":"f6023861b2fbd858946e2108438b5f8f17586179"},{"_id":"themes/landscape-plus/source/css/_partial/sidebar.styl","shasum":"0c91d8e0081cf2de5f729c8cf2f42c3a2ae5ccb6","modified":1463211987000,"hash":"0c91d8e0081cf2de5f729c8cf2f42c3a2ae5ccb6"},{"_id":"themes/landscape-plus/source/css/_util/grid.styl","shasum":"1aa883ab432d9e4139c89dcbd40ae2bd1528d029","modified":1463211987000,"hash":"1aa883ab432d9e4139c89dcbd40ae2bd1528d029"},{"_id":"themes/landscape-plus/source/css/_util/mixin.styl","shasum":"429bad87fc156eacf226c5e35b0eafc277f2504b","modified":1463211987000,"hash":"429bad87fc156eacf226c5e35b0eafc277f2504b"},{"_id":"themes/landscape-plus/source/css/_variables.styl","shasum":"ee930f5f24f72ff3971acade79980d72d03a0c01","modified":1463211987000,"hash":"ee930f5f24f72ff3971acade79980d72d03a0c01"},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.eot","shasum":"0183979056f0b87616cd99d5c54a48f3b771eee6","modified":1463211987000,"hash":"0183979056f0b87616cd99d5c54a48f3b771eee6"},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.woff","shasum":"7d65e0227d0d7cdc1718119cd2a7dce0638f151c","modified":1463211987000,"hash":"7d65e0227d0d7cdc1718119cd2a7dce0638f151c"},{"_id":"themes/landscape-plus/source/css/images/binding_dark.png","shasum":"d3b2672ae31d779a7cc8e23f6e397e533dd3badf","modified":1463211987000,"hash":"d3b2672ae31d779a7cc8e23f6e397e533dd3badf"},{"_id":"themes/landscape-plus/source/css/images/board-bg.png","shasum":"b21f47d8aa862dd82df314bb154a8e8d543a380d","modified":1463211987000,"hash":"b21f47d8aa862dd82df314bb154a8e8d543a380d"},{"_id":"themes/landscape-plus/source/css/images/brickwall.png","shasum":"61cbc80aa93f5d3b73d148b9eea7950d4272fcb9","modified":1463211987000,"hash":"61cbc80aa93f5d3b73d148b9eea7950d4272fcb9"},{"_id":"themes/landscape-plus/source/css/images/hoffman.png","shasum":"01d58bc91f565a9bcb88fbfef605569f49be8462","modified":1463211987000,"hash":"01d58bc91f565a9bcb88fbfef605569f49be8462"},{"_id":"themes/landscape-plus/source/css/images/content-bg.png","shasum":"0b53c6316cc80eb4838b68e152fc442d5bb6681c","modified":1463211987000,"hash":"0b53c6316cc80eb4838b68e152fc442d5bb6681c"},{"_id":"themes/landscape-plus/source/css/images/sidebar-bg.png","shasum":"cafd1d4624dbb1da3c4dbfd75fdf15b103f3da2a","modified":1463211987000,"hash":"cafd1d4624dbb1da3c4dbfd75fdf15b103f3da2a"},{"_id":"themes/landscape-plus/source/css/images/low_contrast_linen.png","shasum":"4ae3fb5d2dd3758152641c817546189fd79cb8cb","modified":1463211987000,"hash":"4ae3fb5d2dd3758152641c817546189fd79cb8cb"},{"_id":"themes/landscape-plus/source/css/style.styl","shasum":"65b26a1114168978d43dbe28c681dbb7988f7b89","modified":1463211987000,"hash":"65b26a1114168978d43dbe28c681dbb7988f7b89"},{"_id":"themes/landscape-plus/source/fancybox/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1463211987000,"hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"themes/landscape-plus/source/fancybox/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1463211987000,"hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"themes/landscape-plus/source/fancybox/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1463211987000,"hash":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"themes/landscape-plus/source/fancybox/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1463211987000,"hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"themes/landscape-plus/source/fancybox/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1463211987000,"hash":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"themes/landscape-plus/source/fancybox/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1463211987000,"hash":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"themes/landscape-plus/source/fancybox/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1463211987000,"hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-buttons.css","shasum":"6394c48092085788a8c0ef72670b0652006231a1","modified":1463211987000,"hash":"6394c48092085788a8c0ef72670b0652006231a1"},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-buttons.js","shasum":"4c9c395d705d22af7da06870d18f434e2a2eeaf9","modified":1463211987000,"hash":"4c9c395d705d22af7da06870d18f434e2a2eeaf9"},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-media.js","shasum":"e14c32cc6823b81b2f758512f13ed8eb9ef2b454","modified":1463211987000,"hash":"e14c32cc6823b81b2f758512f13ed8eb9ef2b454"},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-thumbs.css","shasum":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1463211987000,"hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae"},{"_id":"themes/landscape-plus/source/fancybox/helpers/jquery.fancybox-thumbs.js","shasum":"83cdfea43632b613771691a11f56f99d85fb6dbd","modified":1463211987000,"hash":"83cdfea43632b613771691a11f56f99d85fb6dbd"},{"_id":"themes/landscape-plus/source/fancybox/jquery.fancybox.css","shasum":"2e54d51d21e68ebc4bb870f6e57d3bfb660d4f9c","modified":1463211987000,"hash":"2e54d51d21e68ebc4bb870f6e57d3bfb660d4f9c"},{"_id":"themes/landscape-plus/source/js/script.js","shasum":"53b294e2fad9169b680d038230a41afe5aba3089","modified":1463211987000,"hash":"53b294e2fad9169b680d038230a41afe5aba3089"},{"_id":"themes/landscape-plus/source/fancybox/jquery.fancybox.js","shasum":"58193c802f307ec9bc9e586c0e8a13ebef45d2f8","modified":1463211987000,"hash":"58193c802f307ec9bc9e586c0e8a13ebef45d2f8"},{"_id":"themes/landscape-plus/source/fancybox/jquery.fancybox.pack.js","shasum":"2da892a02778236b64076e5e8802ef0566e1d9e8","modified":1463211987000,"hash":"2da892a02778236b64076e5e8802ef0566e1d9e8"},{"_id":"themes/landscape-plus/source/css/fonts/FontAwesome.otf","shasum":"6270a4a561a69fef5f5cc18cdf9efc256ec2ccbe","modified":1463211987000,"hash":"6270a4a561a69fef5f5cc18cdf9efc256ec2ccbe"},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.ttf","shasum":"6225ccc4ec94d060f19efab97ca42d842845b949","modified":1463211987000,"hash":"6225ccc4ec94d060f19efab97ca42d842845b949"},{"_id":"themes/landscape-plus/source/css/images/banner.jpg","shasum":"843d9d47bf2b7b75495db11b3d765efaaae442a9","modified":1463211987000,"hash":"843d9d47bf2b7b75495db11b3d765efaaae442a9"},{"_id":"themes/landscape-plus/source/css/fonts/fontawesome-webfont.svg","shasum":"e471023286b7dd1d2ccc72f670a471cfdfeafab7","modified":1463211987000,"hash":"e471023286b7dd1d2ccc72f670a471cfdfeafab7"},{"_id":"public/CNAME","hash":"ce6830b5bcc828d16df2918c29a11469979652a1","modified":1465695171983},{"_id":"public/js/script.js","hash":"c7f750718b648acd5e2cc89ece70a6664fa53ffb","modified":1465695172844},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1465695172845},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1465695172845},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1465695172845},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1465695172845},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1465695172845},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1465695172845},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1465695172845},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1465695172845},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1465695171983},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1465695171983},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1465695171983},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1465695171983},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1465695171983},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1465695171983},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1465695171983},{"_id":"public/css/style.css","hash":"90f704a3df6c863fc45ba54ca1c9ee5cb4778edb","modified":1465695172845},{"_id":"public/css/images/sidebar-bg.png","hash":"cafd1d4624dbb1da3c4dbfd75fdf15b103f3da2a","modified":1465695171983},{"_id":"public/css/images/low_contrast_linen.png","hash":"4ae3fb5d2dd3758152641c817546189fd79cb8cb","modified":1465695171983},{"_id":"public/css/images/hoffman.png","hash":"01d58bc91f565a9bcb88fbfef605569f49be8462","modified":1465695171983},{"_id":"public/css/images/content-bg.png","hash":"0b53c6316cc80eb4838b68e152fc442d5bb6681c","modified":1465695171983},{"_id":"public/css/images/brickwall.png","hash":"61cbc80aa93f5d3b73d148b9eea7950d4272fcb9","modified":1465695171984},{"_id":"public/css/images/board-bg.png","hash":"b21f47d8aa862dd82df314bb154a8e8d543a380d","modified":1465695171984},{"_id":"public/css/images/binding_dark.png","hash":"d3b2672ae31d779a7cc8e23f6e397e533dd3badf","modified":1465695171984},{"_id":"public/css/images/banner.jpg","hash":"843d9d47bf2b7b75495db11b3d765efaaae442a9","modified":1465695172889},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"7d65e0227d0d7cdc1718119cd2a7dce0638f151c","modified":1465695171984},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"6225ccc4ec94d060f19efab97ca42d842845b949","modified":1465695172795},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"e471023286b7dd1d2ccc72f670a471cfdfeafab7","modified":1465695172904},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"0183979056f0b87616cd99d5c54a48f3b771eee6","modified":1465695171984},{"_id":"public/css/fonts/FontAwesome.otf","hash":"6270a4a561a69fef5f5cc18cdf9efc256ec2ccbe","modified":1465695172807},{"_id":"public/2015/07/19/日志/index.html","hash":"537b947228d24b780873b6a0ea4ffe442e601236","modified":1465695171878},{"_id":"public/2015/06/05/日志收集架构--ELK/index.html","hash":"d3146196e341d06b0933bcda30af8a17744c0595","modified":1465695171878},{"_id":"public/2015/06/05/logstash整合kafka/index.html","hash":"df1e16fb24f96e17321ea7a70fae965c88e9f59e","modified":1465695171879},{"_id":"public/2015/06/01/https情结/index.html","hash":"7f7f75f6886df3bb7986b1c5727885d6424c96ee","modified":1465695171879},{"_id":"public/2015/05/31/screen命令/index.html","hash":"52213c1c3be90f1cc42c33e9739296406fe45118","modified":1465695171879},{"_id":"public/2015/05/27/关于Flow/index.html","hash":"f4b366c599d0a02f4d57c14651adbb0f36d3674e","modified":1465695171879},{"_id":"public/2015/05/25/ReactNative的Image/index.html","hash":"f4496426d8c68f6077fc8ce07e2141c5b1db1c7f","modified":1465695171879},{"_id":"public/2015/05/24/React和flux初尝心得/index.html","hash":"6973a3cddfb3f2d3db0c8fe5f58fa71e7042a547","modified":1465695171879},{"_id":"public/2015/05/23/RequireJS导入CMD模块/index.html","hash":"65d15ca6689a6c46fca5960fefe05629fe7bddb6","modified":1465695171879},{"_id":"public/2015/04/30/Avro的三种序列化与反序列化方法/index.html","hash":"98ca4782b421d3a425bae67dd929ef15062d9183","modified":1465695171879},{"_id":"public/2015/04/28/JDBC的超时问题/index.html","hash":"37e4f424aead305f3802c2f698c09ea4f12faaf6","modified":1465695171879},{"_id":"public/2015/04/27/Kafka+Avro的demo/index.html","hash":"1d1c07a81184a082958f12bb85854967d60f579d","modified":1465695171880},{"_id":"public/2015/04/25/基于REST的接口文档/index.html","hash":"e92ef8ed28be448c4cca667d9f7a4ecc30558bec","modified":1465695171880},{"_id":"public/2015/04/05/dubbo-admin与多注册中心/index.html","hash":"43717c34d764a22844a21e1add3ca18ed6027b40","modified":1465695171880},{"_id":"public/2015/04/01/dubbo的通信模型/index.html","hash":"17e81c5a7749039a2bd7f0a606ce5a80efb9fecb","modified":1465695171880},{"_id":"public/2015/03/18/基于dubbo的文件上传/index.html","hash":"ac079e9cf0fdf63bb6868ceb9225ccf8014ec1bc","modified":1465695171880},{"_id":"public/2015/03/13/dubbo的缓存实现/index.html","hash":"5986b488b17957ecbbd167358cd391807c232323","modified":1465695171880},{"_id":"public/2015/03/12/dubbox新增的REST协议分析/index.html","hash":"e1d7df60a835b667b32ab1b60113d40109291bc6","modified":1465695171880},{"_id":"public/2015/03/10/看看RESTEasy/index.html","hash":"470dfda668322318d06faec6885fb6708cc2acca","modified":1465695171880},{"_id":"public/2015/03/05/如何把项目soa化系列之三：架构设计/index.html","hash":"4d91fd10dc48c19a5889f4d88188a2710fc2ecd4","modified":1465695171880},{"_id":"public/2015/03/02/如何把项目soa化系列之二：业务梳理和服务发现/index.html","hash":"5c78e0cda0de2bc95171853a0a54a8b1309db358","modified":1465695171880},{"_id":"public/2015/02/25/如何把项目soa化系列之一：计划/index.html","hash":"48efb644ee9a9b16eba016d4a91a271e2310b999","modified":1465695171881},{"_id":"public/2015/02/14/重构团队的开发工作流/index.html","hash":"9e23a7fe198040795058e89e32e4b97fcfbf7c28","modified":1465695171881},{"_id":"public/2015/02/11/dubbo的编解码，序列化和通信/index.html","hash":"672b3f54cdd6010862032ed9cbffe6ba73b028c4","modified":1465695171881},{"_id":"public/2015/02/06/dubbo的拦截器和监听器/index.html","hash":"641e7a25d877ae1d2309b5331313042ea8b00c29","modified":1465695171881},{"_id":"public/2015/02/02/dubbo的服务治理细节/index.html","hash":"958c14a2db73451c4ae5f9eb57d9422a317df1a7","modified":1465695171881},{"_id":"public/2015/01/31/dubbo的服务发现细节/index.html","hash":"70129c86267954fbcfca2a23e39610e7facf4007","modified":1465695171881},{"_id":"public/2015/01/27/dubbo中服务暴露的细节/index.html","hash":"4c27f25efc65334c12a8bafa602f3852062de24e","modified":1465695171881},{"_id":"public/2015/01/26/dubbo如何一步一步拿到bean/index.html","hash":"5a7069b964a0ab66c6331df71430ef98f4fd3b3f","modified":1465695171881},{"_id":"public/2015/01/26/rsync和inotify配置/index.html","hash":"87da9f573ca14055aedc5d5b0a55242f2631a96d","modified":1465695171882},{"_id":"public/2015/01/26/twemproxy安装问题与不支持的操作明细/index.html","hash":"3616df3421e6173ce6cee206ac7f7e766ae78624","modified":1465695171882},{"_id":"public/2015/01/15/dubbo中SPI的基础--Cooma微容器/index.html","hash":"7ce9e57d33b1e93a95fed134a81bea1e8838d4ec","modified":1465695171883},{"_id":"public/2015/01/04/Jedis异常Could not get a resource from the pool/index.html","hash":"cf2dbf19b54cc990bc3f5935fab22148391723be","modified":1465695171883},{"_id":"public/2014/12/24/在无图形界面的Centos6.5下使用OpenOfiice4.1/index.html","hash":"6bcbc29c78ca44cb8b5d8d7328722818118eb754","modified":1465695171883},{"_id":"public/2014/12/15/如何把java项目打包为可执行的jar/index.html","hash":"16ee3626a8d826486a783c630dc31951e9e395e0","modified":1465695171884},{"_id":"public/2014/12/09/No WebApplicationContext found no ContextLoaderListener registered/index.html","hash":"8befdc760ea4f76492bdf2f199e514ea8569b138","modified":1465695171884},{"_id":"public/2014/12/05/@Scope(prototype)的正确用法/index.html","hash":"8d8177d9cb3f8c779c667ec45919870eeaf44ce9","modified":1465695171884},{"_id":"public/2014/12/01/解决springMVC4下使用@ResponseBody的中文乱码/index.html","hash":"7d48b4a47156ccead51c273c83152ed2d95191ea","modified":1465695171884},{"_id":"public/2014/11/14/聊聊大文件上传/index.html","hash":"cb398b59b91abbda6e955c323ec62806ae9a512d","modified":1465695171884},{"_id":"public/2014/11/10/数据库中间件的比较/index.html","hash":"0d6e9061a463bfb33fce259c7e7119f7c3b6086e","modified":1465695171884},{"_id":"public/2014/11/01/关于redis集群和事务/index.html","hash":"9112bbcb7f1791fc6ca85c09e443ede77c4a3a25","modified":1465695171884},{"_id":"public/2014/10/24/java web中的session新手向/index.html","hash":"3ed9d2f23dc685c0fc1540ff764818494d2aa7c3","modified":1465695171884},{"_id":"public/2014/10/23/javaEE部署项目新手向/index.html","hash":"810d0943a7d4136567d75659cb42580e3d054ba5","modified":1465695171885},{"_id":"public/2014/10/23/搭建排查tomcat内存溢出问题的调试环境/index.html","hash":"7e2ea52e791c53be2d9b304cd456dd728240cbba","modified":1465695171884},{"_id":"public/2014/10/13/到底积累什么才是最佳选择/index.html","hash":"7f2e4d92200774bc1c829a4e4b187eb62b37028a","modified":1465695171885},{"_id":"public/2014/09/26/所谓协议相对URL/index.html","hash":"19166020900650b182ec96204d2db468a6fa4803","modified":1465695171885},{"_id":"public/2014/09/22/Mac配置Apache的权限问题/index.html","hash":"c19e28937f691a068b53ce6d24464d0c8d0ebc4e","modified":1465695171885},{"_id":"public/2014/09/20/dubbo协议下的单一长连接与多线程并发如何协同工作/index.html","hash":"e68faf97134ec33c3c757970f0fb3e14910712dd","modified":1465695171885},{"_id":"public/2014/09/05/又一次新气象/index.html","hash":"8f3d4e21bb361113450c0c61c4fb2a4ea9d4f074","modified":1465695171885},{"_id":"public/2014/08/29/redis中坑爹的pattern参数/index.html","hash":"2542f60ff4a0b653835a928ee313e5b9e69b177c","modified":1465695171885},{"_id":"public/2014/08/08/php页面白屏/index.html","hash":"85992f5c0ccaa87b450f8d9243d0f3497efbb8ee","modified":1465695171885},{"_id":"public/2014/07/28/java命令行运行参数/index.html","hash":"3ec33e16203bf1e1608b7b8d7e1e5b9c6d4ee2f3","modified":1465695171885},{"_id":"public/2014/07/18/是什么系列之RMI/index.html","hash":"3f6db10d80b0680ab5aa0c0a215d6c7c5fe40a53","modified":1465695171886},{"_id":"public/2014/07/07/是什么系列之Thrift/index.html","hash":"5bd2c2e5bc62f4b7cc1bf492d4d708d56c0012d5","modified":1465695171886},{"_id":"public/2014/07/07/是什么系列之Avro/index.html","hash":"46acd13999b8077bebdb0678c25d776498482a86","modified":1465695171886},{"_id":"public/2014/07/03/是什么系列之Servlet/index.html","hash":"f86d84250ce53a7aa713f9d99400ffd988dc640d","modified":1465695171886},{"_id":"public/2014/06/06/nodejs操作redis/index.html","hash":"86a37661c51d4260233f677d5a9af9d03c0c3737","modified":1465695171886},{"_id":"public/2014/06/05/用nodejs实现一个小小爬虫/index.html","hash":"1106057c82b17e2d5fe16a7151c6bcb01e4d84b7","modified":1465695171886},{"_id":"public/2014/05/15/rabbitmq的认证/index.html","hash":"cae3205f00dc0daf9a0fcdcb6a0d5a94303656e4","modified":1465695171886},{"_id":"public/2014/05/15/rabbitmq的一些概念/index.html","hash":"3f4c07f53ca54f70826a6dc0122cdaeab9a5406e","modified":1465695171886},{"_id":"public/2014/05/08/hello-world/index.html","hash":"14ecb54e623af281ae7e9b9a4ada4c09be6a4250","modified":1465695171886},{"_id":"public/archives/index.html","hash":"500950819f5e0e14315ac9d3469b7fbfcae3296a","modified":1465695171886},{"_id":"public/archives/page/2/index.html","hash":"b2b4d626cffe7dcd91ac3eb2d49374d00ddaf4e4","modified":1465695171887},{"_id":"public/archives/page/3/index.html","hash":"a0bf0bbcbb759a7ab29f51a534a223beb580593d","modified":1465695171887},{"_id":"public/archives/page/4/index.html","hash":"cfe29fb7c2d37719d2f7c345cfde7d947261cfcb","modified":1465695171887},{"_id":"public/archives/page/5/index.html","hash":"fa8d9dded9c0cd9fc6ff3527a3695c1207d6a447","modified":1465695171887},{"_id":"public/archives/page/6/index.html","hash":"5e10747681c3a7e668e0e382048b9c90d047692b","modified":1465695171887},{"_id":"public/archives/page/7/index.html","hash":"cba9657b1067f97a902bbe7e38dd551e3df6f63a","modified":1465695171887},{"_id":"public/archives/2014/index.html","hash":"55d5940960146fbc3e8b2e384549c042fd5bdb90","modified":1465695171888},{"_id":"public/archives/2014/page/2/index.html","hash":"12230e7a9303760d2dd68a51fa6fdffd73bfcb76","modified":1465695171888},{"_id":"public/archives/2014/page/3/index.html","hash":"2d028d276afb8657166bcbdf3b52a218919fce56","modified":1465695171888},{"_id":"public/archives/2014/05/index.html","hash":"dda1c6655e286d01a27cb0ea41587020f441390e","modified":1465695171888},{"_id":"public/archives/2014/06/index.html","hash":"1db9a5923848721a8617174e074adcbad54fc8d1","modified":1465695171888},{"_id":"public/archives/2014/07/index.html","hash":"64a9bd64d122b5267c3cc8e274d1faa4877ef39b","modified":1465695171888},{"_id":"public/archives/2014/08/index.html","hash":"82d0502cdc0e245ac22999143ae13a6388a49cb9","modified":1465695171888},{"_id":"public/archives/2014/09/index.html","hash":"961ecdff37f944dbc141da9cacfd489cb482ceae","modified":1465695171888},{"_id":"public/archives/2014/10/index.html","hash":"9a1935ced8fca0a9e25adde4e2a5e904b93dcf44","modified":1465695171888},{"_id":"public/archives/2014/11/index.html","hash":"be1bb922098f977f4482b2ba05a666339a2ac650","modified":1465695171889},{"_id":"public/archives/2014/12/index.html","hash":"8a235c9c50c8c0cf5cf12c03472d210bff47ff98","modified":1465695171889},{"_id":"public/archives/2015/index.html","hash":"f8ecf92c5745b5e45d436111e1990b805b4830b9","modified":1465695171889},{"_id":"public/archives/2015/page/2/index.html","hash":"d0f24638c45d937ff1349ca1a4cc4672b24b7268","modified":1465695171889},{"_id":"public/archives/2015/page/3/index.html","hash":"ff361caa1fc62b9cb97dc3c7aa35ae88ecdc85a5","modified":1465695171889},{"_id":"public/archives/2015/page/4/index.html","hash":"876431cd0e21254566b4dc537f3b7448da5496d4","modified":1465695171889},{"_id":"public/archives/2015/01/index.html","hash":"045b298f7f417775910902b8b21ee466f03b1d45","modified":1465695171889},{"_id":"public/archives/2015/02/index.html","hash":"ea08b429ef504f957bfeda517c71344383b5c403","modified":1465695171889},{"_id":"public/archives/2015/03/index.html","hash":"cf97f3e67ee2b415f29220bfa9ac1b908a5988ab","modified":1465695171890},{"_id":"public/archives/2015/04/index.html","hash":"cd5e3a79760156aebe5624fe2febe5f3685d5959","modified":1465695171890},{"_id":"public/archives/2015/05/index.html","hash":"6b9f056d4022d9023baea152540cfae86ed44fe4","modified":1465695171890},{"_id":"public/archives/2015/06/index.html","hash":"7379bccb0c60e6360dbeeecb8979ed417cffa251","modified":1465695171890},{"_id":"public/archives/2015/07/index.html","hash":"38bcdbc363fab0b23873389eec23524abfdaa0d8","modified":1465695171890},{"_id":"public/categories/团队协作/index.html","hash":"018c2e3437440e806eace6aad7137b092d9c8cc7","modified":1465695171896},{"_id":"public/categories/java/index.html","hash":"adc59f0733e574f66c1dbda4d108dec448891347","modified":1465695171896},{"_id":"public/categories/j2ee/index.html","hash":"60024ef84ea16cef533b838bd9e36c7553dffa45","modified":1465695171896},{"_id":"public/categories/j2ee/page/2/index.html","hash":"2c9ffb78019af46fdedb8e8df812974ba75c2c47","modified":1465695171896},{"_id":"public/categories/j2ee/page/3/index.html","hash":"d0a7b31ab4e4e07ed678097b4ba0edd25b201ef6","modified":1465695171896},{"_id":"public/categories/nodejs/index.html","hash":"8dc68d5df634b19d8274582213d59c5dfcacb757","modified":1465695171896},{"_id":"public/categories/运维/index.html","hash":"6bc0970521e63e579f4ccce8369af6f2629f7b9d","modified":1465695171896},{"_id":"public/categories/talk/index.html","hash":"82a3b1a5b5bd1f60c2a974d204fb7d0cba32f26a","modified":1465695171896},{"_id":"public/categories/数据库/index.html","hash":"70bc9fb51d2562706b4b8cf241653d37e402bedd","modified":1465695171897},{"_id":"public/categories/前端/index.html","hash":"f54c8d6a5607bf408974b4101e646de0e937a8ac","modified":1465695171897},{"_id":"public/categories/架构/index.html","hash":"1d89b29058fe014c3b7bf86180b1d313875e9d16","modified":1465695171897},{"_id":"public/categories/nosql/index.html","hash":"02b8094532adf6be3fd51debc7e46c8a6c7c728e","modified":1465695171897},{"_id":"public/categories/php/index.html","hash":"c3e201a5a1ec4dea722985b7d7b5df903d6ef2fa","modified":1465695171897},{"_id":"public/categories/mac/index.html","hash":"cbadcf70afcf30107d43797766dd67ce8da64c81","modified":1465695171897},{"_id":"public/atom.xml","hash":"284df51524d310bab74a5c6be23c8950a0943906","modified":1465695093455},{"_id":"public/index.html","hash":"fe77b64f6982c972f4c56d85f4371c1fc230383d","modified":1465695171898},{"_id":"public/page/2/index.html","hash":"e3b6c3cff1b69285fa630c0d8bb21b64912fdcdb","modified":1465695171898},{"_id":"public/page/3/index.html","hash":"546b350e2d17a7d751e740f5aff95e8d7493b4d4","modified":1465695171898},{"_id":"public/page/4/index.html","hash":"1f3918abfe77ab2a4bbed95a7617c33552c8be21","modified":1465695171898},{"_id":"public/page/5/index.html","hash":"dd516af35f183507eefb8d09b2e2457ef6173120","modified":1465695171898},{"_id":"public/page/6/index.html","hash":"c0bbd2403215c8bbbb4c8a5bc1680ae97fd1670a","modified":1465695171898},{"_id":"public/page/7/index.html","hash":"b43ea1386da163a71e4041a7b8611cfbd23e68ff","modified":1465695171898},{"_id":"public/tags/code-review/index.html","hash":"87449943a0010ec4978d9ee90d5ae98f34dcd7a4","modified":1465695171899},{"_id":"public/tags/git/index.html","hash":"592f1a9670a6b08f2e01db98839e8a95b342b830","modified":1465695171899},{"_id":"public/tags/gitlab/index.html","hash":"0b72caedf53b7a847e5580ba6852d699ae37e9a3","modified":1465695171899},{"_id":"public/tags/sonar/index.html","hash":"ba8ccc87d083562113e91daae484dd088a33a895","modified":1465695171899},{"_id":"public/tags/运维/index.html","hash":"040b25275a2d91c846fd12edfb5e8215d5f575ac","modified":1465695171899},{"_id":"public/tags/springmvc/index.html","hash":"36d08e70728274c38d85580bc16b3f429a86c19f","modified":1465695171899},{"_id":"public/tags/中文乱码/index.html","hash":"36bca62ee7c8fe9836857744932d99fabb199a27","modified":1465695171900},{"_id":"public/tags/秒传/index.html","hash":"5089dfb262eff44af0afa17b76f7bedc2f5bff92","modified":1465695171900},{"_id":"public/tags/断点续传/index.html","hash":"91ff92632457cbf76554009d0aa774c2b95fcd31","modified":1465695171900},{"_id":"public/tags/上传进度/index.html","hash":"77715f68f5c922b5465efe26d75806dc2ca3364f","modified":1465695171900},{"_id":"public/tags/webuploader/index.html","hash":"b403bd136f0dba367f20cf0e33b863e29d42a205","modified":1465695171900},{"_id":"public/tags/分块/index.html","hash":"4ccbad5e78e759a596c159ebbc50222b0c8c395a","modified":1465695171900},{"_id":"public/tags/大文件/index.html","hash":"c813bd318dd763d0f0632a27c01092a301f40481","modified":1465695171900},{"_id":"public/tags/rest/index.html","hash":"79a30d028846f2004e4f7d826d055d7eb0d6e67c","modified":1465695171900},{"_id":"public/tags/dubbox/index.html","hash":"ec12fa155ab28e151bfc80cad9af43c9df5643a8","modified":1465695171900},{"_id":"public/tags/dubbox/page/2/index.html","hash":"353e4b3b3d565129dd7f7c03f0cab5e70c3d48b0","modified":1465695171900},{"_id":"public/tags/xml/index.html","hash":"6b9f80d508ba21b1c5dfbb121bcade2c83297611","modified":1465695171901},{"_id":"public/tags/json/index.html","hash":"ff677317fc763e94a444b65c8cd42f9aba81d92d","modified":1465695171901},{"_id":"public/tags/缓存/index.html","hash":"5a0fc5c6983b13ee263261a355cbd00688fcf116","modified":1465695171901},{"_id":"public/tags/爬虫/index.html","hash":"42765439f7d79583efaef63c43867d403bae36a7","modified":1465695171901},{"_id":"public/tags/rpc/index.html","hash":"0b2581de4411590bb9f2626aa6e36a6f469e93d2","modified":1465695171901},{"_id":"public/tags/schema/index.html","hash":"e67ac18dce12c062b71fca5c8d48eaf3c711ebd1","modified":1465695171901},{"_id":"public/tags/序列化/index.html","hash":"55fbadcace29ef05d967ff751c23e2b4276f8b46","modified":1465695171901},{"_id":"public/tags/编码/index.html","hash":"5a45e74594a4f4be00b391265d102287c5e1e390","modified":1465695171901},{"_id":"public/tags/是什么系列/index.html","hash":"e86668412548d9432eb1e7c5b64f02f096ce04eb","modified":1465695171901},{"_id":"public/tags/Servlet/index.html","hash":"7ae15f76cbd5f859833f5bd813e2d6fd7e2d8da9","modified":1465695171901},{"_id":"public/tags/Tomcat/index.html","hash":"9e84849a5f146c03a21d61a7b483496187ff555a","modified":1465695171902},{"_id":"public/tags/tcp/index.html","hash":"a55e001b5657cca26fa914ac5527985aa037674d","modified":1465695171902},{"_id":"public/tags/分布式/index.html","hash":"668a3f33510618edbd48a5f9ecd1bafb4bd27118","modified":1465695171902},{"_id":"public/tags/Logstash/index.html","hash":"e1d2583699a924b84e0bed456017b9660c0bcd86","modified":1465695171903},{"_id":"public/tags/ElasticSearch/index.html","hash":"10f6f9b3cf675c811ef0ef6e80bdefe269ed8c67","modified":1465695171903},{"_id":"public/tags/Kibana/index.html","hash":"b86afe40e4791a95f07cd3698ce09b220339ff1d","modified":1465695171903},{"_id":"public/tags/离职/index.html","hash":"feb89be92c764ab36f35222097fd4627804d8f0e","modified":1465695171903},{"_id":"public/tags/mysql/index.html","hash":"65a57ba943a8de510827aa6ea4793216fa813155","modified":1465695171903},{"_id":"public/tags/Atlas/index.html","hash":"b8087132c4d6baf09a6738840bcb2c46ed1c871b","modified":1465695171903},{"_id":"public/tags/分库分表/index.html","hash":"51b17696ce8d50c332352243c7e7b6f587bb3e45","modified":1465695171903},{"_id":"public/tags/读写分离/index.html","hash":"16e397d110d4a58b9e2024abd633324860a35161","modified":1465695171903},{"_id":"public/tags/负载均衡/index.html","hash":"ab5cb849fd4f8ad838daef0d14357d264ba4dbc3","modified":1465695171903},{"_id":"public/tags/性能/index.html","hash":"c8d65adacde88fec07ffc5fbefb188f5c8be5dac","modified":1465695171904},{"_id":"public/tags/侵入性/index.html","hash":"be90c734a5342e6a3882a390e8a1ecee4e09cc12","modified":1465695171904},{"_id":"public/tags/jconsole/index.html","hash":"ebbd594d5f40b36ab658560a1b29829a8eb8d611","modified":1465695171904},{"_id":"public/tags/jprofiler/index.html","hash":"b53cac30ee7f265864308860e2d7502174a1c97d","modified":1465695171904},{"_id":"public/tags/内存溢出/index.html","hash":"1e485868eab9df2e60a6ebb1e751f1e24bb71711","modified":1465695171904},{"_id":"public/tags/jvm/index.html","hash":"f2d69ff4a2d1f1f9b46c7d123c6b31726eba51ef","modified":1465695171904},{"_id":"public/tags/url/index.html","hash":"46d25f90496128a7bd67d0f148f666c022f1cfc7","modified":1465695171904},{"_id":"public/tags/soa/index.html","hash":"ad2e68bc8d6b55b6d512a1190418286c720f6343","modified":1465695171904},{"_id":"public/tags/服务/index.html","hash":"6d2d90b093457515522db4d35b12032c89ae237e","modified":1465695171904},{"_id":"public/tags/dubbo/index.html","hash":"f06429002f45c38b30c8d879648e5e39a5bedca0","modified":1465695171905},{"_id":"public/tags/dubbo/page/2/index.html","hash":"52b7977b7325b6cb016b1c62c630e1b588366ad9","modified":1465695171905},{"_id":"public/tags/队列/index.html","hash":"54f905929736204d459018e3fb1f52c01cf5d2cb","modified":1465695171905},{"_id":"public/tags/打包/index.html","hash":"58b9b916827076d8ec2d8f163131f9d016c86f3d","modified":1465695171905},{"_id":"public/tags/jar/index.html","hash":"d4893930c869d05d510feabce0be9a91b1863480","modified":1465695171905},{"_id":"public/tags/idea/index.html","hash":"040e741c7927acb2de3986182bda22101562a819","modified":1465695171905},{"_id":"public/tags/maven/index.html","hash":"08c4e4baa9c66fb85e16c049951f0051e3ede8a7","modified":1465695171905},{"_id":"public/tags/MANIFEST-MF/index.html","hash":"39387e7f95517399deeb415ff1417384e8674577","modified":1465695171905},{"_id":"public/tags/资源/index.html","hash":"b49ece19408ed0feda64717f0bccf663b958f196","modified":1465695171905},{"_id":"public/tags/RESTEasy/index.html","hash":"a605d15c0dc02f905abf5632f006e177de2575ab","modified":1465695171905},{"_id":"public/tags/跨域/index.html","hash":"ac7505221362b5069f355297ea3863c51e1187ee","modified":1465695171906},{"_id":"public/tags/JAX-RS/index.html","hash":"9ddaffb64dcf671620eaec576ce19717410260e7","modified":1465695171906},{"_id":"public/tags/RAP/index.html","hash":"6904ebea9049b642621e0171fd9ee82b4b4c521e","modified":1465695171906},{"_id":"public/tags/RESTful/index.html","hash":"d5d4db159a6175db40131ed7c973bcc89e286827","modified":1465695171906},{"_id":"public/tags/mock/index.html","hash":"31d6ca47c952ce2d0f6024ca8ddf194ddb378706","modified":1465695171906},{"_id":"public/tags/api/index.html","hash":"a0b687e51bd8d36553960da5f49fd6496a3eb4cf","modified":1465695171906},{"_id":"public/tags/centOS/index.html","hash":"532cea0bb34ab7678409330fc3679a748838d8d0","modified":1465695171906},{"_id":"public/tags/openoffice/index.html","hash":"888d15f95519f6394fc18992fbe4d10fb9900a24","modified":1465695171906},{"_id":"public/tags/jodconverter/index.html","hash":"1cfeb519fd5e096d8d23e45d2f96b6aa68d7ab14","modified":1465695171906},{"_id":"public/tags/pdf/index.html","hash":"ba4032b5edb112a66430a4babbb59495f918bbe0","modified":1465695171906},{"_id":"public/tags/中文/index.html","hash":"b7e9bf2285dfe9ac26a2ab63fc9d5122df46f6ba","modified":1465695171906},{"_id":"public/tags/图形界面/index.html","hash":"d617975a7f7c4c88bfd8eee0bac4802435ffa8eb","modified":1465695171907},{"_id":"public/tags/迷茫/index.html","hash":"80f89fc79fbbd73cc29492093aa5fe7e494744b0","modified":1465695171907},{"_id":"public/tags/redis/index.html","hash":"331423755e1cb3b7600a74c789b74ce96fda99d7","modified":1465695171907},{"_id":"public/tags/一致性/index.html","hash":"9d3b6da6f88c7afc5242492e5c06de0cb1f9f633","modified":1465695171907},{"_id":"public/tags/原子性/index.html","hash":"3322b2fdb139a394c6583242c7887e6b70a7eaba","modified":1465695171907},{"_id":"public/tags/回滚/index.html","hash":"e0ce82b9b779256a1f9439711a7aab2b22b0206e","modified":1465695171907},{"_id":"public/tags/twemproxy/index.html","hash":"b7d05b7ca39499dda8a8b5bd756676923d1539a8","modified":1465695171907},{"_id":"public/tags/tomcat/index.html","hash":"9ea76b55f99523c1caad17be820db576157944ee","modified":1465695171907},{"_id":"public/tags/集群/index.html","hash":"ee665158fdb473d25c55ca524a20bf5f63c5b2b3","modified":1465695171907},{"_id":"public/tags/pipe/index.html","hash":"bfa2936baf73fd36021c64dbeb1e0668ebe3ce85","modified":1465695171907},{"_id":"public/tags/flow/index.html","hash":"780710da1ac23a15727497e611fa8a776f366047","modified":1465695171908},{"_id":"public/tags/facebook/index.html","hash":"d368aa7b1305362a06b7c140287dd390047e8cd5","modified":1465695171908},{"_id":"public/tags/类型检查/index.html","hash":"d3d0140fa2d20ca2c18ca1a6e0c039a15bb7d5ea","modified":1465695171908},{"_id":"public/tags/可伸缩/index.html","hash":"9d100578d24d772dd492c6619fe293ea34ad77ab","modified":1465695171908},{"_id":"public/tags/ssh/index.html","hash":"3f25f0694a3d4e06f81da034537038e84d90249d","modified":1465695171908},{"_id":"public/tags/tmux/index.html","hash":"897a29a1fe2dc9f8482351935947e74d0e5a395d","modified":1465695171908},{"_id":"public/tags/终端/index.html","hash":"11d30c660311e2c2711439cf821c2d1b990d4a48","modified":1465695171908},{"_id":"public/tags/rsync/index.html","hash":"212a4442b07c3087cf6331b5238fef0d2ef2ec00","modified":1465695171908},{"_id":"public/tags/inotify/index.html","hash":"37197dca8ea955fc5e283f50b737c8570ffc3d0e","modified":1465695171908},{"_id":"public/tags/文件同步/index.html","hash":"9c8ac9cf192005ea39c111b951c993a98cfbd3a2","modified":1465695171909},{"_id":"public/tags/pattern/index.html","hash":"9e3c2b910289bb88d6d3bccabaa134fbd13ef473","modified":1465695171909},{"_id":"public/tags/zinterstore/index.html","hash":"fdd0a5bd95a1e5a3cb2c5092d2f6ae03c3abf77f","modified":1465695171909},{"_id":"public/tags/zscan/index.html","hash":"131e59a22b6dbfe833dfc3244423268148dd36fe","modified":1465695171909},{"_id":"public/tags/zset/index.html","hash":"65b2b740e4e2c8949cd3d1efe8679e1608556e0c","modified":1465695171909},{"_id":"public/tags/zunionstore/index.html","hash":"6d06509a87dea8cb50d287fb5a739ca8f9d4d623","modified":1465695171909},{"_id":"public/tags/rabbitmq/index.html","hash":"1cc64a4a7a747b4692bd07fc6523f1f0a54bf4cf","modified":1465695171909},{"_id":"public/tags/白屏/index.html","hash":"31143b39cc5fcefc9fe2ca241d8edcab054223e0","modified":1465695171909},{"_id":"public/tags/wdcp/index.html","hash":"10059ed11046eb814df0749f19d8c3d1b68393c9","modified":1465695171909},{"_id":"public/tags/磁盘写满/index.html","hash":"b9081c9ca27710cfa0a242b16bed8095e96f5d35","modified":1465695171910},{"_id":"public/tags/kafka/index.html","hash":"68ff25e2ed551087d0071d3f7bf088bb27858bf7","modified":1465695171923},{"_id":"public/tags/logstash-output-kafka/index.html","hash":"573963b9850757fbe4049215e2ef057ec7e88815","modified":1465695171923},{"_id":"public/tags/logstash插件/index.html","hash":"7995402ea8db4f654dbb1ddd8f7c998db9db6e0c","modified":1465695171922},{"_id":"public/tags/classpath/index.html","hash":"ef79f2087f468c2eb2f897fad3f5b91281699802","modified":1465695171910},{"_id":"public/tags/nginx/index.html","hash":"1ff8d553631c90315fde9aacabcc735dfd30f7c6","modified":1465695171910},{"_id":"public/tags/springMVC/index.html","hash":"ed30a539d05f87350b44aa725b79a90686f82b29","modified":1465695171910},{"_id":"public/tags/Idea13/index.html","hash":"50703fb7a6154d07b9ef10f285a0309769d12c10","modified":1465695171910},{"_id":"public/tags/session/index.html","hash":"dabca5e65dff7f8a420574d386b8c9691b0cb76b","modified":1465695171910},{"_id":"public/tags/会话亲和性/index.html","hash":"b3d1411f71db998b35d1f7cd8a502614b0b47a5a","modified":1465695171911},{"_id":"public/tags/https/index.html","hash":"e0b8ed438b961b850826300bda21d3cd21f728fe","modified":1465695171911},{"_id":"public/tags/ssl/index.html","hash":"8d1c983506d4442e16c346e33da8eb397c041c4d","modified":1465695171911},{"_id":"public/tags/证书/index.html","hash":"cf74bd189f581b4e3eda9cdd093d9cbdffb1c28d","modified":1465695171911},{"_id":"public/tags/hello/index.html","hash":"f67a4b212a67c8f738244ef87db6076704b32159","modified":1465695171911},{"_id":"public/tags/netty/index.html","hash":"8712828b6ab2cdb4a6209c70d6feab729540f5b5","modified":1465695171911},{"_id":"public/tags/nio/index.html","hash":"3ae4d379fba141137fc37279a4c8e10c3180e1f5","modified":1465695171911},{"_id":"public/tags/cache/index.html","hash":"870785b680449e4f3795a2f04a05c76207e35ef2","modified":1465695171912},{"_id":"public/tags/threadlocal/index.html","hash":"76d9c32c13a25caa0f30910ab132dcfb20dc4c35","modified":1465695171912},{"_id":"public/tags/JCache/index.html","hash":"65b920d97182e7fffaddaf334686a386549ef8ae","modified":1465695171912},{"_id":"public/tags/Filter/index.html","hash":"dc115912903cf0fac17f36ac2c1c2a885f5cd4d7","modified":1465695171912},{"_id":"public/tags/路由/index.html","hash":"24a27355c0a2c5c26608d834d11a09a851de9800","modified":1465695171912},{"_id":"public/tags/注册中心/index.html","hash":"73bf2a1436c1f287bd541b3bd6068552240f8624","modified":1465695171912},{"_id":"public/tags/zookeeper/index.html","hash":"b1bb63f0a4fa56142a18226535a8b0872051fa1d","modified":1465695171912},{"_id":"public/tags/拦截器/index.html","hash":"5f471fe32ccae36643956631e2c1c6ea0f99caf9","modified":1465695171913},{"_id":"public/tags/监听器/index.html","hash":"7c7e6df3b32e24cf6672251cdc74e1336b78ee6c","modified":1465695171913},{"_id":"public/tags/SPI/index.html","hash":"a3f154cc19ba4e388a946909927b049fa9b03f1b","modified":1465695171913},{"_id":"public/tags/spring/index.html","hash":"223ddce7e512a80552b6d25f82d08f2275002f68","modified":1465695171913},{"_id":"public/tags/NIO/index.html","hash":"e80318a3dc8a0416c064c55bbea2abeebe8724c0","modified":1465695171913},{"_id":"public/tags/多线程/index.html","hash":"80096832822a5185d97e5dc11da09b2398cb1b8f","modified":1465695171913},{"_id":"public/tags/Netty/index.html","hash":"7b4396f80bf5ac523c0ff87896a4bd924e3f0072","modified":1465695171913},{"_id":"public/tags/cooma/index.html","hash":"dd4987cad358e36229b7a07f5bb7440b25856268","modified":1465695171913},{"_id":"public/tags/微内核/index.html","hash":"18bc44570db20c4e23c3c3a69034e1731c53a454","modified":1465695171914},{"_id":"public/tags/协议/index.html","hash":"0b7313adb91f6734c302125414fc32895306cd3c","modified":1465695171914},{"_id":"public/tags/tomcat-embed/index.html","hash":"3c562ec0366f03e8d72bbdc0eae69e6a2ed80d5a","modified":1465695171914},{"_id":"public/tags/amd/index.html","hash":"770614bf3797b8d73ee92ccdaf7b473799971b9f","modified":1465695171914},{"_id":"public/tags/cmd/index.html","hash":"a3e849b69dc6def44fe6878d6fa5d74dc6b7c3a6","modified":1465695171914},{"_id":"public/tags/RequireJS/index.html","hash":"ca369f37426717b68d7f545a50e8247dc8780a31","modified":1465695171914},{"_id":"public/tags/react/index.html","hash":"287c2b3e45af39e11b3ec1dbfb8e1621fa27b942","modified":1465695171914},{"_id":"public/tags/flux/index.html","hash":"62e85e0f1e7993ac8ed75be50d66122bc0354fe0","modified":1465695171915},{"_id":"public/tags/mvvm/index.html","hash":"31b677b3ec3ad41785fc59388f2a361a6ea53296","modified":1465695171915},{"_id":"public/tags/ReactNative/index.html","hash":"e6df312ca5cd338f3c976f6daacfb40e3b429857","modified":1465695171915},{"_id":"public/tags/xcode/index.html","hash":"a4b099e62f0eb6047b4820166187b70b13fad0f0","modified":1465695171915},{"_id":"public/tags/权限/index.html","hash":"103d41a8fd748726b2efce679197c60d2269a0ef","modified":1465695171915},{"_id":"public/tags/ioc/index.html","hash":"3988d84e6803173a3deab678df45bd6e24d84508","modified":1465695171915},{"_id":"public/tags/filter/index.html","hash":"5507b950afa6623443bd2094dd222dfe1376d327","modified":1465695171915},{"_id":"public/tags/servlet/index.html","hash":"d189f27146b43bc4a32a20ae62c57f955c1588ac","modified":1465695171915},{"_id":"public/tags/DelegatingFilterProxy/index.html","hash":"6b6e274d9d58158771cd6f2a461a5c23249f8f07","modified":1465695171916},{"_id":"public/tags/mac/index.html","hash":"be3a61f32d5ae46fdcedc8e5071fdbbf2fabccf8","modified":1465695171916},{"_id":"public/tags/apache/index.html","hash":"fdf925b78f87d2e579a1a1ec03a4073ef795d658","modified":1465695171916},{"_id":"public/tags/vhost/index.html","hash":"b36046d75db98d230e0e2d014a7196670d0dd863","modified":1465695171916},{"_id":"public/tags/Kafka/index.html","hash":"a519bbc4a46375fbedb0bce7f74ee3d63a3b97bb","modified":1465695171916},{"_id":"public/tags/Avro/index.html","hash":"85c314d764aed93f8f19e96f06e521478f00f63e","modified":1465695171916},{"_id":"public/tags/RabbitMQ/index.html","hash":"b0c2a067d7f239bac19cae5262a16b976ebe0524","modified":1465695171916},{"_id":"public/tags/jedis/index.html","hash":"7241fd907ecd3b85631082d7c29c1929738ba8e4","modified":1465695171916},{"_id":"public/tags/连接池/index.html","hash":"376f7779c8f4dcb77726832779031a6e6dbf6013","modified":1465695171916},{"_id":"public/tags/jmeter/index.html","hash":"8b334fc11964c770e70d3293cdd1e898b5e7a044","modified":1465695171917},{"_id":"public/tags/ulimit/index.html","hash":"bc4aa524b47c685079326de369b842ecaea79a3d","modified":1465695171917},{"_id":"public/tags/timeout/index.html","hash":"61a7eaa4d1892fec6af6051089aa279347603cd0","modified":1465695171917},{"_id":"public/tags/超时/index.html","hash":"3c318c43a6ce15cc35c9ae6b85b11eca8e6262db","modified":1465695171917},{"_id":"public/tags/jdbc/index.html","hash":"2660db6bcc565504cdae6bd3f6dab5c9b589db98","modified":1465695171917},{"_id":"public/tags/DriverManagerDataSource/index.html","hash":"3b3979cd733caf1ed7f30128fd9a30bb5bb10407","modified":1465695171917},{"_id":"public/tags/RPC/index.html","hash":"2a3434655d4ce54752c6d9678636449aabc3083a","modified":1465695171917},{"_id":"public/tags/会话/index.html","hash":"9b3d8e8be08dcccf97fedad23dd0018c174bd1ef","modified":1465695171917},{"_id":"public/tags/依赖注入/index.html","hash":"959f698bc921fc4580b3843d4583f0050f9ad82e","modified":1465695171917},{"_id":"public/tags/作用域/index.html","hash":"caadfa400a477ce8d88076483f9a6c6c6473c5f1","modified":1465695171918},{"_id":"public/tags/生命周期/index.html","hash":"90062fb4c159e068f2d5b5a7b9c252250c8c7dce","modified":1465695171918},{"_id":"public/tags/scope/index.html","hash":"0f9f51eceba13f238b8f03a02f1c22d389b4873b","modified":1465695171918},{"_id":"source/_posts/论UIkit的重要性.md","shasum":"d79e75b442f6922dd1251de8587df4bfbc25185b","modified":1463211996000,"hash":"d79e75b442f6922dd1251de8587df4bfbc25185b"},{"_id":"public/2015/08/08/论UIkit的重要性/index.html","hash":"c4cc75c247295ccf6016cfaed24e3b863a81e861","modified":1465695171878},{"_id":"public/archives/2015/08/index.html","hash":"0ccb9e14c2e31a678106d85a50a6a33013334ce4","modified":1465695171890},{"_id":"public/tags/ui/index.html","hash":"15e0d36c32597600b6e969af58e27d14be647f92","modified":1465695171918},{"_id":"source/_posts/React开发web系统初体验.md","shasum":"be4bcb879d2dffca612561ee9fd0d4876f6e533b","modified":1463211996000,"hash":"be4bcb879d2dffca612561ee9fd0d4876f6e533b"},{"_id":"public/2015/08/25/React开发web系统初体验/index.html","hash":"361f81dfe0e0913b2415b242aa195ac1225e7655","modified":1465695171878},{"_id":"public/tags/react-router/index.html","hash":"bd3cdbfe94adcf3e48d4fbce9824ba48be3f937d","modified":1465695171918},{"_id":"public/tags/reflux/index.html","hash":"139ab63f36b219826e6348e1d02addb62da95490","modified":1465695171918},{"_id":"source/_posts/[译]Reactjs性能篇.md","shasum":"b1433e2c8ff178bdedde85fe90b2d9ffa125ac15","modified":1463211996000,"hash":"b1433e2c8ff178bdedde85fe90b2d9ffa125ac15"},{"_id":"public/2015/09/10/[译]Reactjs性能篇/index.html","hash":"735d59948fb7046d6219748c71671c50cb1e3fe0","modified":1465695171877},{"_id":"public/tags/dom/index.html","hash":"2144de5cd2069a4e91f92ace67de830cc94a0a1c","modified":1465695171918},{"_id":"public/tags/shouldComponentUpdate/index.html","hash":"0c1ed0b72ea99c377d28771d3e3c4666d3aa440d","modified":1465695171918},{"_id":"public/tags/Immutable-js/index.html","hash":"f12de4d080ce70a6fb35e1ba1780b63c44a208ce","modified":1465695171918},{"_id":"public/archives/2015/09/index.html","hash":"005e77ad5f058b8282a39719d3aca99e7ceacec4","modified":1465695171891},{"_id":"source/_posts/[译]全栈Redux实战.md","shasum":"0fe74f546bbf9eebcf297705cfc4306cb97900b0","modified":1463211996000,"hash":"0fe74f546bbf9eebcf297705cfc4306cb97900b0"},{"_id":"public/2015/10/08/[译]全栈Redux实战/index.html","hash":"cc5608d7889e1d6788342e24b9807ca7c710d135","modified":1465695171877},{"_id":"public/archives/2015/10/index.html","hash":"4def8c435b974722e9faccb3f79b5e59549f238c","modified":1465695171891},{"_id":"public/tags/Redux/index.html","hash":"75f74a785bfd97767ac69b9b4f7563373c965679","modified":1465695171918},{"_id":"public/tags/单元测试/index.html","hash":"535259fca3acf9aa77ba0c6f48c4f85669d78da3","modified":1465695171918},{"_id":"source/_posts/[译]Redux中间件深入浅出.md","shasum":"5c66edb5e810b3095125a86a85be6dcd2a30c800","modified":1463211996000,"hash":"5c66edb5e810b3095125a86a85be6dcd2a30c800"},{"_id":"public/2015/10/09/[译]Redux中间件深入浅出/index.html","hash":"a66fe0e444c98314af540518ce184b16bb0215a8","modified":1465695171877},{"_id":"public/tags/Redux-middleware/index.html","hash":"b689712a04e1bf8d2d541a3cb19d5e68a71eddbc","modified":1465695171919},{"_id":"public/tags/函数式编程/index.html","hash":"77fbcf0b0e4cb9f8bf11f8e6632f99adb3fe43f6","modified":1465695171919},{"_id":"public/tags/柯里化/index.html","hash":"cd8aaaa3973ed0eea6af0658c533384fedee5be9","modified":1465695171919},{"_id":"public/tags/复合函数/index.html","hash":"b116de4153ce75e2f4455073db1f2d8eb82a4842","modified":1465695171919},{"_id":"public/tags/currying/index.html","hash":"9948b3c9e6a2ba1190d0b7be6c108c39a6b83cee","modified":1465695171919},{"_id":"public/tags/redux-thunk/index.html","hash":"22a3b8139cf17bd1913d0bdecd6f6dd7c346b556","modified":1465695171919},{"_id":"source/_posts/Webpack科普.md","shasum":"f9be2e5233246b9e9c4a3736fd15c14488c329df","modified":1463211996000,"hash":"f9be2e5233246b9e9c4a3736fd15c14488c329df"},{"_id":"public/2015/10/14/Webpack科普/index.html","hash":"1838379631957d91410fad28f527b7243d53f4f9","modified":1465695171877},{"_id":"public/categories/前端/page/2/index.html","hash":"51b50bf88c9aab30a3b0328f8c18e53c54a5f0c6","modified":1465695171897},{"_id":"public/tags/webpack/index.html","hash":"2e011f19be4da6277e9ec1e880355cd43695ad91","modified":1465695171919},{"_id":"source/_posts/react-router的组件生命周期.md","shasum":"70aa62ebb1a687304866264aa4c205044e8e7a6c","modified":1463211996000,"hash":"70aa62ebb1a687304866264aa4c205044e8e7a6c"},{"_id":"public/2015/10/24/react-router的组件生命周期/index.html","hash":"9670e01e4cabe2a9ccc4c476671c55d213b4907c","modified":1465695171877},{"_id":"public/tags/lifecycle/index.html","hash":"e5a0f1fb2fba4fe293af28d8a11c52a194515d38","modified":1465695171919},{"_id":"public/tags/组件生命周期/index.html","hash":"da0ae22f19f92d0e9fbda8423b8a4f4f24cc367b","modified":1465695171920},{"_id":"public/tags/componentDidUpdate/index.html","hash":"3bb51a407b7c75a372e59224db52ee0c490df0b0","modified":1465695171920},{"_id":"source/_posts/react写小项目后感.md","shasum":"c83dd353cdf38cb8cf74c3f2b2bf857529c2d825","modified":1463211996000,"hash":"c83dd353cdf38cb8cf74c3f2b2bf857529c2d825"},{"_id":"public/2015/11/16/react写小项目后感/index.html","hash":"98cecef1addda732c29aa81b7f9243c544ae9b2e","modified":1465695171876},{"_id":"public/archives/2015/page/5/index.html","hash":"92520af855f1569f1faab2881b0e2a0e8dc52a5c","modified":1465695171889},{"_id":"public/archives/2015/11/index.html","hash":"44605549e987ac8f60639f514b526963f089fa5a","modified":1465695171895},{"_id":"source/_posts/微信第三方登录.md","shasum":"977ed7e079adba8563bafca6ab646dde18a860cd","modified":1463211996000,"hash":"977ed7e079adba8563bafca6ab646dde18a860cd"},{"_id":"public/2015/11/24/微信第三方登录/index.html","hash":"410518e85896efebc38f355cda6fce4d192586e7","modified":1465695171876},{"_id":"public/tags/微信/index.html","hash":"ea6b8c63214adca17d1873fbf9704ae22f922e18","modified":1465695171920},{"_id":"public/tags/OAuth/index.html","hash":"5adf82ca748f75288273b44154ddf153d3eaf29c","modified":1465695171920},{"_id":"public/tags/第三方登录/index.html","hash":"4a4a542fa642d8efba82e9759f69adbfe367b5f7","modified":1465695171920},{"_id":"source/_posts/qq第三方登录.md","shasum":"5686695d2fe8f001d3fca2e20d5f3869d81458ad","modified":1463211996000,"hash":"5686695d2fe8f001d3fca2e20d5f3869d81458ad"},{"_id":"public/2015/11/25/qq第三方登录/index.html","hash":"646012f195d16333eee66e86ad07201af68ae0a9","modified":1465695171876},{"_id":"public/page/8/index.html","hash":"204b14069f27fd85733c2de74168f0d7b5d89f70","modified":1465695171899},{"_id":"public/tags/QQ/index.html","hash":"17df8f80d249a6753f3da5d386cfa06c2560aa37","modified":1465695171920},{"_id":"public/archives/page/8/index.html","hash":"269b109d0561ec5826651115b54bac312a2bbc38","modified":1465695171887},{"_id":"source/_posts/mac下react-native-android环境搭建.md","shasum":"28c5c55b982230129632efe88d3d540964d7d04e","modified":1463211996000,"hash":"28c5c55b982230129632efe88d3d540964d7d04e"},{"_id":"public/2015/12/02/mac下react-native-android环境搭建/index.html","hash":"199fee4514055af660f629f995a530a3177d5c3b","modified":1465695171875},{"_id":"public/categories/移动端/index.html","hash":"cd0783dc3ce394a6e62190180c3ca14803945331","modified":1465695171897},{"_id":"public/archives/2015/12/index.html","hash":"9ba3463118edd91c293edf374db16345fa816536","modified":1465695171895},{"_id":"public/tags/react-native/index.html","hash":"53241004c0f8aa1c86c6706fc09e1ea23fb465f9","modified":1465695171920},{"_id":"public/tags/android/index.html","hash":"7df1ec8fbdfdd842c40ae1adeddca8dc8a7e5a3a","modified":1465695171920},{"_id":"source/_posts/android的浏览器下无法表单提交附件.md","shasum":"3fabe5cbc4697a750491533303e3544d1c15e659","modified":1463211996000,"hash":"3fabe5cbc4697a750491533303e3544d1c15e659"},{"_id":"public/2015/12/04/android的浏览器下无法表单提交附件/index.html","hash":"c47bdd2c922188519f0f9a2c8604772755b4802c","modified":1465695171875},{"_id":"public/tags/微信浏览器/index.html","hash":"c080598c96d0fb0f307717ec096419277153b38f","modified":1465695171920},{"_id":"public/tags/附件上传/index.html","hash":"001b807a6765953fd3ca4249ab349f252c1d5895","modified":1465695171920},{"_id":"source/_posts/React-Native-Android小结.md","shasum":"bdc1e70a690521745f1795f99d73c4ad1287e151","modified":1463211996000,"hash":"bdc1e70a690521745f1795f99d73c4ad1287e151"},{"_id":"source/_posts/关于React-Native的预备知识.md","shasum":"f663540e5ace04cb920a401f4339cd2b28b8d11e","modified":1463211996000,"hash":"f663540e5ace04cb920a401f4339cd2b28b8d11e"},{"_id":"public/2015/12/21/React-Native-Android小结/index.html","hash":"bfefa1cf2d90eb7dc57fcb2216d7602ac646eb5b","modified":1465695171875},{"_id":"public/2015/12/05/关于React-Native的预备知识/index.html","hash":"72d901db1d00398ad476187c9316fb6cc9ab9641","modified":1465695171875},{"_id":"source/_posts/react-native-android关于我是如何打包APK的.md","shasum":"f9001a1a2eb2ade531ca1dec51d3fcbc3618080c","modified":1463211996000,"hash":"f9001a1a2eb2ade531ca1dec51d3fcbc3618080c"},{"_id":"public/2015/12/21/react-native-android关于我是如何打包APK的/index.html","hash":"0aa3c0428657285d67fe3d46d9982c0a42bae608","modified":1465695171875},{"_id":"public/tags/APK/index.html","hash":"80031bd6932dda42e2e8688aac75767fd033c035","modified":1465695171921},{"_id":"source/_posts/GraphQL什么鬼.md","shasum":"f50e57b621b846479c05d8b59c231bfd848490f4","modified":1463211996000,"hash":"f50e57b621b846479c05d8b59c231bfd848490f4"},{"_id":"public/2016/01/01/GraphQL什么鬼/index.html","hash":"de53dc7bb77383cc5be61d06b1cb02dbaa4f2b0b","modified":1465695171874},{"_id":"public/archives/2016/index.html","hash":"7f1d7fdf31a8fc16d91bf96160bc5c7bfade50f9","modified":1465695171895},{"_id":"public/archives/2016/01/index.html","hash":"6c086943fc4b76f28222b2f4d50ab633ab347543","modified":1465695171895},{"_id":"public/tags/GraphQL/index.html","hash":"6c5c997cfea622c65ebffdd442bf35354d4bd6f4","modified":1465695171921},{"_id":"source/_posts/[译]Relay101制作HackerNew客户端.md","shasum":"a75b72005704403eeb12dba28d22e491ba61a4df","modified":1463211996000,"hash":"a75b72005704403eeb12dba28d22e491ba61a4df"},{"_id":"public/2016/01/02/[译]Relay101制作HackerNew客户端/index.html","hash":"fa5b58e27fb759c1b900a6a7331b054a23aba6ee","modified":1465695171874},{"_id":"public/tags/Relay/index.html","hash":"6dfb3093ffe6751b7c845a6c805b4e57874ffeb4","modified":1465695171921},{"_id":"source/_posts/老生常谈Mac下的ntfs写问题.md","shasum":"943ed15eb8c753109d7b82fd65b746a9ca86d65e","modified":1463211996000,"hash":"943ed15eb8c753109d7b82fd65b746a9ca86d65e"},{"_id":"public/2016/02/26/老生常谈Mac下的ntfs写问题/index.html","hash":"38520cb5276c055e14f2cf2d54779a239e16a5dc","modified":1465695171874},{"_id":"public/archives/2016/02/index.html","hash":"b44aa5e60d38e71dbe14425a1452a34515fb2e31","modified":1465695171895},{"_id":"public/tags/ntfs/index.html","hash":"711c4cd7020c33f5b95be99104ee7573bbc08add","modified":1465695171921},{"_id":"source/_posts/关于mariaDB和mysql5.7的json类型特性.md","shasum":"aefc85b19c787fb2dcc956fbf301ea83f0b6d94b","modified":1463211996000,"hash":"aefc85b19c787fb2dcc956fbf301ea83f0b6d94b"},{"_id":"public/2016/03/04/关于mariaDB和mysql5.7的json类型特性/index.html","hash":"b72d773609f9f6790371e0c9a75290aa47b731c3","modified":1465695171874},{"_id":"public/archives/2016/03/index.html","hash":"20304fca9b1a987fc3a5e34e61615f2fb8371c81","modified":1465695171895},{"_id":"public/tags/Mariadb/index.html","hash":"bb946ef8e1540ac1683e7932cad6db538da76d2b","modified":1465695171921},{"_id":"source/_posts/Google Drive的权限设计.md","shasum":"8be320bcd12114f49c336e16070fde8bee5632c4","modified":1463211996000,"hash":"8be320bcd12114f49c336e16070fde8bee5632c4"},{"_id":"source/_posts/关于为google-doc创建带anchor的comment的问题.md","shasum":"d0b9b0d1931c97355723eef59257a540cb427aff","modified":1463211996000,"hash":"d0b9b0d1931c97355723eef59257a540cb427aff"},{"_id":"public/2016/03/11/Google Drive的权限设计/index.html","hash":"0b83ff83743d68543999a2d8103772b99fea1ae2","modified":1465695171874},{"_id":"public/2016/03/08/关于为google-doc创建带anchor的comment的问题/index.html","hash":"f7466ff742ba1d70a35afb1a03bb7a79efb6ead9","modified":1465695171874},{"_id":"public/page/9/index.html","hash":"d298b3121c3d885a9ecfaa9b9ad372e9f0ef025c","modified":1465695171899},{"_id":"public/categories/系统设计/index.html","hash":"be5cd94acfc14aff1a93ec348fc3733c2a7540e9","modified":1465695171898},{"_id":"public/archives/page/9/index.html","hash":"d04578faefb81ccc9b009fc68b849d87bc2ed2ea","modified":1465695171887},{"_id":"public/tags/google/index.html","hash":"5111f98c25d3f2f3af2a8af1705fc97962bdb415","modified":1465695171921},{"_id":"public/tags/anchor/index.html","hash":"09a2b00a343037e415c317c4a85dcebe0dd3756a","modified":1465695171921},{"_id":"source/_posts/windows下mysql5.7无法启动.md","shasum":"22de1099a8f8ab9add422185dfaa62515a4296a1","modified":1463211996000,"hash":"22de1099a8f8ab9add422185dfaa62515a4296a1"},{"_id":"source/_posts/忙里偷闲说说atom.md","shasum":"90ff4738ea29f4603a57fae4118b5e8461ab180e","modified":1463211996000,"hash":"90ff4738ea29f4603a57fae4118b5e8461ab180e"},{"_id":"public/2016/03/24/忙里偷闲说说atom/index.html","hash":"65b7cae13cb2fd37e2ae0138716d3efa830b0eef","modified":1465695171874},{"_id":"public/2016/03/20/windows下mysql5.7无法启动/index.html","hash":"b2762b33da560677abed234d3dbd482c40287f71","modified":1465695171874},{"_id":"public/categories/运维-数据库/index.html","hash":"7a085ff5ba6968b8692d7b708824ade89b89d3fb","modified":1465695171898},{"_id":"public/tags/window/index.html","hash":"9c82a36cabef1ed962d691ddd6f676c1a29bddd4","modified":1465695171921},{"_id":"public/tags/密码/index.html","hash":"bb9cfa65adb4da299b598b154f32fe4789c65184","modified":1465695171921},{"_id":"public/tags/atom/index.html","hash":"2640fe6c93aef1ea18ea9fd59a11e86141285271","modified":1465695171921},{"_id":"public/tags/代码排版/index.html","hash":"d701e54865b42f5eaa1108270c0e418468abd74a","modified":1465695171922},{"_id":"public/tags/皮肤/index.html","hash":"ad4a525071e87751550e8e88747c3dcd2a921db3","modified":1465695171922},{"_id":"public/tags/插件/index.html","hash":"ff34e2359699c03ee2d2d32f2e8c85969b028cf6","modified":1465695171922},{"_id":"public/tags/快捷键/index.html","hash":"74c42aa6ee7cedd2cdbde347d7c794b6e18a6d87","modified":1465695171922},{"_id":"source/_posts/SDKMAN安装的库位置给哪呢.md","shasum":"ea800f7917a70647c73f67016870402d0a4db5cc","modified":1463211996000,"hash":"ea800f7917a70647c73f67016870402d0a4db5cc"},{"_id":"source/_posts/groovy下的field和property.md","shasum":"207a6c8b9b2ccad7682373e7f7a04312ad175057","modified":1463211996000,"hash":"207a6c8b9b2ccad7682373e7f7a04312ad175057"},{"_id":"source/_posts/如何禁止chrome自动跳转https.md","shasum":"96cbe7eac70c4331313cc35922e5cee0843063f8","modified":1463211996000,"hash":"96cbe7eac70c4331313cc35922e5cee0843063f8"},{"_id":"public/2016/04/02/如何禁止chrome自动跳转https/index.html","hash":"8e9c22c627f43535f8c7d44451671c741f72aa9d","modified":1465695171873},{"_id":"public/2016/04/01/groovy下的field和property/index.html","hash":"62a7786d66546e1a7049a33b97e23f185e2d5ab7","modified":1465695171873},{"_id":"public/2016/03/31/SDKMAN安装的库位置给哪呢/index.html","hash":"5676af31658b0a599d5f7a09a28c331af77765d5","modified":1465695171873},{"_id":"public/categories/groovy/index.html","hash":"d2727bcfea8dd3437633d5497f5a9c7875aca694","modified":1465695171898},{"_id":"public/archives/2016/page/2/index.html","hash":"99683dc96b1b87d28ddf7c569c5ce050270e656d","modified":1465695171895},{"_id":"public/archives/2016/04/index.html","hash":"7aab14387f53de4b77b6596e29c0717351bc5ffd","modified":1465695171895},{"_id":"public/tags/SDKMAN/index.html","hash":"7bbb917374c29ecf4a5c93d7b0899c30e1969a21","modified":1465695171922},{"_id":"public/tags/path/index.html","hash":"7443e7f5c61d16f24c491b5bd5a795251f0cd5a6","modified":1465695171922},{"_id":"public/tags/chrome/index.html","hash":"fa18d576296767a8262ff56bccd243ea360b3304","modified":1465695171922},{"_id":"public/tags/自动跳转/index.html","hash":"a10b91bd158c27417b0b46798617dd2db3598043","modified":1465695171922},{"_id":"public/tags/field/index.html","hash":"775025b45c60487bed659a6771de1bd919e16b5e","modified":1465695171922},{"_id":"public/tags/property/index.html","hash":"90db1eb5fe907c32b5b2a5a48defe42f0bc0f940","modified":1465695171922},{"_id":"public/tags/groovy-bean/index.html","hash":"a098243a28c441d90593848903ccf0a71dde240e","modified":1465695171923},{"_id":"public/tags/getter-setter/index.html","hash":"0981e8642f6774c9f2bce930260da036d22120bf","modified":1465695171923},{"_id":"source/_posts/Vue-validator初体验.md","shasum":"437d465f87915d2cdb665009cd8736e4588df8f5","modified":1463211996000,"hash":"437d465f87915d2cdb665009cd8736e4588df8f5"},{"_id":"source/_posts/前端多入口项目如何实现根据用户权限配置显示菜单.md","shasum":"b5a0a7c21b89e0c0ec475b48928c062667d7dd11","modified":1463211996000,"hash":"b5a0a7c21b89e0c0ec475b48928c062667d7dd11"},{"_id":"source/_posts/监听滚动条根据元素是否在屏幕上来触发指定逻辑.md","shasum":"c4c8d1dc619f2f8e4fd5adde882f53e08b025b6e","modified":1463211996000,"hash":"c4c8d1dc619f2f8e4fd5adde882f53e08b025b6e"},{"_id":"public/2016/04/20/Vue-validator初体验/index.html","hash":"e156b1f7caacc6e6cf8910ac749d8fd61c87315d","modified":1465695171873},{"_id":"public/2016/03/30/前端多入口项目如何实现根据用户权限配置显示菜单/index.html","hash":"c7543f9abb6c8b3cec09957e06a98324d6faed09","modified":1465695171873},{"_id":"public/2016/03/27/监听滚动条根据元素是否在屏幕上来触发指定逻辑/index.html","hash":"12c5cd631e50e77b364e4aab996a04ef80763fce","modified":1465695171874},{"_id":"public/categories/前端/page/3/index.html","hash":"eacbfcf30c8c913832108152390fe80339e84b32","modified":1465695171897},{"_id":"public/tags/vue-js/index.html","hash":"b577249f361c899eb80fe1cac808ef24cc13bffb","modified":1465695171923},{"_id":"public/tags/validator/index.html","hash":"fbb1c9d3bfe45ec98ffd2d0a4e866585709419ea","modified":1465695171923},{"_id":"public/tags/jquery/index.html","hash":"da94b3a5b8d499d3a82e93129d94ee909b89abbc","modified":1465695171923},{"_id":"public/tags/滚动条/index.html","hash":"1275ba9af60687449d4e669149e88131498af44f","modified":1465695171923},{"_id":"public/tags/组件化/index.html","hash":"ab634573e1c71b1b70888998364a6c9a9c7b80ab","modified":1465695171923},{"_id":"public/tags/屏幕位置/index.html","hash":"71ea8651ed1d9cd242abc9f08749b6136e47ed74","modified":1465695171924},{"_id":"public/tags/多入口/index.html","hash":"89b24877939d487a40365667413f54492115f535","modified":1465695171924},{"_id":"public/tags/菜单/index.html","hash":"633feb185c7b7dbb1e2a7387cc762081925de953","modified":1465695171924},{"_id":"source/_posts/gmailWatcher之node.md","shasum":"5946071cfc190598051d34c252f6494134e26ba8","modified":1463211996000,"hash":"5946071cfc190598051d34c252f6494134e26ba8"},{"_id":"source/_posts/vue组件通信和一个灵异事件.md","shasum":"efa00582f8df67d88e1622becffbe3d0fe2b3c49","modified":1463755578000,"hash":"438d304b8f071447b5b9cc72ad2c7e6051a605fd"},{"_id":"source/_posts/ztree如何优雅自定义ajax的header参数.md","shasum":"c03c9878815332ee48ae8ac1d090a5e13b5bfcc9","modified":1463211996000,"hash":"c03c9878815332ee48ae8ac1d090a5e13b5bfcc9"},{"_id":"source/_posts/只谈服务切分问题.md","shasum":"31f9d52c271c5e365635cbe0cd5527ea40f1874d","modified":1463211996000,"hash":"31f9d52c271c5e365635cbe0cd5527ea40f1874d"},{"_id":"public/2016/05/10/vue组件通信和一个灵异事件/index.html","hash":"ffb39b2c712c5777eed5d4c8244e33b78a7ca163","modified":1465695171872},{"_id":"public/2016/05/02/只谈服务切分问题/index.html","hash":"caa8ea696e5b0c70ea4dcb4f68e778b6bb151eb6","modified":1465695171873},{"_id":"public/2016/05/01/gmailWatcher之node/index.html","hash":"57ac7811cad6c5eb5f445e97c77e0709cbc83f7d","modified":1465695171873},{"_id":"public/2016/04/30/ztree如何优雅自定义ajax的header参数/index.html","hash":"8ee8ff43af273c8d896c35aec88f10ccaaa15349","modified":1465695171873},{"_id":"public/archives/page/10/index.html","hash":"6f329c7a5523d90b707e8f4e7cb12561c86fe190","modified":1465695171888},{"_id":"public/archives/2016/05/index.html","hash":"8edafba2d25c90c4624184d77c99f38a15cb99e1","modified":1465695171896},{"_id":"public/page/10/index.html","hash":"dc6faf76c527258ef9857f0f00afe029da041fbd","modified":1465695171899},{"_id":"public/tags/gmail/index.html","hash":"0004e448f9fa8b2a9eb0b2e8415e8ca072b6dcf7","modified":1465695171924},{"_id":"public/tags/imap/index.html","hash":"ddb4adbab984dbf93e1b1ee906db9fff5f5bbd7f","modified":1465695171924},{"_id":"public/tags/async/index.html","hash":"19ff75225c43ac27e5521e09e25d4fc9828927d5","modified":1465695171924},{"_id":"public/tags/mailparser/index.html","hash":"c40bbfe857cbaa9c4de89e07b3776e1c9be6d04b","modified":1465695171925},{"_id":"public/tags/ztree/index.html","hash":"cc41e13860ada663f3b434865539d59b499df719","modified":1465695171925},{"_id":"public/tags/ajax/index.html","hash":"af00e0a53062db5a8207721f28ad0db8cb0140e4","modified":1465695171925},{"_id":"public/tags/header/index.html","hash":"e52e03b9a361c727a79c6fbd3d12f26db01961d0","modified":1465695171925},{"_id":"public/tags/ajaxSend/index.html","hash":"757f3086d0c6a33da89ff57c00c65ce9d5c8f1e2","modified":1465695171925},{"_id":"public/tags/vue/index.html","hash":"e7755fdce294a7a88297c93d92614f7d513814ff","modified":1465695171926},{"_id":"public/tags/组件间通信/index.html","hash":"efcac3a69aee99a1c568afe168de281f506c2eeb","modified":1465695171926},{"_id":"public/tags/vue-strap/index.html","hash":"a78cca72a436bde6a1374f2e0780f9dec1509228","modified":1465695171926},{"_id":"source/.DS_Store","hash":"d16e05d672a59079704026f264acc3d59bddd6a3","modified":1463211996000},{"_id":"themes/landscape-plus/.gitattributes","hash":"0dd57adb042e3d90c780c1c8bc867ad547381c64","modified":1463211986000},{"_id":"themes/landscape-plus/.gitignore","hash":"93e809c42231e1d5a30e685a73dd3de745308f70","modified":1463211986000},{"_id":"themes/landscape-plus/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1463211986000},{"_id":"themes/landscape-plus/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1463211986000},{"_id":"themes/landscape-plus/.git/config","hash":"c7f9e2efb0d81792b10075ea46ded700d9f65fe0","modified":1463211986000},{"_id":"themes/landscape-plus/.git/index","hash":"5e5ab5269103a65d2ac96887b71e1c9a1902823c","modified":1463211986000},{"_id":"themes/landscape-plus/.git/packed-refs","hash":"435c4a2e085a0475feb036e66ba6bfe446f1fd03","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/applypatch-msg.sample","hash":"86b9655a9ebbde13ac8dd5795eb4d5b539edab0f","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/pre-applypatch.sample","hash":"42fa41564917b44183a50c4d94bb03e1768ddad8","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/pre-commit.sample","hash":"2e70ba322475d49ae247cc1798349692c7745a51","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/pre-push.sample","hash":"503c3d2cd9066c2329ae84309c03a4c274f6d90e","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1463211986000},{"_id":"themes/landscape-plus/.git/hooks/update.sample","hash":"39355a075977d05708ef74e1b66d09a36e486df1","modified":1463211986000},{"_id":"themes/landscape-plus/.git/logs/HEAD","hash":"e624aaeb427912ec56117774717dd434ca574435","modified":1463211986000},{"_id":"themes/landscape-plus/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1463211986000},{"_id":"themes/landscape-plus/.git/objects/pack/pack-3e37e2fd06fe1e021b714527c031180080612f63.idx","hash":"5f5190cb2dbc0d168a93fbf811d066063a87a201","modified":1463211986000},{"_id":"themes/landscape-plus/.git/refs/heads/master","hash":"b4f18e6c37d6aebe0e83ce62a7c8bedb7f95f33e","modified":1463211986000},{"_id":"themes/landscape-plus/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1463211986000},{"_id":"themes/landscape-plus/.git/logs/refs/heads/master","hash":"e624aaeb427912ec56117774717dd434ca574435","modified":1463211986000},{"_id":"themes/landscape-plus/.git/logs/refs/remotes/origin/HEAD","hash":"e624aaeb427912ec56117774717dd434ca574435","modified":1463211986000},{"_id":"themes/landscape-plus/.git/objects/pack/pack-3e37e2fd06fe1e021b714527c031180080612f63.pack","hash":"c7f488aa9ba64044b8580470de27820627713707","modified":1463211986000},{"_id":"source/_posts/vuejs使用中的两个小坑.md","hash":"0aa3ed4dd6fe167f5c0947a91f7c26f5cd349ef6","modified":1463822732000},{"_id":"public/2016/05/20/vuejs使用中的两个小坑/index.html","hash":"dc37f6b395fee4f7bc5929543dbd51b9eaad9fba","modified":1465695171872},{"_id":"public/tags/VueStrap/index.html","hash":"b1e3dba43967ea7be6efe50b697330c571e4c04e","modified":1465695171926},{"_id":"public/tags/bootstrap/index.html","hash":"13ddf7a2528addb6ba324c4b66db1d5c5b3f2a1f","modified":1465695171926},{"_id":"public/tags/生命周期hook/index.html","hash":"b0c06e16bdfef9676a05a9a909091c22d23c3cc0","modified":1465695171926},{"_id":"public/tags/nextTick/index.html","hash":"17f187a8cd1c9d42d7b5e40c3a7c4fe4bbf0fd08","modified":1465695171926},{"_id":"source/_posts/centos下安装nginx+php-fpm.md","hash":"b058476102d7b1401747642f96175cb3de519eb9","modified":1463822719000},{"_id":"public/tags/centos/index.html","hash":"48e12fa380a13d716214aeccf15b9cac5b9d679f","modified":1465695171926},{"_id":"public/2016/05/21/centos下安装nginx+php-fpm/index.html","hash":"95fac0ff835223f8a604a17566e0c936e72ff6b8","modified":1465695171871},{"_id":"public/tags/php-fpm/index.html","hash":"d9c0af94c8fa455e013e13c55d98c780cc2f98d3","modified":1465695171927},{"_id":"source/favicon.png","hash":"36f2598cb552da16006f6c37469b31b812a31ae2","modified":1463212437000},{"_id":"public/favicon.png","hash":"36f2598cb552da16006f6c37469b31b812a31ae2","modified":1465695171984}],"Category":[{"name":"团队协作","_id":"cica18yjj0001gtfyu8xkmbm3"},{"name":"java","_id":"cica18yk2000egtfyvkrdmydl"},{"name":"j2ee","_id":"cica18ykg000zgtfy09rqwb4h"},{"name":"nodejs","_id":"cica18ykl001agtfya1o2ajsi"},{"name":"运维","_id":"cica18yld002ggtfyq1rhy9mp"},{"name":"talk","_id":"cica18ylh002pgtfyk6l8szwo"},{"name":"数据库","_id":"cica18ylm002ugtfyfo9u40cb"},{"name":"前端","_id":"cica18ym0003lgtfyqoedatad"},{"name":"架构","_id":"cica18ym6003qgtfyx7pl02ff"},{"name":"nosql","_id":"cica18ynj005sgtfybb1k7n7v"},{"name":"php","_id":"cica18yon007ogtfyf5x13c9a"},{"name":"mac","_id":"cica18ysl00cwgtfym9plk4no"},{"name":"移动端","_id":"cihp0xups0001mzfycagcbrxa"},{"name":"系统设计","_id":"cilp4udh80001l1fy0ho9xp63"},{"name":"运维,数据库","_id":"cima1so5n0001vofyq19oay8a"},{"name":"groovy","_id":"cimjc5pzg00011nfy5218hbkh"}],"Data":[],"Page":[],"Post":[{"title":"重构团队的开发工作流","date":"2015-02-14T07:54:30.000Z","_content":"\n\n靠近年根儿，手上的工作其实还有很多，不过还是要总结一下，展望一下，这就是人类。\n\n在公司的年会上，我代表开发部做了一个简短的工作汇报，在PPT里写了很多14年的业绩和不足，也包含了15年的计划和方案。与往年不同，今年不仅是公司发展的一年，也是团队壮大的一年，也是个人成长最快的一年。\n<!--more-->\n其实自己确实有思考过很多，也收获了很多，找到了团队的痛点，也拿到了公司的授权，所以在15年初，要落实一些新的计划。想要强调的是，这些改革并不是我个人的主观意愿，并非我个人想为而为之的，而是包含了开发部各个层面的景愿的。我把我ppt中相关的一页截了个图，给大家展示一下：\n\n![](http://pic.yupoo.com/kazaff/EqIBD7s3/medish.jpg)\n\n你可能会诧异，这些都是围绕这工具的，是的没错，我们的团队以往一直都是靠人海战术来完成这些工作的，尽管团队也就才11个人而已。也许身在大公司的你觉得不可思议的是，没有这些工具，那开发人员要怎么活？项目质量怎么可能有保证？产品怎么可能如期交付？\n\n这些问题其实在任何一家小公司，创业公司都很常见，像我们这种小城市的创业小团队就更习以为常了，我这么说并非妄自菲薄，纯粹是尊重事实而已！刚到公司，刚走上这个岗位的时候，也曾看过一些敏捷开发，摩拳擦掌想要试试，甚至激进的和大领导申请SOHO办公。\n\n后来在InfoQ上看了一些关于团队协作的分享后，确实得到了很多启发，也迫使自己真的第一次思考了一下所处的真实环境。尊重现实吧骚年，妄想那些远在天边的不切实际，最终只是浪费青春。\n\n废话不多说，我们回过头来继续聊主题，如何完成幻灯片上提到的那些点。\n\n\n\n代码质量\n---\n深入思考以后，我把代码质量分为两个方面：\n\n- 业务\n- 代码本身\n\n判断程序员写的代码的质量高低，以我们现在的能力和认知，从上述两个方面最容易做到。**业务**指的是程序员完成项目需求的程度，是否存在功能缺失，是否存在业务理解错误等方面，而**代码本身**则指的是程序员提交的代码是否满足团队的代码规范等相关要求。\n\n可以看出来，前者需要有经验的人来检验团队中的其他参与者，有点像师傅带徒弟的模式，在我们的团队（我相信很多公司都如此），师傅带徒弟模式反而是一种非常高效的培养骨干的方式。\n\n后者则可以交给一些现成的工具来完成，下面我就简单聊一下我脑子里的一些计划。首先要引入两个开源工具：\n\n- [GitLab](https://about.gitlab.com/)\n- [Sonar](http://www.sonarqube.org/)\n\n前者是类似github那样的一个基于git的协同开发平台，提供了功能完善的web界面。之所以选择它，而不是直接使用git，是因为gtilab提供了许多辅助文档化的功能，比方说可以让问题和代码更好的关联在一起，具体做法，可以参见[gitlab flow](http://www.15yan.com/story/6yueHxcgD9Z/#show-last-Point)。\n\n后者提供了强大的代码质量监督功能，不仅支持多种语言，而且也有很好的统计以及社交界面。不过也有些许的不如意，可能是用的不熟的原因吧，具体问题可以看[这里](http://segmentfault.com/q/1010000002553887)。\n\n这两个工具都支持与持续集成套件协作，这就为日后的工作提供了衔接。\n\n在借鉴了一些成熟的work flow后，结合我们团队目前的真实情况，我草拟了一个工作流，如下图：\n\n[![](http://pic.yupoo.com/kazaff/EqOi8ovp/medish.jpg)](http://pic.yupoo.com/kazaff/EqOi8ovp/j8VYL.png)\n\n有兴趣的童鞋可以留言一起讨论哇~\n\n只有解决了这些问题，才可以为PPT上后面两项最好工具基础。\n\n\n\n\n自动化测试\n---\n\n还在我写垃圾网站的那些岁月了，我就已经对持续集成这个概念热血沸腾了，不过那个时候更多的只是被其逼格所吸引。随着团队的壮大，项目的成长，慢慢觉得持续集成不仅仅是搞个工具，定个流程那么简单地问题。这玩意儿是需要很多理论支撑的，需要团队成员有相当的职业素养和扎实的技能。甚至也需要其他部门的大力配合，毕竟是一件有得有失的事儿。\n\n我们团队目前的痛点集中在测试环节上，他们已经被手工测试作业折腾的苦不堪言了，更不要说每次修改完bug后的回归测试了，那感觉简直就像是被轮奸，特酸爽。\n\n当然，也不是说自动化就意味着能够把测试完全交给机器来做，凭借公司现在的实力也不可能像模像样的成立一个专门的测试部门，而且我比较认可一个观点：己所不欲勿施于人。如果只是因为程序员不喜欢做测试，而把测试工作交给别的部门来做，那问题依然存在，其他部门也会恶心于这份工作的枯燥乏味。\n\n那么如何能够增加测试的趣味性呢？这个恐怕真的很难做到，不过倒是可以让测试变得不再那么枯燥，引入测试驱动是一个很好的方法，不过这其实并不是减轻了工作量，从某种角度来看反而是加大了代码量，毕竟测试代码也是要交给程序员来完成的。\n\n优势在于回归测试，如果上升到理论的话，程序员还会因为这种思维模式而在编程思想上得到升华。omg~~\n\n自动化测试中包括的关键词有：单元测试，代码覆盖率等，早在以前我也花了一些时间去了解这些玩意儿，不过一直没有投入使用。15年要迫使自己带头推行测试驱动开发。\n\n**测试又要分为：前端，后端。前端又分为：交互，兼容，逻辑。**当然，这种分类是源于我个人的粗浅理解。至于使用什么具体的工具来搭建自动化测试平台和工作流程，目前无解。\n\n目前目标锁定在：Junit，Jenkins，Mockito等框架。\n\n哇哈哈哈哈哈哈哈哈~实践后再来补充吧。\n\n\n\n\n\n运维监控\n---\n\n这里想说的主要还是监控预警，至于日志分析什么的，并不在这个主题下。我也不曾做过运维相关的职位，也没有太多使用云平台的经验，在这个主题下，我只能说自己的认知很片面，停留在架设一套开源运维监控系统来搞定，目前目标锁定在：Nagios。\n\n\n至于应用的监控，可能会尝试花一些时间看一下：kafka，flume，kibana等工具。\n\n\n\n\n---\n好啦，这篇算是个伏笔吧，等在上面三个方向上尝试过以后再来补充。","source":"_posts/重构团队的开发工作流.md","raw":"title: 重构团队的开发工作流\ndate: 2015-02-14 15:54:30\ntags:\n- code review\n- git\n- gitlab\n- sonar\n- 运维 \n\ncategories: 团队协作\n---\n\n\n靠近年根儿，手上的工作其实还有很多，不过还是要总结一下，展望一下，这就是人类。\n\n在公司的年会上，我代表开发部做了一个简短的工作汇报，在PPT里写了很多14年的业绩和不足，也包含了15年的计划和方案。与往年不同，今年不仅是公司发展的一年，也是团队壮大的一年，也是个人成长最快的一年。\n<!--more-->\n其实自己确实有思考过很多，也收获了很多，找到了团队的痛点，也拿到了公司的授权，所以在15年初，要落实一些新的计划。想要强调的是，这些改革并不是我个人的主观意愿，并非我个人想为而为之的，而是包含了开发部各个层面的景愿的。我把我ppt中相关的一页截了个图，给大家展示一下：\n\n![](http://pic.yupoo.com/kazaff/EqIBD7s3/medish.jpg)\n\n你可能会诧异，这些都是围绕这工具的，是的没错，我们的团队以往一直都是靠人海战术来完成这些工作的，尽管团队也就才11个人而已。也许身在大公司的你觉得不可思议的是，没有这些工具，那开发人员要怎么活？项目质量怎么可能有保证？产品怎么可能如期交付？\n\n这些问题其实在任何一家小公司，创业公司都很常见，像我们这种小城市的创业小团队就更习以为常了，我这么说并非妄自菲薄，纯粹是尊重事实而已！刚到公司，刚走上这个岗位的时候，也曾看过一些敏捷开发，摩拳擦掌想要试试，甚至激进的和大领导申请SOHO办公。\n\n后来在InfoQ上看了一些关于团队协作的分享后，确实得到了很多启发，也迫使自己真的第一次思考了一下所处的真实环境。尊重现实吧骚年，妄想那些远在天边的不切实际，最终只是浪费青春。\n\n废话不多说，我们回过头来继续聊主题，如何完成幻灯片上提到的那些点。\n\n\n\n代码质量\n---\n深入思考以后，我把代码质量分为两个方面：\n\n- 业务\n- 代码本身\n\n判断程序员写的代码的质量高低，以我们现在的能力和认知，从上述两个方面最容易做到。**业务**指的是程序员完成项目需求的程度，是否存在功能缺失，是否存在业务理解错误等方面，而**代码本身**则指的是程序员提交的代码是否满足团队的代码规范等相关要求。\n\n可以看出来，前者需要有经验的人来检验团队中的其他参与者，有点像师傅带徒弟的模式，在我们的团队（我相信很多公司都如此），师傅带徒弟模式反而是一种非常高效的培养骨干的方式。\n\n后者则可以交给一些现成的工具来完成，下面我就简单聊一下我脑子里的一些计划。首先要引入两个开源工具：\n\n- [GitLab](https://about.gitlab.com/)\n- [Sonar](http://www.sonarqube.org/)\n\n前者是类似github那样的一个基于git的协同开发平台，提供了功能完善的web界面。之所以选择它，而不是直接使用git，是因为gtilab提供了许多辅助文档化的功能，比方说可以让问题和代码更好的关联在一起，具体做法，可以参见[gitlab flow](http://www.15yan.com/story/6yueHxcgD9Z/#show-last-Point)。\n\n后者提供了强大的代码质量监督功能，不仅支持多种语言，而且也有很好的统计以及社交界面。不过也有些许的不如意，可能是用的不熟的原因吧，具体问题可以看[这里](http://segmentfault.com/q/1010000002553887)。\n\n这两个工具都支持与持续集成套件协作，这就为日后的工作提供了衔接。\n\n在借鉴了一些成熟的work flow后，结合我们团队目前的真实情况，我草拟了一个工作流，如下图：\n\n[![](http://pic.yupoo.com/kazaff/EqOi8ovp/medish.jpg)](http://pic.yupoo.com/kazaff/EqOi8ovp/j8VYL.png)\n\n有兴趣的童鞋可以留言一起讨论哇~\n\n只有解决了这些问题，才可以为PPT上后面两项最好工具基础。\n\n\n\n\n自动化测试\n---\n\n还在我写垃圾网站的那些岁月了，我就已经对持续集成这个概念热血沸腾了，不过那个时候更多的只是被其逼格所吸引。随着团队的壮大，项目的成长，慢慢觉得持续集成不仅仅是搞个工具，定个流程那么简单地问题。这玩意儿是需要很多理论支撑的，需要团队成员有相当的职业素养和扎实的技能。甚至也需要其他部门的大力配合，毕竟是一件有得有失的事儿。\n\n我们团队目前的痛点集中在测试环节上，他们已经被手工测试作业折腾的苦不堪言了，更不要说每次修改完bug后的回归测试了，那感觉简直就像是被轮奸，特酸爽。\n\n当然，也不是说自动化就意味着能够把测试完全交给机器来做，凭借公司现在的实力也不可能像模像样的成立一个专门的测试部门，而且我比较认可一个观点：己所不欲勿施于人。如果只是因为程序员不喜欢做测试，而把测试工作交给别的部门来做，那问题依然存在，其他部门也会恶心于这份工作的枯燥乏味。\n\n那么如何能够增加测试的趣味性呢？这个恐怕真的很难做到，不过倒是可以让测试变得不再那么枯燥，引入测试驱动是一个很好的方法，不过这其实并不是减轻了工作量，从某种角度来看反而是加大了代码量，毕竟测试代码也是要交给程序员来完成的。\n\n优势在于回归测试，如果上升到理论的话，程序员还会因为这种思维模式而在编程思想上得到升华。omg~~\n\n自动化测试中包括的关键词有：单元测试，代码覆盖率等，早在以前我也花了一些时间去了解这些玩意儿，不过一直没有投入使用。15年要迫使自己带头推行测试驱动开发。\n\n**测试又要分为：前端，后端。前端又分为：交互，兼容，逻辑。**当然，这种分类是源于我个人的粗浅理解。至于使用什么具体的工具来搭建自动化测试平台和工作流程，目前无解。\n\n目前目标锁定在：Junit，Jenkins，Mockito等框架。\n\n哇哈哈哈哈哈哈哈哈~实践后再来补充吧。\n\n\n\n\n\n运维监控\n---\n\n这里想说的主要还是监控预警，至于日志分析什么的，并不在这个主题下。我也不曾做过运维相关的职位，也没有太多使用云平台的经验，在这个主题下，我只能说自己的认知很片面，停留在架设一套开源运维监控系统来搞定，目前目标锁定在：Nagios。\n\n\n至于应用的监控，可能会尝试花一些时间看一下：kafka，flume，kibana等工具。\n\n\n\n\n---\n好啦，这篇算是个伏笔吧，等在上面三个方向上尝试过以后再来补充。","slug":"重构团队的开发工作流","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yjc0000gtfyl5nanu8y","comments":1,"layout":"post","photos":[],"link":"","content":"<p>靠近年根儿，手上的工作其实还有很多，不过还是要总结一下，展望一下，这就是人类。</p>\n<p>在公司的年会上，我代表开发部做了一个简短的工作汇报，在PPT里写了很多14年的业绩和不足，也包含了15年的计划和方案。与往年不同，今年不仅是公司发展的一年，也是团队壮大的一年，也是个人成长最快的一年。<br><a id=\"more\"></a><br>其实自己确实有思考过很多，也收获了很多，找到了团队的痛点，也拿到了公司的授权，所以在15年初，要落实一些新的计划。想要强调的是，这些改革并不是我个人的主观意愿，并非我个人想为而为之的，而是包含了开发部各个层面的景愿的。我把我ppt中相关的一页截了个图，给大家展示一下：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EqIBD7s3/medish.jpg\" alt=\"\"></p>\n<p>你可能会诧异，这些都是围绕这工具的，是的没错，我们的团队以往一直都是靠人海战术来完成这些工作的，尽管团队也就才11个人而已。也许身在大公司的你觉得不可思议的是，没有这些工具，那开发人员要怎么活？项目质量怎么可能有保证？产品怎么可能如期交付？</p>\n<p>这些问题其实在任何一家小公司，创业公司都很常见，像我们这种小城市的创业小团队就更习以为常了，我这么说并非妄自菲薄，纯粹是尊重事实而已！刚到公司，刚走上这个岗位的时候，也曾看过一些敏捷开发，摩拳擦掌想要试试，甚至激进的和大领导申请SOHO办公。</p>\n<p>后来在InfoQ上看了一些关于团队协作的分享后，确实得到了很多启发，也迫使自己真的第一次思考了一下所处的真实环境。尊重现实吧骚年，妄想那些远在天边的不切实际，最终只是浪费青春。</p>\n<p>废话不多说，我们回过头来继续聊主题，如何完成幻灯片上提到的那些点。</p>\n<h2 id=\"代码质量\"><a href=\"#代码质量\" class=\"headerlink\" title=\"代码质量\"></a>代码质量</h2><p>深入思考以后，我把代码质量分为两个方面：</p>\n<ul>\n<li>业务</li>\n<li>代码本身</li>\n</ul>\n<p>判断程序员写的代码的质量高低，以我们现在的能力和认知，从上述两个方面最容易做到。<strong>业务</strong>指的是程序员完成项目需求的程度，是否存在功能缺失，是否存在业务理解错误等方面，而<strong>代码本身</strong>则指的是程序员提交的代码是否满足团队的代码规范等相关要求。</p>\n<p>可以看出来，前者需要有经验的人来检验团队中的其他参与者，有点像师傅带徒弟的模式，在我们的团队（我相信很多公司都如此），师傅带徒弟模式反而是一种非常高效的培养骨干的方式。</p>\n<p>后者则可以交给一些现成的工具来完成，下面我就简单聊一下我脑子里的一些计划。首先要引入两个开源工具：</p>\n<ul>\n<li><a href=\"https://about.gitlab.com/\" target=\"_blank\" rel=\"external\">GitLab</a></li>\n<li><a href=\"http://www.sonarqube.org/\" target=\"_blank\" rel=\"external\">Sonar</a></li>\n</ul>\n<p>前者是类似github那样的一个基于git的协同开发平台，提供了功能完善的web界面。之所以选择它，而不是直接使用git，是因为gtilab提供了许多辅助文档化的功能，比方说可以让问题和代码更好的关联在一起，具体做法，可以参见<a href=\"http://www.15yan.com/story/6yueHxcgD9Z/#show-last-Point\" target=\"_blank\" rel=\"external\">gitlab flow</a>。</p>\n<p>后者提供了强大的代码质量监督功能，不仅支持多种语言，而且也有很好的统计以及社交界面。不过也有些许的不如意，可能是用的不熟的原因吧，具体问题可以看<a href=\"http://segmentfault.com/q/1010000002553887\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>这两个工具都支持与持续集成套件协作，这就为日后的工作提供了衔接。</p>\n<p>在借鉴了一些成熟的work flow后，结合我们团队目前的真实情况，我草拟了一个工作流，如下图：</p>\n<p><a href=\"http://pic.yupoo.com/kazaff/EqOi8ovp/j8VYL.png\" target=\"_blank\" rel=\"external\"><img src=\"http://pic.yupoo.com/kazaff/EqOi8ovp/medish.jpg\" alt=\"\"></a></p>\n<p>有兴趣的童鞋可以留言一起讨论哇~</p>\n<p>只有解决了这些问题，才可以为PPT上后面两项最好工具基础。</p>\n<h2 id=\"自动化测试\"><a href=\"#自动化测试\" class=\"headerlink\" title=\"自动化测试\"></a>自动化测试</h2><p>还在我写垃圾网站的那些岁月了，我就已经对持续集成这个概念热血沸腾了，不过那个时候更多的只是被其逼格所吸引。随着团队的壮大，项目的成长，慢慢觉得持续集成不仅仅是搞个工具，定个流程那么简单地问题。这玩意儿是需要很多理论支撑的，需要团队成员有相当的职业素养和扎实的技能。甚至也需要其他部门的大力配合，毕竟是一件有得有失的事儿。</p>\n<p>我们团队目前的痛点集中在测试环节上，他们已经被手工测试作业折腾的苦不堪言了，更不要说每次修改完bug后的回归测试了，那感觉简直就像是被轮奸，特酸爽。</p>\n<p>当然，也不是说自动化就意味着能够把测试完全交给机器来做，凭借公司现在的实力也不可能像模像样的成立一个专门的测试部门，而且我比较认可一个观点：己所不欲勿施于人。如果只是因为程序员不喜欢做测试，而把测试工作交给别的部门来做，那问题依然存在，其他部门也会恶心于这份工作的枯燥乏味。</p>\n<p>那么如何能够增加测试的趣味性呢？这个恐怕真的很难做到，不过倒是可以让测试变得不再那么枯燥，引入测试驱动是一个很好的方法，不过这其实并不是减轻了工作量，从某种角度来看反而是加大了代码量，毕竟测试代码也是要交给程序员来完成的。</p>\n<p>优势在于回归测试，如果上升到理论的话，程序员还会因为这种思维模式而在编程思想上得到升华。omg~~</p>\n<p>自动化测试中包括的关键词有：单元测试，代码覆盖率等，早在以前我也花了一些时间去了解这些玩意儿，不过一直没有投入使用。15年要迫使自己带头推行测试驱动开发。</p>\n<p><strong>测试又要分为：前端，后端。前端又分为：交互，兼容，逻辑。</strong>当然，这种分类是源于我个人的粗浅理解。至于使用什么具体的工具来搭建自动化测试平台和工作流程，目前无解。</p>\n<p>目前目标锁定在：Junit，Jenkins，Mockito等框架。</p>\n<p>哇哈哈哈哈哈哈哈哈~实践后再来补充吧。</p>\n<h2 id=\"运维监控\"><a href=\"#运维监控\" class=\"headerlink\" title=\"运维监控\"></a>运维监控</h2><p>这里想说的主要还是监控预警，至于日志分析什么的，并不在这个主题下。我也不曾做过运维相关的职位，也没有太多使用云平台的经验，在这个主题下，我只能说自己的认知很片面，停留在架设一套开源运维监控系统来搞定，目前目标锁定在：Nagios。</p>\n<p>至于应用的监控，可能会尝试花一些时间看一下：kafka，flume，kibana等工具。</p>\n<hr>\n<p>好啦，这篇算是个伏笔吧，等在上面三个方向上尝试过以后再来补充。</p>\n","excerpt":"<p>靠近年根儿，手上的工作其实还有很多，不过还是要总结一下，展望一下，这就是人类。</p>\n<p>在公司的年会上，我代表开发部做了一个简短的工作汇报，在PPT里写了很多14年的业绩和不足，也包含了15年的计划和方案。与往年不同，今年不仅是公司发展的一年，也是团队壮大的一年，也是个人成长最快的一年。<br>","more":"<br>其实自己确实有思考过很多，也收获了很多，找到了团队的痛点，也拿到了公司的授权，所以在15年初，要落实一些新的计划。想要强调的是，这些改革并不是我个人的主观意愿，并非我个人想为而为之的，而是包含了开发部各个层面的景愿的。我把我ppt中相关的一页截了个图，给大家展示一下：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EqIBD7s3/medish.jpg\" alt=\"\"></p>\n<p>你可能会诧异，这些都是围绕这工具的，是的没错，我们的团队以往一直都是靠人海战术来完成这些工作的，尽管团队也就才11个人而已。也许身在大公司的你觉得不可思议的是，没有这些工具，那开发人员要怎么活？项目质量怎么可能有保证？产品怎么可能如期交付？</p>\n<p>这些问题其实在任何一家小公司，创业公司都很常见，像我们这种小城市的创业小团队就更习以为常了，我这么说并非妄自菲薄，纯粹是尊重事实而已！刚到公司，刚走上这个岗位的时候，也曾看过一些敏捷开发，摩拳擦掌想要试试，甚至激进的和大领导申请SOHO办公。</p>\n<p>后来在InfoQ上看了一些关于团队协作的分享后，确实得到了很多启发，也迫使自己真的第一次思考了一下所处的真实环境。尊重现实吧骚年，妄想那些远在天边的不切实际，最终只是浪费青春。</p>\n<p>废话不多说，我们回过头来继续聊主题，如何完成幻灯片上提到的那些点。</p>\n<h2 id=\"代码质量\"><a href=\"#代码质量\" class=\"headerlink\" title=\"代码质量\"></a>代码质量</h2><p>深入思考以后，我把代码质量分为两个方面：</p>\n<ul>\n<li>业务</li>\n<li>代码本身</li>\n</ul>\n<p>判断程序员写的代码的质量高低，以我们现在的能力和认知，从上述两个方面最容易做到。<strong>业务</strong>指的是程序员完成项目需求的程度，是否存在功能缺失，是否存在业务理解错误等方面，而<strong>代码本身</strong>则指的是程序员提交的代码是否满足团队的代码规范等相关要求。</p>\n<p>可以看出来，前者需要有经验的人来检验团队中的其他参与者，有点像师傅带徒弟的模式，在我们的团队（我相信很多公司都如此），师傅带徒弟模式反而是一种非常高效的培养骨干的方式。</p>\n<p>后者则可以交给一些现成的工具来完成，下面我就简单聊一下我脑子里的一些计划。首先要引入两个开源工具：</p>\n<ul>\n<li><a href=\"https://about.gitlab.com/\">GitLab</a></li>\n<li><a href=\"http://www.sonarqube.org/\">Sonar</a></li>\n</ul>\n<p>前者是类似github那样的一个基于git的协同开发平台，提供了功能完善的web界面。之所以选择它，而不是直接使用git，是因为gtilab提供了许多辅助文档化的功能，比方说可以让问题和代码更好的关联在一起，具体做法，可以参见<a href=\"http://www.15yan.com/story/6yueHxcgD9Z/#show-last-Point\">gitlab flow</a>。</p>\n<p>后者提供了强大的代码质量监督功能，不仅支持多种语言，而且也有很好的统计以及社交界面。不过也有些许的不如意，可能是用的不熟的原因吧，具体问题可以看<a href=\"http://segmentfault.com/q/1010000002553887\">这里</a>。</p>\n<p>这两个工具都支持与持续集成套件协作，这就为日后的工作提供了衔接。</p>\n<p>在借鉴了一些成熟的work flow后，结合我们团队目前的真实情况，我草拟了一个工作流，如下图：</p>\n<p><a href=\"http://pic.yupoo.com/kazaff/EqOi8ovp/j8VYL.png\"><img src=\"http://pic.yupoo.com/kazaff/EqOi8ovp/medish.jpg\" alt=\"\"></a></p>\n<p>有兴趣的童鞋可以留言一起讨论哇~</p>\n<p>只有解决了这些问题，才可以为PPT上后面两项最好工具基础。</p>\n<h2 id=\"自动化测试\"><a href=\"#自动化测试\" class=\"headerlink\" title=\"自动化测试\"></a>自动化测试</h2><p>还在我写垃圾网站的那些岁月了，我就已经对持续集成这个概念热血沸腾了，不过那个时候更多的只是被其逼格所吸引。随着团队的壮大，项目的成长，慢慢觉得持续集成不仅仅是搞个工具，定个流程那么简单地问题。这玩意儿是需要很多理论支撑的，需要团队成员有相当的职业素养和扎实的技能。甚至也需要其他部门的大力配合，毕竟是一件有得有失的事儿。</p>\n<p>我们团队目前的痛点集中在测试环节上，他们已经被手工测试作业折腾的苦不堪言了，更不要说每次修改完bug后的回归测试了，那感觉简直就像是被轮奸，特酸爽。</p>\n<p>当然，也不是说自动化就意味着能够把测试完全交给机器来做，凭借公司现在的实力也不可能像模像样的成立一个专门的测试部门，而且我比较认可一个观点：己所不欲勿施于人。如果只是因为程序员不喜欢做测试，而把测试工作交给别的部门来做，那问题依然存在，其他部门也会恶心于这份工作的枯燥乏味。</p>\n<p>那么如何能够增加测试的趣味性呢？这个恐怕真的很难做到，不过倒是可以让测试变得不再那么枯燥，引入测试驱动是一个很好的方法，不过这其实并不是减轻了工作量，从某种角度来看反而是加大了代码量，毕竟测试代码也是要交给程序员来完成的。</p>\n<p>优势在于回归测试，如果上升到理论的话，程序员还会因为这种思维模式而在编程思想上得到升华。omg~~</p>\n<p>自动化测试中包括的关键词有：单元测试，代码覆盖率等，早在以前我也花了一些时间去了解这些玩意儿，不过一直没有投入使用。15年要迫使自己带头推行测试驱动开发。</p>\n<p><strong>测试又要分为：前端，后端。前端又分为：交互，兼容，逻辑。</strong>当然，这种分类是源于我个人的粗浅理解。至于使用什么具体的工具来搭建自动化测试平台和工作流程，目前无解。</p>\n<p>目前目标锁定在：Junit，Jenkins，Mockito等框架。</p>\n<p>哇哈哈哈哈哈哈哈哈~实践后再来补充吧。</p>\n<h2 id=\"运维监控\"><a href=\"#运维监控\" class=\"headerlink\" title=\"运维监控\"></a>运维监控</h2><p>这里想说的主要还是监控预警，至于日志分析什么的，并不在这个主题下。我也不曾做过运维相关的职位，也没有太多使用云平台的经验，在这个主题下，我只能说自己的认知很片面，停留在架设一套开源运维监控系统来搞定，目前目标锁定在：Nagios。</p>\n<p>至于应用的监控，可能会尝试花一些时间看一下：kafka，flume，kibana等工具。</p>\n<hr>\n<p>好啦，这篇算是个伏笔吧，等在上面三个方向上尝试过以后再来补充。</p>"},{"title":"解决springMVC4下使用@ResponseBody的中文乱码问题","date":"2014-12-01T01:37:12.000Z","_content":"\n由于现在的项目一般都追求前后端分离，依靠Ajax进行通信，这样有助于团队分工、项目维护和后期的平台移植，这就使得后端框架对视图层的功能要求越来越低~\n<!-- more -->\n今天要说的是基于SpringMVC开发web后端时，为了简单而直接在控制器方法中返回json字符串时碰到的中文乱码问题。算是非常基础的问题，大牛请绕道~\n\n其实我自己一开始也没觉得能有多复杂，认为一搜索就能找到一大把解决方案，所以没有计划耗费多久时间，更没打算转成写一篇博文记录过程。可不曾想到，足足花了我2个半小时，今天看来又要加班了！其实确实在GG和百度中搜索到了大量的相关解决方案，晒晒捡捡也发现至少有不下七八种解决方案。可悲剧的是统统在我测试下无效。\n\n对于JAVAEE，我真真儿的是新手，项目也没有给我太多时间来深究源码，只能快速的试错，总算把几个方案拼凑出来一个能用的了！下面我就简单的说一下我的解决方法吧。\n\n首先，我们要知道，为毛`@ResponseBody`不支持中文：[传送门](http://tchen8.iteye.com/blog/993504)，这是我找到的写的最细的一篇文章了，尽管它并没有解决我的问题。\n\n知道了原因，再来选择解决方案，一开始满心欢喜的找到一个最简单的方案：\n\n\t@RequestMapping(value = \"/add\", produces = {\"application/json;charset=UTF-8\"})\n\n可是不管用撒，原因不明~~\n\n好吧，那再试一个：\n\n\tresponse.setContentType(\"text/plain;charset=UTF-8\");\n\n也不行哇，这个其实只是设置了响应头中的字符集，但是`@ResponseBody`最终还是会把字符以“ISO-8859-1”的方式输出，可恶！\n\n简单的方法木牛了，只能选择手动设置字符转换类了：\n\n\t<bean class=\"org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter\" >  \n\t\t<property name=\"messageConverters\">   \n\t\t\t<list>   \n\t\t\t\t<bean class = \"org.springframework.http.converter.StringHttpMessageConverter\">   \n\t\t\t\t\t<property name = \"supportedMediaTypes\">\n\t\t\t\t\t\t<list>\n\t\t\t\t\t\t\t<value>text/html;charset=UTF-8</value>   \n\t\t\t\t\t\t</list>   \n\t\t\t\t\t</property>   \n\t\t\t\t</bean>   \n\t\t\t</list>   \n\t   </property>  \n\t</bean>  \n\n注意，需要把这段放在`xxx-servlet.xml`中`<context:component-scan base-package=\"xxxxx\"/>`前面哦~\n\n其实这样已经可以解决了，不过不完美，留一下这个时候的响应头，你会发现体积非常大（Accept-Charset会达到4K+），这是因为默认情况下`StringHttpMessageConverter.writeInternal()`会将所有可用字符集回写到响应头中，这会消耗非常大的带宽！浪费可耻！\n\n一筹莫展了吧~幸好发现`StringHttpMessageConverter`提供的参数：`writeAcceptCharset`，所以最终的写法如下：\n\n\t<!-- 用于使用@ResponseBody后返回中文避免乱码 -->\n    <bean class=\"org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter\" >\n        <property name=\"messageConverters\">\n            <list>\n                <bean id=\"stringHttpMessageConverter\" class=\"org.springframework.http.converter.StringHttpMessageConverter\">\n                    <property name=\"writeAcceptCharset\" value=\"false\" /><!-- 用于避免响应头过大 -->\n                    <property name=\"supportedMediaTypes\">\n                        <list>\n                            <value>text/html;charset=UTF-8</value>\n                        </list>\n                    </property>\n                </bean>\n            </list>\n        </property>\n    </bean>\n\n哎，两个多小时就干了点儿这，感觉好尴尬啊！！\n","source":"_posts/解决springMVC4下使用@ResponseBody的中文乱码.md","raw":"title: 解决springMVC4下使用@ResponseBody的中文乱码问题\ndate: 2014-12-01 09:37:12\ntags: \n- springmvc\n- 中文乱码\n\ncategories: \n- java\n---\n\n由于现在的项目一般都追求前后端分离，依靠Ajax进行通信，这样有助于团队分工、项目维护和后期的平台移植，这就使得后端框架对视图层的功能要求越来越低~\n<!-- more -->\n今天要说的是基于SpringMVC开发web后端时，为了简单而直接在控制器方法中返回json字符串时碰到的中文乱码问题。算是非常基础的问题，大牛请绕道~\n\n其实我自己一开始也没觉得能有多复杂，认为一搜索就能找到一大把解决方案，所以没有计划耗费多久时间，更没打算转成写一篇博文记录过程。可不曾想到，足足花了我2个半小时，今天看来又要加班了！其实确实在GG和百度中搜索到了大量的相关解决方案，晒晒捡捡也发现至少有不下七八种解决方案。可悲剧的是统统在我测试下无效。\n\n对于JAVAEE，我真真儿的是新手，项目也没有给我太多时间来深究源码，只能快速的试错，总算把几个方案拼凑出来一个能用的了！下面我就简单的说一下我的解决方法吧。\n\n首先，我们要知道，为毛`@ResponseBody`不支持中文：[传送门](http://tchen8.iteye.com/blog/993504)，这是我找到的写的最细的一篇文章了，尽管它并没有解决我的问题。\n\n知道了原因，再来选择解决方案，一开始满心欢喜的找到一个最简单的方案：\n\n\t@RequestMapping(value = \"/add\", produces = {\"application/json;charset=UTF-8\"})\n\n可是不管用撒，原因不明~~\n\n好吧，那再试一个：\n\n\tresponse.setContentType(\"text/plain;charset=UTF-8\");\n\n也不行哇，这个其实只是设置了响应头中的字符集，但是`@ResponseBody`最终还是会把字符以“ISO-8859-1”的方式输出，可恶！\n\n简单的方法木牛了，只能选择手动设置字符转换类了：\n\n\t<bean class=\"org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter\" >  \n\t\t<property name=\"messageConverters\">   \n\t\t\t<list>   \n\t\t\t\t<bean class = \"org.springframework.http.converter.StringHttpMessageConverter\">   \n\t\t\t\t\t<property name = \"supportedMediaTypes\">\n\t\t\t\t\t\t<list>\n\t\t\t\t\t\t\t<value>text/html;charset=UTF-8</value>   \n\t\t\t\t\t\t</list>   \n\t\t\t\t\t</property>   \n\t\t\t\t</bean>   \n\t\t\t</list>   \n\t   </property>  \n\t</bean>  \n\n注意，需要把这段放在`xxx-servlet.xml`中`<context:component-scan base-package=\"xxxxx\"/>`前面哦~\n\n其实这样已经可以解决了，不过不完美，留一下这个时候的响应头，你会发现体积非常大（Accept-Charset会达到4K+），这是因为默认情况下`StringHttpMessageConverter.writeInternal()`会将所有可用字符集回写到响应头中，这会消耗非常大的带宽！浪费可耻！\n\n一筹莫展了吧~幸好发现`StringHttpMessageConverter`提供的参数：`writeAcceptCharset`，所以最终的写法如下：\n\n\t<!-- 用于使用@ResponseBody后返回中文避免乱码 -->\n    <bean class=\"org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter\" >\n        <property name=\"messageConverters\">\n            <list>\n                <bean id=\"stringHttpMessageConverter\" class=\"org.springframework.http.converter.StringHttpMessageConverter\">\n                    <property name=\"writeAcceptCharset\" value=\"false\" /><!-- 用于避免响应头过大 -->\n                    <property name=\"supportedMediaTypes\">\n                        <list>\n                            <value>text/html;charset=UTF-8</value>\n                        </list>\n                    </property>\n                </bean>\n            </list>\n        </property>\n    </bean>\n\n哎，两个多小时就干了点儿这，感觉好尴尬啊！！\n","slug":"解决springMVC4下使用@ResponseBody的中文乱码","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yk0000dgtfybveb0si0","comments":1,"layout":"post","photos":[],"link":"","content":"<p>由于现在的项目一般都追求前后端分离，依靠Ajax进行通信，这样有助于团队分工、项目维护和后期的平台移植，这就使得后端框架对视图层的功能要求越来越低~<br><a id=\"more\"></a><br>今天要说的是基于SpringMVC开发web后端时，为了简单而直接在控制器方法中返回json字符串时碰到的中文乱码问题。算是非常基础的问题，大牛请绕道~</p>\n<p>其实我自己一开始也没觉得能有多复杂，认为一搜索就能找到一大把解决方案，所以没有计划耗费多久时间，更没打算转成写一篇博文记录过程。可不曾想到，足足花了我2个半小时，今天看来又要加班了！其实确实在GG和百度中搜索到了大量的相关解决方案，晒晒捡捡也发现至少有不下七八种解决方案。可悲剧的是统统在我测试下无效。</p>\n<p>对于JAVAEE，我真真儿的是新手，项目也没有给我太多时间来深究源码，只能快速的试错，总算把几个方案拼凑出来一个能用的了！下面我就简单的说一下我的解决方法吧。</p>\n<p>首先，我们要知道，为毛<code>@ResponseBody</code>不支持中文：<a href=\"http://tchen8.iteye.com/blog/993504\" target=\"_blank\" rel=\"external\">传送门</a>，这是我找到的写的最细的一篇文章了，尽管它并没有解决我的问题。</p>\n<p>知道了原因，再来选择解决方案，一开始满心欢喜的找到一个最简单的方案：</p>\n<pre><code>@RequestMapping(value = &quot;/add&quot;, produces = {&quot;application/json;charset=UTF-8&quot;})\n</code></pre><p>可是不管用撒，原因不明~~</p>\n<p>好吧，那再试一个：</p>\n<pre><code>response.setContentType(&quot;text/plain;charset=UTF-8&quot;);\n</code></pre><p>也不行哇，这个其实只是设置了响应头中的字符集，但是<code>@ResponseBody</code>最终还是会把字符以“ISO-8859-1”的方式输出，可恶！</p>\n<p>简单的方法木牛了，只能选择手动设置字符转换类了：</p>\n<pre><code>&lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot; &gt;  \n    &lt;property name=&quot;messageConverters&quot;&gt;   \n        &lt;list&gt;   \n            &lt;bean class = &quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;   \n                &lt;property name = &quot;supportedMediaTypes&quot;&gt;\n                    &lt;list&gt;\n                        &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;   \n                    &lt;/list&gt;   \n                &lt;/property&gt;   \n            &lt;/bean&gt;   \n        &lt;/list&gt;   \n   &lt;/property&gt;  \n&lt;/bean&gt;  \n</code></pre><p>注意，需要把这段放在<code>xxx-servlet.xml</code>中<code>&lt;context:component-scan base-package=&quot;xxxxx&quot;/&gt;</code>前面哦~</p>\n<p>其实这样已经可以解决了，不过不完美，留一下这个时候的响应头，你会发现体积非常大（Accept-Charset会达到4K+），这是因为默认情况下<code>StringHttpMessageConverter.writeInternal()</code>会将所有可用字符集回写到响应头中，这会消耗非常大的带宽！浪费可耻！</p>\n<p>一筹莫展了吧~幸好发现<code>StringHttpMessageConverter</code>提供的参数：<code>writeAcceptCharset</code>，所以最终的写法如下：</p>\n<pre><code>&lt;!-- 用于使用@ResponseBody后返回中文避免乱码 --&gt;\n&lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot; &gt;\n    &lt;property name=&quot;messageConverters&quot;&gt;\n        &lt;list&gt;\n            &lt;bean id=&quot;stringHttpMessageConverter&quot; class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;\n                &lt;property name=&quot;writeAcceptCharset&quot; value=&quot;false&quot; /&gt;&lt;!-- 用于避免响应头过大 --&gt;\n                &lt;property name=&quot;supportedMediaTypes&quot;&gt;\n                    &lt;list&gt;\n                        &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;\n                    &lt;/list&gt;\n                &lt;/property&gt;\n            &lt;/bean&gt;\n        &lt;/list&gt;\n    &lt;/property&gt;\n&lt;/bean&gt;\n</code></pre><p>哎，两个多小时就干了点儿这，感觉好尴尬啊！！</p>\n","excerpt":"<p>由于现在的项目一般都追求前后端分离，依靠Ajax进行通信，这样有助于团队分工、项目维护和后期的平台移植，这就使得后端框架对视图层的功能要求越来越低~<br>","more":"<br>今天要说的是基于SpringMVC开发web后端时，为了简单而直接在控制器方法中返回json字符串时碰到的中文乱码问题。算是非常基础的问题，大牛请绕道~</p>\n<p>其实我自己一开始也没觉得能有多复杂，认为一搜索就能找到一大把解决方案，所以没有计划耗费多久时间，更没打算转成写一篇博文记录过程。可不曾想到，足足花了我2个半小时，今天看来又要加班了！其实确实在GG和百度中搜索到了大量的相关解决方案，晒晒捡捡也发现至少有不下七八种解决方案。可悲剧的是统统在我测试下无效。</p>\n<p>对于JAVAEE，我真真儿的是新手，项目也没有给我太多时间来深究源码，只能快速的试错，总算把几个方案拼凑出来一个能用的了！下面我就简单的说一下我的解决方法吧。</p>\n<p>首先，我们要知道，为毛<code>@ResponseBody</code>不支持中文：<a href=\"http://tchen8.iteye.com/blog/993504\">传送门</a>，这是我找到的写的最细的一篇文章了，尽管它并没有解决我的问题。</p>\n<p>知道了原因，再来选择解决方案，一开始满心欢喜的找到一个最简单的方案：</p>\n<pre><code>@RequestMapping(value = &quot;/add&quot;, produces = {&quot;application/json;charset=UTF-8&quot;})\n</code></pre><p>可是不管用撒，原因不明~~</p>\n<p>好吧，那再试一个：</p>\n<pre><code>response.setContentType(&quot;text/plain;charset=UTF-8&quot;);\n</code></pre><p>也不行哇，这个其实只是设置了响应头中的字符集，但是<code>@ResponseBody</code>最终还是会把字符以“ISO-8859-1”的方式输出，可恶！</p>\n<p>简单的方法木牛了，只能选择手动设置字符转换类了：</p>\n<pre><code>&lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot; &gt;  \n    &lt;property name=&quot;messageConverters&quot;&gt;   \n        &lt;list&gt;   \n            &lt;bean class = &quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;   \n                &lt;property name = &quot;supportedMediaTypes&quot;&gt;\n                    &lt;list&gt;\n                        &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;   \n                    &lt;/list&gt;   \n                &lt;/property&gt;   \n            &lt;/bean&gt;   \n        &lt;/list&gt;   \n   &lt;/property&gt;  \n&lt;/bean&gt;  \n</code></pre><p>注意，需要把这段放在<code>xxx-servlet.xml</code>中<code>&lt;context:component-scan base-package=&quot;xxxxx&quot;/&gt;</code>前面哦~</p>\n<p>其实这样已经可以解决了，不过不完美，留一下这个时候的响应头，你会发现体积非常大（Accept-Charset会达到4K+），这是因为默认情况下<code>StringHttpMessageConverter.writeInternal()</code>会将所有可用字符集回写到响应头中，这会消耗非常大的带宽！浪费可耻！</p>\n<p>一筹莫展了吧~幸好发现<code>StringHttpMessageConverter</code>提供的参数：<code>writeAcceptCharset</code>，所以最终的写法如下：</p>\n<pre><code>&lt;!-- 用于使用@ResponseBody后返回中文避免乱码 --&gt;\n&lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot; &gt;\n    &lt;property name=&quot;messageConverters&quot;&gt;\n        &lt;list&gt;\n            &lt;bean id=&quot;stringHttpMessageConverter&quot; class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;\n                &lt;property name=&quot;writeAcceptCharset&quot; value=&quot;false&quot; /&gt;&lt;!-- 用于避免响应头过大 --&gt;\n                &lt;property name=&quot;supportedMediaTypes&quot;&gt;\n                    &lt;list&gt;\n                        &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;\n                    &lt;/list&gt;\n                &lt;/property&gt;\n            &lt;/bean&gt;\n        &lt;/list&gt;\n    &lt;/property&gt;\n&lt;/bean&gt;\n</code></pre><p>哎，两个多小时就干了点儿这，感觉好尴尬啊！！</p>"},{"title":"聊聊大文件上传","date":"2014-11-14T01:37:12.000Z","_content":"\n\n\n早先我们在做网站的大文件上传时一般都是借助flash控件的，那个时代html5没有开放文件操作接口给js，而直接用表单提交大文件的话，以那个时候的带宽来上传百兆文件要花非常久的时间，我们无法保证用户能耐心等到上传完（在此期间，用户不能刷新页面，只能等~）。一旦用户的网络出现抖动，就可能导致前功尽弃，这些是不可接受的！\n<!-- more -->\n那么做到什么样的程度才能够保证大文件上传的可用性呢？我在这里简单的列出来一些点：\n\n- 支持断点续传\n- 支持分块\n- 支持多线程(*)\n- 支持秒传(*)\n- 支持显示上传进度\n- 支持图片预览\n- 支持暂停上传\n- 拖拽上传\n\n上面列出的这几点是我认为都需要实现的，**带星号**的我觉得算是加分项吧，毕竟像迅雷客户端这样的体验真的是太劲爆了。\n\n接下来我们就根据上面列出的几点来分析，基于一款百度开源的前端上传控件：[WebUploader](http://fex-team.github.io/webuploader/)（以下简称：WU）。\n\n\n\n上传图片预览\n---\n\n这一点其实在html5开放了本地文件操作接口后，就变得非常[简单](http://www.helloweba.com/view-blog-224.html)了。WU已经把这个[功能](http://fex-team.github.io/webuploader/getting-started.html#%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0)封装起来了，用起来非常的简单，这里就不多说了。\n\n不仅如此，WU还提供了更强大的功能，它可以在生成缩略图的时候进行图片压缩处理，具体可从[API文档](http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options)中查看到。\n\n\n\n上传进度\n---\n\n如果让用户等待十几分钟，不做任何提示肯定是非常不合适的，天知道是正在上传，还是死机了啊！这一点也是依靠[HTML5的新特性](http://ux.sohu.com/topics/4ff177586c423d2471000725)做到的。不过在WU封装后，它就成了一个可监听的[事件](http://fex-team.github.io/webuploader/getting-started.html#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E8%BF%9B%E5%BA%A6)而已，这里也不多说了。\n\n\n\n拖拽上传\n---\n\n你可能会觉得这个功能没啥大用，但我却把它视为革命性的飞跃。不过在WU里实现起来只需要靠一个配置两个参数即可：[dnd和disableGlobalDnd](http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options)。\n\n\n\n分块，暂停上传，多线程，断点续传\n---\n\n其实只要支持了分块功能，像什么断点续传啊多线程啊就都有了！而借助html5提供给我们的文件API，分块也灰常的简单。我们就直接拿WU来说吧，它的配置中有以下几个参数：\n\n- chunked\n- chunkSize\n- chunkRetry\n- threads\n- prepareNextFile\n\n\t\tvar uploader = WebUploader.create({\n\t\t\t\tswf: \"Uploader.swf\"\n\t\t\t\t, server: \"fileUpload.php\"\n\t\t\t\t, pick: \"#picker\"\n\t\t\t\t, resize: false\n\t\t\t\t, dnd: \"#theList\"\n\t\t\t\t, paste: document.body\n\t\t\t\t, disableGlobalDnd: true\n\t\t\t\t, thumb: {\n\t\t\t\t\twidth: 100\n\t\t\t\t\t, height: 100\n\t\t\t\t\t, quality: 70\n\t\t\t\t\t, allowMagnify: true\n\t\t\t\t\t, crop: true\n\t\t\t\t}\n                , compress: false\n\t\t\t\t, prepareNextFile: true\n\t\t\t\t, chunked: true\n\t\t\t\t, chunkSize: 5000 * 1024\n\t\t\t\t, threads: true\n\t\t\t\t, formData: userInfo\n\t\t\t\t, fileNumLimit: 1\n\t\t\t\t, fileSingleSizeLimit: 1000 * 1024 * 1024\n\t\t\t\t, duplicate: true\n\t\t\t});\n\n我把每个分片设置为`5M`大小，同时开启了多线程。这样设置以后，你就会发现上传被切分成多次请求了，如下图：\n\n![](http://pic.yupoo.com/kazaff_v/EcriprRN/amcvb.png)\n\n注意，每个分片的上传请求中都包含三个重要的标识信息：\n\n- size：表示文件的总大小\n- chunks：表示分片的总个数\n- chunk：表示当前是第几个分片（分片下标从0开始）\n\nWU已经把该做的做完了，而且做得还很不错，那么它都做了什么：\n\n- 文件拆分成指定大小的块\n- 分块多线程发起上传请求\n- 提供暂停功能\n- 分块上传失败后重试\n\n\n接下来就是我们后端代码要负责的了，我简单列一下后端要解决的问题点：\n\n1. 如何识别不同的分块是否属于同一个目标文件\n2. 何时把多分片合并成一个完整的文件\n \t- 如何知道所有的分块全部传完完毕\n\t- 如何避免合并大文件造成的内存占用\n\t- 长期未上传完成的文件如何清理\n3. 如何从指定分块开始上传（续传，暂停后继续） \n\n\n第一个问题要如何解决呢？如果能拿到每个文件的唯一标识的话，我们就可以通过这个标识来甄别分块的归属，至于这个唯一标识要根据哪些数据生成，这就要看你的系统的具体情况了，我这里简单的利用上传文件的相关信息和当前用户的id信息做md5签名作为这个标识：\n\n\tuniqueFileName = md5(''+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n\n其中`userInfo`来自于用户登录后返回给前端框架的用户信息，其中`userId`即为用户的id。`file`其实是WU提供的一个对象，用来表示特定的上传文件，我们是怎么拿到这个对象的呢？ 这里需要简单的介绍一下WU提供的**Hook**：[`before-send-file`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)。\n\n文档中指明，它用来在文件发送之前触发，接受`file`为参数，这个对象就是我们要的！当然，其实也可以WU提供的其它相关事件的回调中获得这个对象，不过放在这里是为了更好的和后面讲的**秒传**配合。代码片段为：\n\n\t\tvar userInfo = {userId:\"kazaff\"};\t//模拟用户信息\n        var uniqueFileName = null;\t\t//为了避免每次分片都重新计算唯一标识，放在全局变量中，但如果你的项目需要WU支持多文件上传，那么这里你需要的是一个K/V结构，key可以存file.id\n\n        WebUploader.Uploader.register({\n            \"before-send-file\": \"beforeSendFile\"\n\t\t\t......\n        }, {\n            beforeSendFile: function(file){\n            \t.....\n                //拿到上传文件的唯一名称，用于断点续传\n                uniqueFileName = md5(''+userInfo.userId+file.id+file.name+file.type+file.lastModifiedDate+file.size);\n\t\t\t\t.....\n            }\n\t\t\t......\n        });\n\n上面的代码片段我省略了很多不相干的代码，不过放心最后我会把这个例子的完整代码放到github上的。\n\n这样我们就有了这个唯一标识文件的戳，不过这里我们是在前端生成的，前端的这个戳主要是用于断点续传的，因为每个分片上传前我们都会让WU先发送一个请求来确认该分片是否已经上传过，如果后端告诉我们已经已经传过了，那么WU就会直接跳过该分片，这就实现了我们的断点续传，其实暂停继续和断点续传没啥两样，我们后面再说。当然，判断一个分片是否已经上传，只通过这个文件戳肯定不够，看下图：\n\n![](http://pic.yupoo.com/kazaff_v/EcvJCubA/lZz39.png)\n\n请求中还提供了：分片索引和该分片的大小，这两个数据我们是怎么获取到的呢？依然是利用WU提供的Hook：[`before-send`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)。这个Hook可以在分片发送之前触发，提供给我们`block`对象参数就是分片的相关信息，其中包括了我们要的两个数据，代码如下：\n\n\t.......\n\t, beforeSend: function(block){\n\t\t    //分片验证是否已传过，用于断点续传\n\t\t    var task = new $.Deferred();\n\t\t    $.ajax({\n\t\t        type: \"POST\"\n\t\t        , url: \"fileUpload.php\"\n\t\t        , data: {\n\t\t            type: \"chunkCheck\"\n\t\t            , file: uniqueFileName\n\t\t            , chunkIndex: block.chunk\n\t\t            , size: block.end - block.start\n\t\t        }\n\t\t        , cache: false\n\t\t        , timeout: 1000 //todo 超时的话，只能认为该分片未上传过\n\t\t        , dataType: \"json\"\n\t\t    }).then(function(data, textStatus, jqXHR){\n\t\t        if(data.ifExist){   //若存在，返回失败给WebUploader，表明该分块不需要上传\n\t\t            task.reject();\n\t\t        }else{\n\t\t            task.resolve();\n\t\t        }\n\t\t    }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n\t\t        task.resolve();\n\t\t    });\n\t\t\n\t\t    return $.when(task);\n\t\t}\n\t.......\n\n我在这个Hook中发起了一个ajax请求，用于让后端告诉我们该分片是否需要上传~~\n\n细心的童鞋应该能注意到一个细节，这么设计也就会导致每个分片的上传可能要发送2次请求，一次用于分片验证，一次用于分片上传。这就需要我们设置一个合理的分片大小，用来**避免一个大文件会向后端发起大量的请求**，我的选择是5M~~\n\n做到这里，可以说WU已经做好了暂停继续，断点续传，多线程的全部工作，它们都是基于分块的。再进入后端前，我们先来分析一下断点续传和暂停继续的差别：\n\n**断点续传**表示用户可能刷新了页面，或者甚至干脆重启了电脑，反正总之浏览器丢失了正在上传的文件的所有相关数据：文件路径，正在上传的分片索引，上传进度等信息。\n\n**暂停继续**表示用户仍然在当前页面，只是主动触发暂停上传的动作，并在一定时间间隔后再次触发继续上传行为，期间浏览器依然记录着关于上传文件的相关信息。\n\n除了上面提到的差别外，就没有其它了。也就是说这些差别仅位于浏览器，也就是前端，也就是WU，跟后端关系不大，或者说对于后端处理来说，这两者并没有什么区别，难道不是么？后端只需要回答指定分片是否已存在的问题即可，才不会管这次验证请求来自于断点续传还是暂停继续！！\n\nok，现在来说后端吧，刚才我们在前端创建文件的唯一标识，后端要怎么应对呢？当前端的分片验证请求或分片上传请求过来后，后端需要确定这个请求所对应的文件是哪个，而且要把在整个上传过程中生成的分片关联起来，用于合并时查找使用。方案很多，我这里选择一个不依赖数据库的。\n\n后端在接受到分片上传请求后，会根据我们在前端创建文件标识的方法在后端也创建一个一模一样的标识，用这个标识创建一个文件夹，并把分片上传至这个文件夹中，这样所有同一个文件的分片都会保存在相同的文件夹中，如下图所示：\n\n![](http://pic.yupoo.com/kazaff_v/Ecw7OKMw/12h4Lr.png)\n\n上图来自于某个大文件上传的过程中，以`2e2a311b96d816b695fdf5817bd030f8`命名的文件夹下的分片。\n\n到此为止，我们解决了第一个问题（也为后面的问题做了铺垫）。\n\n第二个问题涉及到合并这些分片的时机和方式，这里要明确一点，WU分片上传时会以分片的先后顺序上传，但由于网络因素，不保证`0号`分片一定先于`1号`分片上传完成，所以**后端不能根据分片下标来判断上传是否完毕**。\n\n> <s>既然如此，我们只能在每个分片上传完毕后检查一下当前文件夹下的文件数是否与总分片数一致，以此来确定是否上传完毕，如果觉得这样做性能不满意，也可以借助WU的Hook：[`after-send-file`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)，这样在所有分片上传完毕后，让WU在该Hook中发送一个ajax请求告诉后端可以合并了，并拿到合并后的目标文件相关信息（路径）。这里我选择了前者。</s>\n\n***以上段落需更正，见文章末尾的[更正1]。***\n\n\n至于合并的方式，我们只需要避免大文件合并时的内存溢出问题即可，这一点跟后端实现语言相关，我打算分别以PHP，NodeJS，JAVA来实现。避免文件读写造成的内存溢出，常用的手段是管道（Pipe），后端代码也会在github上提供，在此就不展示了。\n\n另外我们还要解决一件事儿：如果某个大文件上传了一半，出于种种理由用户决定再也不会上传它的其他部分了，服务器端怎么办？这些过期分片永远存在服务器端的硬盘上显然无法让正常人接受。我们要怎么办呢？方案同样很多，我这里使用的是为每个上传的文件（不是分片）创建一个临时文件，名字使用上面创建的那个文件唯一标识，如：`2e2a311b96d816b695fdf5817bd030f8.tmp`。这个文件的**修改时间**会在每次有分片请求时被更新，然后再开启一个定时任务，比方说每夜凌晨检查一下上传文件夹路径下的所有tmp文件的修改时间，如果发现最后的修改时间距当前时间已经很久了，则认为其对应的分片数据需要被清理。如下图：\n\n![](http://pic.yupoo.com/kazaff_v/EcwpxSRs/guat.png)\n\n好吧，关于第二个问题我们也算搞定了，最后一个问题：如何从指定分块开始上传？这个算是断点续传和暂停继续的核心问题了，而这一点我们需要依赖WU提供的机制：WU分片上传大文件时，会依次上传被切分的分片数据，在这个过程中所需要的分片下标，上传进度等数据都是由WU负责管理的，后端并不需要关注。\n\n每次分片上传前，都会发起一次校验请求，我们就是通过这样的方式来解决第三个问题的。对于暂停继续，WU保存着分片下标的信息，所以它只会从暂停时的那个分片开始询问，而断点续传由于丢失了分片下标信息，则会从0号分片开始询问。这些内容上面已经提及了~~\n\n\n\n秒传\n---\n\n相信大家肯定使用过各种类型的网盘，或者是迅雷会员，都会非常中意“离线下载”这个功能。谁都希望添加到迅雷里的下载任务能够一秒钟下载完毕，同样，我们的用户也希望能够一秒钟就上传完一个1G的文件。但这是不可能的，至少不是真的通过上传的方式实现的！\n\n假设用户A要传的文件是在之前就被用户B上传过的（比方说一部岛国动作片儿，你懂的），这个时候我们不需要傻傻的把这个文件再上传一遍，只需要告诉用户A已经上传完毕了，并返回给他对应的链接，我相信用户A会非常满意的！当然，我们的系统还要处理“写时复制”问题（当用户B删除文件时，由于用户A还在引用，所以文件不应该删除，而应该切断用户B的链接，直到所有用户都不再引用该文件，此时才应该真实删除文件）！\n\n好吧，我们来看看具体如何实现秒传：应该找个方法来判断上传的文件是否服务器端已经存在！这似乎和我们上面提到的文件唯一标识有点类似，但注意我们上面的那个标识中引入了用户id，所以肯定不符合我们这里的情况。那么去掉用户id是否就ok了呢？\n\n恩，其实是可以的，不过这种方式生成的一致性验证其实并没有对内容本身进行验证，而是通过其文件的相关信息来做的判断，也就是说如果两个文件的文件名，大小等“凑巧”一模一样，但这两个文件内容不同的话，就会导致一致性校验错误。\n\n电驴是怎么做的？它会用文件的二进制数据计算文件的md5签名，这样即使文件的名字大小都一样，内容不同也会导致它们的签名不同~这样基本上就是万无一失了，不过对一个大文件进行md5签名可能要话费非常多的时间，这就需要我们来取舍了。\n\n我在自己的开发机测试了一下，用WU提供的[`md5File`](http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_md5File)函数计算一个266M的文件的md5签名，耗时：15.573秒。\n\nWU的md5File函数支持对文件的部分数据做md5签名，这样的话我们就可以对大文件中的一部分内容签名，避免太大的耗时。牛逼坏了！我们按照官方文档的提示使用Hook：[`before-send-file`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)：\n\n\t...... \n\tbeforeSendFile: function(file){\n            //秒传验证\n            var task = new $.Deferred();\n            var start = new Date().getTime();\n            (new WebUploader.Uploader()).md5File(file, 0, 10*1024*1024).progress(function(percentage){\n                console.log(percentage);\n            }).then(function(val){\n                console.log(\"总耗时: \"+((new Date().getTime()) - start)/1000);\n\n                $.ajax({\n                    type: \"POST\"\n                    , url: \"fileUpload.php\"\n                    , data: {\n                        type: \"md5Check\"\n                        , md5: val\n                    }\n                    , cache: false\n                    , timeout: 1000 //todo 超时的话，只能认为该文件不曾上传过\n                    , dataType: \"json\"\n                }).then(function(data, textStatus, jqXHR){\n                    if(data.ifExist){   //若存在，这返回失败给WebUploader，表明该文件不需要上传\n                        task.reject();\n\n                        uploader.skipFile(file);\n                        file.path = data.path;\n                        UploadComlate(file);\n                    }else{\n                        task.resolve();\n                        //拿到上传文件的唯一名称，用于断点续传\n                        uniqueFileName = md5(''+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n                    }\n                }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n                    task.resolve();\n                    //拿到上传文件的唯一名称，用于断点续传\n                    uniqueFileName = md5(''+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n                });\n            });\n            return $.when(task);\n        }\n\t\t......\n\n好啦，前端做完了，后端只需要拿到对应的md5签名，然后进行相关的检索，如果确实存在这个签名匹配的文件，则提示前端该文件已经存在。这部分通常会利用数据库来完成，当然也可以使用内存KV数据结构来做，我们不纠结这！\n\n\n\n\n\n---\n\n好啦，截止到这里，我们大概已经完成了大文件的上传问题，完整的代码我会稍后在[github](https://github.com/kazaff/webuploaderDemo)上提供出来，有兴趣的童鞋可以去瞅瞅。\n\n\n\n---\n更正1：\n\n尽管我们在例子中已经设置为单文件上传，并且在生成文件的唯一标识时加上了userId，但这并不能阻碍并发上传时造成的冲突，先来看下面这个场景，让我来手绘一张图，真的是纯手绘哟~~：\n\n![](http://pic.yupoo.com/kazaff/EcI4oK72/medish.jpg)\n\n假设我们的用户A用浏览器打开了两个tab窗口（userId一致）：tab1，tab2。这两个窗口同时上传同一个文件（文件标识一致），这里暂不考虑浏览器对多tab上传同一文件是否会做优化，如果确实会做优化，那我们也可以假设用户是同时在两款浏览器上同时上传某一个文件。\n\n如上图所示，假设tab1先上传了3个分片，在上传第四个分片之前阻塞了（原因不详）。这个时候tab2开始上传，由于生产的文件标识一致，所以tab2的分片校验请求会对前3个分片返回true，这样tab2就会直接从第4个分片开始上传，我们假设tab2上传完第4个分片且再第5个分片开始上传前，tab1结束了阻塞状态，它会得知第4个分片已经上传完毕，迅速开始第5个分片的上传工作。\n\n到目前为止，一切都是那么的顺利和合理，仿佛生活多么的美好。好，这个时候我们假设这个文件一共就需要5个分片就可以上传完毕。从图上可以看到，此时tab1和tab2会同时进行第5个分片的上传任务（因为在它们发送的分片校验请求时，彼此都没有完成上传，所以它们都会得到一个目标分片不存在须上传的回复）。\n\n如果最终结果是tab1先上传完成了，那么依照我上文的做法，那么tab1会触发合并动作，合并过程中会清理已合并分片。那么问题就来了，会有以下几种不好的情况发生：\n\n1. tab1合并完分片1时，但tab2正在合并分片1，tab1删除分片1失败\n- tab1合并完分片1后成功删除分片1，导致tab2上传完分片5后无法触发合并动作（分片总数不达标），从而导致前端WU很尴尬（因为分片5上传完毕后就会触发uploadSuccess事件，但拿不到合并后的文件地址）\n- tab1合并完毕且删除了tmp文件，此时tab2上传完分片5，再次到回到情况2\n\n好乱啊，总之上文中的方案不能很好的解决这个场景。那该怎么办好捏？\n\nWU似乎应该是考虑过这种情况，所以提供了对应的Hook：**after-send-file**。\n\n> 在所有分片都上传完毕后，且没有错误后request，用来做分片验证，此时如果promise被reject，当前文件上传会触发错误。\n\n我们只需要在这个hook中发送一个ajax请求给后端来触发合并动作，听起来这并没有解决并发啊，毕竟这个请求也可能同时到达后端！\n\n是的，没错，但这么做有个好处，至少WU并不会尴尬，你可以告诉WU上传失败了，至少不会像之前的方案那样，明明触发了uploadSuccess事件，但却拿不到合并后的文件地址。\n\n那么并发冲突怎么解决？我们就需要使用一种锁机制了，如果node平台，由于其执行主进程是单线程的，所以我们可以在全局变量中设置一个标志位即可。在java平台中，由于其依赖多线程实现并发，我们就要借助同步操作来解决这个问题。最头疼的就是php，老一点的手段就是让多个进程基于某个临时文件锁进行同步，当然也可以依赖第三方软件解决，比方说redis的原子操作，甚至再重一点引入zookeeper。\n\n我会在上面提到的github地址中选择一种方案来解决这个问题的，敬请关注。\n\n","source":"_posts/聊聊大文件上传.md","raw":"title: 聊聊大文件上传\ndate: 2014-11-14 09:37:12\ntags: \n- 秒传\n- 断点续传\n- 上传进度\n- webuploader\n- 分块\n- 大文件\n\ncategories: \n- java\n---\n\n\n\n早先我们在做网站的大文件上传时一般都是借助flash控件的，那个时代html5没有开放文件操作接口给js，而直接用表单提交大文件的话，以那个时候的带宽来上传百兆文件要花非常久的时间，我们无法保证用户能耐心等到上传完（在此期间，用户不能刷新页面，只能等~）。一旦用户的网络出现抖动，就可能导致前功尽弃，这些是不可接受的！\n<!-- more -->\n那么做到什么样的程度才能够保证大文件上传的可用性呢？我在这里简单的列出来一些点：\n\n- 支持断点续传\n- 支持分块\n- 支持多线程(*)\n- 支持秒传(*)\n- 支持显示上传进度\n- 支持图片预览\n- 支持暂停上传\n- 拖拽上传\n\n上面列出的这几点是我认为都需要实现的，**带星号**的我觉得算是加分项吧，毕竟像迅雷客户端这样的体验真的是太劲爆了。\n\n接下来我们就根据上面列出的几点来分析，基于一款百度开源的前端上传控件：[WebUploader](http://fex-team.github.io/webuploader/)（以下简称：WU）。\n\n\n\n上传图片预览\n---\n\n这一点其实在html5开放了本地文件操作接口后，就变得非常[简单](http://www.helloweba.com/view-blog-224.html)了。WU已经把这个[功能](http://fex-team.github.io/webuploader/getting-started.html#%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0)封装起来了，用起来非常的简单，这里就不多说了。\n\n不仅如此，WU还提供了更强大的功能，它可以在生成缩略图的时候进行图片压缩处理，具体可从[API文档](http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options)中查看到。\n\n\n\n上传进度\n---\n\n如果让用户等待十几分钟，不做任何提示肯定是非常不合适的，天知道是正在上传，还是死机了啊！这一点也是依靠[HTML5的新特性](http://ux.sohu.com/topics/4ff177586c423d2471000725)做到的。不过在WU封装后，它就成了一个可监听的[事件](http://fex-team.github.io/webuploader/getting-started.html#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E8%BF%9B%E5%BA%A6)而已，这里也不多说了。\n\n\n\n拖拽上传\n---\n\n你可能会觉得这个功能没啥大用，但我却把它视为革命性的飞跃。不过在WU里实现起来只需要靠一个配置两个参数即可：[dnd和disableGlobalDnd](http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options)。\n\n\n\n分块，暂停上传，多线程，断点续传\n---\n\n其实只要支持了分块功能，像什么断点续传啊多线程啊就都有了！而借助html5提供给我们的文件API，分块也灰常的简单。我们就直接拿WU来说吧，它的配置中有以下几个参数：\n\n- chunked\n- chunkSize\n- chunkRetry\n- threads\n- prepareNextFile\n\n\t\tvar uploader = WebUploader.create({\n\t\t\t\tswf: \"Uploader.swf\"\n\t\t\t\t, server: \"fileUpload.php\"\n\t\t\t\t, pick: \"#picker\"\n\t\t\t\t, resize: false\n\t\t\t\t, dnd: \"#theList\"\n\t\t\t\t, paste: document.body\n\t\t\t\t, disableGlobalDnd: true\n\t\t\t\t, thumb: {\n\t\t\t\t\twidth: 100\n\t\t\t\t\t, height: 100\n\t\t\t\t\t, quality: 70\n\t\t\t\t\t, allowMagnify: true\n\t\t\t\t\t, crop: true\n\t\t\t\t}\n                , compress: false\n\t\t\t\t, prepareNextFile: true\n\t\t\t\t, chunked: true\n\t\t\t\t, chunkSize: 5000 * 1024\n\t\t\t\t, threads: true\n\t\t\t\t, formData: userInfo\n\t\t\t\t, fileNumLimit: 1\n\t\t\t\t, fileSingleSizeLimit: 1000 * 1024 * 1024\n\t\t\t\t, duplicate: true\n\t\t\t});\n\n我把每个分片设置为`5M`大小，同时开启了多线程。这样设置以后，你就会发现上传被切分成多次请求了，如下图：\n\n![](http://pic.yupoo.com/kazaff_v/EcriprRN/amcvb.png)\n\n注意，每个分片的上传请求中都包含三个重要的标识信息：\n\n- size：表示文件的总大小\n- chunks：表示分片的总个数\n- chunk：表示当前是第几个分片（分片下标从0开始）\n\nWU已经把该做的做完了，而且做得还很不错，那么它都做了什么：\n\n- 文件拆分成指定大小的块\n- 分块多线程发起上传请求\n- 提供暂停功能\n- 分块上传失败后重试\n\n\n接下来就是我们后端代码要负责的了，我简单列一下后端要解决的问题点：\n\n1. 如何识别不同的分块是否属于同一个目标文件\n2. 何时把多分片合并成一个完整的文件\n \t- 如何知道所有的分块全部传完完毕\n\t- 如何避免合并大文件造成的内存占用\n\t- 长期未上传完成的文件如何清理\n3. 如何从指定分块开始上传（续传，暂停后继续） \n\n\n第一个问题要如何解决呢？如果能拿到每个文件的唯一标识的话，我们就可以通过这个标识来甄别分块的归属，至于这个唯一标识要根据哪些数据生成，这就要看你的系统的具体情况了，我这里简单的利用上传文件的相关信息和当前用户的id信息做md5签名作为这个标识：\n\n\tuniqueFileName = md5(''+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n\n其中`userInfo`来自于用户登录后返回给前端框架的用户信息，其中`userId`即为用户的id。`file`其实是WU提供的一个对象，用来表示特定的上传文件，我们是怎么拿到这个对象的呢？ 这里需要简单的介绍一下WU提供的**Hook**：[`before-send-file`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)。\n\n文档中指明，它用来在文件发送之前触发，接受`file`为参数，这个对象就是我们要的！当然，其实也可以WU提供的其它相关事件的回调中获得这个对象，不过放在这里是为了更好的和后面讲的**秒传**配合。代码片段为：\n\n\t\tvar userInfo = {userId:\"kazaff\"};\t//模拟用户信息\n        var uniqueFileName = null;\t\t//为了避免每次分片都重新计算唯一标识，放在全局变量中，但如果你的项目需要WU支持多文件上传，那么这里你需要的是一个K/V结构，key可以存file.id\n\n        WebUploader.Uploader.register({\n            \"before-send-file\": \"beforeSendFile\"\n\t\t\t......\n        }, {\n            beforeSendFile: function(file){\n            \t.....\n                //拿到上传文件的唯一名称，用于断点续传\n                uniqueFileName = md5(''+userInfo.userId+file.id+file.name+file.type+file.lastModifiedDate+file.size);\n\t\t\t\t.....\n            }\n\t\t\t......\n        });\n\n上面的代码片段我省略了很多不相干的代码，不过放心最后我会把这个例子的完整代码放到github上的。\n\n这样我们就有了这个唯一标识文件的戳，不过这里我们是在前端生成的，前端的这个戳主要是用于断点续传的，因为每个分片上传前我们都会让WU先发送一个请求来确认该分片是否已经上传过，如果后端告诉我们已经已经传过了，那么WU就会直接跳过该分片，这就实现了我们的断点续传，其实暂停继续和断点续传没啥两样，我们后面再说。当然，判断一个分片是否已经上传，只通过这个文件戳肯定不够，看下图：\n\n![](http://pic.yupoo.com/kazaff_v/EcvJCubA/lZz39.png)\n\n请求中还提供了：分片索引和该分片的大小，这两个数据我们是怎么获取到的呢？依然是利用WU提供的Hook：[`before-send`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)。这个Hook可以在分片发送之前触发，提供给我们`block`对象参数就是分片的相关信息，其中包括了我们要的两个数据，代码如下：\n\n\t.......\n\t, beforeSend: function(block){\n\t\t    //分片验证是否已传过，用于断点续传\n\t\t    var task = new $.Deferred();\n\t\t    $.ajax({\n\t\t        type: \"POST\"\n\t\t        , url: \"fileUpload.php\"\n\t\t        , data: {\n\t\t            type: \"chunkCheck\"\n\t\t            , file: uniqueFileName\n\t\t            , chunkIndex: block.chunk\n\t\t            , size: block.end - block.start\n\t\t        }\n\t\t        , cache: false\n\t\t        , timeout: 1000 //todo 超时的话，只能认为该分片未上传过\n\t\t        , dataType: \"json\"\n\t\t    }).then(function(data, textStatus, jqXHR){\n\t\t        if(data.ifExist){   //若存在，返回失败给WebUploader，表明该分块不需要上传\n\t\t            task.reject();\n\t\t        }else{\n\t\t            task.resolve();\n\t\t        }\n\t\t    }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n\t\t        task.resolve();\n\t\t    });\n\t\t\n\t\t    return $.when(task);\n\t\t}\n\t.......\n\n我在这个Hook中发起了一个ajax请求，用于让后端告诉我们该分片是否需要上传~~\n\n细心的童鞋应该能注意到一个细节，这么设计也就会导致每个分片的上传可能要发送2次请求，一次用于分片验证，一次用于分片上传。这就需要我们设置一个合理的分片大小，用来**避免一个大文件会向后端发起大量的请求**，我的选择是5M~~\n\n做到这里，可以说WU已经做好了暂停继续，断点续传，多线程的全部工作，它们都是基于分块的。再进入后端前，我们先来分析一下断点续传和暂停继续的差别：\n\n**断点续传**表示用户可能刷新了页面，或者甚至干脆重启了电脑，反正总之浏览器丢失了正在上传的文件的所有相关数据：文件路径，正在上传的分片索引，上传进度等信息。\n\n**暂停继续**表示用户仍然在当前页面，只是主动触发暂停上传的动作，并在一定时间间隔后再次触发继续上传行为，期间浏览器依然记录着关于上传文件的相关信息。\n\n除了上面提到的差别外，就没有其它了。也就是说这些差别仅位于浏览器，也就是前端，也就是WU，跟后端关系不大，或者说对于后端处理来说，这两者并没有什么区别，难道不是么？后端只需要回答指定分片是否已存在的问题即可，才不会管这次验证请求来自于断点续传还是暂停继续！！\n\nok，现在来说后端吧，刚才我们在前端创建文件的唯一标识，后端要怎么应对呢？当前端的分片验证请求或分片上传请求过来后，后端需要确定这个请求所对应的文件是哪个，而且要把在整个上传过程中生成的分片关联起来，用于合并时查找使用。方案很多，我这里选择一个不依赖数据库的。\n\n后端在接受到分片上传请求后，会根据我们在前端创建文件标识的方法在后端也创建一个一模一样的标识，用这个标识创建一个文件夹，并把分片上传至这个文件夹中，这样所有同一个文件的分片都会保存在相同的文件夹中，如下图所示：\n\n![](http://pic.yupoo.com/kazaff_v/Ecw7OKMw/12h4Lr.png)\n\n上图来自于某个大文件上传的过程中，以`2e2a311b96d816b695fdf5817bd030f8`命名的文件夹下的分片。\n\n到此为止，我们解决了第一个问题（也为后面的问题做了铺垫）。\n\n第二个问题涉及到合并这些分片的时机和方式，这里要明确一点，WU分片上传时会以分片的先后顺序上传，但由于网络因素，不保证`0号`分片一定先于`1号`分片上传完成，所以**后端不能根据分片下标来判断上传是否完毕**。\n\n> <s>既然如此，我们只能在每个分片上传完毕后检查一下当前文件夹下的文件数是否与总分片数一致，以此来确定是否上传完毕，如果觉得这样做性能不满意，也可以借助WU的Hook：[`after-send-file`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)，这样在所有分片上传完毕后，让WU在该Hook中发送一个ajax请求告诉后端可以合并了，并拿到合并后的目标文件相关信息（路径）。这里我选择了前者。</s>\n\n***以上段落需更正，见文章末尾的[更正1]。***\n\n\n至于合并的方式，我们只需要避免大文件合并时的内存溢出问题即可，这一点跟后端实现语言相关，我打算分别以PHP，NodeJS，JAVA来实现。避免文件读写造成的内存溢出，常用的手段是管道（Pipe），后端代码也会在github上提供，在此就不展示了。\n\n另外我们还要解决一件事儿：如果某个大文件上传了一半，出于种种理由用户决定再也不会上传它的其他部分了，服务器端怎么办？这些过期分片永远存在服务器端的硬盘上显然无法让正常人接受。我们要怎么办呢？方案同样很多，我这里使用的是为每个上传的文件（不是分片）创建一个临时文件，名字使用上面创建的那个文件唯一标识，如：`2e2a311b96d816b695fdf5817bd030f8.tmp`。这个文件的**修改时间**会在每次有分片请求时被更新，然后再开启一个定时任务，比方说每夜凌晨检查一下上传文件夹路径下的所有tmp文件的修改时间，如果发现最后的修改时间距当前时间已经很久了，则认为其对应的分片数据需要被清理。如下图：\n\n![](http://pic.yupoo.com/kazaff_v/EcwpxSRs/guat.png)\n\n好吧，关于第二个问题我们也算搞定了，最后一个问题：如何从指定分块开始上传？这个算是断点续传和暂停继续的核心问题了，而这一点我们需要依赖WU提供的机制：WU分片上传大文件时，会依次上传被切分的分片数据，在这个过程中所需要的分片下标，上传进度等数据都是由WU负责管理的，后端并不需要关注。\n\n每次分片上传前，都会发起一次校验请求，我们就是通过这样的方式来解决第三个问题的。对于暂停继续，WU保存着分片下标的信息，所以它只会从暂停时的那个分片开始询问，而断点续传由于丢失了分片下标信息，则会从0号分片开始询问。这些内容上面已经提及了~~\n\n\n\n秒传\n---\n\n相信大家肯定使用过各种类型的网盘，或者是迅雷会员，都会非常中意“离线下载”这个功能。谁都希望添加到迅雷里的下载任务能够一秒钟下载完毕，同样，我们的用户也希望能够一秒钟就上传完一个1G的文件。但这是不可能的，至少不是真的通过上传的方式实现的！\n\n假设用户A要传的文件是在之前就被用户B上传过的（比方说一部岛国动作片儿，你懂的），这个时候我们不需要傻傻的把这个文件再上传一遍，只需要告诉用户A已经上传完毕了，并返回给他对应的链接，我相信用户A会非常满意的！当然，我们的系统还要处理“写时复制”问题（当用户B删除文件时，由于用户A还在引用，所以文件不应该删除，而应该切断用户B的链接，直到所有用户都不再引用该文件，此时才应该真实删除文件）！\n\n好吧，我们来看看具体如何实现秒传：应该找个方法来判断上传的文件是否服务器端已经存在！这似乎和我们上面提到的文件唯一标识有点类似，但注意我们上面的那个标识中引入了用户id，所以肯定不符合我们这里的情况。那么去掉用户id是否就ok了呢？\n\n恩，其实是可以的，不过这种方式生成的一致性验证其实并没有对内容本身进行验证，而是通过其文件的相关信息来做的判断，也就是说如果两个文件的文件名，大小等“凑巧”一模一样，但这两个文件内容不同的话，就会导致一致性校验错误。\n\n电驴是怎么做的？它会用文件的二进制数据计算文件的md5签名，这样即使文件的名字大小都一样，内容不同也会导致它们的签名不同~这样基本上就是万无一失了，不过对一个大文件进行md5签名可能要话费非常多的时间，这就需要我们来取舍了。\n\n我在自己的开发机测试了一下，用WU提供的[`md5File`](http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_md5File)函数计算一个266M的文件的md5签名，耗时：15.573秒。\n\nWU的md5File函数支持对文件的部分数据做md5签名，这样的话我们就可以对大文件中的一部分内容签名，避免太大的耗时。牛逼坏了！我们按照官方文档的提示使用Hook：[`before-send-file`](http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6)：\n\n\t...... \n\tbeforeSendFile: function(file){\n            //秒传验证\n            var task = new $.Deferred();\n            var start = new Date().getTime();\n            (new WebUploader.Uploader()).md5File(file, 0, 10*1024*1024).progress(function(percentage){\n                console.log(percentage);\n            }).then(function(val){\n                console.log(\"总耗时: \"+((new Date().getTime()) - start)/1000);\n\n                $.ajax({\n                    type: \"POST\"\n                    , url: \"fileUpload.php\"\n                    , data: {\n                        type: \"md5Check\"\n                        , md5: val\n                    }\n                    , cache: false\n                    , timeout: 1000 //todo 超时的话，只能认为该文件不曾上传过\n                    , dataType: \"json\"\n                }).then(function(data, textStatus, jqXHR){\n                    if(data.ifExist){   //若存在，这返回失败给WebUploader，表明该文件不需要上传\n                        task.reject();\n\n                        uploader.skipFile(file);\n                        file.path = data.path;\n                        UploadComlate(file);\n                    }else{\n                        task.resolve();\n                        //拿到上传文件的唯一名称，用于断点续传\n                        uniqueFileName = md5(''+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n                    }\n                }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n                    task.resolve();\n                    //拿到上传文件的唯一名称，用于断点续传\n                    uniqueFileName = md5(''+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n                });\n            });\n            return $.when(task);\n        }\n\t\t......\n\n好啦，前端做完了，后端只需要拿到对应的md5签名，然后进行相关的检索，如果确实存在这个签名匹配的文件，则提示前端该文件已经存在。这部分通常会利用数据库来完成，当然也可以使用内存KV数据结构来做，我们不纠结这！\n\n\n\n\n\n---\n\n好啦，截止到这里，我们大概已经完成了大文件的上传问题，完整的代码我会稍后在[github](https://github.com/kazaff/webuploaderDemo)上提供出来，有兴趣的童鞋可以去瞅瞅。\n\n\n\n---\n更正1：\n\n尽管我们在例子中已经设置为单文件上传，并且在生成文件的唯一标识时加上了userId，但这并不能阻碍并发上传时造成的冲突，先来看下面这个场景，让我来手绘一张图，真的是纯手绘哟~~：\n\n![](http://pic.yupoo.com/kazaff/EcI4oK72/medish.jpg)\n\n假设我们的用户A用浏览器打开了两个tab窗口（userId一致）：tab1，tab2。这两个窗口同时上传同一个文件（文件标识一致），这里暂不考虑浏览器对多tab上传同一文件是否会做优化，如果确实会做优化，那我们也可以假设用户是同时在两款浏览器上同时上传某一个文件。\n\n如上图所示，假设tab1先上传了3个分片，在上传第四个分片之前阻塞了（原因不详）。这个时候tab2开始上传，由于生产的文件标识一致，所以tab2的分片校验请求会对前3个分片返回true，这样tab2就会直接从第4个分片开始上传，我们假设tab2上传完第4个分片且再第5个分片开始上传前，tab1结束了阻塞状态，它会得知第4个分片已经上传完毕，迅速开始第5个分片的上传工作。\n\n到目前为止，一切都是那么的顺利和合理，仿佛生活多么的美好。好，这个时候我们假设这个文件一共就需要5个分片就可以上传完毕。从图上可以看到，此时tab1和tab2会同时进行第5个分片的上传任务（因为在它们发送的分片校验请求时，彼此都没有完成上传，所以它们都会得到一个目标分片不存在须上传的回复）。\n\n如果最终结果是tab1先上传完成了，那么依照我上文的做法，那么tab1会触发合并动作，合并过程中会清理已合并分片。那么问题就来了，会有以下几种不好的情况发生：\n\n1. tab1合并完分片1时，但tab2正在合并分片1，tab1删除分片1失败\n- tab1合并完分片1后成功删除分片1，导致tab2上传完分片5后无法触发合并动作（分片总数不达标），从而导致前端WU很尴尬（因为分片5上传完毕后就会触发uploadSuccess事件，但拿不到合并后的文件地址）\n- tab1合并完毕且删除了tmp文件，此时tab2上传完分片5，再次到回到情况2\n\n好乱啊，总之上文中的方案不能很好的解决这个场景。那该怎么办好捏？\n\nWU似乎应该是考虑过这种情况，所以提供了对应的Hook：**after-send-file**。\n\n> 在所有分片都上传完毕后，且没有错误后request，用来做分片验证，此时如果promise被reject，当前文件上传会触发错误。\n\n我们只需要在这个hook中发送一个ajax请求给后端来触发合并动作，听起来这并没有解决并发啊，毕竟这个请求也可能同时到达后端！\n\n是的，没错，但这么做有个好处，至少WU并不会尴尬，你可以告诉WU上传失败了，至少不会像之前的方案那样，明明触发了uploadSuccess事件，但却拿不到合并后的文件地址。\n\n那么并发冲突怎么解决？我们就需要使用一种锁机制了，如果node平台，由于其执行主进程是单线程的，所以我们可以在全局变量中设置一个标志位即可。在java平台中，由于其依赖多线程实现并发，我们就要借助同步操作来解决这个问题。最头疼的就是php，老一点的手段就是让多个进程基于某个临时文件锁进行同步，当然也可以依赖第三方软件解决，比方说redis的原子操作，甚至再重一点引入zookeeper。\n\n我会在上面提到的github地址中选择一种方案来解决这个问题的，敬请关注。\n\n","slug":"聊聊大文件上传","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yk6000kgtfy8ujjbkh3","comments":1,"layout":"post","photos":[],"link":"","content":"<p>早先我们在做网站的大文件上传时一般都是借助flash控件的，那个时代html5没有开放文件操作接口给js，而直接用表单提交大文件的话，以那个时候的带宽来上传百兆文件要花非常久的时间，我们无法保证用户能耐心等到上传完（在此期间，用户不能刷新页面，只能等~）。一旦用户的网络出现抖动，就可能导致前功尽弃，这些是不可接受的！<br><a id=\"more\"></a><br>那么做到什么样的程度才能够保证大文件上传的可用性呢？我在这里简单的列出来一些点：</p>\n<ul>\n<li>支持断点续传</li>\n<li>支持分块</li>\n<li>支持多线程(*)</li>\n<li>支持秒传(*)</li>\n<li>支持显示上传进度</li>\n<li>支持图片预览</li>\n<li>支持暂停上传</li>\n<li>拖拽上传</li>\n</ul>\n<p>上面列出的这几点是我认为都需要实现的，<strong>带星号</strong>的我觉得算是加分项吧，毕竟像迅雷客户端这样的体验真的是太劲爆了。</p>\n<p>接下来我们就根据上面列出的几点来分析，基于一款百度开源的前端上传控件：<a href=\"http://fex-team.github.io/webuploader/\" target=\"_blank\" rel=\"external\">WebUploader</a>（以下简称：WU）。</p>\n<h2 id=\"上传图片预览\"><a href=\"#上传图片预览\" class=\"headerlink\" title=\"上传图片预览\"></a>上传图片预览</h2><p>这一点其实在html5开放了本地文件操作接口后，就变得非常<a href=\"http://www.helloweba.com/view-blog-224.html\" target=\"_blank\" rel=\"external\">简单</a>了。WU已经把这个<a href=\"http://fex-team.github.io/webuploader/getting-started.html#%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0\" target=\"_blank\" rel=\"external\">功能</a>封装起来了，用起来非常的简单，这里就不多说了。</p>\n<p>不仅如此，WU还提供了更强大的功能，它可以在生成缩略图的时候进行图片压缩处理，具体可从<a href=\"http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options\" target=\"_blank\" rel=\"external\">API文档</a>中查看到。</p>\n<h2 id=\"上传进度\"><a href=\"#上传进度\" class=\"headerlink\" title=\"上传进度\"></a>上传进度</h2><p>如果让用户等待十几分钟，不做任何提示肯定是非常不合适的，天知道是正在上传，还是死机了啊！这一点也是依靠<a href=\"http://ux.sohu.com/topics/4ff177586c423d2471000725\" target=\"_blank\" rel=\"external\">HTML5的新特性</a>做到的。不过在WU封装后，它就成了一个可监听的<a href=\"http://fex-team.github.io/webuploader/getting-started.html#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E8%BF%9B%E5%BA%A6\" target=\"_blank\" rel=\"external\">事件</a>而已，这里也不多说了。</p>\n<h2 id=\"拖拽上传\"><a href=\"#拖拽上传\" class=\"headerlink\" title=\"拖拽上传\"></a>拖拽上传</h2><p>你可能会觉得这个功能没啥大用，但我却把它视为革命性的飞跃。不过在WU里实现起来只需要靠一个配置两个参数即可：<a href=\"http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options\" target=\"_blank\" rel=\"external\">dnd和disableGlobalDnd</a>。</p>\n<h2 id=\"分块，暂停上传，多线程，断点续传\"><a href=\"#分块，暂停上传，多线程，断点续传\" class=\"headerlink\" title=\"分块，暂停上传，多线程，断点续传\"></a>分块，暂停上传，多线程，断点续传</h2><p>其实只要支持了分块功能，像什么断点续传啊多线程啊就都有了！而借助html5提供给我们的文件API，分块也灰常的简单。我们就直接拿WU来说吧，它的配置中有以下几个参数：</p>\n<ul>\n<li>chunked</li>\n<li>chunkSize</li>\n<li>chunkRetry</li>\n<li>threads</li>\n<li><p>prepareNextFile</p>\n<pre><code>var uploader = WebUploader.create({\n        swf: &quot;Uploader.swf&quot;\n        , server: &quot;fileUpload.php&quot;\n        , pick: &quot;#picker&quot;\n        , resize: false\n        , dnd: &quot;#theList&quot;\n        , paste: document.body\n        , disableGlobalDnd: true\n        , thumb: {\n            width: 100\n            , height: 100\n            , quality: 70\n            , allowMagnify: true\n            , crop: true\n        }\n        , compress: false\n        , prepareNextFile: true\n        , chunked: true\n        , chunkSize: 5000 * 1024\n        , threads: true\n        , formData: userInfo\n        , fileNumLimit: 1\n        , fileSingleSizeLimit: 1000 * 1024 * 1024\n        , duplicate: true\n    });\n</code></pre></li>\n</ul>\n<p>我把每个分片设置为<code>5M</code>大小，同时开启了多线程。这样设置以后，你就会发现上传被切分成多次请求了，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/EcriprRN/amcvb.png\" alt=\"\"></p>\n<p>注意，每个分片的上传请求中都包含三个重要的标识信息：</p>\n<ul>\n<li>size：表示文件的总大小</li>\n<li>chunks：表示分片的总个数</li>\n<li>chunk：表示当前是第几个分片（分片下标从0开始）</li>\n</ul>\n<p>WU已经把该做的做完了，而且做得还很不错，那么它都做了什么：</p>\n<ul>\n<li>文件拆分成指定大小的块</li>\n<li>分块多线程发起上传请求</li>\n<li>提供暂停功能</li>\n<li>分块上传失败后重试</li>\n</ul>\n<p>接下来就是我们后端代码要负责的了，我简单列一下后端要解决的问题点：</p>\n<ol>\n<li>如何识别不同的分块是否属于同一个目标文件</li>\n<li>何时把多分片合并成一个完整的文件<ul>\n<li>如何知道所有的分块全部传完完毕<ul>\n<li>如何避免合并大文件造成的内存占用</li>\n<li>长期未上传完成的文件如何清理</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>如何从指定分块开始上传（续传，暂停后继续） </li>\n</ol>\n<p>第一个问题要如何解决呢？如果能拿到每个文件的唯一标识的话，我们就可以通过这个标识来甄别分块的归属，至于这个唯一标识要根据哪些数据生成，这就要看你的系统的具体情况了，我这里简单的利用上传文件的相关信息和当前用户的id信息做md5签名作为这个标识：</p>\n<pre><code>uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n</code></pre><p>其中<code>userInfo</code>来自于用户登录后返回给前端框架的用户信息，其中<code>userId</code>即为用户的id。<code>file</code>其实是WU提供的一个对象，用来表示特定的上传文件，我们是怎么拿到这个对象的呢？ 这里需要简单的介绍一下WU提供的<strong>Hook</strong>：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\" target=\"_blank\" rel=\"external\"><code>before-send-file</code></a>。</p>\n<p>文档中指明，它用来在文件发送之前触发，接受<code>file</code>为参数，这个对象就是我们要的！当然，其实也可以WU提供的其它相关事件的回调中获得这个对象，不过放在这里是为了更好的和后面讲的<strong>秒传</strong>配合。代码片段为：</p>\n<pre><code>var userInfo = {userId:&quot;kazaff&quot;};    //模拟用户信息\nvar uniqueFileName = null;        //为了避免每次分片都重新计算唯一标识，放在全局变量中，但如果你的项目需要WU支持多文件上传，那么这里你需要的是一个K/V结构，key可以存file.id\n\nWebUploader.Uploader.register({\n    &quot;before-send-file&quot;: &quot;beforeSendFile&quot;\n    ......\n}, {\n    beforeSendFile: function(file){\n        .....\n        //拿到上传文件的唯一名称，用于断点续传\n        uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.id+file.name+file.type+file.lastModifiedDate+file.size);\n        .....\n    }\n    ......\n});\n</code></pre><p>上面的代码片段我省略了很多不相干的代码，不过放心最后我会把这个例子的完整代码放到github上的。</p>\n<p>这样我们就有了这个唯一标识文件的戳，不过这里我们是在前端生成的，前端的这个戳主要是用于断点续传的，因为每个分片上传前我们都会让WU先发送一个请求来确认该分片是否已经上传过，如果后端告诉我们已经已经传过了，那么WU就会直接跳过该分片，这就实现了我们的断点续传，其实暂停继续和断点续传没啥两样，我们后面再说。当然，判断一个分片是否已经上传，只通过这个文件戳肯定不够，看下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/EcvJCubA/lZz39.png\" alt=\"\"></p>\n<p>请求中还提供了：分片索引和该分片的大小，这两个数据我们是怎么获取到的呢？依然是利用WU提供的Hook：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\" target=\"_blank\" rel=\"external\"><code>before-send</code></a>。这个Hook可以在分片发送之前触发，提供给我们<code>block</code>对象参数就是分片的相关信息，其中包括了我们要的两个数据，代码如下：</p>\n<pre><code>.......\n, beforeSend: function(block){\n        //分片验证是否已传过，用于断点续传\n        var task = new $.Deferred();\n        $.ajax({\n            type: &quot;POST&quot;\n            , url: &quot;fileUpload.php&quot;\n            , data: {\n                type: &quot;chunkCheck&quot;\n                , file: uniqueFileName\n                , chunkIndex: block.chunk\n                , size: block.end - block.start\n            }\n            , cache: false\n            , timeout: 1000 //todo 超时的话，只能认为该分片未上传过\n            , dataType: &quot;json&quot;\n        }).then(function(data, textStatus, jqXHR){\n            if(data.ifExist){   //若存在，返回失败给WebUploader，表明该分块不需要上传\n                task.reject();\n            }else{\n                task.resolve();\n            }\n        }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n            task.resolve();\n        });\n\n        return $.when(task);\n    }\n.......\n</code></pre><p>我在这个Hook中发起了一个ajax请求，用于让后端告诉我们该分片是否需要上传~~</p>\n<p>细心的童鞋应该能注意到一个细节，这么设计也就会导致每个分片的上传可能要发送2次请求，一次用于分片验证，一次用于分片上传。这就需要我们设置一个合理的分片大小，用来<strong>避免一个大文件会向后端发起大量的请求</strong>，我的选择是5M~~</p>\n<p>做到这里，可以说WU已经做好了暂停继续，断点续传，多线程的全部工作，它们都是基于分块的。再进入后端前，我们先来分析一下断点续传和暂停继续的差别：</p>\n<p><strong>断点续传</strong>表示用户可能刷新了页面，或者甚至干脆重启了电脑，反正总之浏览器丢失了正在上传的文件的所有相关数据：文件路径，正在上传的分片索引，上传进度等信息。</p>\n<p><strong>暂停继续</strong>表示用户仍然在当前页面，只是主动触发暂停上传的动作，并在一定时间间隔后再次触发继续上传行为，期间浏览器依然记录着关于上传文件的相关信息。</p>\n<p>除了上面提到的差别外，就没有其它了。也就是说这些差别仅位于浏览器，也就是前端，也就是WU，跟后端关系不大，或者说对于后端处理来说，这两者并没有什么区别，难道不是么？后端只需要回答指定分片是否已存在的问题即可，才不会管这次验证请求来自于断点续传还是暂停继续！！</p>\n<p>ok，现在来说后端吧，刚才我们在前端创建文件的唯一标识，后端要怎么应对呢？当前端的分片验证请求或分片上传请求过来后，后端需要确定这个请求所对应的文件是哪个，而且要把在整个上传过程中生成的分片关联起来，用于合并时查找使用。方案很多，我这里选择一个不依赖数据库的。</p>\n<p>后端在接受到分片上传请求后，会根据我们在前端创建文件标识的方法在后端也创建一个一模一样的标识，用这个标识创建一个文件夹，并把分片上传至这个文件夹中，这样所有同一个文件的分片都会保存在相同的文件夹中，如下图所示：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/Ecw7OKMw/12h4Lr.png\" alt=\"\"></p>\n<p>上图来自于某个大文件上传的过程中，以<code>2e2a311b96d816b695fdf5817bd030f8</code>命名的文件夹下的分片。</p>\n<p>到此为止，我们解决了第一个问题（也为后面的问题做了铺垫）。</p>\n<p>第二个问题涉及到合并这些分片的时机和方式，这里要明确一点，WU分片上传时会以分片的先后顺序上传，但由于网络因素，不保证<code>0号</code>分片一定先于<code>1号</code>分片上传完成，所以<strong>后端不能根据分片下标来判断上传是否完毕</strong>。</p>\n<blockquote>\n<p><s>既然如此，我们只能在每个分片上传完毕后检查一下当前文件夹下的文件数是否与总分片数一致，以此来确定是否上传完毕，如果觉得这样做性能不满意，也可以借助WU的Hook：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\" target=\"_blank\" rel=\"external\"><code>after-send-file</code></a>，这样在所有分片上传完毕后，让WU在该Hook中发送一个ajax请求告诉后端可以合并了，并拿到合并后的目标文件相关信息（路径）。这里我选择了前者。</s></p>\n</blockquote>\n<p><strong><em>以上段落需更正，见文章末尾的[更正1]。</em></strong></p>\n<p>至于合并的方式，我们只需要避免大文件合并时的内存溢出问题即可，这一点跟后端实现语言相关，我打算分别以PHP，NodeJS，JAVA来实现。避免文件读写造成的内存溢出，常用的手段是管道（Pipe），后端代码也会在github上提供，在此就不展示了。</p>\n<p>另外我们还要解决一件事儿：如果某个大文件上传了一半，出于种种理由用户决定再也不会上传它的其他部分了，服务器端怎么办？这些过期分片永远存在服务器端的硬盘上显然无法让正常人接受。我们要怎么办呢？方案同样很多，我这里使用的是为每个上传的文件（不是分片）创建一个临时文件，名字使用上面创建的那个文件唯一标识，如：<code>2e2a311b96d816b695fdf5817bd030f8.tmp</code>。这个文件的<strong>修改时间</strong>会在每次有分片请求时被更新，然后再开启一个定时任务，比方说每夜凌晨检查一下上传文件夹路径下的所有tmp文件的修改时间，如果发现最后的修改时间距当前时间已经很久了，则认为其对应的分片数据需要被清理。如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/EcwpxSRs/guat.png\" alt=\"\"></p>\n<p>好吧，关于第二个问题我们也算搞定了，最后一个问题：如何从指定分块开始上传？这个算是断点续传和暂停继续的核心问题了，而这一点我们需要依赖WU提供的机制：WU分片上传大文件时，会依次上传被切分的分片数据，在这个过程中所需要的分片下标，上传进度等数据都是由WU负责管理的，后端并不需要关注。</p>\n<p>每次分片上传前，都会发起一次校验请求，我们就是通过这样的方式来解决第三个问题的。对于暂停继续，WU保存着分片下标的信息，所以它只会从暂停时的那个分片开始询问，而断点续传由于丢失了分片下标信息，则会从0号分片开始询问。这些内容上面已经提及了~~</p>\n<h2 id=\"秒传\"><a href=\"#秒传\" class=\"headerlink\" title=\"秒传\"></a>秒传</h2><p>相信大家肯定使用过各种类型的网盘，或者是迅雷会员，都会非常中意“离线下载”这个功能。谁都希望添加到迅雷里的下载任务能够一秒钟下载完毕，同样，我们的用户也希望能够一秒钟就上传完一个1G的文件。但这是不可能的，至少不是真的通过上传的方式实现的！</p>\n<p>假设用户A要传的文件是在之前就被用户B上传过的（比方说一部岛国动作片儿，你懂的），这个时候我们不需要傻傻的把这个文件再上传一遍，只需要告诉用户A已经上传完毕了，并返回给他对应的链接，我相信用户A会非常满意的！当然，我们的系统还要处理“写时复制”问题（当用户B删除文件时，由于用户A还在引用，所以文件不应该删除，而应该切断用户B的链接，直到所有用户都不再引用该文件，此时才应该真实删除文件）！</p>\n<p>好吧，我们来看看具体如何实现秒传：应该找个方法来判断上传的文件是否服务器端已经存在！这似乎和我们上面提到的文件唯一标识有点类似，但注意我们上面的那个标识中引入了用户id，所以肯定不符合我们这里的情况。那么去掉用户id是否就ok了呢？</p>\n<p>恩，其实是可以的，不过这种方式生成的一致性验证其实并没有对内容本身进行验证，而是通过其文件的相关信息来做的判断，也就是说如果两个文件的文件名，大小等“凑巧”一模一样，但这两个文件内容不同的话，就会导致一致性校验错误。</p>\n<p>电驴是怎么做的？它会用文件的二进制数据计算文件的md5签名，这样即使文件的名字大小都一样，内容不同也会导致它们的签名不同~这样基本上就是万无一失了，不过对一个大文件进行md5签名可能要话费非常多的时间，这就需要我们来取舍了。</p>\n<p>我在自己的开发机测试了一下，用WU提供的<a href=\"http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_md5File\" target=\"_blank\" rel=\"external\"><code>md5File</code></a>函数计算一个266M的文件的md5签名，耗时：15.573秒。</p>\n<p>WU的md5File函数支持对文件的部分数据做md5签名，这样的话我们就可以对大文件中的一部分内容签名，避免太大的耗时。牛逼坏了！我们按照官方文档的提示使用Hook：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\" target=\"_blank\" rel=\"external\"><code>before-send-file</code></a>：</p>\n<pre><code>...... \nbeforeSendFile: function(file){\n        //秒传验证\n        var task = new $.Deferred();\n        var start = new Date().getTime();\n        (new WebUploader.Uploader()).md5File(file, 0, 10*1024*1024).progress(function(percentage){\n            console.log(percentage);\n        }).then(function(val){\n            console.log(&quot;总耗时: &quot;+((new Date().getTime()) - start)/1000);\n\n            $.ajax({\n                type: &quot;POST&quot;\n                , url: &quot;fileUpload.php&quot;\n                , data: {\n                    type: &quot;md5Check&quot;\n                    , md5: val\n                }\n                , cache: false\n                , timeout: 1000 //todo 超时的话，只能认为该文件不曾上传过\n                , dataType: &quot;json&quot;\n            }).then(function(data, textStatus, jqXHR){\n                if(data.ifExist){   //若存在，这返回失败给WebUploader，表明该文件不需要上传\n                    task.reject();\n\n                    uploader.skipFile(file);\n                    file.path = data.path;\n                    UploadComlate(file);\n                }else{\n                    task.resolve();\n                    //拿到上传文件的唯一名称，用于断点续传\n                    uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n                }\n            }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n                task.resolve();\n                //拿到上传文件的唯一名称，用于断点续传\n                uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n            });\n        });\n        return $.when(task);\n    }\n    ......\n</code></pre><p>好啦，前端做完了，后端只需要拿到对应的md5签名，然后进行相关的检索，如果确实存在这个签名匹配的文件，则提示前端该文件已经存在。这部分通常会利用数据库来完成，当然也可以使用内存KV数据结构来做，我们不纠结这！</p>\n<hr>\n<p>好啦，截止到这里，我们大概已经完成了大文件的上传问题，完整的代码我会稍后在<a href=\"https://github.com/kazaff/webuploaderDemo\" target=\"_blank\" rel=\"external\">github</a>上提供出来，有兴趣的童鞋可以去瞅瞅。</p>\n<hr>\n<p>更正1：</p>\n<p>尽管我们在例子中已经设置为单文件上传，并且在生成文件的唯一标识时加上了userId，但这并不能阻碍并发上传时造成的冲突，先来看下面这个场景，让我来手绘一张图，真的是纯手绘哟~~：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EcI4oK72/medish.jpg\" alt=\"\"></p>\n<p>假设我们的用户A用浏览器打开了两个tab窗口（userId一致）：tab1，tab2。这两个窗口同时上传同一个文件（文件标识一致），这里暂不考虑浏览器对多tab上传同一文件是否会做优化，如果确实会做优化，那我们也可以假设用户是同时在两款浏览器上同时上传某一个文件。</p>\n<p>如上图所示，假设tab1先上传了3个分片，在上传第四个分片之前阻塞了（原因不详）。这个时候tab2开始上传，由于生产的文件标识一致，所以tab2的分片校验请求会对前3个分片返回true，这样tab2就会直接从第4个分片开始上传，我们假设tab2上传完第4个分片且再第5个分片开始上传前，tab1结束了阻塞状态，它会得知第4个分片已经上传完毕，迅速开始第5个分片的上传工作。</p>\n<p>到目前为止，一切都是那么的顺利和合理，仿佛生活多么的美好。好，这个时候我们假设这个文件一共就需要5个分片就可以上传完毕。从图上可以看到，此时tab1和tab2会同时进行第5个分片的上传任务（因为在它们发送的分片校验请求时，彼此都没有完成上传，所以它们都会得到一个目标分片不存在须上传的回复）。</p>\n<p>如果最终结果是tab1先上传完成了，那么依照我上文的做法，那么tab1会触发合并动作，合并过程中会清理已合并分片。那么问题就来了，会有以下几种不好的情况发生：</p>\n<ol>\n<li>tab1合并完分片1时，但tab2正在合并分片1，tab1删除分片1失败</li>\n</ol>\n<ul>\n<li>tab1合并完分片1后成功删除分片1，导致tab2上传完分片5后无法触发合并动作（分片总数不达标），从而导致前端WU很尴尬（因为分片5上传完毕后就会触发uploadSuccess事件，但拿不到合并后的文件地址）</li>\n<li>tab1合并完毕且删除了tmp文件，此时tab2上传完分片5，再次到回到情况2</li>\n</ul>\n<p>好乱啊，总之上文中的方案不能很好的解决这个场景。那该怎么办好捏？</p>\n<p>WU似乎应该是考虑过这种情况，所以提供了对应的Hook：<strong>after-send-file</strong>。</p>\n<blockquote>\n<p>在所有分片都上传完毕后，且没有错误后request，用来做分片验证，此时如果promise被reject，当前文件上传会触发错误。</p>\n</blockquote>\n<p>我们只需要在这个hook中发送一个ajax请求给后端来触发合并动作，听起来这并没有解决并发啊，毕竟这个请求也可能同时到达后端！</p>\n<p>是的，没错，但这么做有个好处，至少WU并不会尴尬，你可以告诉WU上传失败了，至少不会像之前的方案那样，明明触发了uploadSuccess事件，但却拿不到合并后的文件地址。</p>\n<p>那么并发冲突怎么解决？我们就需要使用一种锁机制了，如果node平台，由于其执行主进程是单线程的，所以我们可以在全局变量中设置一个标志位即可。在java平台中，由于其依赖多线程实现并发，我们就要借助同步操作来解决这个问题。最头疼的就是php，老一点的手段就是让多个进程基于某个临时文件锁进行同步，当然也可以依赖第三方软件解决，比方说redis的原子操作，甚至再重一点引入zookeeper。</p>\n<p>我会在上面提到的github地址中选择一种方案来解决这个问题的，敬请关注。</p>\n","excerpt":"<p>早先我们在做网站的大文件上传时一般都是借助flash控件的，那个时代html5没有开放文件操作接口给js，而直接用表单提交大文件的话，以那个时候的带宽来上传百兆文件要花非常久的时间，我们无法保证用户能耐心等到上传完（在此期间，用户不能刷新页面，只能等~）。一旦用户的网络出现抖动，就可能导致前功尽弃，这些是不可接受的！<br>","more":"<br>那么做到什么样的程度才能够保证大文件上传的可用性呢？我在这里简单的列出来一些点：</p>\n<ul>\n<li>支持断点续传</li>\n<li>支持分块</li>\n<li>支持多线程(*)</li>\n<li>支持秒传(*)</li>\n<li>支持显示上传进度</li>\n<li>支持图片预览</li>\n<li>支持暂停上传</li>\n<li>拖拽上传</li>\n</ul>\n<p>上面列出的这几点是我认为都需要实现的，<strong>带星号</strong>的我觉得算是加分项吧，毕竟像迅雷客户端这样的体验真的是太劲爆了。</p>\n<p>接下来我们就根据上面列出的几点来分析，基于一款百度开源的前端上传控件：<a href=\"http://fex-team.github.io/webuploader/\">WebUploader</a>（以下简称：WU）。</p>\n<h2 id=\"上传图片预览\"><a href=\"#上传图片预览\" class=\"headerlink\" title=\"上传图片预览\"></a>上传图片预览</h2><p>这一点其实在html5开放了本地文件操作接口后，就变得非常<a href=\"http://www.helloweba.com/view-blog-224.html\">简单</a>了。WU已经把这个<a href=\"http://fex-team.github.io/webuploader/getting-started.html#%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0\">功能</a>封装起来了，用起来非常的简单，这里就不多说了。</p>\n<p>不仅如此，WU还提供了更强大的功能，它可以在生成缩略图的时候进行图片压缩处理，具体可从<a href=\"http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options\">API文档</a>中查看到。</p>\n<h2 id=\"上传进度\"><a href=\"#上传进度\" class=\"headerlink\" title=\"上传进度\"></a>上传进度</h2><p>如果让用户等待十几分钟，不做任何提示肯定是非常不合适的，天知道是正在上传，还是死机了啊！这一点也是依靠<a href=\"http://ux.sohu.com/topics/4ff177586c423d2471000725\">HTML5的新特性</a>做到的。不过在WU封装后，它就成了一个可监听的<a href=\"http://fex-team.github.io/webuploader/getting-started.html#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E8%BF%9B%E5%BA%A6\">事件</a>而已，这里也不多说了。</p>\n<h2 id=\"拖拽上传\"><a href=\"#拖拽上传\" class=\"headerlink\" title=\"拖拽上传\"></a>拖拽上传</h2><p>你可能会觉得这个功能没啥大用，但我却把它视为革命性的飞跃。不过在WU里实现起来只需要靠一个配置两个参数即可：<a href=\"http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_options\">dnd和disableGlobalDnd</a>。</p>\n<h2 id=\"分块，暂停上传，多线程，断点续传\"><a href=\"#分块，暂停上传，多线程，断点续传\" class=\"headerlink\" title=\"分块，暂停上传，多线程，断点续传\"></a>分块，暂停上传，多线程，断点续传</h2><p>其实只要支持了分块功能，像什么断点续传啊多线程啊就都有了！而借助html5提供给我们的文件API，分块也灰常的简单。我们就直接拿WU来说吧，它的配置中有以下几个参数：</p>\n<ul>\n<li>chunked</li>\n<li>chunkSize</li>\n<li>chunkRetry</li>\n<li>threads</li>\n<li><p>prepareNextFile</p>\n<pre><code>var uploader = WebUploader.create({\n        swf: &quot;Uploader.swf&quot;\n        , server: &quot;fileUpload.php&quot;\n        , pick: &quot;#picker&quot;\n        , resize: false\n        , dnd: &quot;#theList&quot;\n        , paste: document.body\n        , disableGlobalDnd: true\n        , thumb: {\n            width: 100\n            , height: 100\n            , quality: 70\n            , allowMagnify: true\n            , crop: true\n        }\n        , compress: false\n        , prepareNextFile: true\n        , chunked: true\n        , chunkSize: 5000 * 1024\n        , threads: true\n        , formData: userInfo\n        , fileNumLimit: 1\n        , fileSingleSizeLimit: 1000 * 1024 * 1024\n        , duplicate: true\n    });\n</code></pre></li>\n</ul>\n<p>我把每个分片设置为<code>5M</code>大小，同时开启了多线程。这样设置以后，你就会发现上传被切分成多次请求了，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/EcriprRN/amcvb.png\" alt=\"\"></p>\n<p>注意，每个分片的上传请求中都包含三个重要的标识信息：</p>\n<ul>\n<li>size：表示文件的总大小</li>\n<li>chunks：表示分片的总个数</li>\n<li>chunk：表示当前是第几个分片（分片下标从0开始）</li>\n</ul>\n<p>WU已经把该做的做完了，而且做得还很不错，那么它都做了什么：</p>\n<ul>\n<li>文件拆分成指定大小的块</li>\n<li>分块多线程发起上传请求</li>\n<li>提供暂停功能</li>\n<li>分块上传失败后重试</li>\n</ul>\n<p>接下来就是我们后端代码要负责的了，我简单列一下后端要解决的问题点：</p>\n<ol>\n<li>如何识别不同的分块是否属于同一个目标文件</li>\n<li>何时把多分片合并成一个完整的文件<ul>\n<li>如何知道所有的分块全部传完完毕<ul>\n<li>如何避免合并大文件造成的内存占用</li>\n<li>长期未上传完成的文件如何清理</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>如何从指定分块开始上传（续传，暂停后继续） </li>\n</ol>\n<p>第一个问题要如何解决呢？如果能拿到每个文件的唯一标识的话，我们就可以通过这个标识来甄别分块的归属，至于这个唯一标识要根据哪些数据生成，这就要看你的系统的具体情况了，我这里简单的利用上传文件的相关信息和当前用户的id信息做md5签名作为这个标识：</p>\n<pre><code>uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n</code></pre><p>其中<code>userInfo</code>来自于用户登录后返回给前端框架的用户信息，其中<code>userId</code>即为用户的id。<code>file</code>其实是WU提供的一个对象，用来表示特定的上传文件，我们是怎么拿到这个对象的呢？ 这里需要简单的介绍一下WU提供的<strong>Hook</strong>：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\"><code>before-send-file</code></a>。</p>\n<p>文档中指明，它用来在文件发送之前触发，接受<code>file</code>为参数，这个对象就是我们要的！当然，其实也可以WU提供的其它相关事件的回调中获得这个对象，不过放在这里是为了更好的和后面讲的<strong>秒传</strong>配合。代码片段为：</p>\n<pre><code>var userInfo = {userId:&quot;kazaff&quot;};    //模拟用户信息\nvar uniqueFileName = null;        //为了避免每次分片都重新计算唯一标识，放在全局变量中，但如果你的项目需要WU支持多文件上传，那么这里你需要的是一个K/V结构，key可以存file.id\n\nWebUploader.Uploader.register({\n    &quot;before-send-file&quot;: &quot;beforeSendFile&quot;\n    ......\n}, {\n    beforeSendFile: function(file){\n        .....\n        //拿到上传文件的唯一名称，用于断点续传\n        uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.id+file.name+file.type+file.lastModifiedDate+file.size);\n        .....\n    }\n    ......\n});\n</code></pre><p>上面的代码片段我省略了很多不相干的代码，不过放心最后我会把这个例子的完整代码放到github上的。</p>\n<p>这样我们就有了这个唯一标识文件的戳，不过这里我们是在前端生成的，前端的这个戳主要是用于断点续传的，因为每个分片上传前我们都会让WU先发送一个请求来确认该分片是否已经上传过，如果后端告诉我们已经已经传过了，那么WU就会直接跳过该分片，这就实现了我们的断点续传，其实暂停继续和断点续传没啥两样，我们后面再说。当然，判断一个分片是否已经上传，只通过这个文件戳肯定不够，看下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/EcvJCubA/lZz39.png\" alt=\"\"></p>\n<p>请求中还提供了：分片索引和该分片的大小，这两个数据我们是怎么获取到的呢？依然是利用WU提供的Hook：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\"><code>before-send</code></a>。这个Hook可以在分片发送之前触发，提供给我们<code>block</code>对象参数就是分片的相关信息，其中包括了我们要的两个数据，代码如下：</p>\n<pre><code>.......\n, beforeSend: function(block){\n        //分片验证是否已传过，用于断点续传\n        var task = new $.Deferred();\n        $.ajax({\n            type: &quot;POST&quot;\n            , url: &quot;fileUpload.php&quot;\n            , data: {\n                type: &quot;chunkCheck&quot;\n                , file: uniqueFileName\n                , chunkIndex: block.chunk\n                , size: block.end - block.start\n            }\n            , cache: false\n            , timeout: 1000 //todo 超时的话，只能认为该分片未上传过\n            , dataType: &quot;json&quot;\n        }).then(function(data, textStatus, jqXHR){\n            if(data.ifExist){   //若存在，返回失败给WebUploader，表明该分块不需要上传\n                task.reject();\n            }else{\n                task.resolve();\n            }\n        }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n            task.resolve();\n        });\n\n        return $.when(task);\n    }\n.......\n</code></pre><p>我在这个Hook中发起了一个ajax请求，用于让后端告诉我们该分片是否需要上传~~</p>\n<p>细心的童鞋应该能注意到一个细节，这么设计也就会导致每个分片的上传可能要发送2次请求，一次用于分片验证，一次用于分片上传。这就需要我们设置一个合理的分片大小，用来<strong>避免一个大文件会向后端发起大量的请求</strong>，我的选择是5M~~</p>\n<p>做到这里，可以说WU已经做好了暂停继续，断点续传，多线程的全部工作，它们都是基于分块的。再进入后端前，我们先来分析一下断点续传和暂停继续的差别：</p>\n<p><strong>断点续传</strong>表示用户可能刷新了页面，或者甚至干脆重启了电脑，反正总之浏览器丢失了正在上传的文件的所有相关数据：文件路径，正在上传的分片索引，上传进度等信息。</p>\n<p><strong>暂停继续</strong>表示用户仍然在当前页面，只是主动触发暂停上传的动作，并在一定时间间隔后再次触发继续上传行为，期间浏览器依然记录着关于上传文件的相关信息。</p>\n<p>除了上面提到的差别外，就没有其它了。也就是说这些差别仅位于浏览器，也就是前端，也就是WU，跟后端关系不大，或者说对于后端处理来说，这两者并没有什么区别，难道不是么？后端只需要回答指定分片是否已存在的问题即可，才不会管这次验证请求来自于断点续传还是暂停继续！！</p>\n<p>ok，现在来说后端吧，刚才我们在前端创建文件的唯一标识，后端要怎么应对呢？当前端的分片验证请求或分片上传请求过来后，后端需要确定这个请求所对应的文件是哪个，而且要把在整个上传过程中生成的分片关联起来，用于合并时查找使用。方案很多，我这里选择一个不依赖数据库的。</p>\n<p>后端在接受到分片上传请求后，会根据我们在前端创建文件标识的方法在后端也创建一个一模一样的标识，用这个标识创建一个文件夹，并把分片上传至这个文件夹中，这样所有同一个文件的分片都会保存在相同的文件夹中，如下图所示：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/Ecw7OKMw/12h4Lr.png\" alt=\"\"></p>\n<p>上图来自于某个大文件上传的过程中，以<code>2e2a311b96d816b695fdf5817bd030f8</code>命名的文件夹下的分片。</p>\n<p>到此为止，我们解决了第一个问题（也为后面的问题做了铺垫）。</p>\n<p>第二个问题涉及到合并这些分片的时机和方式，这里要明确一点，WU分片上传时会以分片的先后顺序上传，但由于网络因素，不保证<code>0号</code>分片一定先于<code>1号</code>分片上传完成，所以<strong>后端不能根据分片下标来判断上传是否完毕</strong>。</p>\n<blockquote>\n<p><s>既然如此，我们只能在每个分片上传完毕后检查一下当前文件夹下的文件数是否与总分片数一致，以此来确定是否上传完毕，如果觉得这样做性能不满意，也可以借助WU的Hook：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\"><code>after-send-file</code></a>，这样在所有分片上传完毕后，让WU在该Hook中发送一个ajax请求告诉后端可以合并了，并拿到合并后的目标文件相关信息（路径）。这里我选择了前者。</s></p>\n</blockquote>\n<p><strong><em>以上段落需更正，见文章末尾的[更正1]。</em></strong></p>\n<p>至于合并的方式，我们只需要避免大文件合并时的内存溢出问题即可，这一点跟后端实现语言相关，我打算分别以PHP，NodeJS，JAVA来实现。避免文件读写造成的内存溢出，常用的手段是管道（Pipe），后端代码也会在github上提供，在此就不展示了。</p>\n<p>另外我们还要解决一件事儿：如果某个大文件上传了一半，出于种种理由用户决定再也不会上传它的其他部分了，服务器端怎么办？这些过期分片永远存在服务器端的硬盘上显然无法让正常人接受。我们要怎么办呢？方案同样很多，我这里使用的是为每个上传的文件（不是分片）创建一个临时文件，名字使用上面创建的那个文件唯一标识，如：<code>2e2a311b96d816b695fdf5817bd030f8.tmp</code>。这个文件的<strong>修改时间</strong>会在每次有分片请求时被更新，然后再开启一个定时任务，比方说每夜凌晨检查一下上传文件夹路径下的所有tmp文件的修改时间，如果发现最后的修改时间距当前时间已经很久了，则认为其对应的分片数据需要被清理。如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/EcwpxSRs/guat.png\" alt=\"\"></p>\n<p>好吧，关于第二个问题我们也算搞定了，最后一个问题：如何从指定分块开始上传？这个算是断点续传和暂停继续的核心问题了，而这一点我们需要依赖WU提供的机制：WU分片上传大文件时，会依次上传被切分的分片数据，在这个过程中所需要的分片下标，上传进度等数据都是由WU负责管理的，后端并不需要关注。</p>\n<p>每次分片上传前，都会发起一次校验请求，我们就是通过这样的方式来解决第三个问题的。对于暂停继续，WU保存着分片下标的信息，所以它只会从暂停时的那个分片开始询问，而断点续传由于丢失了分片下标信息，则会从0号分片开始询问。这些内容上面已经提及了~~</p>\n<h2 id=\"秒传\"><a href=\"#秒传\" class=\"headerlink\" title=\"秒传\"></a>秒传</h2><p>相信大家肯定使用过各种类型的网盘，或者是迅雷会员，都会非常中意“离线下载”这个功能。谁都希望添加到迅雷里的下载任务能够一秒钟下载完毕，同样，我们的用户也希望能够一秒钟就上传完一个1G的文件。但这是不可能的，至少不是真的通过上传的方式实现的！</p>\n<p>假设用户A要传的文件是在之前就被用户B上传过的（比方说一部岛国动作片儿，你懂的），这个时候我们不需要傻傻的把这个文件再上传一遍，只需要告诉用户A已经上传完毕了，并返回给他对应的链接，我相信用户A会非常满意的！当然，我们的系统还要处理“写时复制”问题（当用户B删除文件时，由于用户A还在引用，所以文件不应该删除，而应该切断用户B的链接，直到所有用户都不再引用该文件，此时才应该真实删除文件）！</p>\n<p>好吧，我们来看看具体如何实现秒传：应该找个方法来判断上传的文件是否服务器端已经存在！这似乎和我们上面提到的文件唯一标识有点类似，但注意我们上面的那个标识中引入了用户id，所以肯定不符合我们这里的情况。那么去掉用户id是否就ok了呢？</p>\n<p>恩，其实是可以的，不过这种方式生成的一致性验证其实并没有对内容本身进行验证，而是通过其文件的相关信息来做的判断，也就是说如果两个文件的文件名，大小等“凑巧”一模一样，但这两个文件内容不同的话，就会导致一致性校验错误。</p>\n<p>电驴是怎么做的？它会用文件的二进制数据计算文件的md5签名，这样即使文件的名字大小都一样，内容不同也会导致它们的签名不同~这样基本上就是万无一失了，不过对一个大文件进行md5签名可能要话费非常多的时间，这就需要我们来取舍了。</p>\n<p>我在自己的开发机测试了一下，用WU提供的<a href=\"http://fex-team.github.io/webuploader/doc/index.html#WebUploader_Uploader_md5File\"><code>md5File</code></a>函数计算一个266M的文件的md5签名，耗时：15.573秒。</p>\n<p>WU的md5File函数支持对文件的部分数据做md5签名，这样的话我们就可以对大文件中的一部分内容签名，避免太大的耗时。牛逼坏了！我们按照官方文档的提示使用Hook：<a href=\"http://fex-team.github.io/webuploader/document.html#%E4%BA%8B%E4%BB%B6\"><code>before-send-file</code></a>：</p>\n<pre><code>...... \nbeforeSendFile: function(file){\n        //秒传验证\n        var task = new $.Deferred();\n        var start = new Date().getTime();\n        (new WebUploader.Uploader()).md5File(file, 0, 10*1024*1024).progress(function(percentage){\n            console.log(percentage);\n        }).then(function(val){\n            console.log(&quot;总耗时: &quot;+((new Date().getTime()) - start)/1000);\n\n            $.ajax({\n                type: &quot;POST&quot;\n                , url: &quot;fileUpload.php&quot;\n                , data: {\n                    type: &quot;md5Check&quot;\n                    , md5: val\n                }\n                , cache: false\n                , timeout: 1000 //todo 超时的话，只能认为该文件不曾上传过\n                , dataType: &quot;json&quot;\n            }).then(function(data, textStatus, jqXHR){\n                if(data.ifExist){   //若存在，这返回失败给WebUploader，表明该文件不需要上传\n                    task.reject();\n\n                    uploader.skipFile(file);\n                    file.path = data.path;\n                    UploadComlate(file);\n                }else{\n                    task.resolve();\n                    //拿到上传文件的唯一名称，用于断点续传\n                    uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n                }\n            }, function(jqXHR, textStatus, errorThrown){    //任何形式的验证失败，都触发重新上传\n                task.resolve();\n                //拿到上传文件的唯一名称，用于断点续传\n                uniqueFileName = md5(&apos;&apos;+userInfo.userId+file.name+file.type+file.lastModifiedDate+file.size);\n            });\n        });\n        return $.when(task);\n    }\n    ......\n</code></pre><p>好啦，前端做完了，后端只需要拿到对应的md5签名，然后进行相关的检索，如果确实存在这个签名匹配的文件，则提示前端该文件已经存在。这部分通常会利用数据库来完成，当然也可以使用内存KV数据结构来做，我们不纠结这！</p>\n<hr>\n<p>好啦，截止到这里，我们大概已经完成了大文件的上传问题，完整的代码我会稍后在<a href=\"https://github.com/kazaff/webuploaderDemo\">github</a>上提供出来，有兴趣的童鞋可以去瞅瞅。</p>\n<hr>\n<p>更正1：</p>\n<p>尽管我们在例子中已经设置为单文件上传，并且在生成文件的唯一标识时加上了userId，但这并不能阻碍并发上传时造成的冲突，先来看下面这个场景，让我来手绘一张图，真的是纯手绘哟~~：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EcI4oK72/medish.jpg\" alt=\"\"></p>\n<p>假设我们的用户A用浏览器打开了两个tab窗口（userId一致）：tab1，tab2。这两个窗口同时上传同一个文件（文件标识一致），这里暂不考虑浏览器对多tab上传同一文件是否会做优化，如果确实会做优化，那我们也可以假设用户是同时在两款浏览器上同时上传某一个文件。</p>\n<p>如上图所示，假设tab1先上传了3个分片，在上传第四个分片之前阻塞了（原因不详）。这个时候tab2开始上传，由于生产的文件标识一致，所以tab2的分片校验请求会对前3个分片返回true，这样tab2就会直接从第4个分片开始上传，我们假设tab2上传完第4个分片且再第5个分片开始上传前，tab1结束了阻塞状态，它会得知第4个分片已经上传完毕，迅速开始第5个分片的上传工作。</p>\n<p>到目前为止，一切都是那么的顺利和合理，仿佛生活多么的美好。好，这个时候我们假设这个文件一共就需要5个分片就可以上传完毕。从图上可以看到，此时tab1和tab2会同时进行第5个分片的上传任务（因为在它们发送的分片校验请求时，彼此都没有完成上传，所以它们都会得到一个目标分片不存在须上传的回复）。</p>\n<p>如果最终结果是tab1先上传完成了，那么依照我上文的做法，那么tab1会触发合并动作，合并过程中会清理已合并分片。那么问题就来了，会有以下几种不好的情况发生：</p>\n<ol>\n<li>tab1合并完分片1时，但tab2正在合并分片1，tab1删除分片1失败</li>\n</ol>\n<ul>\n<li>tab1合并完分片1后成功删除分片1，导致tab2上传完分片5后无法触发合并动作（分片总数不达标），从而导致前端WU很尴尬（因为分片5上传完毕后就会触发uploadSuccess事件，但拿不到合并后的文件地址）</li>\n<li>tab1合并完毕且删除了tmp文件，此时tab2上传完分片5，再次到回到情况2</li>\n</ul>\n<p>好乱啊，总之上文中的方案不能很好的解决这个场景。那该怎么办好捏？</p>\n<p>WU似乎应该是考虑过这种情况，所以提供了对应的Hook：<strong>after-send-file</strong>。</p>\n<blockquote>\n<p>在所有分片都上传完毕后，且没有错误后request，用来做分片验证，此时如果promise被reject，当前文件上传会触发错误。</p>\n</blockquote>\n<p>我们只需要在这个hook中发送一个ajax请求给后端来触发合并动作，听起来这并没有解决并发啊，毕竟这个请求也可能同时到达后端！</p>\n<p>是的，没错，但这么做有个好处，至少WU并不会尴尬，你可以告诉WU上传失败了，至少不会像之前的方案那样，明明触发了uploadSuccess事件，但却拿不到合并后的文件地址。</p>\n<p>那么并发冲突怎么解决？我们就需要使用一种锁机制了，如果node平台，由于其执行主进程是单线程的，所以我们可以在全局变量中设置一个标志位即可。在java平台中，由于其依赖多线程实现并发，我们就要借助同步操作来解决这个问题。最头疼的就是php，老一点的手段就是让多个进程基于某个临时文件锁进行同步，当然也可以依赖第三方软件解决，比方说redis的原子操作，甚至再重一点引入zookeeper。</p>\n<p>我会在上面提到的github地址中选择一种方案来解决这个问题的，敬请关注。</p>"},{"title":"RESTEasy指南","date":"2015-03-10T07:54:30.000Z","_content":"\n由于dubbox的这个[问题](https://github.com/dangdangdotcom/dubbox/issues/30)，我决定先了解一下这个框架。为了快速认识RESTEasy，我决定翻译一篇看似还不错的[文章](http://www.mastertheboss.com/jboss-frameworks/resteasy/resteasy-tutorial)。下面就开始，不过我英文能力确实不如我的中文能力，请大家见谅。\n<!-- more -->\n\n\n---\n\nRESTEasy是一个实现了JAX-RS规范的轻量实现，该规范是针对基于http协议的RESTful Web Service而提供标准的JAVA API定义。这篇指南我们来手把手演示如何使用Resteasy来创建一些简单的RESTful Web Service。\n\n#安装RESTEasy\n---\n根据你所使用的不同版本的JBoss，安装RESTEasy需要不同的步骤。\n\n##JBoss 6/7\n\n在此版本下安装RESTEasy你不需要下载任何包，RESTEasy类已经内嵌在server中。应用服务器会自动发现导出成RESTful的服务资源。\n\n更多关于RESTEasy和JBoss 7的例子可以看[这里](http://www.mastertheboss.com/resteasy/restful-web-services-on-jboss-as-7)。\n\n你唯一需要做的只是在`web.xml`中插入正确的命名空间：\n\n\t<web-app version=\"3.0\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\">\n \n\t</web-app>\n\n##旧JBoss版本\n\n如果你工作在旧的JBoss版本下，安装RESTEasy你只需要做下面几步：\n\n###1.下载RESTEasy\n\n你需要先从[这里](http://sourceforge.net/projects/resteasy/files/Resteasy%20JAX-RS/)下载最新的RESTEasy稳定版。\n\n###2.把RESTEasy类加入你的web应用\n\n![](http://www.mastertheboss.com/images/stories/ws/resteasy-libs.PNG)\n\n###3.定义listenser和bootstrap\n\n在`web.xml`中添加下面的配置：\n\n\t<?xml version=\"1.0\"?>\n\t<!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\"\n\t\"http://java.sun.com/dtd/web-app_2_3.dtd\">\n\t<web-app>\n\t    <display-name>RestEasy sample Web Application</display-name>\n\t \n\t    <listener>\n\t        <listener-class>\n\t            org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap\n\t        </listener-class>\n\t    </listener>\n\t \n\t    <servlet>\n\t        <servlet-name>Resteasy</servlet-name>\n\t        <servlet-class>\n\t            org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher\n\t        </servlet-class>\n\t        <init-param>\n\t            <param-name>javax.ws.rs.Application</param-name>\n\t            <param-value>sample.HelloWorldApplication</param-value>\n\t        </init-param>\n\t    </servlet>\n\t \n\t    <servlet-mapping>\n\t        <servlet-name>Resteasy</servlet-name>\n\t        <url-pattern>/*</url-pattern>\n\t    </servlet-mapping>\n\t \n\t</web-app>\n\n**org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap**类是一个**ServletContextListener**，它负责配置实例化 ResteasyProviderFactory 和 Registry。\n\n然后，你还需要设置 **javax.ws.rs.core.Application** 参数，赋值一个被用于提供给你的应用去作为所有JAX-RS的根资源和提供者的入口单例实现（工厂模式）。不过在JBoss 6-M4或更高版本的环境下可以省略这个设置，因为在你部署应用时应用服务器已经帮你自动处理过了。\n\n最终你还需要指定一个url模式，用于RESTEasy来识别对应服务，如上面的配置例子，`/*`表示所有资源都会被RESTEasy servlet匹配。\n\n###4.创建一个单例类\n\n现在，我们来创建一个单例类，该类就是前面提到的 **javax.ws.rs.core.Application** 所需要的实现：\n\n\tpackage sample;\n\t \n\timport java.util.HashSet;\n\timport java.util.Set;\n\timport javax.ws.rs.core.Application;\n\t \n\timport sample.HelloWorld;\n\t \n\tpublic class HelloWorldApplication extends Application\n\t{\n\t    private Set<Object> singletons = new HashSet();\n\t    private Set<Class<?>> empty = new HashSet();\n\t \n\t    public HelloWorldApplication() {\n\t        // 把你的rest资源添加到这个属性中\n\t        this.singletons.add(new HelloWorld());\n\t    }\n\t \n\t    public Set<Class<?>> getClasses()\n\t    {\n\t        return this.empty;\n\t    }\n\t \n\t    public Set<Object> getSingletons()\n\t    {\n\t        return this.singletons;\n\t    }\n\t}\n\n在启动时上面声明的这个类会被用于初始化你想提供的RESTful服务，在这个例子中，我们加了一个 HelloWorld 服务。\n\n####资源的自动发现\n\n如果你更希望让RESTEasy自动去发现你的资源，而不是像刚才那样手动添加一个单例bean来完成这个目的，你可以在`web.xml`中添加下面的配置：\n\n\t<context-param>\n\t  <param-name>resteasy.scan</param-name>\n\t  <param-value>true</param-value>\n\t</context-param>\n\t<context-param>\n\t  <param-name>resteasy.servlet.mapping.prefix</param-name>\n\t  <param-value>/</param-value>\n\t</context-param>\n\n\n#创建你的第一个RESTful服务\n\n基于REST风格的架构，一切都是资源。 资源可以通过http提供的通用接口（POST,GET,PUT,DELETE）来操作。所有资源都应该支持这些通用接口，并且资源都应该有一个全局唯一的ID（通常指的就是URL）。\n\n在我们的第一个例子里，我们创建一个RESTful服务，每当它被以get方式访问请求时，会返回一个字符串：\n\n\tpackage sample;\n \n\timport javax.ws.rs.*;\n\t \n\t@Path(\"tutorial\")\n\tpublic class HelloWorld\n\t{\n\t    @GET\n\t    @Path(\"helloworld\")\n\t    public String helloworld() {\n\t        return \"Hello World!\";\n\t    }\n\t}\n\n在类上添加的那个**@Path**注解的作用是指定了该资源的统一URL前缀，而方法上的**@Path**注解则是定义了更具体的某一个资源操作。（译者：原文中的“action”违背了RESTful规范，资源url应该以名词为主）\n\n在这个例子中，如果你想调用我们的helloworld服务，你需要访问下面这个URL（我们假设应用打包为：RestEasy.war）:\n\n![](http://www.mastertheboss.com/images/stories/ws/resteasy-path.PNG)\n\n访问后在你的浏览器会显示“Hello World!”字符串。现在我们添加一个参数：\n\n\t@GET\n\t@Path(\"helloname/{name}\")\n\tpublic String hello(@PathParam(\"name\") final String name) {\n\t  return \"Hello \" +name;\n\t}\n\n现在，我们定义了一个“helloname”服务，它接受一个**{name}**参数。服务会从请求url中获取对应参数并返回，如下：\n\nhttp://localhost:8080/RestEasy/tutorial/helloname/francesco\n\n将返回：\n\nHello Francesco\n\n\n\n#使你的RESTEasy服务返回XML\n\n根据JAX-RS规范要求，RESTEasy支持多个JAXB注解，并提供JAXB Providers。\n\nRESTEasy会根据资源的参数类型或返回类型来选择不同的provider。当方法返回的对象的类声明加上了JAXB注解（@XmlRootEntity或@XmlType）时，RESTEasy会选择注解指定的JAXB Provider。\n\n举个例子，下面将返回xml：\n\n\t@GET\n\t@Path(\"item\")\n\t@Produces({\"application/xml\"})\n\tpublic Item getItem() {\n\t\tItem item = new Item(\"computer\",2500);\n\t\treturn item;\n\t} \n\n现在把这个方法加到你的 HelloWorld 服务中，然后调用这个服务（http://localhost:8080/RestEasy/tutorial/item），将返回下面这个xml：\n\n\t<item>\n\t   <description>computer</description>\n\t   <price>2500</price>\n\t</item>\n\n如果你需要返回一个数组，你可以简单的这么写：\n\n\t@GET\n\t@Path(\"itemArray\")\n\t@Produces({\"application/xml\"})\n\tpublic Item[]  getItem() {\n\t  Item item[] = new Item[2];\n\t  item[0] = new Item(\"computer\",2500);\n\t  item[1] = new Item(\"chair\",100);\n\t \n\t  return item;\n\t}\n\n调用后将会返回：\n\n\t<collection>\n\t   <item>\n\t     <description>computer</description>\n\t     <price>2500</price>\n\t   </item>\n\t   <item>\n\t     <description>computer</description>\n\t     <price>2500</price>\n\t   </item>\n\t</collection>\n\n有时候，你需要使用标准的java集合，这时候你就不得不提供一个包装类：\n\n\t@GET\n\t@Path(\"itemList\")\n\t@Produces({\"application/xml\"})\n\t public ItemList  getCollItems() {\n\t  ArrayList list = new ArrayList();\n\t  Item item1 = new Item(\"computer\",2500);\n\t  Item item2 = new Item(\"chair\",100);\n\t  Item item3 = new Item(\"table\",200);\n\t \n\t  list.add(item1);\n\t  list.add(item2);\n\t  list.add(item3);\n\t \n\t  return new ItemList(list);\n\t }\n\n我们来看一下 **ItemList** 包装类的定义：\n\n\tpackage sample;\n \n\timport javax.xml.bind.annotation.XmlRootElement;\n\timport javax.xml.bind.annotation.XmlElement;\n\timport java.util.List;\n\t \n\t \n\t@XmlRootElement(name=\"listing\")\n\tpublic class ItemList\n\t{\n\t    private List<Item> items;\n\t \n\t    public ItemList(){}\n\t \n\t    public ItemList(List<Item> items)\n\t    {\n\t        this.items = items;\n\t    }\n\t \n\t    @XmlElement(name=\"items\")\n\t    public List<Item> getItems()\n\t    {\n\t        return items;\n\t    }\n\t}\n\n返回的xml如下：\n\n\t<listing>\n \n\t  <items>\n\t    <description>computer</description>\n\t    <price>2500</price>\n\t  </items>\n\t\n\t  <items>\n\t    <description>chair</description>\n\t    <price>100</price>\n\t  </items>\n\t \n\t  <items>\n\t    <description>table</description>\n\t    <price>200</price>\n\t  </items>\n\t \n\t</listing>\n\n\n#使用JSON providers\n\n根据[文档](http://docs.jboss.org/resteasy/docs/2.0.0.GA/userguide/html/Built_in_JAXB_providers.html)，RESTEasy支持多个不同的providers去创建xml，而JSON是一个非常有用的返回集合的结构，它支持lists，sets，arrays，如下：\n\n\t@GET\n\t@Path(\"items\")\n\t@Produces(\"application/json\")\n\t@Mapped\n\tpublic ItemList  getJSONItems() {\n\t  ArrayList list = new ArrayList();\n\t  Item item1 = new Item(\"computer\",2500);\n\t  Item item2 = new Item(\"chair\",100);\n\t  Item item3 = new Item(\"table\",200);\n\t \n\t  list.add(item1);\n\t  list.add(item2);\n\t  list.add(item3);\n\t \n\t  return new ItemList(list);\n\t}\n\n返回的数据将依照下面的格式：\n\n\t{xtypo_code}\n\t{\"listing\":{\"items\":[{\"description\":{\"$\":\"computer\"},\"price\":{\"$\":\"2500\"}},{\"description\":{\"$\":\"chair\"},\"price\":{\"$\":\"100\"}},{\"description\":{\"$\":\"table\"},\"price\":{\"$\":\"200\"}}]}}    \n\t{/xtypo_code}\n\n你可以使用下面的ajax客户端来调用这个json服务：\n\n\t<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n\t\"http://www.w3.org/TR/html4/loose.dtd\">\n\t<html>\n    \t<head>\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n            <script type=\"text/javascript\">\n\t\t\t\tfunction createXHR() {\n\t\t\t\t    var request = false;\n\t\t\t\t    try {\n\t\t\t\t        request = new ActiveXObject('Msxml2.XMLHTTP');\n\t\t\t\t    } catch (err2) {\n\t\t\t\t        try {\n\t\t\t\t            request = new ActiveXObject('Microsoft.XMLHTTP');\n\t\t\t\t        } catch (err3) {\n\t\t\t\t            try {\n\t\t\t\t                request = new XMLHttpRequest();\n\t\t\t\t            } catch (err1) {\n\t\t\t\t                request = false;\n\t\t\t\t            }\n\t\t\t\t        }\n\t\t\t\t    }\n\t\t\t\t    return request;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tfunction loadJSON(fname) {\n\t\t\t\t    var xhr = createXHR();\n\t\t\t\t    xhr.open(\"GET\", fname, true);\n\t\t\t\t    xhr.onreadystatechange = function() {\n\t\t\t\t        if (xhr.readyState == 4) {\n\t\t\t\t            if (xhr.status != 404) {\n\t\t\t\t                var data = eval(\"(\" + xhr.responseText + \")\");\n\t\t\t\t                document.getElementById(\"zone\").innerHTML = \"<h2>Items:</h2>\";\n\t\t\t\t                for (i = 0; i < 3; i++) {\n\t\t\t\t                    document.getElementById(\"zone\").innerHTML += data.listing.items[i].description + ', price <i>' + data.listing.items[i].price + \"</i><br/>\";\n\t\t\t\t                }\n\t\t\t\t            } else {\n\t\t\t\t                document.getElementById(\"zone\").innerHTML = fname + \" not found\";\n\t\t\t\t            }\n\t\t\t\t        }\n\t\t\t\t    }\n\t\t\t\t    xhr.send(null);\n\t\t\t\t}\n            </script>\n\t\t\t<title>Ajax Get JSON Demo</title>\n\t\t</head>\n\n\t    <body bgcolor=\"#FFFFFF\">\n\t        <p>\n\t            <font size=\"+3\">Ajax JSON/JAXB Demo</font>\n\t        </p>\n\t        <hr>\n\t            <FORM name=\"ajax\" method=\"POST\" action=\"\">\n\t                <p>\n\t                    <INPUT type=\"BUTTON\" value=\" Click to load the JSON file \"\n\t                        ONCLICK=\"loadJSON('resteasy/tutorial/items')\">\n\t                </p>\n\t \n\t            </FORM>\n\t \n\t            <div id=\"zone\"></div>\n\t \n\t    </body>\n\t</html>       \n\n注意上面javascript部分，它负责从json中拿到数据并放到“zone”DIV中。\n\n\tdocument.getElementById(\"zone\").innerHTML += data.listing.items[i].description + ', price <i>' + data.listing.items[i].price + \"</i><br/>\";\n\n可以阅读这个指南的第二部分：[RESTEasy web parameters handling](http://www.mastertheboss.com/resteasy/resteasy-tutorial-part-two-web-parameters)。","source":"_posts/看看RESTEasy.md","raw":"title: RESTEasy指南\ndate: 2015-03-10 15:54:30\ntags:\n- rest\n- dubbox\n- xml\n- json\n\ncategories: j2ee\n---\n\n由于dubbox的这个[问题](https://github.com/dangdangdotcom/dubbox/issues/30)，我决定先了解一下这个框架。为了快速认识RESTEasy，我决定翻译一篇看似还不错的[文章](http://www.mastertheboss.com/jboss-frameworks/resteasy/resteasy-tutorial)。下面就开始，不过我英文能力确实不如我的中文能力，请大家见谅。\n<!-- more -->\n\n\n---\n\nRESTEasy是一个实现了JAX-RS规范的轻量实现，该规范是针对基于http协议的RESTful Web Service而提供标准的JAVA API定义。这篇指南我们来手把手演示如何使用Resteasy来创建一些简单的RESTful Web Service。\n\n#安装RESTEasy\n---\n根据你所使用的不同版本的JBoss，安装RESTEasy需要不同的步骤。\n\n##JBoss 6/7\n\n在此版本下安装RESTEasy你不需要下载任何包，RESTEasy类已经内嵌在server中。应用服务器会自动发现导出成RESTful的服务资源。\n\n更多关于RESTEasy和JBoss 7的例子可以看[这里](http://www.mastertheboss.com/resteasy/restful-web-services-on-jboss-as-7)。\n\n你唯一需要做的只是在`web.xml`中插入正确的命名空间：\n\n\t<web-app version=\"3.0\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\">\n \n\t</web-app>\n\n##旧JBoss版本\n\n如果你工作在旧的JBoss版本下，安装RESTEasy你只需要做下面几步：\n\n###1.下载RESTEasy\n\n你需要先从[这里](http://sourceforge.net/projects/resteasy/files/Resteasy%20JAX-RS/)下载最新的RESTEasy稳定版。\n\n###2.把RESTEasy类加入你的web应用\n\n![](http://www.mastertheboss.com/images/stories/ws/resteasy-libs.PNG)\n\n###3.定义listenser和bootstrap\n\n在`web.xml`中添加下面的配置：\n\n\t<?xml version=\"1.0\"?>\n\t<!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\"\n\t\"http://java.sun.com/dtd/web-app_2_3.dtd\">\n\t<web-app>\n\t    <display-name>RestEasy sample Web Application</display-name>\n\t \n\t    <listener>\n\t        <listener-class>\n\t            org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap\n\t        </listener-class>\n\t    </listener>\n\t \n\t    <servlet>\n\t        <servlet-name>Resteasy</servlet-name>\n\t        <servlet-class>\n\t            org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher\n\t        </servlet-class>\n\t        <init-param>\n\t            <param-name>javax.ws.rs.Application</param-name>\n\t            <param-value>sample.HelloWorldApplication</param-value>\n\t        </init-param>\n\t    </servlet>\n\t \n\t    <servlet-mapping>\n\t        <servlet-name>Resteasy</servlet-name>\n\t        <url-pattern>/*</url-pattern>\n\t    </servlet-mapping>\n\t \n\t</web-app>\n\n**org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap**类是一个**ServletContextListener**，它负责配置实例化 ResteasyProviderFactory 和 Registry。\n\n然后，你还需要设置 **javax.ws.rs.core.Application** 参数，赋值一个被用于提供给你的应用去作为所有JAX-RS的根资源和提供者的入口单例实现（工厂模式）。不过在JBoss 6-M4或更高版本的环境下可以省略这个设置，因为在你部署应用时应用服务器已经帮你自动处理过了。\n\n最终你还需要指定一个url模式，用于RESTEasy来识别对应服务，如上面的配置例子，`/*`表示所有资源都会被RESTEasy servlet匹配。\n\n###4.创建一个单例类\n\n现在，我们来创建一个单例类，该类就是前面提到的 **javax.ws.rs.core.Application** 所需要的实现：\n\n\tpackage sample;\n\t \n\timport java.util.HashSet;\n\timport java.util.Set;\n\timport javax.ws.rs.core.Application;\n\t \n\timport sample.HelloWorld;\n\t \n\tpublic class HelloWorldApplication extends Application\n\t{\n\t    private Set<Object> singletons = new HashSet();\n\t    private Set<Class<?>> empty = new HashSet();\n\t \n\t    public HelloWorldApplication() {\n\t        // 把你的rest资源添加到这个属性中\n\t        this.singletons.add(new HelloWorld());\n\t    }\n\t \n\t    public Set<Class<?>> getClasses()\n\t    {\n\t        return this.empty;\n\t    }\n\t \n\t    public Set<Object> getSingletons()\n\t    {\n\t        return this.singletons;\n\t    }\n\t}\n\n在启动时上面声明的这个类会被用于初始化你想提供的RESTful服务，在这个例子中，我们加了一个 HelloWorld 服务。\n\n####资源的自动发现\n\n如果你更希望让RESTEasy自动去发现你的资源，而不是像刚才那样手动添加一个单例bean来完成这个目的，你可以在`web.xml`中添加下面的配置：\n\n\t<context-param>\n\t  <param-name>resteasy.scan</param-name>\n\t  <param-value>true</param-value>\n\t</context-param>\n\t<context-param>\n\t  <param-name>resteasy.servlet.mapping.prefix</param-name>\n\t  <param-value>/</param-value>\n\t</context-param>\n\n\n#创建你的第一个RESTful服务\n\n基于REST风格的架构，一切都是资源。 资源可以通过http提供的通用接口（POST,GET,PUT,DELETE）来操作。所有资源都应该支持这些通用接口，并且资源都应该有一个全局唯一的ID（通常指的就是URL）。\n\n在我们的第一个例子里，我们创建一个RESTful服务，每当它被以get方式访问请求时，会返回一个字符串：\n\n\tpackage sample;\n \n\timport javax.ws.rs.*;\n\t \n\t@Path(\"tutorial\")\n\tpublic class HelloWorld\n\t{\n\t    @GET\n\t    @Path(\"helloworld\")\n\t    public String helloworld() {\n\t        return \"Hello World!\";\n\t    }\n\t}\n\n在类上添加的那个**@Path**注解的作用是指定了该资源的统一URL前缀，而方法上的**@Path**注解则是定义了更具体的某一个资源操作。（译者：原文中的“action”违背了RESTful规范，资源url应该以名词为主）\n\n在这个例子中，如果你想调用我们的helloworld服务，你需要访问下面这个URL（我们假设应用打包为：RestEasy.war）:\n\n![](http://www.mastertheboss.com/images/stories/ws/resteasy-path.PNG)\n\n访问后在你的浏览器会显示“Hello World!”字符串。现在我们添加一个参数：\n\n\t@GET\n\t@Path(\"helloname/{name}\")\n\tpublic String hello(@PathParam(\"name\") final String name) {\n\t  return \"Hello \" +name;\n\t}\n\n现在，我们定义了一个“helloname”服务，它接受一个**{name}**参数。服务会从请求url中获取对应参数并返回，如下：\n\nhttp://localhost:8080/RestEasy/tutorial/helloname/francesco\n\n将返回：\n\nHello Francesco\n\n\n\n#使你的RESTEasy服务返回XML\n\n根据JAX-RS规范要求，RESTEasy支持多个JAXB注解，并提供JAXB Providers。\n\nRESTEasy会根据资源的参数类型或返回类型来选择不同的provider。当方法返回的对象的类声明加上了JAXB注解（@XmlRootEntity或@XmlType）时，RESTEasy会选择注解指定的JAXB Provider。\n\n举个例子，下面将返回xml：\n\n\t@GET\n\t@Path(\"item\")\n\t@Produces({\"application/xml\"})\n\tpublic Item getItem() {\n\t\tItem item = new Item(\"computer\",2500);\n\t\treturn item;\n\t} \n\n现在把这个方法加到你的 HelloWorld 服务中，然后调用这个服务（http://localhost:8080/RestEasy/tutorial/item），将返回下面这个xml：\n\n\t<item>\n\t   <description>computer</description>\n\t   <price>2500</price>\n\t</item>\n\n如果你需要返回一个数组，你可以简单的这么写：\n\n\t@GET\n\t@Path(\"itemArray\")\n\t@Produces({\"application/xml\"})\n\tpublic Item[]  getItem() {\n\t  Item item[] = new Item[2];\n\t  item[0] = new Item(\"computer\",2500);\n\t  item[1] = new Item(\"chair\",100);\n\t \n\t  return item;\n\t}\n\n调用后将会返回：\n\n\t<collection>\n\t   <item>\n\t     <description>computer</description>\n\t     <price>2500</price>\n\t   </item>\n\t   <item>\n\t     <description>computer</description>\n\t     <price>2500</price>\n\t   </item>\n\t</collection>\n\n有时候，你需要使用标准的java集合，这时候你就不得不提供一个包装类：\n\n\t@GET\n\t@Path(\"itemList\")\n\t@Produces({\"application/xml\"})\n\t public ItemList  getCollItems() {\n\t  ArrayList list = new ArrayList();\n\t  Item item1 = new Item(\"computer\",2500);\n\t  Item item2 = new Item(\"chair\",100);\n\t  Item item3 = new Item(\"table\",200);\n\t \n\t  list.add(item1);\n\t  list.add(item2);\n\t  list.add(item3);\n\t \n\t  return new ItemList(list);\n\t }\n\n我们来看一下 **ItemList** 包装类的定义：\n\n\tpackage sample;\n \n\timport javax.xml.bind.annotation.XmlRootElement;\n\timport javax.xml.bind.annotation.XmlElement;\n\timport java.util.List;\n\t \n\t \n\t@XmlRootElement(name=\"listing\")\n\tpublic class ItemList\n\t{\n\t    private List<Item> items;\n\t \n\t    public ItemList(){}\n\t \n\t    public ItemList(List<Item> items)\n\t    {\n\t        this.items = items;\n\t    }\n\t \n\t    @XmlElement(name=\"items\")\n\t    public List<Item> getItems()\n\t    {\n\t        return items;\n\t    }\n\t}\n\n返回的xml如下：\n\n\t<listing>\n \n\t  <items>\n\t    <description>computer</description>\n\t    <price>2500</price>\n\t  </items>\n\t\n\t  <items>\n\t    <description>chair</description>\n\t    <price>100</price>\n\t  </items>\n\t \n\t  <items>\n\t    <description>table</description>\n\t    <price>200</price>\n\t  </items>\n\t \n\t</listing>\n\n\n#使用JSON providers\n\n根据[文档](http://docs.jboss.org/resteasy/docs/2.0.0.GA/userguide/html/Built_in_JAXB_providers.html)，RESTEasy支持多个不同的providers去创建xml，而JSON是一个非常有用的返回集合的结构，它支持lists，sets，arrays，如下：\n\n\t@GET\n\t@Path(\"items\")\n\t@Produces(\"application/json\")\n\t@Mapped\n\tpublic ItemList  getJSONItems() {\n\t  ArrayList list = new ArrayList();\n\t  Item item1 = new Item(\"computer\",2500);\n\t  Item item2 = new Item(\"chair\",100);\n\t  Item item3 = new Item(\"table\",200);\n\t \n\t  list.add(item1);\n\t  list.add(item2);\n\t  list.add(item3);\n\t \n\t  return new ItemList(list);\n\t}\n\n返回的数据将依照下面的格式：\n\n\t{xtypo_code}\n\t{\"listing\":{\"items\":[{\"description\":{\"$\":\"computer\"},\"price\":{\"$\":\"2500\"}},{\"description\":{\"$\":\"chair\"},\"price\":{\"$\":\"100\"}},{\"description\":{\"$\":\"table\"},\"price\":{\"$\":\"200\"}}]}}    \n\t{/xtypo_code}\n\n你可以使用下面的ajax客户端来调用这个json服务：\n\n\t<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n\t\"http://www.w3.org/TR/html4/loose.dtd\">\n\t<html>\n    \t<head>\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n            <script type=\"text/javascript\">\n\t\t\t\tfunction createXHR() {\n\t\t\t\t    var request = false;\n\t\t\t\t    try {\n\t\t\t\t        request = new ActiveXObject('Msxml2.XMLHTTP');\n\t\t\t\t    } catch (err2) {\n\t\t\t\t        try {\n\t\t\t\t            request = new ActiveXObject('Microsoft.XMLHTTP');\n\t\t\t\t        } catch (err3) {\n\t\t\t\t            try {\n\t\t\t\t                request = new XMLHttpRequest();\n\t\t\t\t            } catch (err1) {\n\t\t\t\t                request = false;\n\t\t\t\t            }\n\t\t\t\t        }\n\t\t\t\t    }\n\t\t\t\t    return request;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tfunction loadJSON(fname) {\n\t\t\t\t    var xhr = createXHR();\n\t\t\t\t    xhr.open(\"GET\", fname, true);\n\t\t\t\t    xhr.onreadystatechange = function() {\n\t\t\t\t        if (xhr.readyState == 4) {\n\t\t\t\t            if (xhr.status != 404) {\n\t\t\t\t                var data = eval(\"(\" + xhr.responseText + \")\");\n\t\t\t\t                document.getElementById(\"zone\").innerHTML = \"<h2>Items:</h2>\";\n\t\t\t\t                for (i = 0; i < 3; i++) {\n\t\t\t\t                    document.getElementById(\"zone\").innerHTML += data.listing.items[i].description + ', price <i>' + data.listing.items[i].price + \"</i><br/>\";\n\t\t\t\t                }\n\t\t\t\t            } else {\n\t\t\t\t                document.getElementById(\"zone\").innerHTML = fname + \" not found\";\n\t\t\t\t            }\n\t\t\t\t        }\n\t\t\t\t    }\n\t\t\t\t    xhr.send(null);\n\t\t\t\t}\n            </script>\n\t\t\t<title>Ajax Get JSON Demo</title>\n\t\t</head>\n\n\t    <body bgcolor=\"#FFFFFF\">\n\t        <p>\n\t            <font size=\"+3\">Ajax JSON/JAXB Demo</font>\n\t        </p>\n\t        <hr>\n\t            <FORM name=\"ajax\" method=\"POST\" action=\"\">\n\t                <p>\n\t                    <INPUT type=\"BUTTON\" value=\" Click to load the JSON file \"\n\t                        ONCLICK=\"loadJSON('resteasy/tutorial/items')\">\n\t                </p>\n\t \n\t            </FORM>\n\t \n\t            <div id=\"zone\"></div>\n\t \n\t    </body>\n\t</html>       \n\n注意上面javascript部分，它负责从json中拿到数据并放到“zone”DIV中。\n\n\tdocument.getElementById(\"zone\").innerHTML += data.listing.items[i].description + ', price <i>' + data.listing.items[i].price + \"</i><br/>\";\n\n可以阅读这个指南的第二部分：[RESTEasy web parameters handling](http://www.mastertheboss.com/resteasy/resteasy-tutorial-part-two-web-parameters)。","slug":"看看RESTEasy","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ykf000ygtfycmvlkgmg","comments":1,"layout":"post","photos":[],"link":"","content":"<p>由于dubbox的这个<a href=\"https://github.com/dangdangdotcom/dubbox/issues/30\" target=\"_blank\" rel=\"external\">问题</a>，我决定先了解一下这个框架。为了快速认识RESTEasy，我决定翻译一篇看似还不错的<a href=\"http://www.mastertheboss.com/jboss-frameworks/resteasy/resteasy-tutorial\" target=\"_blank\" rel=\"external\">文章</a>。下面就开始，不过我英文能力确实不如我的中文能力，请大家见谅。<br><a id=\"more\"></a></p>\n<hr>\n<p>RESTEasy是一个实现了JAX-RS规范的轻量实现，该规范是针对基于http协议的RESTful Web Service而提供标准的JAVA API定义。这篇指南我们来手把手演示如何使用Resteasy来创建一些简单的RESTful Web Service。</p>\n<h2 id=\"安装RESTEasy\"><a href=\"#安装RESTEasy\" class=\"headerlink\" title=\"#安装RESTEasy\"></a>#安装RESTEasy</h2><p>根据你所使用的不同版本的JBoss，安装RESTEasy需要不同的步骤。</p>\n<p>##JBoss 6/7</p>\n<p>在此版本下安装RESTEasy你不需要下载任何包，RESTEasy类已经内嵌在server中。应用服务器会自动发现导出成RESTful的服务资源。</p>\n<p>更多关于RESTEasy和JBoss 7的例子可以看<a href=\"http://www.mastertheboss.com/resteasy/restful-web-services-on-jboss-as-7\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>你唯一需要做的只是在<code>web.xml</code>中插入正确的命名空间：</p>\n<pre><code>&lt;web-app version=&quot;3.0&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot;&gt;\n\n&lt;/web-app&gt;\n</code></pre><p>##旧JBoss版本</p>\n<p>如果你工作在旧的JBoss版本下，安装RESTEasy你只需要做下面几步：</p>\n<p>###1.下载RESTEasy</p>\n<p>你需要先从<a href=\"http://sourceforge.net/projects/resteasy/files/Resteasy%20JAX-RS/\" target=\"_blank\" rel=\"external\">这里</a>下载最新的RESTEasy稳定版。</p>\n<p>###2.把RESTEasy类加入你的web应用</p>\n<p><img src=\"http://www.mastertheboss.com/images/stories/ws/resteasy-libs.PNG\" alt=\"\"></p>\n<p>###3.定义listenser和bootstrap</p>\n<p>在<code>web.xml</code>中添加下面的配置：</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot;\n&quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot;&gt;\n&lt;web-app&gt;\n    &lt;display-name&gt;RestEasy sample Web Application&lt;/display-name&gt;\n\n    &lt;listener&gt;\n        &lt;listener-class&gt;\n            org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap\n        &lt;/listener-class&gt;\n    &lt;/listener&gt;\n\n    &lt;servlet&gt;\n        &lt;servlet-name&gt;Resteasy&lt;/servlet-name&gt;\n        &lt;servlet-class&gt;\n            org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher\n        &lt;/servlet-class&gt;\n        &lt;init-param&gt;\n            &lt;param-name&gt;javax.ws.rs.Application&lt;/param-name&gt;\n            &lt;param-value&gt;sample.HelloWorldApplication&lt;/param-value&gt;\n        &lt;/init-param&gt;\n    &lt;/servlet&gt;\n\n    &lt;servlet-mapping&gt;\n        &lt;servlet-name&gt;Resteasy&lt;/servlet-name&gt;\n        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n    &lt;/servlet-mapping&gt;\n\n&lt;/web-app&gt;\n</code></pre><p><strong>org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap</strong>类是一个<strong>ServletContextListener</strong>，它负责配置实例化 ResteasyProviderFactory 和 Registry。</p>\n<p>然后，你还需要设置 <strong>javax.ws.rs.core.Application</strong> 参数，赋值一个被用于提供给你的应用去作为所有JAX-RS的根资源和提供者的入口单例实现（工厂模式）。不过在JBoss 6-M4或更高版本的环境下可以省略这个设置，因为在你部署应用时应用服务器已经帮你自动处理过了。</p>\n<p>最终你还需要指定一个url模式，用于RESTEasy来识别对应服务，如上面的配置例子，<code>/*</code>表示所有资源都会被RESTEasy servlet匹配。</p>\n<p>###4.创建一个单例类</p>\n<p>现在，我们来创建一个单例类，该类就是前面提到的 <strong>javax.ws.rs.core.Application</strong> 所需要的实现：</p>\n<pre><code>package sample;\n\nimport java.util.HashSet;\nimport java.util.Set;\nimport javax.ws.rs.core.Application;\n\nimport sample.HelloWorld;\n\npublic class HelloWorldApplication extends Application\n{\n    private Set&lt;Object&gt; singletons = new HashSet();\n    private Set&lt;Class&lt;?&gt;&gt; empty = new HashSet();\n\n    public HelloWorldApplication() {\n        // 把你的rest资源添加到这个属性中\n        this.singletons.add(new HelloWorld());\n    }\n\n    public Set&lt;Class&lt;?&gt;&gt; getClasses()\n    {\n        return this.empty;\n    }\n\n    public Set&lt;Object&gt; getSingletons()\n    {\n        return this.singletons;\n    }\n}\n</code></pre><p>在启动时上面声明的这个类会被用于初始化你想提供的RESTful服务，在这个例子中，我们加了一个 HelloWorld 服务。</p>\n<p>####资源的自动发现</p>\n<p>如果你更希望让RESTEasy自动去发现你的资源，而不是像刚才那样手动添加一个单例bean来完成这个目的，你可以在<code>web.xml</code>中添加下面的配置：</p>\n<pre><code>&lt;context-param&gt;\n  &lt;param-name&gt;resteasy.scan&lt;/param-name&gt;\n  &lt;param-value&gt;true&lt;/param-value&gt;\n&lt;/context-param&gt;\n&lt;context-param&gt;\n  &lt;param-name&gt;resteasy.servlet.mapping.prefix&lt;/param-name&gt;\n  &lt;param-value&gt;/&lt;/param-value&gt;\n&lt;/context-param&gt;\n</code></pre><p>#创建你的第一个RESTful服务</p>\n<p>基于REST风格的架构，一切都是资源。 资源可以通过http提供的通用接口（POST,GET,PUT,DELETE）来操作。所有资源都应该支持这些通用接口，并且资源都应该有一个全局唯一的ID（通常指的就是URL）。</p>\n<p>在我们的第一个例子里，我们创建一个RESTful服务，每当它被以get方式访问请求时，会返回一个字符串：</p>\n<pre><code>package sample;\n\nimport javax.ws.rs.*;\n\n@Path(&quot;tutorial&quot;)\npublic class HelloWorld\n{\n    @GET\n    @Path(&quot;helloworld&quot;)\n    public String helloworld() {\n        return &quot;Hello World!&quot;;\n    }\n}\n</code></pre><p>在类上添加的那个<strong>@Path</strong>注解的作用是指定了该资源的统一URL前缀，而方法上的<strong>@Path</strong>注解则是定义了更具体的某一个资源操作。（译者：原文中的“action”违背了RESTful规范，资源url应该以名词为主）</p>\n<p>在这个例子中，如果你想调用我们的helloworld服务，你需要访问下面这个URL（我们假设应用打包为：RestEasy.war）:</p>\n<p><img src=\"http://www.mastertheboss.com/images/stories/ws/resteasy-path.PNG\" alt=\"\"></p>\n<p>访问后在你的浏览器会显示“Hello World!”字符串。现在我们添加一个参数：</p>\n<pre><code>@GET\n@Path(&quot;helloname/{name}&quot;)\npublic String hello(@PathParam(&quot;name&quot;) final String name) {\n  return &quot;Hello &quot; +name;\n}\n</code></pre><p>现在，我们定义了一个“helloname”服务，它接受一个<strong>{name}</strong>参数。服务会从请求url中获取对应参数并返回，如下：</p>\n<p><a href=\"http://localhost:8080/RestEasy/tutorial/helloname/francesco\" target=\"_blank\" rel=\"external\">http://localhost:8080/RestEasy/tutorial/helloname/francesco</a></p>\n<p>将返回：</p>\n<p>Hello Francesco</p>\n<p>#使你的RESTEasy服务返回XML</p>\n<p>根据JAX-RS规范要求，RESTEasy支持多个JAXB注解，并提供JAXB Providers。</p>\n<p>RESTEasy会根据资源的参数类型或返回类型来选择不同的provider。当方法返回的对象的类声明加上了JAXB注解（@XmlRootEntity或@XmlType）时，RESTEasy会选择注解指定的JAXB Provider。</p>\n<p>举个例子，下面将返回xml：</p>\n<pre><code>@GET\n@Path(&quot;item&quot;)\n@Produces({&quot;application/xml&quot;})\npublic Item getItem() {\n    Item item = new Item(&quot;computer&quot;,2500);\n    return item;\n} \n</code></pre><p>现在把这个方法加到你的 HelloWorld 服务中，然后调用这个服务（<a href=\"http://localhost:8080/RestEasy/tutorial/item），将返回下面这个xml：\" target=\"_blank\" rel=\"external\">http://localhost:8080/RestEasy/tutorial/item），将返回下面这个xml：</a></p>\n<pre><code>&lt;item&gt;\n   &lt;description&gt;computer&lt;/description&gt;\n   &lt;price&gt;2500&lt;/price&gt;\n&lt;/item&gt;\n</code></pre><p>如果你需要返回一个数组，你可以简单的这么写：</p>\n<pre><code>@GET\n@Path(&quot;itemArray&quot;)\n@Produces({&quot;application/xml&quot;})\npublic Item[]  getItem() {\n  Item item[] = new Item[2];\n  item[0] = new Item(&quot;computer&quot;,2500);\n  item[1] = new Item(&quot;chair&quot;,100);\n\n  return item;\n}\n</code></pre><p>调用后将会返回：</p>\n<pre><code>&lt;collection&gt;\n   &lt;item&gt;\n     &lt;description&gt;computer&lt;/description&gt;\n     &lt;price&gt;2500&lt;/price&gt;\n   &lt;/item&gt;\n   &lt;item&gt;\n     &lt;description&gt;computer&lt;/description&gt;\n     &lt;price&gt;2500&lt;/price&gt;\n   &lt;/item&gt;\n&lt;/collection&gt;\n</code></pre><p>有时候，你需要使用标准的java集合，这时候你就不得不提供一个包装类：</p>\n<pre><code>@GET\n@Path(&quot;itemList&quot;)\n@Produces({&quot;application/xml&quot;})\n public ItemList  getCollItems() {\n  ArrayList list = new ArrayList();\n  Item item1 = new Item(&quot;computer&quot;,2500);\n  Item item2 = new Item(&quot;chair&quot;,100);\n  Item item3 = new Item(&quot;table&quot;,200);\n\n  list.add(item1);\n  list.add(item2);\n  list.add(item3);\n\n  return new ItemList(list);\n }\n</code></pre><p>我们来看一下 <strong>ItemList</strong> 包装类的定义：</p>\n<pre><code>package sample;\n\nimport javax.xml.bind.annotation.XmlRootElement;\nimport javax.xml.bind.annotation.XmlElement;\nimport java.util.List;\n\n\n@XmlRootElement(name=&quot;listing&quot;)\npublic class ItemList\n{\n    private List&lt;Item&gt; items;\n\n    public ItemList(){}\n\n    public ItemList(List&lt;Item&gt; items)\n    {\n        this.items = items;\n    }\n\n    @XmlElement(name=&quot;items&quot;)\n    public List&lt;Item&gt; getItems()\n    {\n        return items;\n    }\n}\n</code></pre><p>返回的xml如下：</p>\n<pre><code>&lt;listing&gt;\n\n  &lt;items&gt;\n    &lt;description&gt;computer&lt;/description&gt;\n    &lt;price&gt;2500&lt;/price&gt;\n  &lt;/items&gt;\n\n  &lt;items&gt;\n    &lt;description&gt;chair&lt;/description&gt;\n    &lt;price&gt;100&lt;/price&gt;\n  &lt;/items&gt;\n\n  &lt;items&gt;\n    &lt;description&gt;table&lt;/description&gt;\n    &lt;price&gt;200&lt;/price&gt;\n  &lt;/items&gt;\n\n&lt;/listing&gt;\n</code></pre><p>#使用JSON providers</p>\n<p>根据<a href=\"http://docs.jboss.org/resteasy/docs/2.0.0.GA/userguide/html/Built_in_JAXB_providers.html\" target=\"_blank\" rel=\"external\">文档</a>，RESTEasy支持多个不同的providers去创建xml，而JSON是一个非常有用的返回集合的结构，它支持lists，sets，arrays，如下：</p>\n<pre><code>@GET\n@Path(&quot;items&quot;)\n@Produces(&quot;application/json&quot;)\n@Mapped\npublic ItemList  getJSONItems() {\n  ArrayList list = new ArrayList();\n  Item item1 = new Item(&quot;computer&quot;,2500);\n  Item item2 = new Item(&quot;chair&quot;,100);\n  Item item3 = new Item(&quot;table&quot;,200);\n\n  list.add(item1);\n  list.add(item2);\n  list.add(item3);\n\n  return new ItemList(list);\n}\n</code></pre><p>返回的数据将依照下面的格式：</p>\n<pre><code>{xtypo_code}\n{&quot;listing&quot;:{&quot;items&quot;:[{&quot;description&quot;:{&quot;$&quot;:&quot;computer&quot;},&quot;price&quot;:{&quot;$&quot;:&quot;2500&quot;}},{&quot;description&quot;:{&quot;$&quot;:&quot;chair&quot;},&quot;price&quot;:{&quot;$&quot;:&quot;100&quot;}},{&quot;description&quot;:{&quot;$&quot;:&quot;table&quot;},&quot;price&quot;:{&quot;$&quot;:&quot;200&quot;}}]}}    \n{/xtypo_code}\n</code></pre><p>你可以使用下面的ajax客户端来调用这个json服务：</p>\n<pre><code>&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;\n&quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;\n&lt;html&gt;\n    &lt;head&gt;\n    &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;\n        &lt;script type=&quot;text/javascript&quot;&gt;\n            function createXHR() {\n                var request = false;\n                try {\n                    request = new ActiveXObject(&apos;Msxml2.XMLHTTP&apos;);\n                } catch (err2) {\n                    try {\n                        request = new ActiveXObject(&apos;Microsoft.XMLHTTP&apos;);\n                    } catch (err3) {\n                        try {\n                            request = new XMLHttpRequest();\n                        } catch (err1) {\n                            request = false;\n                        }\n                    }\n                }\n                return request;\n            }\n\n            function loadJSON(fname) {\n                var xhr = createXHR();\n                xhr.open(&quot;GET&quot;, fname, true);\n                xhr.onreadystatechange = function() {\n                    if (xhr.readyState == 4) {\n                        if (xhr.status != 404) {\n                            var data = eval(&quot;(&quot; + xhr.responseText + &quot;)&quot;);\n                            document.getElementById(&quot;zone&quot;).innerHTML = &quot;&lt;h2&gt;Items:&lt;/h2&gt;&quot;;\n                            for (i = 0; i &lt; 3; i++) {\n                                document.getElementById(&quot;zone&quot;).innerHTML += data.listing.items[i].description + &apos;, price &lt;i&gt;&apos; + data.listing.items[i].price + &quot;&lt;/i&gt;&lt;br/&gt;&quot;;\n                            }\n                        } else {\n                            document.getElementById(&quot;zone&quot;).innerHTML = fname + &quot; not found&quot;;\n                        }\n                    }\n                }\n                xhr.send(null);\n            }\n        &lt;/script&gt;\n        &lt;title&gt;Ajax Get JSON Demo&lt;/title&gt;\n    &lt;/head&gt;\n\n    &lt;body bgcolor=&quot;#FFFFFF&quot;&gt;\n        &lt;p&gt;\n            &lt;font size=&quot;+3&quot;&gt;Ajax JSON/JAXB Demo&lt;/font&gt;\n        &lt;/p&gt;\n        &lt;hr&gt;\n            &lt;FORM name=&quot;ajax&quot; method=&quot;POST&quot; action=&quot;&quot;&gt;\n                &lt;p&gt;\n                    &lt;INPUT type=&quot;BUTTON&quot; value=&quot; Click to load the JSON file &quot;\n                        ONCLICK=&quot;loadJSON(&apos;resteasy/tutorial/items&apos;)&quot;&gt;\n                &lt;/p&gt;\n\n            &lt;/FORM&gt;\n\n            &lt;div id=&quot;zone&quot;&gt;&lt;/div&gt;\n\n    &lt;/body&gt;\n&lt;/html&gt;       \n</code></pre><p>注意上面javascript部分，它负责从json中拿到数据并放到“zone”DIV中。</p>\n<pre><code>document.getElementById(&quot;zone&quot;).innerHTML += data.listing.items[i].description + &apos;, price &lt;i&gt;&apos; + data.listing.items[i].price + &quot;&lt;/i&gt;&lt;br/&gt;&quot;;\n</code></pre><p>可以阅读这个指南的第二部分：<a href=\"http://www.mastertheboss.com/resteasy/resteasy-tutorial-part-two-web-parameters\" target=\"_blank\" rel=\"external\">RESTEasy web parameters handling</a>。</p>\n","excerpt":"<p>由于dubbox的这个<a href=\"https://github.com/dangdangdotcom/dubbox/issues/30\">问题</a>，我决定先了解一下这个框架。为了快速认识RESTEasy，我决定翻译一篇看似还不错的<a href=\"http://www.mastertheboss.com/jboss-frameworks/resteasy/resteasy-tutorial\">文章</a>。下面就开始，不过我英文能力确实不如我的中文能力，请大家见谅。<br>","more":"</p>\n<hr>\n<p>RESTEasy是一个实现了JAX-RS规范的轻量实现，该规范是针对基于http协议的RESTful Web Service而提供标准的JAVA API定义。这篇指南我们来手把手演示如何使用Resteasy来创建一些简单的RESTful Web Service。</p>\n<h2 id=\"安装RESTEasy\"><a href=\"#安装RESTEasy\" class=\"headerlink\" title=\"#安装RESTEasy\"></a>#安装RESTEasy</h2><p>根据你所使用的不同版本的JBoss，安装RESTEasy需要不同的步骤。</p>\n<p>##JBoss 6/7</p>\n<p>在此版本下安装RESTEasy你不需要下载任何包，RESTEasy类已经内嵌在server中。应用服务器会自动发现导出成RESTful的服务资源。</p>\n<p>更多关于RESTEasy和JBoss 7的例子可以看<a href=\"http://www.mastertheboss.com/resteasy/restful-web-services-on-jboss-as-7\">这里</a>。</p>\n<p>你唯一需要做的只是在<code>web.xml</code>中插入正确的命名空间：</p>\n<pre><code>&lt;web-app version=&quot;3.0&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot;&gt;\n\n&lt;/web-app&gt;\n</code></pre><p>##旧JBoss版本</p>\n<p>如果你工作在旧的JBoss版本下，安装RESTEasy你只需要做下面几步：</p>\n<p>###1.下载RESTEasy</p>\n<p>你需要先从<a href=\"http://sourceforge.net/projects/resteasy/files/Resteasy%20JAX-RS/\">这里</a>下载最新的RESTEasy稳定版。</p>\n<p>###2.把RESTEasy类加入你的web应用</p>\n<p><img src=\"http://www.mastertheboss.com/images/stories/ws/resteasy-libs.PNG\" alt=\"\"></p>\n<p>###3.定义listenser和bootstrap</p>\n<p>在<code>web.xml</code>中添加下面的配置：</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot;\n&quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot;&gt;\n&lt;web-app&gt;\n    &lt;display-name&gt;RestEasy sample Web Application&lt;/display-name&gt;\n\n    &lt;listener&gt;\n        &lt;listener-class&gt;\n            org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap\n        &lt;/listener-class&gt;\n    &lt;/listener&gt;\n\n    &lt;servlet&gt;\n        &lt;servlet-name&gt;Resteasy&lt;/servlet-name&gt;\n        &lt;servlet-class&gt;\n            org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher\n        &lt;/servlet-class&gt;\n        &lt;init-param&gt;\n            &lt;param-name&gt;javax.ws.rs.Application&lt;/param-name&gt;\n            &lt;param-value&gt;sample.HelloWorldApplication&lt;/param-value&gt;\n        &lt;/init-param&gt;\n    &lt;/servlet&gt;\n\n    &lt;servlet-mapping&gt;\n        &lt;servlet-name&gt;Resteasy&lt;/servlet-name&gt;\n        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n    &lt;/servlet-mapping&gt;\n\n&lt;/web-app&gt;\n</code></pre><p><strong>org.jboss.resteasy.plugins.server.servlet.ResteasyBootstrap</strong>类是一个<strong>ServletContextListener</strong>，它负责配置实例化 ResteasyProviderFactory 和 Registry。</p>\n<p>然后，你还需要设置 <strong>javax.ws.rs.core.Application</strong> 参数，赋值一个被用于提供给你的应用去作为所有JAX-RS的根资源和提供者的入口单例实现（工厂模式）。不过在JBoss 6-M4或更高版本的环境下可以省略这个设置，因为在你部署应用时应用服务器已经帮你自动处理过了。</p>\n<p>最终你还需要指定一个url模式，用于RESTEasy来识别对应服务，如上面的配置例子，<code>/*</code>表示所有资源都会被RESTEasy servlet匹配。</p>\n<p>###4.创建一个单例类</p>\n<p>现在，我们来创建一个单例类，该类就是前面提到的 <strong>javax.ws.rs.core.Application</strong> 所需要的实现：</p>\n<pre><code>package sample;\n\nimport java.util.HashSet;\nimport java.util.Set;\nimport javax.ws.rs.core.Application;\n\nimport sample.HelloWorld;\n\npublic class HelloWorldApplication extends Application\n{\n    private Set&lt;Object&gt; singletons = new HashSet();\n    private Set&lt;Class&lt;?&gt;&gt; empty = new HashSet();\n\n    public HelloWorldApplication() {\n        // 把你的rest资源添加到这个属性中\n        this.singletons.add(new HelloWorld());\n    }\n\n    public Set&lt;Class&lt;?&gt;&gt; getClasses()\n    {\n        return this.empty;\n    }\n\n    public Set&lt;Object&gt; getSingletons()\n    {\n        return this.singletons;\n    }\n}\n</code></pre><p>在启动时上面声明的这个类会被用于初始化你想提供的RESTful服务，在这个例子中，我们加了一个 HelloWorld 服务。</p>\n<p>####资源的自动发现</p>\n<p>如果你更希望让RESTEasy自动去发现你的资源，而不是像刚才那样手动添加一个单例bean来完成这个目的，你可以在<code>web.xml</code>中添加下面的配置：</p>\n<pre><code>&lt;context-param&gt;\n  &lt;param-name&gt;resteasy.scan&lt;/param-name&gt;\n  &lt;param-value&gt;true&lt;/param-value&gt;\n&lt;/context-param&gt;\n&lt;context-param&gt;\n  &lt;param-name&gt;resteasy.servlet.mapping.prefix&lt;/param-name&gt;\n  &lt;param-value&gt;/&lt;/param-value&gt;\n&lt;/context-param&gt;\n</code></pre><p>#创建你的第一个RESTful服务</p>\n<p>基于REST风格的架构，一切都是资源。 资源可以通过http提供的通用接口（POST,GET,PUT,DELETE）来操作。所有资源都应该支持这些通用接口，并且资源都应该有一个全局唯一的ID（通常指的就是URL）。</p>\n<p>在我们的第一个例子里，我们创建一个RESTful服务，每当它被以get方式访问请求时，会返回一个字符串：</p>\n<pre><code>package sample;\n\nimport javax.ws.rs.*;\n\n@Path(&quot;tutorial&quot;)\npublic class HelloWorld\n{\n    @GET\n    @Path(&quot;helloworld&quot;)\n    public String helloworld() {\n        return &quot;Hello World!&quot;;\n    }\n}\n</code></pre><p>在类上添加的那个<strong>@Path</strong>注解的作用是指定了该资源的统一URL前缀，而方法上的<strong>@Path</strong>注解则是定义了更具体的某一个资源操作。（译者：原文中的“action”违背了RESTful规范，资源url应该以名词为主）</p>\n<p>在这个例子中，如果你想调用我们的helloworld服务，你需要访问下面这个URL（我们假设应用打包为：RestEasy.war）:</p>\n<p><img src=\"http://www.mastertheboss.com/images/stories/ws/resteasy-path.PNG\" alt=\"\"></p>\n<p>访问后在你的浏览器会显示“Hello World!”字符串。现在我们添加一个参数：</p>\n<pre><code>@GET\n@Path(&quot;helloname/{name}&quot;)\npublic String hello(@PathParam(&quot;name&quot;) final String name) {\n  return &quot;Hello &quot; +name;\n}\n</code></pre><p>现在，我们定义了一个“helloname”服务，它接受一个<strong>{name}</strong>参数。服务会从请求url中获取对应参数并返回，如下：</p>\n<p><a href=\"http://localhost:8080/RestEasy/tutorial/helloname/francesco\">http://localhost:8080/RestEasy/tutorial/helloname/francesco</a></p>\n<p>将返回：</p>\n<p>Hello Francesco</p>\n<p>#使你的RESTEasy服务返回XML</p>\n<p>根据JAX-RS规范要求，RESTEasy支持多个JAXB注解，并提供JAXB Providers。</p>\n<p>RESTEasy会根据资源的参数类型或返回类型来选择不同的provider。当方法返回的对象的类声明加上了JAXB注解（@XmlRootEntity或@XmlType）时，RESTEasy会选择注解指定的JAXB Provider。</p>\n<p>举个例子，下面将返回xml：</p>\n<pre><code>@GET\n@Path(&quot;item&quot;)\n@Produces({&quot;application/xml&quot;})\npublic Item getItem() {\n    Item item = new Item(&quot;computer&quot;,2500);\n    return item;\n} \n</code></pre><p>现在把这个方法加到你的 HelloWorld 服务中，然后调用这个服务（<a href=\"http://localhost:8080/RestEasy/tutorial/item），将返回下面这个xml：\">http://localhost:8080/RestEasy/tutorial/item），将返回下面这个xml：</a></p>\n<pre><code>&lt;item&gt;\n   &lt;description&gt;computer&lt;/description&gt;\n   &lt;price&gt;2500&lt;/price&gt;\n&lt;/item&gt;\n</code></pre><p>如果你需要返回一个数组，你可以简单的这么写：</p>\n<pre><code>@GET\n@Path(&quot;itemArray&quot;)\n@Produces({&quot;application/xml&quot;})\npublic Item[]  getItem() {\n  Item item[] = new Item[2];\n  item[0] = new Item(&quot;computer&quot;,2500);\n  item[1] = new Item(&quot;chair&quot;,100);\n\n  return item;\n}\n</code></pre><p>调用后将会返回：</p>\n<pre><code>&lt;collection&gt;\n   &lt;item&gt;\n     &lt;description&gt;computer&lt;/description&gt;\n     &lt;price&gt;2500&lt;/price&gt;\n   &lt;/item&gt;\n   &lt;item&gt;\n     &lt;description&gt;computer&lt;/description&gt;\n     &lt;price&gt;2500&lt;/price&gt;\n   &lt;/item&gt;\n&lt;/collection&gt;\n</code></pre><p>有时候，你需要使用标准的java集合，这时候你就不得不提供一个包装类：</p>\n<pre><code>@GET\n@Path(&quot;itemList&quot;)\n@Produces({&quot;application/xml&quot;})\n public ItemList  getCollItems() {\n  ArrayList list = new ArrayList();\n  Item item1 = new Item(&quot;computer&quot;,2500);\n  Item item2 = new Item(&quot;chair&quot;,100);\n  Item item3 = new Item(&quot;table&quot;,200);\n\n  list.add(item1);\n  list.add(item2);\n  list.add(item3);\n\n  return new ItemList(list);\n }\n</code></pre><p>我们来看一下 <strong>ItemList</strong> 包装类的定义：</p>\n<pre><code>package sample;\n\nimport javax.xml.bind.annotation.XmlRootElement;\nimport javax.xml.bind.annotation.XmlElement;\nimport java.util.List;\n\n\n@XmlRootElement(name=&quot;listing&quot;)\npublic class ItemList\n{\n    private List&lt;Item&gt; items;\n\n    public ItemList(){}\n\n    public ItemList(List&lt;Item&gt; items)\n    {\n        this.items = items;\n    }\n\n    @XmlElement(name=&quot;items&quot;)\n    public List&lt;Item&gt; getItems()\n    {\n        return items;\n    }\n}\n</code></pre><p>返回的xml如下：</p>\n<pre><code>&lt;listing&gt;\n\n  &lt;items&gt;\n    &lt;description&gt;computer&lt;/description&gt;\n    &lt;price&gt;2500&lt;/price&gt;\n  &lt;/items&gt;\n\n  &lt;items&gt;\n    &lt;description&gt;chair&lt;/description&gt;\n    &lt;price&gt;100&lt;/price&gt;\n  &lt;/items&gt;\n\n  &lt;items&gt;\n    &lt;description&gt;table&lt;/description&gt;\n    &lt;price&gt;200&lt;/price&gt;\n  &lt;/items&gt;\n\n&lt;/listing&gt;\n</code></pre><p>#使用JSON providers</p>\n<p>根据<a href=\"http://docs.jboss.org/resteasy/docs/2.0.0.GA/userguide/html/Built_in_JAXB_providers.html\">文档</a>，RESTEasy支持多个不同的providers去创建xml，而JSON是一个非常有用的返回集合的结构，它支持lists，sets，arrays，如下：</p>\n<pre><code>@GET\n@Path(&quot;items&quot;)\n@Produces(&quot;application/json&quot;)\n@Mapped\npublic ItemList  getJSONItems() {\n  ArrayList list = new ArrayList();\n  Item item1 = new Item(&quot;computer&quot;,2500);\n  Item item2 = new Item(&quot;chair&quot;,100);\n  Item item3 = new Item(&quot;table&quot;,200);\n\n  list.add(item1);\n  list.add(item2);\n  list.add(item3);\n\n  return new ItemList(list);\n}\n</code></pre><p>返回的数据将依照下面的格式：</p>\n<pre><code>{xtypo_code}\n{&quot;listing&quot;:{&quot;items&quot;:[{&quot;description&quot;:{&quot;$&quot;:&quot;computer&quot;},&quot;price&quot;:{&quot;$&quot;:&quot;2500&quot;}},{&quot;description&quot;:{&quot;$&quot;:&quot;chair&quot;},&quot;price&quot;:{&quot;$&quot;:&quot;100&quot;}},{&quot;description&quot;:{&quot;$&quot;:&quot;table&quot;},&quot;price&quot;:{&quot;$&quot;:&quot;200&quot;}}]}}    \n{/xtypo_code}\n</code></pre><p>你可以使用下面的ajax客户端来调用这个json服务：</p>\n<pre><code>&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;\n&quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;\n&lt;html&gt;\n    &lt;head&gt;\n    &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;\n        &lt;script type=&quot;text/javascript&quot;&gt;\n            function createXHR() {\n                var request = false;\n                try {\n                    request = new ActiveXObject(&apos;Msxml2.XMLHTTP&apos;);\n                } catch (err2) {\n                    try {\n                        request = new ActiveXObject(&apos;Microsoft.XMLHTTP&apos;);\n                    } catch (err3) {\n                        try {\n                            request = new XMLHttpRequest();\n                        } catch (err1) {\n                            request = false;\n                        }\n                    }\n                }\n                return request;\n            }\n\n            function loadJSON(fname) {\n                var xhr = createXHR();\n                xhr.open(&quot;GET&quot;, fname, true);\n                xhr.onreadystatechange = function() {\n                    if (xhr.readyState == 4) {\n                        if (xhr.status != 404) {\n                            var data = eval(&quot;(&quot; + xhr.responseText + &quot;)&quot;);\n                            document.getElementById(&quot;zone&quot;).innerHTML = &quot;&lt;h2&gt;Items:&lt;/h2&gt;&quot;;\n                            for (i = 0; i &lt; 3; i++) {\n                                document.getElementById(&quot;zone&quot;).innerHTML += data.listing.items[i].description + &apos;, price &lt;i&gt;&apos; + data.listing.items[i].price + &quot;&lt;/i&gt;&lt;br/&gt;&quot;;\n                            }\n                        } else {\n                            document.getElementById(&quot;zone&quot;).innerHTML = fname + &quot; not found&quot;;\n                        }\n                    }\n                }\n                xhr.send(null);\n            }\n        &lt;/script&gt;\n        &lt;title&gt;Ajax Get JSON Demo&lt;/title&gt;\n    &lt;/head&gt;\n\n    &lt;body bgcolor=&quot;#FFFFFF&quot;&gt;\n        &lt;p&gt;\n            &lt;font size=&quot;+3&quot;&gt;Ajax JSON/JAXB Demo&lt;/font&gt;\n        &lt;/p&gt;\n        &lt;hr&gt;\n            &lt;FORM name=&quot;ajax&quot; method=&quot;POST&quot; action=&quot;&quot;&gt;\n                &lt;p&gt;\n                    &lt;INPUT type=&quot;BUTTON&quot; value=&quot; Click to load the JSON file &quot;\n                        ONCLICK=&quot;loadJSON(&apos;resteasy/tutorial/items&apos;)&quot;&gt;\n                &lt;/p&gt;\n\n            &lt;/FORM&gt;\n\n            &lt;div id=&quot;zone&quot;&gt;&lt;/div&gt;\n\n    &lt;/body&gt;\n&lt;/html&gt;       \n</code></pre><p>注意上面javascript部分，它负责从json中拿到数据并放到“zone”DIV中。</p>\n<pre><code>document.getElementById(&quot;zone&quot;).innerHTML += data.listing.items[i].description + &apos;, price &lt;i&gt;&apos; + data.listing.items[i].price + &quot;&lt;/i&gt;&lt;br/&gt;&quot;;\n</code></pre><p>可以阅读这个指南的第二部分：<a href=\"http://www.mastertheboss.com/resteasy/resteasy-tutorial-part-two-web-parameters\">RESTEasy web parameters handling</a>。</p>"},{"title":"用nodejs实现一个小小爬虫","date":"2014-06-05T03:37:12.000Z","_content":"\n呵呵，不要被题目给忽悠了啊，我并不具备开发一个足够智能的网络爬虫程序的能力，那我到底要做什么呢？\n\n其实是这样的，目前公司开发了一个门户类型的网站客户端，但是由于数据流比较复杂，性能非常不理想。要解决这个问题其实也不难，那就是加缓存层（计算机领域提速的万能方案就是缓存，不论是硬件还是软件）。当然，你可能还会提到：全站静态化（其实也是缓存的理念）。\n<!-- more -->\n后端开发增加缓存层，其实成本不高，很容易就可以把memcache或redis等内存性KV系统引入到当前项目中。一般情况下会设计为：**当用户第一次访问某个页面时，把相关数据存储到缓存中，以加速下一次请求的响应速度**。\n\n这里需要注意的是**第一次访问**，你大概知道我想说什么了吧？第一次访问的用户就不是亲娘养的了？，谁来保证他们的体验？\n\n我们姑且把这种方案叫做：**被动缓存**，那么如何使缓存更加的主动呢？最好是数据一旦发生CURD，就立刻映射到缓存层。这里面涉及到缓存颗粒度，缓存的键规则等细节问题，而且对于目前我们公司的项目而言，难度会更大，因为数据的CURD是发生在其他系统中，而这个门户网站客户端只有在访问时才需要与其他系统通信。\n\n那么如何快速的实现**主动缓存**呢？再回过头来看看文章标题，你应该猜到最终的解决方案了，对，用机器模拟请求，充当这“第一个用户”，姑且称为**伪主动缓存**吧~~\n\n好吧，说了这么多，总算到今天的主题了：写一个爬虫程序。\n我觉得还是有必要再多说一下场景，这里面涉及到具体需求，有助于思考和权衡！\n\n我们的这个爬虫需要从给定的入口页面开始出发，扫描该页面下所有的链接，并继续进行请求，就这样不停的爬下去。当然，如果检测到的链接和当前入口页面的域不同，则丢弃，毕竟我们是为了创建本站缓存而工作的。另外，我们也不需要爬完全部的链接，按照业界的统计，只需要为三级以内的页面创建缓存即可，什么叫三级以内？简单的说，就是从主页出发，三次跳转以内能达到的页面都算三级以内！这样既能最大程度保证用户体验，又可以尽可能的降低内存占用率，而且我们的爬虫程序也会更快的完成任务！何乐而不为？\n\n最后还要说的是，我们采用广度优先规则进行爬行（而不是搜索引擎用的深度优先），原因很简单，可以简化编程模型，并且个人认为更符合**伪主动缓存**的需求。\n\n开发语言\n---\n我选择使用nodejs，当然从文章题目上，你早已知道答案了！nodejs的编程模型可以有效降低该项目的开发难度（避免多线程模型和锁冲突），又最大程度的确保并发性能（毕竟这个项目是网络IO阻塞型），另外，它有很丰满的工具库供我们使用，这样会让开发成本降至最低。\n\n依赖库\n---\n1. `request`： 用于发起http请求，简化了操作api\n2. `htmlparser2`: 用于解析取得的html内容，方便抽取url\n3. `async`： 用于管理代码执行流程\n4. `redis`： 用于清空redis中的旧缓存（并不是爬虫程序所必须的）\n\n示意图\n---\n![](http://pic.yupoo.com/kazaff/DObSQL7k/XeJAN.png)\n\n看，很简单吧，加上nodejs的强大社区，该程序应该三两天就能做完~我会把相关代码放到[github](https://github.com/kazaff/spider)上，有兴趣的朋友可去看看。\n\n\n\n\n","source":"_posts/用nodejs实现一个小小爬虫.md","raw":"title: 用nodejs实现一个小小爬虫\ndate: 2014-06-05 11:37:12\ntags: \n- 缓存\n- 爬虫\ncategories: nodejs\n---\n\n呵呵，不要被题目给忽悠了啊，我并不具备开发一个足够智能的网络爬虫程序的能力，那我到底要做什么呢？\n\n其实是这样的，目前公司开发了一个门户类型的网站客户端，但是由于数据流比较复杂，性能非常不理想。要解决这个问题其实也不难，那就是加缓存层（计算机领域提速的万能方案就是缓存，不论是硬件还是软件）。当然，你可能还会提到：全站静态化（其实也是缓存的理念）。\n<!-- more -->\n后端开发增加缓存层，其实成本不高，很容易就可以把memcache或redis等内存性KV系统引入到当前项目中。一般情况下会设计为：**当用户第一次访问某个页面时，把相关数据存储到缓存中，以加速下一次请求的响应速度**。\n\n这里需要注意的是**第一次访问**，你大概知道我想说什么了吧？第一次访问的用户就不是亲娘养的了？，谁来保证他们的体验？\n\n我们姑且把这种方案叫做：**被动缓存**，那么如何使缓存更加的主动呢？最好是数据一旦发生CURD，就立刻映射到缓存层。这里面涉及到缓存颗粒度，缓存的键规则等细节问题，而且对于目前我们公司的项目而言，难度会更大，因为数据的CURD是发生在其他系统中，而这个门户网站客户端只有在访问时才需要与其他系统通信。\n\n那么如何快速的实现**主动缓存**呢？再回过头来看看文章标题，你应该猜到最终的解决方案了，对，用机器模拟请求，充当这“第一个用户”，姑且称为**伪主动缓存**吧~~\n\n好吧，说了这么多，总算到今天的主题了：写一个爬虫程序。\n我觉得还是有必要再多说一下场景，这里面涉及到具体需求，有助于思考和权衡！\n\n我们的这个爬虫需要从给定的入口页面开始出发，扫描该页面下所有的链接，并继续进行请求，就这样不停的爬下去。当然，如果检测到的链接和当前入口页面的域不同，则丢弃，毕竟我们是为了创建本站缓存而工作的。另外，我们也不需要爬完全部的链接，按照业界的统计，只需要为三级以内的页面创建缓存即可，什么叫三级以内？简单的说，就是从主页出发，三次跳转以内能达到的页面都算三级以内！这样既能最大程度保证用户体验，又可以尽可能的降低内存占用率，而且我们的爬虫程序也会更快的完成任务！何乐而不为？\n\n最后还要说的是，我们采用广度优先规则进行爬行（而不是搜索引擎用的深度优先），原因很简单，可以简化编程模型，并且个人认为更符合**伪主动缓存**的需求。\n\n开发语言\n---\n我选择使用nodejs，当然从文章题目上，你早已知道答案了！nodejs的编程模型可以有效降低该项目的开发难度（避免多线程模型和锁冲突），又最大程度的确保并发性能（毕竟这个项目是网络IO阻塞型），另外，它有很丰满的工具库供我们使用，这样会让开发成本降至最低。\n\n依赖库\n---\n1. `request`： 用于发起http请求，简化了操作api\n2. `htmlparser2`: 用于解析取得的html内容，方便抽取url\n3. `async`： 用于管理代码执行流程\n4. `redis`： 用于清空redis中的旧缓存（并不是爬虫程序所必须的）\n\n示意图\n---\n![](http://pic.yupoo.com/kazaff/DObSQL7k/XeJAN.png)\n\n看，很简单吧，加上nodejs的强大社区，该程序应该三两天就能做完~我会把相关代码放到[github](https://github.com/kazaff/spider)上，有兴趣的朋友可去看看。\n\n\n\n\n","slug":"用nodejs实现一个小小爬虫","published":1,"updated":"2016-05-14T07:46:20.000Z","_id":"cica18ykk0019gtfy85qqkz0a","comments":1,"layout":"post","photos":[],"link":"","content":"<p>呵呵，不要被题目给忽悠了啊，我并不具备开发一个足够智能的网络爬虫程序的能力，那我到底要做什么呢？</p>\n<p>其实是这样的，目前公司开发了一个门户类型的网站客户端，但是由于数据流比较复杂，性能非常不理想。要解决这个问题其实也不难，那就是加缓存层（计算机领域提速的万能方案就是缓存，不论是硬件还是软件）。当然，你可能还会提到：全站静态化（其实也是缓存的理念）。<br><a id=\"more\"></a><br>后端开发增加缓存层，其实成本不高，很容易就可以把memcache或redis等内存性KV系统引入到当前项目中。一般情况下会设计为：<strong>当用户第一次访问某个页面时，把相关数据存储到缓存中，以加速下一次请求的响应速度</strong>。</p>\n<p>这里需要注意的是<strong>第一次访问</strong>，你大概知道我想说什么了吧？第一次访问的用户就不是亲娘养的了？，谁来保证他们的体验？</p>\n<p>我们姑且把这种方案叫做：<strong>被动缓存</strong>，那么如何使缓存更加的主动呢？最好是数据一旦发生CURD，就立刻映射到缓存层。这里面涉及到缓存颗粒度，缓存的键规则等细节问题，而且对于目前我们公司的项目而言，难度会更大，因为数据的CURD是发生在其他系统中，而这个门户网站客户端只有在访问时才需要与其他系统通信。</p>\n<p>那么如何快速的实现<strong>主动缓存</strong>呢？再回过头来看看文章标题，你应该猜到最终的解决方案了，对，用机器模拟请求，充当这“第一个用户”，姑且称为<strong>伪主动缓存</strong>吧~~</p>\n<p>好吧，说了这么多，总算到今天的主题了：写一个爬虫程序。<br>我觉得还是有必要再多说一下场景，这里面涉及到具体需求，有助于思考和权衡！</p>\n<p>我们的这个爬虫需要从给定的入口页面开始出发，扫描该页面下所有的链接，并继续进行请求，就这样不停的爬下去。当然，如果检测到的链接和当前入口页面的域不同，则丢弃，毕竟我们是为了创建本站缓存而工作的。另外，我们也不需要爬完全部的链接，按照业界的统计，只需要为三级以内的页面创建缓存即可，什么叫三级以内？简单的说，就是从主页出发，三次跳转以内能达到的页面都算三级以内！这样既能最大程度保证用户体验，又可以尽可能的降低内存占用率，而且我们的爬虫程序也会更快的完成任务！何乐而不为？</p>\n<p>最后还要说的是，我们采用广度优先规则进行爬行（而不是搜索引擎用的深度优先），原因很简单，可以简化编程模型，并且个人认为更符合<strong>伪主动缓存</strong>的需求。</p>\n<h2 id=\"开发语言\"><a href=\"#开发语言\" class=\"headerlink\" title=\"开发语言\"></a>开发语言</h2><p>我选择使用nodejs，当然从文章题目上，你早已知道答案了！nodejs的编程模型可以有效降低该项目的开发难度（避免多线程模型和锁冲突），又最大程度的确保并发性能（毕竟这个项目是网络IO阻塞型），另外，它有很丰满的工具库供我们使用，这样会让开发成本降至最低。</p>\n<h2 id=\"依赖库\"><a href=\"#依赖库\" class=\"headerlink\" title=\"依赖库\"></a>依赖库</h2><ol>\n<li><code>request</code>： 用于发起http请求，简化了操作api</li>\n<li><code>htmlparser2</code>: 用于解析取得的html内容，方便抽取url</li>\n<li><code>async</code>： 用于管理代码执行流程</li>\n<li><code>redis</code>： 用于清空redis中的旧缓存（并不是爬虫程序所必须的）</li>\n</ol>\n<h2 id=\"示意图\"><a href=\"#示意图\" class=\"headerlink\" title=\"示意图\"></a>示意图</h2><p><img src=\"http://pic.yupoo.com/kazaff/DObSQL7k/XeJAN.png\" alt=\"\"></p>\n<p>看，很简单吧，加上nodejs的强大社区，该程序应该三两天就能做完~我会把相关代码放到<a href=\"https://github.com/kazaff/spider\" target=\"_blank\" rel=\"external\">github</a>上，有兴趣的朋友可去看看。</p>\n","excerpt":"<p>呵呵，不要被题目给忽悠了啊，我并不具备开发一个足够智能的网络爬虫程序的能力，那我到底要做什么呢？</p>\n<p>其实是这样的，目前公司开发了一个门户类型的网站客户端，但是由于数据流比较复杂，性能非常不理想。要解决这个问题其实也不难，那就是加缓存层（计算机领域提速的万能方案就是缓存，不论是硬件还是软件）。当然，你可能还会提到：全站静态化（其实也是缓存的理念）。<br>","more":"<br>后端开发增加缓存层，其实成本不高，很容易就可以把memcache或redis等内存性KV系统引入到当前项目中。一般情况下会设计为：<strong>当用户第一次访问某个页面时，把相关数据存储到缓存中，以加速下一次请求的响应速度</strong>。</p>\n<p>这里需要注意的是<strong>第一次访问</strong>，你大概知道我想说什么了吧？第一次访问的用户就不是亲娘养的了？，谁来保证他们的体验？</p>\n<p>我们姑且把这种方案叫做：<strong>被动缓存</strong>，那么如何使缓存更加的主动呢？最好是数据一旦发生CURD，就立刻映射到缓存层。这里面涉及到缓存颗粒度，缓存的键规则等细节问题，而且对于目前我们公司的项目而言，难度会更大，因为数据的CURD是发生在其他系统中，而这个门户网站客户端只有在访问时才需要与其他系统通信。</p>\n<p>那么如何快速的实现<strong>主动缓存</strong>呢？再回过头来看看文章标题，你应该猜到最终的解决方案了，对，用机器模拟请求，充当这“第一个用户”，姑且称为<strong>伪主动缓存</strong>吧~~</p>\n<p>好吧，说了这么多，总算到今天的主题了：写一个爬虫程序。<br>我觉得还是有必要再多说一下场景，这里面涉及到具体需求，有助于思考和权衡！</p>\n<p>我们的这个爬虫需要从给定的入口页面开始出发，扫描该页面下所有的链接，并继续进行请求，就这样不停的爬下去。当然，如果检测到的链接和当前入口页面的域不同，则丢弃，毕竟我们是为了创建本站缓存而工作的。另外，我们也不需要爬完全部的链接，按照业界的统计，只需要为三级以内的页面创建缓存即可，什么叫三级以内？简单的说，就是从主页出发，三次跳转以内能达到的页面都算三级以内！这样既能最大程度保证用户体验，又可以尽可能的降低内存占用率，而且我们的爬虫程序也会更快的完成任务！何乐而不为？</p>\n<p>最后还要说的是，我们采用广度优先规则进行爬行（而不是搜索引擎用的深度优先），原因很简单，可以简化编程模型，并且个人认为更符合<strong>伪主动缓存</strong>的需求。</p>\n<h2 id=\"开发语言\"><a href=\"#开发语言\" class=\"headerlink\" title=\"开发语言\"></a>开发语言</h2><p>我选择使用nodejs，当然从文章题目上，你早已知道答案了！nodejs的编程模型可以有效降低该项目的开发难度（避免多线程模型和锁冲突），又最大程度的确保并发性能（毕竟这个项目是网络IO阻塞型），另外，它有很丰满的工具库供我们使用，这样会让开发成本降至最低。</p>\n<h2 id=\"依赖库\"><a href=\"#依赖库\" class=\"headerlink\" title=\"依赖库\"></a>依赖库</h2><ol>\n<li><code>request</code>： 用于发起http请求，简化了操作api</li>\n<li><code>htmlparser2</code>: 用于解析取得的html内容，方便抽取url</li>\n<li><code>async</code>： 用于管理代码执行流程</li>\n<li><code>redis</code>： 用于清空redis中的旧缓存（并不是爬虫程序所必须的）</li>\n</ol>\n<h2 id=\"示意图\"><a href=\"#示意图\" class=\"headerlink\" title=\"示意图\"></a>示意图</h2><p><img src=\"http://pic.yupoo.com/kazaff/DObSQL7k/XeJAN.png\" alt=\"\"></p>\n<p>看，很简单吧，加上nodejs的强大社区，该程序应该三两天就能做完~我会把相关代码放到<a href=\"https://github.com/kazaff/spider\">github</a>上，有兴趣的朋友可去看看。</p>"},{"title":"是什么系列之Thrift","date":"2014-07-07T08:18:12.000Z","_content":"\n这次我们要科普的，是Thrift，它是Facebook的一个开源项目，定位为一个跨语言的远程服务调用框架。\n<!-- more -->\n目前流行的服务调用方式有很多种，例如基于SOAP消息格式的Web Service，基于JSON消息格式的RESTful服务等，其中所用到的数据传输格式包括XML，JSON等，然后XML相对体积太大，传输效率底，JSON体积小，但还不够完善。针对高并发，大数据量和多语言的需求，传输二进制格式的Thrift更有优势。\n\nThrift有一个代码生成器来对它所定义的IDL文件自动生成服务代码框架，用户只需要在其之上进行二次开发即可，对底层的RPC通信等都是透明的。目前它支持的语言有C++，Java，Python，PHP，Ruby，Erlang，Perl，Haskell，C#，Cocoa，Smalltalk，等。（妈蛋，真强悍啊！）\n\n现在看一个Thrift的IDL定义，Hello.thrift文件：\n\n\tnamespace java service.demo\n\tservice Hello{\n\t\tstring helloString(1:string para)\n\t\ti32 helloInt(1:i32 para)\n\t\tbool helloBoolean(1:bool para)\n\t\tvoid helloVoid()\n\t\tstring helloNull()\n\t}\n\n上面的这段代码定义了了服务Hello的5个方法，每个方法包含方法名，参数表和返回类型，每个参数包含参数序号，参数类型及参数名。使用Thrift工具编译Hello.thrift，就会生成响应的Hello.java文件，该文件包含了在Hello.thrift文件中描述的服务Hello的接口定义：Hello.Iface接口，以及服务调用的底层通信细节，包括客户端的调用逻辑Hello.Client以及服务器端的处理逻辑Hello.Processor，用于构建客户端和服务器端的功能。\n\n![](http://pic.yupoo.com/kazaff_v/DT5eHGLc/132ea.jpg)\n\n如图所示，图中黄色部分是用户实现的业务逻辑，褐色部分是根据Thrift定义的服务接口描述文件生成的客户端和服务器端代码框架，红色部分是根据Thrift文件生成代码实现数据的读写操作。红色部分以下是Thrift的传输体系、协议以及底层I/O通信，使用Thrift可以很方便的定义一个服务并且选择不同的传输协议和传输层而不用重新生成代码。\n\nThrift服务器包含用于绑定协议和传输层的基础架构，它提供阻塞、非阻塞、单线程和多线程的模式运行在服务器上，可以配合服务器/容器一起运行，可以和现有的J2EE服务器/Web容器无缝的结合。\n\n![](http://pic.yupoo.com/kazaff_v/DT5mKsO9/zTkIx.png)\n\n该图所示是HelloServiceServer启动的过程以及服务被客户端调用时，服务器的响应过程。从图中我们可以看到，程序调用了TThreadPoolServer的serve方法后，server进入阻塞监听状态，其阻塞在TServerSocket的accept方法上。当接收到来自客户端的消息后，服务器发起一个新线程处理这个消息请求，原线程再次进入阻塞状态。在新线程中，服务器通过TBinaryProtocol协议读取消息内容，调用HelloServiceImpl的helloVoid方法，并将结果写入helloVoid_result中传回客户端。\n\n![](http://pic.yupoo.com/kazaff_v/DT5qrcyO/VFbKS.png)\n\n该图所示是HelloServiceClient调用服务的过程以及接收到服务器端的返回值后处理结果的过程。从图中我们可以看到，程序调用了Hello.Client的helloVoid方法，在helloVoid方法中，通过send_helloVoid方法发送对服务的调用请求，通过recv_helloVoid方法接收服务处理请求后返回的结果。\n\n上述过程对应的代码如下：\n\n服务器端：\n\n\tpackage service.server; \n\timport org.apache.thrift.TProcessor; \n\timport org.apache.thrift.protocol.TBinaryProtocol; \n\timport org.apache.thrift.protocol.TBinaryProtocol.Factory; \n\timport org.apache.thrift.server.TServer; \n\timport org.apache.thrift.server.TThreadPoolServer; \n\timport org.apache.thrift.transport.TServerSocket; \n\timport org.apache.thrift.transport.TTransportException; \n\timport service.demo.Hello; \n\timport service.demo.HelloServiceImpl; \n\t\n\t public class HelloServiceServer { \n\t    /** \n\t     * 启动 Thrift 服务器\n\t     * @param args \n\t     */ \n\t    public static void main(String[] args) { \n\t        try { \n\t            // 设置服务端口为 7911 \n\t            TServerSocket serverTransport = new TServerSocket(7911); \n\t            // 设置协议工厂为 TBinaryProtocol.Factory \n\t            Factory proFactory = new TBinaryProtocol.Factory(); \n\t            // 关联处理器与 Hello 服务的实现\n\t            TProcessor processor = new Hello.Processor(new HelloServiceImpl()); \n\t            TServer server = new TThreadPoolServer(processor, serverTransport, \n\t                    proFactory); \n\t            System.out.println(\"Start server on port 7911...\"); \n\t            server.serve(); \n\t        } catch (TTransportException e) { \n\t            e.printStackTrace(); \n\t        } \n\t    } \n\t } \n\n客户端：\n\n\tpackage service.client; \n\timport org.apache.thrift.TException; \n\timport org.apache.thrift.protocol.TBinaryProtocol; \n\timport org.apache.thrift.protocol.TProtocol; \n\timport org.apache.thrift.transport.TSocket; \n\timport org.apache.thrift.transport.TTransport; \n\timport org.apache.thrift.transport.TTransportException; \n\timport service.demo.Hello; \n\t\n\t public class HelloServiceClient { \n\t /** \n\t     * 调用 Hello 服务\n\t     * @param args \n\t     */ \n\t    public static void main(String[] args) { \n\t        try { \n\t            // 设置调用的服务地址为本地，端口为 7911 \n\t            TTransport transport = new TSocket(\"localhost\", 7911); \n\t            transport.open(); \n\t            // 设置传输协议为 TBinaryProtocol \n\t            TProtocol protocol = new TBinaryProtocol(transport); \n\t            Hello.Client client = new Hello.Client(protocol); \n\t            // 调用服务的 helloVoid 方法\n\t            client.helloVoid(); \n\t            transport.close(); \n\t        } catch (TTransportException e) { \n\t            e.printStackTrace(); \n\t        } catch (TException e) { \n\t            e.printStackTrace(); \n\t        } \n\t    } \n\t } \n\nHelloServiceImpl.java：\n\n\tpackage service.demo; \n\timport org.apache.thrift.TException; \n\tpublic class HelloServiceImpl implements Hello.Iface { \n\t    @Override \n\t    public boolean helloBoolean(boolean para) throws TException { \n\t        return para; \n\t    } \n\t    @Override \n\t    public int helloInt(int para) throws TException { \n\t        try { \n\t            Thread.sleep(20000); \n\t        } catch (InterruptedException e) { \n\t            e.printStackTrace(); \n\t        } \n\t        return para; \n\t    } \n\t    @Override \n\t    public String helloNull() throws TException { \n\t        return null; \n\t    } \n\t    @Override \n\t    public String helloString(String para) throws TException { \n\t        return para; \n\t    } \n\t    @Override \n\t    public void helloVoid() throws TException { \n\t        System.out.println(\"Hello World\"); \n\t    } \n\t } \n\n数据类型\n---\nThrift脚本可定义的数据类型包括以下几种：\n\n* 基本类型\n\t* bool：对应java的boolean，true或false\n\t* byte：对应java的byte，8位有符号整数\n\t* i16：对应java的short，16位有符号整数\n\t* i32：对应java的int，32位有符号整数\n\t* i64：对应java的long，64位有符号整数\n\t* double：对应java的double，64位浮点数\n\t* string：对应java的String，未知编码文本或二进制字符串\n* 结构体类型\n\t* struct：定义公共的对象，对应Java的一个JavaBean，类似C语言中的结构体定义\n* 容器类型\n\t* list：对应java的ArrayList\n\t* set：对应java的HashSet\n\t* map：对应java的HashMap\n* 异常类型\n\t* exception：对应java的Exception\n* 服务类型\n\t* service：对应服务的类\n\n协议\n---\nThrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本（text）和二进制（binary）传输协议，为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为主。常用的协议如下：\n\n* TBinaryProtocol：二进制编码格式传输协议\n* TCompactProtocol：高效率的，密集的二进制编码格式传输协议\n* TJSONProtocol：使用JSON的数据编码传输协议\n* TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析\n\n传输层\n---\n常用的传输层有：\n\n* TSocket：使用阻塞式I/O进行传输\n* TFramedTransport：使用非阻塞方式，按照块的大小进行传输，类似JAVA的NIO\n* TNonblockingTransport：使用非阻塞方式，用于构建异步客户端\n\n部署\n---\n\n![](http://pic.yupoo.com/kazaff_v/DT5yMjza/15i6nB.jpg)\n\n从图中可以看出，客户端和服务端部署时，都需要用到公共的jar包和java文件（图中绿色区域）。\n\n上文内容抄于[这里](http://www.ibm.com/developerworks/cn/java/j-lo-apachethrift/)。\n\n可以看出，Thrift比Avro要简单，至少从例子的角度上来看，RPC的调用方式更直观一些~","source":"_posts/是什么系列之Thrift.md","raw":"title: 是什么系列之Thrift\ndate: 2014-07-07 16:18:12\ntags: \n- rpc\n- json\n- schema\n- 序列化\n- 编码\n- 是什么系列\ncategories: j2ee\n---\n\n这次我们要科普的，是Thrift，它是Facebook的一个开源项目，定位为一个跨语言的远程服务调用框架。\n<!-- more -->\n目前流行的服务调用方式有很多种，例如基于SOAP消息格式的Web Service，基于JSON消息格式的RESTful服务等，其中所用到的数据传输格式包括XML，JSON等，然后XML相对体积太大，传输效率底，JSON体积小，但还不够完善。针对高并发，大数据量和多语言的需求，传输二进制格式的Thrift更有优势。\n\nThrift有一个代码生成器来对它所定义的IDL文件自动生成服务代码框架，用户只需要在其之上进行二次开发即可，对底层的RPC通信等都是透明的。目前它支持的语言有C++，Java，Python，PHP，Ruby，Erlang，Perl，Haskell，C#，Cocoa，Smalltalk，等。（妈蛋，真强悍啊！）\n\n现在看一个Thrift的IDL定义，Hello.thrift文件：\n\n\tnamespace java service.demo\n\tservice Hello{\n\t\tstring helloString(1:string para)\n\t\ti32 helloInt(1:i32 para)\n\t\tbool helloBoolean(1:bool para)\n\t\tvoid helloVoid()\n\t\tstring helloNull()\n\t}\n\n上面的这段代码定义了了服务Hello的5个方法，每个方法包含方法名，参数表和返回类型，每个参数包含参数序号，参数类型及参数名。使用Thrift工具编译Hello.thrift，就会生成响应的Hello.java文件，该文件包含了在Hello.thrift文件中描述的服务Hello的接口定义：Hello.Iface接口，以及服务调用的底层通信细节，包括客户端的调用逻辑Hello.Client以及服务器端的处理逻辑Hello.Processor，用于构建客户端和服务器端的功能。\n\n![](http://pic.yupoo.com/kazaff_v/DT5eHGLc/132ea.jpg)\n\n如图所示，图中黄色部分是用户实现的业务逻辑，褐色部分是根据Thrift定义的服务接口描述文件生成的客户端和服务器端代码框架，红色部分是根据Thrift文件生成代码实现数据的读写操作。红色部分以下是Thrift的传输体系、协议以及底层I/O通信，使用Thrift可以很方便的定义一个服务并且选择不同的传输协议和传输层而不用重新生成代码。\n\nThrift服务器包含用于绑定协议和传输层的基础架构，它提供阻塞、非阻塞、单线程和多线程的模式运行在服务器上，可以配合服务器/容器一起运行，可以和现有的J2EE服务器/Web容器无缝的结合。\n\n![](http://pic.yupoo.com/kazaff_v/DT5mKsO9/zTkIx.png)\n\n该图所示是HelloServiceServer启动的过程以及服务被客户端调用时，服务器的响应过程。从图中我们可以看到，程序调用了TThreadPoolServer的serve方法后，server进入阻塞监听状态，其阻塞在TServerSocket的accept方法上。当接收到来自客户端的消息后，服务器发起一个新线程处理这个消息请求，原线程再次进入阻塞状态。在新线程中，服务器通过TBinaryProtocol协议读取消息内容，调用HelloServiceImpl的helloVoid方法，并将结果写入helloVoid_result中传回客户端。\n\n![](http://pic.yupoo.com/kazaff_v/DT5qrcyO/VFbKS.png)\n\n该图所示是HelloServiceClient调用服务的过程以及接收到服务器端的返回值后处理结果的过程。从图中我们可以看到，程序调用了Hello.Client的helloVoid方法，在helloVoid方法中，通过send_helloVoid方法发送对服务的调用请求，通过recv_helloVoid方法接收服务处理请求后返回的结果。\n\n上述过程对应的代码如下：\n\n服务器端：\n\n\tpackage service.server; \n\timport org.apache.thrift.TProcessor; \n\timport org.apache.thrift.protocol.TBinaryProtocol; \n\timport org.apache.thrift.protocol.TBinaryProtocol.Factory; \n\timport org.apache.thrift.server.TServer; \n\timport org.apache.thrift.server.TThreadPoolServer; \n\timport org.apache.thrift.transport.TServerSocket; \n\timport org.apache.thrift.transport.TTransportException; \n\timport service.demo.Hello; \n\timport service.demo.HelloServiceImpl; \n\t\n\t public class HelloServiceServer { \n\t    /** \n\t     * 启动 Thrift 服务器\n\t     * @param args \n\t     */ \n\t    public static void main(String[] args) { \n\t        try { \n\t            // 设置服务端口为 7911 \n\t            TServerSocket serverTransport = new TServerSocket(7911); \n\t            // 设置协议工厂为 TBinaryProtocol.Factory \n\t            Factory proFactory = new TBinaryProtocol.Factory(); \n\t            // 关联处理器与 Hello 服务的实现\n\t            TProcessor processor = new Hello.Processor(new HelloServiceImpl()); \n\t            TServer server = new TThreadPoolServer(processor, serverTransport, \n\t                    proFactory); \n\t            System.out.println(\"Start server on port 7911...\"); \n\t            server.serve(); \n\t        } catch (TTransportException e) { \n\t            e.printStackTrace(); \n\t        } \n\t    } \n\t } \n\n客户端：\n\n\tpackage service.client; \n\timport org.apache.thrift.TException; \n\timport org.apache.thrift.protocol.TBinaryProtocol; \n\timport org.apache.thrift.protocol.TProtocol; \n\timport org.apache.thrift.transport.TSocket; \n\timport org.apache.thrift.transport.TTransport; \n\timport org.apache.thrift.transport.TTransportException; \n\timport service.demo.Hello; \n\t\n\t public class HelloServiceClient { \n\t /** \n\t     * 调用 Hello 服务\n\t     * @param args \n\t     */ \n\t    public static void main(String[] args) { \n\t        try { \n\t            // 设置调用的服务地址为本地，端口为 7911 \n\t            TTransport transport = new TSocket(\"localhost\", 7911); \n\t            transport.open(); \n\t            // 设置传输协议为 TBinaryProtocol \n\t            TProtocol protocol = new TBinaryProtocol(transport); \n\t            Hello.Client client = new Hello.Client(protocol); \n\t            // 调用服务的 helloVoid 方法\n\t            client.helloVoid(); \n\t            transport.close(); \n\t        } catch (TTransportException e) { \n\t            e.printStackTrace(); \n\t        } catch (TException e) { \n\t            e.printStackTrace(); \n\t        } \n\t    } \n\t } \n\nHelloServiceImpl.java：\n\n\tpackage service.demo; \n\timport org.apache.thrift.TException; \n\tpublic class HelloServiceImpl implements Hello.Iface { \n\t    @Override \n\t    public boolean helloBoolean(boolean para) throws TException { \n\t        return para; \n\t    } \n\t    @Override \n\t    public int helloInt(int para) throws TException { \n\t        try { \n\t            Thread.sleep(20000); \n\t        } catch (InterruptedException e) { \n\t            e.printStackTrace(); \n\t        } \n\t        return para; \n\t    } \n\t    @Override \n\t    public String helloNull() throws TException { \n\t        return null; \n\t    } \n\t    @Override \n\t    public String helloString(String para) throws TException { \n\t        return para; \n\t    } \n\t    @Override \n\t    public void helloVoid() throws TException { \n\t        System.out.println(\"Hello World\"); \n\t    } \n\t } \n\n数据类型\n---\nThrift脚本可定义的数据类型包括以下几种：\n\n* 基本类型\n\t* bool：对应java的boolean，true或false\n\t* byte：对应java的byte，8位有符号整数\n\t* i16：对应java的short，16位有符号整数\n\t* i32：对应java的int，32位有符号整数\n\t* i64：对应java的long，64位有符号整数\n\t* double：对应java的double，64位浮点数\n\t* string：对应java的String，未知编码文本或二进制字符串\n* 结构体类型\n\t* struct：定义公共的对象，对应Java的一个JavaBean，类似C语言中的结构体定义\n* 容器类型\n\t* list：对应java的ArrayList\n\t* set：对应java的HashSet\n\t* map：对应java的HashMap\n* 异常类型\n\t* exception：对应java的Exception\n* 服务类型\n\t* service：对应服务的类\n\n协议\n---\nThrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本（text）和二进制（binary）传输协议，为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为主。常用的协议如下：\n\n* TBinaryProtocol：二进制编码格式传输协议\n* TCompactProtocol：高效率的，密集的二进制编码格式传输协议\n* TJSONProtocol：使用JSON的数据编码传输协议\n* TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析\n\n传输层\n---\n常用的传输层有：\n\n* TSocket：使用阻塞式I/O进行传输\n* TFramedTransport：使用非阻塞方式，按照块的大小进行传输，类似JAVA的NIO\n* TNonblockingTransport：使用非阻塞方式，用于构建异步客户端\n\n部署\n---\n\n![](http://pic.yupoo.com/kazaff_v/DT5yMjza/15i6nB.jpg)\n\n从图中可以看出，客户端和服务端部署时，都需要用到公共的jar包和java文件（图中绿色区域）。\n\n上文内容抄于[这里](http://www.ibm.com/developerworks/cn/java/j-lo-apachethrift/)。\n\n可以看出，Thrift比Avro要简单，至少从例子的角度上来看，RPC的调用方式更直观一些~","slug":"是什么系列之Thrift","published":1,"updated":"2016-05-14T07:46:20.000Z","_id":"cica18yko001ggtfynb2hd0y2","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这次我们要科普的，是Thrift，它是Facebook的一个开源项目，定位为一个跨语言的远程服务调用框架。<br><a id=\"more\"></a><br>目前流行的服务调用方式有很多种，例如基于SOAP消息格式的Web Service，基于JSON消息格式的RESTful服务等，其中所用到的数据传输格式包括XML，JSON等，然后XML相对体积太大，传输效率底，JSON体积小，但还不够完善。针对高并发，大数据量和多语言的需求，传输二进制格式的Thrift更有优势。</p>\n<p>Thrift有一个代码生成器来对它所定义的IDL文件自动生成服务代码框架，用户只需要在其之上进行二次开发即可，对底层的RPC通信等都是透明的。目前它支持的语言有C++，Java，Python，PHP，Ruby，Erlang，Perl，Haskell，C#，Cocoa，Smalltalk，等。（妈蛋，真强悍啊！）</p>\n<p>现在看一个Thrift的IDL定义，Hello.thrift文件：</p>\n<pre><code>namespace java service.demo\nservice Hello{\n    string helloString(1:string para)\n    i32 helloInt(1:i32 para)\n    bool helloBoolean(1:bool para)\n    void helloVoid()\n    string helloNull()\n}\n</code></pre><p>上面的这段代码定义了了服务Hello的5个方法，每个方法包含方法名，参数表和返回类型，每个参数包含参数序号，参数类型及参数名。使用Thrift工具编译Hello.thrift，就会生成响应的Hello.java文件，该文件包含了在Hello.thrift文件中描述的服务Hello的接口定义：Hello.Iface接口，以及服务调用的底层通信细节，包括客户端的调用逻辑Hello.Client以及服务器端的处理逻辑Hello.Processor，用于构建客户端和服务器端的功能。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DT5eHGLc/132ea.jpg\" alt=\"\"></p>\n<p>如图所示，图中黄色部分是用户实现的业务逻辑，褐色部分是根据Thrift定义的服务接口描述文件生成的客户端和服务器端代码框架，红色部分是根据Thrift文件生成代码实现数据的读写操作。红色部分以下是Thrift的传输体系、协议以及底层I/O通信，使用Thrift可以很方便的定义一个服务并且选择不同的传输协议和传输层而不用重新生成代码。</p>\n<p>Thrift服务器包含用于绑定协议和传输层的基础架构，它提供阻塞、非阻塞、单线程和多线程的模式运行在服务器上，可以配合服务器/容器一起运行，可以和现有的J2EE服务器/Web容器无缝的结合。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DT5mKsO9/zTkIx.png\" alt=\"\"></p>\n<p>该图所示是HelloServiceServer启动的过程以及服务被客户端调用时，服务器的响应过程。从图中我们可以看到，程序调用了TThreadPoolServer的serve方法后，server进入阻塞监听状态，其阻塞在TServerSocket的accept方法上。当接收到来自客户端的消息后，服务器发起一个新线程处理这个消息请求，原线程再次进入阻塞状态。在新线程中，服务器通过TBinaryProtocol协议读取消息内容，调用HelloServiceImpl的helloVoid方法，并将结果写入helloVoid_result中传回客户端。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DT5qrcyO/VFbKS.png\" alt=\"\"></p>\n<p>该图所示是HelloServiceClient调用服务的过程以及接收到服务器端的返回值后处理结果的过程。从图中我们可以看到，程序调用了Hello.Client的helloVoid方法，在helloVoid方法中，通过send_helloVoid方法发送对服务的调用请求，通过recv_helloVoid方法接收服务处理请求后返回的结果。</p>\n<p>上述过程对应的代码如下：</p>\n<p>服务器端：</p>\n<pre><code>package service.server; \nimport org.apache.thrift.TProcessor; \nimport org.apache.thrift.protocol.TBinaryProtocol; \nimport org.apache.thrift.protocol.TBinaryProtocol.Factory; \nimport org.apache.thrift.server.TServer; \nimport org.apache.thrift.server.TThreadPoolServer; \nimport org.apache.thrift.transport.TServerSocket; \nimport org.apache.thrift.transport.TTransportException; \nimport service.demo.Hello; \nimport service.demo.HelloServiceImpl; \n\n public class HelloServiceServer { \n    /** \n     * 启动 Thrift 服务器\n     * @param args \n     */ \n    public static void main(String[] args) { \n        try { \n            // 设置服务端口为 7911 \n            TServerSocket serverTransport = new TServerSocket(7911); \n            // 设置协议工厂为 TBinaryProtocol.Factory \n            Factory proFactory = new TBinaryProtocol.Factory(); \n            // 关联处理器与 Hello 服务的实现\n            TProcessor processor = new Hello.Processor(new HelloServiceImpl()); \n            TServer server = new TThreadPoolServer(processor, serverTransport, \n                    proFactory); \n            System.out.println(&quot;Start server on port 7911...&quot;); \n            server.serve(); \n        } catch (TTransportException e) { \n            e.printStackTrace(); \n        } \n    } \n } \n</code></pre><p>客户端：</p>\n<pre><code>package service.client; \nimport org.apache.thrift.TException; \nimport org.apache.thrift.protocol.TBinaryProtocol; \nimport org.apache.thrift.protocol.TProtocol; \nimport org.apache.thrift.transport.TSocket; \nimport org.apache.thrift.transport.TTransport; \nimport org.apache.thrift.transport.TTransportException; \nimport service.demo.Hello; \n\n public class HelloServiceClient { \n /** \n     * 调用 Hello 服务\n     * @param args \n     */ \n    public static void main(String[] args) { \n        try { \n            // 设置调用的服务地址为本地，端口为 7911 \n            TTransport transport = new TSocket(&quot;localhost&quot;, 7911); \n            transport.open(); \n            // 设置传输协议为 TBinaryProtocol \n            TProtocol protocol = new TBinaryProtocol(transport); \n            Hello.Client client = new Hello.Client(protocol); \n            // 调用服务的 helloVoid 方法\n            client.helloVoid(); \n            transport.close(); \n        } catch (TTransportException e) { \n            e.printStackTrace(); \n        } catch (TException e) { \n            e.printStackTrace(); \n        } \n    } \n } \n</code></pre><p>HelloServiceImpl.java：</p>\n<pre><code>package service.demo; \nimport org.apache.thrift.TException; \npublic class HelloServiceImpl implements Hello.Iface { \n    @Override \n    public boolean helloBoolean(boolean para) throws TException { \n        return para; \n    } \n    @Override \n    public int helloInt(int para) throws TException { \n        try { \n            Thread.sleep(20000); \n        } catch (InterruptedException e) { \n            e.printStackTrace(); \n        } \n        return para; \n    } \n    @Override \n    public String helloNull() throws TException { \n        return null; \n    } \n    @Override \n    public String helloString(String para) throws TException { \n        return para; \n    } \n    @Override \n    public void helloVoid() throws TException { \n        System.out.println(&quot;Hello World&quot;); \n    } \n } \n</code></pre><h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p>Thrift脚本可定义的数据类型包括以下几种：</p>\n<ul>\n<li>基本类型<ul>\n<li>bool：对应java的boolean，true或false</li>\n<li>byte：对应java的byte，8位有符号整数</li>\n<li>i16：对应java的short，16位有符号整数</li>\n<li>i32：对应java的int，32位有符号整数</li>\n<li>i64：对应java的long，64位有符号整数</li>\n<li>double：对应java的double，64位浮点数</li>\n<li>string：对应java的String，未知编码文本或二进制字符串</li>\n</ul>\n</li>\n<li>结构体类型<ul>\n<li>struct：定义公共的对象，对应Java的一个JavaBean，类似C语言中的结构体定义</li>\n</ul>\n</li>\n<li>容器类型<ul>\n<li>list：对应java的ArrayList</li>\n<li>set：对应java的HashSet</li>\n<li>map：对应java的HashMap</li>\n</ul>\n</li>\n<li>异常类型<ul>\n<li>exception：对应java的Exception</li>\n</ul>\n</li>\n<li>服务类型<ul>\n<li>service：对应服务的类</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"协议\"><a href=\"#协议\" class=\"headerlink\" title=\"协议\"></a>协议</h2><p>Thrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本（text）和二进制（binary）传输协议，为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为主。常用的协议如下：</p>\n<ul>\n<li>TBinaryProtocol：二进制编码格式传输协议</li>\n<li>TCompactProtocol：高效率的，密集的二进制编码格式传输协议</li>\n<li>TJSONProtocol：使用JSON的数据编码传输协议</li>\n<li>TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析</li>\n</ul>\n<h2 id=\"传输层\"><a href=\"#传输层\" class=\"headerlink\" title=\"传输层\"></a>传输层</h2><p>常用的传输层有：</p>\n<ul>\n<li>TSocket：使用阻塞式I/O进行传输</li>\n<li>TFramedTransport：使用非阻塞方式，按照块的大小进行传输，类似JAVA的NIO</li>\n<li>TNonblockingTransport：使用非阻塞方式，用于构建异步客户端</li>\n</ul>\n<h2 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h2><p><img src=\"http://pic.yupoo.com/kazaff_v/DT5yMjza/15i6nB.jpg\" alt=\"\"></p>\n<p>从图中可以看出，客户端和服务端部署时，都需要用到公共的jar包和java文件（图中绿色区域）。</p>\n<p>上文内容抄于<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-apachethrift/\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>可以看出，Thrift比Avro要简单，至少从例子的角度上来看，RPC的调用方式更直观一些~</p>\n","excerpt":"<p>这次我们要科普的，是Thrift，它是Facebook的一个开源项目，定位为一个跨语言的远程服务调用框架。<br>","more":"<br>目前流行的服务调用方式有很多种，例如基于SOAP消息格式的Web Service，基于JSON消息格式的RESTful服务等，其中所用到的数据传输格式包括XML，JSON等，然后XML相对体积太大，传输效率底，JSON体积小，但还不够完善。针对高并发，大数据量和多语言的需求，传输二进制格式的Thrift更有优势。</p>\n<p>Thrift有一个代码生成器来对它所定义的IDL文件自动生成服务代码框架，用户只需要在其之上进行二次开发即可，对底层的RPC通信等都是透明的。目前它支持的语言有C++，Java，Python，PHP，Ruby，Erlang，Perl，Haskell，C#，Cocoa，Smalltalk，等。（妈蛋，真强悍啊！）</p>\n<p>现在看一个Thrift的IDL定义，Hello.thrift文件：</p>\n<pre><code>namespace java service.demo\nservice Hello{\n    string helloString(1:string para)\n    i32 helloInt(1:i32 para)\n    bool helloBoolean(1:bool para)\n    void helloVoid()\n    string helloNull()\n}\n</code></pre><p>上面的这段代码定义了了服务Hello的5个方法，每个方法包含方法名，参数表和返回类型，每个参数包含参数序号，参数类型及参数名。使用Thrift工具编译Hello.thrift，就会生成响应的Hello.java文件，该文件包含了在Hello.thrift文件中描述的服务Hello的接口定义：Hello.Iface接口，以及服务调用的底层通信细节，包括客户端的调用逻辑Hello.Client以及服务器端的处理逻辑Hello.Processor，用于构建客户端和服务器端的功能。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DT5eHGLc/132ea.jpg\" alt=\"\"></p>\n<p>如图所示，图中黄色部分是用户实现的业务逻辑，褐色部分是根据Thrift定义的服务接口描述文件生成的客户端和服务器端代码框架，红色部分是根据Thrift文件生成代码实现数据的读写操作。红色部分以下是Thrift的传输体系、协议以及底层I/O通信，使用Thrift可以很方便的定义一个服务并且选择不同的传输协议和传输层而不用重新生成代码。</p>\n<p>Thrift服务器包含用于绑定协议和传输层的基础架构，它提供阻塞、非阻塞、单线程和多线程的模式运行在服务器上，可以配合服务器/容器一起运行，可以和现有的J2EE服务器/Web容器无缝的结合。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DT5mKsO9/zTkIx.png\" alt=\"\"></p>\n<p>该图所示是HelloServiceServer启动的过程以及服务被客户端调用时，服务器的响应过程。从图中我们可以看到，程序调用了TThreadPoolServer的serve方法后，server进入阻塞监听状态，其阻塞在TServerSocket的accept方法上。当接收到来自客户端的消息后，服务器发起一个新线程处理这个消息请求，原线程再次进入阻塞状态。在新线程中，服务器通过TBinaryProtocol协议读取消息内容，调用HelloServiceImpl的helloVoid方法，并将结果写入helloVoid_result中传回客户端。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DT5qrcyO/VFbKS.png\" alt=\"\"></p>\n<p>该图所示是HelloServiceClient调用服务的过程以及接收到服务器端的返回值后处理结果的过程。从图中我们可以看到，程序调用了Hello.Client的helloVoid方法，在helloVoid方法中，通过send_helloVoid方法发送对服务的调用请求，通过recv_helloVoid方法接收服务处理请求后返回的结果。</p>\n<p>上述过程对应的代码如下：</p>\n<p>服务器端：</p>\n<pre><code>package service.server; \nimport org.apache.thrift.TProcessor; \nimport org.apache.thrift.protocol.TBinaryProtocol; \nimport org.apache.thrift.protocol.TBinaryProtocol.Factory; \nimport org.apache.thrift.server.TServer; \nimport org.apache.thrift.server.TThreadPoolServer; \nimport org.apache.thrift.transport.TServerSocket; \nimport org.apache.thrift.transport.TTransportException; \nimport service.demo.Hello; \nimport service.demo.HelloServiceImpl; \n\n public class HelloServiceServer { \n    /** \n     * 启动 Thrift 服务器\n     * @param args \n     */ \n    public static void main(String[] args) { \n        try { \n            // 设置服务端口为 7911 \n            TServerSocket serverTransport = new TServerSocket(7911); \n            // 设置协议工厂为 TBinaryProtocol.Factory \n            Factory proFactory = new TBinaryProtocol.Factory(); \n            // 关联处理器与 Hello 服务的实现\n            TProcessor processor = new Hello.Processor(new HelloServiceImpl()); \n            TServer server = new TThreadPoolServer(processor, serverTransport, \n                    proFactory); \n            System.out.println(&quot;Start server on port 7911...&quot;); \n            server.serve(); \n        } catch (TTransportException e) { \n            e.printStackTrace(); \n        } \n    } \n } \n</code></pre><p>客户端：</p>\n<pre><code>package service.client; \nimport org.apache.thrift.TException; \nimport org.apache.thrift.protocol.TBinaryProtocol; \nimport org.apache.thrift.protocol.TProtocol; \nimport org.apache.thrift.transport.TSocket; \nimport org.apache.thrift.transport.TTransport; \nimport org.apache.thrift.transport.TTransportException; \nimport service.demo.Hello; \n\n public class HelloServiceClient { \n /** \n     * 调用 Hello 服务\n     * @param args \n     */ \n    public static void main(String[] args) { \n        try { \n            // 设置调用的服务地址为本地，端口为 7911 \n            TTransport transport = new TSocket(&quot;localhost&quot;, 7911); \n            transport.open(); \n            // 设置传输协议为 TBinaryProtocol \n            TProtocol protocol = new TBinaryProtocol(transport); \n            Hello.Client client = new Hello.Client(protocol); \n            // 调用服务的 helloVoid 方法\n            client.helloVoid(); \n            transport.close(); \n        } catch (TTransportException e) { \n            e.printStackTrace(); \n        } catch (TException e) { \n            e.printStackTrace(); \n        } \n    } \n } \n</code></pre><p>HelloServiceImpl.java：</p>\n<pre><code>package service.demo; \nimport org.apache.thrift.TException; \npublic class HelloServiceImpl implements Hello.Iface { \n    @Override \n    public boolean helloBoolean(boolean para) throws TException { \n        return para; \n    } \n    @Override \n    public int helloInt(int para) throws TException { \n        try { \n            Thread.sleep(20000); \n        } catch (InterruptedException e) { \n            e.printStackTrace(); \n        } \n        return para; \n    } \n    @Override \n    public String helloNull() throws TException { \n        return null; \n    } \n    @Override \n    public String helloString(String para) throws TException { \n        return para; \n    } \n    @Override \n    public void helloVoid() throws TException { \n        System.out.println(&quot;Hello World&quot;); \n    } \n } \n</code></pre><h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p>Thrift脚本可定义的数据类型包括以下几种：</p>\n<ul>\n<li>基本类型<ul>\n<li>bool：对应java的boolean，true或false</li>\n<li>byte：对应java的byte，8位有符号整数</li>\n<li>i16：对应java的short，16位有符号整数</li>\n<li>i32：对应java的int，32位有符号整数</li>\n<li>i64：对应java的long，64位有符号整数</li>\n<li>double：对应java的double，64位浮点数</li>\n<li>string：对应java的String，未知编码文本或二进制字符串</li>\n</ul>\n</li>\n<li>结构体类型<ul>\n<li>struct：定义公共的对象，对应Java的一个JavaBean，类似C语言中的结构体定义</li>\n</ul>\n</li>\n<li>容器类型<ul>\n<li>list：对应java的ArrayList</li>\n<li>set：对应java的HashSet</li>\n<li>map：对应java的HashMap</li>\n</ul>\n</li>\n<li>异常类型<ul>\n<li>exception：对应java的Exception</li>\n</ul>\n</li>\n<li>服务类型<ul>\n<li>service：对应服务的类</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"协议\"><a href=\"#协议\" class=\"headerlink\" title=\"协议\"></a>协议</h2><p>Thrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本（text）和二进制（binary）传输协议，为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为主。常用的协议如下：</p>\n<ul>\n<li>TBinaryProtocol：二进制编码格式传输协议</li>\n<li>TCompactProtocol：高效率的，密集的二进制编码格式传输协议</li>\n<li>TJSONProtocol：使用JSON的数据编码传输协议</li>\n<li>TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析</li>\n</ul>\n<h2 id=\"传输层\"><a href=\"#传输层\" class=\"headerlink\" title=\"传输层\"></a>传输层</h2><p>常用的传输层有：</p>\n<ul>\n<li>TSocket：使用阻塞式I/O进行传输</li>\n<li>TFramedTransport：使用非阻塞方式，按照块的大小进行传输，类似JAVA的NIO</li>\n<li>TNonblockingTransport：使用非阻塞方式，用于构建异步客户端</li>\n</ul>\n<h2 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h2><p><img src=\"http://pic.yupoo.com/kazaff_v/DT5yMjza/15i6nB.jpg\" alt=\"\"></p>\n<p>从图中可以看出，客户端和服务端部署时，都需要用到公共的jar包和java文件（图中绿色区域）。</p>\n<p>上文内容抄于<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-apachethrift/\">这里</a>。</p>\n<p>可以看出，Thrift比Avro要简单，至少从例子的角度上来看，RPC的调用方式更直观一些~</p>"},{"title":"是什么系列之Servlet","date":"2014-07-03T03:37:12.000Z","_content":"\n公司已经开始大面积转型j2ee，正在使用的是整套java web的技术解决方案：Tomcat+springMVC+jdbc。作为一个从php转型过来的程序猿，还是需要好好消化一下java web开发的一些基础概念的。实不相瞒，我就一直闹不懂什么是Servlet，总是无法正确的理解它的作用及位置~\n<!-- more -->\n刚好今天有时间，就找了篇不错的技术贴好好科普一下，下面记录一些相关重点。\n\n首先，先看一下我们要解决的疑惑：\n\n1. 以Tomcat为例了解Servlet容器是如何工作的？\n2. 一个Web工程在Servlet容器中是如何启动的？\n3. Servlet容器如何解析你在web.xml中定义的Servlet？\n4. 用户的请求是如何被分配给指定的Servlet的？\n5. Servlet容器如何管理Servlet生命周期？\n\n先从Servlet容器聊起\n---\nServlet和Servlet容器，从名字上来猜，就想水和器皿，之所以独立出两个东西，完全是为了满足工业化生产，也就是说是为了解耦，通过标准接口来让这两个东西协作从而完成实际需求。\n\n目前成熟的Servlet容器产品很多，像Jetty，Tomcat都是java web开发人员耳熟能详的。我们下面就以Tomcat为例来讲一下Servlet容器如何管理Servlet的。\n\n![](http://pic.yupoo.com/kazaff/DSjSZM95/KxYyT.jpg)\n\n从上图可以看出，Tomcat的容器分为四个等级，真正管理Servlet的是Context容器，可以看到，一个Context对应一个web工程，这在Tomcat配置文件里也可以很容易的发现这一点：\n\n\t <Context path=\"/projectOne \" docBase=\"D:\\projects\\projectOne\" reloadable=\"true\" />\n\nServlet容器的启动过程\n---\n我们已经知道，一个Web项目对应一个Context容器，也就是Servlet运行时的Servlet容器，添加一个Web应用时将会创建一个StandardContext容器，并且给这个Context容器设置别要的参数（url，path等）。\n\n下面看一张时序图，来分析一下Tomcat的启动过程：\n\n![](http://pic.yupoo.com/kazaff/DSjXuOA2/6kRPD.jpg)\n\n上图描述的主要是类之间的时序关系，我们主要关注StandardContext容器的启动过程。\n\n当Context容器初始化状态设为init时，添加在Context容器上的Listener将会被调用，我们主要看一下ContextConfig做了什么，这个类会负责整个Web应用的配置文件的解析工作：\n\n1. 创建用于解析xml配置文件的contextDigester对象\n2. 读取默认context.xml配置文件，如果存在则解析它\n3. 读取默认Host配置文件，如果存在则解析它\n4. 读取默认Context自身的配置文件，如果存在则解析它\n5. 设置Context的DocBase\n\nContextConfig的init方法完成后，Context容器会执行startInternal方法，主要做的是：\n\n1. 创建读取资源文件的对象\n2. 创建ClassLoader对象\n3. 设置应用的工作目录\n4. 启动相关的辅助类，如：logger，realm，resources等\n5. 修改启动状态，通知感兴趣的观察者（web应用的配置）\n6. 子容器的初始化\n7. 获取ServletContext并设置必要的参数\n8. 初始化“load on startup”的Servlet\n\nWeb应用的初始化工作实在ContextConfig的configureStart方法中实现的，应用的初始化主要是要解析web.xml文件，这个文件描述了一个web应用的关键信息，也是一个web应用的入口。\n\nTomcat首先会创建globalWebXml对象，接着是hostWebXml对象，再然后是对应应用的WebXml对象。Tomcat会将ContextConfig从web.xml文件中解析出的各项属性保存在WebXml对象中。再然后会将WebXml对象中的属性设置到Context容器中，这里面包括创建的Servlet对象，filter，listener等等，这个工作在WebXml的configureContext方法中完成，在该方法中会将Servlet包装成Context容器中的StandardWrapper，为什么要将Servlet包装成StandardWrapper而不直接创建Servlet对象呢？这是因为StandardWrapper是Tomcat容器的一部分，它具有容器的特征，而Servlet是一个独立的Web开发标准，不应该强耦合在Tomcat中。\n\n除了将Servlet包装成StandardWrapper并作为子容器添加到Context中，其它的所有web.xml属性都被解析到Context中，所以说Context容器才是真正运行Servlet的Servlet容器。一个Web应用对应一个Context容器，容器的配置属性由应用的web.xml指定，这样我们就能理解web.xml到底起到什么作用了。\n\n创建Servlet实例\n---\n我们已经完成了Servlet的解析工作，并且被包装成StandardWrapper添加在Context容器中，但它仍然不能工作，因为我们还没有实例化它。\n\n如果Servlet的load-on-startup配置项大于0，那么在Context容器启动的时候就会实例化它，之前提到在解析配置文件时会读取在Tomcat目录下的Conf文件夹下的Web.xml文件的默认配置项，用来创建globalWebXml，其定义了两个Servlet，分别是：org.apache.catalina.servlets.DefaultServlet 和 org.apache.jasper.servlet.JspServlet 它们的 load-on-startup 分别是 1 和 3，也就是当Tomcat启动时这两个Servlet就会被实例化。\n\n创建Servlet实例的方法是从Wrapper.loadServlet开始的，该方法要完成的就是获取servletClass，然后把它交给InstanceManager去创建一个基于servletClass.class的对象，并且如果这个Servlet配置了jsp-file，那么这个servletClass就是conf/web.xml中定义的org.apache.jasper.servlet.JspServlet了！\n\n初始化Servlet\n---\n初始化Servlet这个工作是在StandardWrapper的initServlet方法中完成的，这个方法很简单，就是调用Servlet的init方法，同时把包装了StandarWrapper对象的StandardWrappFacade作为ServletConfig传递给Servlet，原因待会在说~\n\n如果该Servlet关联的是一个jsp文件，那么在前面初始化的就是JspServlet，接下去会模拟一次简单的请求，请求调用这个jsp文件，以便编译这个jsp文件为class，并初始化这个class。\n\n这样Servlet对象就初始化完成了，事实上Servlet从被 web.xml 中解析到完成初始化，这个过程非常复杂，中间有很多过程，包括各种容器状态的转化引起的监听事件的触发、各种访问权限的控制和一些不可预料的错误发生的判断行为等等。我们这里只抓了一些关键环节进行阐述，试图让大家有个总体脉络。\n\n下面看一下时序图：\n\n![](http://pic.yupoo.com/kazaff/DSl5s0re/X35p4.jpg)\n\nServlet体系结构\n---\n\n![](http://pic.yupoo.com/kazaff/DSladGCE/xeHEC.jpg)\n\n上图可以看出，Servlet规范就是基于这几个类运转的，与Servlet主动关联的是三个类：ServletConfig，ServletRequest和ServletResponse。这三个类都是通过容器传递给Servlet的，其中ServletConfig是在Servlet初始化时就传递给Servlet的（前面我们提到了）。而后面这两个是在请求到达时调用Servlet时传参过来的。\n\n那么，ServletConfig和ServletContex对Servlet有何作用呢？从ServletConfig的接口中声明的方法不难看出，这些方法都是为了获取这个Servlet的一些配置属性，而这些配置属性可能在Servlet运行时会被用到。\n\n而ServletContext的作用呢？这里提到了Servlet的运行模式，Servlet的运行模式是一个典型的“握手型的交互式”运行模式。所谓“握手型的交互式”就是两个模块为了交换数据通常都会准备一个交易场景，这个场景一直跟随个这个交易过程直到这个交易完成为止。这个交易场景的初始化是根据这次交易对象指定的参数来定制的，这些指定参数通常就会是一个配置类。所以对号入座，交易场景就由ServletContext来描述，而定制的参数集合就由ServletConfig来描述。而ServletRequest和ServletResponse就是要交互的具体对象了，它们通常都是作为运输工具来传递交互结果。\n\n下图是ServletConfig和ServletContex在Tomcat容器中的类关系图：\n\n![](http://pic.yupoo.com/kazaff/DSliYtlh/9JjIN.jpg)\n\n上图可以看出StandardWrapper和StandardWrapperFacade都实现了ServletConfig接口，而StandardWrapperFacade是 StandardWrapper门面类。所以传给Servlet的是StandardWrapperFacade对象，这个类能够保证从StandardWrapper中拿到 ServletConfig所规定的数据，而又不把ServletConfig不关心的数据暴露给Servlet。\n\n同样ServletContext也与ServletConfig有类似的结构，Servlet中能拿到的ServletContext的实际对象也是 ApplicationContextFacade对象。ApplicationContextFacade同样保证ServletContext只能从容器中拿到它该拿的数据，它们都起到对数据的封装作用，它们使用的都是门面设计模式。\n\n通过ServletContext可以拿到Context容器中一些必要信息，比如应用的工作路径，容器支持的Servlet最小版本等。\n\nTomcat一接受到请求首先将会创建org.apache.coyote.Request和org.apache.coyote.Response，这两个类是Tomcat内部使用的描述一次请求和响应的信息类，它们是一个轻量级的类，作用就是在服务器接收到请求后，经过简单解析将这个请求快速的分配给后续线程去处理，所以它们的对象很小，很容易被JVM回收。\n\n接下去当交给一个用户线程去处理这个请求时又创建org.apache.catalina.connector.Request和org.apache.catalina.connector.Response对象。这两个对象一直穿越整个Servlet容器直到要传给Servlet，传给Servlet的是Request和Response的门面类RequestFacade和RequestFacade，这里使用门面模式与前面一样都是基于同样的目的——封装容器中的数据。一次请求对应的Request和Response的类转化如下图所示：\n\n![](http://pic.yupoo.com/kazaff_v/DSr8j5Tq/ri7Eh.jpg)\n\nServlet如何工作\n---\n我们已经清楚了Servlet是如何被加载的，Servlet是如何被初始化的，以及Servlet的体系结构，现在的问题是它如何被调用？\n\n当用户从浏览器向服务器发起一个请求，通常包含如下信息：**http://hostname:port/contextpath/servetpath**，hostname和port是用来与服务器建立tcp连接的，而后面的URL才是用来选择服务器中哪个子容器服务用户的请求。\n\n根据URL来映射正确的Servlet容器的工作有专门的一个类来完成：org.apache.tomcat.util.http.mapper，这个类保存了Tomcat的Container容器中的所有子容器的信息，当org.apache.catalina.connector.Request类在进入Container容器之前，mapper将会根据这次请求的hostname和contextpath将host和context容器设置到Request的mappingData属性中。所以当Request进入Container容器之前就已经确定了它要访问哪个子容器了！看下图：\n\n![](http://pic.yupoo.com/kazaff_v/DSrk9Yhb/3hHbN.jpg)\n\n上图描述了一次Request请求是如何达到最终的Wrapper容器的，我们现正知道了请求是如何达到正确的Wrapper容器，但是请求到达最终的Servlet还要完成一些步骤，必须要执行Filter链，以及要通知你在web.xml中定义的listener。\n\n接下去就要执行Servlet的service方法了，通常情况下，我们自己定义的servlet并不是直接去实现javax.servlet.servlet接口，而是去继承更简单的HttpServlet类或者GenericServlet类，我们可以有选择的覆盖相应方法去实现我们要完成的工作。\n\nServlet的确已经能够帮我们完成所有的工作了，但是现在的web应用很少有直接将交互全部页面都用servlet来实现，而是采用更加高效的MVC框架来实现。这些MVC框架基本的原理都是将所有的请求都映射到一个Servlet，然后去实现service方法，这个方法也就是MVC框架的入口。\n\n当Servlet从Servlet容器中移除时，也就表明该Servlet的生命周期结束了，这时Servlet的destroy方法将被调用，做一些扫尾工作。\n\nSession与Cookie\n---\n\n![](http://pic.yupoo.com/kazaff_v/DSrB5KEx/XhS9F.jpg)\n\n从上图可以看到Session工作的时序图，有了Session ID服务器端就可以创建HttpSession对象了，第一次触发是通过request.getSession()方法，如果当前的Session ID还没有对应的HttpSession对象那么就创建一个新的，并将这个对象加到 org.apache.catalina.Manager的sessions容器中保存，Manager类将管理所有Session的生命周期，Session过期将被回收，服务器关闭，Session将被序列化到磁盘等。只要这个HttpSession对象存在，用户就可以根据Session ID来获取到这个对象，也就达到了状态的保持。\n\n\n引用[原文](http://www.ibm.com/developerworks/cn/java/j-lo-servlet/)\n\n","source":"_posts/是什么系列之Servlet.md","raw":"title: 是什么系列之Servlet\ndate: 2014-07-03 11:37:12\ntags: \n- Servlet\n- Tomcat\n- 是什么系列\ncategories: j2ee\n---\n\n公司已经开始大面积转型j2ee，正在使用的是整套java web的技术解决方案：Tomcat+springMVC+jdbc。作为一个从php转型过来的程序猿，还是需要好好消化一下java web开发的一些基础概念的。实不相瞒，我就一直闹不懂什么是Servlet，总是无法正确的理解它的作用及位置~\n<!-- more -->\n刚好今天有时间，就找了篇不错的技术贴好好科普一下，下面记录一些相关重点。\n\n首先，先看一下我们要解决的疑惑：\n\n1. 以Tomcat为例了解Servlet容器是如何工作的？\n2. 一个Web工程在Servlet容器中是如何启动的？\n3. Servlet容器如何解析你在web.xml中定义的Servlet？\n4. 用户的请求是如何被分配给指定的Servlet的？\n5. Servlet容器如何管理Servlet生命周期？\n\n先从Servlet容器聊起\n---\nServlet和Servlet容器，从名字上来猜，就想水和器皿，之所以独立出两个东西，完全是为了满足工业化生产，也就是说是为了解耦，通过标准接口来让这两个东西协作从而完成实际需求。\n\n目前成熟的Servlet容器产品很多，像Jetty，Tomcat都是java web开发人员耳熟能详的。我们下面就以Tomcat为例来讲一下Servlet容器如何管理Servlet的。\n\n![](http://pic.yupoo.com/kazaff/DSjSZM95/KxYyT.jpg)\n\n从上图可以看出，Tomcat的容器分为四个等级，真正管理Servlet的是Context容器，可以看到，一个Context对应一个web工程，这在Tomcat配置文件里也可以很容易的发现这一点：\n\n\t <Context path=\"/projectOne \" docBase=\"D:\\projects\\projectOne\" reloadable=\"true\" />\n\nServlet容器的启动过程\n---\n我们已经知道，一个Web项目对应一个Context容器，也就是Servlet运行时的Servlet容器，添加一个Web应用时将会创建一个StandardContext容器，并且给这个Context容器设置别要的参数（url，path等）。\n\n下面看一张时序图，来分析一下Tomcat的启动过程：\n\n![](http://pic.yupoo.com/kazaff/DSjXuOA2/6kRPD.jpg)\n\n上图描述的主要是类之间的时序关系，我们主要关注StandardContext容器的启动过程。\n\n当Context容器初始化状态设为init时，添加在Context容器上的Listener将会被调用，我们主要看一下ContextConfig做了什么，这个类会负责整个Web应用的配置文件的解析工作：\n\n1. 创建用于解析xml配置文件的contextDigester对象\n2. 读取默认context.xml配置文件，如果存在则解析它\n3. 读取默认Host配置文件，如果存在则解析它\n4. 读取默认Context自身的配置文件，如果存在则解析它\n5. 设置Context的DocBase\n\nContextConfig的init方法完成后，Context容器会执行startInternal方法，主要做的是：\n\n1. 创建读取资源文件的对象\n2. 创建ClassLoader对象\n3. 设置应用的工作目录\n4. 启动相关的辅助类，如：logger，realm，resources等\n5. 修改启动状态，通知感兴趣的观察者（web应用的配置）\n6. 子容器的初始化\n7. 获取ServletContext并设置必要的参数\n8. 初始化“load on startup”的Servlet\n\nWeb应用的初始化工作实在ContextConfig的configureStart方法中实现的，应用的初始化主要是要解析web.xml文件，这个文件描述了一个web应用的关键信息，也是一个web应用的入口。\n\nTomcat首先会创建globalWebXml对象，接着是hostWebXml对象，再然后是对应应用的WebXml对象。Tomcat会将ContextConfig从web.xml文件中解析出的各项属性保存在WebXml对象中。再然后会将WebXml对象中的属性设置到Context容器中，这里面包括创建的Servlet对象，filter，listener等等，这个工作在WebXml的configureContext方法中完成，在该方法中会将Servlet包装成Context容器中的StandardWrapper，为什么要将Servlet包装成StandardWrapper而不直接创建Servlet对象呢？这是因为StandardWrapper是Tomcat容器的一部分，它具有容器的特征，而Servlet是一个独立的Web开发标准，不应该强耦合在Tomcat中。\n\n除了将Servlet包装成StandardWrapper并作为子容器添加到Context中，其它的所有web.xml属性都被解析到Context中，所以说Context容器才是真正运行Servlet的Servlet容器。一个Web应用对应一个Context容器，容器的配置属性由应用的web.xml指定，这样我们就能理解web.xml到底起到什么作用了。\n\n创建Servlet实例\n---\n我们已经完成了Servlet的解析工作，并且被包装成StandardWrapper添加在Context容器中，但它仍然不能工作，因为我们还没有实例化它。\n\n如果Servlet的load-on-startup配置项大于0，那么在Context容器启动的时候就会实例化它，之前提到在解析配置文件时会读取在Tomcat目录下的Conf文件夹下的Web.xml文件的默认配置项，用来创建globalWebXml，其定义了两个Servlet，分别是：org.apache.catalina.servlets.DefaultServlet 和 org.apache.jasper.servlet.JspServlet 它们的 load-on-startup 分别是 1 和 3，也就是当Tomcat启动时这两个Servlet就会被实例化。\n\n创建Servlet实例的方法是从Wrapper.loadServlet开始的，该方法要完成的就是获取servletClass，然后把它交给InstanceManager去创建一个基于servletClass.class的对象，并且如果这个Servlet配置了jsp-file，那么这个servletClass就是conf/web.xml中定义的org.apache.jasper.servlet.JspServlet了！\n\n初始化Servlet\n---\n初始化Servlet这个工作是在StandardWrapper的initServlet方法中完成的，这个方法很简单，就是调用Servlet的init方法，同时把包装了StandarWrapper对象的StandardWrappFacade作为ServletConfig传递给Servlet，原因待会在说~\n\n如果该Servlet关联的是一个jsp文件，那么在前面初始化的就是JspServlet，接下去会模拟一次简单的请求，请求调用这个jsp文件，以便编译这个jsp文件为class，并初始化这个class。\n\n这样Servlet对象就初始化完成了，事实上Servlet从被 web.xml 中解析到完成初始化，这个过程非常复杂，中间有很多过程，包括各种容器状态的转化引起的监听事件的触发、各种访问权限的控制和一些不可预料的错误发生的判断行为等等。我们这里只抓了一些关键环节进行阐述，试图让大家有个总体脉络。\n\n下面看一下时序图：\n\n![](http://pic.yupoo.com/kazaff/DSl5s0re/X35p4.jpg)\n\nServlet体系结构\n---\n\n![](http://pic.yupoo.com/kazaff/DSladGCE/xeHEC.jpg)\n\n上图可以看出，Servlet规范就是基于这几个类运转的，与Servlet主动关联的是三个类：ServletConfig，ServletRequest和ServletResponse。这三个类都是通过容器传递给Servlet的，其中ServletConfig是在Servlet初始化时就传递给Servlet的（前面我们提到了）。而后面这两个是在请求到达时调用Servlet时传参过来的。\n\n那么，ServletConfig和ServletContex对Servlet有何作用呢？从ServletConfig的接口中声明的方法不难看出，这些方法都是为了获取这个Servlet的一些配置属性，而这些配置属性可能在Servlet运行时会被用到。\n\n而ServletContext的作用呢？这里提到了Servlet的运行模式，Servlet的运行模式是一个典型的“握手型的交互式”运行模式。所谓“握手型的交互式”就是两个模块为了交换数据通常都会准备一个交易场景，这个场景一直跟随个这个交易过程直到这个交易完成为止。这个交易场景的初始化是根据这次交易对象指定的参数来定制的，这些指定参数通常就会是一个配置类。所以对号入座，交易场景就由ServletContext来描述，而定制的参数集合就由ServletConfig来描述。而ServletRequest和ServletResponse就是要交互的具体对象了，它们通常都是作为运输工具来传递交互结果。\n\n下图是ServletConfig和ServletContex在Tomcat容器中的类关系图：\n\n![](http://pic.yupoo.com/kazaff/DSliYtlh/9JjIN.jpg)\n\n上图可以看出StandardWrapper和StandardWrapperFacade都实现了ServletConfig接口，而StandardWrapperFacade是 StandardWrapper门面类。所以传给Servlet的是StandardWrapperFacade对象，这个类能够保证从StandardWrapper中拿到 ServletConfig所规定的数据，而又不把ServletConfig不关心的数据暴露给Servlet。\n\n同样ServletContext也与ServletConfig有类似的结构，Servlet中能拿到的ServletContext的实际对象也是 ApplicationContextFacade对象。ApplicationContextFacade同样保证ServletContext只能从容器中拿到它该拿的数据，它们都起到对数据的封装作用，它们使用的都是门面设计模式。\n\n通过ServletContext可以拿到Context容器中一些必要信息，比如应用的工作路径，容器支持的Servlet最小版本等。\n\nTomcat一接受到请求首先将会创建org.apache.coyote.Request和org.apache.coyote.Response，这两个类是Tomcat内部使用的描述一次请求和响应的信息类，它们是一个轻量级的类，作用就是在服务器接收到请求后，经过简单解析将这个请求快速的分配给后续线程去处理，所以它们的对象很小，很容易被JVM回收。\n\n接下去当交给一个用户线程去处理这个请求时又创建org.apache.catalina.connector.Request和org.apache.catalina.connector.Response对象。这两个对象一直穿越整个Servlet容器直到要传给Servlet，传给Servlet的是Request和Response的门面类RequestFacade和RequestFacade，这里使用门面模式与前面一样都是基于同样的目的——封装容器中的数据。一次请求对应的Request和Response的类转化如下图所示：\n\n![](http://pic.yupoo.com/kazaff_v/DSr8j5Tq/ri7Eh.jpg)\n\nServlet如何工作\n---\n我们已经清楚了Servlet是如何被加载的，Servlet是如何被初始化的，以及Servlet的体系结构，现在的问题是它如何被调用？\n\n当用户从浏览器向服务器发起一个请求，通常包含如下信息：**http://hostname:port/contextpath/servetpath**，hostname和port是用来与服务器建立tcp连接的，而后面的URL才是用来选择服务器中哪个子容器服务用户的请求。\n\n根据URL来映射正确的Servlet容器的工作有专门的一个类来完成：org.apache.tomcat.util.http.mapper，这个类保存了Tomcat的Container容器中的所有子容器的信息，当org.apache.catalina.connector.Request类在进入Container容器之前，mapper将会根据这次请求的hostname和contextpath将host和context容器设置到Request的mappingData属性中。所以当Request进入Container容器之前就已经确定了它要访问哪个子容器了！看下图：\n\n![](http://pic.yupoo.com/kazaff_v/DSrk9Yhb/3hHbN.jpg)\n\n上图描述了一次Request请求是如何达到最终的Wrapper容器的，我们现正知道了请求是如何达到正确的Wrapper容器，但是请求到达最终的Servlet还要完成一些步骤，必须要执行Filter链，以及要通知你在web.xml中定义的listener。\n\n接下去就要执行Servlet的service方法了，通常情况下，我们自己定义的servlet并不是直接去实现javax.servlet.servlet接口，而是去继承更简单的HttpServlet类或者GenericServlet类，我们可以有选择的覆盖相应方法去实现我们要完成的工作。\n\nServlet的确已经能够帮我们完成所有的工作了，但是现在的web应用很少有直接将交互全部页面都用servlet来实现，而是采用更加高效的MVC框架来实现。这些MVC框架基本的原理都是将所有的请求都映射到一个Servlet，然后去实现service方法，这个方法也就是MVC框架的入口。\n\n当Servlet从Servlet容器中移除时，也就表明该Servlet的生命周期结束了，这时Servlet的destroy方法将被调用，做一些扫尾工作。\n\nSession与Cookie\n---\n\n![](http://pic.yupoo.com/kazaff_v/DSrB5KEx/XhS9F.jpg)\n\n从上图可以看到Session工作的时序图，有了Session ID服务器端就可以创建HttpSession对象了，第一次触发是通过request.getSession()方法，如果当前的Session ID还没有对应的HttpSession对象那么就创建一个新的，并将这个对象加到 org.apache.catalina.Manager的sessions容器中保存，Manager类将管理所有Session的生命周期，Session过期将被回收，服务器关闭，Session将被序列化到磁盘等。只要这个HttpSession对象存在，用户就可以根据Session ID来获取到这个对象，也就达到了状态的保持。\n\n\n引用[原文](http://www.ibm.com/developerworks/cn/java/j-lo-servlet/)\n\n","slug":"是什么系列之Servlet","published":1,"updated":"2016-05-14T07:46:20.000Z","_id":"cica18ykt001tgtfye15ccko3","comments":1,"layout":"post","photos":[],"link":"","content":"<p>公司已经开始大面积转型j2ee，正在使用的是整套java web的技术解决方案：Tomcat+springMVC+jdbc。作为一个从php转型过来的程序猿，还是需要好好消化一下java web开发的一些基础概念的。实不相瞒，我就一直闹不懂什么是Servlet，总是无法正确的理解它的作用及位置~<br><a id=\"more\"></a><br>刚好今天有时间，就找了篇不错的技术贴好好科普一下，下面记录一些相关重点。</p>\n<p>首先，先看一下我们要解决的疑惑：</p>\n<ol>\n<li>以Tomcat为例了解Servlet容器是如何工作的？</li>\n<li>一个Web工程在Servlet容器中是如何启动的？</li>\n<li>Servlet容器如何解析你在web.xml中定义的Servlet？</li>\n<li>用户的请求是如何被分配给指定的Servlet的？</li>\n<li>Servlet容器如何管理Servlet生命周期？</li>\n</ol>\n<h2 id=\"先从Servlet容器聊起\"><a href=\"#先从Servlet容器聊起\" class=\"headerlink\" title=\"先从Servlet容器聊起\"></a>先从Servlet容器聊起</h2><p>Servlet和Servlet容器，从名字上来猜，就想水和器皿，之所以独立出两个东西，完全是为了满足工业化生产，也就是说是为了解耦，通过标准接口来让这两个东西协作从而完成实际需求。</p>\n<p>目前成熟的Servlet容器产品很多，像Jetty，Tomcat都是java web开发人员耳熟能详的。我们下面就以Tomcat为例来讲一下Servlet容器如何管理Servlet的。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSjSZM95/KxYyT.jpg\" alt=\"\"></p>\n<p>从上图可以看出，Tomcat的容器分为四个等级，真正管理Servlet的是Context容器，可以看到，一个Context对应一个web工程，这在Tomcat配置文件里也可以很容易的发现这一点：</p>\n<pre><code>&lt;Context path=&quot;/projectOne &quot; docBase=&quot;D:\\projects\\projectOne&quot; reloadable=&quot;true&quot; /&gt;\n</code></pre><h2 id=\"Servlet容器的启动过程\"><a href=\"#Servlet容器的启动过程\" class=\"headerlink\" title=\"Servlet容器的启动过程\"></a>Servlet容器的启动过程</h2><p>我们已经知道，一个Web项目对应一个Context容器，也就是Servlet运行时的Servlet容器，添加一个Web应用时将会创建一个StandardContext容器，并且给这个Context容器设置别要的参数（url，path等）。</p>\n<p>下面看一张时序图，来分析一下Tomcat的启动过程：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSjXuOA2/6kRPD.jpg\" alt=\"\"></p>\n<p>上图描述的主要是类之间的时序关系，我们主要关注StandardContext容器的启动过程。</p>\n<p>当Context容器初始化状态设为init时，添加在Context容器上的Listener将会被调用，我们主要看一下ContextConfig做了什么，这个类会负责整个Web应用的配置文件的解析工作：</p>\n<ol>\n<li>创建用于解析xml配置文件的contextDigester对象</li>\n<li>读取默认context.xml配置文件，如果存在则解析它</li>\n<li>读取默认Host配置文件，如果存在则解析它</li>\n<li>读取默认Context自身的配置文件，如果存在则解析它</li>\n<li>设置Context的DocBase</li>\n</ol>\n<p>ContextConfig的init方法完成后，Context容器会执行startInternal方法，主要做的是：</p>\n<ol>\n<li>创建读取资源文件的对象</li>\n<li>创建ClassLoader对象</li>\n<li>设置应用的工作目录</li>\n<li>启动相关的辅助类，如：logger，realm，resources等</li>\n<li>修改启动状态，通知感兴趣的观察者（web应用的配置）</li>\n<li>子容器的初始化</li>\n<li>获取ServletContext并设置必要的参数</li>\n<li>初始化“load on startup”的Servlet</li>\n</ol>\n<p>Web应用的初始化工作实在ContextConfig的configureStart方法中实现的，应用的初始化主要是要解析web.xml文件，这个文件描述了一个web应用的关键信息，也是一个web应用的入口。</p>\n<p>Tomcat首先会创建globalWebXml对象，接着是hostWebXml对象，再然后是对应应用的WebXml对象。Tomcat会将ContextConfig从web.xml文件中解析出的各项属性保存在WebXml对象中。再然后会将WebXml对象中的属性设置到Context容器中，这里面包括创建的Servlet对象，filter，listener等等，这个工作在WebXml的configureContext方法中完成，在该方法中会将Servlet包装成Context容器中的StandardWrapper，为什么要将Servlet包装成StandardWrapper而不直接创建Servlet对象呢？这是因为StandardWrapper是Tomcat容器的一部分，它具有容器的特征，而Servlet是一个独立的Web开发标准，不应该强耦合在Tomcat中。</p>\n<p>除了将Servlet包装成StandardWrapper并作为子容器添加到Context中，其它的所有web.xml属性都被解析到Context中，所以说Context容器才是真正运行Servlet的Servlet容器。一个Web应用对应一个Context容器，容器的配置属性由应用的web.xml指定，这样我们就能理解web.xml到底起到什么作用了。</p>\n<h2 id=\"创建Servlet实例\"><a href=\"#创建Servlet实例\" class=\"headerlink\" title=\"创建Servlet实例\"></a>创建Servlet实例</h2><p>我们已经完成了Servlet的解析工作，并且被包装成StandardWrapper添加在Context容器中，但它仍然不能工作，因为我们还没有实例化它。</p>\n<p>如果Servlet的load-on-startup配置项大于0，那么在Context容器启动的时候就会实例化它，之前提到在解析配置文件时会读取在Tomcat目录下的Conf文件夹下的Web.xml文件的默认配置项，用来创建globalWebXml，其定义了两个Servlet，分别是：org.apache.catalina.servlets.DefaultServlet 和 org.apache.jasper.servlet.JspServlet 它们的 load-on-startup 分别是 1 和 3，也就是当Tomcat启动时这两个Servlet就会被实例化。</p>\n<p>创建Servlet实例的方法是从Wrapper.loadServlet开始的，该方法要完成的就是获取servletClass，然后把它交给InstanceManager去创建一个基于servletClass.class的对象，并且如果这个Servlet配置了jsp-file，那么这个servletClass就是conf/web.xml中定义的org.apache.jasper.servlet.JspServlet了！</p>\n<h2 id=\"初始化Servlet\"><a href=\"#初始化Servlet\" class=\"headerlink\" title=\"初始化Servlet\"></a>初始化Servlet</h2><p>初始化Servlet这个工作是在StandardWrapper的initServlet方法中完成的，这个方法很简单，就是调用Servlet的init方法，同时把包装了StandarWrapper对象的StandardWrappFacade作为ServletConfig传递给Servlet，原因待会在说~</p>\n<p>如果该Servlet关联的是一个jsp文件，那么在前面初始化的就是JspServlet，接下去会模拟一次简单的请求，请求调用这个jsp文件，以便编译这个jsp文件为class，并初始化这个class。</p>\n<p>这样Servlet对象就初始化完成了，事实上Servlet从被 web.xml 中解析到完成初始化，这个过程非常复杂，中间有很多过程，包括各种容器状态的转化引起的监听事件的触发、各种访问权限的控制和一些不可预料的错误发生的判断行为等等。我们这里只抓了一些关键环节进行阐述，试图让大家有个总体脉络。</p>\n<p>下面看一下时序图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSl5s0re/X35p4.jpg\" alt=\"\"></p>\n<h2 id=\"Servlet体系结构\"><a href=\"#Servlet体系结构\" class=\"headerlink\" title=\"Servlet体系结构\"></a>Servlet体系结构</h2><p><img src=\"http://pic.yupoo.com/kazaff/DSladGCE/xeHEC.jpg\" alt=\"\"></p>\n<p>上图可以看出，Servlet规范就是基于这几个类运转的，与Servlet主动关联的是三个类：ServletConfig，ServletRequest和ServletResponse。这三个类都是通过容器传递给Servlet的，其中ServletConfig是在Servlet初始化时就传递给Servlet的（前面我们提到了）。而后面这两个是在请求到达时调用Servlet时传参过来的。</p>\n<p>那么，ServletConfig和ServletContex对Servlet有何作用呢？从ServletConfig的接口中声明的方法不难看出，这些方法都是为了获取这个Servlet的一些配置属性，而这些配置属性可能在Servlet运行时会被用到。</p>\n<p>而ServletContext的作用呢？这里提到了Servlet的运行模式，Servlet的运行模式是一个典型的“握手型的交互式”运行模式。所谓“握手型的交互式”就是两个模块为了交换数据通常都会准备一个交易场景，这个场景一直跟随个这个交易过程直到这个交易完成为止。这个交易场景的初始化是根据这次交易对象指定的参数来定制的，这些指定参数通常就会是一个配置类。所以对号入座，交易场景就由ServletContext来描述，而定制的参数集合就由ServletConfig来描述。而ServletRequest和ServletResponse就是要交互的具体对象了，它们通常都是作为运输工具来传递交互结果。</p>\n<p>下图是ServletConfig和ServletContex在Tomcat容器中的类关系图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSliYtlh/9JjIN.jpg\" alt=\"\"></p>\n<p>上图可以看出StandardWrapper和StandardWrapperFacade都实现了ServletConfig接口，而StandardWrapperFacade是 StandardWrapper门面类。所以传给Servlet的是StandardWrapperFacade对象，这个类能够保证从StandardWrapper中拿到 ServletConfig所规定的数据，而又不把ServletConfig不关心的数据暴露给Servlet。</p>\n<p>同样ServletContext也与ServletConfig有类似的结构，Servlet中能拿到的ServletContext的实际对象也是 ApplicationContextFacade对象。ApplicationContextFacade同样保证ServletContext只能从容器中拿到它该拿的数据，它们都起到对数据的封装作用，它们使用的都是门面设计模式。</p>\n<p>通过ServletContext可以拿到Context容器中一些必要信息，比如应用的工作路径，容器支持的Servlet最小版本等。</p>\n<p>Tomcat一接受到请求首先将会创建org.apache.coyote.Request和org.apache.coyote.Response，这两个类是Tomcat内部使用的描述一次请求和响应的信息类，它们是一个轻量级的类，作用就是在服务器接收到请求后，经过简单解析将这个请求快速的分配给后续线程去处理，所以它们的对象很小，很容易被JVM回收。</p>\n<p>接下去当交给一个用户线程去处理这个请求时又创建org.apache.catalina.connector.Request和org.apache.catalina.connector.Response对象。这两个对象一直穿越整个Servlet容器直到要传给Servlet，传给Servlet的是Request和Response的门面类RequestFacade和RequestFacade，这里使用门面模式与前面一样都是基于同样的目的——封装容器中的数据。一次请求对应的Request和Response的类转化如下图所示：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSr8j5Tq/ri7Eh.jpg\" alt=\"\"></p>\n<h2 id=\"Servlet如何工作\"><a href=\"#Servlet如何工作\" class=\"headerlink\" title=\"Servlet如何工作\"></a>Servlet如何工作</h2><p>我们已经清楚了Servlet是如何被加载的，Servlet是如何被初始化的，以及Servlet的体系结构，现在的问题是它如何被调用？</p>\n<p>当用户从浏览器向服务器发起一个请求，通常包含如下信息：<strong><a href=\"http://hostname:port/contextpath/servetpath\" target=\"_blank\" rel=\"external\">http://hostname:port/contextpath/servetpath</a></strong>，hostname和port是用来与服务器建立tcp连接的，而后面的URL才是用来选择服务器中哪个子容器服务用户的请求。</p>\n<p>根据URL来映射正确的Servlet容器的工作有专门的一个类来完成：org.apache.tomcat.util.http.mapper，这个类保存了Tomcat的Container容器中的所有子容器的信息，当org.apache.catalina.connector.Request类在进入Container容器之前，mapper将会根据这次请求的hostname和contextpath将host和context容器设置到Request的mappingData属性中。所以当Request进入Container容器之前就已经确定了它要访问哪个子容器了！看下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSrk9Yhb/3hHbN.jpg\" alt=\"\"></p>\n<p>上图描述了一次Request请求是如何达到最终的Wrapper容器的，我们现正知道了请求是如何达到正确的Wrapper容器，但是请求到达最终的Servlet还要完成一些步骤，必须要执行Filter链，以及要通知你在web.xml中定义的listener。</p>\n<p>接下去就要执行Servlet的service方法了，通常情况下，我们自己定义的servlet并不是直接去实现javax.servlet.servlet接口，而是去继承更简单的HttpServlet类或者GenericServlet类，我们可以有选择的覆盖相应方法去实现我们要完成的工作。</p>\n<p>Servlet的确已经能够帮我们完成所有的工作了，但是现在的web应用很少有直接将交互全部页面都用servlet来实现，而是采用更加高效的MVC框架来实现。这些MVC框架基本的原理都是将所有的请求都映射到一个Servlet，然后去实现service方法，这个方法也就是MVC框架的入口。</p>\n<p>当Servlet从Servlet容器中移除时，也就表明该Servlet的生命周期结束了，这时Servlet的destroy方法将被调用，做一些扫尾工作。</p>\n<h2 id=\"Session与Cookie\"><a href=\"#Session与Cookie\" class=\"headerlink\" title=\"Session与Cookie\"></a>Session与Cookie</h2><p><img src=\"http://pic.yupoo.com/kazaff_v/DSrB5KEx/XhS9F.jpg\" alt=\"\"></p>\n<p>从上图可以看到Session工作的时序图，有了Session ID服务器端就可以创建HttpSession对象了，第一次触发是通过request.getSession()方法，如果当前的Session ID还没有对应的HttpSession对象那么就创建一个新的，并将这个对象加到 org.apache.catalina.Manager的sessions容器中保存，Manager类将管理所有Session的生命周期，Session过期将被回收，服务器关闭，Session将被序列化到磁盘等。只要这个HttpSession对象存在，用户就可以根据Session ID来获取到这个对象，也就达到了状态的保持。</p>\n<p>引用<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-servlet/\" target=\"_blank\" rel=\"external\">原文</a></p>\n","excerpt":"<p>公司已经开始大面积转型j2ee，正在使用的是整套java web的技术解决方案：Tomcat+springMVC+jdbc。作为一个从php转型过来的程序猿，还是需要好好消化一下java web开发的一些基础概念的。实不相瞒，我就一直闹不懂什么是Servlet，总是无法正确的理解它的作用及位置~<br>","more":"<br>刚好今天有时间，就找了篇不错的技术贴好好科普一下，下面记录一些相关重点。</p>\n<p>首先，先看一下我们要解决的疑惑：</p>\n<ol>\n<li>以Tomcat为例了解Servlet容器是如何工作的？</li>\n<li>一个Web工程在Servlet容器中是如何启动的？</li>\n<li>Servlet容器如何解析你在web.xml中定义的Servlet？</li>\n<li>用户的请求是如何被分配给指定的Servlet的？</li>\n<li>Servlet容器如何管理Servlet生命周期？</li>\n</ol>\n<h2 id=\"先从Servlet容器聊起\"><a href=\"#先从Servlet容器聊起\" class=\"headerlink\" title=\"先从Servlet容器聊起\"></a>先从Servlet容器聊起</h2><p>Servlet和Servlet容器，从名字上来猜，就想水和器皿，之所以独立出两个东西，完全是为了满足工业化生产，也就是说是为了解耦，通过标准接口来让这两个东西协作从而完成实际需求。</p>\n<p>目前成熟的Servlet容器产品很多，像Jetty，Tomcat都是java web开发人员耳熟能详的。我们下面就以Tomcat为例来讲一下Servlet容器如何管理Servlet的。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSjSZM95/KxYyT.jpg\" alt=\"\"></p>\n<p>从上图可以看出，Tomcat的容器分为四个等级，真正管理Servlet的是Context容器，可以看到，一个Context对应一个web工程，这在Tomcat配置文件里也可以很容易的发现这一点：</p>\n<pre><code>&lt;Context path=&quot;/projectOne &quot; docBase=&quot;D:\\projects\\projectOne&quot; reloadable=&quot;true&quot; /&gt;\n</code></pre><h2 id=\"Servlet容器的启动过程\"><a href=\"#Servlet容器的启动过程\" class=\"headerlink\" title=\"Servlet容器的启动过程\"></a>Servlet容器的启动过程</h2><p>我们已经知道，一个Web项目对应一个Context容器，也就是Servlet运行时的Servlet容器，添加一个Web应用时将会创建一个StandardContext容器，并且给这个Context容器设置别要的参数（url，path等）。</p>\n<p>下面看一张时序图，来分析一下Tomcat的启动过程：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSjXuOA2/6kRPD.jpg\" alt=\"\"></p>\n<p>上图描述的主要是类之间的时序关系，我们主要关注StandardContext容器的启动过程。</p>\n<p>当Context容器初始化状态设为init时，添加在Context容器上的Listener将会被调用，我们主要看一下ContextConfig做了什么，这个类会负责整个Web应用的配置文件的解析工作：</p>\n<ol>\n<li>创建用于解析xml配置文件的contextDigester对象</li>\n<li>读取默认context.xml配置文件，如果存在则解析它</li>\n<li>读取默认Host配置文件，如果存在则解析它</li>\n<li>读取默认Context自身的配置文件，如果存在则解析它</li>\n<li>设置Context的DocBase</li>\n</ol>\n<p>ContextConfig的init方法完成后，Context容器会执行startInternal方法，主要做的是：</p>\n<ol>\n<li>创建读取资源文件的对象</li>\n<li>创建ClassLoader对象</li>\n<li>设置应用的工作目录</li>\n<li>启动相关的辅助类，如：logger，realm，resources等</li>\n<li>修改启动状态，通知感兴趣的观察者（web应用的配置）</li>\n<li>子容器的初始化</li>\n<li>获取ServletContext并设置必要的参数</li>\n<li>初始化“load on startup”的Servlet</li>\n</ol>\n<p>Web应用的初始化工作实在ContextConfig的configureStart方法中实现的，应用的初始化主要是要解析web.xml文件，这个文件描述了一个web应用的关键信息，也是一个web应用的入口。</p>\n<p>Tomcat首先会创建globalWebXml对象，接着是hostWebXml对象，再然后是对应应用的WebXml对象。Tomcat会将ContextConfig从web.xml文件中解析出的各项属性保存在WebXml对象中。再然后会将WebXml对象中的属性设置到Context容器中，这里面包括创建的Servlet对象，filter，listener等等，这个工作在WebXml的configureContext方法中完成，在该方法中会将Servlet包装成Context容器中的StandardWrapper，为什么要将Servlet包装成StandardWrapper而不直接创建Servlet对象呢？这是因为StandardWrapper是Tomcat容器的一部分，它具有容器的特征，而Servlet是一个独立的Web开发标准，不应该强耦合在Tomcat中。</p>\n<p>除了将Servlet包装成StandardWrapper并作为子容器添加到Context中，其它的所有web.xml属性都被解析到Context中，所以说Context容器才是真正运行Servlet的Servlet容器。一个Web应用对应一个Context容器，容器的配置属性由应用的web.xml指定，这样我们就能理解web.xml到底起到什么作用了。</p>\n<h2 id=\"创建Servlet实例\"><a href=\"#创建Servlet实例\" class=\"headerlink\" title=\"创建Servlet实例\"></a>创建Servlet实例</h2><p>我们已经完成了Servlet的解析工作，并且被包装成StandardWrapper添加在Context容器中，但它仍然不能工作，因为我们还没有实例化它。</p>\n<p>如果Servlet的load-on-startup配置项大于0，那么在Context容器启动的时候就会实例化它，之前提到在解析配置文件时会读取在Tomcat目录下的Conf文件夹下的Web.xml文件的默认配置项，用来创建globalWebXml，其定义了两个Servlet，分别是：org.apache.catalina.servlets.DefaultServlet 和 org.apache.jasper.servlet.JspServlet 它们的 load-on-startup 分别是 1 和 3，也就是当Tomcat启动时这两个Servlet就会被实例化。</p>\n<p>创建Servlet实例的方法是从Wrapper.loadServlet开始的，该方法要完成的就是获取servletClass，然后把它交给InstanceManager去创建一个基于servletClass.class的对象，并且如果这个Servlet配置了jsp-file，那么这个servletClass就是conf/web.xml中定义的org.apache.jasper.servlet.JspServlet了！</p>\n<h2 id=\"初始化Servlet\"><a href=\"#初始化Servlet\" class=\"headerlink\" title=\"初始化Servlet\"></a>初始化Servlet</h2><p>初始化Servlet这个工作是在StandardWrapper的initServlet方法中完成的，这个方法很简单，就是调用Servlet的init方法，同时把包装了StandarWrapper对象的StandardWrappFacade作为ServletConfig传递给Servlet，原因待会在说~</p>\n<p>如果该Servlet关联的是一个jsp文件，那么在前面初始化的就是JspServlet，接下去会模拟一次简单的请求，请求调用这个jsp文件，以便编译这个jsp文件为class，并初始化这个class。</p>\n<p>这样Servlet对象就初始化完成了，事实上Servlet从被 web.xml 中解析到完成初始化，这个过程非常复杂，中间有很多过程，包括各种容器状态的转化引起的监听事件的触发、各种访问权限的控制和一些不可预料的错误发生的判断行为等等。我们这里只抓了一些关键环节进行阐述，试图让大家有个总体脉络。</p>\n<p>下面看一下时序图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSl5s0re/X35p4.jpg\" alt=\"\"></p>\n<h2 id=\"Servlet体系结构\"><a href=\"#Servlet体系结构\" class=\"headerlink\" title=\"Servlet体系结构\"></a>Servlet体系结构</h2><p><img src=\"http://pic.yupoo.com/kazaff/DSladGCE/xeHEC.jpg\" alt=\"\"></p>\n<p>上图可以看出，Servlet规范就是基于这几个类运转的，与Servlet主动关联的是三个类：ServletConfig，ServletRequest和ServletResponse。这三个类都是通过容器传递给Servlet的，其中ServletConfig是在Servlet初始化时就传递给Servlet的（前面我们提到了）。而后面这两个是在请求到达时调用Servlet时传参过来的。</p>\n<p>那么，ServletConfig和ServletContex对Servlet有何作用呢？从ServletConfig的接口中声明的方法不难看出，这些方法都是为了获取这个Servlet的一些配置属性，而这些配置属性可能在Servlet运行时会被用到。</p>\n<p>而ServletContext的作用呢？这里提到了Servlet的运行模式，Servlet的运行模式是一个典型的“握手型的交互式”运行模式。所谓“握手型的交互式”就是两个模块为了交换数据通常都会准备一个交易场景，这个场景一直跟随个这个交易过程直到这个交易完成为止。这个交易场景的初始化是根据这次交易对象指定的参数来定制的，这些指定参数通常就会是一个配置类。所以对号入座，交易场景就由ServletContext来描述，而定制的参数集合就由ServletConfig来描述。而ServletRequest和ServletResponse就是要交互的具体对象了，它们通常都是作为运输工具来传递交互结果。</p>\n<p>下图是ServletConfig和ServletContex在Tomcat容器中的类关系图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DSliYtlh/9JjIN.jpg\" alt=\"\"></p>\n<p>上图可以看出StandardWrapper和StandardWrapperFacade都实现了ServletConfig接口，而StandardWrapperFacade是 StandardWrapper门面类。所以传给Servlet的是StandardWrapperFacade对象，这个类能够保证从StandardWrapper中拿到 ServletConfig所规定的数据，而又不把ServletConfig不关心的数据暴露给Servlet。</p>\n<p>同样ServletContext也与ServletConfig有类似的结构，Servlet中能拿到的ServletContext的实际对象也是 ApplicationContextFacade对象。ApplicationContextFacade同样保证ServletContext只能从容器中拿到它该拿的数据，它们都起到对数据的封装作用，它们使用的都是门面设计模式。</p>\n<p>通过ServletContext可以拿到Context容器中一些必要信息，比如应用的工作路径，容器支持的Servlet最小版本等。</p>\n<p>Tomcat一接受到请求首先将会创建org.apache.coyote.Request和org.apache.coyote.Response，这两个类是Tomcat内部使用的描述一次请求和响应的信息类，它们是一个轻量级的类，作用就是在服务器接收到请求后，经过简单解析将这个请求快速的分配给后续线程去处理，所以它们的对象很小，很容易被JVM回收。</p>\n<p>接下去当交给一个用户线程去处理这个请求时又创建org.apache.catalina.connector.Request和org.apache.catalina.connector.Response对象。这两个对象一直穿越整个Servlet容器直到要传给Servlet，传给Servlet的是Request和Response的门面类RequestFacade和RequestFacade，这里使用门面模式与前面一样都是基于同样的目的——封装容器中的数据。一次请求对应的Request和Response的类转化如下图所示：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSr8j5Tq/ri7Eh.jpg\" alt=\"\"></p>\n<h2 id=\"Servlet如何工作\"><a href=\"#Servlet如何工作\" class=\"headerlink\" title=\"Servlet如何工作\"></a>Servlet如何工作</h2><p>我们已经清楚了Servlet是如何被加载的，Servlet是如何被初始化的，以及Servlet的体系结构，现在的问题是它如何被调用？</p>\n<p>当用户从浏览器向服务器发起一个请求，通常包含如下信息：<strong><a href=\"http://hostname:port/contextpath/servetpath\">http://hostname:port/contextpath/servetpath</a></strong>，hostname和port是用来与服务器建立tcp连接的，而后面的URL才是用来选择服务器中哪个子容器服务用户的请求。</p>\n<p>根据URL来映射正确的Servlet容器的工作有专门的一个类来完成：org.apache.tomcat.util.http.mapper，这个类保存了Tomcat的Container容器中的所有子容器的信息，当org.apache.catalina.connector.Request类在进入Container容器之前，mapper将会根据这次请求的hostname和contextpath将host和context容器设置到Request的mappingData属性中。所以当Request进入Container容器之前就已经确定了它要访问哪个子容器了！看下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSrk9Yhb/3hHbN.jpg\" alt=\"\"></p>\n<p>上图描述了一次Request请求是如何达到最终的Wrapper容器的，我们现正知道了请求是如何达到正确的Wrapper容器，但是请求到达最终的Servlet还要完成一些步骤，必须要执行Filter链，以及要通知你在web.xml中定义的listener。</p>\n<p>接下去就要执行Servlet的service方法了，通常情况下，我们自己定义的servlet并不是直接去实现javax.servlet.servlet接口，而是去继承更简单的HttpServlet类或者GenericServlet类，我们可以有选择的覆盖相应方法去实现我们要完成的工作。</p>\n<p>Servlet的确已经能够帮我们完成所有的工作了，但是现在的web应用很少有直接将交互全部页面都用servlet来实现，而是采用更加高效的MVC框架来实现。这些MVC框架基本的原理都是将所有的请求都映射到一个Servlet，然后去实现service方法，这个方法也就是MVC框架的入口。</p>\n<p>当Servlet从Servlet容器中移除时，也就表明该Servlet的生命周期结束了，这时Servlet的destroy方法将被调用，做一些扫尾工作。</p>\n<h2 id=\"Session与Cookie\"><a href=\"#Session与Cookie\" class=\"headerlink\" title=\"Session与Cookie\"></a>Session与Cookie</h2><p><img src=\"http://pic.yupoo.com/kazaff_v/DSrB5KEx/XhS9F.jpg\" alt=\"\"></p>\n<p>从上图可以看到Session工作的时序图，有了Session ID服务器端就可以创建HttpSession对象了，第一次触发是通过request.getSession()方法，如果当前的Session ID还没有对应的HttpSession对象那么就创建一个新的，并将这个对象加到 org.apache.catalina.Manager的sessions容器中保存，Manager类将管理所有Session的生命周期，Session过期将被回收，服务器关闭，Session将被序列化到磁盘等。只要这个HttpSession对象存在，用户就可以根据Session ID来获取到这个对象，也就达到了状态的保持。</p>\n<p>引用<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-servlet/\">原文</a></p>"},{"title":"是什么系列之RMI","date":"2014-07-18T01:18:12.000Z","_content":"\n转型Java阵营没多久，就面对企业级的需求，所以大量的调研内容，“是什么系列”几乎都是针对javaEE领域的姿势，可见我最近是多么的充实啊~\n<!-- more -->\n这次记录一下关于RMI的科普知识，其实它比起之前的[Thrift](http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BThrift/)和[Avro](http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BAvro/)来说，已经非常的轻量级了~~\n\nRMI（Remote Method Invocation）是jdk1.1就已经存在的分布式应用解决方案，轻量简单是它最大的特点，广泛的应用在EJB中。如果我们的系统比较小，服务很少且很轻，并且不需要面向跨语言，那么RMI是一个比较理想的选择。\n\n在另外的一些场景，例如跨语言平台的分布式应用，RMI就显得过于简陋了，这个时候可能就需要其它的同类技术了~\n\nRMI是基于TCP协议的传递可序列化java对象字节数据的库，因此，在同等业务数据量的前提下，RMI的效率要高于基于SOAP规范的WebService。因此，RMI可以用在业务结构简单，要求实时性高的分布式应用中。\n\n设计角度上，java采用三层结构来实现RMI：客户端、服务端、注册表，这是很常见的基于服务的架构。具体细节可以从下图看出：\n\n![](http://pic.yupoo.com/kazaff_v/DUIsJPar/149UNc.png)\n\n**客户端**一方包含：\n\n* 桩（Stub）：远程对象在客户端上的代理；\n* 远程引用层（Remote Reference Layer）：解析并执行远程引用协议，完成了调用的方法与服务对应地址的转换；\n* 传输层（Transport）：发送调用、传递远程方法参数、接受远程方法执行结果。\n\n**服务端**一方包含：\n\n* 骨架（Skeleton）：读取客户端传递的方法参数，调用服务器端的实际对象方法，并接受方法执行后的返回值；\n* 远程引用层（Remote Reference Layer）：处理远程引用语法之后向骨架发送远程方法调用；\n* 传输层（Transport）：监听客户端的入站连接，接受并转发调用到远程引用层。\n\n**注册表（Registry）**：以URL形式注册远程对象，并向客户端回复远程对象的引用。\n\n在实际的应用中，客户端并没有真正的和服务端直接对话来进行远程调用，而是通过本地JVM的桩对象来进行的。\n\n1. 客户端从远程服务器的注册表中查询并获得远程对象引用，当进行远程调用时，客户端首先会与桩对象进行对话，而这个桩对象将远程方法所需的参数序列化后，传递给它下层的远程引用层。\n2. 桩对象与远程对象具有相同的接口和方法列表，当客户端调用远程对象时，实际是由相对应的桩对象代理完成的。远程引用层在将桩的本地引用转换为服务器上对象的远程引用后，再将调用传递给传输层，有传输层通过tcp协议发送调用。\n3. 在服务器端，传输层监听入站连接，它一旦接受到客户端远程调用后，就将这个引用转发给其上层的远程引用。\n4. 服务端的远程引用层将客户端发送的远程引用转化为本地虚拟机的引用后，再将请求传递给骨架。\n5. 骨架读取参数，将请求传递给服务器，最后由服务器进行实际的方法调用。\n6. 如果远程方法调用后有返回值，则服务器将这些结果又沿着骨架->远程引用层->传输层向下传递。\n7. 客户端的传输层接受到返回值后，又沿着传输层->远程引用层->桩向上传递，最后由桩来反序列化这些返回值，并将最终结果传递给客户端程序。\n\n从这个流程上可以看出，java为我们隐藏了很多处理细节，开发者可以只关注业务细节。\n\n关于RMI的例子，网上非常的多，包括上面的内容，出自[这里](http://code727.iteye.com/blog/1874271)。\n\n","source":"_posts/是什么系列之RMI.md","raw":"title: 是什么系列之RMI\ndate: 2014-07-18 09:18:12\ntags: \n- tcp\n- 分布式\n- 是什么系列\ncategories: j2ee\n---\n\n转型Java阵营没多久，就面对企业级的需求，所以大量的调研内容，“是什么系列”几乎都是针对javaEE领域的姿势，可见我最近是多么的充实啊~\n<!-- more -->\n这次记录一下关于RMI的科普知识，其实它比起之前的[Thrift](http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BThrift/)和[Avro](http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BAvro/)来说，已经非常的轻量级了~~\n\nRMI（Remote Method Invocation）是jdk1.1就已经存在的分布式应用解决方案，轻量简单是它最大的特点，广泛的应用在EJB中。如果我们的系统比较小，服务很少且很轻，并且不需要面向跨语言，那么RMI是一个比较理想的选择。\n\n在另外的一些场景，例如跨语言平台的分布式应用，RMI就显得过于简陋了，这个时候可能就需要其它的同类技术了~\n\nRMI是基于TCP协议的传递可序列化java对象字节数据的库，因此，在同等业务数据量的前提下，RMI的效率要高于基于SOAP规范的WebService。因此，RMI可以用在业务结构简单，要求实时性高的分布式应用中。\n\n设计角度上，java采用三层结构来实现RMI：客户端、服务端、注册表，这是很常见的基于服务的架构。具体细节可以从下图看出：\n\n![](http://pic.yupoo.com/kazaff_v/DUIsJPar/149UNc.png)\n\n**客户端**一方包含：\n\n* 桩（Stub）：远程对象在客户端上的代理；\n* 远程引用层（Remote Reference Layer）：解析并执行远程引用协议，完成了调用的方法与服务对应地址的转换；\n* 传输层（Transport）：发送调用、传递远程方法参数、接受远程方法执行结果。\n\n**服务端**一方包含：\n\n* 骨架（Skeleton）：读取客户端传递的方法参数，调用服务器端的实际对象方法，并接受方法执行后的返回值；\n* 远程引用层（Remote Reference Layer）：处理远程引用语法之后向骨架发送远程方法调用；\n* 传输层（Transport）：监听客户端的入站连接，接受并转发调用到远程引用层。\n\n**注册表（Registry）**：以URL形式注册远程对象，并向客户端回复远程对象的引用。\n\n在实际的应用中，客户端并没有真正的和服务端直接对话来进行远程调用，而是通过本地JVM的桩对象来进行的。\n\n1. 客户端从远程服务器的注册表中查询并获得远程对象引用，当进行远程调用时，客户端首先会与桩对象进行对话，而这个桩对象将远程方法所需的参数序列化后，传递给它下层的远程引用层。\n2. 桩对象与远程对象具有相同的接口和方法列表，当客户端调用远程对象时，实际是由相对应的桩对象代理完成的。远程引用层在将桩的本地引用转换为服务器上对象的远程引用后，再将调用传递给传输层，有传输层通过tcp协议发送调用。\n3. 在服务器端，传输层监听入站连接，它一旦接受到客户端远程调用后，就将这个引用转发给其上层的远程引用。\n4. 服务端的远程引用层将客户端发送的远程引用转化为本地虚拟机的引用后，再将请求传递给骨架。\n5. 骨架读取参数，将请求传递给服务器，最后由服务器进行实际的方法调用。\n6. 如果远程方法调用后有返回值，则服务器将这些结果又沿着骨架->远程引用层->传输层向下传递。\n7. 客户端的传输层接受到返回值后，又沿着传输层->远程引用层->桩向上传递，最后由桩来反序列化这些返回值，并将最终结果传递给客户端程序。\n\n从这个流程上可以看出，java为我们隐藏了很多处理细节，开发者可以只关注业务细节。\n\n关于RMI的例子，网上非常的多，包括上面的内容，出自[这里](http://code727.iteye.com/blog/1874271)。\n\n","slug":"是什么系列之RMI","published":1,"updated":"2016-05-14T07:46:20.000Z","_id":"cica18yky0020gtfy2gfzz2sq","comments":1,"layout":"post","photos":[],"link":"","content":"<p>转型Java阵营没多久，就面对企业级的需求，所以大量的调研内容，“是什么系列”几乎都是针对javaEE领域的姿势，可见我最近是多么的充实啊~<br><a id=\"more\"></a><br>这次记录一下关于RMI的科普知识，其实它比起之前的<a href=\"http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BThrift/\">Thrift</a>和<a href=\"http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BAvro/\">Avro</a>来说，已经非常的轻量级了~~</p>\n<p>RMI（Remote Method Invocation）是jdk1.1就已经存在的分布式应用解决方案，轻量简单是它最大的特点，广泛的应用在EJB中。如果我们的系统比较小，服务很少且很轻，并且不需要面向跨语言，那么RMI是一个比较理想的选择。</p>\n<p>在另外的一些场景，例如跨语言平台的分布式应用，RMI就显得过于简陋了，这个时候可能就需要其它的同类技术了~</p>\n<p>RMI是基于TCP协议的传递可序列化java对象字节数据的库，因此，在同等业务数据量的前提下，RMI的效率要高于基于SOAP规范的WebService。因此，RMI可以用在业务结构简单，要求实时性高的分布式应用中。</p>\n<p>设计角度上，java采用三层结构来实现RMI：客户端、服务端、注册表，这是很常见的基于服务的架构。具体细节可以从下图看出：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DUIsJPar/149UNc.png\" alt=\"\"></p>\n<p><strong>客户端</strong>一方包含：</p>\n<ul>\n<li>桩（Stub）：远程对象在客户端上的代理；</li>\n<li>远程引用层（Remote Reference Layer）：解析并执行远程引用协议，完成了调用的方法与服务对应地址的转换；</li>\n<li>传输层（Transport）：发送调用、传递远程方法参数、接受远程方法执行结果。</li>\n</ul>\n<p><strong>服务端</strong>一方包含：</p>\n<ul>\n<li>骨架（Skeleton）：读取客户端传递的方法参数，调用服务器端的实际对象方法，并接受方法执行后的返回值；</li>\n<li>远程引用层（Remote Reference Layer）：处理远程引用语法之后向骨架发送远程方法调用；</li>\n<li>传输层（Transport）：监听客户端的入站连接，接受并转发调用到远程引用层。</li>\n</ul>\n<p><strong>注册表（Registry）</strong>：以URL形式注册远程对象，并向客户端回复远程对象的引用。</p>\n<p>在实际的应用中，客户端并没有真正的和服务端直接对话来进行远程调用，而是通过本地JVM的桩对象来进行的。</p>\n<ol>\n<li>客户端从远程服务器的注册表中查询并获得远程对象引用，当进行远程调用时，客户端首先会与桩对象进行对话，而这个桩对象将远程方法所需的参数序列化后，传递给它下层的远程引用层。</li>\n<li>桩对象与远程对象具有相同的接口和方法列表，当客户端调用远程对象时，实际是由相对应的桩对象代理完成的。远程引用层在将桩的本地引用转换为服务器上对象的远程引用后，再将调用传递给传输层，有传输层通过tcp协议发送调用。</li>\n<li>在服务器端，传输层监听入站连接，它一旦接受到客户端远程调用后，就将这个引用转发给其上层的远程引用。</li>\n<li>服务端的远程引用层将客户端发送的远程引用转化为本地虚拟机的引用后，再将请求传递给骨架。</li>\n<li>骨架读取参数，将请求传递给服务器，最后由服务器进行实际的方法调用。</li>\n<li>如果远程方法调用后有返回值，则服务器将这些结果又沿着骨架-&gt;远程引用层-&gt;传输层向下传递。</li>\n<li>客户端的传输层接受到返回值后，又沿着传输层-&gt;远程引用层-&gt;桩向上传递，最后由桩来反序列化这些返回值，并将最终结果传递给客户端程序。</li>\n</ol>\n<p>从这个流程上可以看出，java为我们隐藏了很多处理细节，开发者可以只关注业务细节。</p>\n<p>关于RMI的例子，网上非常的多，包括上面的内容，出自<a href=\"http://code727.iteye.com/blog/1874271\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n","excerpt":"<p>转型Java阵营没多久，就面对企业级的需求，所以大量的调研内容，“是什么系列”几乎都是针对javaEE领域的姿势，可见我最近是多么的充实啊~<br>","more":"<br>这次记录一下关于RMI的科普知识，其实它比起之前的<a href=\"http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BThrift/\">Thrift</a>和<a href=\"http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BAvro/\">Avro</a>来说，已经非常的轻量级了~~</p>\n<p>RMI（Remote Method Invocation）是jdk1.1就已经存在的分布式应用解决方案，轻量简单是它最大的特点，广泛的应用在EJB中。如果我们的系统比较小，服务很少且很轻，并且不需要面向跨语言，那么RMI是一个比较理想的选择。</p>\n<p>在另外的一些场景，例如跨语言平台的分布式应用，RMI就显得过于简陋了，这个时候可能就需要其它的同类技术了~</p>\n<p>RMI是基于TCP协议的传递可序列化java对象字节数据的库，因此，在同等业务数据量的前提下，RMI的效率要高于基于SOAP规范的WebService。因此，RMI可以用在业务结构简单，要求实时性高的分布式应用中。</p>\n<p>设计角度上，java采用三层结构来实现RMI：客户端、服务端、注册表，这是很常见的基于服务的架构。具体细节可以从下图看出：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DUIsJPar/149UNc.png\" alt=\"\"></p>\n<p><strong>客户端</strong>一方包含：</p>\n<ul>\n<li>桩（Stub）：远程对象在客户端上的代理；</li>\n<li>远程引用层（Remote Reference Layer）：解析并执行远程引用协议，完成了调用的方法与服务对应地址的转换；</li>\n<li>传输层（Transport）：发送调用、传递远程方法参数、接受远程方法执行结果。</li>\n</ul>\n<p><strong>服务端</strong>一方包含：</p>\n<ul>\n<li>骨架（Skeleton）：读取客户端传递的方法参数，调用服务器端的实际对象方法，并接受方法执行后的返回值；</li>\n<li>远程引用层（Remote Reference Layer）：处理远程引用语法之后向骨架发送远程方法调用；</li>\n<li>传输层（Transport）：监听客户端的入站连接，接受并转发调用到远程引用层。</li>\n</ul>\n<p><strong>注册表（Registry）</strong>：以URL形式注册远程对象，并向客户端回复远程对象的引用。</p>\n<p>在实际的应用中，客户端并没有真正的和服务端直接对话来进行远程调用，而是通过本地JVM的桩对象来进行的。</p>\n<ol>\n<li>客户端从远程服务器的注册表中查询并获得远程对象引用，当进行远程调用时，客户端首先会与桩对象进行对话，而这个桩对象将远程方法所需的参数序列化后，传递给它下层的远程引用层。</li>\n<li>桩对象与远程对象具有相同的接口和方法列表，当客户端调用远程对象时，实际是由相对应的桩对象代理完成的。远程引用层在将桩的本地引用转换为服务器上对象的远程引用后，再将调用传递给传输层，有传输层通过tcp协议发送调用。</li>\n<li>在服务器端，传输层监听入站连接，它一旦接受到客户端远程调用后，就将这个引用转发给其上层的远程引用。</li>\n<li>服务端的远程引用层将客户端发送的远程引用转化为本地虚拟机的引用后，再将请求传递给骨架。</li>\n<li>骨架读取参数，将请求传递给服务器，最后由服务器进行实际的方法调用。</li>\n<li>如果远程方法调用后有返回值，则服务器将这些结果又沿着骨架-&gt;远程引用层-&gt;传输层向下传递。</li>\n<li>客户端的传输层接受到返回值后，又沿着传输层-&gt;远程引用层-&gt;桩向上传递，最后由桩来反序列化这些返回值，并将最终结果传递给客户端程序。</li>\n</ol>\n<p>从这个流程上可以看出，java为我们隐藏了很多处理细节，开发者可以只关注业务细节。</p>\n<p>关于RMI的例子，网上非常的多，包括上面的内容，出自<a href=\"http://code727.iteye.com/blog/1874271\">这里</a>。</p>"},{"title":"是什么系列之Avro","date":"2014-07-07T03:13:12.000Z","_content":"\n今天来关注一下Avro，目的是想接触一下跨端RPC中间件中关于数据编解码及传输的相关技术，这和我目前负责的项目很有关系！那么先从网上找一些相关的文献来给自己科普一下~\n<!-- more -->\nAvro是Hadoop的一个子项目，也是Apache中的一个独立项目，它是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中（Hbase，Hive）的客户端与服务端的数据传输中被大量采用。听上去很给力啊？！\n\nAvro是一个数据序列化的系统，它可以将数据结构或对象转化成便于存储或传输的格式，Avro设计之初就定位为用来支持数据密集型应用，适用于远程或本地大规模数据的存储于交换，Avro支持的编程语言包括：C/C++，JAVA，Python，Ruby，PHP，C#，它的特点有：\n\n1. 丰富的数据结构类型\n2. 快速可压缩的二进制数据形式（对数据二进制序列化后可节约数据存储空间和网络传输带宽）\n3. 存储持久数据的文件容器\n4. 可实现远程过程调用(RPC)\n5. 简单的动态语言结合功能\n\nAvro和动态语言结合后，读写数据文件和使用RPC协议都不需要生成代码，而代码生成作为一种可选的优化只需要在静态类型语言中实现。\n\nAvro依赖于模式（Schema），通过模式定义各种数据结构，只有确定了模式才能对数据进行解释，所以在数据的序列化和反序列化之前，必须先确定模式的结构。同时可动态加载相关数据的模式，数据的读写都使用模式，这使得数据之间不存在任何其他标识（类比Thrift），这样就减少了开销，使得序列化快速又轻巧，同时这种数据及模式的自我描述也方便了动态脚本语言的使用。\n\n当数据存储到文件中时，它的模式也随之存储，这样任何程序都可以对文件进行处理。如果读取数据时使用的模式与写入时使用的模式不同，也容易解决，因为读取和写入的模式都是已知的。看下面这个规则：\n\n<table>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">新模式</th>\n<th align=\"left\">Writer</th>\n<th align=\"left\">Reader</th>\n<th align=\"left\">规则</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td align=\"left\">增加了字段</td>\n<td align=\"left\">采用旧的模式（新增前）</td>\n<td align=\"left\">采用新的模式</td>\n<td align=\"left\">Reader对新字段会使用其默认值（Writer不会为新增的字段赋值）</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"></td>\n<td align=\"left\">采用新的模式（新增后）</td>\n<td align=\"left\">采用旧的模式</td>\n<td align=\"left\">Reader会忽略掉新曾的字段，Writer会为新增字段赋值</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">减少了字段</td>\n<td align=\"left\">采用旧的模式（减少前）</td>\n<td align=\"left\">采用新的模式</td>\n<td align=\"left\">Reader会忽略已经被删除的字段</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"></td>\n<td align=\"left\">采用新的模式（减少后）</td>\n<td align=\"left\">采用旧的模式</td>\n<td align=\"left\">如果旧模式里被删除的那个字段有默认值，那么Reader会采用，否则，Reader会报错</td>\n</tr>\n</tbody>\n</table>\n\n类型\n---\n数据类型标准化的意义在于：\n\n1. 使不同系统对相同的数据能够正确解析\n2. 有利于数据序列化/反序列化\n\nAvro定义了几种简单数据类型，包括：null，boolean，int，long，float，double，bytes，string。简单数据类型有类型名称定义，不包含属性信息，如：\n\t{\"type\": \"string\"}\n\nAvro定义了六种复杂数据类型，每一种复杂数据类型都具有独特的属性，如下：\n\n**Records**：\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"名称json字符串[必填]\",\n\t\t\"namespace\": \"命名空间json字符串[选填]\",\n\t\t\"doc\": \"文档json字符串[选填]\"\n\t\t\"aliases\": \"别名json字符串数组[选填]\",\n\t\t\"fields\": [\t//json数组[必填]\n\t\t\t{\n\t\t\t\t\"name\": \"字段名\",\n\t\t\t\t\"type\": \"类型\",\n\t\t\t\t\"default\": \"默认值\",\n\t\t\t\t\"order\": \"字段顺序\"\n\t\t\t},\n\t\t\t....\n\t\t]\n\t}\n\n例如：\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"test\",\n\t\t\"fields\": [\n\t\t\t{\"name\": \"a\", \"type\": \"long\"},\n\t\t\t{\"name\": \"b\", \"type\": \"string\"}\n\t\t]\n\t}\n\n**Enums**：\n\n\t{\n\t\t\"type\": \"enum\",\n\t\t\"name\": \"名称json字符串[必填]\",\n\t\t\"namespace\": \"命名空间json字符串[选填]\",\n\t\t\"doc\": \"文档json字符串[选填]\"\n\t\t\"aliases\": \"别名json字符串数组[选填]\",\n\t\t\"symbols\": [ //json数组[必填]\n\t\t\t\"值json字符串[必填]，所有值必须是唯一的\"\n\t\t]\n\t}\n\n例如：\n\t\n\t{\n\t\t\"type\": \"enum\",\n\t\t\"name\": \"test\",\n\t\t\"symbols\": [\"k\", \"a\", \"z\", \"a\", \"ff\"]\n\t}\n\n**Arrays**：\n\n\t{\n\t\t\"type\": \"array\",\n\t\t\"items\": \"子元素模式\"\n\t}\n\n例如：\n\t\n\t{\n\t\t\"type\": \"array\",\n\t\t\"items\": \"long\"\n\t}\n\n**Maps**：\n\n\t{\n\t\t\"type\": \"map\",\n\t\t\"values\": \"值元素模式\"\n\t}\n\n\n**Fixed**：\n\n\t{\n\t\t\"type\": \"fixed\",\n\t\t\"name\": \"名称json字符串[必填]\",\n\t\t\"namespace\": \"命名空间json字符串[选填]\",\n\t\t\"aliases\": \"别名json字符串数组[选填]\",\n\t\t\"size\" : \"整型，指定每个值的字节数[必填]\"\n\t}\n\n**Unions**： json数组\n\n序列化/反序列化\n---\nAvro指定两种数据序列化编码方式：binary和json。使用二进制编码会高效序列化，并且序列化后得到的结果会比较小，而json一般用于调试系统或基于web应用。\n\n简单数据类型：\n\n<table>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">类型</th>\n<th align=\"left\">编码</th>\n<th align=\"left\">例子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">null</td>\n<td align=\"left\">0字节</td>\n<td align=\"left\">Null</td>\n</tr>\n<tr>\n<td align=\"left\">boolean</td>\n<td align=\"left\">1字节</td>\n<td align=\"left\">{true: 1, false: 0}</td>\n</tr>\n<tr>\n<td align=\"left\">int/long</td>\n<td align=\"left\">variable-length zig-zag coding</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">float</td>\n<td align=\"left\">4字节</td>\n<td align=\"left\">Java’s floatToIntBits</td>\n</tr>\n<tr>\n<td align=\"left\">double</td>\n<td align=\"left\">8字节</td>\n<td align=\"left\">Java’s floatToIntBits</td>\n</tr>\n<tr>\n<td align=\"left\">bytes</td>\n<td align=\"left\">一个表示长度的long值，后跟指定长度的字节序列</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">string</td>\n<td align=\"left\">一个表示长度的long值，后跟UTF-8字符集的指定长度的字节序列</td>\n<td align=\"left\">“foo”:{3,f,o,o}</td>\n</tr>\n</tbody>\n</table>\n\n复杂数据类型：\n\n**records**类型会按字段声明的顺序串连编码值，例如下面这个record schema：\n\t\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"test\",\n\t\t\"fields\": [\n\t\t\t{\"name\": \"a\", \"type\": \"long\"},\n\t\t\t{\"name\": \"b\", \"type\": \"string\"}\n\t\t]\n\t}\n\n实例化这个record，假设给a字段赋值27(编码为0x36)，给b字段赋值“foo”(06 66 6f 6f，注意第一个06表示字符串长度3的编码值)，那么这个record编码结果为： 36 06 66 6f 6f\n\n**enum**被编码为一个int，比如：\n\t\n\t{\n\t\t\"type\": \"enum\",\n\t\t\"name\": \"test\",\n\t\t\"symbols\": [\"A\", \"B\", \"C\", \"D\"]\n\t}\n\n这将被编码为一个取值范围为[0，3]的int，0表示A，3表示D。\n\n**arrays**编码为block序列，每个block包含一个long的count值，紧跟着的是array items，一个block的count为0表示该block是array的结尾。\n\n**maps**编码为block序列，每个block包含一个long的count值，紧跟着的是key/value对，一个block的count为0表示该block是map的结尾。\n\n**union**编码以一个long值开始，表示后面的数据时union中的哪种数据类型。\n\n**fixed**编码为指定数目的字节。\n\n![](http://pic.yupoo.com/kazaff_v/DSBloaTw/wq4vh.jpg)\n\n上图表示的是Avro本地序列化和反序列化流程，Avro将用户定义的模式和具体的数据编码成二进制序列存储在对象容器文件中，例如用户定义了包含学号，姓名，院系和电话的学生模式，而Avro对其进行编码后存储在student.db文件中，其中存储数据的模式放在文件头的元数据中，这样读取的模式即使与写入的模式不同，也可以迅速的读取数据。假如另一个程序需要获取学生的姓名和电话，只需要定义包含姓名和电话的学生模式，然后用此模式去读取容器文件中的数据即可。\n\n排序\n---\nAvro为数据定义了一个标准的排列顺序，“比较”在很多时候都是经常被使用的对象之间的炒作，标准定义可以进行方便有效的比较和排序，同时标准的定义可以方便对Avro的二进制编码数据直接进行排序而不需要反序列化。\n\n只有当数据项包含相同的Schema时，数据之间的比较才有意义，比较按照Schema深度优先，从左至右的顺序递归进行，找到第一个不匹配即可终止比较。\n\n两个拥有相同模式的项的比较按照以下规则进行：\n\n1. null：总是相等\n2. int,long,float：按照数值大小\n3. boolean：flase在true之前\n4. string：按照字典顺序\n5. bytes，fixed：按照byte的字典顺序\n6. array：按照元素的字典顺序\n7. enum：按照符号在枚举中的位置\n8. record：按照域的字典顺序，如果指定了以下属性：\n\t1. ascending：域值的顺序不变\n\t2. descending：域值的顺序颠倒\n\t3. ignore：排序时忽略域值\n9. map：不可进行排序比较\n\n对象容器文件\n---\nAvro定义了一个简单的对象容器文件格式，一个文件对应一个模式，所有存储在文件中的对象都是根据模式写入的，对象按照块进行存数，块可以采用压缩的方式存储。为了在进行MapReduce处理的时候有效的切分文件，在块之间采用了同步记号。\n\n![](http://pic.yupoo.com/kazaff_v/DSBxUm94/VtHbS.jpg)\n\n一个文件有两部分组成：文件头(Header)和一个或多个文件的数据块(Data Block)。而头信息由由三部分构成：四个字节的前缀，文件Meta-data信息和随机生成的16字节同步标记符。目前Avro支持的Meta-data有两种：schema和codec。\n\ncodec表示对后面的文件数据块采用何种压缩方式。Avro的实现都需要支持下面两种压缩方式：null（不压缩）和deflate（使用Deflate算法压缩数据块）。除了文档中认定的两种Meta-data，用户也可以自定义适用于自己的Meta-data，这里用long型来表示有多少个Meta-data数据对，也是让用户在实际应用中可以定义足够的Meta-data信息。\n\n对于每对Meta-data信息，都有一个string型的key（要以“avro.”为前缀）和二进制编码后的value。由于对象可以组织成不同的块，使用时就可以不经过反序列化而对某个数据块进行操作。还可以由数据块数，对象数和同步标记符来定位损坏的块以确保数据完整性。\n\nRPC\n===\n\n当在RPC中使用Avro时，服务器和客户端可以在握手连接时交换模式，服务器和客户端有彼此全部的模式，因此相同命名字段，缺失字段和多余字段等信息之间通信中需要处理的一致性问题就可以解决。\n\n客户端希望同服务器端交互时，就需要交换双方通信的协议，它类似于模式，需要双方来协商定义，在Avro中被称为消息。\n\n![](http://pic.yupoo.com/kazaff_v/DSCXbgqa/Jzy9D.jpg)\n\n上图所示，协议中定义了用于传输的消息，消息使用框架后放入缓冲区中进行传输，由于传输的开始就交换了各自的协议定义，因此数据就能够正确解析。所谓传输的开始，也就是很重要的握手阶段。\n\n握手的过程是确保Server和Client获得对方的Schema定义，从而使Server能够正确反序列化请求信息，Client能够正确反序列化响应信息。通常，Server/Client会缓存最后使用到的一些协议格式，所以大多数情况下，握手过程不需要交换整个Schema文本。\n\n所有的RPC请求和响应处理都建立在已经完成握手的基础上，对于无状态的连接，所有的请求响应之前都附有一次握手过程，而对于有状态的连接，一次握手完成，整个连接的生命期内都有效。\n\n下面看一下具体握手过程：\n\n1. Client发起HandshakeRequest，其中包含Client本身SchemaHash值和对应Server端的SchemaHash值，例如：（clientHash!=null,clientProtocol=null,serverHash!=null），如果本地缓存有ServerHash值则直接填充，如果没有则通过猜测填充；\n2. Server用如下之一的HandshakeResponse响应Client请求：\n\t1. （match=BOTH,serverProtocol=null,serverHash=null）：表示当Client发送正确的ServerHash值且Server缓存中存在相应的ClientHash，则握手过程完成；\n\t2. （match=CLIENT,serverProtocol!=null,serverHash!=null）：表示当Server缓存有Client的Schema，但Client请求中的ServHash值不正确。Server发送Server端的Schema数据和相应的Hash值，此次握手完成。\n\t3. （match=NONE）：表示当Client发送的ServerHash不正确且Server端没有Client的Schema缓存。这种情况下Client需要重新提交请求信息（clientHash!=null,clientProtocol!=null,serverHash!=null），Server根据实际情况给予正确的响应，握手完成。\n\n握手过程使用的Schema结构如下：\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"HandshakeRequest\",\n\t\t\"namespace\": \"org.apache.avro.ipc\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"clientHash\",\n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"fixed\",\n\t\t\t\t\t\"name\": \"MD5\",\n\t\t\t\t\t\"size\": 16\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\"name\": \"clientProtocol\", \"type\": [\"null\", \"string\"]},\n\t\t\t{\"name\": \"serverHash\", \"type\": \"MD5\"},\n\t\t\t{\n\t\t\t\t\"name\": \"meta\", \n\t\t\t\t\"type\": [\n\t\t\t\t\t\"null\",\n\t\t\t\t\t{\n\t\t\t\t\t\t\"type\": \"map\",\n\t\t\t\t\t\t\"values\": \"bytes\"\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t}\n\t\t]\n\t}\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"HandshakeResponse\",\n\t\t\"namespace\": \"org.apache.avro.ipc\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"match\", \n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"enum\",\n\t\t\t\t\t\"name\": \"HandshakeMatch\",\n\t\t\t\t\t\"symbols\": [\"BOTH\", \"CLIENT\", \"NONE\"]\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\"name\": \"serverProtocol\", \"type\": [\"null\", \"string\"]},\n\t\t\t{\n\t\t\t\t\"name\": \"serverHash\",\n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"fixed\",\n\t\t\t\t\t\"name\": \"MD5\",\n\t\t\t\t\t\"size\": 16\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"meta\", \n\t\t\t\t\"type\": [\n\t\t\t\t\t\"null\",\n\t\t\t\t\t{\n\t\t\t\t\t\t\"type\": \"map\",\n\t\t\t\t\t\t\"values\": \"bytes\"\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t}\n\t\t]\n\t}\n\n\n消息从客户端发送到服务器端需要经过传输层（Transport Layer），它发送消息并接受服务器端响应。到达传输层的数据就已经是二进制数据了，通常以HTTP作为传输模型，数据以POST方式发送给对方，在Avro中，消息被封装成一组Buffer，如下图所示：\n\n![](http://pic.yupoo.com/kazaff_v/DSCZH27c/9Qe0j.jpg)\n\n每个Buffer以四个字节开头，中间是多个字节的数据，最后以一个空缓冲区结尾。\n\n协议定义\n---\nAvro协议描述了RPC接口，和Schema一样，用JSON定义，有以下属性：\n\n* protocol，必需，协议名称\n* namespace，可选，协议的命名空间\n* doc，可选，描述这个协议的字符串\n* types，可选，定义协议类型名称列表\n* messages，可选，一个json对象，key是message名称，value是json对象\n\t* doc，可选，对消息的说明\n\t* request，参数列表，其中参数拥有名字和类型\n\t* response，响应数据的schema\n\t* error，可选，用一个declared union来描述，error类型的定义和record一样，除了它使用error，而不是record\n\t* one-way，可选，布尔类型，当response 类型是null，并且没有列出error时，one-way parameter只能是true\n\n\n实例\n---\n可以参考这篇文章，写得非常详细：[这里](http://www.cnblogs.com/agoodegg/p/3309041.html)","source":"_posts/是什么系列之Avro.md","raw":"title: 是什么系列之Avro\ndate: 2014-07-07 11:13:12\ntags: \n- rpc\n- json\n- schema\n- 序列化\n- 编码\n- 是什么系列\ncategories: j2ee\n---\n\n今天来关注一下Avro，目的是想接触一下跨端RPC中间件中关于数据编解码及传输的相关技术，这和我目前负责的项目很有关系！那么先从网上找一些相关的文献来给自己科普一下~\n<!-- more -->\nAvro是Hadoop的一个子项目，也是Apache中的一个独立项目，它是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中（Hbase，Hive）的客户端与服务端的数据传输中被大量采用。听上去很给力啊？！\n\nAvro是一个数据序列化的系统，它可以将数据结构或对象转化成便于存储或传输的格式，Avro设计之初就定位为用来支持数据密集型应用，适用于远程或本地大规模数据的存储于交换，Avro支持的编程语言包括：C/C++，JAVA，Python，Ruby，PHP，C#，它的特点有：\n\n1. 丰富的数据结构类型\n2. 快速可压缩的二进制数据形式（对数据二进制序列化后可节约数据存储空间和网络传输带宽）\n3. 存储持久数据的文件容器\n4. 可实现远程过程调用(RPC)\n5. 简单的动态语言结合功能\n\nAvro和动态语言结合后，读写数据文件和使用RPC协议都不需要生成代码，而代码生成作为一种可选的优化只需要在静态类型语言中实现。\n\nAvro依赖于模式（Schema），通过模式定义各种数据结构，只有确定了模式才能对数据进行解释，所以在数据的序列化和反序列化之前，必须先确定模式的结构。同时可动态加载相关数据的模式，数据的读写都使用模式，这使得数据之间不存在任何其他标识（类比Thrift），这样就减少了开销，使得序列化快速又轻巧，同时这种数据及模式的自我描述也方便了动态脚本语言的使用。\n\n当数据存储到文件中时，它的模式也随之存储，这样任何程序都可以对文件进行处理。如果读取数据时使用的模式与写入时使用的模式不同，也容易解决，因为读取和写入的模式都是已知的。看下面这个规则：\n\n<table>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">新模式</th>\n<th align=\"left\">Writer</th>\n<th align=\"left\">Reader</th>\n<th align=\"left\">规则</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td align=\"left\">增加了字段</td>\n<td align=\"left\">采用旧的模式（新增前）</td>\n<td align=\"left\">采用新的模式</td>\n<td align=\"left\">Reader对新字段会使用其默认值（Writer不会为新增的字段赋值）</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"></td>\n<td align=\"left\">采用新的模式（新增后）</td>\n<td align=\"left\">采用旧的模式</td>\n<td align=\"left\">Reader会忽略掉新曾的字段，Writer会为新增字段赋值</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">减少了字段</td>\n<td align=\"left\">采用旧的模式（减少前）</td>\n<td align=\"left\">采用新的模式</td>\n<td align=\"left\">Reader会忽略已经被删除的字段</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"></td>\n<td align=\"left\">采用新的模式（减少后）</td>\n<td align=\"left\">采用旧的模式</td>\n<td align=\"left\">如果旧模式里被删除的那个字段有默认值，那么Reader会采用，否则，Reader会报错</td>\n</tr>\n</tbody>\n</table>\n\n类型\n---\n数据类型标准化的意义在于：\n\n1. 使不同系统对相同的数据能够正确解析\n2. 有利于数据序列化/反序列化\n\nAvro定义了几种简单数据类型，包括：null，boolean，int，long，float，double，bytes，string。简单数据类型有类型名称定义，不包含属性信息，如：\n\t{\"type\": \"string\"}\n\nAvro定义了六种复杂数据类型，每一种复杂数据类型都具有独特的属性，如下：\n\n**Records**：\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"名称json字符串[必填]\",\n\t\t\"namespace\": \"命名空间json字符串[选填]\",\n\t\t\"doc\": \"文档json字符串[选填]\"\n\t\t\"aliases\": \"别名json字符串数组[选填]\",\n\t\t\"fields\": [\t//json数组[必填]\n\t\t\t{\n\t\t\t\t\"name\": \"字段名\",\n\t\t\t\t\"type\": \"类型\",\n\t\t\t\t\"default\": \"默认值\",\n\t\t\t\t\"order\": \"字段顺序\"\n\t\t\t},\n\t\t\t....\n\t\t]\n\t}\n\n例如：\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"test\",\n\t\t\"fields\": [\n\t\t\t{\"name\": \"a\", \"type\": \"long\"},\n\t\t\t{\"name\": \"b\", \"type\": \"string\"}\n\t\t]\n\t}\n\n**Enums**：\n\n\t{\n\t\t\"type\": \"enum\",\n\t\t\"name\": \"名称json字符串[必填]\",\n\t\t\"namespace\": \"命名空间json字符串[选填]\",\n\t\t\"doc\": \"文档json字符串[选填]\"\n\t\t\"aliases\": \"别名json字符串数组[选填]\",\n\t\t\"symbols\": [ //json数组[必填]\n\t\t\t\"值json字符串[必填]，所有值必须是唯一的\"\n\t\t]\n\t}\n\n例如：\n\t\n\t{\n\t\t\"type\": \"enum\",\n\t\t\"name\": \"test\",\n\t\t\"symbols\": [\"k\", \"a\", \"z\", \"a\", \"ff\"]\n\t}\n\n**Arrays**：\n\n\t{\n\t\t\"type\": \"array\",\n\t\t\"items\": \"子元素模式\"\n\t}\n\n例如：\n\t\n\t{\n\t\t\"type\": \"array\",\n\t\t\"items\": \"long\"\n\t}\n\n**Maps**：\n\n\t{\n\t\t\"type\": \"map\",\n\t\t\"values\": \"值元素模式\"\n\t}\n\n\n**Fixed**：\n\n\t{\n\t\t\"type\": \"fixed\",\n\t\t\"name\": \"名称json字符串[必填]\",\n\t\t\"namespace\": \"命名空间json字符串[选填]\",\n\t\t\"aliases\": \"别名json字符串数组[选填]\",\n\t\t\"size\" : \"整型，指定每个值的字节数[必填]\"\n\t}\n\n**Unions**： json数组\n\n序列化/反序列化\n---\nAvro指定两种数据序列化编码方式：binary和json。使用二进制编码会高效序列化，并且序列化后得到的结果会比较小，而json一般用于调试系统或基于web应用。\n\n简单数据类型：\n\n<table>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">类型</th>\n<th align=\"left\">编码</th>\n<th align=\"left\">例子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">null</td>\n<td align=\"left\">0字节</td>\n<td align=\"left\">Null</td>\n</tr>\n<tr>\n<td align=\"left\">boolean</td>\n<td align=\"left\">1字节</td>\n<td align=\"left\">{true: 1, false: 0}</td>\n</tr>\n<tr>\n<td align=\"left\">int/long</td>\n<td align=\"left\">variable-length zig-zag coding</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">float</td>\n<td align=\"left\">4字节</td>\n<td align=\"left\">Java’s floatToIntBits</td>\n</tr>\n<tr>\n<td align=\"left\">double</td>\n<td align=\"left\">8字节</td>\n<td align=\"left\">Java’s floatToIntBits</td>\n</tr>\n<tr>\n<td align=\"left\">bytes</td>\n<td align=\"left\">一个表示长度的long值，后跟指定长度的字节序列</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">string</td>\n<td align=\"left\">一个表示长度的long值，后跟UTF-8字符集的指定长度的字节序列</td>\n<td align=\"left\">“foo”:{3,f,o,o}</td>\n</tr>\n</tbody>\n</table>\n\n复杂数据类型：\n\n**records**类型会按字段声明的顺序串连编码值，例如下面这个record schema：\n\t\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"test\",\n\t\t\"fields\": [\n\t\t\t{\"name\": \"a\", \"type\": \"long\"},\n\t\t\t{\"name\": \"b\", \"type\": \"string\"}\n\t\t]\n\t}\n\n实例化这个record，假设给a字段赋值27(编码为0x36)，给b字段赋值“foo”(06 66 6f 6f，注意第一个06表示字符串长度3的编码值)，那么这个record编码结果为： 36 06 66 6f 6f\n\n**enum**被编码为一个int，比如：\n\t\n\t{\n\t\t\"type\": \"enum\",\n\t\t\"name\": \"test\",\n\t\t\"symbols\": [\"A\", \"B\", \"C\", \"D\"]\n\t}\n\n这将被编码为一个取值范围为[0，3]的int，0表示A，3表示D。\n\n**arrays**编码为block序列，每个block包含一个long的count值，紧跟着的是array items，一个block的count为0表示该block是array的结尾。\n\n**maps**编码为block序列，每个block包含一个long的count值，紧跟着的是key/value对，一个block的count为0表示该block是map的结尾。\n\n**union**编码以一个long值开始，表示后面的数据时union中的哪种数据类型。\n\n**fixed**编码为指定数目的字节。\n\n![](http://pic.yupoo.com/kazaff_v/DSBloaTw/wq4vh.jpg)\n\n上图表示的是Avro本地序列化和反序列化流程，Avro将用户定义的模式和具体的数据编码成二进制序列存储在对象容器文件中，例如用户定义了包含学号，姓名，院系和电话的学生模式，而Avro对其进行编码后存储在student.db文件中，其中存储数据的模式放在文件头的元数据中，这样读取的模式即使与写入的模式不同，也可以迅速的读取数据。假如另一个程序需要获取学生的姓名和电话，只需要定义包含姓名和电话的学生模式，然后用此模式去读取容器文件中的数据即可。\n\n排序\n---\nAvro为数据定义了一个标准的排列顺序，“比较”在很多时候都是经常被使用的对象之间的炒作，标准定义可以进行方便有效的比较和排序，同时标准的定义可以方便对Avro的二进制编码数据直接进行排序而不需要反序列化。\n\n只有当数据项包含相同的Schema时，数据之间的比较才有意义，比较按照Schema深度优先，从左至右的顺序递归进行，找到第一个不匹配即可终止比较。\n\n两个拥有相同模式的项的比较按照以下规则进行：\n\n1. null：总是相等\n2. int,long,float：按照数值大小\n3. boolean：flase在true之前\n4. string：按照字典顺序\n5. bytes，fixed：按照byte的字典顺序\n6. array：按照元素的字典顺序\n7. enum：按照符号在枚举中的位置\n8. record：按照域的字典顺序，如果指定了以下属性：\n\t1. ascending：域值的顺序不变\n\t2. descending：域值的顺序颠倒\n\t3. ignore：排序时忽略域值\n9. map：不可进行排序比较\n\n对象容器文件\n---\nAvro定义了一个简单的对象容器文件格式，一个文件对应一个模式，所有存储在文件中的对象都是根据模式写入的，对象按照块进行存数，块可以采用压缩的方式存储。为了在进行MapReduce处理的时候有效的切分文件，在块之间采用了同步记号。\n\n![](http://pic.yupoo.com/kazaff_v/DSBxUm94/VtHbS.jpg)\n\n一个文件有两部分组成：文件头(Header)和一个或多个文件的数据块(Data Block)。而头信息由由三部分构成：四个字节的前缀，文件Meta-data信息和随机生成的16字节同步标记符。目前Avro支持的Meta-data有两种：schema和codec。\n\ncodec表示对后面的文件数据块采用何种压缩方式。Avro的实现都需要支持下面两种压缩方式：null（不压缩）和deflate（使用Deflate算法压缩数据块）。除了文档中认定的两种Meta-data，用户也可以自定义适用于自己的Meta-data，这里用long型来表示有多少个Meta-data数据对，也是让用户在实际应用中可以定义足够的Meta-data信息。\n\n对于每对Meta-data信息，都有一个string型的key（要以“avro.”为前缀）和二进制编码后的value。由于对象可以组织成不同的块，使用时就可以不经过反序列化而对某个数据块进行操作。还可以由数据块数，对象数和同步标记符来定位损坏的块以确保数据完整性。\n\nRPC\n===\n\n当在RPC中使用Avro时，服务器和客户端可以在握手连接时交换模式，服务器和客户端有彼此全部的模式，因此相同命名字段，缺失字段和多余字段等信息之间通信中需要处理的一致性问题就可以解决。\n\n客户端希望同服务器端交互时，就需要交换双方通信的协议，它类似于模式，需要双方来协商定义，在Avro中被称为消息。\n\n![](http://pic.yupoo.com/kazaff_v/DSCXbgqa/Jzy9D.jpg)\n\n上图所示，协议中定义了用于传输的消息，消息使用框架后放入缓冲区中进行传输，由于传输的开始就交换了各自的协议定义，因此数据就能够正确解析。所谓传输的开始，也就是很重要的握手阶段。\n\n握手的过程是确保Server和Client获得对方的Schema定义，从而使Server能够正确反序列化请求信息，Client能够正确反序列化响应信息。通常，Server/Client会缓存最后使用到的一些协议格式，所以大多数情况下，握手过程不需要交换整个Schema文本。\n\n所有的RPC请求和响应处理都建立在已经完成握手的基础上，对于无状态的连接，所有的请求响应之前都附有一次握手过程，而对于有状态的连接，一次握手完成，整个连接的生命期内都有效。\n\n下面看一下具体握手过程：\n\n1. Client发起HandshakeRequest，其中包含Client本身SchemaHash值和对应Server端的SchemaHash值，例如：（clientHash!=null,clientProtocol=null,serverHash!=null），如果本地缓存有ServerHash值则直接填充，如果没有则通过猜测填充；\n2. Server用如下之一的HandshakeResponse响应Client请求：\n\t1. （match=BOTH,serverProtocol=null,serverHash=null）：表示当Client发送正确的ServerHash值且Server缓存中存在相应的ClientHash，则握手过程完成；\n\t2. （match=CLIENT,serverProtocol!=null,serverHash!=null）：表示当Server缓存有Client的Schema，但Client请求中的ServHash值不正确。Server发送Server端的Schema数据和相应的Hash值，此次握手完成。\n\t3. （match=NONE）：表示当Client发送的ServerHash不正确且Server端没有Client的Schema缓存。这种情况下Client需要重新提交请求信息（clientHash!=null,clientProtocol!=null,serverHash!=null），Server根据实际情况给予正确的响应，握手完成。\n\n握手过程使用的Schema结构如下：\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"HandshakeRequest\",\n\t\t\"namespace\": \"org.apache.avro.ipc\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"clientHash\",\n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"fixed\",\n\t\t\t\t\t\"name\": \"MD5\",\n\t\t\t\t\t\"size\": 16\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\"name\": \"clientProtocol\", \"type\": [\"null\", \"string\"]},\n\t\t\t{\"name\": \"serverHash\", \"type\": \"MD5\"},\n\t\t\t{\n\t\t\t\t\"name\": \"meta\", \n\t\t\t\t\"type\": [\n\t\t\t\t\t\"null\",\n\t\t\t\t\t{\n\t\t\t\t\t\t\"type\": \"map\",\n\t\t\t\t\t\t\"values\": \"bytes\"\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t}\n\t\t]\n\t}\n\n\t{\n\t\t\"type\": \"record\",\n\t\t\"name\": \"HandshakeResponse\",\n\t\t\"namespace\": \"org.apache.avro.ipc\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"match\", \n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"enum\",\n\t\t\t\t\t\"name\": \"HandshakeMatch\",\n\t\t\t\t\t\"symbols\": [\"BOTH\", \"CLIENT\", \"NONE\"]\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\"name\": \"serverProtocol\", \"type\": [\"null\", \"string\"]},\n\t\t\t{\n\t\t\t\t\"name\": \"serverHash\",\n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"fixed\",\n\t\t\t\t\t\"name\": \"MD5\",\n\t\t\t\t\t\"size\": 16\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"meta\", \n\t\t\t\t\"type\": [\n\t\t\t\t\t\"null\",\n\t\t\t\t\t{\n\t\t\t\t\t\t\"type\": \"map\",\n\t\t\t\t\t\t\"values\": \"bytes\"\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t}\n\t\t]\n\t}\n\n\n消息从客户端发送到服务器端需要经过传输层（Transport Layer），它发送消息并接受服务器端响应。到达传输层的数据就已经是二进制数据了，通常以HTTP作为传输模型，数据以POST方式发送给对方，在Avro中，消息被封装成一组Buffer，如下图所示：\n\n![](http://pic.yupoo.com/kazaff_v/DSCZH27c/9Qe0j.jpg)\n\n每个Buffer以四个字节开头，中间是多个字节的数据，最后以一个空缓冲区结尾。\n\n协议定义\n---\nAvro协议描述了RPC接口，和Schema一样，用JSON定义，有以下属性：\n\n* protocol，必需，协议名称\n* namespace，可选，协议的命名空间\n* doc，可选，描述这个协议的字符串\n* types，可选，定义协议类型名称列表\n* messages，可选，一个json对象，key是message名称，value是json对象\n\t* doc，可选，对消息的说明\n\t* request，参数列表，其中参数拥有名字和类型\n\t* response，响应数据的schema\n\t* error，可选，用一个declared union来描述，error类型的定义和record一样，除了它使用error，而不是record\n\t* one-way，可选，布尔类型，当response 类型是null，并且没有列出error时，one-way parameter只能是true\n\n\n实例\n---\n可以参考这篇文章，写得非常详细：[这里](http://www.cnblogs.com/agoodegg/p/3309041.html)","slug":"是什么系列之Avro","published":1,"updated":"2016-05-14T07:46:20.000Z","_id":"cica18yl20027gtfyg1p5hqc8","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天来关注一下Avro，目的是想接触一下跨端RPC中间件中关于数据编解码及传输的相关技术，这和我目前负责的项目很有关系！那么先从网上找一些相关的文献来给自己科普一下~<br><a id=\"more\"></a><br>Avro是Hadoop的一个子项目，也是Apache中的一个独立项目，它是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中（Hbase，Hive）的客户端与服务端的数据传输中被大量采用。听上去很给力啊？！</p>\n<p>Avro是一个数据序列化的系统，它可以将数据结构或对象转化成便于存储或传输的格式，Avro设计之初就定位为用来支持数据密集型应用，适用于远程或本地大规模数据的存储于交换，Avro支持的编程语言包括：C/C++，JAVA，Python，Ruby，PHP，C#，它的特点有：</p>\n<ol>\n<li>丰富的数据结构类型</li>\n<li>快速可压缩的二进制数据形式（对数据二进制序列化后可节约数据存储空间和网络传输带宽）</li>\n<li>存储持久数据的文件容器</li>\n<li>可实现远程过程调用(RPC)</li>\n<li>简单的动态语言结合功能</li>\n</ol>\n<p>Avro和动态语言结合后，读写数据文件和使用RPC协议都不需要生成代码，而代码生成作为一种可选的优化只需要在静态类型语言中实现。</p>\n<p>Avro依赖于模式（Schema），通过模式定义各种数据结构，只有确定了模式才能对数据进行解释，所以在数据的序列化和反序列化之前，必须先确定模式的结构。同时可动态加载相关数据的模式，数据的读写都使用模式，这使得数据之间不存在任何其他标识（类比Thrift），这样就减少了开销，使得序列化快速又轻巧，同时这种数据及模式的自我描述也方便了动态脚本语言的使用。</p>\n<p>当数据存储到文件中时，它的模式也随之存储，这样任何程序都可以对文件进行处理。如果读取数据时使用的模式与写入时使用的模式不同，也容易解决，因为读取和写入的模式都是已知的。看下面这个规则：</p>\n<table><br><thead><br><tr class=\"header\"><br><th align=\"left\">新模式</th><br><th align=\"left\">Writer</th><br><th align=\"left\">Reader</th><br><th align=\"left\">规则</th><br></tr><br></thead><br><tbody><br><tr class=\"odd\"><br><td align=\"left\">增加了字段</td><br><td align=\"left\">采用旧的模式（新增前）</td><br><td align=\"left\">采用新的模式</td><br><td align=\"left\">Reader对新字段会使用其默认值（Writer不会为新增的字段赋值）</td><br></tr><br><tr class=\"odd\"><br><td align=\"left\"></td><br><td align=\"left\">采用新的模式（新增后）</td><br><td align=\"left\">采用旧的模式</td><br><td align=\"left\">Reader会忽略掉新曾的字段，Writer会为新增字段赋值</td><br></tr><br><tr class=\"odd\"><br><td align=\"left\">减少了字段</td><br><td align=\"left\">采用旧的模式（减少前）</td><br><td align=\"left\">采用新的模式</td><br><td align=\"left\">Reader会忽略已经被删除的字段</td><br></tr><br><tr class=\"odd\"><br><td align=\"left\"></td><br><td align=\"left\">采用新的模式（减少后）</td><br><td align=\"left\">采用旧的模式</td><br><td align=\"left\">如果旧模式里被删除的那个字段有默认值，那么Reader会采用，否则，Reader会报错</td><br></tr><br></tbody><br></table>\n\n<h2 id=\"类型\"><a href=\"#类型\" class=\"headerlink\" title=\"类型\"></a>类型</h2><p>数据类型标准化的意义在于：</p>\n<ol>\n<li>使不同系统对相同的数据能够正确解析</li>\n<li>有利于数据序列化/反序列化</li>\n</ol>\n<p>Avro定义了几种简单数据类型，包括：null，boolean，int，long，float，double，bytes，string。简单数据类型有类型名称定义，不包含属性信息，如：<br>    {“type”: “string”}</p>\n<p>Avro定义了六种复杂数据类型，每一种复杂数据类型都具有独特的属性，如下：</p>\n<p><strong>Records</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;名称json字符串[必填]&quot;,\n    &quot;namespace&quot;: &quot;命名空间json字符串[选填]&quot;,\n    &quot;doc&quot;: &quot;文档json字符串[选填]&quot;\n    &quot;aliases&quot;: &quot;别名json字符串数组[选填]&quot;,\n    &quot;fields&quot;: [    //json数组[必填]\n        {\n            &quot;name&quot;: &quot;字段名&quot;,\n            &quot;type&quot;: &quot;类型&quot;,\n            &quot;default&quot;: &quot;默认值&quot;,\n            &quot;order&quot;: &quot;字段顺序&quot;\n        },\n        ....\n    ]\n}\n</code></pre><p>例如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;fields&quot;: [\n        {&quot;name&quot;: &quot;a&quot;, &quot;type&quot;: &quot;long&quot;},\n        {&quot;name&quot;: &quot;b&quot;, &quot;type&quot;: &quot;string&quot;}\n    ]\n}\n</code></pre><p><strong>Enums</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;enum&quot;,\n    &quot;name&quot;: &quot;名称json字符串[必填]&quot;,\n    &quot;namespace&quot;: &quot;命名空间json字符串[选填]&quot;,\n    &quot;doc&quot;: &quot;文档json字符串[选填]&quot;\n    &quot;aliases&quot;: &quot;别名json字符串数组[选填]&quot;,\n    &quot;symbols&quot;: [ //json数组[必填]\n        &quot;值json字符串[必填]，所有值必须是唯一的&quot;\n    ]\n}\n</code></pre><p>例如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;enum&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;symbols&quot;: [&quot;k&quot;, &quot;a&quot;, &quot;z&quot;, &quot;a&quot;, &quot;ff&quot;]\n}\n</code></pre><p><strong>Arrays</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;array&quot;,\n    &quot;items&quot;: &quot;子元素模式&quot;\n}\n</code></pre><p>例如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;array&quot;,\n    &quot;items&quot;: &quot;long&quot;\n}\n</code></pre><p><strong>Maps</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;map&quot;,\n    &quot;values&quot;: &quot;值元素模式&quot;\n}\n</code></pre><p><strong>Fixed</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;fixed&quot;,\n    &quot;name&quot;: &quot;名称json字符串[必填]&quot;,\n    &quot;namespace&quot;: &quot;命名空间json字符串[选填]&quot;,\n    &quot;aliases&quot;: &quot;别名json字符串数组[选填]&quot;,\n    &quot;size&quot; : &quot;整型，指定每个值的字节数[必填]&quot;\n}\n</code></pre><p><strong>Unions</strong>： json数组</p>\n<h2 id=\"序列化-反序列化\"><a href=\"#序列化-反序列化\" class=\"headerlink\" title=\"序列化/反序列化\"></a>序列化/反序列化</h2><p>Avro指定两种数据序列化编码方式：binary和json。使用二进制编码会高效序列化，并且序列化后得到的结果会比较小，而json一般用于调试系统或基于web应用。</p>\n<p>简单数据类型：</p>\n<table><br><thead><br><tr class=\"header\"><br><th align=\"left\">类型</th><br><th align=\"left\">编码</th><br><th align=\"left\">例子</th><br></tr><br></thead><br><tbody><br><tr><br><td align=\"left\">null</td><br><td align=\"left\">0字节</td><br><td align=\"left\">Null</td><br></tr><br><tr><br><td align=\"left\">boolean</td><br><td align=\"left\">1字节</td><br><td align=\"left\">{true: 1, false: 0}</td><br></tr><br><tr><br><td align=\"left\">int/long</td><br><td align=\"left\">variable-length zig-zag coding</td><br><td align=\"left\"></td><br></tr><br><tr><br><td align=\"left\">float</td><br><td align=\"left\">4字节</td><br><td align=\"left\">Java’s floatToIntBits</td><br></tr><br><tr><br><td align=\"left\">double</td><br><td align=\"left\">8字节</td><br><td align=\"left\">Java’s floatToIntBits</td><br></tr><br><tr><br><td align=\"left\">bytes</td><br><td align=\"left\">一个表示长度的long值，后跟指定长度的字节序列</td><br><td align=\"left\"></td><br></tr><br><tr><br><td align=\"left\">string</td><br><td align=\"left\">一个表示长度的long值，后跟UTF-8字符集的指定长度的字节序列</td><br><td align=\"left\">“foo”:{3,f,o,o}</td><br></tr><br></tbody><br></table>\n\n<p>复杂数据类型：</p>\n<p><strong>records</strong>类型会按字段声明的顺序串连编码值，例如下面这个record schema：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;fields&quot;: [\n        {&quot;name&quot;: &quot;a&quot;, &quot;type&quot;: &quot;long&quot;},\n        {&quot;name&quot;: &quot;b&quot;, &quot;type&quot;: &quot;string&quot;}\n    ]\n}\n</code></pre><p>实例化这个record，假设给a字段赋值27(编码为0x36)，给b字段赋值“foo”(06 66 6f 6f，注意第一个06表示字符串长度3的编码值)，那么这个record编码结果为： 36 06 66 6f 6f</p>\n<p><strong>enum</strong>被编码为一个int，比如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;enum&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;symbols&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;]\n}\n</code></pre><p>这将被编码为一个取值范围为[0，3]的int，0表示A，3表示D。</p>\n<p><strong>arrays</strong>编码为block序列，每个block包含一个long的count值，紧跟着的是array items，一个block的count为0表示该block是array的结尾。</p>\n<p><strong>maps</strong>编码为block序列，每个block包含一个long的count值，紧跟着的是key/value对，一个block的count为0表示该block是map的结尾。</p>\n<p><strong>union</strong>编码以一个long值开始，表示后面的数据时union中的哪种数据类型。</p>\n<p><strong>fixed</strong>编码为指定数目的字节。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSBloaTw/wq4vh.jpg\" alt=\"\"></p>\n<p>上图表示的是Avro本地序列化和反序列化流程，Avro将用户定义的模式和具体的数据编码成二进制序列存储在对象容器文件中，例如用户定义了包含学号，姓名，院系和电话的学生模式，而Avro对其进行编码后存储在student.db文件中，其中存储数据的模式放在文件头的元数据中，这样读取的模式即使与写入的模式不同，也可以迅速的读取数据。假如另一个程序需要获取学生的姓名和电话，只需要定义包含姓名和电话的学生模式，然后用此模式去读取容器文件中的数据即可。</p>\n<h2 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h2><p>Avro为数据定义了一个标准的排列顺序，“比较”在很多时候都是经常被使用的对象之间的炒作，标准定义可以进行方便有效的比较和排序，同时标准的定义可以方便对Avro的二进制编码数据直接进行排序而不需要反序列化。</p>\n<p>只有当数据项包含相同的Schema时，数据之间的比较才有意义，比较按照Schema深度优先，从左至右的顺序递归进行，找到第一个不匹配即可终止比较。</p>\n<p>两个拥有相同模式的项的比较按照以下规则进行：</p>\n<ol>\n<li>null：总是相等</li>\n<li>int,long,float：按照数值大小</li>\n<li>boolean：flase在true之前</li>\n<li>string：按照字典顺序</li>\n<li>bytes，fixed：按照byte的字典顺序</li>\n<li>array：按照元素的字典顺序</li>\n<li>enum：按照符号在枚举中的位置</li>\n<li>record：按照域的字典顺序，如果指定了以下属性：<ol>\n<li>ascending：域值的顺序不变</li>\n<li>descending：域值的顺序颠倒</li>\n<li>ignore：排序时忽略域值</li>\n</ol>\n</li>\n<li>map：不可进行排序比较</li>\n</ol>\n<h2 id=\"对象容器文件\"><a href=\"#对象容器文件\" class=\"headerlink\" title=\"对象容器文件\"></a>对象容器文件</h2><p>Avro定义了一个简单的对象容器文件格式，一个文件对应一个模式，所有存储在文件中的对象都是根据模式写入的，对象按照块进行存数，块可以采用压缩的方式存储。为了在进行MapReduce处理的时候有效的切分文件，在块之间采用了同步记号。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSBxUm94/VtHbS.jpg\" alt=\"\"></p>\n<p>一个文件有两部分组成：文件头(Header)和一个或多个文件的数据块(Data Block)。而头信息由由三部分构成：四个字节的前缀，文件Meta-data信息和随机生成的16字节同步标记符。目前Avro支持的Meta-data有两种：schema和codec。</p>\n<p>codec表示对后面的文件数据块采用何种压缩方式。Avro的实现都需要支持下面两种压缩方式：null（不压缩）和deflate（使用Deflate算法压缩数据块）。除了文档中认定的两种Meta-data，用户也可以自定义适用于自己的Meta-data，这里用long型来表示有多少个Meta-data数据对，也是让用户在实际应用中可以定义足够的Meta-data信息。</p>\n<p>对于每对Meta-data信息，都有一个string型的key（要以“avro.”为前缀）和二进制编码后的value。由于对象可以组织成不同的块，使用时就可以不经过反序列化而对某个数据块进行操作。还可以由数据块数，对象数和同步标记符来定位损坏的块以确保数据完整性。</p>\n<h1 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h1><p>当在RPC中使用Avro时，服务器和客户端可以在握手连接时交换模式，服务器和客户端有彼此全部的模式，因此相同命名字段，缺失字段和多余字段等信息之间通信中需要处理的一致性问题就可以解决。</p>\n<p>客户端希望同服务器端交互时，就需要交换双方通信的协议，它类似于模式，需要双方来协商定义，在Avro中被称为消息。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSCXbgqa/Jzy9D.jpg\" alt=\"\"></p>\n<p>上图所示，协议中定义了用于传输的消息，消息使用框架后放入缓冲区中进行传输，由于传输的开始就交换了各自的协议定义，因此数据就能够正确解析。所谓传输的开始，也就是很重要的握手阶段。</p>\n<p>握手的过程是确保Server和Client获得对方的Schema定义，从而使Server能够正确反序列化请求信息，Client能够正确反序列化响应信息。通常，Server/Client会缓存最后使用到的一些协议格式，所以大多数情况下，握手过程不需要交换整个Schema文本。</p>\n<p>所有的RPC请求和响应处理都建立在已经完成握手的基础上，对于无状态的连接，所有的请求响应之前都附有一次握手过程，而对于有状态的连接，一次握手完成，整个连接的生命期内都有效。</p>\n<p>下面看一下具体握手过程：</p>\n<ol>\n<li>Client发起HandshakeRequest，其中包含Client本身SchemaHash值和对应Server端的SchemaHash值，例如：（clientHash!=null,clientProtocol=null,serverHash!=null），如果本地缓存有ServerHash值则直接填充，如果没有则通过猜测填充；</li>\n<li>Server用如下之一的HandshakeResponse响应Client请求：<ol>\n<li>（match=BOTH,serverProtocol=null,serverHash=null）：表示当Client发送正确的ServerHash值且Server缓存中存在相应的ClientHash，则握手过程完成；</li>\n<li>（match=CLIENT,serverProtocol!=null,serverHash!=null）：表示当Server缓存有Client的Schema，但Client请求中的ServHash值不正确。Server发送Server端的Schema数据和相应的Hash值，此次握手完成。</li>\n<li>（match=NONE）：表示当Client发送的ServerHash不正确且Server端没有Client的Schema缓存。这种情况下Client需要重新提交请求信息（clientHash!=null,clientProtocol!=null,serverHash!=null），Server根据实际情况给予正确的响应，握手完成。</li>\n</ol>\n</li>\n</ol>\n<p>握手过程使用的Schema结构如下：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;HandshakeRequest&quot;,\n    &quot;namespace&quot;: &quot;org.apache.avro.ipc&quot;,\n    &quot;fields&quot;: [\n        {\n            &quot;name&quot;: &quot;clientHash&quot;,\n            &quot;type&quot;: {\n                &quot;type&quot;: &quot;fixed&quot;,\n                &quot;name&quot;: &quot;MD5&quot;,\n                &quot;size&quot;: 16\n            }\n        },\n        {&quot;name&quot;: &quot;clientProtocol&quot;, &quot;type&quot;: [&quot;null&quot;, &quot;string&quot;]},\n        {&quot;name&quot;: &quot;serverHash&quot;, &quot;type&quot;: &quot;MD5&quot;},\n        {\n            &quot;name&quot;: &quot;meta&quot;, \n            &quot;type&quot;: [\n                &quot;null&quot;,\n                {\n                    &quot;type&quot;: &quot;map&quot;,\n                    &quot;values&quot;: &quot;bytes&quot;\n                }\n            ]\n        }\n    ]\n}\n\n{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;HandshakeResponse&quot;,\n    &quot;namespace&quot;: &quot;org.apache.avro.ipc&quot;,\n    &quot;fields&quot;: [\n        {\n            &quot;name&quot;: &quot;match&quot;, \n            &quot;type&quot;: {\n                &quot;type&quot;: &quot;enum&quot;,\n                &quot;name&quot;: &quot;HandshakeMatch&quot;,\n                &quot;symbols&quot;: [&quot;BOTH&quot;, &quot;CLIENT&quot;, &quot;NONE&quot;]\n            }\n        },\n        {&quot;name&quot;: &quot;serverProtocol&quot;, &quot;type&quot;: [&quot;null&quot;, &quot;string&quot;]},\n        {\n            &quot;name&quot;: &quot;serverHash&quot;,\n            &quot;type&quot;: {\n                &quot;type&quot;: &quot;fixed&quot;,\n                &quot;name&quot;: &quot;MD5&quot;,\n                &quot;size&quot;: 16\n            }\n        },\n        {\n            &quot;name&quot;: &quot;meta&quot;, \n            &quot;type&quot;: [\n                &quot;null&quot;,\n                {\n                    &quot;type&quot;: &quot;map&quot;,\n                    &quot;values&quot;: &quot;bytes&quot;\n                }\n            ]\n        }\n    ]\n}\n</code></pre><p>消息从客户端发送到服务器端需要经过传输层（Transport Layer），它发送消息并接受服务器端响应。到达传输层的数据就已经是二进制数据了，通常以HTTP作为传输模型，数据以POST方式发送给对方，在Avro中，消息被封装成一组Buffer，如下图所示：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSCZH27c/9Qe0j.jpg\" alt=\"\"></p>\n<p>每个Buffer以四个字节开头，中间是多个字节的数据，最后以一个空缓冲区结尾。</p>\n<h2 id=\"协议定义\"><a href=\"#协议定义\" class=\"headerlink\" title=\"协议定义\"></a>协议定义</h2><p>Avro协议描述了RPC接口，和Schema一样，用JSON定义，有以下属性：</p>\n<ul>\n<li>protocol，必需，协议名称</li>\n<li>namespace，可选，协议的命名空间</li>\n<li>doc，可选，描述这个协议的字符串</li>\n<li>types，可选，定义协议类型名称列表</li>\n<li>messages，可选，一个json对象，key是message名称，value是json对象<ul>\n<li>doc，可选，对消息的说明</li>\n<li>request，参数列表，其中参数拥有名字和类型</li>\n<li>response，响应数据的schema</li>\n<li>error，可选，用一个declared union来描述，error类型的定义和record一样，除了它使用error，而不是record</li>\n<li>one-way，可选，布尔类型，当response 类型是null，并且没有列出error时，one-way parameter只能是true</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><p>可以参考这篇文章，写得非常详细：<a href=\"http://www.cnblogs.com/agoodegg/p/3309041.html\" target=\"_blank\" rel=\"external\">这里</a></p>\n","excerpt":"<p>今天来关注一下Avro，目的是想接触一下跨端RPC中间件中关于数据编解码及传输的相关技术，这和我目前负责的项目很有关系！那么先从网上找一些相关的文献来给自己科普一下~<br>","more":"<br>Avro是Hadoop的一个子项目，也是Apache中的一个独立项目，它是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中（Hbase，Hive）的客户端与服务端的数据传输中被大量采用。听上去很给力啊？！</p>\n<p>Avro是一个数据序列化的系统，它可以将数据结构或对象转化成便于存储或传输的格式，Avro设计之初就定位为用来支持数据密集型应用，适用于远程或本地大规模数据的存储于交换，Avro支持的编程语言包括：C/C++，JAVA，Python，Ruby，PHP，C#，它的特点有：</p>\n<ol>\n<li>丰富的数据结构类型</li>\n<li>快速可压缩的二进制数据形式（对数据二进制序列化后可节约数据存储空间和网络传输带宽）</li>\n<li>存储持久数据的文件容器</li>\n<li>可实现远程过程调用(RPC)</li>\n<li>简单的动态语言结合功能</li>\n</ol>\n<p>Avro和动态语言结合后，读写数据文件和使用RPC协议都不需要生成代码，而代码生成作为一种可选的优化只需要在静态类型语言中实现。</p>\n<p>Avro依赖于模式（Schema），通过模式定义各种数据结构，只有确定了模式才能对数据进行解释，所以在数据的序列化和反序列化之前，必须先确定模式的结构。同时可动态加载相关数据的模式，数据的读写都使用模式，这使得数据之间不存在任何其他标识（类比Thrift），这样就减少了开销，使得序列化快速又轻巧，同时这种数据及模式的自我描述也方便了动态脚本语言的使用。</p>\n<p>当数据存储到文件中时，它的模式也随之存储，这样任何程序都可以对文件进行处理。如果读取数据时使用的模式与写入时使用的模式不同，也容易解决，因为读取和写入的模式都是已知的。看下面这个规则：</p>\n<table><br><thead><br><tr class=\"header\"><br><th align=\"left\">新模式</th><br><th align=\"left\">Writer</th><br><th align=\"left\">Reader</th><br><th align=\"left\">规则</th><br></tr><br></thead><br><tbody><br><tr class=\"odd\"><br><td align=\"left\">增加了字段</td><br><td align=\"left\">采用旧的模式（新增前）</td><br><td align=\"left\">采用新的模式</td><br><td align=\"left\">Reader对新字段会使用其默认值（Writer不会为新增的字段赋值）</td><br></tr><br><tr class=\"odd\"><br><td align=\"left\"></td><br><td align=\"left\">采用新的模式（新增后）</td><br><td align=\"left\">采用旧的模式</td><br><td align=\"left\">Reader会忽略掉新曾的字段，Writer会为新增字段赋值</td><br></tr><br><tr class=\"odd\"><br><td align=\"left\">减少了字段</td><br><td align=\"left\">采用旧的模式（减少前）</td><br><td align=\"left\">采用新的模式</td><br><td align=\"left\">Reader会忽略已经被删除的字段</td><br></tr><br><tr class=\"odd\"><br><td align=\"left\"></td><br><td align=\"left\">采用新的模式（减少后）</td><br><td align=\"left\">采用旧的模式</td><br><td align=\"left\">如果旧模式里被删除的那个字段有默认值，那么Reader会采用，否则，Reader会报错</td><br></tr><br></tbody><br></table>\n\n<h2 id=\"类型\"><a href=\"#类型\" class=\"headerlink\" title=\"类型\"></a>类型</h2><p>数据类型标准化的意义在于：</p>\n<ol>\n<li>使不同系统对相同的数据能够正确解析</li>\n<li>有利于数据序列化/反序列化</li>\n</ol>\n<p>Avro定义了几种简单数据类型，包括：null，boolean，int，long，float，double，bytes，string。简单数据类型有类型名称定义，不包含属性信息，如：<br>    {“type”: “string”}</p>\n<p>Avro定义了六种复杂数据类型，每一种复杂数据类型都具有独特的属性，如下：</p>\n<p><strong>Records</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;名称json字符串[必填]&quot;,\n    &quot;namespace&quot;: &quot;命名空间json字符串[选填]&quot;,\n    &quot;doc&quot;: &quot;文档json字符串[选填]&quot;\n    &quot;aliases&quot;: &quot;别名json字符串数组[选填]&quot;,\n    &quot;fields&quot;: [    //json数组[必填]\n        {\n            &quot;name&quot;: &quot;字段名&quot;,\n            &quot;type&quot;: &quot;类型&quot;,\n            &quot;default&quot;: &quot;默认值&quot;,\n            &quot;order&quot;: &quot;字段顺序&quot;\n        },\n        ....\n    ]\n}\n</code></pre><p>例如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;fields&quot;: [\n        {&quot;name&quot;: &quot;a&quot;, &quot;type&quot;: &quot;long&quot;},\n        {&quot;name&quot;: &quot;b&quot;, &quot;type&quot;: &quot;string&quot;}\n    ]\n}\n</code></pre><p><strong>Enums</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;enum&quot;,\n    &quot;name&quot;: &quot;名称json字符串[必填]&quot;,\n    &quot;namespace&quot;: &quot;命名空间json字符串[选填]&quot;,\n    &quot;doc&quot;: &quot;文档json字符串[选填]&quot;\n    &quot;aliases&quot;: &quot;别名json字符串数组[选填]&quot;,\n    &quot;symbols&quot;: [ //json数组[必填]\n        &quot;值json字符串[必填]，所有值必须是唯一的&quot;\n    ]\n}\n</code></pre><p>例如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;enum&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;symbols&quot;: [&quot;k&quot;, &quot;a&quot;, &quot;z&quot;, &quot;a&quot;, &quot;ff&quot;]\n}\n</code></pre><p><strong>Arrays</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;array&quot;,\n    &quot;items&quot;: &quot;子元素模式&quot;\n}\n</code></pre><p>例如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;array&quot;,\n    &quot;items&quot;: &quot;long&quot;\n}\n</code></pre><p><strong>Maps</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;map&quot;,\n    &quot;values&quot;: &quot;值元素模式&quot;\n}\n</code></pre><p><strong>Fixed</strong>：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;fixed&quot;,\n    &quot;name&quot;: &quot;名称json字符串[必填]&quot;,\n    &quot;namespace&quot;: &quot;命名空间json字符串[选填]&quot;,\n    &quot;aliases&quot;: &quot;别名json字符串数组[选填]&quot;,\n    &quot;size&quot; : &quot;整型，指定每个值的字节数[必填]&quot;\n}\n</code></pre><p><strong>Unions</strong>： json数组</p>\n<h2 id=\"序列化-反序列化\"><a href=\"#序列化-反序列化\" class=\"headerlink\" title=\"序列化/反序列化\"></a>序列化/反序列化</h2><p>Avro指定两种数据序列化编码方式：binary和json。使用二进制编码会高效序列化，并且序列化后得到的结果会比较小，而json一般用于调试系统或基于web应用。</p>\n<p>简单数据类型：</p>\n<table><br><thead><br><tr class=\"header\"><br><th align=\"left\">类型</th><br><th align=\"left\">编码</th><br><th align=\"left\">例子</th><br></tr><br></thead><br><tbody><br><tr><br><td align=\"left\">null</td><br><td align=\"left\">0字节</td><br><td align=\"left\">Null</td><br></tr><br><tr><br><td align=\"left\">boolean</td><br><td align=\"left\">1字节</td><br><td align=\"left\">{true: 1, false: 0}</td><br></tr><br><tr><br><td align=\"left\">int/long</td><br><td align=\"left\">variable-length zig-zag coding</td><br><td align=\"left\"></td><br></tr><br><tr><br><td align=\"left\">float</td><br><td align=\"left\">4字节</td><br><td align=\"left\">Java’s floatToIntBits</td><br></tr><br><tr><br><td align=\"left\">double</td><br><td align=\"left\">8字节</td><br><td align=\"left\">Java’s floatToIntBits</td><br></tr><br><tr><br><td align=\"left\">bytes</td><br><td align=\"left\">一个表示长度的long值，后跟指定长度的字节序列</td><br><td align=\"left\"></td><br></tr><br><tr><br><td align=\"left\">string</td><br><td align=\"left\">一个表示长度的long值，后跟UTF-8字符集的指定长度的字节序列</td><br><td align=\"left\">“foo”:{3,f,o,o}</td><br></tr><br></tbody><br></table>\n\n<p>复杂数据类型：</p>\n<p><strong>records</strong>类型会按字段声明的顺序串连编码值，例如下面这个record schema：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;fields&quot;: [\n        {&quot;name&quot;: &quot;a&quot;, &quot;type&quot;: &quot;long&quot;},\n        {&quot;name&quot;: &quot;b&quot;, &quot;type&quot;: &quot;string&quot;}\n    ]\n}\n</code></pre><p>实例化这个record，假设给a字段赋值27(编码为0x36)，给b字段赋值“foo”(06 66 6f 6f，注意第一个06表示字符串长度3的编码值)，那么这个record编码结果为： 36 06 66 6f 6f</p>\n<p><strong>enum</strong>被编码为一个int，比如：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;enum&quot;,\n    &quot;name&quot;: &quot;test&quot;,\n    &quot;symbols&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;]\n}\n</code></pre><p>这将被编码为一个取值范围为[0，3]的int，0表示A，3表示D。</p>\n<p><strong>arrays</strong>编码为block序列，每个block包含一个long的count值，紧跟着的是array items，一个block的count为0表示该block是array的结尾。</p>\n<p><strong>maps</strong>编码为block序列，每个block包含一个long的count值，紧跟着的是key/value对，一个block的count为0表示该block是map的结尾。</p>\n<p><strong>union</strong>编码以一个long值开始，表示后面的数据时union中的哪种数据类型。</p>\n<p><strong>fixed</strong>编码为指定数目的字节。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSBloaTw/wq4vh.jpg\" alt=\"\"></p>\n<p>上图表示的是Avro本地序列化和反序列化流程，Avro将用户定义的模式和具体的数据编码成二进制序列存储在对象容器文件中，例如用户定义了包含学号，姓名，院系和电话的学生模式，而Avro对其进行编码后存储在student.db文件中，其中存储数据的模式放在文件头的元数据中，这样读取的模式即使与写入的模式不同，也可以迅速的读取数据。假如另一个程序需要获取学生的姓名和电话，只需要定义包含姓名和电话的学生模式，然后用此模式去读取容器文件中的数据即可。</p>\n<h2 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h2><p>Avro为数据定义了一个标准的排列顺序，“比较”在很多时候都是经常被使用的对象之间的炒作，标准定义可以进行方便有效的比较和排序，同时标准的定义可以方便对Avro的二进制编码数据直接进行排序而不需要反序列化。</p>\n<p>只有当数据项包含相同的Schema时，数据之间的比较才有意义，比较按照Schema深度优先，从左至右的顺序递归进行，找到第一个不匹配即可终止比较。</p>\n<p>两个拥有相同模式的项的比较按照以下规则进行：</p>\n<ol>\n<li>null：总是相等</li>\n<li>int,long,float：按照数值大小</li>\n<li>boolean：flase在true之前</li>\n<li>string：按照字典顺序</li>\n<li>bytes，fixed：按照byte的字典顺序</li>\n<li>array：按照元素的字典顺序</li>\n<li>enum：按照符号在枚举中的位置</li>\n<li>record：按照域的字典顺序，如果指定了以下属性：<ol>\n<li>ascending：域值的顺序不变</li>\n<li>descending：域值的顺序颠倒</li>\n<li>ignore：排序时忽略域值</li>\n</ol>\n</li>\n<li>map：不可进行排序比较</li>\n</ol>\n<h2 id=\"对象容器文件\"><a href=\"#对象容器文件\" class=\"headerlink\" title=\"对象容器文件\"></a>对象容器文件</h2><p>Avro定义了一个简单的对象容器文件格式，一个文件对应一个模式，所有存储在文件中的对象都是根据模式写入的，对象按照块进行存数，块可以采用压缩的方式存储。为了在进行MapReduce处理的时候有效的切分文件，在块之间采用了同步记号。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSBxUm94/VtHbS.jpg\" alt=\"\"></p>\n<p>一个文件有两部分组成：文件头(Header)和一个或多个文件的数据块(Data Block)。而头信息由由三部分构成：四个字节的前缀，文件Meta-data信息和随机生成的16字节同步标记符。目前Avro支持的Meta-data有两种：schema和codec。</p>\n<p>codec表示对后面的文件数据块采用何种压缩方式。Avro的实现都需要支持下面两种压缩方式：null（不压缩）和deflate（使用Deflate算法压缩数据块）。除了文档中认定的两种Meta-data，用户也可以自定义适用于自己的Meta-data，这里用long型来表示有多少个Meta-data数据对，也是让用户在实际应用中可以定义足够的Meta-data信息。</p>\n<p>对于每对Meta-data信息，都有一个string型的key（要以“avro.”为前缀）和二进制编码后的value。由于对象可以组织成不同的块，使用时就可以不经过反序列化而对某个数据块进行操作。还可以由数据块数，对象数和同步标记符来定位损坏的块以确保数据完整性。</p>\n<h1 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h1><p>当在RPC中使用Avro时，服务器和客户端可以在握手连接时交换模式，服务器和客户端有彼此全部的模式，因此相同命名字段，缺失字段和多余字段等信息之间通信中需要处理的一致性问题就可以解决。</p>\n<p>客户端希望同服务器端交互时，就需要交换双方通信的协议，它类似于模式，需要双方来协商定义，在Avro中被称为消息。</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSCXbgqa/Jzy9D.jpg\" alt=\"\"></p>\n<p>上图所示，协议中定义了用于传输的消息，消息使用框架后放入缓冲区中进行传输，由于传输的开始就交换了各自的协议定义，因此数据就能够正确解析。所谓传输的开始，也就是很重要的握手阶段。</p>\n<p>握手的过程是确保Server和Client获得对方的Schema定义，从而使Server能够正确反序列化请求信息，Client能够正确反序列化响应信息。通常，Server/Client会缓存最后使用到的一些协议格式，所以大多数情况下，握手过程不需要交换整个Schema文本。</p>\n<p>所有的RPC请求和响应处理都建立在已经完成握手的基础上，对于无状态的连接，所有的请求响应之前都附有一次握手过程，而对于有状态的连接，一次握手完成，整个连接的生命期内都有效。</p>\n<p>下面看一下具体握手过程：</p>\n<ol>\n<li>Client发起HandshakeRequest，其中包含Client本身SchemaHash值和对应Server端的SchemaHash值，例如：（clientHash!=null,clientProtocol=null,serverHash!=null），如果本地缓存有ServerHash值则直接填充，如果没有则通过猜测填充；</li>\n<li>Server用如下之一的HandshakeResponse响应Client请求：<ol>\n<li>（match=BOTH,serverProtocol=null,serverHash=null）：表示当Client发送正确的ServerHash值且Server缓存中存在相应的ClientHash，则握手过程完成；</li>\n<li>（match=CLIENT,serverProtocol!=null,serverHash!=null）：表示当Server缓存有Client的Schema，但Client请求中的ServHash值不正确。Server发送Server端的Schema数据和相应的Hash值，此次握手完成。</li>\n<li>（match=NONE）：表示当Client发送的ServerHash不正确且Server端没有Client的Schema缓存。这种情况下Client需要重新提交请求信息（clientHash!=null,clientProtocol!=null,serverHash!=null），Server根据实际情况给予正确的响应，握手完成。</li>\n</ol>\n</li>\n</ol>\n<p>握手过程使用的Schema结构如下：</p>\n<pre><code>{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;HandshakeRequest&quot;,\n    &quot;namespace&quot;: &quot;org.apache.avro.ipc&quot;,\n    &quot;fields&quot;: [\n        {\n            &quot;name&quot;: &quot;clientHash&quot;,\n            &quot;type&quot;: {\n                &quot;type&quot;: &quot;fixed&quot;,\n                &quot;name&quot;: &quot;MD5&quot;,\n                &quot;size&quot;: 16\n            }\n        },\n        {&quot;name&quot;: &quot;clientProtocol&quot;, &quot;type&quot;: [&quot;null&quot;, &quot;string&quot;]},\n        {&quot;name&quot;: &quot;serverHash&quot;, &quot;type&quot;: &quot;MD5&quot;},\n        {\n            &quot;name&quot;: &quot;meta&quot;, \n            &quot;type&quot;: [\n                &quot;null&quot;,\n                {\n                    &quot;type&quot;: &quot;map&quot;,\n                    &quot;values&quot;: &quot;bytes&quot;\n                }\n            ]\n        }\n    ]\n}\n\n{\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;HandshakeResponse&quot;,\n    &quot;namespace&quot;: &quot;org.apache.avro.ipc&quot;,\n    &quot;fields&quot;: [\n        {\n            &quot;name&quot;: &quot;match&quot;, \n            &quot;type&quot;: {\n                &quot;type&quot;: &quot;enum&quot;,\n                &quot;name&quot;: &quot;HandshakeMatch&quot;,\n                &quot;symbols&quot;: [&quot;BOTH&quot;, &quot;CLIENT&quot;, &quot;NONE&quot;]\n            }\n        },\n        {&quot;name&quot;: &quot;serverProtocol&quot;, &quot;type&quot;: [&quot;null&quot;, &quot;string&quot;]},\n        {\n            &quot;name&quot;: &quot;serverHash&quot;,\n            &quot;type&quot;: {\n                &quot;type&quot;: &quot;fixed&quot;,\n                &quot;name&quot;: &quot;MD5&quot;,\n                &quot;size&quot;: 16\n            }\n        },\n        {\n            &quot;name&quot;: &quot;meta&quot;, \n            &quot;type&quot;: [\n                &quot;null&quot;,\n                {\n                    &quot;type&quot;: &quot;map&quot;,\n                    &quot;values&quot;: &quot;bytes&quot;\n                }\n            ]\n        }\n    ]\n}\n</code></pre><p>消息从客户端发送到服务器端需要经过传输层（Transport Layer），它发送消息并接受服务器端响应。到达传输层的数据就已经是二进制数据了，通常以HTTP作为传输模型，数据以POST方式发送给对方，在Avro中，消息被封装成一组Buffer，如下图所示：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/DSCZH27c/9Qe0j.jpg\" alt=\"\"></p>\n<p>每个Buffer以四个字节开头，中间是多个字节的数据，最后以一个空缓冲区结尾。</p>\n<h2 id=\"协议定义\"><a href=\"#协议定义\" class=\"headerlink\" title=\"协议定义\"></a>协议定义</h2><p>Avro协议描述了RPC接口，和Schema一样，用JSON定义，有以下属性：</p>\n<ul>\n<li>protocol，必需，协议名称</li>\n<li>namespace，可选，协议的命名空间</li>\n<li>doc，可选，描述这个协议的字符串</li>\n<li>types，可选，定义协议类型名称列表</li>\n<li>messages，可选，一个json对象，key是message名称，value是json对象<ul>\n<li>doc，可选，对消息的说明</li>\n<li>request，参数列表，其中参数拥有名字和类型</li>\n<li>response，响应数据的schema</li>\n<li>error，可选，用一个declared union来描述，error类型的定义和record一样，除了它使用error，而不是record</li>\n<li>one-way，可选，布尔类型，当response 类型是null，并且没有列出error时，one-way parameter只能是true</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><p>可以参考这篇文章，写得非常详细：<a href=\"http://www.cnblogs.com/agoodegg/p/3309041.html\">这里</a></p>"},{"title":"日志收集架构－ELK","date":"2015-06-05T01:37:12.000Z","_content":"\n本周的工作计划是调研并测试ELK，那什么是ELK呢？简而言之就是开源的主流的日志收集与分析系统。\n<!--more-->\nELK是三个工具的总称：\n\n- E: ElasticSearch\n- L: Logstash\n- K: Kibana\n\n我这里主要想强调的，是它们三个组合起来以后，提供强大的**开箱即用**的日志收集和检索功能，这对于创业公司和小团队来说，简直就是完美~\n\n**可能对我来讲，最不理想的就是它基于ruby语言，这么高逼格的语言我不会啊……**\n\n但是也不要太乐观，社区和大牛们表示，想用好这三个工具也不是一件很简单的事儿，我们本次的目的，就是搞清楚这三者之间的关系和它们各自的作用，并最终搭建一个可测试环境，好吧，废话不多说，开始吧。\n\n最为强迫症的我，一向是尽可能用最新版本，也就是说，我们本次尝试搭建的ELK环境，软件版本分别为：\n\n- [ElasticSearch-1.5.2](https://www.elastic.co/downloads/elasticsearch)\n- [Logstash-1.5.0](https://www.elastic.co/downloads/logstash)\n- [Kibana-4.0.2](https://www.elastic.co/downloads/kibana)\n\n安装\n---\n\n之前提过“开箱即用”，绝对不是吹牛逼的，安装流程就是：\n\n\t下载 --> 解压 --> 简单配置 --> 运行 --> 看效果\n\n完全不需要编译安装，真是醉了~我们从logstash开始，下载上面给的版本后，解压并拷贝到`/usr/local`下：\n\n\t$ cd /usr/local/logstash\n\t$ mkdir conf logs\n\n我们创建了两个文件夹，分别用来放配置文件和日志。\n\n接下来我们先简单的配置一下logstash，在conf下创建一个central.conf，内容如下：\n\n\tinput {\n\t\tstdin {}\n\t}\n\n\toutput {\n\t\tstdout {}\n\t\telasticsearch {\n\t\t\tcluster => \"elasticsearch\"\n\t\t\tcodec => \"json\"\n\t\t\tprotocol => \"http\"\n\t\t}   \n\t}\n\n保存，运行下面这个命令启动：\n\n\t$ ./bin/logstash agent --verbose --config ./conf/central.conf --log ./logs/stdout.log\n\n接下来安装elasticsearch，一样简单，解压到`/usr/local/`下，然后直接启动：\n\n\t$ ./bin/elasticsearch -d\n\n最后来配置kibana，解压到`/usr/local/`下，然后直接启动：\n\n\t$ ./bin/kibana\n\n我们使用的是kibana默认的配置，现在可以直接在浏览器中访问： [http://127.0.0.1:5601](http://127.0.0.1:5601)。\n\n怎么测试我们安装的是否成功呢？很简单，在刚才我们执行logstash的终端中，直接输入字符串：hello world，然后刷新kibana页面，你将会看到对应的日志信息~~\n\n知道什么叫开箱即用了么？\n\n搭建好了，不等于我们就可以直接使用在产品环境下了，毕竟这个例子貌似没有卵用...下面我们来聊一下理论知识。\n\n\n架构\n---\n\n![](http://nkcoder.github.io/images/post/ELKR-log-platform.jpg)\n\n说明：\n\n- 多个独立的agent(Shipper)负责收集不同来源的数据，一个中心agent(Indexer)负责汇总和分析数据，在中心agent前的Broker(使用redis实现)作为缓冲区，中心agent后的ElasticSearch用于存储和搜索数据，前端的Kibana提供丰富的图表展示。\n- Shipper表示日志收集，使用LogStash收集各种来源的日志数据，可以是系统日志、文件、redis、mq等等；\n- Broker作为远程agent与中心agent之间的缓冲区，使用redis实现，一是可以提高系统的性能，二是可以提高系统的可靠性，当中心agent提取数据失败时，数据保存在redis中，而不至于丢失；\n- 中心agent也是LogStash，从Broker中提取数据，可以执行相关的分析和处理(Filter)；\n- ElasticSearch用于存储最终的数据，并提供搜索功能；\n- Kibana提供一个简单、丰富的web界面，数据来自于ElasticSearch，支持各种查询、统计和展示；\n\n上面这个图是参考前辈的（下面的参考列表中有具体链接），需要知道的是上面的这种搭配并非是唯一的，例如你可以不使用redis而是用kafka来做消息队列，你也可以让Shipper直接从你希望的日志源中拉取日志数据，如你喜欢你也可以让数据存到Elasticsearch后再存一份到hdfs中，反正大牛们说logstash的插件非常的多，我是信了~~\n\n接下来，我们就试试用logstash来获取一些常用的web server的access log，例如：nginx，tomcat等。由于测试环境都是在同一台机器上本地完成，所有就不需要劳烦消息队列中间件了。\n\n\nNginx-->Logstash\n---\n\n根据上图所示，我们其实就是让logstash去监听nginx的日志文件，首先我们得先修改一下上面的那个logstash的配置文件：\n\n\tinput {\n\t\tfile {\n\t\t\ttype => \"nginx_access\"\n\t\t\tpath => [\"/usr/local/nginx/logs/*.log\"]\n\t\t\texclude => [\"*.gz\",\"error.log\",\"nginx.pid\"]\n\t\t\tsincedb_path => \"/dev/null\"\n\t\t\tcodec => \"json\"\t\n\t\t}\n\t}\n\t\n\toutput {\n\t\tstdout {}\n\t\telasticsearch {\n\t\t\tcluster => \"elasticsearch\"\n\t\t\tcodec => \"json\"\n\t\t\tprotocol => \"http\"\n\t\t}\n\t}\n\nok，接下来我们就需要安装nginx了，这部分我就不多讲了，安装好nginx后在启动之前，我们需要先修改一下nginx的配置文件（`nginx.conf`）:\n\t\n\t......\n\tlog_format   json  '{\"@timestamp\":\"$time_iso8601\",'\n\t\t\t\t'\"@source\":\"$server_addr\",'\n\t\t\t\t'\"@nginx_fields\":{'\n\t\t\t\t\t'\"client\":\"$remote_addr\",'\n\t\t\t\t\t'\"size\":$body_bytes_sent,'\n\t\t\t\t\t'\"responsetime\":\"$request_time\",'\n\t\t\t\t\t'\"upstreamtime\":\"$upstream_response_time\",'\n\t\t\t\t\t'\"upstreamaddr\":\"$upstream_addr\",'\n\t\t\t\t\t'\"request_method\":\"$request_method\",'\n\t\t\t\t\t'\"domain\":\"$host\",'\n\t\t\t\t\t'\"url\":\"$uri\",'\n\t\t\t\t\t'\"http_user_agent\":\"$http_user_agent\",'\n\t\t\t\t\t'\"status\":$status,'\n\t\t\t\t\t'\"x_forwarded_for\":\"$http_x_forwarded_for\"'\n\t\t\t\t'}'\n\t\t\t'}';\n\n    access_log  logs/access.log  json;\n\t......\n\n大功告成了，启动nginx后，浏览器访问nginx下的页面，你会看到kibana中的对应更新。\n\n\nTomcat-->Logstash\n---\n\ntomcat的日志比nginx要复杂一些，打开对应的日志文件（`catalina.out`）,你会发现类似下面这样的日志结构：\n\n\tJun 12, 2014 11:17:34 AM org.apache.catalina.core.AprLifecycleListener init\n\tINFO: The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib\n\tJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\n\tINFO: Initializing ProtocolHandler [\"http-bio-8080\"]\n\tJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\n\tSEVERE: Failed to initialize end point associated with ProtocolHandler [\"http-bio-8080\"]\n\tjava.net.BindException: Address already in use <null>:8080\n\t\tat org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:411)\n\t\tat org.apache.tomcat.util.net.AbstractEndpoint.init(AbstractEndpoint.java:640)\n\t\tat org.apache.coyote.AbstractProtocol.init(AbstractProtocol.java:434)\n\t\tat org.apache.coyote.http11.AbstractHttp11JsseProtocol.init(AbstractHttp11JsseProtocol.java:119)\n\t\tat org.apache.catalina.connector.Connector.initInternal(Connector.java:978)\n\t\tat org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n\t\tat org.apache.catalina.core.StandardService.initInternal(StandardService.java:559)\n\t\tat org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n\t\tat org.apache.catalina.core.StandardServer.initInternal(StandardServer.java:813)\n\t\tat org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n\t\tat org.apache.catalina.startup.Catalina.load(Catalina.java:638)\n\t\tat org.apache.catalina.startup.Catalina.load(Catalina.java:663)\n\t\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\t\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\t\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\t\tat java.lang.reflect.Method.invoke(Method.java:606)\n\t\tat org.apache.catalina.startup.Bootstrap.load(Bootstrap.java:280)\n\t\tat org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:454)\n\tCaused by: java.net.BindException: Address already in use\n\t\tat java.net.PlainSocketImpl.socketBind(Native Method)\n\t\tat java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)\n\t\tat java.net.ServerSocket.bind(ServerSocket.java:376)\n\t\tat java.net.ServerSocket.<init>(ServerSocket.java:237)\n\t\tat java.net.ServerSocket.<init>(ServerSocket.java:181)\n\t\tat org.apache.tomcat.util.net.DefaultServerSocketFactory.createSocket(DefaultServerSocketFactory.java:49)\n\t\tat org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:398)\n\t\t... 17 more\n\n无法直视啊简直，不过还好，logstash提供了强大的插件来帮助我们解析各种各样的日志输出结构，分析一下可以得出，日志结构是：时间戳，后面跟着类名，再后面跟着日志信息，这样，我们就可以根据这种结构来写过滤规则：\n\t\n\tCOMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-)\n\tCOMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}\n\n\tCATALINA_DATESTAMP %{MONTH} %{MONTHDAY}, 20%{YEAR} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) (?:AM|PM)\n\tCATALINALOG %{CATALINA_DATESTAMP:timestamp} %{JAVACLASS:class} %{JAVALOGMESSAGE:logmessage}\n\n我们把[这些规则](https://gist.github.com/LanyonM/8390458#file-grok-patterns)存储在一个文件（`/logstash安装路径/patterns/grok-patterns`）中，接下来我们要改写logstash的配置文件了：\n\n\tinput {\n\t\tfile {\n\t\t\ttype => \"tomcat_access\"\n\t\t\tpath => [\"/usr/local/tomcat/logs/catalina.out\"]\n\t\t\texclude => [\"*.log\",\"*.txt\"]\n\t\t\tsincedb_path => \"/dev/null\"\n\t\t\tstart_position => \"beginning\"\n\t\t}\n\t\tfile {\n\t\t\ttype => \"apache_access\"\n\t\t\tpath => [\"/usr/local/tomcat/logs/*.txt\"]\n\t\t\texclude => [\"*.log\"]\n\t\t\tsincedb_path => \"/dev/null\"\n\t\t\tstart_position => \"beginning\"\n\t\t}\n\t}\n\t\n\tfilter {\n\t\tif [type] == \"tomcat_access\" {\n\t\t\tmultiline {\n\t\t\t\tpatterns_dir => \"/usr/local/logstash/patterns\"\n\t\t\t\tpattern => \"(^%{CATALINA_DATESTAMP})\"\n\t\t\t        negate => true\n\t\t\t        what => \"previous\"\n\t\t\t}\n\t\t\tif \"_grokparsefailure\" in [tags] {\n\t\t\t\tdrop { }\n\t\t\t}\n\t\t\tgrok {\n\t\t\t      \tpatterns_dir => \"/usr/local/logstash/patterns\"\n\t\t\t      \tmatch => [ \"message\", \"%{CATALINALOG}\" ]\n\t\t\t}\n\t\t\tdate {\n\t\t\t      \tmatch => [ \"timestamp\", \"yyyy-MM-dd HH:mm:ss,SSS Z\", \"MMM dd, yyyy HH:mm:ss a\" ]\n\t\t\t}\n\t\t}\n\t\tif [type] == \"apache\" {\n\t\t\tgrok {\n\t\t\t\tpatterns_dir => \"/usr/local/logstash/patterns\"\n\t\t      \t\tmatch => { \"message\" => \"%{COMBINEDAPACHELOG}\" }\n\t\t    \t}\n\t\t    \tdate {\n\t\t      \t\tmatch => [ \"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n\t\t    \t}\n\t\t}\n\t}\n\t\n\toutput {\n\t\tstdout {}\n\t\telasticsearch {\n\t\t\tcluster => \"elasticsearch\"\n\t\t\tprotocol => \"http\"\n\t\t\tembedded => true\n\t\t}\n\t}\n\n然后你就可以重启一下logstash看结果啦。注意这里，我配置的是`start_position => \"beginning\"`，字面意思就是从日志文件头部开始解析，这样可以把一些原始日志给收集过来，但是可能会造成一些重复日志~~\n\n\nLog4j-->Logstash\n---\n\n其实通过上面两个场景，你大概也知道是个什么尿性了，对，就是指定好要监控的日志文件（input），然后解析对应的格式（filter），然后导入到对应的存储中（output），而且整个过程是管道化的，前面提到了，由于咱们的测试环境是单机本地化，所以并没有使用消息队列，否则你会感受到更明显的管道化风格。\n\n把log4j产生的日志导入到logstash要做的事儿依然如此，不过官方提供了更简单的方式：[log4j-jsonevent-layout](https://github.com/logstash/log4j-jsonevent-layout)，这玩意儿的作用相当于我们在nginx中干的事儿，直接将log4j的日志格式定义成json的，有助于性能提升~\n\n剩下的事儿就是老样子了，只需要改一下我们的logstash配置文件即可：\n\n\t......\n\tfile {\n\t\ttype => \"log4j\"\n\t\tpath => [\"/usr/local/tomcat/logs/logTest.log\"]\n\t\tsincedb_path => \"/dev/null\"\n\t\tstart_position => \"beginning\"\n\t}\n\t......\n\n\n高可用\n---\n\n有经验的童鞋不难看出，上图中存在单点故障，但，其实是可以通过把对应单点集群化部署来增加这套架构的可用性和处理性能，具体可参考[ElasticSearch+LogStash+Kibana+Redis日志服务的高可用方案](http://nkcoder.github.io/blog/20141106/elkr-log-platform-deploy-ha/)。\n\n总结\n---\n\n上面的场景和简单介绍都是非常入门级的，放在线上场景中肯定太粗糙了，肯定还需要考量更多的因素，例如数据量，日志大小，通信方式等，不过我相信到现在大家应该对ELK有了一个基本的认知。\n\n\n参考\n---\n\n[Kibana 中文指南](http://kibana.logstash.es/content/)\n\n[使用ElasticSearch+LogStash+Kibana+Redis搭建日志管理服务](http://nkcoder.github.io/blog/20141031/elkr-log-platform-deploy/)\n\n[使用Logstash收集Nginx日志](http://john88wang.blog.51cto.com/2165294/1632190)\n\n[Logstash Multiline Tomcat and Apache Log Parsing](http://blog.lanyonm.org/articles/2014/01/12/logstash-multiline-tomcat-log-parsing.html)\n\n[Logstash and Log4j](http://drumcoder.co.uk/blog/2014/nov/11/logstash-and-log4j/)","source":"_posts/日志收集架构--ELK.md","raw":"title: 日志收集架构－ELK\ndate: 2015-06-05 09:37:12\ntags: \n- Logstash\n- ElasticSearch\n- Kibana\ncategories: 运维\n---\n\n本周的工作计划是调研并测试ELK，那什么是ELK呢？简而言之就是开源的主流的日志收集与分析系统。\n<!--more-->\nELK是三个工具的总称：\n\n- E: ElasticSearch\n- L: Logstash\n- K: Kibana\n\n我这里主要想强调的，是它们三个组合起来以后，提供强大的**开箱即用**的日志收集和检索功能，这对于创业公司和小团队来说，简直就是完美~\n\n**可能对我来讲，最不理想的就是它基于ruby语言，这么高逼格的语言我不会啊……**\n\n但是也不要太乐观，社区和大牛们表示，想用好这三个工具也不是一件很简单的事儿，我们本次的目的，就是搞清楚这三者之间的关系和它们各自的作用，并最终搭建一个可测试环境，好吧，废话不多说，开始吧。\n\n最为强迫症的我，一向是尽可能用最新版本，也就是说，我们本次尝试搭建的ELK环境，软件版本分别为：\n\n- [ElasticSearch-1.5.2](https://www.elastic.co/downloads/elasticsearch)\n- [Logstash-1.5.0](https://www.elastic.co/downloads/logstash)\n- [Kibana-4.0.2](https://www.elastic.co/downloads/kibana)\n\n安装\n---\n\n之前提过“开箱即用”，绝对不是吹牛逼的，安装流程就是：\n\n\t下载 --> 解压 --> 简单配置 --> 运行 --> 看效果\n\n完全不需要编译安装，真是醉了~我们从logstash开始，下载上面给的版本后，解压并拷贝到`/usr/local`下：\n\n\t$ cd /usr/local/logstash\n\t$ mkdir conf logs\n\n我们创建了两个文件夹，分别用来放配置文件和日志。\n\n接下来我们先简单的配置一下logstash，在conf下创建一个central.conf，内容如下：\n\n\tinput {\n\t\tstdin {}\n\t}\n\n\toutput {\n\t\tstdout {}\n\t\telasticsearch {\n\t\t\tcluster => \"elasticsearch\"\n\t\t\tcodec => \"json\"\n\t\t\tprotocol => \"http\"\n\t\t}   \n\t}\n\n保存，运行下面这个命令启动：\n\n\t$ ./bin/logstash agent --verbose --config ./conf/central.conf --log ./logs/stdout.log\n\n接下来安装elasticsearch，一样简单，解压到`/usr/local/`下，然后直接启动：\n\n\t$ ./bin/elasticsearch -d\n\n最后来配置kibana，解压到`/usr/local/`下，然后直接启动：\n\n\t$ ./bin/kibana\n\n我们使用的是kibana默认的配置，现在可以直接在浏览器中访问： [http://127.0.0.1:5601](http://127.0.0.1:5601)。\n\n怎么测试我们安装的是否成功呢？很简单，在刚才我们执行logstash的终端中，直接输入字符串：hello world，然后刷新kibana页面，你将会看到对应的日志信息~~\n\n知道什么叫开箱即用了么？\n\n搭建好了，不等于我们就可以直接使用在产品环境下了，毕竟这个例子貌似没有卵用...下面我们来聊一下理论知识。\n\n\n架构\n---\n\n![](http://nkcoder.github.io/images/post/ELKR-log-platform.jpg)\n\n说明：\n\n- 多个独立的agent(Shipper)负责收集不同来源的数据，一个中心agent(Indexer)负责汇总和分析数据，在中心agent前的Broker(使用redis实现)作为缓冲区，中心agent后的ElasticSearch用于存储和搜索数据，前端的Kibana提供丰富的图表展示。\n- Shipper表示日志收集，使用LogStash收集各种来源的日志数据，可以是系统日志、文件、redis、mq等等；\n- Broker作为远程agent与中心agent之间的缓冲区，使用redis实现，一是可以提高系统的性能，二是可以提高系统的可靠性，当中心agent提取数据失败时，数据保存在redis中，而不至于丢失；\n- 中心agent也是LogStash，从Broker中提取数据，可以执行相关的分析和处理(Filter)；\n- ElasticSearch用于存储最终的数据，并提供搜索功能；\n- Kibana提供一个简单、丰富的web界面，数据来自于ElasticSearch，支持各种查询、统计和展示；\n\n上面这个图是参考前辈的（下面的参考列表中有具体链接），需要知道的是上面的这种搭配并非是唯一的，例如你可以不使用redis而是用kafka来做消息队列，你也可以让Shipper直接从你希望的日志源中拉取日志数据，如你喜欢你也可以让数据存到Elasticsearch后再存一份到hdfs中，反正大牛们说logstash的插件非常的多，我是信了~~\n\n接下来，我们就试试用logstash来获取一些常用的web server的access log，例如：nginx，tomcat等。由于测试环境都是在同一台机器上本地完成，所有就不需要劳烦消息队列中间件了。\n\n\nNginx-->Logstash\n---\n\n根据上图所示，我们其实就是让logstash去监听nginx的日志文件，首先我们得先修改一下上面的那个logstash的配置文件：\n\n\tinput {\n\t\tfile {\n\t\t\ttype => \"nginx_access\"\n\t\t\tpath => [\"/usr/local/nginx/logs/*.log\"]\n\t\t\texclude => [\"*.gz\",\"error.log\",\"nginx.pid\"]\n\t\t\tsincedb_path => \"/dev/null\"\n\t\t\tcodec => \"json\"\t\n\t\t}\n\t}\n\t\n\toutput {\n\t\tstdout {}\n\t\telasticsearch {\n\t\t\tcluster => \"elasticsearch\"\n\t\t\tcodec => \"json\"\n\t\t\tprotocol => \"http\"\n\t\t}\n\t}\n\nok，接下来我们就需要安装nginx了，这部分我就不多讲了，安装好nginx后在启动之前，我们需要先修改一下nginx的配置文件（`nginx.conf`）:\n\t\n\t......\n\tlog_format   json  '{\"@timestamp\":\"$time_iso8601\",'\n\t\t\t\t'\"@source\":\"$server_addr\",'\n\t\t\t\t'\"@nginx_fields\":{'\n\t\t\t\t\t'\"client\":\"$remote_addr\",'\n\t\t\t\t\t'\"size\":$body_bytes_sent,'\n\t\t\t\t\t'\"responsetime\":\"$request_time\",'\n\t\t\t\t\t'\"upstreamtime\":\"$upstream_response_time\",'\n\t\t\t\t\t'\"upstreamaddr\":\"$upstream_addr\",'\n\t\t\t\t\t'\"request_method\":\"$request_method\",'\n\t\t\t\t\t'\"domain\":\"$host\",'\n\t\t\t\t\t'\"url\":\"$uri\",'\n\t\t\t\t\t'\"http_user_agent\":\"$http_user_agent\",'\n\t\t\t\t\t'\"status\":$status,'\n\t\t\t\t\t'\"x_forwarded_for\":\"$http_x_forwarded_for\"'\n\t\t\t\t'}'\n\t\t\t'}';\n\n    access_log  logs/access.log  json;\n\t......\n\n大功告成了，启动nginx后，浏览器访问nginx下的页面，你会看到kibana中的对应更新。\n\n\nTomcat-->Logstash\n---\n\ntomcat的日志比nginx要复杂一些，打开对应的日志文件（`catalina.out`）,你会发现类似下面这样的日志结构：\n\n\tJun 12, 2014 11:17:34 AM org.apache.catalina.core.AprLifecycleListener init\n\tINFO: The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib\n\tJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\n\tINFO: Initializing ProtocolHandler [\"http-bio-8080\"]\n\tJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\n\tSEVERE: Failed to initialize end point associated with ProtocolHandler [\"http-bio-8080\"]\n\tjava.net.BindException: Address already in use <null>:8080\n\t\tat org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:411)\n\t\tat org.apache.tomcat.util.net.AbstractEndpoint.init(AbstractEndpoint.java:640)\n\t\tat org.apache.coyote.AbstractProtocol.init(AbstractProtocol.java:434)\n\t\tat org.apache.coyote.http11.AbstractHttp11JsseProtocol.init(AbstractHttp11JsseProtocol.java:119)\n\t\tat org.apache.catalina.connector.Connector.initInternal(Connector.java:978)\n\t\tat org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n\t\tat org.apache.catalina.core.StandardService.initInternal(StandardService.java:559)\n\t\tat org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n\t\tat org.apache.catalina.core.StandardServer.initInternal(StandardServer.java:813)\n\t\tat org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n\t\tat org.apache.catalina.startup.Catalina.load(Catalina.java:638)\n\t\tat org.apache.catalina.startup.Catalina.load(Catalina.java:663)\n\t\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\t\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\t\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\t\tat java.lang.reflect.Method.invoke(Method.java:606)\n\t\tat org.apache.catalina.startup.Bootstrap.load(Bootstrap.java:280)\n\t\tat org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:454)\n\tCaused by: java.net.BindException: Address already in use\n\t\tat java.net.PlainSocketImpl.socketBind(Native Method)\n\t\tat java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)\n\t\tat java.net.ServerSocket.bind(ServerSocket.java:376)\n\t\tat java.net.ServerSocket.<init>(ServerSocket.java:237)\n\t\tat java.net.ServerSocket.<init>(ServerSocket.java:181)\n\t\tat org.apache.tomcat.util.net.DefaultServerSocketFactory.createSocket(DefaultServerSocketFactory.java:49)\n\t\tat org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:398)\n\t\t... 17 more\n\n无法直视啊简直，不过还好，logstash提供了强大的插件来帮助我们解析各种各样的日志输出结构，分析一下可以得出，日志结构是：时间戳，后面跟着类名，再后面跟着日志信息，这样，我们就可以根据这种结构来写过滤规则：\n\t\n\tCOMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-)\n\tCOMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}\n\n\tCATALINA_DATESTAMP %{MONTH} %{MONTHDAY}, 20%{YEAR} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) (?:AM|PM)\n\tCATALINALOG %{CATALINA_DATESTAMP:timestamp} %{JAVACLASS:class} %{JAVALOGMESSAGE:logmessage}\n\n我们把[这些规则](https://gist.github.com/LanyonM/8390458#file-grok-patterns)存储在一个文件（`/logstash安装路径/patterns/grok-patterns`）中，接下来我们要改写logstash的配置文件了：\n\n\tinput {\n\t\tfile {\n\t\t\ttype => \"tomcat_access\"\n\t\t\tpath => [\"/usr/local/tomcat/logs/catalina.out\"]\n\t\t\texclude => [\"*.log\",\"*.txt\"]\n\t\t\tsincedb_path => \"/dev/null\"\n\t\t\tstart_position => \"beginning\"\n\t\t}\n\t\tfile {\n\t\t\ttype => \"apache_access\"\n\t\t\tpath => [\"/usr/local/tomcat/logs/*.txt\"]\n\t\t\texclude => [\"*.log\"]\n\t\t\tsincedb_path => \"/dev/null\"\n\t\t\tstart_position => \"beginning\"\n\t\t}\n\t}\n\t\n\tfilter {\n\t\tif [type] == \"tomcat_access\" {\n\t\t\tmultiline {\n\t\t\t\tpatterns_dir => \"/usr/local/logstash/patterns\"\n\t\t\t\tpattern => \"(^%{CATALINA_DATESTAMP})\"\n\t\t\t        negate => true\n\t\t\t        what => \"previous\"\n\t\t\t}\n\t\t\tif \"_grokparsefailure\" in [tags] {\n\t\t\t\tdrop { }\n\t\t\t}\n\t\t\tgrok {\n\t\t\t      \tpatterns_dir => \"/usr/local/logstash/patterns\"\n\t\t\t      \tmatch => [ \"message\", \"%{CATALINALOG}\" ]\n\t\t\t}\n\t\t\tdate {\n\t\t\t      \tmatch => [ \"timestamp\", \"yyyy-MM-dd HH:mm:ss,SSS Z\", \"MMM dd, yyyy HH:mm:ss a\" ]\n\t\t\t}\n\t\t}\n\t\tif [type] == \"apache\" {\n\t\t\tgrok {\n\t\t\t\tpatterns_dir => \"/usr/local/logstash/patterns\"\n\t\t      \t\tmatch => { \"message\" => \"%{COMBINEDAPACHELOG}\" }\n\t\t    \t}\n\t\t    \tdate {\n\t\t      \t\tmatch => [ \"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n\t\t    \t}\n\t\t}\n\t}\n\t\n\toutput {\n\t\tstdout {}\n\t\telasticsearch {\n\t\t\tcluster => \"elasticsearch\"\n\t\t\tprotocol => \"http\"\n\t\t\tembedded => true\n\t\t}\n\t}\n\n然后你就可以重启一下logstash看结果啦。注意这里，我配置的是`start_position => \"beginning\"`，字面意思就是从日志文件头部开始解析，这样可以把一些原始日志给收集过来，但是可能会造成一些重复日志~~\n\n\nLog4j-->Logstash\n---\n\n其实通过上面两个场景，你大概也知道是个什么尿性了，对，就是指定好要监控的日志文件（input），然后解析对应的格式（filter），然后导入到对应的存储中（output），而且整个过程是管道化的，前面提到了，由于咱们的测试环境是单机本地化，所以并没有使用消息队列，否则你会感受到更明显的管道化风格。\n\n把log4j产生的日志导入到logstash要做的事儿依然如此，不过官方提供了更简单的方式：[log4j-jsonevent-layout](https://github.com/logstash/log4j-jsonevent-layout)，这玩意儿的作用相当于我们在nginx中干的事儿，直接将log4j的日志格式定义成json的，有助于性能提升~\n\n剩下的事儿就是老样子了，只需要改一下我们的logstash配置文件即可：\n\n\t......\n\tfile {\n\t\ttype => \"log4j\"\n\t\tpath => [\"/usr/local/tomcat/logs/logTest.log\"]\n\t\tsincedb_path => \"/dev/null\"\n\t\tstart_position => \"beginning\"\n\t}\n\t......\n\n\n高可用\n---\n\n有经验的童鞋不难看出，上图中存在单点故障，但，其实是可以通过把对应单点集群化部署来增加这套架构的可用性和处理性能，具体可参考[ElasticSearch+LogStash+Kibana+Redis日志服务的高可用方案](http://nkcoder.github.io/blog/20141106/elkr-log-platform-deploy-ha/)。\n\n总结\n---\n\n上面的场景和简单介绍都是非常入门级的，放在线上场景中肯定太粗糙了，肯定还需要考量更多的因素，例如数据量，日志大小，通信方式等，不过我相信到现在大家应该对ELK有了一个基本的认知。\n\n\n参考\n---\n\n[Kibana 中文指南](http://kibana.logstash.es/content/)\n\n[使用ElasticSearch+LogStash+Kibana+Redis搭建日志管理服务](http://nkcoder.github.io/blog/20141031/elkr-log-platform-deploy/)\n\n[使用Logstash收集Nginx日志](http://john88wang.blog.51cto.com/2165294/1632190)\n\n[Logstash Multiline Tomcat and Apache Log Parsing](http://blog.lanyonm.org/articles/2014/01/12/logstash-multiline-tomcat-log-parsing.html)\n\n[Logstash and Log4j](http://drumcoder.co.uk/blog/2014/nov/11/logstash-and-log4j/)","slug":"日志收集架构--ELK","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ylb002fgtfyxvdbg42h","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本周的工作计划是调研并测试ELK，那什么是ELK呢？简而言之就是开源的主流的日志收集与分析系统。<br><a id=\"more\"></a><br>ELK是三个工具的总称：</p>\n<ul>\n<li>E: ElasticSearch</li>\n<li>L: Logstash</li>\n<li>K: Kibana</li>\n</ul>\n<p>我这里主要想强调的，是它们三个组合起来以后，提供强大的<strong>开箱即用</strong>的日志收集和检索功能，这对于创业公司和小团队来说，简直就是完美~</p>\n<p><strong>可能对我来讲，最不理想的就是它基于ruby语言，这么高逼格的语言我不会啊……</strong></p>\n<p>但是也不要太乐观，社区和大牛们表示，想用好这三个工具也不是一件很简单的事儿，我们本次的目的，就是搞清楚这三者之间的关系和它们各自的作用，并最终搭建一个可测试环境，好吧，废话不多说，开始吧。</p>\n<p>最为强迫症的我，一向是尽可能用最新版本，也就是说，我们本次尝试搭建的ELK环境，软件版本分别为：</p>\n<ul>\n<li><a href=\"https://www.elastic.co/downloads/elasticsearch\" target=\"_blank\" rel=\"external\">ElasticSearch-1.5.2</a></li>\n<li><a href=\"https://www.elastic.co/downloads/logstash\" target=\"_blank\" rel=\"external\">Logstash-1.5.0</a></li>\n<li><a href=\"https://www.elastic.co/downloads/kibana\" target=\"_blank\" rel=\"external\">Kibana-4.0.2</a></li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>之前提过“开箱即用”，绝对不是吹牛逼的，安装流程就是：</p>\n<pre><code>下载 --&gt; 解压 --&gt; 简单配置 --&gt; 运行 --&gt; 看效果\n</code></pre><p>完全不需要编译安装，真是醉了~我们从logstash开始，下载上面给的版本后，解压并拷贝到<code>/usr/local</code>下：</p>\n<pre><code>$ cd /usr/local/logstash\n$ mkdir conf logs\n</code></pre><p>我们创建了两个文件夹，分别用来放配置文件和日志。</p>\n<p>接下来我们先简单的配置一下logstash，在conf下创建一个central.conf，内容如下：</p>\n<pre><code>input {\n    stdin {}\n}\n\noutput {\n    stdout {}\n    elasticsearch {\n        cluster =&gt; &quot;elasticsearch&quot;\n        codec =&gt; &quot;json&quot;\n        protocol =&gt; &quot;http&quot;\n    }   \n}\n</code></pre><p>保存，运行下面这个命令启动：</p>\n<pre><code>$ ./bin/logstash agent --verbose --config ./conf/central.conf --log ./logs/stdout.log\n</code></pre><p>接下来安装elasticsearch，一样简单，解压到<code>/usr/local/</code>下，然后直接启动：</p>\n<pre><code>$ ./bin/elasticsearch -d\n</code></pre><p>最后来配置kibana，解压到<code>/usr/local/</code>下，然后直接启动：</p>\n<pre><code>$ ./bin/kibana\n</code></pre><p>我们使用的是kibana默认的配置，现在可以直接在浏览器中访问： <a href=\"http://127.0.0.1:5601\" target=\"_blank\" rel=\"external\">http://127.0.0.1:5601</a>。</p>\n<p>怎么测试我们安装的是否成功呢？很简单，在刚才我们执行logstash的终端中，直接输入字符串：hello world，然后刷新kibana页面，你将会看到对应的日志信息~~</p>\n<p>知道什么叫开箱即用了么？</p>\n<p>搭建好了，不等于我们就可以直接使用在产品环境下了，毕竟这个例子貌似没有卵用…下面我们来聊一下理论知识。</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p><img src=\"http://nkcoder.github.io/images/post/ELKR-log-platform.jpg\" alt=\"\"></p>\n<p>说明：</p>\n<ul>\n<li>多个独立的agent(Shipper)负责收集不同来源的数据，一个中心agent(Indexer)负责汇总和分析数据，在中心agent前的Broker(使用redis实现)作为缓冲区，中心agent后的ElasticSearch用于存储和搜索数据，前端的Kibana提供丰富的图表展示。</li>\n<li>Shipper表示日志收集，使用LogStash收集各种来源的日志数据，可以是系统日志、文件、redis、mq等等；</li>\n<li>Broker作为远程agent与中心agent之间的缓冲区，使用redis实现，一是可以提高系统的性能，二是可以提高系统的可靠性，当中心agent提取数据失败时，数据保存在redis中，而不至于丢失；</li>\n<li>中心agent也是LogStash，从Broker中提取数据，可以执行相关的分析和处理(Filter)；</li>\n<li>ElasticSearch用于存储最终的数据，并提供搜索功能；</li>\n<li>Kibana提供一个简单、丰富的web界面，数据来自于ElasticSearch，支持各种查询、统计和展示；</li>\n</ul>\n<p>上面这个图是参考前辈的（下面的参考列表中有具体链接），需要知道的是上面的这种搭配并非是唯一的，例如你可以不使用redis而是用kafka来做消息队列，你也可以让Shipper直接从你希望的日志源中拉取日志数据，如你喜欢你也可以让数据存到Elasticsearch后再存一份到hdfs中，反正大牛们说logstash的插件非常的多，我是信了~~</p>\n<p>接下来，我们就试试用logstash来获取一些常用的web server的access log，例如：nginx，tomcat等。由于测试环境都是在同一台机器上本地完成，所有就不需要劳烦消息队列中间件了。</p>\n<h2 id=\"Nginx–-gt-Logstash\"><a href=\"#Nginx–-gt-Logstash\" class=\"headerlink\" title=\"Nginx–&gt;Logstash\"></a>Nginx–&gt;Logstash</h2><p>根据上图所示，我们其实就是让logstash去监听nginx的日志文件，首先我们得先修改一下上面的那个logstash的配置文件：</p>\n<pre><code>input {\n    file {\n        type =&gt; &quot;nginx_access&quot;\n        path =&gt; [&quot;/usr/local/nginx/logs/*.log&quot;]\n        exclude =&gt; [&quot;*.gz&quot;,&quot;error.log&quot;,&quot;nginx.pid&quot;]\n        sincedb_path =&gt; &quot;/dev/null&quot;\n        codec =&gt; &quot;json&quot;    \n    }\n}\n\noutput {\n    stdout {}\n    elasticsearch {\n        cluster =&gt; &quot;elasticsearch&quot;\n        codec =&gt; &quot;json&quot;\n        protocol =&gt; &quot;http&quot;\n    }\n}\n</code></pre><p>ok，接下来我们就需要安装nginx了，这部分我就不多讲了，安装好nginx后在启动之前，我们需要先修改一下nginx的配置文件（<code>nginx.conf</code>）:</p>\n<pre><code>......\nlog_format   json  &apos;{&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos;\n            &apos;&quot;@source&quot;:&quot;$server_addr&quot;,&apos;\n            &apos;&quot;@nginx_fields&quot;:{&apos;\n                &apos;&quot;client&quot;:&quot;$remote_addr&quot;,&apos;\n                &apos;&quot;size&quot;:$body_bytes_sent,&apos;\n                &apos;&quot;responsetime&quot;:&quot;$request_time&quot;,&apos;\n                &apos;&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,&apos;\n                &apos;&quot;upstreamaddr&quot;:&quot;$upstream_addr&quot;,&apos;\n                &apos;&quot;request_method&quot;:&quot;$request_method&quot;,&apos;\n                &apos;&quot;domain&quot;:&quot;$host&quot;,&apos;\n                &apos;&quot;url&quot;:&quot;$uri&quot;,&apos;\n                &apos;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&apos;\n                &apos;&quot;status&quot;:$status,&apos;\n                &apos;&quot;x_forwarded_for&quot;:&quot;$http_x_forwarded_for&quot;&apos;\n            &apos;}&apos;\n        &apos;}&apos;;\n\naccess_log  logs/access.log  json;\n......\n</code></pre><p>大功告成了，启动nginx后，浏览器访问nginx下的页面，你会看到kibana中的对应更新。</p>\n<h2 id=\"Tomcat–-gt-Logstash\"><a href=\"#Tomcat–-gt-Logstash\" class=\"headerlink\" title=\"Tomcat–&gt;Logstash\"></a>Tomcat–&gt;Logstash</h2><p>tomcat的日志比nginx要复杂一些，打开对应的日志文件（<code>catalina.out</code>）,你会发现类似下面这样的日志结构：</p>\n<pre><code>Jun 12, 2014 11:17:34 AM org.apache.catalina.core.AprLifecycleListener init\nINFO: The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib\nJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\nINFO: Initializing ProtocolHandler [&quot;http-bio-8080&quot;]\nJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\nSEVERE: Failed to initialize end point associated with ProtocolHandler [&quot;http-bio-8080&quot;]\njava.net.BindException: Address already in use &lt;null&gt;:8080\n    at org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:411)\n    at org.apache.tomcat.util.net.AbstractEndpoint.init(AbstractEndpoint.java:640)\n    at org.apache.coyote.AbstractProtocol.init(AbstractProtocol.java:434)\n    at org.apache.coyote.http11.AbstractHttp11JsseProtocol.init(AbstractHttp11JsseProtocol.java:119)\n    at org.apache.catalina.connector.Connector.initInternal(Connector.java:978)\n    at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n    at org.apache.catalina.core.StandardService.initInternal(StandardService.java:559)\n    at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n    at org.apache.catalina.core.StandardServer.initInternal(StandardServer.java:813)\n    at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n    at org.apache.catalina.startup.Catalina.load(Catalina.java:638)\n    at org.apache.catalina.startup.Catalina.load(Catalina.java:663)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.apache.catalina.startup.Bootstrap.load(Bootstrap.java:280)\n    at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:454)\nCaused by: java.net.BindException: Address already in use\n    at java.net.PlainSocketImpl.socketBind(Native Method)\n    at java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)\n    at java.net.ServerSocket.bind(ServerSocket.java:376)\n    at java.net.ServerSocket.&lt;init&gt;(ServerSocket.java:237)\n    at java.net.ServerSocket.&lt;init&gt;(ServerSocket.java:181)\n    at org.apache.tomcat.util.net.DefaultServerSocketFactory.createSocket(DefaultServerSocketFactory.java:49)\n    at org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:398)\n    ... 17 more\n</code></pre><p>无法直视啊简直，不过还好，logstash提供了强大的插件来帮助我们解析各种各样的日志输出结构，分析一下可以得出，日志结构是：时间戳，后面跟着类名，再后面跟着日志信息，这样，我们就可以根据这种结构来写过滤规则：</p>\n<pre><code>COMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] &quot;(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})&quot; %{NUMBER:response} (?:%{NUMBER:bytes}|-)\nCOMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}\n\nCATALINA_DATESTAMP %{MONTH} %{MONTHDAY}, 20%{YEAR} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) (?:AM|PM)\nCATALINALOG %{CATALINA_DATESTAMP:timestamp} %{JAVACLASS:class} %{JAVALOGMESSAGE:logmessage}\n</code></pre><p>我们把<a href=\"https://gist.github.com/LanyonM/8390458#file-grok-patterns\" target=\"_blank\" rel=\"external\">这些规则</a>存储在一个文件（<code>/logstash安装路径/patterns/grok-patterns</code>）中，接下来我们要改写logstash的配置文件了：</p>\n<pre><code>input {\n    file {\n        type =&gt; &quot;tomcat_access&quot;\n        path =&gt; [&quot;/usr/local/tomcat/logs/catalina.out&quot;]\n        exclude =&gt; [&quot;*.log&quot;,&quot;*.txt&quot;]\n        sincedb_path =&gt; &quot;/dev/null&quot;\n        start_position =&gt; &quot;beginning&quot;\n    }\n    file {\n        type =&gt; &quot;apache_access&quot;\n        path =&gt; [&quot;/usr/local/tomcat/logs/*.txt&quot;]\n        exclude =&gt; [&quot;*.log&quot;]\n        sincedb_path =&gt; &quot;/dev/null&quot;\n        start_position =&gt; &quot;beginning&quot;\n    }\n}\n\nfilter {\n    if [type] == &quot;tomcat_access&quot; {\n        multiline {\n            patterns_dir =&gt; &quot;/usr/local/logstash/patterns&quot;\n            pattern =&gt; &quot;(^%{CATALINA_DATESTAMP})&quot;\n                negate =&gt; true\n                what =&gt; &quot;previous&quot;\n        }\n        if &quot;_grokparsefailure&quot; in [tags] {\n            drop { }\n        }\n        grok {\n                  patterns_dir =&gt; &quot;/usr/local/logstash/patterns&quot;\n                  match =&gt; [ &quot;message&quot;, &quot;%{CATALINALOG}&quot; ]\n        }\n        date {\n                  match =&gt; [ &quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss,SSS Z&quot;, &quot;MMM dd, yyyy HH:mm:ss a&quot; ]\n        }\n    }\n    if [type] == &quot;apache&quot; {\n        grok {\n            patterns_dir =&gt; &quot;/usr/local/logstash/patterns&quot;\n                  match =&gt; { &quot;message&quot; =&gt; &quot;%{COMBINEDAPACHELOG}&quot; }\n            }\n            date {\n                  match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]\n            }\n    }\n}\n\noutput {\n    stdout {}\n    elasticsearch {\n        cluster =&gt; &quot;elasticsearch&quot;\n        protocol =&gt; &quot;http&quot;\n        embedded =&gt; true\n    }\n}\n</code></pre><p>然后你就可以重启一下logstash看结果啦。注意这里，我配置的是<code>start_position =&gt; &quot;beginning&quot;</code>，字面意思就是从日志文件头部开始解析，这样可以把一些原始日志给收集过来，但是可能会造成一些重复日志~~</p>\n<h2 id=\"Log4j–-gt-Logstash\"><a href=\"#Log4j–-gt-Logstash\" class=\"headerlink\" title=\"Log4j–&gt;Logstash\"></a>Log4j–&gt;Logstash</h2><p>其实通过上面两个场景，你大概也知道是个什么尿性了，对，就是指定好要监控的日志文件（input），然后解析对应的格式（filter），然后导入到对应的存储中（output），而且整个过程是管道化的，前面提到了，由于咱们的测试环境是单机本地化，所以并没有使用消息队列，否则你会感受到更明显的管道化风格。</p>\n<p>把log4j产生的日志导入到logstash要做的事儿依然如此，不过官方提供了更简单的方式：<a href=\"https://github.com/logstash/log4j-jsonevent-layout\" target=\"_blank\" rel=\"external\">log4j-jsonevent-layout</a>，这玩意儿的作用相当于我们在nginx中干的事儿，直接将log4j的日志格式定义成json的，有助于性能提升~</p>\n<p>剩下的事儿就是老样子了，只需要改一下我们的logstash配置文件即可：</p>\n<pre><code>......\nfile {\n    type =&gt; &quot;log4j&quot;\n    path =&gt; [&quot;/usr/local/tomcat/logs/logTest.log&quot;]\n    sincedb_path =&gt; &quot;/dev/null&quot;\n    start_position =&gt; &quot;beginning&quot;\n}\n......\n</code></pre><h2 id=\"高可用\"><a href=\"#高可用\" class=\"headerlink\" title=\"高可用\"></a>高可用</h2><p>有经验的童鞋不难看出，上图中存在单点故障，但，其实是可以通过把对应单点集群化部署来增加这套架构的可用性和处理性能，具体可参考<a href=\"http://nkcoder.github.io/blog/20141106/elkr-log-platform-deploy-ha/\" target=\"_blank\" rel=\"external\">ElasticSearch+LogStash+Kibana+Redis日志服务的高可用方案</a>。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>上面的场景和简单介绍都是非常入门级的，放在线上场景中肯定太粗糙了，肯定还需要考量更多的因素，例如数据量，日志大小，通信方式等，不过我相信到现在大家应该对ELK有了一个基本的认知。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"http://kibana.logstash.es/content/\" target=\"_blank\" rel=\"external\">Kibana 中文指南</a></p>\n<p><a href=\"http://nkcoder.github.io/blog/20141031/elkr-log-platform-deploy/\" target=\"_blank\" rel=\"external\">使用ElasticSearch+LogStash+Kibana+Redis搭建日志管理服务</a></p>\n<p><a href=\"http://john88wang.blog.51cto.com/2165294/1632190\" target=\"_blank\" rel=\"external\">使用Logstash收集Nginx日志</a></p>\n<p><a href=\"http://blog.lanyonm.org/articles/2014/01/12/logstash-multiline-tomcat-log-parsing.html\" target=\"_blank\" rel=\"external\">Logstash Multiline Tomcat and Apache Log Parsing</a></p>\n<p><a href=\"http://drumcoder.co.uk/blog/2014/nov/11/logstash-and-log4j/\" target=\"_blank\" rel=\"external\">Logstash and Log4j</a></p>\n","excerpt":"<p>本周的工作计划是调研并测试ELK，那什么是ELK呢？简而言之就是开源的主流的日志收集与分析系统。<br>","more":"<br>ELK是三个工具的总称：</p>\n<ul>\n<li>E: ElasticSearch</li>\n<li>L: Logstash</li>\n<li>K: Kibana</li>\n</ul>\n<p>我这里主要想强调的，是它们三个组合起来以后，提供强大的<strong>开箱即用</strong>的日志收集和检索功能，这对于创业公司和小团队来说，简直就是完美~</p>\n<p><strong>可能对我来讲，最不理想的就是它基于ruby语言，这么高逼格的语言我不会啊……</strong></p>\n<p>但是也不要太乐观，社区和大牛们表示，想用好这三个工具也不是一件很简单的事儿，我们本次的目的，就是搞清楚这三者之间的关系和它们各自的作用，并最终搭建一个可测试环境，好吧，废话不多说，开始吧。</p>\n<p>最为强迫症的我，一向是尽可能用最新版本，也就是说，我们本次尝试搭建的ELK环境，软件版本分别为：</p>\n<ul>\n<li><a href=\"https://www.elastic.co/downloads/elasticsearch\">ElasticSearch-1.5.2</a></li>\n<li><a href=\"https://www.elastic.co/downloads/logstash\">Logstash-1.5.0</a></li>\n<li><a href=\"https://www.elastic.co/downloads/kibana\">Kibana-4.0.2</a></li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>之前提过“开箱即用”，绝对不是吹牛逼的，安装流程就是：</p>\n<pre><code>下载 --&gt; 解压 --&gt; 简单配置 --&gt; 运行 --&gt; 看效果\n</code></pre><p>完全不需要编译安装，真是醉了~我们从logstash开始，下载上面给的版本后，解压并拷贝到<code>/usr/local</code>下：</p>\n<pre><code>$ cd /usr/local/logstash\n$ mkdir conf logs\n</code></pre><p>我们创建了两个文件夹，分别用来放配置文件和日志。</p>\n<p>接下来我们先简单的配置一下logstash，在conf下创建一个central.conf，内容如下：</p>\n<pre><code>input {\n    stdin {}\n}\n\noutput {\n    stdout {}\n    elasticsearch {\n        cluster =&gt; &quot;elasticsearch&quot;\n        codec =&gt; &quot;json&quot;\n        protocol =&gt; &quot;http&quot;\n    }   \n}\n</code></pre><p>保存，运行下面这个命令启动：</p>\n<pre><code>$ ./bin/logstash agent --verbose --config ./conf/central.conf --log ./logs/stdout.log\n</code></pre><p>接下来安装elasticsearch，一样简单，解压到<code>/usr/local/</code>下，然后直接启动：</p>\n<pre><code>$ ./bin/elasticsearch -d\n</code></pre><p>最后来配置kibana，解压到<code>/usr/local/</code>下，然后直接启动：</p>\n<pre><code>$ ./bin/kibana\n</code></pre><p>我们使用的是kibana默认的配置，现在可以直接在浏览器中访问： <a href=\"http://127.0.0.1:5601\">http://127.0.0.1:5601</a>。</p>\n<p>怎么测试我们安装的是否成功呢？很简单，在刚才我们执行logstash的终端中，直接输入字符串：hello world，然后刷新kibana页面，你将会看到对应的日志信息~~</p>\n<p>知道什么叫开箱即用了么？</p>\n<p>搭建好了，不等于我们就可以直接使用在产品环境下了，毕竟这个例子貌似没有卵用…下面我们来聊一下理论知识。</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p><img src=\"http://nkcoder.github.io/images/post/ELKR-log-platform.jpg\" alt=\"\"></p>\n<p>说明：</p>\n<ul>\n<li>多个独立的agent(Shipper)负责收集不同来源的数据，一个中心agent(Indexer)负责汇总和分析数据，在中心agent前的Broker(使用redis实现)作为缓冲区，中心agent后的ElasticSearch用于存储和搜索数据，前端的Kibana提供丰富的图表展示。</li>\n<li>Shipper表示日志收集，使用LogStash收集各种来源的日志数据，可以是系统日志、文件、redis、mq等等；</li>\n<li>Broker作为远程agent与中心agent之间的缓冲区，使用redis实现，一是可以提高系统的性能，二是可以提高系统的可靠性，当中心agent提取数据失败时，数据保存在redis中，而不至于丢失；</li>\n<li>中心agent也是LogStash，从Broker中提取数据，可以执行相关的分析和处理(Filter)；</li>\n<li>ElasticSearch用于存储最终的数据，并提供搜索功能；</li>\n<li>Kibana提供一个简单、丰富的web界面，数据来自于ElasticSearch，支持各种查询、统计和展示；</li>\n</ul>\n<p>上面这个图是参考前辈的（下面的参考列表中有具体链接），需要知道的是上面的这种搭配并非是唯一的，例如你可以不使用redis而是用kafka来做消息队列，你也可以让Shipper直接从你希望的日志源中拉取日志数据，如你喜欢你也可以让数据存到Elasticsearch后再存一份到hdfs中，反正大牛们说logstash的插件非常的多，我是信了~~</p>\n<p>接下来，我们就试试用logstash来获取一些常用的web server的access log，例如：nginx，tomcat等。由于测试环境都是在同一台机器上本地完成，所有就不需要劳烦消息队列中间件了。</p>\n<h2 id=\"Nginx–-gt-Logstash\"><a href=\"#Nginx–-gt-Logstash\" class=\"headerlink\" title=\"Nginx–&gt;Logstash\"></a>Nginx–&gt;Logstash</h2><p>根据上图所示，我们其实就是让logstash去监听nginx的日志文件，首先我们得先修改一下上面的那个logstash的配置文件：</p>\n<pre><code>input {\n    file {\n        type =&gt; &quot;nginx_access&quot;\n        path =&gt; [&quot;/usr/local/nginx/logs/*.log&quot;]\n        exclude =&gt; [&quot;*.gz&quot;,&quot;error.log&quot;,&quot;nginx.pid&quot;]\n        sincedb_path =&gt; &quot;/dev/null&quot;\n        codec =&gt; &quot;json&quot;    \n    }\n}\n\noutput {\n    stdout {}\n    elasticsearch {\n        cluster =&gt; &quot;elasticsearch&quot;\n        codec =&gt; &quot;json&quot;\n        protocol =&gt; &quot;http&quot;\n    }\n}\n</code></pre><p>ok，接下来我们就需要安装nginx了，这部分我就不多讲了，安装好nginx后在启动之前，我们需要先修改一下nginx的配置文件（<code>nginx.conf</code>）:</p>\n<pre><code>......\nlog_format   json  &apos;{&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos;\n            &apos;&quot;@source&quot;:&quot;$server_addr&quot;,&apos;\n            &apos;&quot;@nginx_fields&quot;:{&apos;\n                &apos;&quot;client&quot;:&quot;$remote_addr&quot;,&apos;\n                &apos;&quot;size&quot;:$body_bytes_sent,&apos;\n                &apos;&quot;responsetime&quot;:&quot;$request_time&quot;,&apos;\n                &apos;&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,&apos;\n                &apos;&quot;upstreamaddr&quot;:&quot;$upstream_addr&quot;,&apos;\n                &apos;&quot;request_method&quot;:&quot;$request_method&quot;,&apos;\n                &apos;&quot;domain&quot;:&quot;$host&quot;,&apos;\n                &apos;&quot;url&quot;:&quot;$uri&quot;,&apos;\n                &apos;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&apos;\n                &apos;&quot;status&quot;:$status,&apos;\n                &apos;&quot;x_forwarded_for&quot;:&quot;$http_x_forwarded_for&quot;&apos;\n            &apos;}&apos;\n        &apos;}&apos;;\n\naccess_log  logs/access.log  json;\n......\n</code></pre><p>大功告成了，启动nginx后，浏览器访问nginx下的页面，你会看到kibana中的对应更新。</p>\n<h2 id=\"Tomcat–-gt-Logstash\"><a href=\"#Tomcat–-gt-Logstash\" class=\"headerlink\" title=\"Tomcat–&gt;Logstash\"></a>Tomcat–&gt;Logstash</h2><p>tomcat的日志比nginx要复杂一些，打开对应的日志文件（<code>catalina.out</code>）,你会发现类似下面这样的日志结构：</p>\n<pre><code>Jun 12, 2014 11:17:34 AM org.apache.catalina.core.AprLifecycleListener init\nINFO: The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib\nJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\nINFO: Initializing ProtocolHandler [&quot;http-bio-8080&quot;]\nJun 12, 2014 11:17:34 AM org.apache.coyote.AbstractProtocol init\nSEVERE: Failed to initialize end point associated with ProtocolHandler [&quot;http-bio-8080&quot;]\njava.net.BindException: Address already in use &lt;null&gt;:8080\n    at org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:411)\n    at org.apache.tomcat.util.net.AbstractEndpoint.init(AbstractEndpoint.java:640)\n    at org.apache.coyote.AbstractProtocol.init(AbstractProtocol.java:434)\n    at org.apache.coyote.http11.AbstractHttp11JsseProtocol.init(AbstractHttp11JsseProtocol.java:119)\n    at org.apache.catalina.connector.Connector.initInternal(Connector.java:978)\n    at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n    at org.apache.catalina.core.StandardService.initInternal(StandardService.java:559)\n    at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n    at org.apache.catalina.core.StandardServer.initInternal(StandardServer.java:813)\n    at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:102)\n    at org.apache.catalina.startup.Catalina.load(Catalina.java:638)\n    at org.apache.catalina.startup.Catalina.load(Catalina.java:663)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.apache.catalina.startup.Bootstrap.load(Bootstrap.java:280)\n    at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:454)\nCaused by: java.net.BindException: Address already in use\n    at java.net.PlainSocketImpl.socketBind(Native Method)\n    at java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)\n    at java.net.ServerSocket.bind(ServerSocket.java:376)\n    at java.net.ServerSocket.&lt;init&gt;(ServerSocket.java:237)\n    at java.net.ServerSocket.&lt;init&gt;(ServerSocket.java:181)\n    at org.apache.tomcat.util.net.DefaultServerSocketFactory.createSocket(DefaultServerSocketFactory.java:49)\n    at org.apache.tomcat.util.net.JIoEndpoint.bind(JIoEndpoint.java:398)\n    ... 17 more\n</code></pre><p>无法直视啊简直，不过还好，logstash提供了强大的插件来帮助我们解析各种各样的日志输出结构，分析一下可以得出，日志结构是：时间戳，后面跟着类名，再后面跟着日志信息，这样，我们就可以根据这种结构来写过滤规则：</p>\n<pre><code>COMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] &quot;(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})&quot; %{NUMBER:response} (?:%{NUMBER:bytes}|-)\nCOMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}\n\nCATALINA_DATESTAMP %{MONTH} %{MONTHDAY}, 20%{YEAR} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) (?:AM|PM)\nCATALINALOG %{CATALINA_DATESTAMP:timestamp} %{JAVACLASS:class} %{JAVALOGMESSAGE:logmessage}\n</code></pre><p>我们把<a href=\"https://gist.github.com/LanyonM/8390458#file-grok-patterns\">这些规则</a>存储在一个文件（<code>/logstash安装路径/patterns/grok-patterns</code>）中，接下来我们要改写logstash的配置文件了：</p>\n<pre><code>input {\n    file {\n        type =&gt; &quot;tomcat_access&quot;\n        path =&gt; [&quot;/usr/local/tomcat/logs/catalina.out&quot;]\n        exclude =&gt; [&quot;*.log&quot;,&quot;*.txt&quot;]\n        sincedb_path =&gt; &quot;/dev/null&quot;\n        start_position =&gt; &quot;beginning&quot;\n    }\n    file {\n        type =&gt; &quot;apache_access&quot;\n        path =&gt; [&quot;/usr/local/tomcat/logs/*.txt&quot;]\n        exclude =&gt; [&quot;*.log&quot;]\n        sincedb_path =&gt; &quot;/dev/null&quot;\n        start_position =&gt; &quot;beginning&quot;\n    }\n}\n\nfilter {\n    if [type] == &quot;tomcat_access&quot; {\n        multiline {\n            patterns_dir =&gt; &quot;/usr/local/logstash/patterns&quot;\n            pattern =&gt; &quot;(^%{CATALINA_DATESTAMP})&quot;\n                negate =&gt; true\n                what =&gt; &quot;previous&quot;\n        }\n        if &quot;_grokparsefailure&quot; in [tags] {\n            drop { }\n        }\n        grok {\n                  patterns_dir =&gt; &quot;/usr/local/logstash/patterns&quot;\n                  match =&gt; [ &quot;message&quot;, &quot;%{CATALINALOG}&quot; ]\n        }\n        date {\n                  match =&gt; [ &quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss,SSS Z&quot;, &quot;MMM dd, yyyy HH:mm:ss a&quot; ]\n        }\n    }\n    if [type] == &quot;apache&quot; {\n        grok {\n            patterns_dir =&gt; &quot;/usr/local/logstash/patterns&quot;\n                  match =&gt; { &quot;message&quot; =&gt; &quot;%{COMBINEDAPACHELOG}&quot; }\n            }\n            date {\n                  match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]\n            }\n    }\n}\n\noutput {\n    stdout {}\n    elasticsearch {\n        cluster =&gt; &quot;elasticsearch&quot;\n        protocol =&gt; &quot;http&quot;\n        embedded =&gt; true\n    }\n}\n</code></pre><p>然后你就可以重启一下logstash看结果啦。注意这里，我配置的是<code>start_position =&gt; &quot;beginning&quot;</code>，字面意思就是从日志文件头部开始解析，这样可以把一些原始日志给收集过来，但是可能会造成一些重复日志~~</p>\n<h2 id=\"Log4j–-gt-Logstash\"><a href=\"#Log4j–-gt-Logstash\" class=\"headerlink\" title=\"Log4j–&gt;Logstash\"></a>Log4j–&gt;Logstash</h2><p>其实通过上面两个场景，你大概也知道是个什么尿性了，对，就是指定好要监控的日志文件（input），然后解析对应的格式（filter），然后导入到对应的存储中（output），而且整个过程是管道化的，前面提到了，由于咱们的测试环境是单机本地化，所以并没有使用消息队列，否则你会感受到更明显的管道化风格。</p>\n<p>把log4j产生的日志导入到logstash要做的事儿依然如此，不过官方提供了更简单的方式：<a href=\"https://github.com/logstash/log4j-jsonevent-layout\">log4j-jsonevent-layout</a>，这玩意儿的作用相当于我们在nginx中干的事儿，直接将log4j的日志格式定义成json的，有助于性能提升~</p>\n<p>剩下的事儿就是老样子了，只需要改一下我们的logstash配置文件即可：</p>\n<pre><code>......\nfile {\n    type =&gt; &quot;log4j&quot;\n    path =&gt; [&quot;/usr/local/tomcat/logs/logTest.log&quot;]\n    sincedb_path =&gt; &quot;/dev/null&quot;\n    start_position =&gt; &quot;beginning&quot;\n}\n......\n</code></pre><h2 id=\"高可用\"><a href=\"#高可用\" class=\"headerlink\" title=\"高可用\"></a>高可用</h2><p>有经验的童鞋不难看出，上图中存在单点故障，但，其实是可以通过把对应单点集群化部署来增加这套架构的可用性和处理性能，具体可参考<a href=\"http://nkcoder.github.io/blog/20141106/elkr-log-platform-deploy-ha/\">ElasticSearch+LogStash+Kibana+Redis日志服务的高可用方案</a>。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>上面的场景和简单介绍都是非常入门级的，放在线上场景中肯定太粗糙了，肯定还需要考量更多的因素，例如数据量，日志大小，通信方式等，不过我相信到现在大家应该对ELK有了一个基本的认知。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"http://kibana.logstash.es/content/\">Kibana 中文指南</a></p>\n<p><a href=\"http://nkcoder.github.io/blog/20141031/elkr-log-platform-deploy/\">使用ElasticSearch+LogStash+Kibana+Redis搭建日志管理服务</a></p>\n<p><a href=\"http://john88wang.blog.51cto.com/2165294/1632190\">使用Logstash收集Nginx日志</a></p>\n<p><a href=\"http://blog.lanyonm.org/articles/2014/01/12/logstash-multiline-tomcat-log-parsing.html\">Logstash Multiline Tomcat and Apache Log Parsing</a></p>\n<p><a href=\"http://drumcoder.co.uk/blog/2014/nov/11/logstash-and-log4j/\">Logstash and Log4j</a></p>"},{"title":"这几天的感想","date":"2015-07-19T01:37:12.000Z","_content":"\n###总结\n\n今天已是离职的第7天，时间过的真尼玛快，不知不觉就给家待了一周了。从一开始因为会议上沟通吃力的失望，到为了捍卫原则的愤怒，再到离职后经济带来的恐慌，到各种职位把手机打爆的惊叹，再到模拟笔试题带来的精神打击，到朋友喝同事给予我的肯定和安慰，再到家人给予的支持，我的情绪就像在坐过山车一样时好时坏。\n\n<!--more-->\n\n不过时间确实是机械的，不管你是快乐还是悲伤，是愤怒还是失望，它都不会为此多停哪怕一亚秒。它以简单粗暴的方式逼着你向前看，这种方式或许也是最行之有效的啦～\n\n在这家公司工作了少说四年吧，说没有感情那绝壁是气话，即便是对公司早已失望，对产品从没看好，但相处了那么久的同事，打磨了那么久的团队，捍卫了多次的团队文化，总让我感到依依不舍。但事实证明，在企业文化面前，谈团队文化并没有什么卵用，几年前我对这句话还抱着鄙视的态度，但这几天发生的事儿让我无奈，也让我成长。\n\n和一个朋友聊天，本来还带着些许成就感的我，被朋友一个问题问的我竟无言以对。大概的对话如下：\n\n> 我：这些年至少学了不少技术，做了几个产品。\n\n> TA：你们的产品有用户么？你们的产品改变了某些人的生活么？提高了哪怕些许人的生活质量了吗？\n\n我tm竟然无言以对，静下来思考一下，才恍然大悟，以前口口声声说要改变世界，却花了四年的时间为的只是老板在饭桌上吹牛逼，如果非要说改善了谁的生活质量，那估计也就公司股东吧～\n\n到底是公司的产品是不是在圈钱，我说不太好，那是市场和营销范畴。我能感觉到的，仅仅是以现在公司的内部状况来说，不太像是做实事儿的，老板的观点是：**在中国，想成任何事，都要拉好关系，抱对大腿**，领导们的观点是：**大老板说的对！**，投资人的观点是：**技术人员不重要，随时都能招的到**。这就是一家创业公司的企业文化，这就是那个我工作了4年之久的公司，这就是一个开发人员的悲哀。\n\n可能我确实太平庸，没有能力和资格去要求更多，能在家门口拿一份体面的工资就应该知足的。但我却忘记了，对每个人来说，时间才是最珍贵的资源。同样的时间，为何要挥霍在那些嗤之以鼻的事情上？同样的时间，为何要浪费在那些不值得的人上？更可悲的是，让我顿悟这一点的，是那些年纪比我还小的朋友。\n\n\n\n###规划\n\n最近一段时间依赖，一直在穷尽最大的努力再拓展自己的技术视野，毕竟我的理想是当一名架构师。但有得有失，长时间的拉宽知识面，却让我对一些基础知识变的生疏，导致的直接结果就是，面试没啥问题（这几天的电话面试基本上都很容易的过了:)），笔试成了问题（我可不想交白卷啊T_T）。\n\n所以接下来的一个月时间，我的计划是恢复一下自己的笔试能力，找回那些原本亲切的算法和教科书式填空题的记忆（ps：智力题真的太伤自尊了啊Q_Q）。\n\n\n\n###下一个五年\n\n人生能有多少个十年，多少个五年，多少个三年，我已经三十了，身边朋友们的下一代都会喊爸爸了，我却还一身负债，这就是对自己不够狠的报应吧～\n\n下一个五年计划，就是要朝着我的理想加速前行，我猜35岁的我，应该是个合格的架构师，应该是个好父亲，应该是个更懂得生活的好老公，应该是个有担当的好儿子，应该依然是个有棱有角的人，一个坚持原则的人，一个就事论事实事求是的人，一个依然有着正义感的中年人。\n\n我的朋友们，请你们见证！\n\n\n\n","source":"_posts/日志.md","raw":"title: 这几天的感想\ndate: 2015-07-19 09:37:12\ntags: \n- 离职\ncategories: talk\n---\n\n###总结\n\n今天已是离职的第7天，时间过的真尼玛快，不知不觉就给家待了一周了。从一开始因为会议上沟通吃力的失望，到为了捍卫原则的愤怒，再到离职后经济带来的恐慌，到各种职位把手机打爆的惊叹，再到模拟笔试题带来的精神打击，到朋友喝同事给予我的肯定和安慰，再到家人给予的支持，我的情绪就像在坐过山车一样时好时坏。\n\n<!--more-->\n\n不过时间确实是机械的，不管你是快乐还是悲伤，是愤怒还是失望，它都不会为此多停哪怕一亚秒。它以简单粗暴的方式逼着你向前看，这种方式或许也是最行之有效的啦～\n\n在这家公司工作了少说四年吧，说没有感情那绝壁是气话，即便是对公司早已失望，对产品从没看好，但相处了那么久的同事，打磨了那么久的团队，捍卫了多次的团队文化，总让我感到依依不舍。但事实证明，在企业文化面前，谈团队文化并没有什么卵用，几年前我对这句话还抱着鄙视的态度，但这几天发生的事儿让我无奈，也让我成长。\n\n和一个朋友聊天，本来还带着些许成就感的我，被朋友一个问题问的我竟无言以对。大概的对话如下：\n\n> 我：这些年至少学了不少技术，做了几个产品。\n\n> TA：你们的产品有用户么？你们的产品改变了某些人的生活么？提高了哪怕些许人的生活质量了吗？\n\n我tm竟然无言以对，静下来思考一下，才恍然大悟，以前口口声声说要改变世界，却花了四年的时间为的只是老板在饭桌上吹牛逼，如果非要说改善了谁的生活质量，那估计也就公司股东吧～\n\n到底是公司的产品是不是在圈钱，我说不太好，那是市场和营销范畴。我能感觉到的，仅仅是以现在公司的内部状况来说，不太像是做实事儿的，老板的观点是：**在中国，想成任何事，都要拉好关系，抱对大腿**，领导们的观点是：**大老板说的对！**，投资人的观点是：**技术人员不重要，随时都能招的到**。这就是一家创业公司的企业文化，这就是那个我工作了4年之久的公司，这就是一个开发人员的悲哀。\n\n可能我确实太平庸，没有能力和资格去要求更多，能在家门口拿一份体面的工资就应该知足的。但我却忘记了，对每个人来说，时间才是最珍贵的资源。同样的时间，为何要挥霍在那些嗤之以鼻的事情上？同样的时间，为何要浪费在那些不值得的人上？更可悲的是，让我顿悟这一点的，是那些年纪比我还小的朋友。\n\n\n\n###规划\n\n最近一段时间依赖，一直在穷尽最大的努力再拓展自己的技术视野，毕竟我的理想是当一名架构师。但有得有失，长时间的拉宽知识面，却让我对一些基础知识变的生疏，导致的直接结果就是，面试没啥问题（这几天的电话面试基本上都很容易的过了:)），笔试成了问题（我可不想交白卷啊T_T）。\n\n所以接下来的一个月时间，我的计划是恢复一下自己的笔试能力，找回那些原本亲切的算法和教科书式填空题的记忆（ps：智力题真的太伤自尊了啊Q_Q）。\n\n\n\n###下一个五年\n\n人生能有多少个十年，多少个五年，多少个三年，我已经三十了，身边朋友们的下一代都会喊爸爸了，我却还一身负债，这就是对自己不够狠的报应吧～\n\n下一个五年计划，就是要朝着我的理想加速前行，我猜35岁的我，应该是个合格的架构师，应该是个好父亲，应该是个更懂得生活的好老公，应该是个有担当的好儿子，应该依然是个有棱有角的人，一个坚持原则的人，一个就事论事实事求是的人，一个依然有着正义感的中年人。\n\n我的朋友们，请你们见证！\n\n\n\n","slug":"日志","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ylg002ogtfyx8hgxi6f","comments":1,"layout":"post","photos":[],"link":"","content":"<p>###总结</p>\n<p>今天已是离职的第7天，时间过的真尼玛快，不知不觉就给家待了一周了。从一开始因为会议上沟通吃力的失望，到为了捍卫原则的愤怒，再到离职后经济带来的恐慌，到各种职位把手机打爆的惊叹，再到模拟笔试题带来的精神打击，到朋友喝同事给予我的肯定和安慰，再到家人给予的支持，我的情绪就像在坐过山车一样时好时坏。</p>\n<a id=\"more\"></a>\n<p>不过时间确实是机械的，不管你是快乐还是悲伤，是愤怒还是失望，它都不会为此多停哪怕一亚秒。它以简单粗暴的方式逼着你向前看，这种方式或许也是最行之有效的啦～</p>\n<p>在这家公司工作了少说四年吧，说没有感情那绝壁是气话，即便是对公司早已失望，对产品从没看好，但相处了那么久的同事，打磨了那么久的团队，捍卫了多次的团队文化，总让我感到依依不舍。但事实证明，在企业文化面前，谈团队文化并没有什么卵用，几年前我对这句话还抱着鄙视的态度，但这几天发生的事儿让我无奈，也让我成长。</p>\n<p>和一个朋友聊天，本来还带着些许成就感的我，被朋友一个问题问的我竟无言以对。大概的对话如下：</p>\n<blockquote>\n<p>我：这些年至少学了不少技术，做了几个产品。</p>\n<p>TA：你们的产品有用户么？你们的产品改变了某些人的生活么？提高了哪怕些许人的生活质量了吗？</p>\n</blockquote>\n<p>我tm竟然无言以对，静下来思考一下，才恍然大悟，以前口口声声说要改变世界，却花了四年的时间为的只是老板在饭桌上吹牛逼，如果非要说改善了谁的生活质量，那估计也就公司股东吧～</p>\n<p>到底是公司的产品是不是在圈钱，我说不太好，那是市场和营销范畴。我能感觉到的，仅仅是以现在公司的内部状况来说，不太像是做实事儿的，老板的观点是：<strong>在中国，想成任何事，都要拉好关系，抱对大腿</strong>，领导们的观点是：<strong>大老板说的对！</strong>，投资人的观点是：<strong>技术人员不重要，随时都能招的到</strong>。这就是一家创业公司的企业文化，这就是那个我工作了4年之久的公司，这就是一个开发人员的悲哀。</p>\n<p>可能我确实太平庸，没有能力和资格去要求更多，能在家门口拿一份体面的工资就应该知足的。但我却忘记了，对每个人来说，时间才是最珍贵的资源。同样的时间，为何要挥霍在那些嗤之以鼻的事情上？同样的时间，为何要浪费在那些不值得的人上？更可悲的是，让我顿悟这一点的，是那些年纪比我还小的朋友。</p>\n<p>###规划</p>\n<p>最近一段时间依赖，一直在穷尽最大的努力再拓展自己的技术视野，毕竟我的理想是当一名架构师。但有得有失，长时间的拉宽知识面，却让我对一些基础知识变的生疏，导致的直接结果就是，面试没啥问题（这几天的电话面试基本上都很容易的过了:)），笔试成了问题（我可不想交白卷啊T_T）。</p>\n<p>所以接下来的一个月时间，我的计划是恢复一下自己的笔试能力，找回那些原本亲切的算法和教科书式填空题的记忆（ps：智力题真的太伤自尊了啊Q_Q）。</p>\n<p>###下一个五年</p>\n<p>人生能有多少个十年，多少个五年，多少个三年，我已经三十了，身边朋友们的下一代都会喊爸爸了，我却还一身负债，这就是对自己不够狠的报应吧～</p>\n<p>下一个五年计划，就是要朝着我的理想加速前行，我猜35岁的我，应该是个合格的架构师，应该是个好父亲，应该是个更懂得生活的好老公，应该是个有担当的好儿子，应该依然是个有棱有角的人，一个坚持原则的人，一个就事论事实事求是的人，一个依然有着正义感的中年人。</p>\n<p>我的朋友们，请你们见证！</p>\n","excerpt":"<p>###总结</p>\n<p>今天已是离职的第7天，时间过的真尼玛快，不知不觉就给家待了一周了。从一开始因为会议上沟通吃力的失望，到为了捍卫原则的愤怒，再到离职后经济带来的恐慌，到各种职位把手机打爆的惊叹，再到模拟笔试题带来的精神打击，到朋友喝同事给予我的肯定和安慰，再到家人给予的支持，我的情绪就像在坐过山车一样时好时坏。</p>","more":"<p>不过时间确实是机械的，不管你是快乐还是悲伤，是愤怒还是失望，它都不会为此多停哪怕一亚秒。它以简单粗暴的方式逼着你向前看，这种方式或许也是最行之有效的啦～</p>\n<p>在这家公司工作了少说四年吧，说没有感情那绝壁是气话，即便是对公司早已失望，对产品从没看好，但相处了那么久的同事，打磨了那么久的团队，捍卫了多次的团队文化，总让我感到依依不舍。但事实证明，在企业文化面前，谈团队文化并没有什么卵用，几年前我对这句话还抱着鄙视的态度，但这几天发生的事儿让我无奈，也让我成长。</p>\n<p>和一个朋友聊天，本来还带着些许成就感的我，被朋友一个问题问的我竟无言以对。大概的对话如下：</p>\n<blockquote>\n<p>我：这些年至少学了不少技术，做了几个产品。</p>\n<p>TA：你们的产品有用户么？你们的产品改变了某些人的生活么？提高了哪怕些许人的生活质量了吗？</p>\n</blockquote>\n<p>我tm竟然无言以对，静下来思考一下，才恍然大悟，以前口口声声说要改变世界，却花了四年的时间为的只是老板在饭桌上吹牛逼，如果非要说改善了谁的生活质量，那估计也就公司股东吧～</p>\n<p>到底是公司的产品是不是在圈钱，我说不太好，那是市场和营销范畴。我能感觉到的，仅仅是以现在公司的内部状况来说，不太像是做实事儿的，老板的观点是：<strong>在中国，想成任何事，都要拉好关系，抱对大腿</strong>，领导们的观点是：<strong>大老板说的对！</strong>，投资人的观点是：<strong>技术人员不重要，随时都能招的到</strong>。这就是一家创业公司的企业文化，这就是那个我工作了4年之久的公司，这就是一个开发人员的悲哀。</p>\n<p>可能我确实太平庸，没有能力和资格去要求更多，能在家门口拿一份体面的工资就应该知足的。但我却忘记了，对每个人来说，时间才是最珍贵的资源。同样的时间，为何要挥霍在那些嗤之以鼻的事情上？同样的时间，为何要浪费在那些不值得的人上？更可悲的是，让我顿悟这一点的，是那些年纪比我还小的朋友。</p>\n<p>###规划</p>\n<p>最近一段时间依赖，一直在穷尽最大的努力再拓展自己的技术视野，毕竟我的理想是当一名架构师。但有得有失，长时间的拉宽知识面，却让我对一些基础知识变的生疏，导致的直接结果就是，面试没啥问题（这几天的电话面试基本上都很容易的过了:)），笔试成了问题（我可不想交白卷啊T_T）。</p>\n<p>所以接下来的一个月时间，我的计划是恢复一下自己的笔试能力，找回那些原本亲切的算法和教科书式填空题的记忆（ps：智力题真的太伤自尊了啊Q_Q）。</p>\n<p>###下一个五年</p>\n<p>人生能有多少个十年，多少个五年，多少个三年，我已经三十了，身边朋友们的下一代都会喊爸爸了，我却还一身负债，这就是对自己不够狠的报应吧～</p>\n<p>下一个五年计划，就是要朝着我的理想加速前行，我猜35岁的我，应该是个合格的架构师，应该是个好父亲，应该是个更懂得生活的好老公，应该是个有担当的好儿子，应该依然是个有棱有角的人，一个坚持原则的人，一个就事论事实事求是的人，一个依然有着正义感的中年人。</p>\n<p>我的朋友们，请你们见证！</p>"},{"title":"数据库中间件的比较","date":"2014-11-10T01:37:12.000Z","_content":"\n\n这年头，但凡是搞开发的，都要和互联网挂上边儿，但凡是搞互联网的，都要和大数据挂上钩儿，我们也不例外~~哇哈哈哈哈！\n<!-- more -->\n这里我们不谈什么高大上的数据挖掘分析（为什么看到“挖掘”就不自觉地联想到山东呢？），今次我们要聊的是应用中要如何处理海量数据的数据库存储和使用。说的更详细一些，就是如何保证面对应用所需的海量数据，我们如何确保mysql数据库高可用和高性能：\n\n- 高可用，自然是做冗余备份，并能做到Failover；\n- 高性能，一般就是数据库调优，读写分离，分库分表。\n\n在此我们不考虑更复杂的方案，例如：引入nosql，缓存，等等。\n\n其实现存的数据库高可用的开源解决方案中，已经有很多[现成模块](http://www.aboutmood.com/post/2014-06-17/40062036560)足够我们选择的了。\n\n就我个人而言，是比较亲近阿里的。本来以为会毫不犹豫的选择**cobar**，不过出于复杂度的考虑，我目前可能更倾向于**Atlas**~~还是自己搭建一下运行环境测试测试再做最后的决定吧。\n\nAtlas\n---\n\n我比较欣赏的是它的简单，非常适合中小型项目或者刚起步的创业公司。正是由于它的简单，所以不需要什么耗时的学习和调优就可以快速投入使用。\n\n我在虚拟机中测试安装，[步骤](https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E5%AE%89%E8%A3%85)很简单，我使用是`rpm`安装：\n\n\trpm -ivh Atlas-2.2.el6.x86_64.rpm\n\n一切是如此的顺利，接下来就是按照说明书修改配置文件。最后，[执行](https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E8%BF%90%E8%A1%8C%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98)：\n\n\tsudo ./mysql-proxyd test start\n\n搞定。接下来就是在终端中以管理员的身份连接Atlas：\n\n\tmysql -h127.0.0.1 -P2345 -uadmin -p123456\n\n注意，上面的参数是需要和配置文件保持一致的。然后在终端中执行：\n\n\tmysql> select * from help;\n\t+----------------------------+---------------------------------------------------------+\n\t| command                    | description                                             |\n\t+----------------------------+---------------------------------------------------------+\n\t| SELECT * FROM help         | shows this help                                         |\n\t| SELECT * FROM backends     | lists the backends and their state                      |\n\t| SET OFFLINE $backend_id    | offline backend server, $backend_id is backend_ndx's id |\n\t| SET ONLINE $backend_id     | online backend server, ...                              |\n\t| ADD MASTER $backend        | example: \"add master 127.0.0.1:3306\", ...               |\n\t| ADD SLAVE $backend         | example: \"add slave 127.0.0.1:3306\", ...                |\n\t| REMOVE BACKEND $backend_id | example: \"remove backend 1\", ...                        |\n\t| ADD CLIENT $client         | example: \"add client 192.168.1.2\", ...                  |\n\t| REMOVE CLIENT $client      | example: \"remove client 192.168.1.2\", ...               |\n\t| SAVE CONFIG                | save the backends to config file                        |\n\t+----------------------------+---------------------------------------------------------+\n\t10 rows in set (0.00 sec)\n\n可以看到管理员可以使用的运维命令。\n\n我们可以只使用它提供的读写分离，但是你的mysql主从配置还是需要自己在mysql中配置好的。\n\nAtlas的这种中间代理的设计架构，不可避免的会损失掉一部分[性能](https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95)，主要是数据转发引起的，就看你是否接受了。\n\n至于分库分表功能，Atlas并不是非常的强大，细节可以看[这里](https://github.com/Qihoo360/Atlas/wiki/Atlas的分表功能简介)。还是那句话，中小项目足矣！\n\n目前我能想到的Atlas的代码侵入性也就是在分库分表中如果想要指定sql执行的服务器，需要加入：\n\n\t/*master*/\n\n另外的侵入性体现在分库分表需要用户自己创建固定个数的数据表，而且表名也有硬性规则。别的应该木有啦~~\n\n对于我们目前的项目来说，完全足够了~\n\n\n\n\n\nCobar\n---\n\n有人说，阿里开源出来的东西里，cobar算是一个非常成功的项目之一（还有LVS，Dubbo等）！这也是我一直比较亲睐阿里的原因之一，毕竟能够回馈开源，展示国人实力，是一件非常伟大的使命，阿里做到了。不说废话，先来学习一下Cobar的基础知识：[传送门](https://github.com/alibaba/cobar/wiki)（万万没想到github上Cobar的wiki现在还在完善中，只能通过下载“其他”栏目中的原来的wiki资料学习了！）\n\n简单的总结一下就是说，Cobar在分库分表和提高SQL查询上做了非常多的工作，所以不可避免的引入了复杂性！如果项目足够大，确实可以考虑使用，不过小项目还是算了。","source":"_posts/数据库中间件的比较.md","raw":"title: 数据库中间件的比较\ndate: 2014-11-10 09:37:12\ntags: \n- mysql\n- Atlas\n- 分库分表\n- 读写分离\n- 负载均衡\n- 性能\n- 侵入性\ncategories: 数据库\n---\n\n\n这年头，但凡是搞开发的，都要和互联网挂上边儿，但凡是搞互联网的，都要和大数据挂上钩儿，我们也不例外~~哇哈哈哈哈！\n<!-- more -->\n这里我们不谈什么高大上的数据挖掘分析（为什么看到“挖掘”就不自觉地联想到山东呢？），今次我们要聊的是应用中要如何处理海量数据的数据库存储和使用。说的更详细一些，就是如何保证面对应用所需的海量数据，我们如何确保mysql数据库高可用和高性能：\n\n- 高可用，自然是做冗余备份，并能做到Failover；\n- 高性能，一般就是数据库调优，读写分离，分库分表。\n\n在此我们不考虑更复杂的方案，例如：引入nosql，缓存，等等。\n\n其实现存的数据库高可用的开源解决方案中，已经有很多[现成模块](http://www.aboutmood.com/post/2014-06-17/40062036560)足够我们选择的了。\n\n就我个人而言，是比较亲近阿里的。本来以为会毫不犹豫的选择**cobar**，不过出于复杂度的考虑，我目前可能更倾向于**Atlas**~~还是自己搭建一下运行环境测试测试再做最后的决定吧。\n\nAtlas\n---\n\n我比较欣赏的是它的简单，非常适合中小型项目或者刚起步的创业公司。正是由于它的简单，所以不需要什么耗时的学习和调优就可以快速投入使用。\n\n我在虚拟机中测试安装，[步骤](https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E5%AE%89%E8%A3%85)很简单，我使用是`rpm`安装：\n\n\trpm -ivh Atlas-2.2.el6.x86_64.rpm\n\n一切是如此的顺利，接下来就是按照说明书修改配置文件。最后，[执行](https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E8%BF%90%E8%A1%8C%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98)：\n\n\tsudo ./mysql-proxyd test start\n\n搞定。接下来就是在终端中以管理员的身份连接Atlas：\n\n\tmysql -h127.0.0.1 -P2345 -uadmin -p123456\n\n注意，上面的参数是需要和配置文件保持一致的。然后在终端中执行：\n\n\tmysql> select * from help;\n\t+----------------------------+---------------------------------------------------------+\n\t| command                    | description                                             |\n\t+----------------------------+---------------------------------------------------------+\n\t| SELECT * FROM help         | shows this help                                         |\n\t| SELECT * FROM backends     | lists the backends and their state                      |\n\t| SET OFFLINE $backend_id    | offline backend server, $backend_id is backend_ndx's id |\n\t| SET ONLINE $backend_id     | online backend server, ...                              |\n\t| ADD MASTER $backend        | example: \"add master 127.0.0.1:3306\", ...               |\n\t| ADD SLAVE $backend         | example: \"add slave 127.0.0.1:3306\", ...                |\n\t| REMOVE BACKEND $backend_id | example: \"remove backend 1\", ...                        |\n\t| ADD CLIENT $client         | example: \"add client 192.168.1.2\", ...                  |\n\t| REMOVE CLIENT $client      | example: \"remove client 192.168.1.2\", ...               |\n\t| SAVE CONFIG                | save the backends to config file                        |\n\t+----------------------------+---------------------------------------------------------+\n\t10 rows in set (0.00 sec)\n\n可以看到管理员可以使用的运维命令。\n\n我们可以只使用它提供的读写分离，但是你的mysql主从配置还是需要自己在mysql中配置好的。\n\nAtlas的这种中间代理的设计架构，不可避免的会损失掉一部分[性能](https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95)，主要是数据转发引起的，就看你是否接受了。\n\n至于分库分表功能，Atlas并不是非常的强大，细节可以看[这里](https://github.com/Qihoo360/Atlas/wiki/Atlas的分表功能简介)。还是那句话，中小项目足矣！\n\n目前我能想到的Atlas的代码侵入性也就是在分库分表中如果想要指定sql执行的服务器，需要加入：\n\n\t/*master*/\n\n另外的侵入性体现在分库分表需要用户自己创建固定个数的数据表，而且表名也有硬性规则。别的应该木有啦~~\n\n对于我们目前的项目来说，完全足够了~\n\n\n\n\n\nCobar\n---\n\n有人说，阿里开源出来的东西里，cobar算是一个非常成功的项目之一（还有LVS，Dubbo等）！这也是我一直比较亲睐阿里的原因之一，毕竟能够回馈开源，展示国人实力，是一件非常伟大的使命，阿里做到了。不说废话，先来学习一下Cobar的基础知识：[传送门](https://github.com/alibaba/cobar/wiki)（万万没想到github上Cobar的wiki现在还在完善中，只能通过下载“其他”栏目中的原来的wiki资料学习了！）\n\n简单的总结一下就是说，Cobar在分库分表和提高SQL查询上做了非常多的工作，所以不可避免的引入了复杂性！如果项目足够大，确实可以考虑使用，不过小项目还是算了。","slug":"数据库中间件的比较","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yll002tgtfy7c69jkiv","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这年头，但凡是搞开发的，都要和互联网挂上边儿，但凡是搞互联网的，都要和大数据挂上钩儿，我们也不例外~~哇哈哈哈哈！<br><a id=\"more\"></a><br>这里我们不谈什么高大上的数据挖掘分析（为什么看到“挖掘”就不自觉地联想到山东呢？），今次我们要聊的是应用中要如何处理海量数据的数据库存储和使用。说的更详细一些，就是如何保证面对应用所需的海量数据，我们如何确保mysql数据库高可用和高性能：</p>\n<ul>\n<li>高可用，自然是做冗余备份，并能做到Failover；</li>\n<li>高性能，一般就是数据库调优，读写分离，分库分表。</li>\n</ul>\n<p>在此我们不考虑更复杂的方案，例如：引入nosql，缓存，等等。</p>\n<p>其实现存的数据库高可用的开源解决方案中，已经有很多<a href=\"http://www.aboutmood.com/post/2014-06-17/40062036560\" target=\"_blank\" rel=\"external\">现成模块</a>足够我们选择的了。</p>\n<p>就我个人而言，是比较亲近阿里的。本来以为会毫不犹豫的选择<strong>cobar</strong>，不过出于复杂度的考虑，我目前可能更倾向于<strong>Atlas</strong>~~还是自己搭建一下运行环境测试测试再做最后的决定吧。</p>\n<h2 id=\"Atlas\"><a href=\"#Atlas\" class=\"headerlink\" title=\"Atlas\"></a>Atlas</h2><p>我比较欣赏的是它的简单，非常适合中小型项目或者刚起步的创业公司。正是由于它的简单，所以不需要什么耗时的学习和调优就可以快速投入使用。</p>\n<p>我在虚拟机中测试安装，<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E5%AE%89%E8%A3%85\" target=\"_blank\" rel=\"external\">步骤</a>很简单，我使用是<code>rpm</code>安装：</p>\n<pre><code>rpm -ivh Atlas-2.2.el6.x86_64.rpm\n</code></pre><p>一切是如此的顺利，接下来就是按照说明书修改配置文件。最后，<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E8%BF%90%E8%A1%8C%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98\" target=\"_blank\" rel=\"external\">执行</a>：</p>\n<pre><code>sudo ./mysql-proxyd test start\n</code></pre><p>搞定。接下来就是在终端中以管理员的身份连接Atlas：</p>\n<pre><code>mysql -h127.0.0.1 -P2345 -uadmin -p123456\n</code></pre><p>注意，上面的参数是需要和配置文件保持一致的。然后在终端中执行：</p>\n<pre><code>mysql&gt; select * from help;\n+----------------------------+---------------------------------------------------------+\n| command                    | description                                             |\n+----------------------------+---------------------------------------------------------+\n| SELECT * FROM help         | shows this help                                         |\n| SELECT * FROM backends     | lists the backends and their state                      |\n| SET OFFLINE $backend_id    | offline backend server, $backend_id is backend_ndx&apos;s id |\n| SET ONLINE $backend_id     | online backend server, ...                              |\n| ADD MASTER $backend        | example: &quot;add master 127.0.0.1:3306&quot;, ...               |\n| ADD SLAVE $backend         | example: &quot;add slave 127.0.0.1:3306&quot;, ...                |\n| REMOVE BACKEND $backend_id | example: &quot;remove backend 1&quot;, ...                        |\n| ADD CLIENT $client         | example: &quot;add client 192.168.1.2&quot;, ...                  |\n| REMOVE CLIENT $client      | example: &quot;remove client 192.168.1.2&quot;, ...               |\n| SAVE CONFIG                | save the backends to config file                        |\n+----------------------------+---------------------------------------------------------+\n10 rows in set (0.00 sec)\n</code></pre><p>可以看到管理员可以使用的运维命令。</p>\n<p>我们可以只使用它提供的读写分离，但是你的mysql主从配置还是需要自己在mysql中配置好的。</p>\n<p>Atlas的这种中间代理的设计架构，不可避免的会损失掉一部分<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95\" target=\"_blank\" rel=\"external\">性能</a>，主要是数据转发引起的，就看你是否接受了。</p>\n<p>至于分库分表功能，Atlas并不是非常的强大，细节可以看<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas的分表功能简介\" target=\"_blank\" rel=\"external\">这里</a>。还是那句话，中小项目足矣！</p>\n<p>目前我能想到的Atlas的代码侵入性也就是在分库分表中如果想要指定sql执行的服务器，需要加入：</p>\n<pre><code>/*master*/\n</code></pre><p>另外的侵入性体现在分库分表需要用户自己创建固定个数的数据表，而且表名也有硬性规则。别的应该木有啦~~</p>\n<p>对于我们目前的项目来说，完全足够了~</p>\n<h2 id=\"Cobar\"><a href=\"#Cobar\" class=\"headerlink\" title=\"Cobar\"></a>Cobar</h2><p>有人说，阿里开源出来的东西里，cobar算是一个非常成功的项目之一（还有LVS，Dubbo等）！这也是我一直比较亲睐阿里的原因之一，毕竟能够回馈开源，展示国人实力，是一件非常伟大的使命，阿里做到了。不说废话，先来学习一下Cobar的基础知识：<a href=\"https://github.com/alibaba/cobar/wiki\" target=\"_blank\" rel=\"external\">传送门</a>（万万没想到github上Cobar的wiki现在还在完善中，只能通过下载“其他”栏目中的原来的wiki资料学习了！）</p>\n<p>简单的总结一下就是说，Cobar在分库分表和提高SQL查询上做了非常多的工作，所以不可避免的引入了复杂性！如果项目足够大，确实可以考虑使用，不过小项目还是算了。</p>\n","excerpt":"<p>这年头，但凡是搞开发的，都要和互联网挂上边儿，但凡是搞互联网的，都要和大数据挂上钩儿，我们也不例外~~哇哈哈哈哈！<br>","more":"<br>这里我们不谈什么高大上的数据挖掘分析（为什么看到“挖掘”就不自觉地联想到山东呢？），今次我们要聊的是应用中要如何处理海量数据的数据库存储和使用。说的更详细一些，就是如何保证面对应用所需的海量数据，我们如何确保mysql数据库高可用和高性能：</p>\n<ul>\n<li>高可用，自然是做冗余备份，并能做到Failover；</li>\n<li>高性能，一般就是数据库调优，读写分离，分库分表。</li>\n</ul>\n<p>在此我们不考虑更复杂的方案，例如：引入nosql，缓存，等等。</p>\n<p>其实现存的数据库高可用的开源解决方案中，已经有很多<a href=\"http://www.aboutmood.com/post/2014-06-17/40062036560\">现成模块</a>足够我们选择的了。</p>\n<p>就我个人而言，是比较亲近阿里的。本来以为会毫不犹豫的选择<strong>cobar</strong>，不过出于复杂度的考虑，我目前可能更倾向于<strong>Atlas</strong>~~还是自己搭建一下运行环境测试测试再做最后的决定吧。</p>\n<h2 id=\"Atlas\"><a href=\"#Atlas\" class=\"headerlink\" title=\"Atlas\"></a>Atlas</h2><p>我比较欣赏的是它的简单，非常适合中小型项目或者刚起步的创业公司。正是由于它的简单，所以不需要什么耗时的学习和调优就可以快速投入使用。</p>\n<p>我在虚拟机中测试安装，<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E5%AE%89%E8%A3%85\">步骤</a>很简单，我使用是<code>rpm</code>安装：</p>\n<pre><code>rpm -ivh Atlas-2.2.el6.x86_64.rpm\n</code></pre><p>一切是如此的顺利，接下来就是按照说明书修改配置文件。最后，<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E8%BF%90%E8%A1%8C%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98\">执行</a>：</p>\n<pre><code>sudo ./mysql-proxyd test start\n</code></pre><p>搞定。接下来就是在终端中以管理员的身份连接Atlas：</p>\n<pre><code>mysql -h127.0.0.1 -P2345 -uadmin -p123456\n</code></pre><p>注意，上面的参数是需要和配置文件保持一致的。然后在终端中执行：</p>\n<pre><code>mysql&gt; select * from help;\n+----------------------------+---------------------------------------------------------+\n| command                    | description                                             |\n+----------------------------+---------------------------------------------------------+\n| SELECT * FROM help         | shows this help                                         |\n| SELECT * FROM backends     | lists the backends and their state                      |\n| SET OFFLINE $backend_id    | offline backend server, $backend_id is backend_ndx&apos;s id |\n| SET ONLINE $backend_id     | online backend server, ...                              |\n| ADD MASTER $backend        | example: &quot;add master 127.0.0.1:3306&quot;, ...               |\n| ADD SLAVE $backend         | example: &quot;add slave 127.0.0.1:3306&quot;, ...                |\n| REMOVE BACKEND $backend_id | example: &quot;remove backend 1&quot;, ...                        |\n| ADD CLIENT $client         | example: &quot;add client 192.168.1.2&quot;, ...                  |\n| REMOVE CLIENT $client      | example: &quot;remove client 192.168.1.2&quot;, ...               |\n| SAVE CONFIG                | save the backends to config file                        |\n+----------------------------+---------------------------------------------------------+\n10 rows in set (0.00 sec)\n</code></pre><p>可以看到管理员可以使用的运维命令。</p>\n<p>我们可以只使用它提供的读写分离，但是你的mysql主从配置还是需要自己在mysql中配置好的。</p>\n<p>Atlas的这种中间代理的设计架构，不可避免的会损失掉一部分<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95\">性能</a>，主要是数据转发引起的，就看你是否接受了。</p>\n<p>至于分库分表功能，Atlas并不是非常的强大，细节可以看<a href=\"https://github.com/Qihoo360/Atlas/wiki/Atlas的分表功能简介\">这里</a>。还是那句话，中小项目足矣！</p>\n<p>目前我能想到的Atlas的代码侵入性也就是在分库分表中如果想要指定sql执行的服务器，需要加入：</p>\n<pre><code>/*master*/\n</code></pre><p>另外的侵入性体现在分库分表需要用户自己创建固定个数的数据表，而且表名也有硬性规则。别的应该木有啦~~</p>\n<p>对于我们目前的项目来说，完全足够了~</p>\n<h2 id=\"Cobar\"><a href=\"#Cobar\" class=\"headerlink\" title=\"Cobar\"></a>Cobar</h2><p>有人说，阿里开源出来的东西里，cobar算是一个非常成功的项目之一（还有LVS，Dubbo等）！这也是我一直比较亲睐阿里的原因之一，毕竟能够回馈开源，展示国人实力，是一件非常伟大的使命，阿里做到了。不说废话，先来学习一下Cobar的基础知识：<a href=\"https://github.com/alibaba/cobar/wiki\">传送门</a>（万万没想到github上Cobar的wiki现在还在完善中，只能通过下载“其他”栏目中的原来的wiki资料学习了！）</p>\n<p>简单的总结一下就是说，Cobar在分库分表和提高SQL查询上做了非常多的工作，所以不可避免的引入了复杂性！如果项目足够大，确实可以考虑使用，不过小项目还是算了。</p>"},{"title":"搭建排查tomcat内存溢出问题的调试环境","date":"2014-10-23T01:37:12.000Z","_content":"\n上个月赶工上线的门户网站，由于种种原因导致部署到线上服务器后每隔一段时间后就会导致tomcat内存溢出，今天我就要来直面这个棘手的问题。\n\n<!--more-->\n\n要解决的问题对我来说还是有点难度的，原因有二：\n\n1. 代码不是我写的；\n2. 我对java并不熟悉。\n\n废话不多说，就由我这个小白依靠GG带领大家来启程吧！\n\n凭借我多年的编程经验，我认为首先要找到趁手的工具，那么，问题就来了，挖掘机技术到底哪家强？……\n\n好吧，GG一下，可以很容易查到很多用来监控jvm实时状态的工具，我们以jconsole为第一款尝试的工具吧。\n\n\n\njconsole\n---\n\n这里要说明的是，我们需要搭建的监控环境是在win桌面机上远程监控一台centos服务器。按照网上说的，搭建起这么一个环境没有多大难度，大家可以参考这里：[传送门](http://zhumeng8337797.blog.163.com/blog/static/100768914201282833448384/)。\n\n如果你像我一样碰到了timeout提示，那多半就是centos防火墙拦截导致的，可以暂时关闭防火墙再尝试一下：\n\n\t/etc/init.d/iptables stop\n\n好的，终于有了一个监控界面了，是不是感觉心里敞亮了不少呢？不过我感觉还是太笼统了，只能大概知道jvm的状况，而对于我们要排查代码导致的内存泄露问题似乎并没有帮到太大的忙~~\n\n不过可以通过提供的一些信息来判断是否配置了比较合理的参数，比方说可以通过`GC时间`看出是否给tomcat分配了适当的内存大小，尽可能的设置一个合理的内存来减少gc的次数和耗时。\n\n那我们接下来换哪个工具呢？\n\n\n\nJProfiler\n---\n\n好吧，上大杀器！无需我多讲，我相信没有人会对我的选择有质疑吧？哇哈哈哈哈哈~~不过JProfiler是个商用产品，钱花到位才能享受生活，这一点儿错都没有。\n\n大家可以参考下面这些链接，相信你们很快就能搭建成功：\n\n[传送门1](http://www.flybi.net/article/101),[传送门2](http://sgq0085.iteye.com/blog/1947526),[传送门3](http://blog.csdn.net/attilax/article/details/17077857)\n\n按照上面提供的信息，我相信你很顺利就能安装部署完毕jprofiler（毕竟是商用产品嘛，肯定做的足够简单），但如果你和我一样是第一次用这个玩意儿，肯定会被它的默认界面震出翔！\n\n不要pia，先阅读一下这篇文章： [传送门](http://www.cnblogs.com/jayzee/p/3184087.html)。\n\n这里要提到的一点是，可能是软件版本的原因，按照上面前辈说的方法我却死活查不到方法调用Tree，查了一下GG才发现是需要调整配置选项，如下图：\n\n![查看调用轨迹](http://pic.yupoo.com/kazaff_v/E8qo6nio/W5piy.png)\n\n我这属于暴力解决吧，毕竟我把能开启的选项都选中了，不过想得到的问题也就是速度慢点，对于远程连接方式来说带宽占用多一些而已吧~~\n\n\n\n测试代码\n---\n\n找到了趁手的兵器，下一步就是要挖的坑了！哦，no，是一段会造成内存溢出的测试代码，我简单地修改了一下tomcat提供的例子中的`HelloWorldExample.java`：\n\n\timport java.io.IOException;\n\timport java.io.PrintWriter;\n\timport java.util.ResourceBundle;\n\t\n\timport javax.servlet.ServletException;\n\timport javax.servlet.http.HttpServlet;\n\timport javax.servlet.http.HttpServletRequest;\n\timport javax.servlet.http.HttpServletResponse;\n\t\n\timport java.util.ArrayList;\n\t\n\tpublic class HelloWorldExample extends HttpServlet {\n\t\n\t    private static final long serialVersionUID = 1L;\n\t\n\t    private static ArrayList list = new ArrayList();\n\t\n\t    @Override\n\t    public void doGet(HttpServletRequest request,\n\t                      HttpServletResponse response)\n\t        throws IOException, ServletException\n\t    {\n\t        ResourceBundle rb =\n\t            ResourceBundle.getBundle(\"LocalStrings\",request.getLocale());\n\t        response.setContentType(\"text/html\");\n\t        PrintWriter out = response.getWriter();\n\t\n\t        out.println(\"<html>\");\n\t        out.println(\"<head>\");\n\t        out.println(\"</head>\");\n\t        out.println(\"<body bgcolor=\\\"white\\\">\");\n\t        \n\t\t\n\t\tfor(int i=0; i < 1000; i++){\n\t\t\t//Object o = new String(\"by kazaff, index is :\" + i);\n\t\t\tHelloWorldExample.list.add(new kazaffBean());\n\t\t\t//o = null;\t\n\t\t}\t\n\t\n\t\tout.println(\"<div>kazaff in here!!!!!!!</div>\");\t\n\t\n\t\tout.println(\"</body>\");\n\t        out.println(\"</html>\");\n\t\n\t    }\n\t}\n\t\n\tclass kazaffBean {\n\t\tString name= \"\";\n\t}\n\n然后我们还要手动编译修改后的java代码，进入到`/usr/local/apache-tomcat-7.0.53/webapps/examples/WEB-INF/classes/HelloWorldExample.java`所在的文件夹中，执行下面的命令：\n\n\t javac HelloWorldExample.java -cp /usr/local/apache-tomcat-7.0.53/lib/servlet-api.jar \n\n当然，你的tomcat路径和我的很可能不同，酌情修改即可~~\n\n然后我们重启tomcat，对了，重启之前最好改一下分配给tomcat的内存上限，改小一些，有助于问题快速的暴露：\n\n\t-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/www/java-OOM/\n\n后面的两个`-XX`参数是用来让jvm在出现OOM后自动保存内存堆栈快照信息用的，方便我们排查问题。\n\n重启吧，然后为了加速内存溢出，我们可以使用apache自带的`ab`做压力测试：\n\n\tab -c 100 -n 10000 http://192.168.153.128:81/examples/jsp/\n\n执行上面的这条命令后，基本上tomcat肯定就已经挂掉了，注意，我说的是tomcat挂掉了！也就是说你在终端中执行`jps`命令，不再会看到`Bootstrap`这个进程了！我之所以强调这一点，是因为我在测试中发现直接导致`jconsole`断开连接，并且再也无法建立连接。\n\n而奇怪的是，`jprofiler`照常可以连接并获取到远程服务器上的jvm的监控数据，这种情况一度使我陷入深深的迷惘。因为我在tomcat的logs里死活找不到任何关于内存溢出或其他异常的记录，直到我的目光落在终端上：\n\n\n\tException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"http-bio-81-exec-13\"\n\t……\n\tjava.lang.OutOfMemoryError: GC overhead limit exceeded\n\t……\n\tjava.lang.OutOfMemoryError: Java heap space\n\t……\n\tException in thread \"RMI TCP Connection(idle)\" java.lang.OutOfMemoryError: Java heap space\n\n这才是乖孩子嘛，就应该是这样的才对嘛~~不过还有几个点想不明白：\n\n- 虽然`jps`已经查不到tomcat的进程，但是从jprofiler的线程监控中还是可以看到相关的线程，如下图：\n\n![](http://pic.yupoo.com/kazaff_v/E8rChOsQ/FN83O.png)\n\n- 既然tomcat都已经挂了，为什么`jprofiler`没有像`jconsole`那样连接断开呢？\n\n我这种小白目前是搞不定这两个问题了，还是抛到社区给大牛们分析吧。我们继续往下走~\n\n\n\n关于内存溢出\n---\n\n通过我上面列出的异常信息，已经是非常常见的了，对于一些java老鸟而言肯定是再熟悉不过的了！不过我还是找到了一篇排版不咋滴但是比较全面的文章： [传送门](http://yanguz123.iteye.com/blog/2017335)。\n\n到此为止，就算做好了一切准备，可以去真正的项目上搞了！\n\n\n","source":"_posts/搭建排查tomcat内存溢出问题的调试环境.md","raw":"title: 搭建排查tomcat内存溢出问题的调试环境\ndate: 2014-10-23 09:37:12\ntags: \n- jconsole\n- jprofiler\n- 内存溢出\n- jvm\ncategories: j2ee\n---\n\n上个月赶工上线的门户网站，由于种种原因导致部署到线上服务器后每隔一段时间后就会导致tomcat内存溢出，今天我就要来直面这个棘手的问题。\n\n<!--more-->\n\n要解决的问题对我来说还是有点难度的，原因有二：\n\n1. 代码不是我写的；\n2. 我对java并不熟悉。\n\n废话不多说，就由我这个小白依靠GG带领大家来启程吧！\n\n凭借我多年的编程经验，我认为首先要找到趁手的工具，那么，问题就来了，挖掘机技术到底哪家强？……\n\n好吧，GG一下，可以很容易查到很多用来监控jvm实时状态的工具，我们以jconsole为第一款尝试的工具吧。\n\n\n\njconsole\n---\n\n这里要说明的是，我们需要搭建的监控环境是在win桌面机上远程监控一台centos服务器。按照网上说的，搭建起这么一个环境没有多大难度，大家可以参考这里：[传送门](http://zhumeng8337797.blog.163.com/blog/static/100768914201282833448384/)。\n\n如果你像我一样碰到了timeout提示，那多半就是centos防火墙拦截导致的，可以暂时关闭防火墙再尝试一下：\n\n\t/etc/init.d/iptables stop\n\n好的，终于有了一个监控界面了，是不是感觉心里敞亮了不少呢？不过我感觉还是太笼统了，只能大概知道jvm的状况，而对于我们要排查代码导致的内存泄露问题似乎并没有帮到太大的忙~~\n\n不过可以通过提供的一些信息来判断是否配置了比较合理的参数，比方说可以通过`GC时间`看出是否给tomcat分配了适当的内存大小，尽可能的设置一个合理的内存来减少gc的次数和耗时。\n\n那我们接下来换哪个工具呢？\n\n\n\nJProfiler\n---\n\n好吧，上大杀器！无需我多讲，我相信没有人会对我的选择有质疑吧？哇哈哈哈哈哈~~不过JProfiler是个商用产品，钱花到位才能享受生活，这一点儿错都没有。\n\n大家可以参考下面这些链接，相信你们很快就能搭建成功：\n\n[传送门1](http://www.flybi.net/article/101),[传送门2](http://sgq0085.iteye.com/blog/1947526),[传送门3](http://blog.csdn.net/attilax/article/details/17077857)\n\n按照上面提供的信息，我相信你很顺利就能安装部署完毕jprofiler（毕竟是商用产品嘛，肯定做的足够简单），但如果你和我一样是第一次用这个玩意儿，肯定会被它的默认界面震出翔！\n\n不要pia，先阅读一下这篇文章： [传送门](http://www.cnblogs.com/jayzee/p/3184087.html)。\n\n这里要提到的一点是，可能是软件版本的原因，按照上面前辈说的方法我却死活查不到方法调用Tree，查了一下GG才发现是需要调整配置选项，如下图：\n\n![查看调用轨迹](http://pic.yupoo.com/kazaff_v/E8qo6nio/W5piy.png)\n\n我这属于暴力解决吧，毕竟我把能开启的选项都选中了，不过想得到的问题也就是速度慢点，对于远程连接方式来说带宽占用多一些而已吧~~\n\n\n\n测试代码\n---\n\n找到了趁手的兵器，下一步就是要挖的坑了！哦，no，是一段会造成内存溢出的测试代码，我简单地修改了一下tomcat提供的例子中的`HelloWorldExample.java`：\n\n\timport java.io.IOException;\n\timport java.io.PrintWriter;\n\timport java.util.ResourceBundle;\n\t\n\timport javax.servlet.ServletException;\n\timport javax.servlet.http.HttpServlet;\n\timport javax.servlet.http.HttpServletRequest;\n\timport javax.servlet.http.HttpServletResponse;\n\t\n\timport java.util.ArrayList;\n\t\n\tpublic class HelloWorldExample extends HttpServlet {\n\t\n\t    private static final long serialVersionUID = 1L;\n\t\n\t    private static ArrayList list = new ArrayList();\n\t\n\t    @Override\n\t    public void doGet(HttpServletRequest request,\n\t                      HttpServletResponse response)\n\t        throws IOException, ServletException\n\t    {\n\t        ResourceBundle rb =\n\t            ResourceBundle.getBundle(\"LocalStrings\",request.getLocale());\n\t        response.setContentType(\"text/html\");\n\t        PrintWriter out = response.getWriter();\n\t\n\t        out.println(\"<html>\");\n\t        out.println(\"<head>\");\n\t        out.println(\"</head>\");\n\t        out.println(\"<body bgcolor=\\\"white\\\">\");\n\t        \n\t\t\n\t\tfor(int i=0; i < 1000; i++){\n\t\t\t//Object o = new String(\"by kazaff, index is :\" + i);\n\t\t\tHelloWorldExample.list.add(new kazaffBean());\n\t\t\t//o = null;\t\n\t\t}\t\n\t\n\t\tout.println(\"<div>kazaff in here!!!!!!!</div>\");\t\n\t\n\t\tout.println(\"</body>\");\n\t        out.println(\"</html>\");\n\t\n\t    }\n\t}\n\t\n\tclass kazaffBean {\n\t\tString name= \"\";\n\t}\n\n然后我们还要手动编译修改后的java代码，进入到`/usr/local/apache-tomcat-7.0.53/webapps/examples/WEB-INF/classes/HelloWorldExample.java`所在的文件夹中，执行下面的命令：\n\n\t javac HelloWorldExample.java -cp /usr/local/apache-tomcat-7.0.53/lib/servlet-api.jar \n\n当然，你的tomcat路径和我的很可能不同，酌情修改即可~~\n\n然后我们重启tomcat，对了，重启之前最好改一下分配给tomcat的内存上限，改小一些，有助于问题快速的暴露：\n\n\t-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/www/java-OOM/\n\n后面的两个`-XX`参数是用来让jvm在出现OOM后自动保存内存堆栈快照信息用的，方便我们排查问题。\n\n重启吧，然后为了加速内存溢出，我们可以使用apache自带的`ab`做压力测试：\n\n\tab -c 100 -n 10000 http://192.168.153.128:81/examples/jsp/\n\n执行上面的这条命令后，基本上tomcat肯定就已经挂掉了，注意，我说的是tomcat挂掉了！也就是说你在终端中执行`jps`命令，不再会看到`Bootstrap`这个进程了！我之所以强调这一点，是因为我在测试中发现直接导致`jconsole`断开连接，并且再也无法建立连接。\n\n而奇怪的是，`jprofiler`照常可以连接并获取到远程服务器上的jvm的监控数据，这种情况一度使我陷入深深的迷惘。因为我在tomcat的logs里死活找不到任何关于内存溢出或其他异常的记录，直到我的目光落在终端上：\n\n\n\tException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"http-bio-81-exec-13\"\n\t……\n\tjava.lang.OutOfMemoryError: GC overhead limit exceeded\n\t……\n\tjava.lang.OutOfMemoryError: Java heap space\n\t……\n\tException in thread \"RMI TCP Connection(idle)\" java.lang.OutOfMemoryError: Java heap space\n\n这才是乖孩子嘛，就应该是这样的才对嘛~~不过还有几个点想不明白：\n\n- 虽然`jps`已经查不到tomcat的进程，但是从jprofiler的线程监控中还是可以看到相关的线程，如下图：\n\n![](http://pic.yupoo.com/kazaff_v/E8rChOsQ/FN83O.png)\n\n- 既然tomcat都已经挂了，为什么`jprofiler`没有像`jconsole`那样连接断开呢？\n\n我这种小白目前是搞不定这两个问题了，还是抛到社区给大牛们分析吧。我们继续往下走~\n\n\n\n关于内存溢出\n---\n\n通过我上面列出的异常信息，已经是非常常见的了，对于一些java老鸟而言肯定是再熟悉不过的了！不过我还是找到了一篇排版不咋滴但是比较全面的文章： [传送门](http://yanguz123.iteye.com/blog/2017335)。\n\n到此为止，就算做好了一切准备，可以去真正的项目上搞了！\n\n\n","slug":"搭建排查tomcat内存溢出问题的调试环境","published":1,"updated":"2016-05-14T07:46:20.000Z","_id":"cica18ylt003agtfyle01pmmj","comments":1,"layout":"post","photos":[],"link":"","content":"<p>上个月赶工上线的门户网站，由于种种原因导致部署到线上服务器后每隔一段时间后就会导致tomcat内存溢出，今天我就要来直面这个棘手的问题。</p>\n<a id=\"more\"></a>\n<p>要解决的问题对我来说还是有点难度的，原因有二：</p>\n<ol>\n<li>代码不是我写的；</li>\n<li>我对java并不熟悉。</li>\n</ol>\n<p>废话不多说，就由我这个小白依靠GG带领大家来启程吧！</p>\n<p>凭借我多年的编程经验，我认为首先要找到趁手的工具，那么，问题就来了，挖掘机技术到底哪家强？……</p>\n<p>好吧，GG一下，可以很容易查到很多用来监控jvm实时状态的工具，我们以jconsole为第一款尝试的工具吧。</p>\n<h2 id=\"jconsole\"><a href=\"#jconsole\" class=\"headerlink\" title=\"jconsole\"></a>jconsole</h2><p>这里要说明的是，我们需要搭建的监控环境是在win桌面机上远程监控一台centos服务器。按照网上说的，搭建起这么一个环境没有多大难度，大家可以参考这里：<a href=\"http://zhumeng8337797.blog.163.com/blog/static/100768914201282833448384/\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<p>如果你像我一样碰到了timeout提示，那多半就是centos防火墙拦截导致的，可以暂时关闭防火墙再尝试一下：</p>\n<pre><code>/etc/init.d/iptables stop\n</code></pre><p>好的，终于有了一个监控界面了，是不是感觉心里敞亮了不少呢？不过我感觉还是太笼统了，只能大概知道jvm的状况，而对于我们要排查代码导致的内存泄露问题似乎并没有帮到太大的忙~~</p>\n<p>不过可以通过提供的一些信息来判断是否配置了比较合理的参数，比方说可以通过<code>GC时间</code>看出是否给tomcat分配了适当的内存大小，尽可能的设置一个合理的内存来减少gc的次数和耗时。</p>\n<p>那我们接下来换哪个工具呢？</p>\n<h2 id=\"JProfiler\"><a href=\"#JProfiler\" class=\"headerlink\" title=\"JProfiler\"></a>JProfiler</h2><p>好吧，上大杀器！无需我多讲，我相信没有人会对我的选择有质疑吧？哇哈哈哈哈哈~~不过JProfiler是个商用产品，钱花到位才能享受生活，这一点儿错都没有。</p>\n<p>大家可以参考下面这些链接，相信你们很快就能搭建成功：</p>\n<p><a href=\"http://www.flybi.net/article/101\" target=\"_blank\" rel=\"external\">传送门1</a>,<a href=\"http://sgq0085.iteye.com/blog/1947526\" target=\"_blank\" rel=\"external\">传送门2</a>,<a href=\"http://blog.csdn.net/attilax/article/details/17077857\" target=\"_blank\" rel=\"external\">传送门3</a></p>\n<p>按照上面提供的信息，我相信你很顺利就能安装部署完毕jprofiler（毕竟是商用产品嘛，肯定做的足够简单），但如果你和我一样是第一次用这个玩意儿，肯定会被它的默认界面震出翔！</p>\n<p>不要pia，先阅读一下这篇文章： <a href=\"http://www.cnblogs.com/jayzee/p/3184087.html\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<p>这里要提到的一点是，可能是软件版本的原因，按照上面前辈说的方法我却死活查不到方法调用Tree，查了一下GG才发现是需要调整配置选项，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E8qo6nio/W5piy.png\" alt=\"查看调用轨迹\"></p>\n<p>我这属于暴力解决吧，毕竟我把能开启的选项都选中了，不过想得到的问题也就是速度慢点，对于远程连接方式来说带宽占用多一些而已吧~~</p>\n<h2 id=\"测试代码\"><a href=\"#测试代码\" class=\"headerlink\" title=\"测试代码\"></a>测试代码</h2><p>找到了趁手的兵器，下一步就是要挖的坑了！哦，no，是一段会造成内存溢出的测试代码，我简单地修改了一下tomcat提供的例子中的<code>HelloWorldExample.java</code>：</p>\n<pre><code>import java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.ResourceBundle;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.http.HttpServlet;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\nimport java.util.ArrayList;\n\npublic class HelloWorldExample extends HttpServlet {\n\n    private static final long serialVersionUID = 1L;\n\n    private static ArrayList list = new ArrayList();\n\n    @Override\n    public void doGet(HttpServletRequest request,\n                      HttpServletResponse response)\n        throws IOException, ServletException\n    {\n        ResourceBundle rb =\n            ResourceBundle.getBundle(&quot;LocalStrings&quot;,request.getLocale());\n        response.setContentType(&quot;text/html&quot;);\n        PrintWriter out = response.getWriter();\n\n        out.println(&quot;&lt;html&gt;&quot;);\n        out.println(&quot;&lt;head&gt;&quot;);\n        out.println(&quot;&lt;/head&gt;&quot;);\n        out.println(&quot;&lt;body bgcolor=\\&quot;white\\&quot;&gt;&quot;);\n\n\n    for(int i=0; i &lt; 1000; i++){\n        //Object o = new String(&quot;by kazaff, index is :&quot; + i);\n        HelloWorldExample.list.add(new kazaffBean());\n        //o = null;    \n    }    \n\n    out.println(&quot;&lt;div&gt;kazaff in here!!!!!!!&lt;/div&gt;&quot;);    \n\n    out.println(&quot;&lt;/body&gt;&quot;);\n        out.println(&quot;&lt;/html&gt;&quot;);\n\n    }\n}\n\nclass kazaffBean {\n    String name= &quot;&quot;;\n}\n</code></pre><p>然后我们还要手动编译修改后的java代码，进入到<code>/usr/local/apache-tomcat-7.0.53/webapps/examples/WEB-INF/classes/HelloWorldExample.java</code>所在的文件夹中，执行下面的命令：</p>\n<pre><code>javac HelloWorldExample.java -cp /usr/local/apache-tomcat-7.0.53/lib/servlet-api.jar \n</code></pre><p>当然，你的tomcat路径和我的很可能不同，酌情修改即可~~</p>\n<p>然后我们重启tomcat，对了，重启之前最好改一下分配给tomcat的内存上限，改小一些，有助于问题快速的暴露：</p>\n<pre><code>-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/www/java-OOM/\n</code></pre><p>后面的两个<code>-XX</code>参数是用来让jvm在出现OOM后自动保存内存堆栈快照信息用的，方便我们排查问题。</p>\n<p>重启吧，然后为了加速内存溢出，我们可以使用apache自带的<code>ab</code>做压力测试：</p>\n<pre><code>ab -c 100 -n 10000 http://192.168.153.128:81/examples/jsp/\n</code></pre><p>执行上面的这条命令后，基本上tomcat肯定就已经挂掉了，注意，我说的是tomcat挂掉了！也就是说你在终端中执行<code>jps</code>命令，不再会看到<code>Bootstrap</code>这个进程了！我之所以强调这一点，是因为我在测试中发现直接导致<code>jconsole</code>断开连接，并且再也无法建立连接。</p>\n<p>而奇怪的是，<code>jprofiler</code>照常可以连接并获取到远程服务器上的jvm的监控数据，这种情况一度使我陷入深深的迷惘。因为我在tomcat的logs里死活找不到任何关于内存溢出或其他异常的记录，直到我的目光落在终端上：</p>\n<pre><code>Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread &quot;http-bio-81-exec-13&quot;\n……\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n……\njava.lang.OutOfMemoryError: Java heap space\n……\nException in thread &quot;RMI TCP Connection(idle)&quot; java.lang.OutOfMemoryError: Java heap space\n</code></pre><p>这才是乖孩子嘛，就应该是这样的才对嘛~~不过还有几个点想不明白：</p>\n<ul>\n<li>虽然<code>jps</code>已经查不到tomcat的进程，但是从jprofiler的线程监控中还是可以看到相关的线程，如下图：</li>\n</ul>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E8rChOsQ/FN83O.png\" alt=\"\"></p>\n<ul>\n<li>既然tomcat都已经挂了，为什么<code>jprofiler</code>没有像<code>jconsole</code>那样连接断开呢？</li>\n</ul>\n<p>我这种小白目前是搞不定这两个问题了，还是抛到社区给大牛们分析吧。我们继续往下走~</p>\n<h2 id=\"关于内存溢出\"><a href=\"#关于内存溢出\" class=\"headerlink\" title=\"关于内存溢出\"></a>关于内存溢出</h2><p>通过我上面列出的异常信息，已经是非常常见的了，对于一些java老鸟而言肯定是再熟悉不过的了！不过我还是找到了一篇排版不咋滴但是比较全面的文章： <a href=\"http://yanguz123.iteye.com/blog/2017335\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<p>到此为止，就算做好了一切准备，可以去真正的项目上搞了！</p>\n","excerpt":"<p>上个月赶工上线的门户网站，由于种种原因导致部署到线上服务器后每隔一段时间后就会导致tomcat内存溢出，今天我就要来直面这个棘手的问题。</p>","more":"<p>要解决的问题对我来说还是有点难度的，原因有二：</p>\n<ol>\n<li>代码不是我写的；</li>\n<li>我对java并不熟悉。</li>\n</ol>\n<p>废话不多说，就由我这个小白依靠GG带领大家来启程吧！</p>\n<p>凭借我多年的编程经验，我认为首先要找到趁手的工具，那么，问题就来了，挖掘机技术到底哪家强？……</p>\n<p>好吧，GG一下，可以很容易查到很多用来监控jvm实时状态的工具，我们以jconsole为第一款尝试的工具吧。</p>\n<h2 id=\"jconsole\"><a href=\"#jconsole\" class=\"headerlink\" title=\"jconsole\"></a>jconsole</h2><p>这里要说明的是，我们需要搭建的监控环境是在win桌面机上远程监控一台centos服务器。按照网上说的，搭建起这么一个环境没有多大难度，大家可以参考这里：<a href=\"http://zhumeng8337797.blog.163.com/blog/static/100768914201282833448384/\">传送门</a>。</p>\n<p>如果你像我一样碰到了timeout提示，那多半就是centos防火墙拦截导致的，可以暂时关闭防火墙再尝试一下：</p>\n<pre><code>/etc/init.d/iptables stop\n</code></pre><p>好的，终于有了一个监控界面了，是不是感觉心里敞亮了不少呢？不过我感觉还是太笼统了，只能大概知道jvm的状况，而对于我们要排查代码导致的内存泄露问题似乎并没有帮到太大的忙~~</p>\n<p>不过可以通过提供的一些信息来判断是否配置了比较合理的参数，比方说可以通过<code>GC时间</code>看出是否给tomcat分配了适当的内存大小，尽可能的设置一个合理的内存来减少gc的次数和耗时。</p>\n<p>那我们接下来换哪个工具呢？</p>\n<h2 id=\"JProfiler\"><a href=\"#JProfiler\" class=\"headerlink\" title=\"JProfiler\"></a>JProfiler</h2><p>好吧，上大杀器！无需我多讲，我相信没有人会对我的选择有质疑吧？哇哈哈哈哈哈~~不过JProfiler是个商用产品，钱花到位才能享受生活，这一点儿错都没有。</p>\n<p>大家可以参考下面这些链接，相信你们很快就能搭建成功：</p>\n<p><a href=\"http://www.flybi.net/article/101\">传送门1</a>,<a href=\"http://sgq0085.iteye.com/blog/1947526\">传送门2</a>,<a href=\"http://blog.csdn.net/attilax/article/details/17077857\">传送门3</a></p>\n<p>按照上面提供的信息，我相信你很顺利就能安装部署完毕jprofiler（毕竟是商用产品嘛，肯定做的足够简单），但如果你和我一样是第一次用这个玩意儿，肯定会被它的默认界面震出翔！</p>\n<p>不要pia，先阅读一下这篇文章： <a href=\"http://www.cnblogs.com/jayzee/p/3184087.html\">传送门</a>。</p>\n<p>这里要提到的一点是，可能是软件版本的原因，按照上面前辈说的方法我却死活查不到方法调用Tree，查了一下GG才发现是需要调整配置选项，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E8qo6nio/W5piy.png\" alt=\"查看调用轨迹\"></p>\n<p>我这属于暴力解决吧，毕竟我把能开启的选项都选中了，不过想得到的问题也就是速度慢点，对于远程连接方式来说带宽占用多一些而已吧~~</p>\n<h2 id=\"测试代码\"><a href=\"#测试代码\" class=\"headerlink\" title=\"测试代码\"></a>测试代码</h2><p>找到了趁手的兵器，下一步就是要挖的坑了！哦，no，是一段会造成内存溢出的测试代码，我简单地修改了一下tomcat提供的例子中的<code>HelloWorldExample.java</code>：</p>\n<pre><code>import java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.ResourceBundle;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.http.HttpServlet;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\nimport java.util.ArrayList;\n\npublic class HelloWorldExample extends HttpServlet {\n\n    private static final long serialVersionUID = 1L;\n\n    private static ArrayList list = new ArrayList();\n\n    @Override\n    public void doGet(HttpServletRequest request,\n                      HttpServletResponse response)\n        throws IOException, ServletException\n    {\n        ResourceBundle rb =\n            ResourceBundle.getBundle(&quot;LocalStrings&quot;,request.getLocale());\n        response.setContentType(&quot;text/html&quot;);\n        PrintWriter out = response.getWriter();\n\n        out.println(&quot;&lt;html&gt;&quot;);\n        out.println(&quot;&lt;head&gt;&quot;);\n        out.println(&quot;&lt;/head&gt;&quot;);\n        out.println(&quot;&lt;body bgcolor=\\&quot;white\\&quot;&gt;&quot;);\n\n\n    for(int i=0; i &lt; 1000; i++){\n        //Object o = new String(&quot;by kazaff, index is :&quot; + i);\n        HelloWorldExample.list.add(new kazaffBean());\n        //o = null;    \n    }    \n\n    out.println(&quot;&lt;div&gt;kazaff in here!!!!!!!&lt;/div&gt;&quot;);    \n\n    out.println(&quot;&lt;/body&gt;&quot;);\n        out.println(&quot;&lt;/html&gt;&quot;);\n\n    }\n}\n\nclass kazaffBean {\n    String name= &quot;&quot;;\n}\n</code></pre><p>然后我们还要手动编译修改后的java代码，进入到<code>/usr/local/apache-tomcat-7.0.53/webapps/examples/WEB-INF/classes/HelloWorldExample.java</code>所在的文件夹中，执行下面的命令：</p>\n<pre><code>javac HelloWorldExample.java -cp /usr/local/apache-tomcat-7.0.53/lib/servlet-api.jar \n</code></pre><p>当然，你的tomcat路径和我的很可能不同，酌情修改即可~~</p>\n<p>然后我们重启tomcat，对了，重启之前最好改一下分配给tomcat的内存上限，改小一些，有助于问题快速的暴露：</p>\n<pre><code>-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/www/java-OOM/\n</code></pre><p>后面的两个<code>-XX</code>参数是用来让jvm在出现OOM后自动保存内存堆栈快照信息用的，方便我们排查问题。</p>\n<p>重启吧，然后为了加速内存溢出，我们可以使用apache自带的<code>ab</code>做压力测试：</p>\n<pre><code>ab -c 100 -n 10000 http://192.168.153.128:81/examples/jsp/\n</code></pre><p>执行上面的这条命令后，基本上tomcat肯定就已经挂掉了，注意，我说的是tomcat挂掉了！也就是说你在终端中执行<code>jps</code>命令，不再会看到<code>Bootstrap</code>这个进程了！我之所以强调这一点，是因为我在测试中发现直接导致<code>jconsole</code>断开连接，并且再也无法建立连接。</p>\n<p>而奇怪的是，<code>jprofiler</code>照常可以连接并获取到远程服务器上的jvm的监控数据，这种情况一度使我陷入深深的迷惘。因为我在tomcat的logs里死活找不到任何关于内存溢出或其他异常的记录，直到我的目光落在终端上：</p>\n<pre><code>Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread &quot;http-bio-81-exec-13&quot;\n……\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n……\njava.lang.OutOfMemoryError: Java heap space\n……\nException in thread &quot;RMI TCP Connection(idle)&quot; java.lang.OutOfMemoryError: Java heap space\n</code></pre><p>这才是乖孩子嘛，就应该是这样的才对嘛~~不过还有几个点想不明白：</p>\n<ul>\n<li>虽然<code>jps</code>已经查不到tomcat的进程，但是从jprofiler的线程监控中还是可以看到相关的线程，如下图：</li>\n</ul>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E8rChOsQ/FN83O.png\" alt=\"\"></p>\n<ul>\n<li>既然tomcat都已经挂了，为什么<code>jprofiler</code>没有像<code>jconsole</code>那样连接断开呢？</li>\n</ul>\n<p>我这种小白目前是搞不定这两个问题了，还是抛到社区给大牛们分析吧。我们继续往下走~</p>\n<h2 id=\"关于内存溢出\"><a href=\"#关于内存溢出\" class=\"headerlink\" title=\"关于内存溢出\"></a>关于内存溢出</h2><p>通过我上面列出的异常信息，已经是非常常见的了，对于一些java老鸟而言肯定是再熟悉不过的了！不过我还是找到了一篇排版不咋滴但是比较全面的文章： <a href=\"http://yanguz123.iteye.com/blog/2017335\">传送门</a>。</p>\n<p>到此为止，就算做好了一切准备，可以去真正的项目上搞了！</p>"},{"title":"所谓协议相对URL","date":"2014-09-26T10:15:30.000Z","_content":"\n之前在搞前端的时候，看到过很多国外的插件或library都好使用没有指定协议的url，查过原因，但忘记了～～这次又看到，决定记录下来。\n\n<!-- more -->\n\n\t\n\t<script src=\"//cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\"></script>\n\t\n这种写法还有一个较为学术的名字：**协议相对URL（The Protocol-relative URL）**。\n\n具体作用其实很简单，也就是根据页面使用的协议来适配。例如上面的那行代码，如果页面使用的是http，则会加载：\n\n\thttp://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n\t\n如果是https，则加载：\n\n\thttps://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n\t\n就是这么简单明了！！\n\n参考：\n[协议相对URL](http://www.fising.cn/2014/09/the-protocol-relative-url.shtml)","source":"_posts/所谓协议相对URL.md","raw":"title: 所谓协议相对URL\ndate: 2014-09-26 18:15:30\ntags:\n- url\ncategories: 前端\n---\n\n之前在搞前端的时候，看到过很多国外的插件或library都好使用没有指定协议的url，查过原因，但忘记了～～这次又看到，决定记录下来。\n\n<!-- more -->\n\n\t\n\t<script src=\"//cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\"></script>\n\t\n这种写法还有一个较为学术的名字：**协议相对URL（The Protocol-relative URL）**。\n\n具体作用其实很简单，也就是根据页面使用的协议来适配。例如上面的那行代码，如果页面使用的是http，则会加载：\n\n\thttp://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n\t\n如果是https，则加载：\n\n\thttps://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n\t\n就是这么简单明了！！\n\n参考：\n[协议相对URL](http://www.fising.cn/2014/09/the-protocol-relative-url.shtml)","slug":"所谓协议相对URL","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yly003kgtfyjuoosei1","comments":1,"layout":"post","photos":[],"link":"","content":"<p>之前在搞前端的时候，看到过很多国外的插件或library都好使用没有指定协议的url，查过原因，但忘记了～～这次又看到，决定记录下来。</p>\n<a id=\"more\"></a>\n<pre><code>&lt;script src=&quot;//cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js&quot;&gt;&lt;/script&gt;\n</code></pre><p>这种写法还有一个较为学术的名字：<strong>协议相对URL（The Protocol-relative URL）</strong>。</p>\n<p>具体作用其实很简单，也就是根据页面使用的协议来适配。例如上面的那行代码，如果页面使用的是http，则会加载：</p>\n<pre><code>http://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n</code></pre><p>如果是https，则加载：</p>\n<pre><code>https://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n</code></pre><p>就是这么简单明了！！</p>\n<p>参考：<br><a href=\"http://www.fising.cn/2014/09/the-protocol-relative-url.shtml\" target=\"_blank\" rel=\"external\">协议相对URL</a></p>\n","excerpt":"<p>之前在搞前端的时候，看到过很多国外的插件或library都好使用没有指定协议的url，查过原因，但忘记了～～这次又看到，决定记录下来。</p>","more":"<pre><code>&lt;script src=&quot;//cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js&quot;&gt;&lt;/script&gt;\n</code></pre><p>这种写法还有一个较为学术的名字：<strong>协议相对URL（The Protocol-relative URL）</strong>。</p>\n<p>具体作用其实很简单，也就是根据页面使用的协议来适配。例如上面的那行代码，如果页面使用的是http，则会加载：</p>\n<pre><code>http://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n</code></pre><p>如果是https，则加载：</p>\n<pre><code>https://cdnjscn.b0.upaiyun.com/libs/jquery/2.1.1/jquery.min.js\n</code></pre><p>就是这么简单明了！！</p>\n<p>参考：<br><a href=\"http://www.fising.cn/2014/09/the-protocol-relative-url.shtml\">协议相对URL</a></p>"},{"title":"如何把项目SOA化系列之二：业务梳理","date":"2015-03-02T07:54:30.000Z","_content":"\n好吧，按照[计划](http://blog.kazaff.me/2015/02/25/%E5%A6%82%E4%BD%95%E6%8A%8A%E9%A1%B9%E7%9B%AEsoa%E5%8C%96%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%80%EF%BC%9A%E8%AE%A1%E5%88%92/)，我们接下来要做的就是根据项目现有的功能，依照相关的标准抽离出相关的服务。\n<!--more-->\n\n把这个任务根据我们公司的实际情况，还可以细分，不过不确定是否对大家有参考价值，但是为了记录下每一步重构流程，我还是坚持要写出来的，所以如果你觉得不耐烦，请移步到该系列其它文章，谢谢合作。\n\n服务发现\n---\n首先，小弟花了三天的时间，把公司相关的项目文档和代码粗略的滤了一遍，方法简单粗暴，谈不上合理，但个人感觉还是有点用的，根据之前提到的基准，整理出了个文档，如下：\n\n![](http://pic.yupoo.com/kazaff/EsYPTBXF/HrRKb.png)\n\n其中每个维度的满分为5（不建议选用过大的分值范围），粗略的解释一下每个分值的含义：\n\n**重要度：**\n\n1分：作用程度几乎可以不考虑\n\n2分：出现问题不影响业务正常工作\n\n3分：普通，出现问题允许在1天的时间内给予修复即可\n\n4分：重要，不允许失效\n\n5分：核心，不允许失效，且要保证高的执行效率\n\n\n**复杂度：**\n\n1分：简单的直接操作一张表，或表达为入职一个月的普通应届生就可完成的任务（这么说可能容易被拍）\n\n2分：需要同时操作多张表，存在一对多关系的数据组合\n\n3分：包含较多的业务逻辑，但全部操作都在同一个上下文中完成（单进程单线程）\n\n4分：产生RPC调用\n\n5分：使用了多线程\n\n\n**复用度：**\n\n1分：只有自己使用，这里的“自己”表示自身所在的单个系统中的个别操作使用\n\n2分：自身所在的单个系统中不超过5个操作使用\n\n3分：自身所在单个系统中超过5个操作使用\n\n4分：2个以上的系统都使用\n\n5分：可预见的所有系统都会使用\n\n\n**频度：**\n\n1分：偶尔会用，或叫几乎不用（其实大多数操作都属于这一类，又一次验证了二八定理）\n\n2分：普通操作，但并非日常必须\n\n3分：通用操作，正常用户日常会经常使用的\n\n4分：热门操作，所有用户日常会经常使用的\n\n5分：必经操作，所有用户一定会频繁使用的\n\n\n**类型：**\n\n原子：基础服务，可以理解为自包含，有明确边界的功能\n\n复合：组合服务，需要由1个以上的原子服务组合出来的功能\n\n\n以上打分并不是非常的严谨，只是争取做到了有个粗略的标准来区分服务的目的。\n\n\n\n\n服务关系梳理\n---\n\n粗略的数了数，我们公司的在使用项目大概也有十四个之多，上一篇文章介绍过，由于初期设计时就考虑到了系统间的依赖，所以单独在某个项目自身上去发现服务，是不准确的，很可能A系统中的一些功能是依赖B系统的，这样上述的列表中就会有大量的重复内容，所以我们下一步需要做的，就是**梳理服务之间的关系**。\n\n既然要研究关系，视角就不能只局限在某个系统，而是应该上升到平台上，自嘲的说，我们团队现有的项目用\"平台\"二字有点小题大做，不过意思到了就行了，不要在意细节，咱们聊的是方法论。\n\n其实在服务发现时，根据基准，就可以第一轮筛选出一部分较为合适的服务集合了，我们只需要把选中的服务的关系整理出来即可。依然采用图的方式，如下：\n\n![](http://pic.yupoo.com/kazaff/EthzHHM9/294CP.png)\n\nPS:哥知道画的很丑，但确实没有美化的能力啊，**求推荐工具**。\n\n\n---\n\n这样下来，目标就明确很多了。但，这还不够，接下来就是要深入到每一个服务中，根据实际情况来设计该服务的实现细节。我们放在下一篇来继续。","source":"_posts/如何把项目soa化系列之二：业务梳理和服务发现.md","raw":"title: 如何把项目SOA化系列之二：业务梳理\ndate: 2015-03-2 15:54:30\ntags:\n- soa\n- 服务\n\ncategories: 架构\n---\n\n好吧，按照[计划](http://blog.kazaff.me/2015/02/25/%E5%A6%82%E4%BD%95%E6%8A%8A%E9%A1%B9%E7%9B%AEsoa%E5%8C%96%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%80%EF%BC%9A%E8%AE%A1%E5%88%92/)，我们接下来要做的就是根据项目现有的功能，依照相关的标准抽离出相关的服务。\n<!--more-->\n\n把这个任务根据我们公司的实际情况，还可以细分，不过不确定是否对大家有参考价值，但是为了记录下每一步重构流程，我还是坚持要写出来的，所以如果你觉得不耐烦，请移步到该系列其它文章，谢谢合作。\n\n服务发现\n---\n首先，小弟花了三天的时间，把公司相关的项目文档和代码粗略的滤了一遍，方法简单粗暴，谈不上合理，但个人感觉还是有点用的，根据之前提到的基准，整理出了个文档，如下：\n\n![](http://pic.yupoo.com/kazaff/EsYPTBXF/HrRKb.png)\n\n其中每个维度的满分为5（不建议选用过大的分值范围），粗略的解释一下每个分值的含义：\n\n**重要度：**\n\n1分：作用程度几乎可以不考虑\n\n2分：出现问题不影响业务正常工作\n\n3分：普通，出现问题允许在1天的时间内给予修复即可\n\n4分：重要，不允许失效\n\n5分：核心，不允许失效，且要保证高的执行效率\n\n\n**复杂度：**\n\n1分：简单的直接操作一张表，或表达为入职一个月的普通应届生就可完成的任务（这么说可能容易被拍）\n\n2分：需要同时操作多张表，存在一对多关系的数据组合\n\n3分：包含较多的业务逻辑，但全部操作都在同一个上下文中完成（单进程单线程）\n\n4分：产生RPC调用\n\n5分：使用了多线程\n\n\n**复用度：**\n\n1分：只有自己使用，这里的“自己”表示自身所在的单个系统中的个别操作使用\n\n2分：自身所在的单个系统中不超过5个操作使用\n\n3分：自身所在单个系统中超过5个操作使用\n\n4分：2个以上的系统都使用\n\n5分：可预见的所有系统都会使用\n\n\n**频度：**\n\n1分：偶尔会用，或叫几乎不用（其实大多数操作都属于这一类，又一次验证了二八定理）\n\n2分：普通操作，但并非日常必须\n\n3分：通用操作，正常用户日常会经常使用的\n\n4分：热门操作，所有用户日常会经常使用的\n\n5分：必经操作，所有用户一定会频繁使用的\n\n\n**类型：**\n\n原子：基础服务，可以理解为自包含，有明确边界的功能\n\n复合：组合服务，需要由1个以上的原子服务组合出来的功能\n\n\n以上打分并不是非常的严谨，只是争取做到了有个粗略的标准来区分服务的目的。\n\n\n\n\n服务关系梳理\n---\n\n粗略的数了数，我们公司的在使用项目大概也有十四个之多，上一篇文章介绍过，由于初期设计时就考虑到了系统间的依赖，所以单独在某个项目自身上去发现服务，是不准确的，很可能A系统中的一些功能是依赖B系统的，这样上述的列表中就会有大量的重复内容，所以我们下一步需要做的，就是**梳理服务之间的关系**。\n\n既然要研究关系，视角就不能只局限在某个系统，而是应该上升到平台上，自嘲的说，我们团队现有的项目用\"平台\"二字有点小题大做，不过意思到了就行了，不要在意细节，咱们聊的是方法论。\n\n其实在服务发现时，根据基准，就可以第一轮筛选出一部分较为合适的服务集合了，我们只需要把选中的服务的关系整理出来即可。依然采用图的方式，如下：\n\n![](http://pic.yupoo.com/kazaff/EthzHHM9/294CP.png)\n\nPS:哥知道画的很丑，但确实没有美化的能力啊，**求推荐工具**。\n\n\n---\n\n这样下来，目标就明确很多了。但，这还不够，接下来就是要深入到每一个服务中，根据实际情况来设计该服务的实现细节。我们放在下一篇来继续。","slug":"如何把项目soa化系列之二：业务梳理和服务发现","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ym5003pgtfyturapd57","comments":1,"layout":"post","photos":[],"link":"","content":"<p>好吧，按照<a href=\"http://blog.kazaff.me/2015/02/25/%E5%A6%82%E4%BD%95%E6%8A%8A%E9%A1%B9%E7%9B%AEsoa%E5%8C%96%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%80%EF%BC%9A%E8%AE%A1%E5%88%92/\">计划</a>，我们接下来要做的就是根据项目现有的功能，依照相关的标准抽离出相关的服务。<br><a id=\"more\"></a></p>\n<p>把这个任务根据我们公司的实际情况，还可以细分，不过不确定是否对大家有参考价值，但是为了记录下每一步重构流程，我还是坚持要写出来的，所以如果你觉得不耐烦，请移步到该系列其它文章，谢谢合作。</p>\n<h2 id=\"服务发现\"><a href=\"#服务发现\" class=\"headerlink\" title=\"服务发现\"></a>服务发现</h2><p>首先，小弟花了三天的时间，把公司相关的项目文档和代码粗略的滤了一遍，方法简单粗暴，谈不上合理，但个人感觉还是有点用的，根据之前提到的基准，整理出了个文档，如下：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EsYPTBXF/HrRKb.png\" alt=\"\"></p>\n<p>其中每个维度的满分为5（不建议选用过大的分值范围），粗略的解释一下每个分值的含义：</p>\n<p><strong>重要度：</strong></p>\n<p>1分：作用程度几乎可以不考虑</p>\n<p>2分：出现问题不影响业务正常工作</p>\n<p>3分：普通，出现问题允许在1天的时间内给予修复即可</p>\n<p>4分：重要，不允许失效</p>\n<p>5分：核心，不允许失效，且要保证高的执行效率</p>\n<p><strong>复杂度：</strong></p>\n<p>1分：简单的直接操作一张表，或表达为入职一个月的普通应届生就可完成的任务（这么说可能容易被拍）</p>\n<p>2分：需要同时操作多张表，存在一对多关系的数据组合</p>\n<p>3分：包含较多的业务逻辑，但全部操作都在同一个上下文中完成（单进程单线程）</p>\n<p>4分：产生RPC调用</p>\n<p>5分：使用了多线程</p>\n<p><strong>复用度：</strong></p>\n<p>1分：只有自己使用，这里的“自己”表示自身所在的单个系统中的个别操作使用</p>\n<p>2分：自身所在的单个系统中不超过5个操作使用</p>\n<p>3分：自身所在单个系统中超过5个操作使用</p>\n<p>4分：2个以上的系统都使用</p>\n<p>5分：可预见的所有系统都会使用</p>\n<p><strong>频度：</strong></p>\n<p>1分：偶尔会用，或叫几乎不用（其实大多数操作都属于这一类，又一次验证了二八定理）</p>\n<p>2分：普通操作，但并非日常必须</p>\n<p>3分：通用操作，正常用户日常会经常使用的</p>\n<p>4分：热门操作，所有用户日常会经常使用的</p>\n<p>5分：必经操作，所有用户一定会频繁使用的</p>\n<p><strong>类型：</strong></p>\n<p>原子：基础服务，可以理解为自包含，有明确边界的功能</p>\n<p>复合：组合服务，需要由1个以上的原子服务组合出来的功能</p>\n<p>以上打分并不是非常的严谨，只是争取做到了有个粗略的标准来区分服务的目的。</p>\n<h2 id=\"服务关系梳理\"><a href=\"#服务关系梳理\" class=\"headerlink\" title=\"服务关系梳理\"></a>服务关系梳理</h2><p>粗略的数了数，我们公司的在使用项目大概也有十四个之多，上一篇文章介绍过，由于初期设计时就考虑到了系统间的依赖，所以单独在某个项目自身上去发现服务，是不准确的，很可能A系统中的一些功能是依赖B系统的，这样上述的列表中就会有大量的重复内容，所以我们下一步需要做的，就是<strong>梳理服务之间的关系</strong>。</p>\n<p>既然要研究关系，视角就不能只局限在某个系统，而是应该上升到平台上，自嘲的说，我们团队现有的项目用”平台”二字有点小题大做，不过意思到了就行了，不要在意细节，咱们聊的是方法论。</p>\n<p>其实在服务发现时，根据基准，就可以第一轮筛选出一部分较为合适的服务集合了，我们只需要把选中的服务的关系整理出来即可。依然采用图的方式，如下：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EthzHHM9/294CP.png\" alt=\"\"></p>\n<p>PS:哥知道画的很丑，但确实没有美化的能力啊，<strong>求推荐工具</strong>。</p>\n<hr>\n<p>这样下来，目标就明确很多了。但，这还不够，接下来就是要深入到每一个服务中，根据实际情况来设计该服务的实现细节。我们放在下一篇来继续。</p>\n","excerpt":"<p>好吧，按照<a href=\"http://blog.kazaff.me/2015/02/25/%E5%A6%82%E4%BD%95%E6%8A%8A%E9%A1%B9%E7%9B%AEsoa%E5%8C%96%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%80%EF%BC%9A%E8%AE%A1%E5%88%92/\">计划</a>，我们接下来要做的就是根据项目现有的功能，依照相关的标准抽离出相关的服务。<br>","more":"</p>\n<p>把这个任务根据我们公司的实际情况，还可以细分，不过不确定是否对大家有参考价值，但是为了记录下每一步重构流程，我还是坚持要写出来的，所以如果你觉得不耐烦，请移步到该系列其它文章，谢谢合作。</p>\n<h2 id=\"服务发现\"><a href=\"#服务发现\" class=\"headerlink\" title=\"服务发现\"></a>服务发现</h2><p>首先，小弟花了三天的时间，把公司相关的项目文档和代码粗略的滤了一遍，方法简单粗暴，谈不上合理，但个人感觉还是有点用的，根据之前提到的基准，整理出了个文档，如下：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EsYPTBXF/HrRKb.png\" alt=\"\"></p>\n<p>其中每个维度的满分为5（不建议选用过大的分值范围），粗略的解释一下每个分值的含义：</p>\n<p><strong>重要度：</strong></p>\n<p>1分：作用程度几乎可以不考虑</p>\n<p>2分：出现问题不影响业务正常工作</p>\n<p>3分：普通，出现问题允许在1天的时间内给予修复即可</p>\n<p>4分：重要，不允许失效</p>\n<p>5分：核心，不允许失效，且要保证高的执行效率</p>\n<p><strong>复杂度：</strong></p>\n<p>1分：简单的直接操作一张表，或表达为入职一个月的普通应届生就可完成的任务（这么说可能容易被拍）</p>\n<p>2分：需要同时操作多张表，存在一对多关系的数据组合</p>\n<p>3分：包含较多的业务逻辑，但全部操作都在同一个上下文中完成（单进程单线程）</p>\n<p>4分：产生RPC调用</p>\n<p>5分：使用了多线程</p>\n<p><strong>复用度：</strong></p>\n<p>1分：只有自己使用，这里的“自己”表示自身所在的单个系统中的个别操作使用</p>\n<p>2分：自身所在的单个系统中不超过5个操作使用</p>\n<p>3分：自身所在单个系统中超过5个操作使用</p>\n<p>4分：2个以上的系统都使用</p>\n<p>5分：可预见的所有系统都会使用</p>\n<p><strong>频度：</strong></p>\n<p>1分：偶尔会用，或叫几乎不用（其实大多数操作都属于这一类，又一次验证了二八定理）</p>\n<p>2分：普通操作，但并非日常必须</p>\n<p>3分：通用操作，正常用户日常会经常使用的</p>\n<p>4分：热门操作，所有用户日常会经常使用的</p>\n<p>5分：必经操作，所有用户一定会频繁使用的</p>\n<p><strong>类型：</strong></p>\n<p>原子：基础服务，可以理解为自包含，有明确边界的功能</p>\n<p>复合：组合服务，需要由1个以上的原子服务组合出来的功能</p>\n<p>以上打分并不是非常的严谨，只是争取做到了有个粗略的标准来区分服务的目的。</p>\n<h2 id=\"服务关系梳理\"><a href=\"#服务关系梳理\" class=\"headerlink\" title=\"服务关系梳理\"></a>服务关系梳理</h2><p>粗略的数了数，我们公司的在使用项目大概也有十四个之多，上一篇文章介绍过，由于初期设计时就考虑到了系统间的依赖，所以单独在某个项目自身上去发现服务，是不准确的，很可能A系统中的一些功能是依赖B系统的，这样上述的列表中就会有大量的重复内容，所以我们下一步需要做的，就是<strong>梳理服务之间的关系</strong>。</p>\n<p>既然要研究关系，视角就不能只局限在某个系统，而是应该上升到平台上，自嘲的说，我们团队现有的项目用”平台”二字有点小题大做，不过意思到了就行了，不要在意细节，咱们聊的是方法论。</p>\n<p>其实在服务发现时，根据基准，就可以第一轮筛选出一部分较为合适的服务集合了，我们只需要把选中的服务的关系整理出来即可。依然采用图的方式，如下：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EthzHHM9/294CP.png\" alt=\"\"></p>\n<p>PS:哥知道画的很丑，但确实没有美化的能力啊，<strong>求推荐工具</strong>。</p>\n<hr>\n<p>这样下来，目标就明确很多了。但，这还不够，接下来就是要深入到每一个服务中，根据实际情况来设计该服务的实现细节。我们放在下一篇来继续。</p>"},{"title":"如何把项目SOA化系列之三：架构设计","date":"2015-03-05T07:54:30.000Z","_content":"\n已经到了这一步，进度还算比较快。只是悲剧的是，当我整理完项目调用关系后才“恍然大悟”，妈蛋，年前某个时间我已经做过一次这样的工作了。而且更夸张的是，那一次做的比现在还彻底，哇哈哈哈哈，我这种记性，也是醉了。值得庆幸的是，两次流程的大致方向还是一致的（不然就麻烦了，精神分裂~）。\n<!--more-->\n言归正传，本来计划接着上一篇，直接开始写服务的详细设计呢，但是感觉还是缺少什么，应该就是对平台的整体设计规划吧。先上一张图：\n\n![](http://pic.yupoo.com/kazaff/EtyynD4b/h1Cdl.png)\n\n**图解：**\n\n- 客户端和运营平台之间的通信统一基于Http的REST API，这类API尽可能保证完整业务逻辑，以粗颗粒度提供（意味着复用性较差）\n- Rest API内部会负责业务编排，以dubbo提供的高性能协议与运营平台中的数据应用服务进行通信\n- 数据应用服务之间允许相互依赖，同样基于dubbo\n- 数据应用服务之间的依赖应该尽可能的少，应该尽可能放在Rest API层来做处理这种依赖\n- 后方的各个数据系统之间不存在直接依赖，所有依赖都需要通过运营平台的数据应用服务来提供，通信同样基于dubbo\n- 计费和权限认证等逻辑尽可能的异步化或并行（后面详细讨论）\n\n这是年前设计出的一张图，现在来看依然是很满意的，唯一值得考虑的就是**“微服务”**概念，我一直比较赞同这个概念，尤其是在做SOA筹备的时候更是如此。上图中，数据应用服务是比较适合以**微服务**方式设计的，不过还需要结合dubbo更仔细的琢磨琢磨。\n\n接下来再来说一下关于上图中一些特殊的服务：计费，认证授权等。我提到了异步和并行，如图：\n\n![](http://pic.yupoo.com/kazaff/EtyLEKAY/18Thz.png)\n\n**图解：**\n\n- 虚线表示异步调用，实线表示并行调用\n- 计费和余额查询分离，会产生一个不一致的时间窗口，这需要结合业务来衡量可行性\n- 余额查询，权限认证和获取数据并行调用，最终会在API层合并后给予最终裁决\n- 图中省略了SLB的相关部分\n\n最后，我们讨论一下系统中另外一种场景的通信：消息通知。稍微复杂一些的系统，都会对消息队列有强的需求。这是因为，系统之间的通信在排除了人类参与的情况下，并不需要非常之高的即时响应指标，相反，对消息的最终可达性要求确实100%的。这也是消息中间件的战场，各种各样的开源产品可供我们选择。\n\n我们跳出具体的消息中间件，从业务层面来梳理一下我们目前的平台中要如何设计这部分场景，如下图：\n\n![](http://pic.yupoo.com/kazaff/EtyXLyam/12Dm6j.png)\n\n**图解：**\n\n- 没什么要解释的啦\n\n\n---\n\n目前为止，我们已经从整体上描述了一下要做的事情，不管你们看完后有啥感受，我自己是清晰了不少，哇哈哈。这一篇谈的有点虚，都是围绕着实际业务来谈概念的，应该就是所谓的概念架构设计了吧~~\n\n下一篇开始，就要深入到代码微观视角了，尽请期待！","source":"_posts/如何把项目soa化系列之三：架构设计.md","raw":"title: 如何把项目SOA化系列之三：架构设计\ndate: 2015-03-5 15:54:30\ntags:\n- soa\n- dubbo\n- rest\n- 队列\n\ncategories: 架构\n---\n\n已经到了这一步，进度还算比较快。只是悲剧的是，当我整理完项目调用关系后才“恍然大悟”，妈蛋，年前某个时间我已经做过一次这样的工作了。而且更夸张的是，那一次做的比现在还彻底，哇哈哈哈哈，我这种记性，也是醉了。值得庆幸的是，两次流程的大致方向还是一致的（不然就麻烦了，精神分裂~）。\n<!--more-->\n言归正传，本来计划接着上一篇，直接开始写服务的详细设计呢，但是感觉还是缺少什么，应该就是对平台的整体设计规划吧。先上一张图：\n\n![](http://pic.yupoo.com/kazaff/EtyynD4b/h1Cdl.png)\n\n**图解：**\n\n- 客户端和运营平台之间的通信统一基于Http的REST API，这类API尽可能保证完整业务逻辑，以粗颗粒度提供（意味着复用性较差）\n- Rest API内部会负责业务编排，以dubbo提供的高性能协议与运营平台中的数据应用服务进行通信\n- 数据应用服务之间允许相互依赖，同样基于dubbo\n- 数据应用服务之间的依赖应该尽可能的少，应该尽可能放在Rest API层来做处理这种依赖\n- 后方的各个数据系统之间不存在直接依赖，所有依赖都需要通过运营平台的数据应用服务来提供，通信同样基于dubbo\n- 计费和权限认证等逻辑尽可能的异步化或并行（后面详细讨论）\n\n这是年前设计出的一张图，现在来看依然是很满意的，唯一值得考虑的就是**“微服务”**概念，我一直比较赞同这个概念，尤其是在做SOA筹备的时候更是如此。上图中，数据应用服务是比较适合以**微服务**方式设计的，不过还需要结合dubbo更仔细的琢磨琢磨。\n\n接下来再来说一下关于上图中一些特殊的服务：计费，认证授权等。我提到了异步和并行，如图：\n\n![](http://pic.yupoo.com/kazaff/EtyLEKAY/18Thz.png)\n\n**图解：**\n\n- 虚线表示异步调用，实线表示并行调用\n- 计费和余额查询分离，会产生一个不一致的时间窗口，这需要结合业务来衡量可行性\n- 余额查询，权限认证和获取数据并行调用，最终会在API层合并后给予最终裁决\n- 图中省略了SLB的相关部分\n\n最后，我们讨论一下系统中另外一种场景的通信：消息通知。稍微复杂一些的系统，都会对消息队列有强的需求。这是因为，系统之间的通信在排除了人类参与的情况下，并不需要非常之高的即时响应指标，相反，对消息的最终可达性要求确实100%的。这也是消息中间件的战场，各种各样的开源产品可供我们选择。\n\n我们跳出具体的消息中间件，从业务层面来梳理一下我们目前的平台中要如何设计这部分场景，如下图：\n\n![](http://pic.yupoo.com/kazaff/EtyXLyam/12Dm6j.png)\n\n**图解：**\n\n- 没什么要解释的啦\n\n\n---\n\n目前为止，我们已经从整体上描述了一下要做的事情，不管你们看完后有啥感受，我自己是清晰了不少，哇哈哈。这一篇谈的有点虚，都是围绕着实际业务来谈概念的，应该就是所谓的概念架构设计了吧~~\n\n下一篇开始，就要深入到代码微观视角了，尽请期待！","slug":"如何把项目soa化系列之三：架构设计","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yma003wgtfyy0riin4e","comments":1,"layout":"post","photos":[],"link":"","content":"<p>已经到了这一步，进度还算比较快。只是悲剧的是，当我整理完项目调用关系后才“恍然大悟”，妈蛋，年前某个时间我已经做过一次这样的工作了。而且更夸张的是，那一次做的比现在还彻底，哇哈哈哈哈，我这种记性，也是醉了。值得庆幸的是，两次流程的大致方向还是一致的（不然就麻烦了，精神分裂~）。<br><a id=\"more\"></a><br>言归正传，本来计划接着上一篇，直接开始写服务的详细设计呢，但是感觉还是缺少什么，应该就是对平台的整体设计规划吧。先上一张图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EtyynD4b/h1Cdl.png\" alt=\"\"></p>\n<p><strong>图解：</strong></p>\n<ul>\n<li>客户端和运营平台之间的通信统一基于Http的REST API，这类API尽可能保证完整业务逻辑，以粗颗粒度提供（意味着复用性较差）</li>\n<li>Rest API内部会负责业务编排，以dubbo提供的高性能协议与运营平台中的数据应用服务进行通信</li>\n<li>数据应用服务之间允许相互依赖，同样基于dubbo</li>\n<li>数据应用服务之间的依赖应该尽可能的少，应该尽可能放在Rest API层来做处理这种依赖</li>\n<li>后方的各个数据系统之间不存在直接依赖，所有依赖都需要通过运营平台的数据应用服务来提供，通信同样基于dubbo</li>\n<li>计费和权限认证等逻辑尽可能的异步化或并行（后面详细讨论）</li>\n</ul>\n<p>这是年前设计出的一张图，现在来看依然是很满意的，唯一值得考虑的就是<strong>“微服务”</strong>概念，我一直比较赞同这个概念，尤其是在做SOA筹备的时候更是如此。上图中，数据应用服务是比较适合以<strong>微服务</strong>方式设计的，不过还需要结合dubbo更仔细的琢磨琢磨。</p>\n<p>接下来再来说一下关于上图中一些特殊的服务：计费，认证授权等。我提到了异步和并行，如图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EtyLEKAY/18Thz.png\" alt=\"\"></p>\n<p><strong>图解：</strong></p>\n<ul>\n<li>虚线表示异步调用，实线表示并行调用</li>\n<li>计费和余额查询分离，会产生一个不一致的时间窗口，这需要结合业务来衡量可行性</li>\n<li>余额查询，权限认证和获取数据并行调用，最终会在API层合并后给予最终裁决</li>\n<li>图中省略了SLB的相关部分</li>\n</ul>\n<p>最后，我们讨论一下系统中另外一种场景的通信：消息通知。稍微复杂一些的系统，都会对消息队列有强的需求。这是因为，系统之间的通信在排除了人类参与的情况下，并不需要非常之高的即时响应指标，相反，对消息的最终可达性要求确实100%的。这也是消息中间件的战场，各种各样的开源产品可供我们选择。</p>\n<p>我们跳出具体的消息中间件，从业务层面来梳理一下我们目前的平台中要如何设计这部分场景，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EtyXLyam/12Dm6j.png\" alt=\"\"></p>\n<p><strong>图解：</strong></p>\n<ul>\n<li>没什么要解释的啦</li>\n</ul>\n<hr>\n<p>目前为止，我们已经从整体上描述了一下要做的事情，不管你们看完后有啥感受，我自己是清晰了不少，哇哈哈。这一篇谈的有点虚，都是围绕着实际业务来谈概念的，应该就是所谓的概念架构设计了吧~~</p>\n<p>下一篇开始，就要深入到代码微观视角了，尽请期待！</p>\n","excerpt":"<p>已经到了这一步，进度还算比较快。只是悲剧的是，当我整理完项目调用关系后才“恍然大悟”，妈蛋，年前某个时间我已经做过一次这样的工作了。而且更夸张的是，那一次做的比现在还彻底，哇哈哈哈哈，我这种记性，也是醉了。值得庆幸的是，两次流程的大致方向还是一致的（不然就麻烦了，精神分裂~）。<br>","more":"<br>言归正传，本来计划接着上一篇，直接开始写服务的详细设计呢，但是感觉还是缺少什么，应该就是对平台的整体设计规划吧。先上一张图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EtyynD4b/h1Cdl.png\" alt=\"\"></p>\n<p><strong>图解：</strong></p>\n<ul>\n<li>客户端和运营平台之间的通信统一基于Http的REST API，这类API尽可能保证完整业务逻辑，以粗颗粒度提供（意味着复用性较差）</li>\n<li>Rest API内部会负责业务编排，以dubbo提供的高性能协议与运营平台中的数据应用服务进行通信</li>\n<li>数据应用服务之间允许相互依赖，同样基于dubbo</li>\n<li>数据应用服务之间的依赖应该尽可能的少，应该尽可能放在Rest API层来做处理这种依赖</li>\n<li>后方的各个数据系统之间不存在直接依赖，所有依赖都需要通过运营平台的数据应用服务来提供，通信同样基于dubbo</li>\n<li>计费和权限认证等逻辑尽可能的异步化或并行（后面详细讨论）</li>\n</ul>\n<p>这是年前设计出的一张图，现在来看依然是很满意的，唯一值得考虑的就是<strong>“微服务”</strong>概念，我一直比较赞同这个概念，尤其是在做SOA筹备的时候更是如此。上图中，数据应用服务是比较适合以<strong>微服务</strong>方式设计的，不过还需要结合dubbo更仔细的琢磨琢磨。</p>\n<p>接下来再来说一下关于上图中一些特殊的服务：计费，认证授权等。我提到了异步和并行，如图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EtyLEKAY/18Thz.png\" alt=\"\"></p>\n<p><strong>图解：</strong></p>\n<ul>\n<li>虚线表示异步调用，实线表示并行调用</li>\n<li>计费和余额查询分离，会产生一个不一致的时间窗口，这需要结合业务来衡量可行性</li>\n<li>余额查询，权限认证和获取数据并行调用，最终会在API层合并后给予最终裁决</li>\n<li>图中省略了SLB的相关部分</li>\n</ul>\n<p>最后，我们讨论一下系统中另外一种场景的通信：消息通知。稍微复杂一些的系统，都会对消息队列有强的需求。这是因为，系统之间的通信在排除了人类参与的情况下，并不需要非常之高的即时响应指标，相反，对消息的最终可达性要求确实100%的。这也是消息中间件的战场，各种各样的开源产品可供我们选择。</p>\n<p>我们跳出具体的消息中间件，从业务层面来梳理一下我们目前的平台中要如何设计这部分场景，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EtyXLyam/12Dm6j.png\" alt=\"\"></p>\n<p><strong>图解：</strong></p>\n<ul>\n<li>没什么要解释的啦</li>\n</ul>\n<hr>\n<p>目前为止，我们已经从整体上描述了一下要做的事情，不管你们看完后有啥感受，我自己是清晰了不少，哇哈哈。这一篇谈的有点虚，都是围绕着实际业务来谈概念的，应该就是所谓的概念架构设计了吧~~</p>\n<p>下一篇开始，就要深入到代码微观视角了，尽请期待！</p>"},{"title":"如何把项目SOA化系列之一：计划","date":"2015-02-25T07:54:30.000Z","_content":"\n\n过年回来了，也休息够了，去年年会上该吹的牛逼也都吹的很到位了，年假回来，是该着手兑现的时候了。废话不多说，走起！\n<!--more-->\n\n背景\n---\n\n公司的项目，在设计之初其实就一定程度的引入了服务的概念，当时的出发点更多的是因为：团队协同和项目进度分期，不过还有一个重要的原因，是因为要完成的目标有点太大太虚，很多细节不可能一次性全部想到位，所以就采用了把大系统拆成一个一个的小系统来完成，这样来做，系统之间自然就产生了通信的必要性。\n\n期初为了快速搭建原型和团队成员的技能分布，选择使用php作为开发语言。确实也在初期达到了快速开发的目的，拿到了一血后也踏上了小系统逐渐变大的不归路。系统和系统之间的通信使用的就是简单的http+cache，简单粗暴能运行，是当时的重要哲学。\n\n工期的紧张，人员流动，再加上员工心态和情绪的波动等原因，映射在项目上就会成为功能缺失，代码质量下降，依赖混乱，抽象不足等。除此之外，开发人员毫无节制的重复发明服务，使前面说到的问题进一步放大，一度成为毫无解决希望的技术债务。\n\n由于公司业务变更，团队大部分成员投入到了一个新项目的开发上，这给这个项目和我都留出了一个非常完美的空档期，在获得了领导的授权后，我调整状态，踏上了系统重构的大道，也就产生了该系列文章。\n\n其实早在13年后半年，项目组开会时就已经提到了关于服务化的设想，无奈当时并没有如今这样好的条件，也就不了了之。经历了14年的php转java，项目soa的条件逐渐成熟，是时候大展身手了。\n\n\n\n计划\n---\n\n依照前辈大神们的心得体会，需要在项目中首先确定一些有价值的业务进行SOA重构，什么叫有价值的？就是那些项目的核心模块么？\n\n其实不全对，为了保证开门红，建议从项目中选择一些复杂度相对较低，重要度适中的一些模块来下刀，避免造成骑虎难下的尴尬局面，而且也可以更快的积累经验和信心，当然，也不要选择太简单太无所谓的模块来搞，这样既无法积累经验，也不利于团队推广。\n\n那么我们该怎么选呢？我考虑了一下，决定以下面三个维度来作为选择的基准：\n\n- 重要度：■ ■ □ □ □\n- 复杂度：■ ■ □ □ □\n- 频度：■ ■ ■ □ □\n\n确定了这个标准后，我又进一步给自己安排了一个重构流程：\n\n1. 从需求书中寻找服务，并依照基准分类\n2. 梳理服务之间的关系，确定哪些是原子服务，哪些是复合服务\n3. 设计服务接口，以及协议类型（RPC？REST？）\n4. 代码实现\n\n\n\n技术选型\n---\n\n了解soa的童鞋，自然会问：你基于哪些技术来实现SOA？其实SOA的技术骨架也无非就是：服务发现，服务治理，数据通信等几大块，商业的解决方案中还会提供强大的服务总线，工作流等功能（这些仅代表我个人理解，不喜勿拍）。\n\n相信关注我博客的朋友肯定知道我要使用的框架是什么，没错，就是[dubbox](https://github.com/dangdangdotcom/dubbox)，其细节请参看我博客中的[相关文章](http://blog.kazaff.me/tags/dubbo/)。\n\n\n指标\n---\n\n我们引入dubbox的目标，不仅是改善系统间依赖的混乱局面，还要标准化一些开发流程，提升开发效率，提升系统的可用性，性能，可伸缩，扩展性，重用性等。\n\n下面我们具体来定一些指标，由于缺乏经验和相关数据，所以列出的指标会过于笼统，不过有生于无嘛。\n\n1. 标准化服务开发流程，从流程视角杜绝服务的重复，以及确保服务质量；\n2. 提高服务的可用性，确保每个服务都有冗余，并提供针对应用的监控工具；\n3. 提高服务响应时间，根据实际的复杂度来度量，尽可能保证服务响应时间在100ms--500ms之间（不启用缓存的情况下）；\n4. 提升代码的重用性，并尽可能降低代码的耦合度；\n5. 提升代码的质量，提供更完善的代码检测工具和流程。\n\n好了，日后根据工作的进行，再逐步细化指标，总之大的方向就这些。\n\n\n\n","source":"_posts/如何把项目soa化系列之一：计划.md","raw":"title: 如何把项目SOA化系列之一：计划\ndate: 2015-02-25 15:54:30\ntags:\n- soa\n- dubbo\n\ncategories: 架构\n---\n\n\n过年回来了，也休息够了，去年年会上该吹的牛逼也都吹的很到位了，年假回来，是该着手兑现的时候了。废话不多说，走起！\n<!--more-->\n\n背景\n---\n\n公司的项目，在设计之初其实就一定程度的引入了服务的概念，当时的出发点更多的是因为：团队协同和项目进度分期，不过还有一个重要的原因，是因为要完成的目标有点太大太虚，很多细节不可能一次性全部想到位，所以就采用了把大系统拆成一个一个的小系统来完成，这样来做，系统之间自然就产生了通信的必要性。\n\n期初为了快速搭建原型和团队成员的技能分布，选择使用php作为开发语言。确实也在初期达到了快速开发的目的，拿到了一血后也踏上了小系统逐渐变大的不归路。系统和系统之间的通信使用的就是简单的http+cache，简单粗暴能运行，是当时的重要哲学。\n\n工期的紧张，人员流动，再加上员工心态和情绪的波动等原因，映射在项目上就会成为功能缺失，代码质量下降，依赖混乱，抽象不足等。除此之外，开发人员毫无节制的重复发明服务，使前面说到的问题进一步放大，一度成为毫无解决希望的技术债务。\n\n由于公司业务变更，团队大部分成员投入到了一个新项目的开发上，这给这个项目和我都留出了一个非常完美的空档期，在获得了领导的授权后，我调整状态，踏上了系统重构的大道，也就产生了该系列文章。\n\n其实早在13年后半年，项目组开会时就已经提到了关于服务化的设想，无奈当时并没有如今这样好的条件，也就不了了之。经历了14年的php转java，项目soa的条件逐渐成熟，是时候大展身手了。\n\n\n\n计划\n---\n\n依照前辈大神们的心得体会，需要在项目中首先确定一些有价值的业务进行SOA重构，什么叫有价值的？就是那些项目的核心模块么？\n\n其实不全对，为了保证开门红，建议从项目中选择一些复杂度相对较低，重要度适中的一些模块来下刀，避免造成骑虎难下的尴尬局面，而且也可以更快的积累经验和信心，当然，也不要选择太简单太无所谓的模块来搞，这样既无法积累经验，也不利于团队推广。\n\n那么我们该怎么选呢？我考虑了一下，决定以下面三个维度来作为选择的基准：\n\n- 重要度：■ ■ □ □ □\n- 复杂度：■ ■ □ □ □\n- 频度：■ ■ ■ □ □\n\n确定了这个标准后，我又进一步给自己安排了一个重构流程：\n\n1. 从需求书中寻找服务，并依照基准分类\n2. 梳理服务之间的关系，确定哪些是原子服务，哪些是复合服务\n3. 设计服务接口，以及协议类型（RPC？REST？）\n4. 代码实现\n\n\n\n技术选型\n---\n\n了解soa的童鞋，自然会问：你基于哪些技术来实现SOA？其实SOA的技术骨架也无非就是：服务发现，服务治理，数据通信等几大块，商业的解决方案中还会提供强大的服务总线，工作流等功能（这些仅代表我个人理解，不喜勿拍）。\n\n相信关注我博客的朋友肯定知道我要使用的框架是什么，没错，就是[dubbox](https://github.com/dangdangdotcom/dubbox)，其细节请参看我博客中的[相关文章](http://blog.kazaff.me/tags/dubbo/)。\n\n\n指标\n---\n\n我们引入dubbox的目标，不仅是改善系统间依赖的混乱局面，还要标准化一些开发流程，提升开发效率，提升系统的可用性，性能，可伸缩，扩展性，重用性等。\n\n下面我们具体来定一些指标，由于缺乏经验和相关数据，所以列出的指标会过于笼统，不过有生于无嘛。\n\n1. 标准化服务开发流程，从流程视角杜绝服务的重复，以及确保服务质量；\n2. 提高服务的可用性，确保每个服务都有冗余，并提供针对应用的监控工具；\n3. 提高服务响应时间，根据实际的复杂度来度量，尽可能保证服务响应时间在100ms--500ms之间（不启用缓存的情况下）；\n4. 提升代码的重用性，并尽可能降低代码的耦合度；\n5. 提升代码的质量，提供更完善的代码检测工具和流程。\n\n好了，日后根据工作的进行，再逐步细化指标，总之大的方向就这些。\n\n\n\n","slug":"如何把项目soa化系列之一：计划","published":1,"updated":"2016-05-20T13:44:13.000Z","_id":"cica18ymf0044gtfywmn9ysss","comments":1,"layout":"post","photos":[],"link":"","content":"<p>过年回来了，也休息够了，去年年会上该吹的牛逼也都吹的很到位了，年假回来，是该着手兑现的时候了。废话不多说，走起！<br><a id=\"more\"></a></p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>公司的项目，在设计之初其实就一定程度的引入了服务的概念，当时的出发点更多的是因为：团队协同和项目进度分期，不过还有一个重要的原因，是因为要完成的目标有点太大太虚，很多细节不可能一次性全部想到位，所以就采用了把大系统拆成一个一个的小系统来完成，这样来做，系统之间自然就产生了通信的必要性。</p>\n<p>期初为了快速搭建原型和团队成员的技能分布，选择使用php作为开发语言。确实也在初期达到了快速开发的目的，拿到了一血后也踏上了小系统逐渐变大的不归路。系统和系统之间的通信使用的就是简单的http+cache，简单粗暴能运行，是当时的重要哲学。</p>\n<p>工期的紧张，人员流动，再加上员工心态和情绪的波动等原因，映射在项目上就会成为功能缺失，代码质量下降，依赖混乱，抽象不足等。除此之外，开发人员毫无节制的重复发明服务，使前面说到的问题进一步放大，一度成为毫无解决希望的技术债务。</p>\n<p>由于公司业务变更，团队大部分成员投入到了一个新项目的开发上，这给这个项目和我都留出了一个非常完美的空档期，在获得了领导的授权后，我调整状态，踏上了系统重构的大道，也就产生了该系列文章。</p>\n<p>其实早在13年后半年，项目组开会时就已经提到了关于服务化的设想，无奈当时并没有如今这样好的条件，也就不了了之。经历了14年的php转java，项目soa的条件逐渐成熟，是时候大展身手了。</p>\n<h2 id=\"计划\"><a href=\"#计划\" class=\"headerlink\" title=\"计划\"></a>计划</h2><p>依照前辈大神们的心得体会，需要在项目中首先确定一些有价值的业务进行SOA重构，什么叫有价值的？就是那些项目的核心模块么？</p>\n<p>其实不全对，为了保证开门红，建议从项目中选择一些复杂度相对较低，重要度适中的一些模块来下刀，避免造成骑虎难下的尴尬局面，而且也可以更快的积累经验和信心，当然，也不要选择太简单太无所谓的模块来搞，这样既无法积累经验，也不利于团队推广。</p>\n<p>那么我们该怎么选呢？我考虑了一下，决定以下面三个维度来作为选择的基准：</p>\n<ul>\n<li>重要度：■ ■ □ □ □</li>\n<li>复杂度：■ ■ □ □ □</li>\n<li>频度：■ ■ ■ □ □</li>\n</ul>\n<p>确定了这个标准后，我又进一步给自己安排了一个重构流程：</p>\n<ol>\n<li>从需求书中寻找服务，并依照基准分类</li>\n<li>梳理服务之间的关系，确定哪些是原子服务，哪些是复合服务</li>\n<li>设计服务接口，以及协议类型（RPC？REST？）</li>\n<li>代码实现</li>\n</ol>\n<h2 id=\"技术选型\"><a href=\"#技术选型\" class=\"headerlink\" title=\"技术选型\"></a>技术选型</h2><p>了解soa的童鞋，自然会问：你基于哪些技术来实现SOA？其实SOA的技术骨架也无非就是：服务发现，服务治理，数据通信等几大块，商业的解决方案中还会提供强大的服务总线，工作流等功能（这些仅代表我个人理解，不喜勿拍）。</p>\n<p>相信关注我博客的朋友肯定知道我要使用的框架是什么，没错，就是<a href=\"https://github.com/dangdangdotcom/dubbox\" target=\"_blank\" rel=\"external\">dubbox</a>，其细节请参看我博客中的<a href=\"http://blog.kazaff.me/tags/dubbo/\">相关文章</a>。</p>\n<h2 id=\"指标\"><a href=\"#指标\" class=\"headerlink\" title=\"指标\"></a>指标</h2><p>我们引入dubbox的目标，不仅是改善系统间依赖的混乱局面，还要标准化一些开发流程，提升开发效率，提升系统的可用性，性能，可伸缩，扩展性，重用性等。</p>\n<p>下面我们具体来定一些指标，由于缺乏经验和相关数据，所以列出的指标会过于笼统，不过有生于无嘛。</p>\n<ol>\n<li>标准化服务开发流程，从流程视角杜绝服务的重复，以及确保服务质量；</li>\n<li>提高服务的可用性，确保每个服务都有冗余，并提供针对应用的监控工具；</li>\n<li>提高服务响应时间，根据实际的复杂度来度量，尽可能保证服务响应时间在100ms–500ms之间（不启用缓存的情况下）；</li>\n<li>提升代码的重用性，并尽可能降低代码的耦合度；</li>\n<li>提升代码的质量，提供更完善的代码检测工具和流程。</li>\n</ol>\n<p>好了，日后根据工作的进行，再逐步细化指标，总之大的方向就这些。</p>\n","excerpt":"<p>过年回来了，也休息够了，去年年会上该吹的牛逼也都吹的很到位了，年假回来，是该着手兑现的时候了。废话不多说，走起！<br>","more":"</p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>公司的项目，在设计之初其实就一定程度的引入了服务的概念，当时的出发点更多的是因为：团队协同和项目进度分期，不过还有一个重要的原因，是因为要完成的目标有点太大太虚，很多细节不可能一次性全部想到位，所以就采用了把大系统拆成一个一个的小系统来完成，这样来做，系统之间自然就产生了通信的必要性。</p>\n<p>期初为了快速搭建原型和团队成员的技能分布，选择使用php作为开发语言。确实也在初期达到了快速开发的目的，拿到了一血后也踏上了小系统逐渐变大的不归路。系统和系统之间的通信使用的就是简单的http+cache，简单粗暴能运行，是当时的重要哲学。</p>\n<p>工期的紧张，人员流动，再加上员工心态和情绪的波动等原因，映射在项目上就会成为功能缺失，代码质量下降，依赖混乱，抽象不足等。除此之外，开发人员毫无节制的重复发明服务，使前面说到的问题进一步放大，一度成为毫无解决希望的技术债务。</p>\n<p>由于公司业务变更，团队大部分成员投入到了一个新项目的开发上，这给这个项目和我都留出了一个非常完美的空档期，在获得了领导的授权后，我调整状态，踏上了系统重构的大道，也就产生了该系列文章。</p>\n<p>其实早在13年后半年，项目组开会时就已经提到了关于服务化的设想，无奈当时并没有如今这样好的条件，也就不了了之。经历了14年的php转java，项目soa的条件逐渐成熟，是时候大展身手了。</p>\n<h2 id=\"计划\"><a href=\"#计划\" class=\"headerlink\" title=\"计划\"></a>计划</h2><p>依照前辈大神们的心得体会，需要在项目中首先确定一些有价值的业务进行SOA重构，什么叫有价值的？就是那些项目的核心模块么？</p>\n<p>其实不全对，为了保证开门红，建议从项目中选择一些复杂度相对较低，重要度适中的一些模块来下刀，避免造成骑虎难下的尴尬局面，而且也可以更快的积累经验和信心，当然，也不要选择太简单太无所谓的模块来搞，这样既无法积累经验，也不利于团队推广。</p>\n<p>那么我们该怎么选呢？我考虑了一下，决定以下面三个维度来作为选择的基准：</p>\n<ul>\n<li>重要度：■ ■ □ □ □</li>\n<li>复杂度：■ ■ □ □ □</li>\n<li>频度：■ ■ ■ □ □</li>\n</ul>\n<p>确定了这个标准后，我又进一步给自己安排了一个重构流程：</p>\n<ol>\n<li>从需求书中寻找服务，并依照基准分类</li>\n<li>梳理服务之间的关系，确定哪些是原子服务，哪些是复合服务</li>\n<li>设计服务接口，以及协议类型（RPC？REST？）</li>\n<li>代码实现</li>\n</ol>\n<h2 id=\"技术选型\"><a href=\"#技术选型\" class=\"headerlink\" title=\"技术选型\"></a>技术选型</h2><p>了解soa的童鞋，自然会问：你基于哪些技术来实现SOA？其实SOA的技术骨架也无非就是：服务发现，服务治理，数据通信等几大块，商业的解决方案中还会提供强大的服务总线，工作流等功能（这些仅代表我个人理解，不喜勿拍）。</p>\n<p>相信关注我博客的朋友肯定知道我要使用的框架是什么，没错，就是<a href=\"https://github.com/dangdangdotcom/dubbox\">dubbox</a>，其细节请参看我博客中的<a href=\"http://blog.kazaff.me/tags/dubbo/\">相关文章</a>。</p>\n<h2 id=\"指标\"><a href=\"#指标\" class=\"headerlink\" title=\"指标\"></a>指标</h2><p>我们引入dubbox的目标，不仅是改善系统间依赖的混乱局面，还要标准化一些开发流程，提升开发效率，提升系统的可用性，性能，可伸缩，扩展性，重用性等。</p>\n<p>下面我们具体来定一些指标，由于缺乏经验和相关数据，所以列出的指标会过于笼统，不过有生于无嘛。</p>\n<ol>\n<li>标准化服务开发流程，从流程视角杜绝服务的重复，以及确保服务质量；</li>\n<li>提高服务的可用性，确保每个服务都有冗余，并提供针对应用的监控工具；</li>\n<li>提高服务响应时间，根据实际的复杂度来度量，尽可能保证服务响应时间在100ms–500ms之间（不启用缓存的情况下）；</li>\n<li>提升代码的重用性，并尽可能降低代码的耦合度；</li>\n<li>提升代码的质量，提供更完善的代码检测工具和流程。</li>\n</ol>\n<p>好了，日后根据工作的进行，再逐步细化指标，总之大的方向就这些。</p>"},{"title":"如何把java项目打包为可执行的jar","date":"2014-12-15T01:37:12.000Z","_content":"\n这几天用java写了一个后台服务，就是把office文件转换成pdf。实现挺简单的，直接调用openoffice服务即可，大致做法网上有很多教程，这里就不多扯了，今天主要是说一下项目打包的事儿。\n<!--more-->\n\n用Idea打包\n---\n\n前段时间是直接用IDE提供的支持把java Web项目打包成war。一切都是那么的顺利，可现在想要的是直接把项目打包成jar，而且需要的是直接在终端中输入`java -jar xxxx.jar`即可运行！\n\n一开始也打算尝试使用IDE提供的打包方式，可总是失败，jar是生成了，不过运行时总提示类缺失，明明已经把所有依赖的第三方jar包都copy了一份，可死活就是找不到，十分怀疑是`MANIFEST.MF`文件的配置问题。\n\n总之使用了几种网上找的方式都出现各种问题，所以暂时放弃了Idea打包jar的想法，有经验的童鞋可以来[这里](http://segmentfault.com/q/1010000002429996)捧场，一经测试，立马送分哟~。\n\n\n用Maven打包\n---\n\n要说吧，这算是大家最认可的方式，不过maven打包也有好多种插件，这让我这种新手很是头疼。\n\n**方案一：**\n\n\t<plugin>\n        <artifactId>maven-assembly-plugin</artifactId>\n        <version>2.2</version>\n        <configuration>\n            <archive>\n                <manifest>\n                    <mainClass>me.kazaff.Main</mainClass>\n                </manifest>\n            </archive>\n            <descriptorRefs>\n                <descriptorRef>jar-with-dependencies</descriptorRef>\n            </descriptorRefs>\n        </configuration>\n        <executions>\n            <execution>\n                <id>make-assembly</id>\n                <phase>package</phase>\n                <goals>\n                    <goal>single</goal>\n                </goals>\n            </execution>\n        </executions>\n    </plugin>\n\n这会将所有依赖的包解压后重新和自己的项目包合并打入jar包中，至于这么做的优劣可以留给你自己去体会，这么做的理由我猜应该和jar包查找classpatch有关系吧，否则为什么要这么奇葩呢？\n\n**方案二：**\n\n\t<plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-jar-plugin</artifactId>\n        <configuration>\n            <archive>\n                <manifest>\n                    <addClasspath>true</addClasspath>\n                    <classpathPrefix>lib/</classpathPrefix>\n                    <mainClass>me.kazaff.Main</mainClass>\n                </manifest>\n            </archive>\n        </configuration>\n    </plugin>\n    <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-dependency-plugin</artifactId>\n        <executions>\n            <execution>\n                <id>copy</id>\n                <phase>package</phase>\n                <goals>\n                    <goal>copy-dependencies</goal>\n                </goals>\n                <configuration>\n                    <outputDirectory>./target/lib</outputDirectory>\n                </configuration>\n            </execution>\n        </executions>\n    </plugin>\n\n这种方式相对方案一，似乎好了那么一些，它会把你的项目打成一个独立的jar包，并在jar包所在的目录中建立一个lib文件夹，并把所有三方依赖jar包拷贝进去，这还不算完，生成的那个jar包中的`MANIFEST.MF`会配置好`Class-Path`属性。\n\n需要注意的是，如果你想直接在终端中运行该jar包，必须保证终端进入到项目jar包所在的目录下，否则相对路径会导致依赖的三方jar包找不到哟~~\n\n好吧，如果你像我一样记性不好，又需要将打包的jar文件拷贝到其他机器上部署的话，很容易忘记lib文件夹！这里有一个进阶的打包方法：[传送门](http://www.xeclipse.com/?p=1470)。\n\n\n**方案三：**\n\n那有没有一种方法，可以让我们把项目真正的打包成单一可执行的jar包呢？而且这个jar包中的结构不会像方案一那样混乱，而是把所有第三方依赖包以jar包的方式存储。这难道成了奢望么？\n\n油腻的湿姐并非我一个人在寻找：[队友](http://www.gznote.com/2014/07/maven%E4%B8%ADmaven-assembly-plugin%E7%9A%84%E4%BD%BF%E7%94%A8.html)。不过，按照他的最后一个办法打包出来的jar是无法直接执行的，因为其中`MANIFEST.MF`缺少`Main-Class`和`Class-Path`属性，他的这种方式如果是打包成一个非执行jar包的话应该还是不错的。\n\n所以，如你所见，方案三并不存在，至少我不知道应该怎么做！有办法的朋友可以在文章下面留言，不胜感激！\n\n\n\njava读取jar包中的资源文件\n---\n\n打包后发现原先在代码中直接通过路径读取的配置文件再也找不到了，可是打开jar包明明看得到啊！\n\n查了一下资料，才知道到底发生了什么，看这里：[传送门](http://ppjava.com/?p=1205)，[传送门2](http://www.iteye.com/topic/483115)。\n\n","source":"_posts/如何把java项目打包为可执行的jar.md","raw":"title: 如何把java项目打包为可执行的jar\ndate: 2014-12-15 09:37:12\ntags: \n- 打包\n- jar\n- idea\n- maven\n- MANIFEST.MF\n- 资源\ncategories: j2ee\n---\n\n这几天用java写了一个后台服务，就是把office文件转换成pdf。实现挺简单的，直接调用openoffice服务即可，大致做法网上有很多教程，这里就不多扯了，今天主要是说一下项目打包的事儿。\n<!--more-->\n\n用Idea打包\n---\n\n前段时间是直接用IDE提供的支持把java Web项目打包成war。一切都是那么的顺利，可现在想要的是直接把项目打包成jar，而且需要的是直接在终端中输入`java -jar xxxx.jar`即可运行！\n\n一开始也打算尝试使用IDE提供的打包方式，可总是失败，jar是生成了，不过运行时总提示类缺失，明明已经把所有依赖的第三方jar包都copy了一份，可死活就是找不到，十分怀疑是`MANIFEST.MF`文件的配置问题。\n\n总之使用了几种网上找的方式都出现各种问题，所以暂时放弃了Idea打包jar的想法，有经验的童鞋可以来[这里](http://segmentfault.com/q/1010000002429996)捧场，一经测试，立马送分哟~。\n\n\n用Maven打包\n---\n\n要说吧，这算是大家最认可的方式，不过maven打包也有好多种插件，这让我这种新手很是头疼。\n\n**方案一：**\n\n\t<plugin>\n        <artifactId>maven-assembly-plugin</artifactId>\n        <version>2.2</version>\n        <configuration>\n            <archive>\n                <manifest>\n                    <mainClass>me.kazaff.Main</mainClass>\n                </manifest>\n            </archive>\n            <descriptorRefs>\n                <descriptorRef>jar-with-dependencies</descriptorRef>\n            </descriptorRefs>\n        </configuration>\n        <executions>\n            <execution>\n                <id>make-assembly</id>\n                <phase>package</phase>\n                <goals>\n                    <goal>single</goal>\n                </goals>\n            </execution>\n        </executions>\n    </plugin>\n\n这会将所有依赖的包解压后重新和自己的项目包合并打入jar包中，至于这么做的优劣可以留给你自己去体会，这么做的理由我猜应该和jar包查找classpatch有关系吧，否则为什么要这么奇葩呢？\n\n**方案二：**\n\n\t<plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-jar-plugin</artifactId>\n        <configuration>\n            <archive>\n                <manifest>\n                    <addClasspath>true</addClasspath>\n                    <classpathPrefix>lib/</classpathPrefix>\n                    <mainClass>me.kazaff.Main</mainClass>\n                </manifest>\n            </archive>\n        </configuration>\n    </plugin>\n    <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-dependency-plugin</artifactId>\n        <executions>\n            <execution>\n                <id>copy</id>\n                <phase>package</phase>\n                <goals>\n                    <goal>copy-dependencies</goal>\n                </goals>\n                <configuration>\n                    <outputDirectory>./target/lib</outputDirectory>\n                </configuration>\n            </execution>\n        </executions>\n    </plugin>\n\n这种方式相对方案一，似乎好了那么一些，它会把你的项目打成一个独立的jar包，并在jar包所在的目录中建立一个lib文件夹，并把所有三方依赖jar包拷贝进去，这还不算完，生成的那个jar包中的`MANIFEST.MF`会配置好`Class-Path`属性。\n\n需要注意的是，如果你想直接在终端中运行该jar包，必须保证终端进入到项目jar包所在的目录下，否则相对路径会导致依赖的三方jar包找不到哟~~\n\n好吧，如果你像我一样记性不好，又需要将打包的jar文件拷贝到其他机器上部署的话，很容易忘记lib文件夹！这里有一个进阶的打包方法：[传送门](http://www.xeclipse.com/?p=1470)。\n\n\n**方案三：**\n\n那有没有一种方法，可以让我们把项目真正的打包成单一可执行的jar包呢？而且这个jar包中的结构不会像方案一那样混乱，而是把所有第三方依赖包以jar包的方式存储。这难道成了奢望么？\n\n油腻的湿姐并非我一个人在寻找：[队友](http://www.gznote.com/2014/07/maven%E4%B8%ADmaven-assembly-plugin%E7%9A%84%E4%BD%BF%E7%94%A8.html)。不过，按照他的最后一个办法打包出来的jar是无法直接执行的，因为其中`MANIFEST.MF`缺少`Main-Class`和`Class-Path`属性，他的这种方式如果是打包成一个非执行jar包的话应该还是不错的。\n\n所以，如你所见，方案三并不存在，至少我不知道应该怎么做！有办法的朋友可以在文章下面留言，不胜感激！\n\n\n\njava读取jar包中的资源文件\n---\n\n打包后发现原先在代码中直接通过路径读取的配置文件再也找不到了，可是打开jar包明明看得到啊！\n\n查了一下资料，才知道到底发生了什么，看这里：[传送门](http://ppjava.com/?p=1205)，[传送门2](http://www.iteye.com/topic/483115)。\n\n","slug":"如何把java项目打包为可执行的jar","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ymh0048gtfy6ik151aa","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这几天用java写了一个后台服务，就是把office文件转换成pdf。实现挺简单的，直接调用openoffice服务即可，大致做法网上有很多教程，这里就不多扯了，今天主要是说一下项目打包的事儿。<br><a id=\"more\"></a></p>\n<h2 id=\"用Idea打包\"><a href=\"#用Idea打包\" class=\"headerlink\" title=\"用Idea打包\"></a>用Idea打包</h2><p>前段时间是直接用IDE提供的支持把java Web项目打包成war。一切都是那么的顺利，可现在想要的是直接把项目打包成jar，而且需要的是直接在终端中输入<code>java -jar xxxx.jar</code>即可运行！</p>\n<p>一开始也打算尝试使用IDE提供的打包方式，可总是失败，jar是生成了，不过运行时总提示类缺失，明明已经把所有依赖的第三方jar包都copy了一份，可死活就是找不到，十分怀疑是<code>MANIFEST.MF</code>文件的配置问题。</p>\n<p>总之使用了几种网上找的方式都出现各种问题，所以暂时放弃了Idea打包jar的想法，有经验的童鞋可以来<a href=\"http://segmentfault.com/q/1010000002429996\" target=\"_blank\" rel=\"external\">这里</a>捧场，一经测试，立马送分哟~。</p>\n<h2 id=\"用Maven打包\"><a href=\"#用Maven打包\" class=\"headerlink\" title=\"用Maven打包\"></a>用Maven打包</h2><p>要说吧，这算是大家最认可的方式，不过maven打包也有好多种插件，这让我这种新手很是头疼。</p>\n<p><strong>方案一：</strong></p>\n<pre><code>&lt;plugin&gt;\n    &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n    &lt;version&gt;2.2&lt;/version&gt;\n    &lt;configuration&gt;\n        &lt;archive&gt;\n            &lt;manifest&gt;\n                &lt;mainClass&gt;me.kazaff.Main&lt;/mainClass&gt;\n            &lt;/manifest&gt;\n        &lt;/archive&gt;\n        &lt;descriptorRefs&gt;\n            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;\n        &lt;/descriptorRefs&gt;\n    &lt;/configuration&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;id&gt;make-assembly&lt;/id&gt;\n            &lt;phase&gt;package&lt;/phase&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;single&lt;/goal&gt;\n            &lt;/goals&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p>这会将所有依赖的包解压后重新和自己的项目包合并打入jar包中，至于这么做的优劣可以留给你自己去体会，这么做的理由我猜应该和jar包查找classpatch有关系吧，否则为什么要这么奇葩呢？</p>\n<p><strong>方案二：</strong></p>\n<pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n    &lt;configuration&gt;\n        &lt;archive&gt;\n            &lt;manifest&gt;\n                &lt;addClasspath&gt;true&lt;/addClasspath&gt;\n                &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;\n                &lt;mainClass&gt;me.kazaff.Main&lt;/mainClass&gt;\n            &lt;/manifest&gt;\n        &lt;/archive&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;id&gt;copy&lt;/id&gt;\n            &lt;phase&gt;package&lt;/phase&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;copy-dependencies&lt;/goal&gt;\n            &lt;/goals&gt;\n            &lt;configuration&gt;\n                &lt;outputDirectory&gt;./target/lib&lt;/outputDirectory&gt;\n            &lt;/configuration&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p>这种方式相对方案一，似乎好了那么一些，它会把你的项目打成一个独立的jar包，并在jar包所在的目录中建立一个lib文件夹，并把所有三方依赖jar包拷贝进去，这还不算完，生成的那个jar包中的<code>MANIFEST.MF</code>会配置好<code>Class-Path</code>属性。</p>\n<p>需要注意的是，如果你想直接在终端中运行该jar包，必须保证终端进入到项目jar包所在的目录下，否则相对路径会导致依赖的三方jar包找不到哟~~</p>\n<p>好吧，如果你像我一样记性不好，又需要将打包的jar文件拷贝到其他机器上部署的话，很容易忘记lib文件夹！这里有一个进阶的打包方法：<a href=\"http://www.xeclipse.com/?p=1470\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<p><strong>方案三：</strong></p>\n<p>那有没有一种方法，可以让我们把项目真正的打包成单一可执行的jar包呢？而且这个jar包中的结构不会像方案一那样混乱，而是把所有第三方依赖包以jar包的方式存储。这难道成了奢望么？</p>\n<p>油腻的湿姐并非我一个人在寻找：<a href=\"http://www.gznote.com/2014/07/maven%E4%B8%ADmaven-assembly-plugin%E7%9A%84%E4%BD%BF%E7%94%A8.html\" target=\"_blank\" rel=\"external\">队友</a>。不过，按照他的最后一个办法打包出来的jar是无法直接执行的，因为其中<code>MANIFEST.MF</code>缺少<code>Main-Class</code>和<code>Class-Path</code>属性，他的这种方式如果是打包成一个非执行jar包的话应该还是不错的。</p>\n<p>所以，如你所见，方案三并不存在，至少我不知道应该怎么做！有办法的朋友可以在文章下面留言，不胜感激！</p>\n<h2 id=\"java读取jar包中的资源文件\"><a href=\"#java读取jar包中的资源文件\" class=\"headerlink\" title=\"java读取jar包中的资源文件\"></a>java读取jar包中的资源文件</h2><p>打包后发现原先在代码中直接通过路径读取的配置文件再也找不到了，可是打开jar包明明看得到啊！</p>\n<p>查了一下资料，才知道到底发生了什么，看这里：<a href=\"http://ppjava.com/?p=1205\" target=\"_blank\" rel=\"external\">传送门</a>，<a href=\"http://www.iteye.com/topic/483115\" target=\"_blank\" rel=\"external\">传送门2</a>。</p>\n","excerpt":"<p>这几天用java写了一个后台服务，就是把office文件转换成pdf。实现挺简单的，直接调用openoffice服务即可，大致做法网上有很多教程，这里就不多扯了，今天主要是说一下项目打包的事儿。<br>","more":"</p>\n<h2 id=\"用Idea打包\"><a href=\"#用Idea打包\" class=\"headerlink\" title=\"用Idea打包\"></a>用Idea打包</h2><p>前段时间是直接用IDE提供的支持把java Web项目打包成war。一切都是那么的顺利，可现在想要的是直接把项目打包成jar，而且需要的是直接在终端中输入<code>java -jar xxxx.jar</code>即可运行！</p>\n<p>一开始也打算尝试使用IDE提供的打包方式，可总是失败，jar是生成了，不过运行时总提示类缺失，明明已经把所有依赖的第三方jar包都copy了一份，可死活就是找不到，十分怀疑是<code>MANIFEST.MF</code>文件的配置问题。</p>\n<p>总之使用了几种网上找的方式都出现各种问题，所以暂时放弃了Idea打包jar的想法，有经验的童鞋可以来<a href=\"http://segmentfault.com/q/1010000002429996\">这里</a>捧场，一经测试，立马送分哟~。</p>\n<h2 id=\"用Maven打包\"><a href=\"#用Maven打包\" class=\"headerlink\" title=\"用Maven打包\"></a>用Maven打包</h2><p>要说吧，这算是大家最认可的方式，不过maven打包也有好多种插件，这让我这种新手很是头疼。</p>\n<p><strong>方案一：</strong></p>\n<pre><code>&lt;plugin&gt;\n    &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n    &lt;version&gt;2.2&lt;/version&gt;\n    &lt;configuration&gt;\n        &lt;archive&gt;\n            &lt;manifest&gt;\n                &lt;mainClass&gt;me.kazaff.Main&lt;/mainClass&gt;\n            &lt;/manifest&gt;\n        &lt;/archive&gt;\n        &lt;descriptorRefs&gt;\n            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;\n        &lt;/descriptorRefs&gt;\n    &lt;/configuration&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;id&gt;make-assembly&lt;/id&gt;\n            &lt;phase&gt;package&lt;/phase&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;single&lt;/goal&gt;\n            &lt;/goals&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p>这会将所有依赖的包解压后重新和自己的项目包合并打入jar包中，至于这么做的优劣可以留给你自己去体会，这么做的理由我猜应该和jar包查找classpatch有关系吧，否则为什么要这么奇葩呢？</p>\n<p><strong>方案二：</strong></p>\n<pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n    &lt;configuration&gt;\n        &lt;archive&gt;\n            &lt;manifest&gt;\n                &lt;addClasspath&gt;true&lt;/addClasspath&gt;\n                &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;\n                &lt;mainClass&gt;me.kazaff.Main&lt;/mainClass&gt;\n            &lt;/manifest&gt;\n        &lt;/archive&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;id&gt;copy&lt;/id&gt;\n            &lt;phase&gt;package&lt;/phase&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;copy-dependencies&lt;/goal&gt;\n            &lt;/goals&gt;\n            &lt;configuration&gt;\n                &lt;outputDirectory&gt;./target/lib&lt;/outputDirectory&gt;\n            &lt;/configuration&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p>这种方式相对方案一，似乎好了那么一些，它会把你的项目打成一个独立的jar包，并在jar包所在的目录中建立一个lib文件夹，并把所有三方依赖jar包拷贝进去，这还不算完，生成的那个jar包中的<code>MANIFEST.MF</code>会配置好<code>Class-Path</code>属性。</p>\n<p>需要注意的是，如果你想直接在终端中运行该jar包，必须保证终端进入到项目jar包所在的目录下，否则相对路径会导致依赖的三方jar包找不到哟~~</p>\n<p>好吧，如果你像我一样记性不好，又需要将打包的jar文件拷贝到其他机器上部署的话，很容易忘记lib文件夹！这里有一个进阶的打包方法：<a href=\"http://www.xeclipse.com/?p=1470\">传送门</a>。</p>\n<p><strong>方案三：</strong></p>\n<p>那有没有一种方法，可以让我们把项目真正的打包成单一可执行的jar包呢？而且这个jar包中的结构不会像方案一那样混乱，而是把所有第三方依赖包以jar包的方式存储。这难道成了奢望么？</p>\n<p>油腻的湿姐并非我一个人在寻找：<a href=\"http://www.gznote.com/2014/07/maven%E4%B8%ADmaven-assembly-plugin%E7%9A%84%E4%BD%BF%E7%94%A8.html\">队友</a>。不过，按照他的最后一个办法打包出来的jar是无法直接执行的，因为其中<code>MANIFEST.MF</code>缺少<code>Main-Class</code>和<code>Class-Path</code>属性，他的这种方式如果是打包成一个非执行jar包的话应该还是不错的。</p>\n<p>所以，如你所见，方案三并不存在，至少我不知道应该怎么做！有办法的朋友可以在文章下面留言，不胜感激！</p>\n<h2 id=\"java读取jar包中的资源文件\"><a href=\"#java读取jar包中的资源文件\" class=\"headerlink\" title=\"java读取jar包中的资源文件\"></a>java读取jar包中的资源文件</h2><p>打包后发现原先在代码中直接通过路径读取的配置文件再也找不到了，可是打开jar包明明看得到啊！</p>\n<p>查了一下资料，才知道到底发生了什么，看这里：<a href=\"http://ppjava.com/?p=1205\">传送门</a>，<a href=\"http://www.iteye.com/topic/483115\">传送门2</a>。</p>"},{"title":"基于dubbo的文件上传","date":"2015-03-18T07:54:30.000Z","_content":"\n之前写过基于[WebUploader+Java/Php/Nodejs](http://blog.kazaff.me/2014/11/14/%E8%81%8A%E8%81%8A%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/)的文章，今天来结合dubbo聊一下文件上传的问题。\n<!-- more -->\n目前我们的项目中，文件上传功能是以独立服务的方式部署的，也就是说多个不同的应用可以向同一个文件上传API发起请求（可能需要跨域支持）。我个人是比较喜欢这样的部署方式，不过任何事都是有利弊的，这里就不展开讨论了。\n\n复习完上面的内容后，我们开始今天的主题，那就是基于dubbo来完成文件上传服务的开发，这么做的动机也很单纯，就是**尽可能保持统一的设计哲学和实现方案**。统一的好处，从运维、监控等多方面也是非常有必要的，**任何自动化的前提是足够的规范**。\n\n要想做到把之前写的java版本的文件上传功能集成到dubbo中，我们就得先了解一下dubbo的[协议细节](http://alibaba.github.io/dubbo-doc-static/Protocol+Reference-zh.htm)。不难发现，凡是以单一长连接提供通信的协议都不太适合大数据的传输，原因很简单，凡是单个客户端会长期占用通道传输的场景都会造成通道阻塞，你可以脑补高架上堵车的景象。\n\n而我们这里提供文件上传服务要使用的协议是REST，也就是dubbox新增的一个方式，具体细节可以看[这里](http://blog.kazaff.me/2015/03/12/dubbox%E6%96%B0%E5%A2%9E%E7%9A%84REST%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/)和[这里](http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point)。其实和上面文档描述的`http://`协议很相似。\n\n之前的请求流程如下图：\n\n\tclient ---> tomcat ---> servlet ---> spring ---> springMVC ---> business code\n\ndubbo化后的如下图：\n\n\tclient ---> tmocat embed ---> servlet ---> dubbo/spring ---> resteasy ---> business code\n\n不确定这么描述是否合适，但大致就是这样了，其中`springMVC`和`resteasy`做的事儿是一样的。我之所以犹豫，是因为不确定`dubbo`放在哪合适~~完成我们的预期需求，我们可以按照以下几步来走：\n\n1. 编写Filter实现跨域请求（因为我们的前端全部都是Ajax调用）；\n2. 配置以REST协议暴露dubbo服务；\n3. 使用RESTEasy及JAX-RS规范提供的注解完成把请求参数映射成Bean；\n4. 实现文件上传的业务逻辑（其实就是把原先的springMVC版的相关代码移植到RESTEasy对应位置）\n5. 测试\n\n\n剩下的任务就是实操了，我会更新[原先的github项目](https://github.com/kazaff/webuploaderDemo)，有兴趣的盆宇可以去关注一下。\n\n\n","source":"_posts/基于dubbo的文件上传.md","raw":"title: 基于dubbo的文件上传\ndate: 2015-03-18 15:54:30\ntags:\n- webuploader\n- dubbox\n- dubbo\n- RESTEasy\n- 跨域\n- JAX-RS\n\ncategories: j2ee\n---\n\n之前写过基于[WebUploader+Java/Php/Nodejs](http://blog.kazaff.me/2014/11/14/%E8%81%8A%E8%81%8A%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/)的文章，今天来结合dubbo聊一下文件上传的问题。\n<!-- more -->\n目前我们的项目中，文件上传功能是以独立服务的方式部署的，也就是说多个不同的应用可以向同一个文件上传API发起请求（可能需要跨域支持）。我个人是比较喜欢这样的部署方式，不过任何事都是有利弊的，这里就不展开讨论了。\n\n复习完上面的内容后，我们开始今天的主题，那就是基于dubbo来完成文件上传服务的开发，这么做的动机也很单纯，就是**尽可能保持统一的设计哲学和实现方案**。统一的好处，从运维、监控等多方面也是非常有必要的，**任何自动化的前提是足够的规范**。\n\n要想做到把之前写的java版本的文件上传功能集成到dubbo中，我们就得先了解一下dubbo的[协议细节](http://alibaba.github.io/dubbo-doc-static/Protocol+Reference-zh.htm)。不难发现，凡是以单一长连接提供通信的协议都不太适合大数据的传输，原因很简单，凡是单个客户端会长期占用通道传输的场景都会造成通道阻塞，你可以脑补高架上堵车的景象。\n\n而我们这里提供文件上传服务要使用的协议是REST，也就是dubbox新增的一个方式，具体细节可以看[这里](http://blog.kazaff.me/2015/03/12/dubbox%E6%96%B0%E5%A2%9E%E7%9A%84REST%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/)和[这里](http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point)。其实和上面文档描述的`http://`协议很相似。\n\n之前的请求流程如下图：\n\n\tclient ---> tomcat ---> servlet ---> spring ---> springMVC ---> business code\n\ndubbo化后的如下图：\n\n\tclient ---> tmocat embed ---> servlet ---> dubbo/spring ---> resteasy ---> business code\n\n不确定这么描述是否合适，但大致就是这样了，其中`springMVC`和`resteasy`做的事儿是一样的。我之所以犹豫，是因为不确定`dubbo`放在哪合适~~完成我们的预期需求，我们可以按照以下几步来走：\n\n1. 编写Filter实现跨域请求（因为我们的前端全部都是Ajax调用）；\n2. 配置以REST协议暴露dubbo服务；\n3. 使用RESTEasy及JAX-RS规范提供的注解完成把请求参数映射成Bean；\n4. 实现文件上传的业务逻辑（其实就是把原先的springMVC版的相关代码移植到RESTEasy对应位置）\n5. 测试\n\n\n剩下的任务就是实操了，我会更新[原先的github项目](https://github.com/kazaff/webuploaderDemo)，有兴趣的盆宇可以去关注一下。\n\n\n","slug":"基于dubbo的文件上传","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ymo004mgtfyywrwwshg","comments":1,"layout":"post","photos":[],"link":"","content":"<p>之前写过基于<a href=\"http://blog.kazaff.me/2014/11/14/%E8%81%8A%E8%81%8A%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/\">WebUploader+Java/Php/Nodejs</a>的文章，今天来结合dubbo聊一下文件上传的问题。<br><a id=\"more\"></a><br>目前我们的项目中，文件上传功能是以独立服务的方式部署的，也就是说多个不同的应用可以向同一个文件上传API发起请求（可能需要跨域支持）。我个人是比较喜欢这样的部署方式，不过任何事都是有利弊的，这里就不展开讨论了。</p>\n<p>复习完上面的内容后，我们开始今天的主题，那就是基于dubbo来完成文件上传服务的开发，这么做的动机也很单纯，就是<strong>尽可能保持统一的设计哲学和实现方案</strong>。统一的好处，从运维、监控等多方面也是非常有必要的，<strong>任何自动化的前提是足够的规范</strong>。</p>\n<p>要想做到把之前写的java版本的文件上传功能集成到dubbo中，我们就得先了解一下dubbo的<a href=\"http://alibaba.github.io/dubbo-doc-static/Protocol+Reference-zh.htm\" target=\"_blank\" rel=\"external\">协议细节</a>。不难发现，凡是以单一长连接提供通信的协议都不太适合大数据的传输，原因很简单，凡是单个客户端会长期占用通道传输的场景都会造成通道阻塞，你可以脑补高架上堵车的景象。</p>\n<p>而我们这里提供文件上传服务要使用的协议是REST，也就是dubbox新增的一个方式，具体细节可以看<a href=\"http://blog.kazaff.me/2015/03/12/dubbox%E6%96%B0%E5%A2%9E%E7%9A%84REST%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/\">这里</a>和<a href=\"http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point\" target=\"_blank\" rel=\"external\">这里</a>。其实和上面文档描述的<code>http://</code>协议很相似。</p>\n<p>之前的请求流程如下图：</p>\n<pre><code>client ---&gt; tomcat ---&gt; servlet ---&gt; spring ---&gt; springMVC ---&gt; business code\n</code></pre><p>dubbo化后的如下图：</p>\n<pre><code>client ---&gt; tmocat embed ---&gt; servlet ---&gt; dubbo/spring ---&gt; resteasy ---&gt; business code\n</code></pre><p>不确定这么描述是否合适，但大致就是这样了，其中<code>springMVC</code>和<code>resteasy</code>做的事儿是一样的。我之所以犹豫，是因为不确定<code>dubbo</code>放在哪合适~~完成我们的预期需求，我们可以按照以下几步来走：</p>\n<ol>\n<li>编写Filter实现跨域请求（因为我们的前端全部都是Ajax调用）；</li>\n<li>配置以REST协议暴露dubbo服务；</li>\n<li>使用RESTEasy及JAX-RS规范提供的注解完成把请求参数映射成Bean；</li>\n<li>实现文件上传的业务逻辑（其实就是把原先的springMVC版的相关代码移植到RESTEasy对应位置）</li>\n<li>测试</li>\n</ol>\n<p>剩下的任务就是实操了，我会更新<a href=\"https://github.com/kazaff/webuploaderDemo\" target=\"_blank\" rel=\"external\">原先的github项目</a>，有兴趣的盆宇可以去关注一下。</p>\n","excerpt":"<p>之前写过基于<a href=\"http://blog.kazaff.me/2014/11/14/%E8%81%8A%E8%81%8A%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/\">WebUploader+Java/Php/Nodejs</a>的文章，今天来结合dubbo聊一下文件上传的问题。<br>","more":"<br>目前我们的项目中，文件上传功能是以独立服务的方式部署的，也就是说多个不同的应用可以向同一个文件上传API发起请求（可能需要跨域支持）。我个人是比较喜欢这样的部署方式，不过任何事都是有利弊的，这里就不展开讨论了。</p>\n<p>复习完上面的内容后，我们开始今天的主题，那就是基于dubbo来完成文件上传服务的开发，这么做的动机也很单纯，就是<strong>尽可能保持统一的设计哲学和实现方案</strong>。统一的好处，从运维、监控等多方面也是非常有必要的，<strong>任何自动化的前提是足够的规范</strong>。</p>\n<p>要想做到把之前写的java版本的文件上传功能集成到dubbo中，我们就得先了解一下dubbo的<a href=\"http://alibaba.github.io/dubbo-doc-static/Protocol+Reference-zh.htm\">协议细节</a>。不难发现，凡是以单一长连接提供通信的协议都不太适合大数据的传输，原因很简单，凡是单个客户端会长期占用通道传输的场景都会造成通道阻塞，你可以脑补高架上堵车的景象。</p>\n<p>而我们这里提供文件上传服务要使用的协议是REST，也就是dubbox新增的一个方式，具体细节可以看<a href=\"http://blog.kazaff.me/2015/03/12/dubbox%E6%96%B0%E5%A2%9E%E7%9A%84REST%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/\">这里</a>和<a href=\"http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point\">这里</a>。其实和上面文档描述的<code>http://</code>协议很相似。</p>\n<p>之前的请求流程如下图：</p>\n<pre><code>client ---&gt; tomcat ---&gt; servlet ---&gt; spring ---&gt; springMVC ---&gt; business code\n</code></pre><p>dubbo化后的如下图：</p>\n<pre><code>client ---&gt; tmocat embed ---&gt; servlet ---&gt; dubbo/spring ---&gt; resteasy ---&gt; business code\n</code></pre><p>不确定这么描述是否合适，但大致就是这样了，其中<code>springMVC</code>和<code>resteasy</code>做的事儿是一样的。我之所以犹豫，是因为不确定<code>dubbo</code>放在哪合适~~完成我们的预期需求，我们可以按照以下几步来走：</p>\n<ol>\n<li>编写Filter实现跨域请求（因为我们的前端全部都是Ajax调用）；</li>\n<li>配置以REST协议暴露dubbo服务；</li>\n<li>使用RESTEasy及JAX-RS规范提供的注解完成把请求参数映射成Bean；</li>\n<li>实现文件上传的业务逻辑（其实就是把原先的springMVC版的相关代码移植到RESTEasy对应位置）</li>\n<li>测试</li>\n</ol>\n<p>剩下的任务就是实操了，我会更新<a href=\"https://github.com/kazaff/webuploaderDemo\">原先的github项目</a>，有兴趣的盆宇可以去关注一下。</p>"},{"title":"前后端分离的契约：接口文档","date":"2015-04-25T07:54:30.000Z","_content":"\n最近在公司开发部举办了一次关于前后端配合为主题的研（si）讨(b)会，主要矛盾还是针对前后端协作所使用的接口文档随意变更问题。\n<!--more-->\n其实，接口文档是在我们前后端分离后产生的一个文档，现在的前端基于Angularjs，以Ajax的方式向后端暴露的RESTful接口进行调用，这就要求，在前后端各自开发的过程中如何尽可能的摆脱跨端的依赖。\n\n最直观的方案，就是在设计阶段中产生一个接口文档，在编码阶段开发人员根据分工各自根据接口文档进行功能的实现。这本来是一套简单可爱的流程，不过由于我们在设计阶段所暴露的问题导致了混乱产生：\n\n- 经验不足，无法一次性就设计出完美的接口\n- 时间不够\n- 认知问题，对接口文档重视程度不够\n\n经过几个小时的撕逼，基本上大家统一了一些基础观念，把接口文档当做是契约，在确定后严格履行其声明。\n\n不过，只是解决了认知问题远远不够，光有接口文档也是不能达到理想状态：\n\n- 拒绝写文档的繁琐\n- 尽可能的摆脱依赖\n\n好，第一个问题，我们需要一个足够“程序员化”的接口文档编写工具，找了找，发现一个轻量级的工具不错：[APIDOC](http://apidocjs.com/)。\n\n该工具针对RESTful风格的api，提供了多种语言的支持，而且基于码农擅长的注解方式完成接口的声明，十分贴心。而且，可以自动导出成html，方便部署在各种环境下。\n\n美中不足的是，它没有提供MOCK功能，自带的模拟请求也需要依赖后端服务。不过我依然推荐的理由是：真的很简单。\n\n跟我们的开发人员商量了一下，发现前端人员对mock数据的需求非常强烈，这让我不得不忍痛放弃APIDOC，继续寻找油腻的师姐。\n\n知乎上我看有人推荐一款工具：[RAP](http://thx.github.io/RAP/)，阿里吊炸天啊~\n\nRAP不仅提供了对Mock的完美支持，而且还加入了一些组织结构的功能用于满足团队的使用。\n\n不过就是复杂一些，还好官方提供了视频教学。目前能想到的遗憾之处，就是不像APIDOC那样，可以方便的直接作为接口文档开放给所有第三方使用。","source":"_posts/基于REST的接口文档.md","raw":"title: 前后端分离的契约：接口文档\ndate: 2015-04-25 15:54:30\ntags:\n- RAP\n- RESTful\n- mock\n- api\n\ncategories: 团队协作\n---\n\n最近在公司开发部举办了一次关于前后端配合为主题的研（si）讨(b)会，主要矛盾还是针对前后端协作所使用的接口文档随意变更问题。\n<!--more-->\n其实，接口文档是在我们前后端分离后产生的一个文档，现在的前端基于Angularjs，以Ajax的方式向后端暴露的RESTful接口进行调用，这就要求，在前后端各自开发的过程中如何尽可能的摆脱跨端的依赖。\n\n最直观的方案，就是在设计阶段中产生一个接口文档，在编码阶段开发人员根据分工各自根据接口文档进行功能的实现。这本来是一套简单可爱的流程，不过由于我们在设计阶段所暴露的问题导致了混乱产生：\n\n- 经验不足，无法一次性就设计出完美的接口\n- 时间不够\n- 认知问题，对接口文档重视程度不够\n\n经过几个小时的撕逼，基本上大家统一了一些基础观念，把接口文档当做是契约，在确定后严格履行其声明。\n\n不过，只是解决了认知问题远远不够，光有接口文档也是不能达到理想状态：\n\n- 拒绝写文档的繁琐\n- 尽可能的摆脱依赖\n\n好，第一个问题，我们需要一个足够“程序员化”的接口文档编写工具，找了找，发现一个轻量级的工具不错：[APIDOC](http://apidocjs.com/)。\n\n该工具针对RESTful风格的api，提供了多种语言的支持，而且基于码农擅长的注解方式完成接口的声明，十分贴心。而且，可以自动导出成html，方便部署在各种环境下。\n\n美中不足的是，它没有提供MOCK功能，自带的模拟请求也需要依赖后端服务。不过我依然推荐的理由是：真的很简单。\n\n跟我们的开发人员商量了一下，发现前端人员对mock数据的需求非常强烈，这让我不得不忍痛放弃APIDOC，继续寻找油腻的师姐。\n\n知乎上我看有人推荐一款工具：[RAP](http://thx.github.io/RAP/)，阿里吊炸天啊~\n\nRAP不仅提供了对Mock的完美支持，而且还加入了一些组织结构的功能用于满足团队的使用。\n\n不过就是复杂一些，还好官方提供了视频教学。目前能想到的遗憾之处，就是不像APIDOC那样，可以方便的直接作为接口文档开放给所有第三方使用。","slug":"基于REST的接口文档","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ymt004xgtfypno4kvmv","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近在公司开发部举办了一次关于前后端配合为主题的研（si）讨(b)会，主要矛盾还是针对前后端协作所使用的接口文档随意变更问题。<br><a id=\"more\"></a><br>其实，接口文档是在我们前后端分离后产生的一个文档，现在的前端基于Angularjs，以Ajax的方式向后端暴露的RESTful接口进行调用，这就要求，在前后端各自开发的过程中如何尽可能的摆脱跨端的依赖。</p>\n<p>最直观的方案，就是在设计阶段中产生一个接口文档，在编码阶段开发人员根据分工各自根据接口文档进行功能的实现。这本来是一套简单可爱的流程，不过由于我们在设计阶段所暴露的问题导致了混乱产生：</p>\n<ul>\n<li>经验不足，无法一次性就设计出完美的接口</li>\n<li>时间不够</li>\n<li>认知问题，对接口文档重视程度不够</li>\n</ul>\n<p>经过几个小时的撕逼，基本上大家统一了一些基础观念，把接口文档当做是契约，在确定后严格履行其声明。</p>\n<p>不过，只是解决了认知问题远远不够，光有接口文档也是不能达到理想状态：</p>\n<ul>\n<li>拒绝写文档的繁琐</li>\n<li>尽可能的摆脱依赖</li>\n</ul>\n<p>好，第一个问题，我们需要一个足够“程序员化”的接口文档编写工具，找了找，发现一个轻量级的工具不错：<a href=\"http://apidocjs.com/\" target=\"_blank\" rel=\"external\">APIDOC</a>。</p>\n<p>该工具针对RESTful风格的api，提供了多种语言的支持，而且基于码农擅长的注解方式完成接口的声明，十分贴心。而且，可以自动导出成html，方便部署在各种环境下。</p>\n<p>美中不足的是，它没有提供MOCK功能，自带的模拟请求也需要依赖后端服务。不过我依然推荐的理由是：真的很简单。</p>\n<p>跟我们的开发人员商量了一下，发现前端人员对mock数据的需求非常强烈，这让我不得不忍痛放弃APIDOC，继续寻找油腻的师姐。</p>\n<p>知乎上我看有人推荐一款工具：<a href=\"http://thx.github.io/RAP/\" target=\"_blank\" rel=\"external\">RAP</a>，阿里吊炸天啊~</p>\n<p>RAP不仅提供了对Mock的完美支持，而且还加入了一些组织结构的功能用于满足团队的使用。</p>\n<p>不过就是复杂一些，还好官方提供了视频教学。目前能想到的遗憾之处，就是不像APIDOC那样，可以方便的直接作为接口文档开放给所有第三方使用。</p>\n","excerpt":"<p>最近在公司开发部举办了一次关于前后端配合为主题的研（si）讨(b)会，主要矛盾还是针对前后端协作所使用的接口文档随意变更问题。<br>","more":"<br>其实，接口文档是在我们前后端分离后产生的一个文档，现在的前端基于Angularjs，以Ajax的方式向后端暴露的RESTful接口进行调用，这就要求，在前后端各自开发的过程中如何尽可能的摆脱跨端的依赖。</p>\n<p>最直观的方案，就是在设计阶段中产生一个接口文档，在编码阶段开发人员根据分工各自根据接口文档进行功能的实现。这本来是一套简单可爱的流程，不过由于我们在设计阶段所暴露的问题导致了混乱产生：</p>\n<ul>\n<li>经验不足，无法一次性就设计出完美的接口</li>\n<li>时间不够</li>\n<li>认知问题，对接口文档重视程度不够</li>\n</ul>\n<p>经过几个小时的撕逼，基本上大家统一了一些基础观念，把接口文档当做是契约，在确定后严格履行其声明。</p>\n<p>不过，只是解决了认知问题远远不够，光有接口文档也是不能达到理想状态：</p>\n<ul>\n<li>拒绝写文档的繁琐</li>\n<li>尽可能的摆脱依赖</li>\n</ul>\n<p>好，第一个问题，我们需要一个足够“程序员化”的接口文档编写工具，找了找，发现一个轻量级的工具不错：<a href=\"http://apidocjs.com/\">APIDOC</a>。</p>\n<p>该工具针对RESTful风格的api，提供了多种语言的支持，而且基于码农擅长的注解方式完成接口的声明，十分贴心。而且，可以自动导出成html，方便部署在各种环境下。</p>\n<p>美中不足的是，它没有提供MOCK功能，自带的模拟请求也需要依赖后端服务。不过我依然推荐的理由是：真的很简单。</p>\n<p>跟我们的开发人员商量了一下，发现前端人员对mock数据的需求非常强烈，这让我不得不忍痛放弃APIDOC，继续寻找油腻的师姐。</p>\n<p>知乎上我看有人推荐一款工具：<a href=\"http://thx.github.io/RAP/\">RAP</a>，阿里吊炸天啊~</p>\n<p>RAP不仅提供了对Mock的完美支持，而且还加入了一些组织结构的功能用于满足团队的使用。</p>\n<p>不过就是复杂一些，还好官方提供了视频教学。目前能想到的遗憾之处，就是不像APIDOC那样，可以方便的直接作为接口文档开放给所有第三方使用。</p>"},{"title":"在无图形界面的Centos6.5下使用OpenOffice4.1","date":"2014-12-24T03:37:12.000Z","_content":"这两天发生了一件尴尬的事儿，倾听我娓娓道来：我在开发机上（Win7）上写了一段java代码，使用`jodconverter`类调用`OpenOffice`来将office格式的文件转换成pdf。写完以后第一件事儿就是去虚拟机中的CentOS中测试兼容性，一切比想象中的还要顺利！\n<!--more-->\n事儿如果就这么完了，那就没有这篇日志了，昨天交给同事往线上服务器上部署，可他说有异常，提示无法连接openoffice服务。我就说嘛，事儿不可能这么顺利的！\n\n网上查了一下原因，苦逼了：[OpenOffice安装声明](http://www.openoffice.org/dev_docs/source/sys_reqs_aoo41.html)。\n\n> X-Server with 1024 x 768 pixel or higher resolution with at least 256 colors (16.7 million colors recommended)\n\n图形界面\n---\n\n沃特华克，还需要X-Server啊，线上服务器上是没有装图形界面的，难道需要在为系统安装一套图形界面么？这勾起了我大学时代的残酷回忆，曾经给Ubuntu安装图形界面搞崩系统N多次！我怎么可能有胆子直接给线上服务器上搞这个动作呢？\n\n可是不搞又不行，领导在后面催得要死要活，只能另想办法了！最坏的打算就是给服务器重装系统，所以拜托运维同学先把服务器上的系统进行了备份，然后找机房负责人协商装系统的事儿，不过在此期间，我还是在本地虚拟机装了一套测试环境来尝试解决这个问题。\n\n[安装jdk](http://hermosa-young.iteye.com/blog/1798026)和[openoffice](http://www.if-not-true-then-false.com/2010/install-openoffice-org-on-fedora-centos-red-hat-rhel/)的流程我就不写了，我们直接从安装`Xvfb`开始。\n\n\tyum install  xorg-x11-server-Xvfb\n\n挺顺利的，一次性搞定，不过还是建议先执行`yum update`一下。这个东西我理解的就是相当于给系统装了一套虚拟的图形界面，这样就满足了openoffice的要求。\n\n安装完后，执行：\n\n\tXvfb :1 -screen 0 800x600x24 &\n\tsoffice -headless -accept=\"socket,host=127.0.0.1,port=8100;urp;\" -nofirstartwizard -display :1 &\n\n执行完上面第一条命令后，系统提示了一个报错：\n\n\t......\n\tInitializing built-in extension GLX\n\tThe XKEYBOARD keymap compiler (xkbcomp) reports:\n\t> Internal error:   Could not resolve keysym XF86AudioMicMute\n\tErrors from xkbcomp are not fatal to the X server\n\n不过提示的好像不是致命错误，所以暂时没有理会它。需要注意的是，虽然OpenOffice提示需要的是**1027x768x256**的图形分辨率，但是由于我们的服务器配置问题达不到这个标准，但我实际测试填写**800x600x24**也是完全没问题的！\n\n其实上面第二条命令也可以忽略，如果你用的是`jodconverter3.0+`的话！\n\n现在我们已经可以成功的启动openoffice服务了，我写的那个服务也成功的进行了pdf的生成。\n\n中文字体\n---\n\n可别高兴太早，打开生成的pdf一看，妈蛋，无字经书么？你拿我当唐僧么？这个问题其实也很好理解，系统里没有中文嘛，好说好说，把`C:\\Windows\\Fonts`下所有的字体文件都打包传到服务器上，放在你安装的openoffice的文件夹中，我的是这里：\n\n\t/opt/openoffice4/share/fonts/truetype/\n\n不过需要注意的是，放字体的时候最好是先让刚才开启的openoffice服务停止，如果忘记进程id了，可以执行：\n\n\tnetstat -lnp | grep 8100\n\tnetstat -lnp | grep 2002 //这个是jodconverter3.0+默认使用的端口号\n\n直接kill掉就行了。\n\n\nok，完美了，终于可以不用重装系统就搞定问题了！！！","source":"_posts/在无图形界面的Centos6.5下使用OpenOfiice4.1.md","raw":"title: 在无图形界面的Centos6.5下使用OpenOffice4.1\ndate: 2014-12-24 11:37:12\ntags: \n- centOS\n- openoffice\n- jodconverter\n- pdf\n- 中文\n- 图形界面\ncategories: 运维\n---\n这两天发生了一件尴尬的事儿，倾听我娓娓道来：我在开发机上（Win7）上写了一段java代码，使用`jodconverter`类调用`OpenOffice`来将office格式的文件转换成pdf。写完以后第一件事儿就是去虚拟机中的CentOS中测试兼容性，一切比想象中的还要顺利！\n<!--more-->\n事儿如果就这么完了，那就没有这篇日志了，昨天交给同事往线上服务器上部署，可他说有异常，提示无法连接openoffice服务。我就说嘛，事儿不可能这么顺利的！\n\n网上查了一下原因，苦逼了：[OpenOffice安装声明](http://www.openoffice.org/dev_docs/source/sys_reqs_aoo41.html)。\n\n> X-Server with 1024 x 768 pixel or higher resolution with at least 256 colors (16.7 million colors recommended)\n\n图形界面\n---\n\n沃特华克，还需要X-Server啊，线上服务器上是没有装图形界面的，难道需要在为系统安装一套图形界面么？这勾起了我大学时代的残酷回忆，曾经给Ubuntu安装图形界面搞崩系统N多次！我怎么可能有胆子直接给线上服务器上搞这个动作呢？\n\n可是不搞又不行，领导在后面催得要死要活，只能另想办法了！最坏的打算就是给服务器重装系统，所以拜托运维同学先把服务器上的系统进行了备份，然后找机房负责人协商装系统的事儿，不过在此期间，我还是在本地虚拟机装了一套测试环境来尝试解决这个问题。\n\n[安装jdk](http://hermosa-young.iteye.com/blog/1798026)和[openoffice](http://www.if-not-true-then-false.com/2010/install-openoffice-org-on-fedora-centos-red-hat-rhel/)的流程我就不写了，我们直接从安装`Xvfb`开始。\n\n\tyum install  xorg-x11-server-Xvfb\n\n挺顺利的，一次性搞定，不过还是建议先执行`yum update`一下。这个东西我理解的就是相当于给系统装了一套虚拟的图形界面，这样就满足了openoffice的要求。\n\n安装完后，执行：\n\n\tXvfb :1 -screen 0 800x600x24 &\n\tsoffice -headless -accept=\"socket,host=127.0.0.1,port=8100;urp;\" -nofirstartwizard -display :1 &\n\n执行完上面第一条命令后，系统提示了一个报错：\n\n\t......\n\tInitializing built-in extension GLX\n\tThe XKEYBOARD keymap compiler (xkbcomp) reports:\n\t> Internal error:   Could not resolve keysym XF86AudioMicMute\n\tErrors from xkbcomp are not fatal to the X server\n\n不过提示的好像不是致命错误，所以暂时没有理会它。需要注意的是，虽然OpenOffice提示需要的是**1027x768x256**的图形分辨率，但是由于我们的服务器配置问题达不到这个标准，但我实际测试填写**800x600x24**也是完全没问题的！\n\n其实上面第二条命令也可以忽略，如果你用的是`jodconverter3.0+`的话！\n\n现在我们已经可以成功的启动openoffice服务了，我写的那个服务也成功的进行了pdf的生成。\n\n中文字体\n---\n\n可别高兴太早，打开生成的pdf一看，妈蛋，无字经书么？你拿我当唐僧么？这个问题其实也很好理解，系统里没有中文嘛，好说好说，把`C:\\Windows\\Fonts`下所有的字体文件都打包传到服务器上，放在你安装的openoffice的文件夹中，我的是这里：\n\n\t/opt/openoffice4/share/fonts/truetype/\n\n不过需要注意的是，放字体的时候最好是先让刚才开启的openoffice服务停止，如果忘记进程id了，可以执行：\n\n\tnetstat -lnp | grep 8100\n\tnetstat -lnp | grep 2002 //这个是jodconverter3.0+默认使用的端口号\n\n直接kill掉就行了。\n\n\nok，完美了，终于可以不用重装系统就搞定问题了！！！","slug":"在无图形界面的Centos6.5下使用OpenOfiice4.1","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ymx0057gtfyv1f124rb","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这两天发生了一件尴尬的事儿，倾听我娓娓道来：我在开发机上（Win7）上写了一段java代码，使用<code>jodconverter</code>类调用<code>OpenOffice</code>来将office格式的文件转换成pdf。写完以后第一件事儿就是去虚拟机中的CentOS中测试兼容性，一切比想象中的还要顺利！<br><a id=\"more\"></a><br>事儿如果就这么完了，那就没有这篇日志了，昨天交给同事往线上服务器上部署，可他说有异常，提示无法连接openoffice服务。我就说嘛，事儿不可能这么顺利的！</p>\n<p>网上查了一下原因，苦逼了：<a href=\"http://www.openoffice.org/dev_docs/source/sys_reqs_aoo41.html\" target=\"_blank\" rel=\"external\">OpenOffice安装声明</a>。</p>\n<blockquote>\n<p>X-Server with 1024 x 768 pixel or higher resolution with at least 256 colors (16.7 million colors recommended)</p>\n</blockquote>\n<h2 id=\"图形界面\"><a href=\"#图形界面\" class=\"headerlink\" title=\"图形界面\"></a>图形界面</h2><p>沃特华克，还需要X-Server啊，线上服务器上是没有装图形界面的，难道需要在为系统安装一套图形界面么？这勾起了我大学时代的残酷回忆，曾经给Ubuntu安装图形界面搞崩系统N多次！我怎么可能有胆子直接给线上服务器上搞这个动作呢？</p>\n<p>可是不搞又不行，领导在后面催得要死要活，只能另想办法了！最坏的打算就是给服务器重装系统，所以拜托运维同学先把服务器上的系统进行了备份，然后找机房负责人协商装系统的事儿，不过在此期间，我还是在本地虚拟机装了一套测试环境来尝试解决这个问题。</p>\n<p><a href=\"http://hermosa-young.iteye.com/blog/1798026\" target=\"_blank\" rel=\"external\">安装jdk</a>和<a href=\"http://www.if-not-true-then-false.com/2010/install-openoffice-org-on-fedora-centos-red-hat-rhel/\" target=\"_blank\" rel=\"external\">openoffice</a>的流程我就不写了，我们直接从安装<code>Xvfb</code>开始。</p>\n<pre><code>yum install  xorg-x11-server-Xvfb\n</code></pre><p>挺顺利的，一次性搞定，不过还是建议先执行<code>yum update</code>一下。这个东西我理解的就是相当于给系统装了一套虚拟的图形界面，这样就满足了openoffice的要求。</p>\n<p>安装完后，执行：</p>\n<pre><code>Xvfb :1 -screen 0 800x600x24 &amp;\nsoffice -headless -accept=&quot;socket,host=127.0.0.1,port=8100;urp;&quot; -nofirstartwizard -display :1 &amp;\n</code></pre><p>执行完上面第一条命令后，系统提示了一个报错：</p>\n<pre><code>......\nInitializing built-in extension GLX\nThe XKEYBOARD keymap compiler (xkbcomp) reports:\n&gt; Internal error:   Could not resolve keysym XF86AudioMicMute\nErrors from xkbcomp are not fatal to the X server\n</code></pre><p>不过提示的好像不是致命错误，所以暂时没有理会它。需要注意的是，虽然OpenOffice提示需要的是<strong>1027x768x256</strong>的图形分辨率，但是由于我们的服务器配置问题达不到这个标准，但我实际测试填写<strong>800x600x24</strong>也是完全没问题的！</p>\n<p>其实上面第二条命令也可以忽略，如果你用的是<code>jodconverter3.0+</code>的话！</p>\n<p>现在我们已经可以成功的启动openoffice服务了，我写的那个服务也成功的进行了pdf的生成。</p>\n<h2 id=\"中文字体\"><a href=\"#中文字体\" class=\"headerlink\" title=\"中文字体\"></a>中文字体</h2><p>可别高兴太早，打开生成的pdf一看，妈蛋，无字经书么？你拿我当唐僧么？这个问题其实也很好理解，系统里没有中文嘛，好说好说，把<code>C:\\Windows\\Fonts</code>下所有的字体文件都打包传到服务器上，放在你安装的openoffice的文件夹中，我的是这里：</p>\n<pre><code>/opt/openoffice4/share/fonts/truetype/\n</code></pre><p>不过需要注意的是，放字体的时候最好是先让刚才开启的openoffice服务停止，如果忘记进程id了，可以执行：</p>\n<pre><code>netstat -lnp | grep 8100\nnetstat -lnp | grep 2002 //这个是jodconverter3.0+默认使用的端口号\n</code></pre><p>直接kill掉就行了。</p>\n<p>ok，完美了，终于可以不用重装系统就搞定问题了！！！</p>\n","excerpt":"<p>这两天发生了一件尴尬的事儿，倾听我娓娓道来：我在开发机上（Win7）上写了一段java代码，使用<code>jodconverter</code>类调用<code>OpenOffice</code>来将office格式的文件转换成pdf。写完以后第一件事儿就是去虚拟机中的CentOS中测试兼容性，一切比想象中的还要顺利！<br>","more":"<br>事儿如果就这么完了，那就没有这篇日志了，昨天交给同事往线上服务器上部署，可他说有异常，提示无法连接openoffice服务。我就说嘛，事儿不可能这么顺利的！</p>\n<p>网上查了一下原因，苦逼了：<a href=\"http://www.openoffice.org/dev_docs/source/sys_reqs_aoo41.html\">OpenOffice安装声明</a>。</p>\n<blockquote>\n<p>X-Server with 1024 x 768 pixel or higher resolution with at least 256 colors (16.7 million colors recommended)</p>\n</blockquote>\n<h2 id=\"图形界面\"><a href=\"#图形界面\" class=\"headerlink\" title=\"图形界面\"></a>图形界面</h2><p>沃特华克，还需要X-Server啊，线上服务器上是没有装图形界面的，难道需要在为系统安装一套图形界面么？这勾起了我大学时代的残酷回忆，曾经给Ubuntu安装图形界面搞崩系统N多次！我怎么可能有胆子直接给线上服务器上搞这个动作呢？</p>\n<p>可是不搞又不行，领导在后面催得要死要活，只能另想办法了！最坏的打算就是给服务器重装系统，所以拜托运维同学先把服务器上的系统进行了备份，然后找机房负责人协商装系统的事儿，不过在此期间，我还是在本地虚拟机装了一套测试环境来尝试解决这个问题。</p>\n<p><a href=\"http://hermosa-young.iteye.com/blog/1798026\">安装jdk</a>和<a href=\"http://www.if-not-true-then-false.com/2010/install-openoffice-org-on-fedora-centos-red-hat-rhel/\">openoffice</a>的流程我就不写了，我们直接从安装<code>Xvfb</code>开始。</p>\n<pre><code>yum install  xorg-x11-server-Xvfb\n</code></pre><p>挺顺利的，一次性搞定，不过还是建议先执行<code>yum update</code>一下。这个东西我理解的就是相当于给系统装了一套虚拟的图形界面，这样就满足了openoffice的要求。</p>\n<p>安装完后，执行：</p>\n<pre><code>Xvfb :1 -screen 0 800x600x24 &amp;\nsoffice -headless -accept=&quot;socket,host=127.0.0.1,port=8100;urp;&quot; -nofirstartwizard -display :1 &amp;\n</code></pre><p>执行完上面第一条命令后，系统提示了一个报错：</p>\n<pre><code>......\nInitializing built-in extension GLX\nThe XKEYBOARD keymap compiler (xkbcomp) reports:\n&gt; Internal error:   Could not resolve keysym XF86AudioMicMute\nErrors from xkbcomp are not fatal to the X server\n</code></pre><p>不过提示的好像不是致命错误，所以暂时没有理会它。需要注意的是，虽然OpenOffice提示需要的是<strong>1027x768x256</strong>的图形分辨率，但是由于我们的服务器配置问题达不到这个标准，但我实际测试填写<strong>800x600x24</strong>也是完全没问题的！</p>\n<p>其实上面第二条命令也可以忽略，如果你用的是<code>jodconverter3.0+</code>的话！</p>\n<p>现在我们已经可以成功的启动openoffice服务了，我写的那个服务也成功的进行了pdf的生成。</p>\n<h2 id=\"中文字体\"><a href=\"#中文字体\" class=\"headerlink\" title=\"中文字体\"></a>中文字体</h2><p>可别高兴太早，打开生成的pdf一看，妈蛋，无字经书么？你拿我当唐僧么？这个问题其实也很好理解，系统里没有中文嘛，好说好说，把<code>C:\\Windows\\Fonts</code>下所有的字体文件都打包传到服务器上，放在你安装的openoffice的文件夹中，我的是这里：</p>\n<pre><code>/opt/openoffice4/share/fonts/truetype/\n</code></pre><p>不过需要注意的是，放字体的时候最好是先让刚才开启的openoffice服务停止，如果忘记进程id了，可以执行：</p>\n<pre><code>netstat -lnp | grep 8100\nnetstat -lnp | grep 2002 //这个是jodconverter3.0+默认使用的端口号\n</code></pre><p>直接kill掉就行了。</p>\n<p>ok，完美了，终于可以不用重装系统就搞定问题了！！！</p>"},{"title":"又一次新气象","date":"2014-09-05T00:13:12.000Z","_content":"\n作为一个懒惰的，只会指手画脚，自己设计不来的程序猿，换一次博客皮肤是多么奢侈的一件事儿啊~~想想都头疼！\n<!--more-->\n不过，还是在昨晚陪同组员加班到凌晨1点多期间忙（yi）里（xin）偷（yi）闲（yi）的把node版本的hexo博客系统重新整了整，当然，由于是突发奇想的行为，所以并没有太多时间用来筹备，直接在github上找到一款个人比较喜欢的皮肤，稍加改动就成了你现在看到的样子~\n\n至于wp版，已经决定不在更新了，也就是说现在哥只会在node版本的这个网址下添加新的内容，有兴趣查阅老的内容的童鞋请点击顶部导航的[Deprecated链接](http://www.kazaff.me/)。\n\n好吧，再扯点别的，说点什么好呢？哦，对了，我要结婚了马上~~当然，是和一个女人！婚期定在冬天，一个众人鸭绒我西装独显我瘦的季节。顺便征求一下婚礼现场的音乐清单，目前我喜欢的有：\n\n![](http://pic.yupoo.com/kazaff_v/E2auBlc6/r3yxo.png)\n\n大家还有什么推荐的吗？逗比就算了，毕竟是一个各族人民欢聚一堂的正经场合，单曲循环小苹果什么的有点太神经了~~\n\nPS：忘记说了，发现一个非常牛叉的chrome插件：[Point](http://www.appinn.com/point-for-chrome/)，实现了我多年以来一直计划开发但却迟迟下不了手的构想，哎，又一次和百万富翁擦肩而过啊~~","source":"_posts/又一次新气象.md","raw":"title: 又一次新气象\ndate: 2014-09-05 08:13:12\ntags: \ncategories: talk\n---\n\n作为一个懒惰的，只会指手画脚，自己设计不来的程序猿，换一次博客皮肤是多么奢侈的一件事儿啊~~想想都头疼！\n<!--more-->\n不过，还是在昨晚陪同组员加班到凌晨1点多期间忙（yi）里（xin）偷（yi）闲（yi）的把node版本的hexo博客系统重新整了整，当然，由于是突发奇想的行为，所以并没有太多时间用来筹备，直接在github上找到一款个人比较喜欢的皮肤，稍加改动就成了你现在看到的样子~\n\n至于wp版，已经决定不在更新了，也就是说现在哥只会在node版本的这个网址下添加新的内容，有兴趣查阅老的内容的童鞋请点击顶部导航的[Deprecated链接](http://www.kazaff.me/)。\n\n好吧，再扯点别的，说点什么好呢？哦，对了，我要结婚了马上~~当然，是和一个女人！婚期定在冬天，一个众人鸭绒我西装独显我瘦的季节。顺便征求一下婚礼现场的音乐清单，目前我喜欢的有：\n\n![](http://pic.yupoo.com/kazaff_v/E2auBlc6/r3yxo.png)\n\n大家还有什么推荐的吗？逗比就算了，毕竟是一个各族人民欢聚一堂的正经场合，单曲循环小苹果什么的有点太神经了~~\n\nPS：忘记说了，发现一个非常牛叉的chrome插件：[Point](http://www.appinn.com/point-for-chrome/)，实现了我多年以来一直计划开发但却迟迟下不了手的构想，哎，又一次和百万富翁擦肩而过啊~~","slug":"又一次新气象","published":1,"updated":"2016-05-14T07:46:19.000Z","_id":"cica18yn9005lgtfygrzb043y","comments":1,"layout":"post","photos":[],"link":"","content":"<p>作为一个懒惰的，只会指手画脚，自己设计不来的程序猿，换一次博客皮肤是多么奢侈的一件事儿啊~~想想都头疼！<br><a id=\"more\"></a><br>不过，还是在昨晚陪同组员加班到凌晨1点多期间忙（yi）里（xin）偷（yi）闲（yi）的把node版本的hexo博客系统重新整了整，当然，由于是突发奇想的行为，所以并没有太多时间用来筹备，直接在github上找到一款个人比较喜欢的皮肤，稍加改动就成了你现在看到的样子~</p>\n<p>至于wp版，已经决定不在更新了，也就是说现在哥只会在node版本的这个网址下添加新的内容，有兴趣查阅老的内容的童鞋请点击顶部导航的<a href=\"http://www.kazaff.me/\" target=\"_blank\" rel=\"external\">Deprecated链接</a>。</p>\n<p>好吧，再扯点别的，说点什么好呢？哦，对了，我要结婚了马上~~当然，是和一个女人！婚期定在冬天，一个众人鸭绒我西装独显我瘦的季节。顺便征求一下婚礼现场的音乐清单，目前我喜欢的有：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E2auBlc6/r3yxo.png\" alt=\"\"></p>\n<p>大家还有什么推荐的吗？逗比就算了，毕竟是一个各族人民欢聚一堂的正经场合，单曲循环小苹果什么的有点太神经了~~</p>\n<p>PS：忘记说了，发现一个非常牛叉的chrome插件：<a href=\"http://www.appinn.com/point-for-chrome/\" target=\"_blank\" rel=\"external\">Point</a>，实现了我多年以来一直计划开发但却迟迟下不了手的构想，哎，又一次和百万富翁擦肩而过啊~~</p>\n","excerpt":"<p>作为一个懒惰的，只会指手画脚，自己设计不来的程序猿，换一次博客皮肤是多么奢侈的一件事儿啊~~想想都头疼！<br>","more":"<br>不过，还是在昨晚陪同组员加班到凌晨1点多期间忙（yi）里（xin）偷（yi）闲（yi）的把node版本的hexo博客系统重新整了整，当然，由于是突发奇想的行为，所以并没有太多时间用来筹备，直接在github上找到一款个人比较喜欢的皮肤，稍加改动就成了你现在看到的样子~</p>\n<p>至于wp版，已经决定不在更新了，也就是说现在哥只会在node版本的这个网址下添加新的内容，有兴趣查阅老的内容的童鞋请点击顶部导航的<a href=\"http://www.kazaff.me/\">Deprecated链接</a>。</p>\n<p>好吧，再扯点别的，说点什么好呢？哦，对了，我要结婚了马上~~当然，是和一个女人！婚期定在冬天，一个众人鸭绒我西装独显我瘦的季节。顺便征求一下婚礼现场的音乐清单，目前我喜欢的有：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E2auBlc6/r3yxo.png\" alt=\"\"></p>\n<p>大家还有什么推荐的吗？逗比就算了，毕竟是一个各族人民欢聚一堂的正经场合，单曲循环小苹果什么的有点太神经了~~</p>\n<p>PS：忘记说了，发现一个非常牛叉的chrome插件：<a href=\"http://www.appinn.com/point-for-chrome/\">Point</a>，实现了我多年以来一直计划开发但却迟迟下不了手的构想，哎，又一次和百万富翁擦肩而过啊~~</p>"},{"title":"到底积累什么才是最佳选择？","date":"2014-10-13T09:25:30.000Z","_content":"\n其实一直以来都在困惑，像我这种草根出身的程序员，随着工作时间的增长，价值到底体现在什么地方？\n\n如果说是体现在编程能力上，那其实任何一个上心的普通正常人都可以在2-3年的编程岗位上达到一样的高度，这样来说，5年的程序员和3年的程序员差别又是什么呢？\n\n而且技术迭代的速度着实快，编程语言更是每年都有黑马，你曾经积累的某种语言的编程经验很可能没过几年就变成了垃圾。相比之下，可能编程思想才是真正有价值的遗产。\n\n那么编程思想又都包含什么呢？\n\n这个问题就涉及到软件开发领域中的一些术语，像设计模式、项目把控、需求分析，等等。那是不是搞定这些就能保证你不会被公司外聘来的“和尚”所代替呢？我看也不尽然。\n\n我觉得应该是你对业务理解的程度，才是你保值的最有利武器。这个道理并不难理解，但恰恰是很多程序员所做不到的！我们往往由于折服于技术的强大，而忽略了真正的驱动力：业务。\n\n为什么多数VC们总是盯着商业价值？其实商业价值跟技术关系并不大，跟市场，跟业务却是密不可分的。当然不能否认的是：只有过硬的技术才能支撑哪些天花乱坠的商业模式。不过，天外有天，你技术再好，也会被更nb的咖秒杀。\n\n我想，这就是为什么销售人员比开发人员的吃香的本质吧？\n\nPS：上面说的都是建立在很多假定上的，例如你所在的环境确实有前景，例如你得到了老板的重视和认可，例如你确实遇到了瓶颈等。\n\nPS2：最近一段时间，组织了团队内的一次较大的头脑风暴会议，感触颇多，我想这是非常难得的经历，而目前公司的这个项目也是一个非常好的历练机会，真心希望可以通过半年的时间，能让自己更上一层楼。","source":"_posts/到底积累什么才是最佳选择.md","raw":"title: 到底积累什么才是最佳选择？\ndate: 2014-10-13 17:25:30\ntags:\n- 迷茫\ncategories: talk\n---\n\n其实一直以来都在困惑，像我这种草根出身的程序员，随着工作时间的增长，价值到底体现在什么地方？\n\n如果说是体现在编程能力上，那其实任何一个上心的普通正常人都可以在2-3年的编程岗位上达到一样的高度，这样来说，5年的程序员和3年的程序员差别又是什么呢？\n\n而且技术迭代的速度着实快，编程语言更是每年都有黑马，你曾经积累的某种语言的编程经验很可能没过几年就变成了垃圾。相比之下，可能编程思想才是真正有价值的遗产。\n\n那么编程思想又都包含什么呢？\n\n这个问题就涉及到软件开发领域中的一些术语，像设计模式、项目把控、需求分析，等等。那是不是搞定这些就能保证你不会被公司外聘来的“和尚”所代替呢？我看也不尽然。\n\n我觉得应该是你对业务理解的程度，才是你保值的最有利武器。这个道理并不难理解，但恰恰是很多程序员所做不到的！我们往往由于折服于技术的强大，而忽略了真正的驱动力：业务。\n\n为什么多数VC们总是盯着商业价值？其实商业价值跟技术关系并不大，跟市场，跟业务却是密不可分的。当然不能否认的是：只有过硬的技术才能支撑哪些天花乱坠的商业模式。不过，天外有天，你技术再好，也会被更nb的咖秒杀。\n\n我想，这就是为什么销售人员比开发人员的吃香的本质吧？\n\nPS：上面说的都是建立在很多假定上的，例如你所在的环境确实有前景，例如你得到了老板的重视和认可，例如你确实遇到了瓶颈等。\n\nPS2：最近一段时间，组织了团队内的一次较大的头脑风暴会议，感触颇多，我想这是非常难得的经历，而目前公司的这个项目也是一个非常好的历练机会，真心希望可以通过半年的时间，能让自己更上一层楼。","slug":"到底积累什么才是最佳选择","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ynd005ngtfypl7cnto7","comments":1,"layout":"post","photos":[],"link":"","content":"<p>其实一直以来都在困惑，像我这种草根出身的程序员，随着工作时间的增长，价值到底体现在什么地方？</p>\n<p>如果说是体现在编程能力上，那其实任何一个上心的普通正常人都可以在2-3年的编程岗位上达到一样的高度，这样来说，5年的程序员和3年的程序员差别又是什么呢？</p>\n<p>而且技术迭代的速度着实快，编程语言更是每年都有黑马，你曾经积累的某种语言的编程经验很可能没过几年就变成了垃圾。相比之下，可能编程思想才是真正有价值的遗产。</p>\n<p>那么编程思想又都包含什么呢？</p>\n<p>这个问题就涉及到软件开发领域中的一些术语，像设计模式、项目把控、需求分析，等等。那是不是搞定这些就能保证你不会被公司外聘来的“和尚”所代替呢？我看也不尽然。</p>\n<p>我觉得应该是你对业务理解的程度，才是你保值的最有利武器。这个道理并不难理解，但恰恰是很多程序员所做不到的！我们往往由于折服于技术的强大，而忽略了真正的驱动力：业务。</p>\n<p>为什么多数VC们总是盯着商业价值？其实商业价值跟技术关系并不大，跟市场，跟业务却是密不可分的。当然不能否认的是：只有过硬的技术才能支撑哪些天花乱坠的商业模式。不过，天外有天，你技术再好，也会被更nb的咖秒杀。</p>\n<p>我想，这就是为什么销售人员比开发人员的吃香的本质吧？</p>\n<p>PS：上面说的都是建立在很多假定上的，例如你所在的环境确实有前景，例如你得到了老板的重视和认可，例如你确实遇到了瓶颈等。</p>\n<p>PS2：最近一段时间，组织了团队内的一次较大的头脑风暴会议，感触颇多，我想这是非常难得的经历，而目前公司的这个项目也是一个非常好的历练机会，真心希望可以通过半年的时间，能让自己更上一层楼。</p>\n","excerpt":"","more":"<p>其实一直以来都在困惑，像我这种草根出身的程序员，随着工作时间的增长，价值到底体现在什么地方？</p>\n<p>如果说是体现在编程能力上，那其实任何一个上心的普通正常人都可以在2-3年的编程岗位上达到一样的高度，这样来说，5年的程序员和3年的程序员差别又是什么呢？</p>\n<p>而且技术迭代的速度着实快，编程语言更是每年都有黑马，你曾经积累的某种语言的编程经验很可能没过几年就变成了垃圾。相比之下，可能编程思想才是真正有价值的遗产。</p>\n<p>那么编程思想又都包含什么呢？</p>\n<p>这个问题就涉及到软件开发领域中的一些术语，像设计模式、项目把控、需求分析，等等。那是不是搞定这些就能保证你不会被公司外聘来的“和尚”所代替呢？我看也不尽然。</p>\n<p>我觉得应该是你对业务理解的程度，才是你保值的最有利武器。这个道理并不难理解，但恰恰是很多程序员所做不到的！我们往往由于折服于技术的强大，而忽略了真正的驱动力：业务。</p>\n<p>为什么多数VC们总是盯着商业价值？其实商业价值跟技术关系并不大，跟市场，跟业务却是密不可分的。当然不能否认的是：只有过硬的技术才能支撑哪些天花乱坠的商业模式。不过，天外有天，你技术再好，也会被更nb的咖秒杀。</p>\n<p>我想，这就是为什么销售人员比开发人员的吃香的本质吧？</p>\n<p>PS：上面说的都是建立在很多假定上的，例如你所在的环境确实有前景，例如你得到了老板的重视和认可，例如你确实遇到了瓶颈等。</p>\n<p>PS2：最近一段时间，组织了团队内的一次较大的头脑风暴会议，感触颇多，我想这是非常难得的经历，而目前公司的这个项目也是一个非常好的历练机会，真心希望可以通过半年的时间，能让自己更上一层楼。</p>\n"},{"title":"关于redis集群和事务","date":"2014-11-01T01:37:12.000Z","_content":"\n\n最近为了核算项目的两个架构指标（可用性和伸缩性），需要对项目中使用的Redis数据库的集群部署进行一定程度的了解，当然顺便再学习一遍它的事务细节。\n<!-- more -->\n既然我在上面把Redis称之为数据库，那么在我们目前的项目里，它自然就需要持久化相关的数据，而不仅仅充当缓存而已！\n\n在网上逛了一遍，看了不少关于redis集群搭建的文章，有一些把redis的主备当集群来讲的，也有一些讲的是以第三方代理方式搭建集群的，比较新的是讲的redis3.0beta提供的服务器端实现集群的~~\n\n比较有代表型的一款中间代理方式实现redis集群的开源产品是Twitter推出的[twemproxy](https://github.com/twitter/twemproxy)。而这种方式的优劣，redis的作者早已经写过一篇分析的[文章](http://www.oschina.net/translate/twemproxy-a-twitter-redis-proxy)了，相信大家读过以后就能了解其中的好坏。\n\n在这里，我主要是贴一下关于[twemproxy对redis命令的支持情况](https://github.com/twitter/twemproxy/blob/master/notes/redis.md)的细节，相信有了这个数据，我们在设计使用redis时可以起到指导的作用。\n\n另外，twemproxy中不少命令的支持与否需要依赖[Hash Tags](https://github.com/twitter/twemproxy/blob/master/notes/recommendation.md#hash-tags)，简单粗暴解释的话，其实就是说twemproxy支持指定key中的某一部分用来做hash散列，这样就有助于把相关的一些数据分布在同一台服务器上，从而避免一些指令导致数据在多服务器之间不必要的迁移而影响了性能！\n\n从这个表格中我们注意到，twemproxy不支持redis的事务操作，原因其实在上面给出的文章中已经解释了~这里我主要想来聊一下redis的事务到底是什么？记忆中看过一篇文章，模糊记得redis的事务和传统关系型数据库的事务是存在差异的。\n\n先看一下这篇[文章](http://redisbook.readthedocs.org/en/latest/feature/transaction.html)，写的已经非常之详细了，不是么？我们必须搞清楚： **原子性、一致性和回滚功能**。这可能显得有一些过于纠结定义了，不过查了一下GG才发现，其实关于原子性和一致性的理解却是有很多种说法~~而我更偏向于下面这种解释：\n\n- **一致性：**如果事务启动时数据是一致的，那么当这个事务成功结束的时候数据库也应该是一致的;\n- **原子性：**事务的所有操作在数据库中要么全部正确反映，要么全部不反映。\n\n分别举例子来说，一致性就是数据库的数据状态符合数据库所描述的业务逻辑和规则，比如最简单的一条一致性规则：银行账户存款余额不能是负值。\n\n而原子性就是其字面解释：要么都执行，要么都取消！这时候就需要数据库事务有**回滚能力**。不难理解吧？\n\n接下来我们再说redis的事务，上面的资料中提到：\n\n\t当事务失败时，Redis 也不会进行任何的重试或者回滚动作。\n\n也就是说，redis不具备事务原子性（非事务下的redis命令具备原子性）。看一个代码例子：\n\n\tset name kazaff0  \t//首先我们为key为name的键设置了一个值：kazaff0\n\tmulti\t\t\t\t//开启事务\n\tset name kazaff1\t//事务里我们修改name的值为kazaff1\n\tlpush name kazaff2\t//故意造成一个执行错误\n\texec\t\t\t\t//提交事务\n\tget name\t\t\t//？\n\n可以猜出最后一条指令的返回结果应该：`kazaff1`。为什么？因为redis不支持事务失败后回滚！\n\n但是需要注意的是，服务器在执行事务之前会先检查客户端的状态，如果发现不满足事务执行的条件的话服务器端会直接终止事务，也就是说任务队列中的指令一条都没有执行！\n\n为什么要注意这一点呢？也就是说**只有执行错误才会需要回滚，而watch，discard，入队错误等都不需要回滚**，因为执行队列中的指令压根一条都没有执行过！\n\n以前总是把redis的事务和[pipe](http://blog.csdn.net/freebird_lb/article/details/7778919)看成一个东西：打包执行指令~~但现在才发现，完全两码事儿嘛！！\n\n\n\n\n\n---\n\n参考：\n[理解事务的一致性和原子性](http://blog.csdn.net/amghost/article/details/17651891)\n\n\n\n\n\n\n\n","source":"_posts/关于redis集群和事务.md","raw":"title: 关于redis集群和事务\ndate: 2014-11-1 09:37:12\ntags: \n- redis\n- 一致性\n- 原子性\n- 回滚\n- twemproxy\n- tomcat\n- 集群\n- pipe\n- 缓存\ncategories: nosql\n---\n\n\n最近为了核算项目的两个架构指标（可用性和伸缩性），需要对项目中使用的Redis数据库的集群部署进行一定程度的了解，当然顺便再学习一遍它的事务细节。\n<!-- more -->\n既然我在上面把Redis称之为数据库，那么在我们目前的项目里，它自然就需要持久化相关的数据，而不仅仅充当缓存而已！\n\n在网上逛了一遍，看了不少关于redis集群搭建的文章，有一些把redis的主备当集群来讲的，也有一些讲的是以第三方代理方式搭建集群的，比较新的是讲的redis3.0beta提供的服务器端实现集群的~~\n\n比较有代表型的一款中间代理方式实现redis集群的开源产品是Twitter推出的[twemproxy](https://github.com/twitter/twemproxy)。而这种方式的优劣，redis的作者早已经写过一篇分析的[文章](http://www.oschina.net/translate/twemproxy-a-twitter-redis-proxy)了，相信大家读过以后就能了解其中的好坏。\n\n在这里，我主要是贴一下关于[twemproxy对redis命令的支持情况](https://github.com/twitter/twemproxy/blob/master/notes/redis.md)的细节，相信有了这个数据，我们在设计使用redis时可以起到指导的作用。\n\n另外，twemproxy中不少命令的支持与否需要依赖[Hash Tags](https://github.com/twitter/twemproxy/blob/master/notes/recommendation.md#hash-tags)，简单粗暴解释的话，其实就是说twemproxy支持指定key中的某一部分用来做hash散列，这样就有助于把相关的一些数据分布在同一台服务器上，从而避免一些指令导致数据在多服务器之间不必要的迁移而影响了性能！\n\n从这个表格中我们注意到，twemproxy不支持redis的事务操作，原因其实在上面给出的文章中已经解释了~这里我主要想来聊一下redis的事务到底是什么？记忆中看过一篇文章，模糊记得redis的事务和传统关系型数据库的事务是存在差异的。\n\n先看一下这篇[文章](http://redisbook.readthedocs.org/en/latest/feature/transaction.html)，写的已经非常之详细了，不是么？我们必须搞清楚： **原子性、一致性和回滚功能**。这可能显得有一些过于纠结定义了，不过查了一下GG才发现，其实关于原子性和一致性的理解却是有很多种说法~~而我更偏向于下面这种解释：\n\n- **一致性：**如果事务启动时数据是一致的，那么当这个事务成功结束的时候数据库也应该是一致的;\n- **原子性：**事务的所有操作在数据库中要么全部正确反映，要么全部不反映。\n\n分别举例子来说，一致性就是数据库的数据状态符合数据库所描述的业务逻辑和规则，比如最简单的一条一致性规则：银行账户存款余额不能是负值。\n\n而原子性就是其字面解释：要么都执行，要么都取消！这时候就需要数据库事务有**回滚能力**。不难理解吧？\n\n接下来我们再说redis的事务，上面的资料中提到：\n\n\t当事务失败时，Redis 也不会进行任何的重试或者回滚动作。\n\n也就是说，redis不具备事务原子性（非事务下的redis命令具备原子性）。看一个代码例子：\n\n\tset name kazaff0  \t//首先我们为key为name的键设置了一个值：kazaff0\n\tmulti\t\t\t\t//开启事务\n\tset name kazaff1\t//事务里我们修改name的值为kazaff1\n\tlpush name kazaff2\t//故意造成一个执行错误\n\texec\t\t\t\t//提交事务\n\tget name\t\t\t//？\n\n可以猜出最后一条指令的返回结果应该：`kazaff1`。为什么？因为redis不支持事务失败后回滚！\n\n但是需要注意的是，服务器在执行事务之前会先检查客户端的状态，如果发现不满足事务执行的条件的话服务器端会直接终止事务，也就是说任务队列中的指令一条都没有执行！\n\n为什么要注意这一点呢？也就是说**只有执行错误才会需要回滚，而watch，discard，入队错误等都不需要回滚**，因为执行队列中的指令压根一条都没有执行过！\n\n以前总是把redis的事务和[pipe](http://blog.csdn.net/freebird_lb/article/details/7778919)看成一个东西：打包执行指令~~但现在才发现，完全两码事儿嘛！！\n\n\n\n\n\n---\n\n参考：\n[理解事务的一致性和原子性](http://blog.csdn.net/amghost/article/details/17651891)\n\n\n\n\n\n\n\n","slug":"关于redis集群和事务","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ynh005rgtfy4574ndbq","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近为了核算项目的两个架构指标（可用性和伸缩性），需要对项目中使用的Redis数据库的集群部署进行一定程度的了解，当然顺便再学习一遍它的事务细节。<br><a id=\"more\"></a><br>既然我在上面把Redis称之为数据库，那么在我们目前的项目里，它自然就需要持久化相关的数据，而不仅仅充当缓存而已！</p>\n<p>在网上逛了一遍，看了不少关于redis集群搭建的文章，有一些把redis的主备当集群来讲的，也有一些讲的是以第三方代理方式搭建集群的，比较新的是讲的redis3.0beta提供的服务器端实现集群的~~</p>\n<p>比较有代表型的一款中间代理方式实现redis集群的开源产品是Twitter推出的<a href=\"https://github.com/twitter/twemproxy\" target=\"_blank\" rel=\"external\">twemproxy</a>。而这种方式的优劣，redis的作者早已经写过一篇分析的<a href=\"http://www.oschina.net/translate/twemproxy-a-twitter-redis-proxy\" target=\"_blank\" rel=\"external\">文章</a>了，相信大家读过以后就能了解其中的好坏。</p>\n<p>在这里，我主要是贴一下关于<a href=\"https://github.com/twitter/twemproxy/blob/master/notes/redis.md\" target=\"_blank\" rel=\"external\">twemproxy对redis命令的支持情况</a>的细节，相信有了这个数据，我们在设计使用redis时可以起到指导的作用。</p>\n<p>另外，twemproxy中不少命令的支持与否需要依赖<a href=\"https://github.com/twitter/twemproxy/blob/master/notes/recommendation.md#hash-tags\" target=\"_blank\" rel=\"external\">Hash Tags</a>，简单粗暴解释的话，其实就是说twemproxy支持指定key中的某一部分用来做hash散列，这样就有助于把相关的一些数据分布在同一台服务器上，从而避免一些指令导致数据在多服务器之间不必要的迁移而影响了性能！</p>\n<p>从这个表格中我们注意到，twemproxy不支持redis的事务操作，原因其实在上面给出的文章中已经解释了~这里我主要想来聊一下redis的事务到底是什么？记忆中看过一篇文章，模糊记得redis的事务和传统关系型数据库的事务是存在差异的。</p>\n<p>先看一下这篇<a href=\"http://redisbook.readthedocs.org/en/latest/feature/transaction.html\" target=\"_blank\" rel=\"external\">文章</a>，写的已经非常之详细了，不是么？我们必须搞清楚： <strong>原子性、一致性和回滚功能</strong>。这可能显得有一些过于纠结定义了，不过查了一下GG才发现，其实关于原子性和一致性的理解却是有很多种说法~~而我更偏向于下面这种解释：</p>\n<ul>\n<li><strong>一致性：</strong>如果事务启动时数据是一致的，那么当这个事务成功结束的时候数据库也应该是一致的;</li>\n<li><strong>原子性：</strong>事务的所有操作在数据库中要么全部正确反映，要么全部不反映。</li>\n</ul>\n<p>分别举例子来说，一致性就是数据库的数据状态符合数据库所描述的业务逻辑和规则，比如最简单的一条一致性规则：银行账户存款余额不能是负值。</p>\n<p>而原子性就是其字面解释：要么都执行，要么都取消！这时候就需要数据库事务有<strong>回滚能力</strong>。不难理解吧？</p>\n<p>接下来我们再说redis的事务，上面的资料中提到：</p>\n<pre><code>当事务失败时，Redis 也不会进行任何的重试或者回滚动作。\n</code></pre><p>也就是说，redis不具备事务原子性（非事务下的redis命令具备原子性）。看一个代码例子：</p>\n<pre><code>set name kazaff0      //首先我们为key为name的键设置了一个值：kazaff0\nmulti                //开启事务\nset name kazaff1    //事务里我们修改name的值为kazaff1\nlpush name kazaff2    //故意造成一个执行错误\nexec                //提交事务\nget name            //？\n</code></pre><p>可以猜出最后一条指令的返回结果应该：<code>kazaff1</code>。为什么？因为redis不支持事务失败后回滚！</p>\n<p>但是需要注意的是，服务器在执行事务之前会先检查客户端的状态，如果发现不满足事务执行的条件的话服务器端会直接终止事务，也就是说任务队列中的指令一条都没有执行！</p>\n<p>为什么要注意这一点呢？也就是说<strong>只有执行错误才会需要回滚，而watch，discard，入队错误等都不需要回滚</strong>，因为执行队列中的指令压根一条都没有执行过！</p>\n<p>以前总是把redis的事务和<a href=\"http://blog.csdn.net/freebird_lb/article/details/7778919\" target=\"_blank\" rel=\"external\">pipe</a>看成一个东西：打包执行指令~~但现在才发现，完全两码事儿嘛！！</p>\n<hr>\n<p>参考：<br><a href=\"http://blog.csdn.net/amghost/article/details/17651891\" target=\"_blank\" rel=\"external\">理解事务的一致性和原子性</a></p>\n","excerpt":"<p>最近为了核算项目的两个架构指标（可用性和伸缩性），需要对项目中使用的Redis数据库的集群部署进行一定程度的了解，当然顺便再学习一遍它的事务细节。<br>","more":"<br>既然我在上面把Redis称之为数据库，那么在我们目前的项目里，它自然就需要持久化相关的数据，而不仅仅充当缓存而已！</p>\n<p>在网上逛了一遍，看了不少关于redis集群搭建的文章，有一些把redis的主备当集群来讲的，也有一些讲的是以第三方代理方式搭建集群的，比较新的是讲的redis3.0beta提供的服务器端实现集群的~~</p>\n<p>比较有代表型的一款中间代理方式实现redis集群的开源产品是Twitter推出的<a href=\"https://github.com/twitter/twemproxy\">twemproxy</a>。而这种方式的优劣，redis的作者早已经写过一篇分析的<a href=\"http://www.oschina.net/translate/twemproxy-a-twitter-redis-proxy\">文章</a>了，相信大家读过以后就能了解其中的好坏。</p>\n<p>在这里，我主要是贴一下关于<a href=\"https://github.com/twitter/twemproxy/blob/master/notes/redis.md\">twemproxy对redis命令的支持情况</a>的细节，相信有了这个数据，我们在设计使用redis时可以起到指导的作用。</p>\n<p>另外，twemproxy中不少命令的支持与否需要依赖<a href=\"https://github.com/twitter/twemproxy/blob/master/notes/recommendation.md#hash-tags\">Hash Tags</a>，简单粗暴解释的话，其实就是说twemproxy支持指定key中的某一部分用来做hash散列，这样就有助于把相关的一些数据分布在同一台服务器上，从而避免一些指令导致数据在多服务器之间不必要的迁移而影响了性能！</p>\n<p>从这个表格中我们注意到，twemproxy不支持redis的事务操作，原因其实在上面给出的文章中已经解释了~这里我主要想来聊一下redis的事务到底是什么？记忆中看过一篇文章，模糊记得redis的事务和传统关系型数据库的事务是存在差异的。</p>\n<p>先看一下这篇<a href=\"http://redisbook.readthedocs.org/en/latest/feature/transaction.html\">文章</a>，写的已经非常之详细了，不是么？我们必须搞清楚： <strong>原子性、一致性和回滚功能</strong>。这可能显得有一些过于纠结定义了，不过查了一下GG才发现，其实关于原子性和一致性的理解却是有很多种说法~~而我更偏向于下面这种解释：</p>\n<ul>\n<li><strong>一致性：</strong>如果事务启动时数据是一致的，那么当这个事务成功结束的时候数据库也应该是一致的;</li>\n<li><strong>原子性：</strong>事务的所有操作在数据库中要么全部正确反映，要么全部不反映。</li>\n</ul>\n<p>分别举例子来说，一致性就是数据库的数据状态符合数据库所描述的业务逻辑和规则，比如最简单的一条一致性规则：银行账户存款余额不能是负值。</p>\n<p>而原子性就是其字面解释：要么都执行，要么都取消！这时候就需要数据库事务有<strong>回滚能力</strong>。不难理解吧？</p>\n<p>接下来我们再说redis的事务，上面的资料中提到：</p>\n<pre><code>当事务失败时，Redis 也不会进行任何的重试或者回滚动作。\n</code></pre><p>也就是说，redis不具备事务原子性（非事务下的redis命令具备原子性）。看一个代码例子：</p>\n<pre><code>set name kazaff0      //首先我们为key为name的键设置了一个值：kazaff0\nmulti                //开启事务\nset name kazaff1    //事务里我们修改name的值为kazaff1\nlpush name kazaff2    //故意造成一个执行错误\nexec                //提交事务\nget name            //？\n</code></pre><p>可以猜出最后一条指令的返回结果应该：<code>kazaff1</code>。为什么？因为redis不支持事务失败后回滚！</p>\n<p>但是需要注意的是，服务器在执行事务之前会先检查客户端的状态，如果发现不满足事务执行的条件的话服务器端会直接终止事务，也就是说任务队列中的指令一条都没有执行！</p>\n<p>为什么要注意这一点呢？也就是说<strong>只有执行错误才会需要回滚，而watch，discard，入队错误等都不需要回滚</strong>，因为执行队列中的指令压根一条都没有执行过！</p>\n<p>以前总是把redis的事务和<a href=\"http://blog.csdn.net/freebird_lb/article/details/7778919\">pipe</a>看成一个东西：打包执行指令~~但现在才发现，完全两码事儿嘛！！</p>\n<hr>\n<p>参考：<br><a href=\"http://blog.csdn.net/amghost/article/details/17651891\">理解事务的一致性和原子性</a></p>"},{"title":"关于Flow","date":"2015-05-27T01:37:12.000Z","_content":"\n最近感觉又back2js了，仅仅是几个月的暂别，就感觉js又tmd翻天覆地了￥Q@#@#$～\n\n这次要科普的是[Flow](http://flowtype.org)，这玩意儿是FaceBook开源的一个**类型检查**库，从此写js就再也不\"自由\"了～\n<!--more-->\n都说FB的天才多，现在终于感觉到了，人家玩的都是语言扩展，顿时感觉高端大气档次高了啊！其实为若类型语言增加类型检查，JS并不是第一个语言，早先FB就给PHP改造过了……之所以我突然想起来科普这个，是因为最近在看React的代码，发现有很多看似眼熟又总觉得怪怪的代码风格，一开始以为是ES6的新特性，但是查了一下却没找到对应介绍，谁知道是Flow提供的，真是让我大开眼界啊！\n\n看一个官方的demo：\n\t\n\tfunction add(num1, num2) {\n  \t\treturn num1 + num2;\n  \t}\n\tvar x = add(3, '0');\n\tconsole.log(x);\n\t\n你说，`x`的值是啥？3？30？undefined？不管是啥，其实这都是动态类型带来的连带伤害，我们在以前的js/php编程的日子里上面这种场景屡见不鲜。但是FB的大大们坐不住了，非得改到爽才行：\n\n\t\n\t/* @flow */\n\tfunction add(num1: number, num2: number): number {\n  \t\treturn num1 + num2;\n\t}\n\tvar x: number = add(3, '0');\n\tconsole.log(x);\n\t\n在Flow的世界里，你就得这么老实的写，这样，是个人都应该知道x应该是啥了吧？\n\n这里我就好奇了，Flow提供的既然不是标准的js语法，那浏览器怎么可能理解？确实不能理解，别说浏览器，我的WebStorm都报错，怎么办？\n\n我们需要在交给客户端之前转换为标准的js代码，官方提供了对应的[转换工具](http://flowtype.org/docs/running.html)，这样我们的js代码就可以在编写时拥有完善的类型检查，又可以直接在产品环境下运行了，这种思想和**less**如出一辙。\n\n再往下聊，就需要我们同时对js这门语言和Flow提供的适配规则有很全面的了解了。所以我就不多说了，免得误人子弟～～","source":"_posts/关于Flow.md","raw":"title: 关于Flow\ndate: 2015-05-27 09:37:12\ntags: \n- flow\n- facebook\n- 类型检查\ncategories: 前端\n---\n\n最近感觉又back2js了，仅仅是几个月的暂别，就感觉js又tmd翻天覆地了￥Q@#@#$～\n\n这次要科普的是[Flow](http://flowtype.org)，这玩意儿是FaceBook开源的一个**类型检查**库，从此写js就再也不\"自由\"了～\n<!--more-->\n都说FB的天才多，现在终于感觉到了，人家玩的都是语言扩展，顿时感觉高端大气档次高了啊！其实为若类型语言增加类型检查，JS并不是第一个语言，早先FB就给PHP改造过了……之所以我突然想起来科普这个，是因为最近在看React的代码，发现有很多看似眼熟又总觉得怪怪的代码风格，一开始以为是ES6的新特性，但是查了一下却没找到对应介绍，谁知道是Flow提供的，真是让我大开眼界啊！\n\n看一个官方的demo：\n\t\n\tfunction add(num1, num2) {\n  \t\treturn num1 + num2;\n  \t}\n\tvar x = add(3, '0');\n\tconsole.log(x);\n\t\n你说，`x`的值是啥？3？30？undefined？不管是啥，其实这都是动态类型带来的连带伤害，我们在以前的js/php编程的日子里上面这种场景屡见不鲜。但是FB的大大们坐不住了，非得改到爽才行：\n\n\t\n\t/* @flow */\n\tfunction add(num1: number, num2: number): number {\n  \t\treturn num1 + num2;\n\t}\n\tvar x: number = add(3, '0');\n\tconsole.log(x);\n\t\n在Flow的世界里，你就得这么老实的写，这样，是个人都应该知道x应该是啥了吧？\n\n这里我就好奇了，Flow提供的既然不是标准的js语法，那浏览器怎么可能理解？确实不能理解，别说浏览器，我的WebStorm都报错，怎么办？\n\n我们需要在交给客户端之前转换为标准的js代码，官方提供了对应的[转换工具](http://flowtype.org/docs/running.html)，这样我们的js代码就可以在编写时拥有完善的类型检查，又可以直接在产品环境下运行了，这种思想和**less**如出一辙。\n\n再往下聊，就需要我们同时对js这门语言和Flow提供的适配规则有很全面的了解了。所以我就不多说了，免得误人子弟～～","slug":"关于Flow","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ynr006bgtfysbri9p4q","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近感觉又back2js了，仅仅是几个月的暂别，就感觉js又tmd翻天覆地了￥Q@#@#$～</p>\n<p>这次要科普的是<a href=\"http://flowtype.org\" target=\"_blank\" rel=\"external\">Flow</a>，这玩意儿是FaceBook开源的一个<strong>类型检查</strong>库，从此写js就再也不”自由”了～<br><a id=\"more\"></a><br>都说FB的天才多，现在终于感觉到了，人家玩的都是语言扩展，顿时感觉高端大气档次高了啊！其实为若类型语言增加类型检查，JS并不是第一个语言，早先FB就给PHP改造过了……之所以我突然想起来科普这个，是因为最近在看React的代码，发现有很多看似眼熟又总觉得怪怪的代码风格，一开始以为是ES6的新特性，但是查了一下却没找到对应介绍，谁知道是Flow提供的，真是让我大开眼界啊！</p>\n<p>看一个官方的demo：</p>\n<pre><code>function add(num1, num2) {\n      return num1 + num2;\n  }\nvar x = add(3, &apos;0&apos;);\nconsole.log(x);\n</code></pre><p>你说，<code>x</code>的值是啥？3？30？undefined？不管是啥，其实这都是动态类型带来的连带伤害，我们在以前的js/php编程的日子里上面这种场景屡见不鲜。但是FB的大大们坐不住了，非得改到爽才行：</p>\n<pre><code>/* @flow */\nfunction add(num1: number, num2: number): number {\n      return num1 + num2;\n}\nvar x: number = add(3, &apos;0&apos;);\nconsole.log(x);\n</code></pre><p>在Flow的世界里，你就得这么老实的写，这样，是个人都应该知道x应该是啥了吧？</p>\n<p>这里我就好奇了，Flow提供的既然不是标准的js语法，那浏览器怎么可能理解？确实不能理解，别说浏览器，我的WebStorm都报错，怎么办？</p>\n<p>我们需要在交给客户端之前转换为标准的js代码，官方提供了对应的<a href=\"http://flowtype.org/docs/running.html\" target=\"_blank\" rel=\"external\">转换工具</a>，这样我们的js代码就可以在编写时拥有完善的类型检查，又可以直接在产品环境下运行了，这种思想和<strong>less</strong>如出一辙。</p>\n<p>再往下聊，就需要我们同时对js这门语言和Flow提供的适配规则有很全面的了解了。所以我就不多说了，免得误人子弟～～</p>\n","excerpt":"<p>最近感觉又back2js了，仅仅是几个月的暂别，就感觉js又tmd翻天覆地了￥Q@#@#$～</p>\n<p>这次要科普的是<a href=\"http://flowtype.org\">Flow</a>，这玩意儿是FaceBook开源的一个<strong>类型检查</strong>库，从此写js就再也不”自由”了～<br>","more":"<br>都说FB的天才多，现在终于感觉到了，人家玩的都是语言扩展，顿时感觉高端大气档次高了啊！其实为若类型语言增加类型检查，JS并不是第一个语言，早先FB就给PHP改造过了……之所以我突然想起来科普这个，是因为最近在看React的代码，发现有很多看似眼熟又总觉得怪怪的代码风格，一开始以为是ES6的新特性，但是查了一下却没找到对应介绍，谁知道是Flow提供的，真是让我大开眼界啊！</p>\n<p>看一个官方的demo：</p>\n<pre><code>function add(num1, num2) {\n      return num1 + num2;\n  }\nvar x = add(3, &apos;0&apos;);\nconsole.log(x);\n</code></pre><p>你说，<code>x</code>的值是啥？3？30？undefined？不管是啥，其实这都是动态类型带来的连带伤害，我们在以前的js/php编程的日子里上面这种场景屡见不鲜。但是FB的大大们坐不住了，非得改到爽才行：</p>\n<pre><code>/* @flow */\nfunction add(num1: number, num2: number): number {\n      return num1 + num2;\n}\nvar x: number = add(3, &apos;0&apos;);\nconsole.log(x);\n</code></pre><p>在Flow的世界里，你就得这么老实的写，这样，是个人都应该知道x应该是啥了吧？</p>\n<p>这里我就好奇了，Flow提供的既然不是标准的js语法，那浏览器怎么可能理解？确实不能理解，别说浏览器，我的WebStorm都报错，怎么办？</p>\n<p>我们需要在交给客户端之前转换为标准的js代码，官方提供了对应的<a href=\"http://flowtype.org/docs/running.html\">转换工具</a>，这样我们的js代码就可以在编写时拥有完善的类型检查，又可以直接在产品环境下运行了，这种思想和<strong>less</strong>如出一辙。</p>\n<p>再往下聊，就需要我们同时对js这门语言和Flow提供的适配规则有很全面的了解了。所以我就不多说了，免得误人子弟～～</p>"},{"title":"twemproxy安装问题与不支持的操作明细","date":"2015-01-26T06:53:12.000Z","_content":"\nredis已经成为我们项目中不可或缺的一部分，充当了各种业务数据的持久化：用户会话，部分数据关系，缓存等。那么，保证redis的高可用高扩展性自然成了一个不可忽视的目标。\n<!--more-->\n值得庆幸的是业界已经有大量的[成功案例](http://jolestar.com/redis-ha/)用来驾驭redis，我们只需要拿来主义即可。今天要聊的就是一款普世的redis中间代理：[twemproxy](http://zhangxiong0301.iteye.com/blog/2157757)。相关内容可以在网上找到很多，这里肯定没必要重复了，我就先来说一下本人安装twemproxy时遇到的问题吧。\n\n先安装git：\n\n\tyum install git\n\n这个没啥好说的，接下来我们来下载twemproxy源文件：\n\n\tcd /usr/local\n\tgit clone https://github.com/twitter/twemproxy.git\n\tcd twemproxy\n\n第一次编译：\n\n\tautoreconf -fvi\n\n结果提示autoconf版本太低，我们只能[更新autoconf](http://zhaohe162.blog.163.com/blog/static/3821679720147276238862/)。\n\n第二次编译，依然不顺利，报错如下：\n\n\tautoreconf: Entering directory `.'\n\tautoreconf: configure.ac: not using Gettext\n\tautoreconf: running: aclocal --force -I m4\n\tCan't exec xxxxxxx //忘记了，不过不重要\n\n查了一下，原因是由于我们手动安装的autoconf，导致其他两个必要的依赖包缺失，**依照顺序**安装下面两个包：\n\n1. automake-1.12.tar.gz： ftp://ftp.gnu.org/gnu/automake/automake-1.12.tar.xz\n2. [libtool-2.2.4.tar.gz](http://ftp.gnu.org/gnu/libtool/libtool-2.2.4.tar.gz)\n\n一切就绪了，可以顺利安装了。\n\n\n最后需要**提醒**你看一下twemproxy[不支持的命令集合](https://github.com/twitter/twemproxy/blob/master/notes/redis.md)，把自己项目中与redis相关的逻辑都过滤一遍，避免执行失败。\n\n","source":"_posts/twemproxy安装问题与不支持的操作明细.md","raw":"title: twemproxy安装问题与不支持的操作明细\ndate: 2015-1-26 14:53:12\ntags: \n- redis\n- twemproxy\n- 可伸缩\ncategories: nosql\n---\n\nredis已经成为我们项目中不可或缺的一部分，充当了各种业务数据的持久化：用户会话，部分数据关系，缓存等。那么，保证redis的高可用高扩展性自然成了一个不可忽视的目标。\n<!--more-->\n值得庆幸的是业界已经有大量的[成功案例](http://jolestar.com/redis-ha/)用来驾驭redis，我们只需要拿来主义即可。今天要聊的就是一款普世的redis中间代理：[twemproxy](http://zhangxiong0301.iteye.com/blog/2157757)。相关内容可以在网上找到很多，这里肯定没必要重复了，我就先来说一下本人安装twemproxy时遇到的问题吧。\n\n先安装git：\n\n\tyum install git\n\n这个没啥好说的，接下来我们来下载twemproxy源文件：\n\n\tcd /usr/local\n\tgit clone https://github.com/twitter/twemproxy.git\n\tcd twemproxy\n\n第一次编译：\n\n\tautoreconf -fvi\n\n结果提示autoconf版本太低，我们只能[更新autoconf](http://zhaohe162.blog.163.com/blog/static/3821679720147276238862/)。\n\n第二次编译，依然不顺利，报错如下：\n\n\tautoreconf: Entering directory `.'\n\tautoreconf: configure.ac: not using Gettext\n\tautoreconf: running: aclocal --force -I m4\n\tCan't exec xxxxxxx //忘记了，不过不重要\n\n查了一下，原因是由于我们手动安装的autoconf，导致其他两个必要的依赖包缺失，**依照顺序**安装下面两个包：\n\n1. automake-1.12.tar.gz： ftp://ftp.gnu.org/gnu/automake/automake-1.12.tar.xz\n2. [libtool-2.2.4.tar.gz](http://ftp.gnu.org/gnu/libtool/libtool-2.2.4.tar.gz)\n\n一切就绪了，可以顺利安装了。\n\n\n最后需要**提醒**你看一下twemproxy[不支持的命令集合](https://github.com/twitter/twemproxy/blob/master/notes/redis.md)，把自己项目中与redis相关的逻辑都过滤一遍，避免执行失败。\n\n","slug":"twemproxy安装问题与不支持的操作明细","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ynx006jgtfyz1rbbfu4","comments":1,"layout":"post","photos":[],"link":"","content":"<p>redis已经成为我们项目中不可或缺的一部分，充当了各种业务数据的持久化：用户会话，部分数据关系，缓存等。那么，保证redis的高可用高扩展性自然成了一个不可忽视的目标。<br><a id=\"more\"></a><br>值得庆幸的是业界已经有大量的<a href=\"http://jolestar.com/redis-ha/\" target=\"_blank\" rel=\"external\">成功案例</a>用来驾驭redis，我们只需要拿来主义即可。今天要聊的就是一款普世的redis中间代理：<a href=\"http://zhangxiong0301.iteye.com/blog/2157757\" target=\"_blank\" rel=\"external\">twemproxy</a>。相关内容可以在网上找到很多，这里肯定没必要重复了，我就先来说一下本人安装twemproxy时遇到的问题吧。</p>\n<p>先安装git：</p>\n<pre><code>yum install git\n</code></pre><p>这个没啥好说的，接下来我们来下载twemproxy源文件：</p>\n<pre><code>cd /usr/local\ngit clone https://github.com/twitter/twemproxy.git\ncd twemproxy\n</code></pre><p>第一次编译：</p>\n<pre><code>autoreconf -fvi\n</code></pre><p>结果提示autoconf版本太低，我们只能<a href=\"http://zhaohe162.blog.163.com/blog/static/3821679720147276238862/\" target=\"_blank\" rel=\"external\">更新autoconf</a>。</p>\n<p>第二次编译，依然不顺利，报错如下：</p>\n<pre><code>autoreconf: Entering directory `.&apos;\nautoreconf: configure.ac: not using Gettext\nautoreconf: running: aclocal --force -I m4\nCan&apos;t exec xxxxxxx //忘记了，不过不重要\n</code></pre><p>查了一下，原因是由于我们手动安装的autoconf，导致其他两个必要的依赖包缺失，<strong>依照顺序</strong>安装下面两个包：</p>\n<ol>\n<li>automake-1.12.tar.gz： ftp://ftp.gnu.org/gnu/automake/automake-1.12.tar.xz</li>\n<li><a href=\"http://ftp.gnu.org/gnu/libtool/libtool-2.2.4.tar.gz\" target=\"_blank\" rel=\"external\">libtool-2.2.4.tar.gz</a></li>\n</ol>\n<p>一切就绪了，可以顺利安装了。</p>\n<p>最后需要<strong>提醒</strong>你看一下twemproxy<a href=\"https://github.com/twitter/twemproxy/blob/master/notes/redis.md\" target=\"_blank\" rel=\"external\">不支持的命令集合</a>，把自己项目中与redis相关的逻辑都过滤一遍，避免执行失败。</p>\n","excerpt":"<p>redis已经成为我们项目中不可或缺的一部分，充当了各种业务数据的持久化：用户会话，部分数据关系，缓存等。那么，保证redis的高可用高扩展性自然成了一个不可忽视的目标。<br>","more":"<br>值得庆幸的是业界已经有大量的<a href=\"http://jolestar.com/redis-ha/\">成功案例</a>用来驾驭redis，我们只需要拿来主义即可。今天要聊的就是一款普世的redis中间代理：<a href=\"http://zhangxiong0301.iteye.com/blog/2157757\">twemproxy</a>。相关内容可以在网上找到很多，这里肯定没必要重复了，我就先来说一下本人安装twemproxy时遇到的问题吧。</p>\n<p>先安装git：</p>\n<pre><code>yum install git\n</code></pre><p>这个没啥好说的，接下来我们来下载twemproxy源文件：</p>\n<pre><code>cd /usr/local\ngit clone https://github.com/twitter/twemproxy.git\ncd twemproxy\n</code></pre><p>第一次编译：</p>\n<pre><code>autoreconf -fvi\n</code></pre><p>结果提示autoconf版本太低，我们只能<a href=\"http://zhaohe162.blog.163.com/blog/static/3821679720147276238862/\">更新autoconf</a>。</p>\n<p>第二次编译，依然不顺利，报错如下：</p>\n<pre><code>autoreconf: Entering directory `.&apos;\nautoreconf: configure.ac: not using Gettext\nautoreconf: running: aclocal --force -I m4\nCan&apos;t exec xxxxxxx //忘记了，不过不重要\n</code></pre><p>查了一下，原因是由于我们手动安装的autoconf，导致其他两个必要的依赖包缺失，<strong>依照顺序</strong>安装下面两个包：</p>\n<ol>\n<li>automake-1.12.tar.gz： ftp://ftp.gnu.org/gnu/automake/automake-1.12.tar.xz</li>\n<li><a href=\"http://ftp.gnu.org/gnu/libtool/libtool-2.2.4.tar.gz\">libtool-2.2.4.tar.gz</a></li>\n</ol>\n<p>一切就绪了，可以顺利安装了。</p>\n<p>最后需要<strong>提醒</strong>你看一下twemproxy<a href=\"https://github.com/twitter/twemproxy/blob/master/notes/redis.md\">不支持的命令集合</a>，把自己项目中与redis相关的逻辑都过滤一遍，避免执行失败。</p>"},{"title":"screen命令","date":"2015-05-31T01:37:12.000Z","_content":"\n今天发现一个好东西，你是不是以前和我一样，当需要执行一个后台常驻进程的命令时，总像下面这样写：\n\n\tnohup command &\n\n但是尴尬的是，一旦你这么做，当你需要查看相关命令输出的时候，你只能扇自己脸了。\n<!--more-->\n\n有童鞋说可以指定输出到对应文件，是的，然后就是不停的刷新对应文件，你有考虑过文件的感受么？\n\n今天算是长见识了，你其实可以通过`screen`命令创建一个平行环境，该环境下运行的终端命令，其父进程不是sshd登录会话，也就是说它可以避免用户退出进程消失的问题，更神奇的是，它还支持随时重新接管回终端继续操作。妈蛋，简直逆天~\n\n创建独立的screen命令如下：\n\n\tscreen -dmS kazaff-Demo\n\n接管连入创建的kazaff-Demo环境命令如下：\n\n\tscreen -r kazaff-Demo\n\n想退出当前平行环境，也不难，直接**按 Ctrl+A+D 键**，如果创建了多个screen，可以查看列表，命令如下：\n\n\tscreen -list\n\n好了，从今以后，又可以装逼了~\n\n如果你觉得这个不够屌，那你不妨看看[Tmux](http://blog.jobbole.com/87278/)。","source":"_posts/screen命令.md","raw":"title: screen命令\ndate: 2015-05-31 09:37:12\ntags: \n- ssh\n- tmux\n- 终端\ncategories: 运维\n---\n\n今天发现一个好东西，你是不是以前和我一样，当需要执行一个后台常驻进程的命令时，总像下面这样写：\n\n\tnohup command &\n\n但是尴尬的是，一旦你这么做，当你需要查看相关命令输出的时候，你只能扇自己脸了。\n<!--more-->\n\n有童鞋说可以指定输出到对应文件，是的，然后就是不停的刷新对应文件，你有考虑过文件的感受么？\n\n今天算是长见识了，你其实可以通过`screen`命令创建一个平行环境，该环境下运行的终端命令，其父进程不是sshd登录会话，也就是说它可以避免用户退出进程消失的问题，更神奇的是，它还支持随时重新接管回终端继续操作。妈蛋，简直逆天~\n\n创建独立的screen命令如下：\n\n\tscreen -dmS kazaff-Demo\n\n接管连入创建的kazaff-Demo环境命令如下：\n\n\tscreen -r kazaff-Demo\n\n想退出当前平行环境，也不难，直接**按 Ctrl+A+D 键**，如果创建了多个screen，可以查看列表，命令如下：\n\n\tscreen -list\n\n好了，从今以后，又可以装逼了~\n\n如果你觉得这个不够屌，那你不妨看看[Tmux](http://blog.jobbole.com/87278/)。","slug":"screen命令","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yo0006pgtfywlgh99d4","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天发现一个好东西，你是不是以前和我一样，当需要执行一个后台常驻进程的命令时，总像下面这样写：</p>\n<pre><code>nohup command &amp;\n</code></pre><p>但是尴尬的是，一旦你这么做，当你需要查看相关命令输出的时候，你只能扇自己脸了。<br><a id=\"more\"></a></p>\n<p>有童鞋说可以指定输出到对应文件，是的，然后就是不停的刷新对应文件，你有考虑过文件的感受么？</p>\n<p>今天算是长见识了，你其实可以通过<code>screen</code>命令创建一个平行环境，该环境下运行的终端命令，其父进程不是sshd登录会话，也就是说它可以避免用户退出进程消失的问题，更神奇的是，它还支持随时重新接管回终端继续操作。妈蛋，简直逆天~</p>\n<p>创建独立的screen命令如下：</p>\n<pre><code>screen -dmS kazaff-Demo\n</code></pre><p>接管连入创建的kazaff-Demo环境命令如下：</p>\n<pre><code>screen -r kazaff-Demo\n</code></pre><p>想退出当前平行环境，也不难，直接<strong>按 Ctrl+A+D 键</strong>，如果创建了多个screen，可以查看列表，命令如下：</p>\n<pre><code>screen -list\n</code></pre><p>好了，从今以后，又可以装逼了~</p>\n<p>如果你觉得这个不够屌，那你不妨看看<a href=\"http://blog.jobbole.com/87278/\" target=\"_blank\" rel=\"external\">Tmux</a>。</p>\n","excerpt":"<p>今天发现一个好东西，你是不是以前和我一样，当需要执行一个后台常驻进程的命令时，总像下面这样写：</p>\n<pre><code>nohup command &amp;\n</code></pre><p>但是尴尬的是，一旦你这么做，当你需要查看相关命令输出的时候，你只能扇自己脸了。<br>","more":"</p>\n<p>有童鞋说可以指定输出到对应文件，是的，然后就是不停的刷新对应文件，你有考虑过文件的感受么？</p>\n<p>今天算是长见识了，你其实可以通过<code>screen</code>命令创建一个平行环境，该环境下运行的终端命令，其父进程不是sshd登录会话，也就是说它可以避免用户退出进程消失的问题，更神奇的是，它还支持随时重新接管回终端继续操作。妈蛋，简直逆天~</p>\n<p>创建独立的screen命令如下：</p>\n<pre><code>screen -dmS kazaff-Demo\n</code></pre><p>接管连入创建的kazaff-Demo环境命令如下：</p>\n<pre><code>screen -r kazaff-Demo\n</code></pre><p>想退出当前平行环境，也不难，直接<strong>按 Ctrl+A+D 键</strong>，如果创建了多个screen，可以查看列表，命令如下：</p>\n<pre><code>screen -list\n</code></pre><p>好了，从今以后，又可以装逼了~</p>\n<p>如果你觉得这个不够屌，那你不妨看看<a href=\"http://blog.jobbole.com/87278/\">Tmux</a>。</p>"},{"title":"rsync和inotify配置","date":"2015-01-26T08:53:12.000Z","_content":"\n两台服务器之间需要进行文件的主从同步，常用的方案是rsync+inotify，网上可以看到一大把相关的[资料](http://dl528888.blog.51cto.com/2382721/771533)。\n<!--more-->\n可我在按照前辈说的方法配置时却遇到了一些问题，首先是因为自己的懒惰，直接从网页上把shell脚本拷贝到win系统下的编辑器中，然后再放入cecntos中，结果发现执行报错，是那种很诡异的提示：\n\n\tsyntax error: unexpected end of file\n\n只需要在centos中用vi手动key一遍脚本即可，这个错误应该是有win->linux时编码不同导致的。\n\n接下来脚本执行成功了，可每次同步时都会报错，提示无法连接从机地址，这是由于防火墙没有放行对应端口导致的，简单的方法就是关闭防火墙：\n\n\tservice iptables stop\n\n最后我又发现，除了mv命令以外其他命令都可以触发同步，唯独mv不行，查了一下发现是上面前辈提供的脚本并没有监控mv对应的事件导致的，详情可见这篇[博文](http://www.lvtao.net/tool/inotify.html)。\n\n知道原因了就很简答了，把最终脚本改成：\n\n\t#!/bin/bash\n\thost=192.168.76.135\n\tsrc=/www/       \n\tdes=web\n\tuser=kazaff\n\t/usr/local/inotify/bin/inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %w%f%e' -e  modify,delete,create,attrib,moved_to $src | while read files\n\tdo\n\t/usr/local/rsync/bin/rsync -vzrtopg --delete --progress --password-file=/usr/local/rsync/rsync.passwd $src $user@$host::$des >>dev/null 2>>/tmp/rsync.log  \n\tdone\n\n","source":"_posts/rsync和inotify配置.md","raw":"title: rsync和inotify配置\ndate: 2015-1-26 16:53:12\ntags: \n- rsync\n- inotify\n- 文件同步\ncategories: 运维\n---\n\n两台服务器之间需要进行文件的主从同步，常用的方案是rsync+inotify，网上可以看到一大把相关的[资料](http://dl528888.blog.51cto.com/2382721/771533)。\n<!--more-->\n可我在按照前辈说的方法配置时却遇到了一些问题，首先是因为自己的懒惰，直接从网页上把shell脚本拷贝到win系统下的编辑器中，然后再放入cecntos中，结果发现执行报错，是那种很诡异的提示：\n\n\tsyntax error: unexpected end of file\n\n只需要在centos中用vi手动key一遍脚本即可，这个错误应该是有win->linux时编码不同导致的。\n\n接下来脚本执行成功了，可每次同步时都会报错，提示无法连接从机地址，这是由于防火墙没有放行对应端口导致的，简单的方法就是关闭防火墙：\n\n\tservice iptables stop\n\n最后我又发现，除了mv命令以外其他命令都可以触发同步，唯独mv不行，查了一下发现是上面前辈提供的脚本并没有监控mv对应的事件导致的，详情可见这篇[博文](http://www.lvtao.net/tool/inotify.html)。\n\n知道原因了就很简答了，把最终脚本改成：\n\n\t#!/bin/bash\n\thost=192.168.76.135\n\tsrc=/www/       \n\tdes=web\n\tuser=kazaff\n\t/usr/local/inotify/bin/inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %w%f%e' -e  modify,delete,create,attrib,moved_to $src | while read files\n\tdo\n\t/usr/local/rsync/bin/rsync -vzrtopg --delete --progress --password-file=/usr/local/rsync/rsync.passwd $src $user@$host::$des >>dev/null 2>>/tmp/rsync.log  \n\tdone\n\n","slug":"rsync和inotify配置","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yo5006xgtfytj665w58","comments":1,"layout":"post","photos":[],"link":"","content":"<p>两台服务器之间需要进行文件的主从同步，常用的方案是rsync+inotify，网上可以看到一大把相关的<a href=\"http://dl528888.blog.51cto.com/2382721/771533\" target=\"_blank\" rel=\"external\">资料</a>。<br><a id=\"more\"></a><br>可我在按照前辈说的方法配置时却遇到了一些问题，首先是因为自己的懒惰，直接从网页上把shell脚本拷贝到win系统下的编辑器中，然后再放入cecntos中，结果发现执行报错，是那种很诡异的提示：</p>\n<pre><code>syntax error: unexpected end of file\n</code></pre><p>只需要在centos中用vi手动key一遍脚本即可，这个错误应该是有win-&gt;linux时编码不同导致的。</p>\n<p>接下来脚本执行成功了，可每次同步时都会报错，提示无法连接从机地址，这是由于防火墙没有放行对应端口导致的，简单的方法就是关闭防火墙：</p>\n<pre><code>service iptables stop\n</code></pre><p>最后我又发现，除了mv命令以外其他命令都可以触发同步，唯独mv不行，查了一下发现是上面前辈提供的脚本并没有监控mv对应的事件导致的，详情可见这篇<a href=\"http://www.lvtao.net/tool/inotify.html\" target=\"_blank\" rel=\"external\">博文</a>。</p>\n<p>知道原因了就很简答了，把最终脚本改成：</p>\n<pre><code>#!/bin/bash\nhost=192.168.76.135\nsrc=/www/       \ndes=web\nuser=kazaff\n/usr/local/inotify/bin/inotifywait -mrq --timefmt &apos;%d/%m/%y %H:%M&apos; --format &apos;%T %w%f%e&apos; -e  modify,delete,create,attrib,moved_to $src | while read files\ndo\n/usr/local/rsync/bin/rsync -vzrtopg --delete --progress --password-file=/usr/local/rsync/rsync.passwd $src $user@$host::$des &gt;&gt;dev/null 2&gt;&gt;/tmp/rsync.log  \ndone\n</code></pre>","excerpt":"<p>两台服务器之间需要进行文件的主从同步，常用的方案是rsync+inotify，网上可以看到一大把相关的<a href=\"http://dl528888.blog.51cto.com/2382721/771533\">资料</a>。<br>","more":"<br>可我在按照前辈说的方法配置时却遇到了一些问题，首先是因为自己的懒惰，直接从网页上把shell脚本拷贝到win系统下的编辑器中，然后再放入cecntos中，结果发现执行报错，是那种很诡异的提示：</p>\n<pre><code>syntax error: unexpected end of file\n</code></pre><p>只需要在centos中用vi手动key一遍脚本即可，这个错误应该是有win-&gt;linux时编码不同导致的。</p>\n<p>接下来脚本执行成功了，可每次同步时都会报错，提示无法连接从机地址，这是由于防火墙没有放行对应端口导致的，简单的方法就是关闭防火墙：</p>\n<pre><code>service iptables stop\n</code></pre><p>最后我又发现，除了mv命令以外其他命令都可以触发同步，唯独mv不行，查了一下发现是上面前辈提供的脚本并没有监控mv对应的事件导致的，详情可见这篇<a href=\"http://www.lvtao.net/tool/inotify.html\">博文</a>。</p>\n<p>知道原因了就很简答了，把最终脚本改成：</p>\n<pre><code>#!/bin/bash\nhost=192.168.76.135\nsrc=/www/       \ndes=web\nuser=kazaff\n/usr/local/inotify/bin/inotifywait -mrq --timefmt &apos;%d/%m/%y %H:%M&apos; --format &apos;%T %w%f%e&apos; -e  modify,delete,create,attrib,moved_to $src | while read files\ndo\n/usr/local/rsync/bin/rsync -vzrtopg --delete --progress --password-file=/usr/local/rsync/rsync.passwd $src $user@$host::$des &gt;&gt;dev/null 2&gt;&gt;/tmp/rsync.log  \ndone\n</code></pre>"},{"title":"redis中坑爹的pattern参数","date":"2014-08-29T09:22:12.000Z","_content":"\n很久没有更新博客了，久的都有点忘记自己还有个博客~~\n\n今天和同事讨论一个问题：如何从redis的多个zset中汇总并过滤数据给客户端。\n<!-- more -->\n你听起来可能有点费劲儿，我再来稍微描述一下场景：\n\n假设现在我们的redis中有2个zset，分别如下：\n\n\tone => a,80\n\t\t   b,75\n\t\t   c,60\n\t\n\ttwo => x,99\n\t\t   y,66\n\t\t   z,100\n\n不熟悉redis或者zset用法的童鞋，请自己[脑补](http://www.redis.cn/commands.html#sorted_set)。\n\n我们假设 `one` 和 `two` 这两个集合中存放的是两个班级学生的名字和总分（不考虑学生重名的问题）。那么，现在我们要在系统中显示一个列表，该列表要按照分数排列显示这两个班级的学生名单，考虑到例子里的数据并不多，那我们只能假设每一页只显示3个人。\n\n场景描述到这里，应该就足够清晰了~~\n\n解决方案很多，我们以最佳性能为基准，来评论方案的好坏。当然，最简单的是从分别从2个集合中取出所有数据，然后在应用系统中进行排序和截断。但不用多想，这种方法是最吃力不讨好的，为什么这么说？首先要从redis中拿出全部数据，这就已经不太合理了，还要自己实现一个排序算法~~我不往下说了！\n\n还可以使用zset提供的[ZUNIONSTORE](http://www.redis.cn/commands/zunionstore.html)，调用后它会在redis中创建一个新的zset集合，不过却可以帮我们提供排序和截断方法，从另一个角度想，新建的这个zset集合其实充当了“缓存”的作用，只要在应用逻辑中先检查是否存在这个key，就避免了每次都做合并操作。但，数据更新后，如何即时的更新这个“缓存”就成了问题，这涉及到定时任务的话题，就不展开了，总之知道这种方法的利弊即可。当然你也可以说每次都做合并操作，但考虑到这个合并操作的时间复杂度是 **O(N)+O(M log(M))**，再加上并发请求，我可以认为，这是在玩火，但至于redis是内部如何处理并发创建集合的，是否有多线程保护等，我就不得而知了。总之，不推荐这么做。\n\n步入正题，现在我们延伸一下场景，如果我们给出一个**学生名单{a,c,x,z}**，我要求你在上述方案2中拿到的汇总集合上做一次子集的排序获取，并按照前端页面的要求，根据分数顺序只取前三个用于显示。\n\n这个名单中的学生，由于分数是错乱的，所以你该怎么办？分别获取每一个学生在集合中的score，再在应用系统中做排序和截断？这又回到了之前的那个方案1……\n\n好吧，我们还可以构建一个zset，如下：\n\n\tlist => a,0\n            c,0\n\t\t\tx,0\n\t\t\tz,0\n\n然后执行：\n\n\t//total代表学生总集合\n\t//target表示我们临时创建的目标集合\n\tzinterstore target 2 list total\n\n这样就拿到了我们学生名单中的所有学生的zset集合，然后可以根据显示需求做分页显示了。这么做的问题我在方案2中已经提过了，就不多说了。总之觉得这么做很不尽人意！\n\n其实说到这里，也就没什么好办法了，不过翻了翻文档，发现redis2.8以后，提供了一个新的操作：**[ZSCAN](http://www.redis.cn/commands/scan.html)**。\n\n我擦，以为找到了希望，眼睛瞬间冒了绿光。尝试这么做：\n\n\tzscan total a|c|x|z 3\n\n我觉得这么做太爽了，要是真的管用，那就更好了T_T\n\n返回的结果里，毛都没有，哇哈哈哈~为什么呢？难道是我的正则写错了？换了好几种写法，还是不行。\n\n最后发现，原来，redis命令中所谓的pattern模式参数，并不支持正则这么强大的规则，我们可以在[这里](http://www.redis.cn/commands/keys.html)看到redis的pattern所支持的模式。\n\n额，貌似有点悲剧的味道~~~","source":"_posts/redis中坑爹的pattern参数.md","raw":"title: redis中坑爹的pattern参数\ndate: 2014-08-29 17:22:12\ntags: \n- pattern\n- zinterstore\n- zscan\n- zset\n- zunionstore\n- redis\ncategories: nosql\n---\n\n很久没有更新博客了，久的都有点忘记自己还有个博客~~\n\n今天和同事讨论一个问题：如何从redis的多个zset中汇总并过滤数据给客户端。\n<!-- more -->\n你听起来可能有点费劲儿，我再来稍微描述一下场景：\n\n假设现在我们的redis中有2个zset，分别如下：\n\n\tone => a,80\n\t\t   b,75\n\t\t   c,60\n\t\n\ttwo => x,99\n\t\t   y,66\n\t\t   z,100\n\n不熟悉redis或者zset用法的童鞋，请自己[脑补](http://www.redis.cn/commands.html#sorted_set)。\n\n我们假设 `one` 和 `two` 这两个集合中存放的是两个班级学生的名字和总分（不考虑学生重名的问题）。那么，现在我们要在系统中显示一个列表，该列表要按照分数排列显示这两个班级的学生名单，考虑到例子里的数据并不多，那我们只能假设每一页只显示3个人。\n\n场景描述到这里，应该就足够清晰了~~\n\n解决方案很多，我们以最佳性能为基准，来评论方案的好坏。当然，最简单的是从分别从2个集合中取出所有数据，然后在应用系统中进行排序和截断。但不用多想，这种方法是最吃力不讨好的，为什么这么说？首先要从redis中拿出全部数据，这就已经不太合理了，还要自己实现一个排序算法~~我不往下说了！\n\n还可以使用zset提供的[ZUNIONSTORE](http://www.redis.cn/commands/zunionstore.html)，调用后它会在redis中创建一个新的zset集合，不过却可以帮我们提供排序和截断方法，从另一个角度想，新建的这个zset集合其实充当了“缓存”的作用，只要在应用逻辑中先检查是否存在这个key，就避免了每次都做合并操作。但，数据更新后，如何即时的更新这个“缓存”就成了问题，这涉及到定时任务的话题，就不展开了，总之知道这种方法的利弊即可。当然你也可以说每次都做合并操作，但考虑到这个合并操作的时间复杂度是 **O(N)+O(M log(M))**，再加上并发请求，我可以认为，这是在玩火，但至于redis是内部如何处理并发创建集合的，是否有多线程保护等，我就不得而知了。总之，不推荐这么做。\n\n步入正题，现在我们延伸一下场景，如果我们给出一个**学生名单{a,c,x,z}**，我要求你在上述方案2中拿到的汇总集合上做一次子集的排序获取，并按照前端页面的要求，根据分数顺序只取前三个用于显示。\n\n这个名单中的学生，由于分数是错乱的，所以你该怎么办？分别获取每一个学生在集合中的score，再在应用系统中做排序和截断？这又回到了之前的那个方案1……\n\n好吧，我们还可以构建一个zset，如下：\n\n\tlist => a,0\n            c,0\n\t\t\tx,0\n\t\t\tz,0\n\n然后执行：\n\n\t//total代表学生总集合\n\t//target表示我们临时创建的目标集合\n\tzinterstore target 2 list total\n\n这样就拿到了我们学生名单中的所有学生的zset集合，然后可以根据显示需求做分页显示了。这么做的问题我在方案2中已经提过了，就不多说了。总之觉得这么做很不尽人意！\n\n其实说到这里，也就没什么好办法了，不过翻了翻文档，发现redis2.8以后，提供了一个新的操作：**[ZSCAN](http://www.redis.cn/commands/scan.html)**。\n\n我擦，以为找到了希望，眼睛瞬间冒了绿光。尝试这么做：\n\n\tzscan total a|c|x|z 3\n\n我觉得这么做太爽了，要是真的管用，那就更好了T_T\n\n返回的结果里，毛都没有，哇哈哈哈~为什么呢？难道是我的正则写错了？换了好几种写法，还是不行。\n\n最后发现，原来，redis命令中所谓的pattern模式参数，并不支持正则这么强大的规则，我们可以在[这里](http://www.redis.cn/commands/keys.html)看到redis的pattern所支持的模式。\n\n额，貌似有点悲剧的味道~~~","slug":"redis中坑爹的pattern参数","published":1,"updated":"2016-05-14T07:46:19.000Z","_id":"cica18yo80075gtfyp6864958","comments":1,"layout":"post","photos":[],"link":"","content":"<p>很久没有更新博客了，久的都有点忘记自己还有个博客~~</p>\n<p>今天和同事讨论一个问题：如何从redis的多个zset中汇总并过滤数据给客户端。<br><a id=\"more\"></a><br>你听起来可能有点费劲儿，我再来稍微描述一下场景：</p>\n<p>假设现在我们的redis中有2个zset，分别如下：</p>\n<pre><code>one =&gt; a,80\n       b,75\n       c,60\n\ntwo =&gt; x,99\n       y,66\n       z,100\n</code></pre><p>不熟悉redis或者zset用法的童鞋，请自己<a href=\"http://www.redis.cn/commands.html#sorted_set\" target=\"_blank\" rel=\"external\">脑补</a>。</p>\n<p>我们假设 <code>one</code> 和 <code>two</code> 这两个集合中存放的是两个班级学生的名字和总分（不考虑学生重名的问题）。那么，现在我们要在系统中显示一个列表，该列表要按照分数排列显示这两个班级的学生名单，考虑到例子里的数据并不多，那我们只能假设每一页只显示3个人。</p>\n<p>场景描述到这里，应该就足够清晰了~~</p>\n<p>解决方案很多，我们以最佳性能为基准，来评论方案的好坏。当然，最简单的是从分别从2个集合中取出所有数据，然后在应用系统中进行排序和截断。但不用多想，这种方法是最吃力不讨好的，为什么这么说？首先要从redis中拿出全部数据，这就已经不太合理了，还要自己实现一个排序算法~~我不往下说了！</p>\n<p>还可以使用zset提供的<a href=\"http://www.redis.cn/commands/zunionstore.html\" target=\"_blank\" rel=\"external\">ZUNIONSTORE</a>，调用后它会在redis中创建一个新的zset集合，不过却可以帮我们提供排序和截断方法，从另一个角度想，新建的这个zset集合其实充当了“缓存”的作用，只要在应用逻辑中先检查是否存在这个key，就避免了每次都做合并操作。但，数据更新后，如何即时的更新这个“缓存”就成了问题，这涉及到定时任务的话题，就不展开了，总之知道这种方法的利弊即可。当然你也可以说每次都做合并操作，但考虑到这个合并操作的时间复杂度是 <strong>O(N)+O(M log(M))</strong>，再加上并发请求，我可以认为，这是在玩火，但至于redis是内部如何处理并发创建集合的，是否有多线程保护等，我就不得而知了。总之，不推荐这么做。</p>\n<p>步入正题，现在我们延伸一下场景，如果我们给出一个<strong>学生名单{a,c,x,z}</strong>，我要求你在上述方案2中拿到的汇总集合上做一次子集的排序获取，并按照前端页面的要求，根据分数顺序只取前三个用于显示。</p>\n<p>这个名单中的学生，由于分数是错乱的，所以你该怎么办？分别获取每一个学生在集合中的score，再在应用系统中做排序和截断？这又回到了之前的那个方案1……</p>\n<p>好吧，我们还可以构建一个zset，如下：</p>\n<pre><code>list =&gt; a,0\n        c,0\n        x,0\n        z,0\n</code></pre><p>然后执行：</p>\n<pre><code>//total代表学生总集合\n//target表示我们临时创建的目标集合\nzinterstore target 2 list total\n</code></pre><p>这样就拿到了我们学生名单中的所有学生的zset集合，然后可以根据显示需求做分页显示了。这么做的问题我在方案2中已经提过了，就不多说了。总之觉得这么做很不尽人意！</p>\n<p>其实说到这里，也就没什么好办法了，不过翻了翻文档，发现redis2.8以后，提供了一个新的操作：<strong><a href=\"http://www.redis.cn/commands/scan.html\" target=\"_blank\" rel=\"external\">ZSCAN</a></strong>。</p>\n<p>我擦，以为找到了希望，眼睛瞬间冒了绿光。尝试这么做：</p>\n<pre><code>zscan total a|c|x|z 3\n</code></pre><p>我觉得这么做太爽了，要是真的管用，那就更好了T_T</p>\n<p>返回的结果里，毛都没有，哇哈哈哈~为什么呢？难道是我的正则写错了？换了好几种写法，还是不行。</p>\n<p>最后发现，原来，redis命令中所谓的pattern模式参数，并不支持正则这么强大的规则，我们可以在<a href=\"http://www.redis.cn/commands/keys.html\" target=\"_blank\" rel=\"external\">这里</a>看到redis的pattern所支持的模式。</p>\n<p>额，貌似有点悲剧的味道~~~</p>\n","excerpt":"<p>很久没有更新博客了，久的都有点忘记自己还有个博客~~</p>\n<p>今天和同事讨论一个问题：如何从redis的多个zset中汇总并过滤数据给客户端。<br>","more":"<br>你听起来可能有点费劲儿，我再来稍微描述一下场景：</p>\n<p>假设现在我们的redis中有2个zset，分别如下：</p>\n<pre><code>one =&gt; a,80\n       b,75\n       c,60\n\ntwo =&gt; x,99\n       y,66\n       z,100\n</code></pre><p>不熟悉redis或者zset用法的童鞋，请自己<a href=\"http://www.redis.cn/commands.html#sorted_set\">脑补</a>。</p>\n<p>我们假设 <code>one</code> 和 <code>two</code> 这两个集合中存放的是两个班级学生的名字和总分（不考虑学生重名的问题）。那么，现在我们要在系统中显示一个列表，该列表要按照分数排列显示这两个班级的学生名单，考虑到例子里的数据并不多，那我们只能假设每一页只显示3个人。</p>\n<p>场景描述到这里，应该就足够清晰了~~</p>\n<p>解决方案很多，我们以最佳性能为基准，来评论方案的好坏。当然，最简单的是从分别从2个集合中取出所有数据，然后在应用系统中进行排序和截断。但不用多想，这种方法是最吃力不讨好的，为什么这么说？首先要从redis中拿出全部数据，这就已经不太合理了，还要自己实现一个排序算法~~我不往下说了！</p>\n<p>还可以使用zset提供的<a href=\"http://www.redis.cn/commands/zunionstore.html\">ZUNIONSTORE</a>，调用后它会在redis中创建一个新的zset集合，不过却可以帮我们提供排序和截断方法，从另一个角度想，新建的这个zset集合其实充当了“缓存”的作用，只要在应用逻辑中先检查是否存在这个key，就避免了每次都做合并操作。但，数据更新后，如何即时的更新这个“缓存”就成了问题，这涉及到定时任务的话题，就不展开了，总之知道这种方法的利弊即可。当然你也可以说每次都做合并操作，但考虑到这个合并操作的时间复杂度是 <strong>O(N)+O(M log(M))</strong>，再加上并发请求，我可以认为，这是在玩火，但至于redis是内部如何处理并发创建集合的，是否有多线程保护等，我就不得而知了。总之，不推荐这么做。</p>\n<p>步入正题，现在我们延伸一下场景，如果我们给出一个<strong>学生名单{a,c,x,z}</strong>，我要求你在上述方案2中拿到的汇总集合上做一次子集的排序获取，并按照前端页面的要求，根据分数顺序只取前三个用于显示。</p>\n<p>这个名单中的学生，由于分数是错乱的，所以你该怎么办？分别获取每一个学生在集合中的score，再在应用系统中做排序和截断？这又回到了之前的那个方案1……</p>\n<p>好吧，我们还可以构建一个zset，如下：</p>\n<pre><code>list =&gt; a,0\n        c,0\n        x,0\n        z,0\n</code></pre><p>然后执行：</p>\n<pre><code>//total代表学生总集合\n//target表示我们临时创建的目标集合\nzinterstore target 2 list total\n</code></pre><p>这样就拿到了我们学生名单中的所有学生的zset集合，然后可以根据显示需求做分页显示了。这么做的问题我在方案2中已经提过了，就不多说了。总之觉得这么做很不尽人意！</p>\n<p>其实说到这里，也就没什么好办法了，不过翻了翻文档，发现redis2.8以后，提供了一个新的操作：<strong><a href=\"http://www.redis.cn/commands/scan.html\">ZSCAN</a></strong>。</p>\n<p>我擦，以为找到了希望，眼睛瞬间冒了绿光。尝试这么做：</p>\n<pre><code>zscan total a|c|x|z 3\n</code></pre><p>我觉得这么做太爽了，要是真的管用，那就更好了T_T</p>\n<p>返回的结果里，毛都没有，哇哈哈哈~为什么呢？难道是我的正则写错了？换了好几种写法，还是不行。</p>\n<p>最后发现，原来，redis命令中所谓的pattern模式参数，并不支持正则这么强大的规则，我们可以在<a href=\"http://www.redis.cn/commands/keys.html\">这里</a>看到redis的pattern所支持的模式。</p>\n<p>额，貌似有点悲剧的味道~~~</p>"},{"title":"RabbitMQ的认证","date":"2014-05-15T08:42:58.000Z","_content":"一旦要把模块上线，那么安全就成了一个关注点。这在互联网领域更是焦点话题！\n\n我在本地开启RabbitMQ Server后，用 *localhost* 去连接其默认vhost（“/”）,代码一切正常，无需提供用户名密码。\n\n但是一旦把localhost换成真实ip，RabbitMQ就会立刻提示你无权限操作（或者你尝试用localhost去连接非默认vhost也会报错）！\n<!-- more -->\n那么我们只需要为RabbitMQ创建用户即可：\n\t\n\trabbitmqctl add_user kazaff 123456\n\n如果需要创建新的vhos：\n\n\trabbitmqctl add_vhost foo\n\n然后还要把新创建的账户绑定到指定的vhost上：\n\t\n\trabbitmqctl set_permissions -p foo kazaff \".*\" \".*\" \".*\"\n\n后面3个\".*\"分别代表kazaff用户拥有对foo虚拟机的配置，写，读等权限。举个例子：\n\n1. \".*\"：表示匹配任何Exchange和queue；\n2. \" \"：表示不匹配任何Exchange和queue；\n3. \"kazaff-*\"：表示匹配任何以kazaff-开头的Exchange和queue。\n\n其他相关的命令如下：\n\n\trabbitmqctl list_permissions -p vhost  //查看vhost上用户权限列表\n\t\n\trabbitmqctl list_user_permissions user  //查看user用户在所有vhost上的配置权限列表\n\n\trabbitmqctl clear_permissions -p vhost user  //删除vhost上user的权限\n\n\n","source":"_posts/rabbitmq的认证.md","raw":"title: RabbitMQ的认证\ndate: 2014-05-15 16:42:58\ntags: rabbitmq\n---\n一旦要把模块上线，那么安全就成了一个关注点。这在互联网领域更是焦点话题！\n\n我在本地开启RabbitMQ Server后，用 *localhost* 去连接其默认vhost（“/”）,代码一切正常，无需提供用户名密码。\n\n但是一旦把localhost换成真实ip，RabbitMQ就会立刻提示你无权限操作（或者你尝试用localhost去连接非默认vhost也会报错）！\n<!-- more -->\n那么我们只需要为RabbitMQ创建用户即可：\n\t\n\trabbitmqctl add_user kazaff 123456\n\n如果需要创建新的vhos：\n\n\trabbitmqctl add_vhost foo\n\n然后还要把新创建的账户绑定到指定的vhost上：\n\t\n\trabbitmqctl set_permissions -p foo kazaff \".*\" \".*\" \".*\"\n\n后面3个\".*\"分别代表kazaff用户拥有对foo虚拟机的配置，写，读等权限。举个例子：\n\n1. \".*\"：表示匹配任何Exchange和queue；\n2. \" \"：表示不匹配任何Exchange和queue；\n3. \"kazaff-*\"：表示匹配任何以kazaff-开头的Exchange和queue。\n\n其他相关的命令如下：\n\n\trabbitmqctl list_permissions -p vhost  //查看vhost上用户权限列表\n\t\n\trabbitmqctl list_user_permissions user  //查看user用户在所有vhost上的配置权限列表\n\n\trabbitmqctl clear_permissions -p vhost user  //删除vhost上user的权限\n\n\n","slug":"rabbitmq的认证","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18yoe007igtfy3s5uqac3","comments":1,"layout":"post","photos":[],"link":"","content":"<p>一旦要把模块上线，那么安全就成了一个关注点。这在互联网领域更是焦点话题！</p>\n<p>我在本地开启RabbitMQ Server后，用 <em>localhost</em> 去连接其默认vhost（“/”）,代码一切正常，无需提供用户名密码。</p>\n<p>但是一旦把localhost换成真实ip，RabbitMQ就会立刻提示你无权限操作（或者你尝试用localhost去连接非默认vhost也会报错）！<br><a id=\"more\"></a><br>那么我们只需要为RabbitMQ创建用户即可：</p>\n<pre><code>rabbitmqctl add_user kazaff 123456\n</code></pre><p>如果需要创建新的vhos：</p>\n<pre><code>rabbitmqctl add_vhost foo\n</code></pre><p>然后还要把新创建的账户绑定到指定的vhost上：</p>\n<pre><code>rabbitmqctl set_permissions -p foo kazaff &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;\n</code></pre><p>后面3个”.*”分别代表kazaff用户拥有对foo虚拟机的配置，写，读等权限。举个例子：</p>\n<ol>\n<li>“.*”：表示匹配任何Exchange和queue；</li>\n<li>“ “：表示不匹配任何Exchange和queue；</li>\n<li>“kazaff-*”：表示匹配任何以kazaff-开头的Exchange和queue。</li>\n</ol>\n<p>其他相关的命令如下：</p>\n<pre><code>rabbitmqctl list_permissions -p vhost  //查看vhost上用户权限列表\n\nrabbitmqctl list_user_permissions user  //查看user用户在所有vhost上的配置权限列表\n\nrabbitmqctl clear_permissions -p vhost user  //删除vhost上user的权限\n</code></pre>","excerpt":"<p>一旦要把模块上线，那么安全就成了一个关注点。这在互联网领域更是焦点话题！</p>\n<p>我在本地开启RabbitMQ Server后，用 <em>localhost</em> 去连接其默认vhost（“/”）,代码一切正常，无需提供用户名密码。</p>\n<p>但是一旦把localhost换成真实ip，RabbitMQ就会立刻提示你无权限操作（或者你尝试用localhost去连接非默认vhost也会报错）！<br>","more":"<br>那么我们只需要为RabbitMQ创建用户即可：</p>\n<pre><code>rabbitmqctl add_user kazaff 123456\n</code></pre><p>如果需要创建新的vhos：</p>\n<pre><code>rabbitmqctl add_vhost foo\n</code></pre><p>然后还要把新创建的账户绑定到指定的vhost上：</p>\n<pre><code>rabbitmqctl set_permissions -p foo kazaff &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;\n</code></pre><p>后面3个”.*”分别代表kazaff用户拥有对foo虚拟机的配置，写，读等权限。举个例子：</p>\n<ol>\n<li>“.*”：表示匹配任何Exchange和queue；</li>\n<li>“ “：表示不匹配任何Exchange和queue；</li>\n<li>“kazaff-*”：表示匹配任何以kazaff-开头的Exchange和queue。</li>\n</ol>\n<p>其他相关的命令如下：</p>\n<pre><code>rabbitmqctl list_permissions -p vhost  //查看vhost上用户权限列表\n\nrabbitmqctl list_user_permissions user  //查看user用户在所有vhost上的配置权限列表\n\nrabbitmqctl clear_permissions -p vhost user  //删除vhost上user的权限\n</code></pre>"},{"title":"RabbitMQ的一些概念","date":"2014-05-15T03:35:39.000Z","_content":"早在一年多以前，我就已经开始试图在项目中异步化一些业务，例如系统的行为日志。当时选择的就是大名鼎鼎的RabbitMQ，这也是调查过不少同类产品后最终的选择，直到今天也无怨无悔~\n<!-- more -->\n最喜欢的一点并不是它的业务模型丰富，而是它支持的[语言](http://www.rabbitmq.com/devtools.html)很全面，从php到java，c/c++，甚至nodejs，都可以很方便的使用（虽然c/c++下的库文档真的很少~）！\n\n虽然我一直记着它的好，但悲剧的是早先调研它时学习的很多概念，时至今日已经忘不少了~所以感觉还是要写一篇博文记录下来，以备后用！\n\n那就一个一个来吧：\n\n##Message acknowledgment\n当队列中的任务被你的消费者进程取走后，如果消费者处理中挂掉了，那这个任务也就丢失了（虽然可能只做了一半）！很多情况下这并不是我们可以接受的，所以 *Ack* 机制出现了，它给了我们一个很优的解决方案： **当消费者连接断开后，如果RabbitMQ没有收到消费者针对该任务的Ack，那么RabbitMQ就会认为该消费者挂掉了，同时会把该任务分给其他消费者。**\n\n这里还要注意的是：**任务是没有超时限制的，也就是说只要消费者的连接有效，RabbitMQ就不会把任务再发送给其他消费者，这样可以保证某些需要耗时很久的任务正常执行。**\n\n尤其注意的是，千万不要忘记发送Ack，否则RabbitMQ会不停的把任务重复发送并且一直积累，直到崩溃~可以通过下面这个命令来查看当前没有收到Ack的消息个数：\n\n\t$ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged\n\tListing queues ...\n\thello    0       0\n\t...done.\n\n\n##Message durability\n一般情况下当RabbitMQ退出或崩溃，那么队列和任务将会丢失，这当然是不能容忍的。RabbitMQ提供了持久化方案，只需要把队列声明成持久的即可（注意，RabbitMQ并不允许修改当前已存在队列的持久性）。\n\n此外我们还需要把消息也设置成持久化的，这些都有对应的属性参数让我们来设置。\n\n但注意，RabbitMQ并不能百分之百保证消息一定不会丢失，因为为了提升性能，RabbitMQ会把消息暂存在内存缓存中，直到达到阀值才会批量持久化到磁盘，也就是说如果在持久化到磁盘之前RabbitMQ崩溃了，那么就会丢失一小部分数据，这对于大多数场景来说并不是不可接受的，如果确实需要保证任务绝对不丢失，那么应该使用事务机制。\n\n##Round-robin dispatching\n这个机制是RabbitMQ最常用业务模型中的。一般我们选择异步任务，除了降低模块间的依赖外，还有一个理由就是有效规避大并发负载，尤其是针对http。\n\n举个场景，网站上的找回密码功能，系统会向对应用户的邮箱发送修改密码的连接。如果是同步流程的话，大量用户同时请求该功能，由于发送邮件比较耗时，那么你的web服务器会持续等待，这个时候就可能会被大量涌入的请求搞死，即便是没死，也会大大影响其响应速度。\n\n那么如果使用异步的话，我们可以把找回密码的请求都存到队列里，然后由后台进程逐步完成邮件发送的任务，web服务器就可以快速响应用户。\n\n好，说了这么多，那么到底 *Round-robin* 是做什么的？看图：\n\n![](http://pic.yupoo.com/kazaff/DKUd6IvQ/b0EV.png)\n\n上图中我们有两个消费者（C1，C2），它们同时从队列中领取任务并执行，默认情况下RabbitMQ会按照顺序依次把消息发送给C1和C2，这样可以保证每个消费者领到的任务个数都是相同的，这种分配任务的方式就是Round-robin。\n\n任务耗时不均匀的情况下，这种方式可能并不是最佳的。\n\n##Fair dispatch\n上面说到了，由于默认情况下RabbitMQ不会去管任务到底是什么类型的（特指其耗时情况），它只会一味的按照 *Round-robin* 的算法把队列中的消息平均分配给所有消费者。还是上面的那个图，我们假设队列中的任务很奇葩，奇数任务是耗时久的，偶数任务是耗时低的，那么C1可能一直很忙，而C2则几乎没事儿可做！\n\n听上去很不公平是吧？这就是因为 *Round-robin* 机制并不考虑每个消费者当前正在处理的任务数（换句话说，就是当前该消费者仍没有Ack的任务数）。\n\n我们可以设置 *prefetch* 来避免上述情况，该设置可以告诉RabbitMQ：直到该消费者处理完当前指定数目的任务之前，不要再给消费者分配新任务（这是依赖统计该消费者的Ack情况来实现的，可见两者必须欧同时开启哦）。\n\n如果当前所有消费者都在忙，那么任务将会阻塞在队列中，你可能需要增加消费者数量来避免大量任务被阻塞。\n\n##Exchanges\n上图中的那种架构并不是RabbitMQ推荐的，为什么这么说呢？RabbitMQ核心思想是生产者绝对不应该直接将任务投递到目标队列中，换句话说，生产者根本不需要知道任务最终应该会投递到哪里。\n\n取而代之的，生产者只需要把任务发送到一个 *Exchange* 中即可，如下图：\n\n![](http://pic.yupoo.com/kazaff/DKZ3KKeJ/9itDc.png)\n\nExchange 非常容易理解，它负责根据映射关系和投递模型把任务投递到队列中，有效的投递模型有：direct，topic，headers，fanout。官方提供的例子中就已经把这些模型讲的很清楚了。\n\n剩下要做的就是把Exchange和Queue绑定到一起了，**如果向一个没有绑定任何队列的Exchange发送任务，则任务都会被丢弃。**\n\n你可以通过下面的命令来查看绑定关系：\n\n\t$ sudo rabbitmqctl list_bindings\n\tListing bindings ...\n\tlogs    exchange        amq.gen-JzTY20BRgKO-HjmUJj0wLg  queue           []\n\tlogs    exchange        amq.gen-vso0PVvyiRIL2WoV3i48Yg  queue           []\n\t...done.\n\n##Routing\n其实这个机制是建立在 *Exchanges* 上的，有了Route，我们就可以实现根据类别，让Exchange来选择性的分发任务给匹配的队列。\n\n要做到这点，只需要在为Exchange绑定queue时设置一个 *routingKey* 即可。注意，**fanout类型的exchanges会忽略这个值，毕竟这种类型的exchange要实现的是广播机制。**\n\n![](http://pic.yupoo.com/kazaff/DKZfdwV1/8GjaF.png)\n\n如上图，我们这次使用的是 *direct* 投递模型的Exchage，这种模型下的路由逻辑非常简单：根据绑定时声明的routingKey来分发任务。\n\n另外值得一提的是，绑定非常灵活，不仅可以像上图那样为一个队列绑定多个不同的routingKey，也可以为Exchage绑定多个队列同时监听相同的routingKey（这等同于fanout模型）。\n\n##Topic exchange\n我承认，可能排版上有点乱，因为按道理说这个概念应该合并到 *Exchanges* 中，但是由于它依赖 *Routing* ，所以我决定采用官方提供的学习步骤。\n\n我们已经了解过direct，fanout两种投递模型。那么topic到底又是什么呢？\n\n简单来说，topic只是为routingKey设置了一个规则（任意单词来描述主题，以\".\"分割为不同层级，长度不能超过255位），有点命名空间的味道，这里称之为主题可能更加合适一些。\n\n在规则中还提供了两个关键字：\n\n1. *\\**：可以匹配任意1个单词；\n2. *#*：可以匹配任意0个或多个单词。\n\n有点正则的味道，不过确实在direct模型的基础上进一步提升了灵活性。举个例子，如果我们用这么一个routingKey：\\*.love.\\*，那么投递任务时，任何这种模式主题的任务都会投递到对应队列，例如：everyone.love.kazaff。再如：kazaff.#，这意味着会匹配kazaff.me.is.cool，也会匹配kazaff.me，等等。\n\n**如果发送任务用的routingKey不能匹配声明的模式，那么任务就会被丢弃。**\n\n你可以把模式只定义为#来模仿fanout模型，也可以把模式定义为不包含\\*和\\#的具体字符串来模仿direct模型。\n\n##Message properties\n在AMQP协议中为每个任务预定义了14个属性，大多数属性都非常少用，常用的4个如下：\n\n1. deliveryMode：标识任务的持久性；\n2. contentType：用于描述任务数据的MIME-TYPE，例如application/json；\n3. replyTo：用于命名一个callback队列；\n4. correlationId：用于标识RPC任务的请求与响应的配对编号。\n\n可想到为每一次RPC请求都创建一个回调队列是非常低效的。更高效的做法是为每一个发出RPC请求的客户端创建一个回调队列，但这又产生了一个新问题：**如何知道回调队列中的响应是对应哪一个请求的呢？**\n\n这就是 *correlationId* 属性存在的意义，我们只要为每个请求设置一个唯一的值，我们就能在从回调队列中取到响应数据后根据correlationId找到对应的请求。\n\n如果我们收到一个未知的correlationId响应，只需要忽略它既可。你可能会想，怎么可能收到未知的响应？确实，这种情况发生的概率不高，如下图：\n\n![](http://pic.yupoo.com/kazaff/DKZLeZiI/Zjdye.png)\n\n假设S从rpc_queue中取得RPC任务后，进行处理，然后把响应发送给reply_to队列，此时S挂了，它还没来得及向rpc_queue发送ack！但是你知道的，其实整个RPC已经可以算完成了！\n\n这个时候S重启完毕，它会再次取到刚才的那个RPC任务，再次处理，再次把结果发送给reply_to队列，这次它挺了下来没死机，并把ack发送到rpc_queue。但是，C端早已经在S第一次死机之前就拿到结果了，第二次发来的响应任务C自然找不到对应的correlationId。我这么说，你懂了么？\n\n---\n当目前为止，我已经把我认为重要的概念都提到了，有啥问题，私下讨论吧！","source":"_posts/rabbitmq的一些概念.md","raw":"title: RabbitMQ的一些概念\ndate: 2014-05-15 11:35:39\ntags: rabbitmq\n---\n早在一年多以前，我就已经开始试图在项目中异步化一些业务，例如系统的行为日志。当时选择的就是大名鼎鼎的RabbitMQ，这也是调查过不少同类产品后最终的选择，直到今天也无怨无悔~\n<!-- more -->\n最喜欢的一点并不是它的业务模型丰富，而是它支持的[语言](http://www.rabbitmq.com/devtools.html)很全面，从php到java，c/c++，甚至nodejs，都可以很方便的使用（虽然c/c++下的库文档真的很少~）！\n\n虽然我一直记着它的好，但悲剧的是早先调研它时学习的很多概念，时至今日已经忘不少了~所以感觉还是要写一篇博文记录下来，以备后用！\n\n那就一个一个来吧：\n\n##Message acknowledgment\n当队列中的任务被你的消费者进程取走后，如果消费者处理中挂掉了，那这个任务也就丢失了（虽然可能只做了一半）！很多情况下这并不是我们可以接受的，所以 *Ack* 机制出现了，它给了我们一个很优的解决方案： **当消费者连接断开后，如果RabbitMQ没有收到消费者针对该任务的Ack，那么RabbitMQ就会认为该消费者挂掉了，同时会把该任务分给其他消费者。**\n\n这里还要注意的是：**任务是没有超时限制的，也就是说只要消费者的连接有效，RabbitMQ就不会把任务再发送给其他消费者，这样可以保证某些需要耗时很久的任务正常执行。**\n\n尤其注意的是，千万不要忘记发送Ack，否则RabbitMQ会不停的把任务重复发送并且一直积累，直到崩溃~可以通过下面这个命令来查看当前没有收到Ack的消息个数：\n\n\t$ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged\n\tListing queues ...\n\thello    0       0\n\t...done.\n\n\n##Message durability\n一般情况下当RabbitMQ退出或崩溃，那么队列和任务将会丢失，这当然是不能容忍的。RabbitMQ提供了持久化方案，只需要把队列声明成持久的即可（注意，RabbitMQ并不允许修改当前已存在队列的持久性）。\n\n此外我们还需要把消息也设置成持久化的，这些都有对应的属性参数让我们来设置。\n\n但注意，RabbitMQ并不能百分之百保证消息一定不会丢失，因为为了提升性能，RabbitMQ会把消息暂存在内存缓存中，直到达到阀值才会批量持久化到磁盘，也就是说如果在持久化到磁盘之前RabbitMQ崩溃了，那么就会丢失一小部分数据，这对于大多数场景来说并不是不可接受的，如果确实需要保证任务绝对不丢失，那么应该使用事务机制。\n\n##Round-robin dispatching\n这个机制是RabbitMQ最常用业务模型中的。一般我们选择异步任务，除了降低模块间的依赖外，还有一个理由就是有效规避大并发负载，尤其是针对http。\n\n举个场景，网站上的找回密码功能，系统会向对应用户的邮箱发送修改密码的连接。如果是同步流程的话，大量用户同时请求该功能，由于发送邮件比较耗时，那么你的web服务器会持续等待，这个时候就可能会被大量涌入的请求搞死，即便是没死，也会大大影响其响应速度。\n\n那么如果使用异步的话，我们可以把找回密码的请求都存到队列里，然后由后台进程逐步完成邮件发送的任务，web服务器就可以快速响应用户。\n\n好，说了这么多，那么到底 *Round-robin* 是做什么的？看图：\n\n![](http://pic.yupoo.com/kazaff/DKUd6IvQ/b0EV.png)\n\n上图中我们有两个消费者（C1，C2），它们同时从队列中领取任务并执行，默认情况下RabbitMQ会按照顺序依次把消息发送给C1和C2，这样可以保证每个消费者领到的任务个数都是相同的，这种分配任务的方式就是Round-robin。\n\n任务耗时不均匀的情况下，这种方式可能并不是最佳的。\n\n##Fair dispatch\n上面说到了，由于默认情况下RabbitMQ不会去管任务到底是什么类型的（特指其耗时情况），它只会一味的按照 *Round-robin* 的算法把队列中的消息平均分配给所有消费者。还是上面的那个图，我们假设队列中的任务很奇葩，奇数任务是耗时久的，偶数任务是耗时低的，那么C1可能一直很忙，而C2则几乎没事儿可做！\n\n听上去很不公平是吧？这就是因为 *Round-robin* 机制并不考虑每个消费者当前正在处理的任务数（换句话说，就是当前该消费者仍没有Ack的任务数）。\n\n我们可以设置 *prefetch* 来避免上述情况，该设置可以告诉RabbitMQ：直到该消费者处理完当前指定数目的任务之前，不要再给消费者分配新任务（这是依赖统计该消费者的Ack情况来实现的，可见两者必须欧同时开启哦）。\n\n如果当前所有消费者都在忙，那么任务将会阻塞在队列中，你可能需要增加消费者数量来避免大量任务被阻塞。\n\n##Exchanges\n上图中的那种架构并不是RabbitMQ推荐的，为什么这么说呢？RabbitMQ核心思想是生产者绝对不应该直接将任务投递到目标队列中，换句话说，生产者根本不需要知道任务最终应该会投递到哪里。\n\n取而代之的，生产者只需要把任务发送到一个 *Exchange* 中即可，如下图：\n\n![](http://pic.yupoo.com/kazaff/DKZ3KKeJ/9itDc.png)\n\nExchange 非常容易理解，它负责根据映射关系和投递模型把任务投递到队列中，有效的投递模型有：direct，topic，headers，fanout。官方提供的例子中就已经把这些模型讲的很清楚了。\n\n剩下要做的就是把Exchange和Queue绑定到一起了，**如果向一个没有绑定任何队列的Exchange发送任务，则任务都会被丢弃。**\n\n你可以通过下面的命令来查看绑定关系：\n\n\t$ sudo rabbitmqctl list_bindings\n\tListing bindings ...\n\tlogs    exchange        amq.gen-JzTY20BRgKO-HjmUJj0wLg  queue           []\n\tlogs    exchange        amq.gen-vso0PVvyiRIL2WoV3i48Yg  queue           []\n\t...done.\n\n##Routing\n其实这个机制是建立在 *Exchanges* 上的，有了Route，我们就可以实现根据类别，让Exchange来选择性的分发任务给匹配的队列。\n\n要做到这点，只需要在为Exchange绑定queue时设置一个 *routingKey* 即可。注意，**fanout类型的exchanges会忽略这个值，毕竟这种类型的exchange要实现的是广播机制。**\n\n![](http://pic.yupoo.com/kazaff/DKZfdwV1/8GjaF.png)\n\n如上图，我们这次使用的是 *direct* 投递模型的Exchage，这种模型下的路由逻辑非常简单：根据绑定时声明的routingKey来分发任务。\n\n另外值得一提的是，绑定非常灵活，不仅可以像上图那样为一个队列绑定多个不同的routingKey，也可以为Exchage绑定多个队列同时监听相同的routingKey（这等同于fanout模型）。\n\n##Topic exchange\n我承认，可能排版上有点乱，因为按道理说这个概念应该合并到 *Exchanges* 中，但是由于它依赖 *Routing* ，所以我决定采用官方提供的学习步骤。\n\n我们已经了解过direct，fanout两种投递模型。那么topic到底又是什么呢？\n\n简单来说，topic只是为routingKey设置了一个规则（任意单词来描述主题，以\".\"分割为不同层级，长度不能超过255位），有点命名空间的味道，这里称之为主题可能更加合适一些。\n\n在规则中还提供了两个关键字：\n\n1. *\\**：可以匹配任意1个单词；\n2. *#*：可以匹配任意0个或多个单词。\n\n有点正则的味道，不过确实在direct模型的基础上进一步提升了灵活性。举个例子，如果我们用这么一个routingKey：\\*.love.\\*，那么投递任务时，任何这种模式主题的任务都会投递到对应队列，例如：everyone.love.kazaff。再如：kazaff.#，这意味着会匹配kazaff.me.is.cool，也会匹配kazaff.me，等等。\n\n**如果发送任务用的routingKey不能匹配声明的模式，那么任务就会被丢弃。**\n\n你可以把模式只定义为#来模仿fanout模型，也可以把模式定义为不包含\\*和\\#的具体字符串来模仿direct模型。\n\n##Message properties\n在AMQP协议中为每个任务预定义了14个属性，大多数属性都非常少用，常用的4个如下：\n\n1. deliveryMode：标识任务的持久性；\n2. contentType：用于描述任务数据的MIME-TYPE，例如application/json；\n3. replyTo：用于命名一个callback队列；\n4. correlationId：用于标识RPC任务的请求与响应的配对编号。\n\n可想到为每一次RPC请求都创建一个回调队列是非常低效的。更高效的做法是为每一个发出RPC请求的客户端创建一个回调队列，但这又产生了一个新问题：**如何知道回调队列中的响应是对应哪一个请求的呢？**\n\n这就是 *correlationId* 属性存在的意义，我们只要为每个请求设置一个唯一的值，我们就能在从回调队列中取到响应数据后根据correlationId找到对应的请求。\n\n如果我们收到一个未知的correlationId响应，只需要忽略它既可。你可能会想，怎么可能收到未知的响应？确实，这种情况发生的概率不高，如下图：\n\n![](http://pic.yupoo.com/kazaff/DKZLeZiI/Zjdye.png)\n\n假设S从rpc_queue中取得RPC任务后，进行处理，然后把响应发送给reply_to队列，此时S挂了，它还没来得及向rpc_queue发送ack！但是你知道的，其实整个RPC已经可以算完成了！\n\n这个时候S重启完毕，它会再次取到刚才的那个RPC任务，再次处理，再次把结果发送给reply_to队列，这次它挺了下来没死机，并把ack发送到rpc_queue。但是，C端早已经在S第一次死机之前就拿到结果了，第二次发来的响应任务C自然找不到对应的correlationId。我这么说，你懂了么？\n\n---\n当目前为止，我已经把我认为重要的概念都提到了，有啥问题，私下讨论吧！","slug":"rabbitmq的一些概念","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18yoi007lgtfyyhoic5si","comments":1,"layout":"post","photos":[],"link":"","content":"<p>早在一年多以前，我就已经开始试图在项目中异步化一些业务，例如系统的行为日志。当时选择的就是大名鼎鼎的RabbitMQ，这也是调查过不少同类产品后最终的选择，直到今天也无怨无悔~<br><a id=\"more\"></a><br>最喜欢的一点并不是它的业务模型丰富，而是它支持的<a href=\"http://www.rabbitmq.com/devtools.html\" target=\"_blank\" rel=\"external\">语言</a>很全面，从php到java，c/c++，甚至nodejs，都可以很方便的使用（虽然c/c++下的库文档真的很少~）！</p>\n<p>虽然我一直记着它的好，但悲剧的是早先调研它时学习的很多概念，时至今日已经忘不少了~所以感觉还是要写一篇博文记录下来，以备后用！</p>\n<p>那就一个一个来吧：</p>\n<p>##Message acknowledgment<br>当队列中的任务被你的消费者进程取走后，如果消费者处理中挂掉了，那这个任务也就丢失了（虽然可能只做了一半）！很多情况下这并不是我们可以接受的，所以 <em>Ack</em> 机制出现了，它给了我们一个很优的解决方案： <strong>当消费者连接断开后，如果RabbitMQ没有收到消费者针对该任务的Ack，那么RabbitMQ就会认为该消费者挂掉了，同时会把该任务分给其他消费者。</strong></p>\n<p>这里还要注意的是：<strong>任务是没有超时限制的，也就是说只要消费者的连接有效，RabbitMQ就不会把任务再发送给其他消费者，这样可以保证某些需要耗时很久的任务正常执行。</strong></p>\n<p>尤其注意的是，千万不要忘记发送Ack，否则RabbitMQ会不停的把任务重复发送并且一直积累，直到崩溃~可以通过下面这个命令来查看当前没有收到Ack的消息个数：</p>\n<pre><code>$ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged\nListing queues ...\nhello    0       0\n...done.\n</code></pre><p>##Message durability<br>一般情况下当RabbitMQ退出或崩溃，那么队列和任务将会丢失，这当然是不能容忍的。RabbitMQ提供了持久化方案，只需要把队列声明成持久的即可（注意，RabbitMQ并不允许修改当前已存在队列的持久性）。</p>\n<p>此外我们还需要把消息也设置成持久化的，这些都有对应的属性参数让我们来设置。</p>\n<p>但注意，RabbitMQ并不能百分之百保证消息一定不会丢失，因为为了提升性能，RabbitMQ会把消息暂存在内存缓存中，直到达到阀值才会批量持久化到磁盘，也就是说如果在持久化到磁盘之前RabbitMQ崩溃了，那么就会丢失一小部分数据，这对于大多数场景来说并不是不可接受的，如果确实需要保证任务绝对不丢失，那么应该使用事务机制。</p>\n<p>##Round-robin dispatching<br>这个机制是RabbitMQ最常用业务模型中的。一般我们选择异步任务，除了降低模块间的依赖外，还有一个理由就是有效规避大并发负载，尤其是针对http。</p>\n<p>举个场景，网站上的找回密码功能，系统会向对应用户的邮箱发送修改密码的连接。如果是同步流程的话，大量用户同时请求该功能，由于发送邮件比较耗时，那么你的web服务器会持续等待，这个时候就可能会被大量涌入的请求搞死，即便是没死，也会大大影响其响应速度。</p>\n<p>那么如果使用异步的话，我们可以把找回密码的请求都存到队列里，然后由后台进程逐步完成邮件发送的任务，web服务器就可以快速响应用户。</p>\n<p>好，说了这么多，那么到底 <em>Round-robin</em> 是做什么的？看图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKUd6IvQ/b0EV.png\" alt=\"\"></p>\n<p>上图中我们有两个消费者（C1，C2），它们同时从队列中领取任务并执行，默认情况下RabbitMQ会按照顺序依次把消息发送给C1和C2，这样可以保证每个消费者领到的任务个数都是相同的，这种分配任务的方式就是Round-robin。</p>\n<p>任务耗时不均匀的情况下，这种方式可能并不是最佳的。</p>\n<p>##Fair dispatch<br>上面说到了，由于默认情况下RabbitMQ不会去管任务到底是什么类型的（特指其耗时情况），它只会一味的按照 <em>Round-robin</em> 的算法把队列中的消息平均分配给所有消费者。还是上面的那个图，我们假设队列中的任务很奇葩，奇数任务是耗时久的，偶数任务是耗时低的，那么C1可能一直很忙，而C2则几乎没事儿可做！</p>\n<p>听上去很不公平是吧？这就是因为 <em>Round-robin</em> 机制并不考虑每个消费者当前正在处理的任务数（换句话说，就是当前该消费者仍没有Ack的任务数）。</p>\n<p>我们可以设置 <em>prefetch</em> 来避免上述情况，该设置可以告诉RabbitMQ：直到该消费者处理完当前指定数目的任务之前，不要再给消费者分配新任务（这是依赖统计该消费者的Ack情况来实现的，可见两者必须欧同时开启哦）。</p>\n<p>如果当前所有消费者都在忙，那么任务将会阻塞在队列中，你可能需要增加消费者数量来避免大量任务被阻塞。</p>\n<p>##Exchanges<br>上图中的那种架构并不是RabbitMQ推荐的，为什么这么说呢？RabbitMQ核心思想是生产者绝对不应该直接将任务投递到目标队列中，换句话说，生产者根本不需要知道任务最终应该会投递到哪里。</p>\n<p>取而代之的，生产者只需要把任务发送到一个 <em>Exchange</em> 中即可，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKZ3KKeJ/9itDc.png\" alt=\"\"></p>\n<p>Exchange 非常容易理解，它负责根据映射关系和投递模型把任务投递到队列中，有效的投递模型有：direct，topic，headers，fanout。官方提供的例子中就已经把这些模型讲的很清楚了。</p>\n<p>剩下要做的就是把Exchange和Queue绑定到一起了，<strong>如果向一个没有绑定任何队列的Exchange发送任务，则任务都会被丢弃。</strong></p>\n<p>你可以通过下面的命令来查看绑定关系：</p>\n<pre><code>$ sudo rabbitmqctl list_bindings\nListing bindings ...\nlogs    exchange        amq.gen-JzTY20BRgKO-HjmUJj0wLg  queue           []\nlogs    exchange        amq.gen-vso0PVvyiRIL2WoV3i48Yg  queue           []\n...done.\n</code></pre><p>##Routing<br>其实这个机制是建立在 <em>Exchanges</em> 上的，有了Route，我们就可以实现根据类别，让Exchange来选择性的分发任务给匹配的队列。</p>\n<p>要做到这点，只需要在为Exchange绑定queue时设置一个 <em>routingKey</em> 即可。注意，<strong>fanout类型的exchanges会忽略这个值，毕竟这种类型的exchange要实现的是广播机制。</strong></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKZfdwV1/8GjaF.png\" alt=\"\"></p>\n<p>如上图，我们这次使用的是 <em>direct</em> 投递模型的Exchage，这种模型下的路由逻辑非常简单：根据绑定时声明的routingKey来分发任务。</p>\n<p>另外值得一提的是，绑定非常灵活，不仅可以像上图那样为一个队列绑定多个不同的routingKey，也可以为Exchage绑定多个队列同时监听相同的routingKey（这等同于fanout模型）。</p>\n<p>##Topic exchange<br>我承认，可能排版上有点乱，因为按道理说这个概念应该合并到 <em>Exchanges</em> 中，但是由于它依赖 <em>Routing</em> ，所以我决定采用官方提供的学习步骤。</p>\n<p>我们已经了解过direct，fanout两种投递模型。那么topic到底又是什么呢？</p>\n<p>简单来说，topic只是为routingKey设置了一个规则（任意单词来描述主题，以”.”分割为不同层级，长度不能超过255位），有点命名空间的味道，这里称之为主题可能更加合适一些。</p>\n<p>在规则中还提供了两个关键字：</p>\n<ol>\n<li><em>*</em>：可以匹配任意1个单词；</li>\n<li><em>#</em>：可以匹配任意0个或多个单词。</li>\n</ol>\n<p>有点正则的味道，不过确实在direct模型的基础上进一步提升了灵活性。举个例子，如果我们用这么一个routingKey：*.love.*，那么投递任务时，任何这种模式主题的任务都会投递到对应队列，例如：everyone.love.kazaff。再如：kazaff.#，这意味着会匹配kazaff.me.is.cool，也会匹配kazaff.me，等等。</p>\n<p><strong>如果发送任务用的routingKey不能匹配声明的模式，那么任务就会被丢弃。</strong></p>\n<p>你可以把模式只定义为#来模仿fanout模型，也可以把模式定义为不包含*和#的具体字符串来模仿direct模型。</p>\n<p>##Message properties<br>在AMQP协议中为每个任务预定义了14个属性，大多数属性都非常少用，常用的4个如下：</p>\n<ol>\n<li>deliveryMode：标识任务的持久性；</li>\n<li>contentType：用于描述任务数据的MIME-TYPE，例如application/json；</li>\n<li>replyTo：用于命名一个callback队列；</li>\n<li>correlationId：用于标识RPC任务的请求与响应的配对编号。</li>\n</ol>\n<p>可想到为每一次RPC请求都创建一个回调队列是非常低效的。更高效的做法是为每一个发出RPC请求的客户端创建一个回调队列，但这又产生了一个新问题：<strong>如何知道回调队列中的响应是对应哪一个请求的呢？</strong></p>\n<p>这就是 <em>correlationId</em> 属性存在的意义，我们只要为每个请求设置一个唯一的值，我们就能在从回调队列中取到响应数据后根据correlationId找到对应的请求。</p>\n<p>如果我们收到一个未知的correlationId响应，只需要忽略它既可。你可能会想，怎么可能收到未知的响应？确实，这种情况发生的概率不高，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKZLeZiI/Zjdye.png\" alt=\"\"></p>\n<p>假设S从rpc_queue中取得RPC任务后，进行处理，然后把响应发送给reply_to队列，此时S挂了，它还没来得及向rpc_queue发送ack！但是你知道的，其实整个RPC已经可以算完成了！</p>\n<p>这个时候S重启完毕，它会再次取到刚才的那个RPC任务，再次处理，再次把结果发送给reply_to队列，这次它挺了下来没死机，并把ack发送到rpc_queue。但是，C端早已经在S第一次死机之前就拿到结果了，第二次发来的响应任务C自然找不到对应的correlationId。我这么说，你懂了么？</p>\n<hr>\n<p>当目前为止，我已经把我认为重要的概念都提到了，有啥问题，私下讨论吧！</p>\n","excerpt":"<p>早在一年多以前，我就已经开始试图在项目中异步化一些业务，例如系统的行为日志。当时选择的就是大名鼎鼎的RabbitMQ，这也是调查过不少同类产品后最终的选择，直到今天也无怨无悔~<br>","more":"<br>最喜欢的一点并不是它的业务模型丰富，而是它支持的<a href=\"http://www.rabbitmq.com/devtools.html\">语言</a>很全面，从php到java，c/c++，甚至nodejs，都可以很方便的使用（虽然c/c++下的库文档真的很少~）！</p>\n<p>虽然我一直记着它的好，但悲剧的是早先调研它时学习的很多概念，时至今日已经忘不少了~所以感觉还是要写一篇博文记录下来，以备后用！</p>\n<p>那就一个一个来吧：</p>\n<p>##Message acknowledgment<br>当队列中的任务被你的消费者进程取走后，如果消费者处理中挂掉了，那这个任务也就丢失了（虽然可能只做了一半）！很多情况下这并不是我们可以接受的，所以 <em>Ack</em> 机制出现了，它给了我们一个很优的解决方案： <strong>当消费者连接断开后，如果RabbitMQ没有收到消费者针对该任务的Ack，那么RabbitMQ就会认为该消费者挂掉了，同时会把该任务分给其他消费者。</strong></p>\n<p>这里还要注意的是：<strong>任务是没有超时限制的，也就是说只要消费者的连接有效，RabbitMQ就不会把任务再发送给其他消费者，这样可以保证某些需要耗时很久的任务正常执行。</strong></p>\n<p>尤其注意的是，千万不要忘记发送Ack，否则RabbitMQ会不停的把任务重复发送并且一直积累，直到崩溃~可以通过下面这个命令来查看当前没有收到Ack的消息个数：</p>\n<pre><code>$ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged\nListing queues ...\nhello    0       0\n...done.\n</code></pre><p>##Message durability<br>一般情况下当RabbitMQ退出或崩溃，那么队列和任务将会丢失，这当然是不能容忍的。RabbitMQ提供了持久化方案，只需要把队列声明成持久的即可（注意，RabbitMQ并不允许修改当前已存在队列的持久性）。</p>\n<p>此外我们还需要把消息也设置成持久化的，这些都有对应的属性参数让我们来设置。</p>\n<p>但注意，RabbitMQ并不能百分之百保证消息一定不会丢失，因为为了提升性能，RabbitMQ会把消息暂存在内存缓存中，直到达到阀值才会批量持久化到磁盘，也就是说如果在持久化到磁盘之前RabbitMQ崩溃了，那么就会丢失一小部分数据，这对于大多数场景来说并不是不可接受的，如果确实需要保证任务绝对不丢失，那么应该使用事务机制。</p>\n<p>##Round-robin dispatching<br>这个机制是RabbitMQ最常用业务模型中的。一般我们选择异步任务，除了降低模块间的依赖外，还有一个理由就是有效规避大并发负载，尤其是针对http。</p>\n<p>举个场景，网站上的找回密码功能，系统会向对应用户的邮箱发送修改密码的连接。如果是同步流程的话，大量用户同时请求该功能，由于发送邮件比较耗时，那么你的web服务器会持续等待，这个时候就可能会被大量涌入的请求搞死，即便是没死，也会大大影响其响应速度。</p>\n<p>那么如果使用异步的话，我们可以把找回密码的请求都存到队列里，然后由后台进程逐步完成邮件发送的任务，web服务器就可以快速响应用户。</p>\n<p>好，说了这么多，那么到底 <em>Round-robin</em> 是做什么的？看图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKUd6IvQ/b0EV.png\" alt=\"\"></p>\n<p>上图中我们有两个消费者（C1，C2），它们同时从队列中领取任务并执行，默认情况下RabbitMQ会按照顺序依次把消息发送给C1和C2，这样可以保证每个消费者领到的任务个数都是相同的，这种分配任务的方式就是Round-robin。</p>\n<p>任务耗时不均匀的情况下，这种方式可能并不是最佳的。</p>\n<p>##Fair dispatch<br>上面说到了，由于默认情况下RabbitMQ不会去管任务到底是什么类型的（特指其耗时情况），它只会一味的按照 <em>Round-robin</em> 的算法把队列中的消息平均分配给所有消费者。还是上面的那个图，我们假设队列中的任务很奇葩，奇数任务是耗时久的，偶数任务是耗时低的，那么C1可能一直很忙，而C2则几乎没事儿可做！</p>\n<p>听上去很不公平是吧？这就是因为 <em>Round-robin</em> 机制并不考虑每个消费者当前正在处理的任务数（换句话说，就是当前该消费者仍没有Ack的任务数）。</p>\n<p>我们可以设置 <em>prefetch</em> 来避免上述情况，该设置可以告诉RabbitMQ：直到该消费者处理完当前指定数目的任务之前，不要再给消费者分配新任务（这是依赖统计该消费者的Ack情况来实现的，可见两者必须欧同时开启哦）。</p>\n<p>如果当前所有消费者都在忙，那么任务将会阻塞在队列中，你可能需要增加消费者数量来避免大量任务被阻塞。</p>\n<p>##Exchanges<br>上图中的那种架构并不是RabbitMQ推荐的，为什么这么说呢？RabbitMQ核心思想是生产者绝对不应该直接将任务投递到目标队列中，换句话说，生产者根本不需要知道任务最终应该会投递到哪里。</p>\n<p>取而代之的，生产者只需要把任务发送到一个 <em>Exchange</em> 中即可，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKZ3KKeJ/9itDc.png\" alt=\"\"></p>\n<p>Exchange 非常容易理解，它负责根据映射关系和投递模型把任务投递到队列中，有效的投递模型有：direct，topic，headers，fanout。官方提供的例子中就已经把这些模型讲的很清楚了。</p>\n<p>剩下要做的就是把Exchange和Queue绑定到一起了，<strong>如果向一个没有绑定任何队列的Exchange发送任务，则任务都会被丢弃。</strong></p>\n<p>你可以通过下面的命令来查看绑定关系：</p>\n<pre><code>$ sudo rabbitmqctl list_bindings\nListing bindings ...\nlogs    exchange        amq.gen-JzTY20BRgKO-HjmUJj0wLg  queue           []\nlogs    exchange        amq.gen-vso0PVvyiRIL2WoV3i48Yg  queue           []\n...done.\n</code></pre><p>##Routing<br>其实这个机制是建立在 <em>Exchanges</em> 上的，有了Route，我们就可以实现根据类别，让Exchange来选择性的分发任务给匹配的队列。</p>\n<p>要做到这点，只需要在为Exchange绑定queue时设置一个 <em>routingKey</em> 即可。注意，<strong>fanout类型的exchanges会忽略这个值，毕竟这种类型的exchange要实现的是广播机制。</strong></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKZfdwV1/8GjaF.png\" alt=\"\"></p>\n<p>如上图，我们这次使用的是 <em>direct</em> 投递模型的Exchage，这种模型下的路由逻辑非常简单：根据绑定时声明的routingKey来分发任务。</p>\n<p>另外值得一提的是，绑定非常灵活，不仅可以像上图那样为一个队列绑定多个不同的routingKey，也可以为Exchage绑定多个队列同时监听相同的routingKey（这等同于fanout模型）。</p>\n<p>##Topic exchange<br>我承认，可能排版上有点乱，因为按道理说这个概念应该合并到 <em>Exchanges</em> 中，但是由于它依赖 <em>Routing</em> ，所以我决定采用官方提供的学习步骤。</p>\n<p>我们已经了解过direct，fanout两种投递模型。那么topic到底又是什么呢？</p>\n<p>简单来说，topic只是为routingKey设置了一个规则（任意单词来描述主题，以”.”分割为不同层级，长度不能超过255位），有点命名空间的味道，这里称之为主题可能更加合适一些。</p>\n<p>在规则中还提供了两个关键字：</p>\n<ol>\n<li><em>*</em>：可以匹配任意1个单词；</li>\n<li><em>#</em>：可以匹配任意0个或多个单词。</li>\n</ol>\n<p>有点正则的味道，不过确实在direct模型的基础上进一步提升了灵活性。举个例子，如果我们用这么一个routingKey：*.love.*，那么投递任务时，任何这种模式主题的任务都会投递到对应队列，例如：everyone.love.kazaff。再如：kazaff.#，这意味着会匹配kazaff.me.is.cool，也会匹配kazaff.me，等等。</p>\n<p><strong>如果发送任务用的routingKey不能匹配声明的模式，那么任务就会被丢弃。</strong></p>\n<p>你可以把模式只定义为#来模仿fanout模型，也可以把模式定义为不包含*和#的具体字符串来模仿direct模型。</p>\n<p>##Message properties<br>在AMQP协议中为每个任务预定义了14个属性，大多数属性都非常少用，常用的4个如下：</p>\n<ol>\n<li>deliveryMode：标识任务的持久性；</li>\n<li>contentType：用于描述任务数据的MIME-TYPE，例如application/json；</li>\n<li>replyTo：用于命名一个callback队列；</li>\n<li>correlationId：用于标识RPC任务的请求与响应的配对编号。</li>\n</ol>\n<p>可想到为每一次RPC请求都创建一个回调队列是非常低效的。更高效的做法是为每一个发出RPC请求的客户端创建一个回调队列，但这又产生了一个新问题：<strong>如何知道回调队列中的响应是对应哪一个请求的呢？</strong></p>\n<p>这就是 <em>correlationId</em> 属性存在的意义，我们只要为每个请求设置一个唯一的值，我们就能在从回调队列中取到响应数据后根据correlationId找到对应的请求。</p>\n<p>如果我们收到一个未知的correlationId响应，只需要忽略它既可。你可能会想，怎么可能收到未知的响应？确实，这种情况发生的概率不高，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/DKZLeZiI/Zjdye.png\" alt=\"\"></p>\n<p>假设S从rpc_queue中取得RPC任务后，进行处理，然后把响应发送给reply_to队列，此时S挂了，它还没来得及向rpc_queue发送ack！但是你知道的，其实整个RPC已经可以算完成了！</p>\n<p>这个时候S重启完毕，它会再次取到刚才的那个RPC任务，再次处理，再次把结果发送给reply_to队列，这次它挺了下来没死机，并把ack发送到rpc_queue。但是，C端早已经在S第一次死机之前就拿到结果了，第二次发来的响应任务C自然找不到对应的correlationId。我这么说，你懂了么？</p>\n<hr>\n<p>当目前为止，我已经把我认为重要的概念都提到了，有啥问题，私下讨论吧！</p>"},{"title":"php页面白屏","date":"2014-08-08T03:37:12.000Z","_content":"\n昨天给家正惬意着，突然朋友打电话说让我帮着看看他们的服务器，貌似出问题了~电话里描述的问题是：\n\n> 访问所有的php页面都是白屏，但是静态页面却能打开\n<!-- more -->\n老实说，我之前还真没印象碰见过这种问题，第一印象以为是apache配置的php参数有问题，但那也不会白屏啊，应该是下载php文件才对啊~好吧，我确实抓瞎了！\n\n先简单描述一下服务器的配置环境，其实很简单，用的是VPS，操作系统是CentOS，web环境装的是`WDCP`，这应该是一个很常见的产品环境下的lnamp集成套件了，提供了强大的界面管理后台，我很喜欢~~不多说了，再说就成了广告贴了！\n\n通过ssh登录到服务器上，简单的看了看相关的配置，确实没什么思路，相关的log也没发现什么眉目！只能求助于[wdcp](http://www.wdlinux.cn/bbs/search.php?searchid=27&orderby=lastpost&ascdesc=desc&searchsubmit=yes)论坛了，按照前辈们的[解决方案](http://www.wdlinux.cn/bbs/redirect.php?goto=findpost&ptid=4641&pid=22018&fromuid=9712)，开始排查，结果发现果然是由于磁盘满了造成的php页面白屏！\n\n非常的好奇，为什么磁盘满了，php就会白屏呢？这尼玛是不死逗比？\n\n既然知道原因，那么解决就不是问题了，找到造成磁盘写满的主要原因，是因为mysql的数据库文件被指定到了根目录挂载点，而vps的这个挂载点分配的很小，所以只需要把数据库文件指定到最大的挂载点即可。注意修改新路径下的文件夹权限，否则mysql可能无法正常启动哟~\n\n\n\n","source":"_posts/php页面白屏.md","raw":"title: php页面白屏\ndate: 2014-08-08 11:37:12\ntags: \n- 白屏\n- wdcp\n- 磁盘写满\ncategories: php\n---\n\n昨天给家正惬意着，突然朋友打电话说让我帮着看看他们的服务器，貌似出问题了~电话里描述的问题是：\n\n> 访问所有的php页面都是白屏，但是静态页面却能打开\n<!-- more -->\n老实说，我之前还真没印象碰见过这种问题，第一印象以为是apache配置的php参数有问题，但那也不会白屏啊，应该是下载php文件才对啊~好吧，我确实抓瞎了！\n\n先简单描述一下服务器的配置环境，其实很简单，用的是VPS，操作系统是CentOS，web环境装的是`WDCP`，这应该是一个很常见的产品环境下的lnamp集成套件了，提供了强大的界面管理后台，我很喜欢~~不多说了，再说就成了广告贴了！\n\n通过ssh登录到服务器上，简单的看了看相关的配置，确实没什么思路，相关的log也没发现什么眉目！只能求助于[wdcp](http://www.wdlinux.cn/bbs/search.php?searchid=27&orderby=lastpost&ascdesc=desc&searchsubmit=yes)论坛了，按照前辈们的[解决方案](http://www.wdlinux.cn/bbs/redirect.php?goto=findpost&ptid=4641&pid=22018&fromuid=9712)，开始排查，结果发现果然是由于磁盘满了造成的php页面白屏！\n\n非常的好奇，为什么磁盘满了，php就会白屏呢？这尼玛是不死逗比？\n\n既然知道原因，那么解决就不是问题了，找到造成磁盘写满的主要原因，是因为mysql的数据库文件被指定到了根目录挂载点，而vps的这个挂载点分配的很小，所以只需要把数据库文件指定到最大的挂载点即可。注意修改新路径下的文件夹权限，否则mysql可能无法正常启动哟~\n\n\n\n","slug":"php页面白屏","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18yom007ngtfydxe2kpb5","comments":1,"layout":"post","photos":[],"link":"","content":"<p>昨天给家正惬意着，突然朋友打电话说让我帮着看看他们的服务器，貌似出问题了~电话里描述的问题是：</p>\n<blockquote>\n<p>访问所有的php页面都是白屏，但是静态页面却能打开<br><a id=\"more\"></a><br>老实说，我之前还真没印象碰见过这种问题，第一印象以为是apache配置的php参数有问题，但那也不会白屏啊，应该是下载php文件才对啊~好吧，我确实抓瞎了！</p>\n</blockquote>\n<p>先简单描述一下服务器的配置环境，其实很简单，用的是VPS，操作系统是CentOS，web环境装的是<code>WDCP</code>，这应该是一个很常见的产品环境下的lnamp集成套件了，提供了强大的界面管理后台，我很喜欢~~不多说了，再说就成了广告贴了！</p>\n<p>通过ssh登录到服务器上，简单的看了看相关的配置，确实没什么思路，相关的log也没发现什么眉目！只能求助于<a href=\"http://www.wdlinux.cn/bbs/search.php?searchid=27&amp;orderby=lastpost&amp;ascdesc=desc&amp;searchsubmit=yes\" target=\"_blank\" rel=\"external\">wdcp</a>论坛了，按照前辈们的<a href=\"http://www.wdlinux.cn/bbs/redirect.php?goto=findpost&amp;ptid=4641&amp;pid=22018&amp;fromuid=9712\" target=\"_blank\" rel=\"external\">解决方案</a>，开始排查，结果发现果然是由于磁盘满了造成的php页面白屏！</p>\n<p>非常的好奇，为什么磁盘满了，php就会白屏呢？这尼玛是不死逗比？</p>\n<p>既然知道原因，那么解决就不是问题了，找到造成磁盘写满的主要原因，是因为mysql的数据库文件被指定到了根目录挂载点，而vps的这个挂载点分配的很小，所以只需要把数据库文件指定到最大的挂载点即可。注意修改新路径下的文件夹权限，否则mysql可能无法正常启动哟~</p>\n","excerpt":"<p>昨天给家正惬意着，突然朋友打电话说让我帮着看看他们的服务器，貌似出问题了~电话里描述的问题是：</p>\n<blockquote>\n<p>访问所有的php页面都是白屏，但是静态页面却能打开<br>","more":"<br>老实说，我之前还真没印象碰见过这种问题，第一印象以为是apache配置的php参数有问题，但那也不会白屏啊，应该是下载php文件才对啊~好吧，我确实抓瞎了！</p>\n</blockquote>\n<p>先简单描述一下服务器的配置环境，其实很简单，用的是VPS，操作系统是CentOS，web环境装的是<code>WDCP</code>，这应该是一个很常见的产品环境下的lnamp集成套件了，提供了强大的界面管理后台，我很喜欢~~不多说了，再说就成了广告贴了！</p>\n<p>通过ssh登录到服务器上，简单的看了看相关的配置，确实没什么思路，相关的log也没发现什么眉目！只能求助于<a href=\"http://www.wdlinux.cn/bbs/search.php?searchid=27&amp;orderby=lastpost&amp;ascdesc=desc&amp;searchsubmit=yes\">wdcp</a>论坛了，按照前辈们的<a href=\"http://www.wdlinux.cn/bbs/redirect.php?goto=findpost&amp;ptid=4641&amp;pid=22018&amp;fromuid=9712\">解决方案</a>，开始排查，结果发现果然是由于磁盘满了造成的php页面白屏！</p>\n<p>非常的好奇，为什么磁盘满了，php就会白屏呢？这尼玛是不死逗比？</p>\n<p>既然知道原因，那么解决就不是问题了，找到造成磁盘写满的主要原因，是因为mysql的数据库文件被指定到了根目录挂载点，而vps的这个挂载点分配的很小，所以只需要把数据库文件指定到最大的挂载点即可。注意修改新路径下的文件夹权限，否则mysql可能无法正常启动哟~</p>"},{"title":"nodejs操作redis","date":"2014-06-06T06:53:12.000Z","_content":"\n前前后后已经写过好多个语言与redis进行结合了，有php，c++，java，今天总算要用nodejs来操作redis了，不知为何还有点儿小兴奋~~\n\n虽然限于nodejs的异步编程模型的影响，直观上和其它语言非常不同，但基本上花一些时间都可以很快的适应，操作redis的方法依然如此，与操作mysql的api没什么两样~\n\n我还是准备着重介绍关于redis的认证，事务和批处理相关的内容，毕竟redis的数据结构本身非常的直观，并没有什么好多讲的~\n<!-- more -->\n哦，忘记说了，我使用的库是：[redis](https://github.com/mranney/node_redis)，从官网上可以了解很全面信息，这里面有个小插曲，我的桌面OS是win7 64bit，但是死活安装不好vs环境，导致无法成功编译hiredis，所以只能使用redis提供的javascript接口，这在[性能](https://github.com/mranney/node_redis#performance)上会有所降低，不过目前这并不是我的关注点。\n\njavascript是基于事件驱动的，nodejs理所当然的也拥有事件驱动引擎，所以先看一下这个redis库提供了哪些重要的事件：\n\nready\n---\n与redis服务创建连接成功后，会触发“ready”事件，这表明服务器端已经准备好接受命令了，但这并不表明必须在该事件发生后才能使用client执行命令，那是因为在“ready”事件触发之前，用client执行的命令会存放在队列中，等到就绪后会根据顺序依次调用命令。\n\nend\n---\n当连接关闭后，会触发“end”事件。\n\ndrain\n---\n当连接缓冲区可写后，会触发“drain”事件，这有助于你控制发送频率。\n\n\n\n---\n下面来介绍一些重要的接口：\n\nredis.createClient(port, host, options)\n---\n默认port是6379，默认的host当然是127.0.0.1，options为一个对象，可以包含下列的属性：\n\n* parser： redis协议的解析器，默认是hiredis，如果像我一样悲剧的装不上，那该项会被设置为javascript；\n* no_ready_check： 默认为false，当连接建立后，服务器端可能还处在从磁盘加载数据的loading阶段，这个时候服务器端是不会响应任何命令的，这个时候node_redis会发送INFO命令来检查服务器状态，一旦INFO命令收到响应了，则表明服务器端已经可以提供服务了，此时node_redis会触发“ready”事件，这就是为什么会有“connect”和“ready”事件之分，如果你关闭了这个功能，我觉得会出现一些貌似灵异的问题；\n* enable_offline_queue： 默认为true，前面提到过，当连接ready之前，client会把收到的命令放入队列中等待执行，如果关闭该项，所有ready前的调用都将会立刻得到一个error callback；\n* retry_max_delay： 默认为null，默认情况下client连接失败后会重试，每次重试的时间间隔会翻倍，直到永远，而设置这个值会增加一个阀值，单位为毫秒；\n* connect_timeout: 默认为false，默认情况下客户端将会一直尝试连接，设置该参数可以限制尝试连接的总时间，单位为毫秒；\n* max_attempts: 默认为null，可以设置该参数来限制尝试的总次数；\n* auth_pass： 默认为null，该参数用来认证身份。\n\nclient.auth(password, callback)\n---\n这个接口用来认证身份的，如果你要连接的redis服务器是需要认证身份的，那么你必须确保这个方法是创建连接后第一个被调用的。需要注意的是，为了让使重连足够的简单，client.auth()保存了密码，用于每次重连后的认证，而回调只有会执行一次哦~~\n\n另外你需要确保的是，千万别自作聪明的把client.auth()放在“ready”或“connect”事件的回调中，你将会得到一行神秘的报错：\n\n\tError: Ready check failed: ERR operation not permitted\n\n只需要在redis.createClient()代码后直接调用clietn.auth()即可，具体原因我没有深究~\n\nclient.end()\n---\n这个方法会强行关闭连接，并不会等待所有的响应。如果不想如此暴力，推荐使用client.quit()，该方法会在收到所有响应后发送QUIT命令。\n\nclient.unref()\n---\n这个方法作用于底层socket连接，可以在程序没有其他任务后自动退出，可以类比nodejs自己的unref()。这个方法目前是个试验特性，只支持一部分redis协议。\n\nclient.multi([commands])\n---\nmulti命令可以理解为打包，它会把命令都存放在队列里，直到调用exec方法，redis服务器端会一次性原子性的执行所有发来的命令，node_redis接口最终会返回一个Multi对象。\n\nMulti.exec(callback)\n---\nclient.multi()会返回一个Multi对象，它包含所有的命令，直到调用Multi.exec()。我们来主要说一下这个方法的回调函数中的两个参数：\n\n* err: null或者Array，没有出错当然就会返回null，如果出错则返回命令队列链中对应的发生错误的命令的错误信息，数组中最后一个元素exec()方法自身的错误信息，**这里我要说的是，可以看出这种方式所谓的原子性主要是指的命令链中的命令一定会保证一起在服务器端执行，而不是指的像关系型数据库那样的回滚功能**；\n* results： null或者Array，返回命令链中每个命令的返回信息。\n\n\n\tvar redis  = require(\"./index\"),\n        client = redis.createClient(), set_size = 20;\n\n    client.sadd(\"bigset\", \"a member\");\n    client.sadd(\"bigset\", \"another member\");\n\n    while (set_size > 0) {\n        client.sadd(\"bigset\", \"member \" + set_size);\n        set_size -= 1;\n    }\n\n    // multi chain with an individual callback\n    client.multi()\n        .scard(\"bigset\")\n        .smembers(\"bigset\")\n        .keys(\"*\", function (err, replies) {\n            // NOTE: code in this callback is NOT atomic\n            // this only happens after the the .exec call finishes.\n            client.mget(replies, redis.print);\n        })\n        .dbsize()\n        .exec(function (err, replies) {\n            console.log(\"MULTI got \" + replies.length + \" replies\");\n            replies.forEach(function (reply, index) {\n                console.log(\"Reply \" + index + \": \" + reply.toString());\n            });\n        });","source":"_posts/nodejs操作redis.md","raw":"title: nodejs操作redis\ndate: 2014-06-06 14:53:12\ntags: \n- redis\ncategories: nodejs\n---\n\n前前后后已经写过好多个语言与redis进行结合了，有php，c++，java，今天总算要用nodejs来操作redis了，不知为何还有点儿小兴奋~~\n\n虽然限于nodejs的异步编程模型的影响，直观上和其它语言非常不同，但基本上花一些时间都可以很快的适应，操作redis的方法依然如此，与操作mysql的api没什么两样~\n\n我还是准备着重介绍关于redis的认证，事务和批处理相关的内容，毕竟redis的数据结构本身非常的直观，并没有什么好多讲的~\n<!-- more -->\n哦，忘记说了，我使用的库是：[redis](https://github.com/mranney/node_redis)，从官网上可以了解很全面信息，这里面有个小插曲，我的桌面OS是win7 64bit，但是死活安装不好vs环境，导致无法成功编译hiredis，所以只能使用redis提供的javascript接口，这在[性能](https://github.com/mranney/node_redis#performance)上会有所降低，不过目前这并不是我的关注点。\n\njavascript是基于事件驱动的，nodejs理所当然的也拥有事件驱动引擎，所以先看一下这个redis库提供了哪些重要的事件：\n\nready\n---\n与redis服务创建连接成功后，会触发“ready”事件，这表明服务器端已经准备好接受命令了，但这并不表明必须在该事件发生后才能使用client执行命令，那是因为在“ready”事件触发之前，用client执行的命令会存放在队列中，等到就绪后会根据顺序依次调用命令。\n\nend\n---\n当连接关闭后，会触发“end”事件。\n\ndrain\n---\n当连接缓冲区可写后，会触发“drain”事件，这有助于你控制发送频率。\n\n\n\n---\n下面来介绍一些重要的接口：\n\nredis.createClient(port, host, options)\n---\n默认port是6379，默认的host当然是127.0.0.1，options为一个对象，可以包含下列的属性：\n\n* parser： redis协议的解析器，默认是hiredis，如果像我一样悲剧的装不上，那该项会被设置为javascript；\n* no_ready_check： 默认为false，当连接建立后，服务器端可能还处在从磁盘加载数据的loading阶段，这个时候服务器端是不会响应任何命令的，这个时候node_redis会发送INFO命令来检查服务器状态，一旦INFO命令收到响应了，则表明服务器端已经可以提供服务了，此时node_redis会触发“ready”事件，这就是为什么会有“connect”和“ready”事件之分，如果你关闭了这个功能，我觉得会出现一些貌似灵异的问题；\n* enable_offline_queue： 默认为true，前面提到过，当连接ready之前，client会把收到的命令放入队列中等待执行，如果关闭该项，所有ready前的调用都将会立刻得到一个error callback；\n* retry_max_delay： 默认为null，默认情况下client连接失败后会重试，每次重试的时间间隔会翻倍，直到永远，而设置这个值会增加一个阀值，单位为毫秒；\n* connect_timeout: 默认为false，默认情况下客户端将会一直尝试连接，设置该参数可以限制尝试连接的总时间，单位为毫秒；\n* max_attempts: 默认为null，可以设置该参数来限制尝试的总次数；\n* auth_pass： 默认为null，该参数用来认证身份。\n\nclient.auth(password, callback)\n---\n这个接口用来认证身份的，如果你要连接的redis服务器是需要认证身份的，那么你必须确保这个方法是创建连接后第一个被调用的。需要注意的是，为了让使重连足够的简单，client.auth()保存了密码，用于每次重连后的认证，而回调只有会执行一次哦~~\n\n另外你需要确保的是，千万别自作聪明的把client.auth()放在“ready”或“connect”事件的回调中，你将会得到一行神秘的报错：\n\n\tError: Ready check failed: ERR operation not permitted\n\n只需要在redis.createClient()代码后直接调用clietn.auth()即可，具体原因我没有深究~\n\nclient.end()\n---\n这个方法会强行关闭连接，并不会等待所有的响应。如果不想如此暴力，推荐使用client.quit()，该方法会在收到所有响应后发送QUIT命令。\n\nclient.unref()\n---\n这个方法作用于底层socket连接，可以在程序没有其他任务后自动退出，可以类比nodejs自己的unref()。这个方法目前是个试验特性，只支持一部分redis协议。\n\nclient.multi([commands])\n---\nmulti命令可以理解为打包，它会把命令都存放在队列里，直到调用exec方法，redis服务器端会一次性原子性的执行所有发来的命令，node_redis接口最终会返回一个Multi对象。\n\nMulti.exec(callback)\n---\nclient.multi()会返回一个Multi对象，它包含所有的命令，直到调用Multi.exec()。我们来主要说一下这个方法的回调函数中的两个参数：\n\n* err: null或者Array，没有出错当然就会返回null，如果出错则返回命令队列链中对应的发生错误的命令的错误信息，数组中最后一个元素exec()方法自身的错误信息，**这里我要说的是，可以看出这种方式所谓的原子性主要是指的命令链中的命令一定会保证一起在服务器端执行，而不是指的像关系型数据库那样的回滚功能**；\n* results： null或者Array，返回命令链中每个命令的返回信息。\n\n\n\tvar redis  = require(\"./index\"),\n        client = redis.createClient(), set_size = 20;\n\n    client.sadd(\"bigset\", \"a member\");\n    client.sadd(\"bigset\", \"another member\");\n\n    while (set_size > 0) {\n        client.sadd(\"bigset\", \"member \" + set_size);\n        set_size -= 1;\n    }\n\n    // multi chain with an individual callback\n    client.multi()\n        .scard(\"bigset\")\n        .smembers(\"bigset\")\n        .keys(\"*\", function (err, replies) {\n            // NOTE: code in this callback is NOT atomic\n            // this only happens after the the .exec call finishes.\n            client.mget(replies, redis.print);\n        })\n        .dbsize()\n        .exec(function (err, replies) {\n            console.log(\"MULTI got \" + replies.length + \" replies\");\n            replies.forEach(function (reply, index) {\n                console.log(\"Reply \" + index + \": \" + reply.toString());\n            });\n        });","slug":"nodejs操作redis","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18yov007wgtfyv9a10d2f","comments":1,"layout":"post","photos":[],"link":"","content":"<p>前前后后已经写过好多个语言与redis进行结合了，有php，c++，java，今天总算要用nodejs来操作redis了，不知为何还有点儿小兴奋~~</p>\n<p>虽然限于nodejs的异步编程模型的影响，直观上和其它语言非常不同，但基本上花一些时间都可以很快的适应，操作redis的方法依然如此，与操作mysql的api没什么两样~</p>\n<p>我还是准备着重介绍关于redis的认证，事务和批处理相关的内容，毕竟redis的数据结构本身非常的直观，并没有什么好多讲的~<br><a id=\"more\"></a><br>哦，忘记说了，我使用的库是：<a href=\"https://github.com/mranney/node_redis\" target=\"_blank\" rel=\"external\">redis</a>，从官网上可以了解很全面信息，这里面有个小插曲，我的桌面OS是win7 64bit，但是死活安装不好vs环境，导致无法成功编译hiredis，所以只能使用redis提供的javascript接口，这在<a href=\"https://github.com/mranney/node_redis#performance\" target=\"_blank\" rel=\"external\">性能</a>上会有所降低，不过目前这并不是我的关注点。</p>\n<p>javascript是基于事件驱动的，nodejs理所当然的也拥有事件驱动引擎，所以先看一下这个redis库提供了哪些重要的事件：</p>\n<h2 id=\"ready\"><a href=\"#ready\" class=\"headerlink\" title=\"ready\"></a>ready</h2><p>与redis服务创建连接成功后，会触发“ready”事件，这表明服务器端已经准备好接受命令了，但这并不表明必须在该事件发生后才能使用client执行命令，那是因为在“ready”事件触发之前，用client执行的命令会存放在队列中，等到就绪后会根据顺序依次调用命令。</p>\n<h2 id=\"end\"><a href=\"#end\" class=\"headerlink\" title=\"end\"></a>end</h2><p>当连接关闭后，会触发“end”事件。</p>\n<h2 id=\"drain\"><a href=\"#drain\" class=\"headerlink\" title=\"drain\"></a>drain</h2><p>当连接缓冲区可写后，会触发“drain”事件，这有助于你控制发送频率。</p>\n<hr>\n<p>下面来介绍一些重要的接口：</p>\n<h2 id=\"redis-createClient-port-host-options\"><a href=\"#redis-createClient-port-host-options\" class=\"headerlink\" title=\"redis.createClient(port, host, options)\"></a>redis.createClient(port, host, options)</h2><p>默认port是6379，默认的host当然是127.0.0.1，options为一个对象，可以包含下列的属性：</p>\n<ul>\n<li>parser： redis协议的解析器，默认是hiredis，如果像我一样悲剧的装不上，那该项会被设置为javascript；</li>\n<li>no_ready_check： 默认为false，当连接建立后，服务器端可能还处在从磁盘加载数据的loading阶段，这个时候服务器端是不会响应任何命令的，这个时候node_redis会发送INFO命令来检查服务器状态，一旦INFO命令收到响应了，则表明服务器端已经可以提供服务了，此时node_redis会触发“ready”事件，这就是为什么会有“connect”和“ready”事件之分，如果你关闭了这个功能，我觉得会出现一些貌似灵异的问题；</li>\n<li>enable_offline_queue： 默认为true，前面提到过，当连接ready之前，client会把收到的命令放入队列中等待执行，如果关闭该项，所有ready前的调用都将会立刻得到一个error callback；</li>\n<li>retry_max_delay： 默认为null，默认情况下client连接失败后会重试，每次重试的时间间隔会翻倍，直到永远，而设置这个值会增加一个阀值，单位为毫秒；</li>\n<li>connect_timeout: 默认为false，默认情况下客户端将会一直尝试连接，设置该参数可以限制尝试连接的总时间，单位为毫秒；</li>\n<li>max_attempts: 默认为null，可以设置该参数来限制尝试的总次数；</li>\n<li>auth_pass： 默认为null，该参数用来认证身份。</li>\n</ul>\n<h2 id=\"client-auth-password-callback\"><a href=\"#client-auth-password-callback\" class=\"headerlink\" title=\"client.auth(password, callback)\"></a>client.auth(password, callback)</h2><p>这个接口用来认证身份的，如果你要连接的redis服务器是需要认证身份的，那么你必须确保这个方法是创建连接后第一个被调用的。需要注意的是，为了让使重连足够的简单，client.auth()保存了密码，用于每次重连后的认证，而回调只有会执行一次哦~~</p>\n<p>另外你需要确保的是，千万别自作聪明的把client.auth()放在“ready”或“connect”事件的回调中，你将会得到一行神秘的报错：</p>\n<pre><code>Error: Ready check failed: ERR operation not permitted\n</code></pre><p>只需要在redis.createClient()代码后直接调用clietn.auth()即可，具体原因我没有深究~</p>\n<h2 id=\"client-end\"><a href=\"#client-end\" class=\"headerlink\" title=\"client.end()\"></a>client.end()</h2><p>这个方法会强行关闭连接，并不会等待所有的响应。如果不想如此暴力，推荐使用client.quit()，该方法会在收到所有响应后发送QUIT命令。</p>\n<h2 id=\"client-unref\"><a href=\"#client-unref\" class=\"headerlink\" title=\"client.unref()\"></a>client.unref()</h2><p>这个方法作用于底层socket连接，可以在程序没有其他任务后自动退出，可以类比nodejs自己的unref()。这个方法目前是个试验特性，只支持一部分redis协议。</p>\n<h2 id=\"client-multi-commands\"><a href=\"#client-multi-commands\" class=\"headerlink\" title=\"client.multi([commands])\"></a>client.multi([commands])</h2><p>multi命令可以理解为打包，它会把命令都存放在队列里，直到调用exec方法，redis服务器端会一次性原子性的执行所有发来的命令，node_redis接口最终会返回一个Multi对象。</p>\n<h2 id=\"Multi-exec-callback\"><a href=\"#Multi-exec-callback\" class=\"headerlink\" title=\"Multi.exec(callback)\"></a>Multi.exec(callback)</h2><p>client.multi()会返回一个Multi对象，它包含所有的命令，直到调用Multi.exec()。我们来主要说一下这个方法的回调函数中的两个参数：</p>\n<ul>\n<li>err: null或者Array，没有出错当然就会返回null，如果出错则返回命令队列链中对应的发生错误的命令的错误信息，数组中最后一个元素exec()方法自身的错误信息，<strong>这里我要说的是，可以看出这种方式所谓的原子性主要是指的命令链中的命令一定会保证一起在服务器端执行，而不是指的像关系型数据库那样的回滚功能</strong>；</li>\n<li>results： null或者Array，返回命令链中每个命令的返回信息。</li>\n</ul>\n<pre><code>var redis  = require(&quot;./index&quot;),\n    client = redis.createClient(), set_size = 20;\n\nclient.sadd(&quot;bigset&quot;, &quot;a member&quot;);\nclient.sadd(&quot;bigset&quot;, &quot;another member&quot;);\n\nwhile (set_size &gt; 0) {\n    client.sadd(&quot;bigset&quot;, &quot;member &quot; + set_size);\n    set_size -= 1;\n}\n\n// multi chain with an individual callback\nclient.multi()\n    .scard(&quot;bigset&quot;)\n    .smembers(&quot;bigset&quot;)\n    .keys(&quot;*&quot;, function (err, replies) {\n        // NOTE: code in this callback is NOT atomic\n        // this only happens after the the .exec call finishes.\n        client.mget(replies, redis.print);\n    })\n    .dbsize()\n    .exec(function (err, replies) {\n        console.log(&quot;MULTI got &quot; + replies.length + &quot; replies&quot;);\n        replies.forEach(function (reply, index) {\n            console.log(&quot;Reply &quot; + index + &quot;: &quot; + reply.toString());\n        });\n    });\n</code></pre>","excerpt":"<p>前前后后已经写过好多个语言与redis进行结合了，有php，c++，java，今天总算要用nodejs来操作redis了，不知为何还有点儿小兴奋~~</p>\n<p>虽然限于nodejs的异步编程模型的影响，直观上和其它语言非常不同，但基本上花一些时间都可以很快的适应，操作redis的方法依然如此，与操作mysql的api没什么两样~</p>\n<p>我还是准备着重介绍关于redis的认证，事务和批处理相关的内容，毕竟redis的数据结构本身非常的直观，并没有什么好多讲的~<br>","more":"<br>哦，忘记说了，我使用的库是：<a href=\"https://github.com/mranney/node_redis\">redis</a>，从官网上可以了解很全面信息，这里面有个小插曲，我的桌面OS是win7 64bit，但是死活安装不好vs环境，导致无法成功编译hiredis，所以只能使用redis提供的javascript接口，这在<a href=\"https://github.com/mranney/node_redis#performance\">性能</a>上会有所降低，不过目前这并不是我的关注点。</p>\n<p>javascript是基于事件驱动的，nodejs理所当然的也拥有事件驱动引擎，所以先看一下这个redis库提供了哪些重要的事件：</p>\n<h2 id=\"ready\"><a href=\"#ready\" class=\"headerlink\" title=\"ready\"></a>ready</h2><p>与redis服务创建连接成功后，会触发“ready”事件，这表明服务器端已经准备好接受命令了，但这并不表明必须在该事件发生后才能使用client执行命令，那是因为在“ready”事件触发之前，用client执行的命令会存放在队列中，等到就绪后会根据顺序依次调用命令。</p>\n<h2 id=\"end\"><a href=\"#end\" class=\"headerlink\" title=\"end\"></a>end</h2><p>当连接关闭后，会触发“end”事件。</p>\n<h2 id=\"drain\"><a href=\"#drain\" class=\"headerlink\" title=\"drain\"></a>drain</h2><p>当连接缓冲区可写后，会触发“drain”事件，这有助于你控制发送频率。</p>\n<hr>\n<p>下面来介绍一些重要的接口：</p>\n<h2 id=\"redis-createClient-port-host-options\"><a href=\"#redis-createClient-port-host-options\" class=\"headerlink\" title=\"redis.createClient(port, host, options)\"></a>redis.createClient(port, host, options)</h2><p>默认port是6379，默认的host当然是127.0.0.1，options为一个对象，可以包含下列的属性：</p>\n<ul>\n<li>parser： redis协议的解析器，默认是hiredis，如果像我一样悲剧的装不上，那该项会被设置为javascript；</li>\n<li>no_ready_check： 默认为false，当连接建立后，服务器端可能还处在从磁盘加载数据的loading阶段，这个时候服务器端是不会响应任何命令的，这个时候node_redis会发送INFO命令来检查服务器状态，一旦INFO命令收到响应了，则表明服务器端已经可以提供服务了，此时node_redis会触发“ready”事件，这就是为什么会有“connect”和“ready”事件之分，如果你关闭了这个功能，我觉得会出现一些貌似灵异的问题；</li>\n<li>enable_offline_queue： 默认为true，前面提到过，当连接ready之前，client会把收到的命令放入队列中等待执行，如果关闭该项，所有ready前的调用都将会立刻得到一个error callback；</li>\n<li>retry_max_delay： 默认为null，默认情况下client连接失败后会重试，每次重试的时间间隔会翻倍，直到永远，而设置这个值会增加一个阀值，单位为毫秒；</li>\n<li>connect_timeout: 默认为false，默认情况下客户端将会一直尝试连接，设置该参数可以限制尝试连接的总时间，单位为毫秒；</li>\n<li>max_attempts: 默认为null，可以设置该参数来限制尝试的总次数；</li>\n<li>auth_pass： 默认为null，该参数用来认证身份。</li>\n</ul>\n<h2 id=\"client-auth-password-callback\"><a href=\"#client-auth-password-callback\" class=\"headerlink\" title=\"client.auth(password, callback)\"></a>client.auth(password, callback)</h2><p>这个接口用来认证身份的，如果你要连接的redis服务器是需要认证身份的，那么你必须确保这个方法是创建连接后第一个被调用的。需要注意的是，为了让使重连足够的简单，client.auth()保存了密码，用于每次重连后的认证，而回调只有会执行一次哦~~</p>\n<p>另外你需要确保的是，千万别自作聪明的把client.auth()放在“ready”或“connect”事件的回调中，你将会得到一行神秘的报错：</p>\n<pre><code>Error: Ready check failed: ERR operation not permitted\n</code></pre><p>只需要在redis.createClient()代码后直接调用clietn.auth()即可，具体原因我没有深究~</p>\n<h2 id=\"client-end\"><a href=\"#client-end\" class=\"headerlink\" title=\"client.end()\"></a>client.end()</h2><p>这个方法会强行关闭连接，并不会等待所有的响应。如果不想如此暴力，推荐使用client.quit()，该方法会在收到所有响应后发送QUIT命令。</p>\n<h2 id=\"client-unref\"><a href=\"#client-unref\" class=\"headerlink\" title=\"client.unref()\"></a>client.unref()</h2><p>这个方法作用于底层socket连接，可以在程序没有其他任务后自动退出，可以类比nodejs自己的unref()。这个方法目前是个试验特性，只支持一部分redis协议。</p>\n<h2 id=\"client-multi-commands\"><a href=\"#client-multi-commands\" class=\"headerlink\" title=\"client.multi([commands])\"></a>client.multi([commands])</h2><p>multi命令可以理解为打包，它会把命令都存放在队列里，直到调用exec方法，redis服务器端会一次性原子性的执行所有发来的命令，node_redis接口最终会返回一个Multi对象。</p>\n<h2 id=\"Multi-exec-callback\"><a href=\"#Multi-exec-callback\" class=\"headerlink\" title=\"Multi.exec(callback)\"></a>Multi.exec(callback)</h2><p>client.multi()会返回一个Multi对象，它包含所有的命令，直到调用Multi.exec()。我们来主要说一下这个方法的回调函数中的两个参数：</p>\n<ul>\n<li>err: null或者Array，没有出错当然就会返回null，如果出错则返回命令队列链中对应的发生错误的命令的错误信息，数组中最后一个元素exec()方法自身的错误信息，<strong>这里我要说的是，可以看出这种方式所谓的原子性主要是指的命令链中的命令一定会保证一起在服务器端执行，而不是指的像关系型数据库那样的回滚功能</strong>；</li>\n<li>results： null或者Array，返回命令链中每个命令的返回信息。</li>\n</ul>\n<pre><code>var redis  = require(&quot;./index&quot;),\n    client = redis.createClient(), set_size = 20;\n\nclient.sadd(&quot;bigset&quot;, &quot;a member&quot;);\nclient.sadd(&quot;bigset&quot;, &quot;another member&quot;);\n\nwhile (set_size &gt; 0) {\n    client.sadd(&quot;bigset&quot;, &quot;member &quot; + set_size);\n    set_size -= 1;\n}\n\n// multi chain with an individual callback\nclient.multi()\n    .scard(&quot;bigset&quot;)\n    .smembers(&quot;bigset&quot;)\n    .keys(&quot;*&quot;, function (err, replies) {\n        // NOTE: code in this callback is NOT atomic\n        // this only happens after the the .exec call finishes.\n        client.mget(replies, redis.print);\n    })\n    .dbsize()\n    .exec(function (err, replies) {\n        console.log(&quot;MULTI got &quot; + replies.length + &quot; replies&quot;);\n        replies.forEach(function (reply, index) {\n            console.log(&quot;Reply &quot; + index + &quot;: &quot; + reply.toString());\n        });\n    });\n</code></pre>"},{"title":"logstash整合kafka","date":"2015-06-05T01:37:12.000Z","_content":"\n今天要搞一搞的，是把logstash和kafka整合起来，由于我们使用的是logstash1.5.0+版本，此版本下官方已经提拱了plugin用来整合kafka，这篇文章的目的就是简单的搭建这么一个环境。\n\nkafka的安装\n---\n\nkafka是基于scala实现的，scala是一种jvm语言，也就是说你得先装jdk，我就不从jdk开始介绍如何安装了，我们直接开始安装kafka，其实这玩意儿官方提供了编译好的版本，你只需要下载，解压，运行即可~\n<!--more-->\n当然，如果想搭建集群，还是需要了解一下kafka的配置的，这不是我们关注的重点，so，我们就简单地先跑起来它吧：\n\n1. [下载](http://kafka.apache.org/downloads.html)\n2. 解压，我们解压在`/usr/local`下\n3. 运行，为了测试方便，我们需要一共开启四个终端窗口：\n\n首先，我们要运行zookeeper，kafka自带了zookeeper，所以我们无需下载，只需要在/usr/local/kafka目录下执行：\n\n\tbin/zookeeper-server-start.sh config/zookeeper.properties\n\n然后，再开启一个终端，执行：\n\n\tbin/kafka-server-start.sh config/server.properties\n\n这样，我们的kafka就已经运行起来了，不过还不是集群环境，只有一个borker哟~但是，我们测试足够了。\n\n再然后，开启一个新的终端，执行：\n\n\tbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n\n这样我们就创建了一个用于测试的topic，接下来继续执行：\n\n\tbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test\n\n该命令执行完毕后会阻塞终端，你可以随便输入一些数据，每一行都相当于一个消息，会发送给kafka。\n\n最后，再再开启一个新终端，执行：\n\n\tbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning\n\n你会看到你之前输入的那些消息都会显示在终端中，这就完成了kafka的测试环境搭建。\n\n**值得注意的是**，上面消息生产者的命令，需要参数`broker-list`，也就是说我们的kafka生产者必须自己知道所有的kafka broker的位置，而其它命令则只需要填写zookeeper的位置即可，我不清楚这样做的用意是什么，我只是隐约感到有些问题（**如果broker出现扩容，如何更新应用代码中的borker信息？？**），但这不是我们本次的关注的重点。\n\n\n\n\nlogstash-->kafka\n---\n\n我们现在想要干的，是从logstash的Shipper中收集到的数据发送给kafka，所以我们需要安装[logstash-output-kafka](https://github.com/logstash-plugins/logstash-output-kafka)插件。\n\n但是由于未知原因，我试图安装插件时却碰到了报错：\n\n\t[root@kazaff logstash-1.5.0]# bin/plugin install logstash-output-kafka\n\tValidating logstash-output-kafka\n\tPlugin logstash-output-kafka does not exist\n\tERROR: Installation aborted, verification failed for logstash-output-kafka \n\n不像是被墙了的味道，因为提醒的是不存在，而不是网络连接超时。本来还想搭建一个翻墙环境，后来执行了一下这个命令：\n\n\tbin/plugin list  \n\n竟然发现kafka插件已经预装好了，我也是醉了。OK，我们可以继续了，接下来就是配置一下logstash：\n\n\tinput {\n\t\tstdin{}\n\t}\n\t\n\t\n\toutput {\n\t\tkafka {\n\t\t\tbroker_list => \"localhost:9092\"\n\t\t\ttopic_id => \"test\"\n\t\t\tcompression_codec => \"snappy\"\n\t\t}\n\t}\n\n不多做解释了，在终端运行logstash后，就可以直接输入“helloworld”测试一下了，如果没有问题的话，你将会在之前的kafka消费者终端中看到输出：\n\n\t{\"message\":\"hello world!\",\"@version\":\"1\",\"@timestamp\":\"2015-06-11T10:01:21.183Z\",\"host\":\"kazaff\"}\n\n就是这么简单啦~\n\n\t\n参考\n---\n\n[Kafka快速入门](http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point)\n\n[Logstash入门教程 - 启动命令行参数及插件安装](http://corejava2008.iteye.com/blog/2215545)\n\n[logstash-input-file以及logstash-output-kafka插件性能测试](http://bigbo.github.io/pages/2015/03/26/logstash_performance/)","source":"_posts/logstash整合kafka.md","raw":"title: logstash整合kafka\ndate: 2015-06-05 09:37:12\ntags: \n- Logstash\n- kafka\n- logstash-output-kafka\n- logstash插件\ncategories: 运维\n---\n\n今天要搞一搞的，是把logstash和kafka整合起来，由于我们使用的是logstash1.5.0+版本，此版本下官方已经提拱了plugin用来整合kafka，这篇文章的目的就是简单的搭建这么一个环境。\n\nkafka的安装\n---\n\nkafka是基于scala实现的，scala是一种jvm语言，也就是说你得先装jdk，我就不从jdk开始介绍如何安装了，我们直接开始安装kafka，其实这玩意儿官方提供了编译好的版本，你只需要下载，解压，运行即可~\n<!--more-->\n当然，如果想搭建集群，还是需要了解一下kafka的配置的，这不是我们关注的重点，so，我们就简单地先跑起来它吧：\n\n1. [下载](http://kafka.apache.org/downloads.html)\n2. 解压，我们解压在`/usr/local`下\n3. 运行，为了测试方便，我们需要一共开启四个终端窗口：\n\n首先，我们要运行zookeeper，kafka自带了zookeeper，所以我们无需下载，只需要在/usr/local/kafka目录下执行：\n\n\tbin/zookeeper-server-start.sh config/zookeeper.properties\n\n然后，再开启一个终端，执行：\n\n\tbin/kafka-server-start.sh config/server.properties\n\n这样，我们的kafka就已经运行起来了，不过还不是集群环境，只有一个borker哟~但是，我们测试足够了。\n\n再然后，开启一个新的终端，执行：\n\n\tbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n\n这样我们就创建了一个用于测试的topic，接下来继续执行：\n\n\tbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test\n\n该命令执行完毕后会阻塞终端，你可以随便输入一些数据，每一行都相当于一个消息，会发送给kafka。\n\n最后，再再开启一个新终端，执行：\n\n\tbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning\n\n你会看到你之前输入的那些消息都会显示在终端中，这就完成了kafka的测试环境搭建。\n\n**值得注意的是**，上面消息生产者的命令，需要参数`broker-list`，也就是说我们的kafka生产者必须自己知道所有的kafka broker的位置，而其它命令则只需要填写zookeeper的位置即可，我不清楚这样做的用意是什么，我只是隐约感到有些问题（**如果broker出现扩容，如何更新应用代码中的borker信息？？**），但这不是我们本次的关注的重点。\n\n\n\n\nlogstash-->kafka\n---\n\n我们现在想要干的，是从logstash的Shipper中收集到的数据发送给kafka，所以我们需要安装[logstash-output-kafka](https://github.com/logstash-plugins/logstash-output-kafka)插件。\n\n但是由于未知原因，我试图安装插件时却碰到了报错：\n\n\t[root@kazaff logstash-1.5.0]# bin/plugin install logstash-output-kafka\n\tValidating logstash-output-kafka\n\tPlugin logstash-output-kafka does not exist\n\tERROR: Installation aborted, verification failed for logstash-output-kafka \n\n不像是被墙了的味道，因为提醒的是不存在，而不是网络连接超时。本来还想搭建一个翻墙环境，后来执行了一下这个命令：\n\n\tbin/plugin list  \n\n竟然发现kafka插件已经预装好了，我也是醉了。OK，我们可以继续了，接下来就是配置一下logstash：\n\n\tinput {\n\t\tstdin{}\n\t}\n\t\n\t\n\toutput {\n\t\tkafka {\n\t\t\tbroker_list => \"localhost:9092\"\n\t\t\ttopic_id => \"test\"\n\t\t\tcompression_codec => \"snappy\"\n\t\t}\n\t}\n\n不多做解释了，在终端运行logstash后，就可以直接输入“helloworld”测试一下了，如果没有问题的话，你将会在之前的kafka消费者终端中看到输出：\n\n\t{\"message\":\"hello world!\",\"@version\":\"1\",\"@timestamp\":\"2015-06-11T10:01:21.183Z\",\"host\":\"kazaff\"}\n\n就是这么简单啦~\n\n\t\n参考\n---\n\n[Kafka快速入门](http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point)\n\n[Logstash入门教程 - 启动命令行参数及插件安装](http://corejava2008.iteye.com/blog/2215545)\n\n[logstash-input-file以及logstash-output-kafka插件性能测试](http://bigbo.github.io/pages/2015/03/26/logstash_performance/)","slug":"logstash整合kafka","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yp1007zgtfykaibz3ri","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天要搞一搞的，是把logstash和kafka整合起来，由于我们使用的是logstash1.5.0+版本，此版本下官方已经提拱了plugin用来整合kafka，这篇文章的目的就是简单的搭建这么一个环境。</p>\n<h2 id=\"kafka的安装\"><a href=\"#kafka的安装\" class=\"headerlink\" title=\"kafka的安装\"></a>kafka的安装</h2><p>kafka是基于scala实现的，scala是一种jvm语言，也就是说你得先装jdk，我就不从jdk开始介绍如何安装了，我们直接开始安装kafka，其实这玩意儿官方提供了编译好的版本，你只需要下载，解压，运行即可~<br><a id=\"more\"></a><br>当然，如果想搭建集群，还是需要了解一下kafka的配置的，这不是我们关注的重点，so，我们就简单地先跑起来它吧：</p>\n<ol>\n<li><a href=\"http://kafka.apache.org/downloads.html\" target=\"_blank\" rel=\"external\">下载</a></li>\n<li>解压，我们解压在<code>/usr/local</code>下</li>\n<li>运行，为了测试方便，我们需要一共开启四个终端窗口：</li>\n</ol>\n<p>首先，我们要运行zookeeper，kafka自带了zookeeper，所以我们无需下载，只需要在/usr/local/kafka目录下执行：</p>\n<pre><code>bin/zookeeper-server-start.sh config/zookeeper.properties\n</code></pre><p>然后，再开启一个终端，执行：</p>\n<pre><code>bin/kafka-server-start.sh config/server.properties\n</code></pre><p>这样，我们的kafka就已经运行起来了，不过还不是集群环境，只有一个borker哟~但是，我们测试足够了。</p>\n<p>再然后，开启一个新的终端，执行：</p>\n<pre><code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n</code></pre><p>这样我们就创建了一个用于测试的topic，接下来继续执行：</p>\n<pre><code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test\n</code></pre><p>该命令执行完毕后会阻塞终端，你可以随便输入一些数据，每一行都相当于一个消息，会发送给kafka。</p>\n<p>最后，再再开启一个新终端，执行：</p>\n<pre><code>bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning\n</code></pre><p>你会看到你之前输入的那些消息都会显示在终端中，这就完成了kafka的测试环境搭建。</p>\n<p><strong>值得注意的是</strong>，上面消息生产者的命令，需要参数<code>broker-list</code>，也就是说我们的kafka生产者必须自己知道所有的kafka broker的位置，而其它命令则只需要填写zookeeper的位置即可，我不清楚这样做的用意是什么，我只是隐约感到有些问题（<strong>如果broker出现扩容，如何更新应用代码中的borker信息？？</strong>），但这不是我们本次的关注的重点。</p>\n<h2 id=\"logstash–-gt-kafka\"><a href=\"#logstash–-gt-kafka\" class=\"headerlink\" title=\"logstash–&gt;kafka\"></a>logstash–&gt;kafka</h2><p>我们现在想要干的，是从logstash的Shipper中收集到的数据发送给kafka，所以我们需要安装<a href=\"https://github.com/logstash-plugins/logstash-output-kafka\" target=\"_blank\" rel=\"external\">logstash-output-kafka</a>插件。</p>\n<p>但是由于未知原因，我试图安装插件时却碰到了报错：</p>\n<pre><code>[root@kazaff logstash-1.5.0]# bin/plugin install logstash-output-kafka\nValidating logstash-output-kafka\nPlugin logstash-output-kafka does not exist\nERROR: Installation aborted, verification failed for logstash-output-kafka \n</code></pre><p>不像是被墙了的味道，因为提醒的是不存在，而不是网络连接超时。本来还想搭建一个翻墙环境，后来执行了一下这个命令：</p>\n<pre><code>bin/plugin list  \n</code></pre><p>竟然发现kafka插件已经预装好了，我也是醉了。OK，我们可以继续了，接下来就是配置一下logstash：</p>\n<pre><code>input {\n    stdin{}\n}\n\n\noutput {\n    kafka {\n        broker_list =&gt; &quot;localhost:9092&quot;\n        topic_id =&gt; &quot;test&quot;\n        compression_codec =&gt; &quot;snappy&quot;\n    }\n}\n</code></pre><p>不多做解释了，在终端运行logstash后，就可以直接输入“helloworld”测试一下了，如果没有问题的话，你将会在之前的kafka消费者终端中看到输出：</p>\n<pre><code>{&quot;message&quot;:&quot;hello world!&quot;,&quot;@version&quot;:&quot;1&quot;,&quot;@timestamp&quot;:&quot;2015-06-11T10:01:21.183Z&quot;,&quot;host&quot;:&quot;kazaff&quot;}\n</code></pre><p>就是这么简单啦~</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point\" target=\"_blank\" rel=\"external\">Kafka快速入门</a></p>\n<p><a href=\"http://corejava2008.iteye.com/blog/2215545\" target=\"_blank\" rel=\"external\">Logstash入门教程 - 启动命令行参数及插件安装</a></p>\n<p><a href=\"http://bigbo.github.io/pages/2015/03/26/logstash_performance/\" target=\"_blank\" rel=\"external\">logstash-input-file以及logstash-output-kafka插件性能测试</a></p>\n","excerpt":"<p>今天要搞一搞的，是把logstash和kafka整合起来，由于我们使用的是logstash1.5.0+版本，此版本下官方已经提拱了plugin用来整合kafka，这篇文章的目的就是简单的搭建这么一个环境。</p>\n<h2 id=\"kafka的安装\"><a href=\"#kafka的安装\" class=\"headerlink\" title=\"kafka的安装\"></a>kafka的安装</h2><p>kafka是基于scala实现的，scala是一种jvm语言，也就是说你得先装jdk，我就不从jdk开始介绍如何安装了，我们直接开始安装kafka，其实这玩意儿官方提供了编译好的版本，你只需要下载，解压，运行即可~<br>","more":"<br>当然，如果想搭建集群，还是需要了解一下kafka的配置的，这不是我们关注的重点，so，我们就简单地先跑起来它吧：</p>\n<ol>\n<li><a href=\"http://kafka.apache.org/downloads.html\">下载</a></li>\n<li>解压，我们解压在<code>/usr/local</code>下</li>\n<li>运行，为了测试方便，我们需要一共开启四个终端窗口：</li>\n</ol>\n<p>首先，我们要运行zookeeper，kafka自带了zookeeper，所以我们无需下载，只需要在/usr/local/kafka目录下执行：</p>\n<pre><code>bin/zookeeper-server-start.sh config/zookeeper.properties\n</code></pre><p>然后，再开启一个终端，执行：</p>\n<pre><code>bin/kafka-server-start.sh config/server.properties\n</code></pre><p>这样，我们的kafka就已经运行起来了，不过还不是集群环境，只有一个borker哟~但是，我们测试足够了。</p>\n<p>再然后，开启一个新的终端，执行：</p>\n<pre><code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n</code></pre><p>这样我们就创建了一个用于测试的topic，接下来继续执行：</p>\n<pre><code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test\n</code></pre><p>该命令执行完毕后会阻塞终端，你可以随便输入一些数据，每一行都相当于一个消息，会发送给kafka。</p>\n<p>最后，再再开启一个新终端，执行：</p>\n<pre><code>bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning\n</code></pre><p>你会看到你之前输入的那些消息都会显示在终端中，这就完成了kafka的测试环境搭建。</p>\n<p><strong>值得注意的是</strong>，上面消息生产者的命令，需要参数<code>broker-list</code>，也就是说我们的kafka生产者必须自己知道所有的kafka broker的位置，而其它命令则只需要填写zookeeper的位置即可，我不清楚这样做的用意是什么，我只是隐约感到有些问题（<strong>如果broker出现扩容，如何更新应用代码中的borker信息？？</strong>），但这不是我们本次的关注的重点。</p>\n<h2 id=\"logstash–-gt-kafka\"><a href=\"#logstash–-gt-kafka\" class=\"headerlink\" title=\"logstash–&gt;kafka\"></a>logstash–&gt;kafka</h2><p>我们现在想要干的，是从logstash的Shipper中收集到的数据发送给kafka，所以我们需要安装<a href=\"https://github.com/logstash-plugins/logstash-output-kafka\">logstash-output-kafka</a>插件。</p>\n<p>但是由于未知原因，我试图安装插件时却碰到了报错：</p>\n<pre><code>[root@kazaff logstash-1.5.0]# bin/plugin install logstash-output-kafka\nValidating logstash-output-kafka\nPlugin logstash-output-kafka does not exist\nERROR: Installation aborted, verification failed for logstash-output-kafka \n</code></pre><p>不像是被墙了的味道，因为提醒的是不存在，而不是网络连接超时。本来还想搭建一个翻墙环境，后来执行了一下这个命令：</p>\n<pre><code>bin/plugin list  \n</code></pre><p>竟然发现kafka插件已经预装好了，我也是醉了。OK，我们可以继续了，接下来就是配置一下logstash：</p>\n<pre><code>input {\n    stdin{}\n}\n\n\noutput {\n    kafka {\n        broker_list =&gt; &quot;localhost:9092&quot;\n        topic_id =&gt; &quot;test&quot;\n        compression_codec =&gt; &quot;snappy&quot;\n    }\n}\n</code></pre><p>不多做解释了，在终端运行logstash后，就可以直接输入“helloworld”测试一下了，如果没有问题的话，你将会在之前的kafka消费者终端中看到输出：</p>\n<pre><code>{&quot;message&quot;:&quot;hello world!&quot;,&quot;@version&quot;:&quot;1&quot;,&quot;@timestamp&quot;:&quot;2015-06-11T10:01:21.183Z&quot;,&quot;host&quot;:&quot;kazaff&quot;}\n</code></pre><p>就是这么简单啦~</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point\">Kafka快速入门</a></p>\n<p><a href=\"http://corejava2008.iteye.com/blog/2215545\">Logstash入门教程 - 启动命令行参数及插件安装</a></p>\n<p><a href=\"http://bigbo.github.io/pages/2015/03/26/logstash_performance/\">logstash-input-file以及logstash-output-kafka插件性能测试</a></p>"},{"title":"java命令行参数","date":"2014-07-28T06:53:12.000Z","_content":"\n妈蛋，实在是顶不住部分文章的排版，看着太让人心焦了~~所以，对一篇文章重新排版一下，希望能帮助到其他人~\n\n先发出[原文链接](http://xinklabi.iteye.com/blog/837435)，供眼神好的童鞋~~\n\n<!-- more -->\n\n下面是小弟排版后的内容：\n\nJava在运行已编译完成的类时，是通过java虚拟机来装载和执行的，java虚拟机通过操作系统命令`JAVA_HOME\"bin/\"java -option`来启动，`option`为虚拟机参数， `JAVA_HOME`为JDK安装路径，通过虚拟机参数可对虚拟机的运行状态进行调整，掌握参数的含义可对虚拟机的运行模式有更深入的理解。\n\n如何查看参数列表\n---\n虚拟机参数分为基本和扩展两类，在命令行中输入`JAVA_HOME\"bin/\"java`就可得到基本的参数列表，在命令行中输入`JAVA_HOME\"bin/\"java -X`就可以得到扩展参数列表。\n\n基本参数说明\n---\n\n**-client/-server**\n\n这两个参数用于设置虚拟机使用何种运行模式，`client`模式启动比较快，但运行时性能和内存管理效率不如`server`模式，通常用于客户端应用程序。相反，`server`模式启动稍慢，但可获得更高的运行性能。\n\n在win上，缺省的虚拟机类型为`client`模式，如果要使用`server`模式就需要在启动虚拟机时加上`-server`参数，以获得更高性能。对服务器应用，推荐采用`server`模式，尤其是多个cpu的系统。\n\n在Linux，Solaris上缺省采用的是`server`模式。\n\n**-hotspot**\n\n含义与`client`相同，jdk1.4以前使用的参数，现在已经不再使用，取而代之的是`client`。\n\n**-classpath/-cp**\n\n虚拟机在运行一个类时需要将其装入内存，搜索类的方式和顺序如下：\n\n1. Bootstrap classes\n2. Extension Classes\n3. User Classes\n\n`Bootstrap`中的路径是虚拟机自带的jar或zip文件，虚拟机首选搜索这些包文件，用下面这种方式可得到虚拟机搜索的路径：\n\n\tSystem.getProperty(\"sun.boot.class.path\")\n\n`Extension`位于jre的`lib/ext`目录下的jar文件，虚拟机在搜索完Bootstrap后就搜索该目录下的jar文件，用下面这种方式可得到虚拟机使用的Extension搜索路径：\n\n\tSystem.getProperty(\"java.ext.dirs\")\n\n`User`类搜索顺序为：\n\n1. `-classpath`指定的路径\n2. 环境变量`CLASSPATH`\n3. 当前目录\n\n在使用`-classpath/-cp`时，多个目录之间用分号分隔。推荐使用该命令来指定虚拟机要搜索的类路径，而不是依赖环境变量，以减少多个项目同时使用环境变量时存在的潜在冲突（多版本库）。\n\n可在运行时通过下面的代码获取虚拟机查找类的路径：\n\n\tSystem.getProperty(\"java.class.path\")\n\n**-D<propertyName>=value**\n\n在虚拟机的系统属性中设置属性名/值对，运行在此虚拟机上的应用程序可用：\n\n\tSystem.getProperty(\"属性名\")\n\n得到value的值。\n\n如果value中有空格，则需要用双引号将该值括起来，如：`-Dname=\"kazaf f\"`。\n\n该参数通常用于设置系统级全局变量值，如配置文件路径，保证该属性在程序中任何地方都可访问。\n\n\n**-verbose[:class|gc|jni]**\n\n在输出设备上显示虚拟机运行信息。 `-verbose`和`-verbose:class`含义相同，表示输出虚拟机装入的类的信息，格式如下：\n\n\t[Loaded java.io.FilePermission$1 from shared objects file]\n\n当虚拟机报告类找不到或类冲突时，用此参数来查看虚拟机装入类的情况。\n\n`-verbose:gc`用于在虚拟机发生内存回收时在输出设备上显示信息，格式如下：\n\n\t[Full GC 268K->168K(1984K), 0.0187390 secs]\n\n`-verbose:jni`用于在虚拟机调用native方法时在设备上输出显示信息，格式如下：\n\t\n\t[Dynamic-linking native method HelloNative.sum ... JNI]\n\n该参数用于监视虚拟机调用本地方法的情况，在发生jni错误时可以为诊断提供便利。\n\n**-ea[:<packagename>...|:<classname>]/-enableassertions[:<packagename>...|:<classname>]**\n\n从jdk1.4开始，java可支持断言机制，用于诊断运行时问题。通常在测试阶段使断言有效，在线上运行时不需要运行断言。断言后的表达式的值是一个逻辑值，为`true`时断言不运行，为`false`时断言抛出`java.lang.AssertionError`错误。\n\n这个参数就是用来设置虚拟机是否启动断言机制，缺省时虚拟机关闭断言机制，用`-ea`可打开断言机制，不加`packagename`和`classname`表示运行所有包和类中的断言，如果希望只是运行某些包或类中的断言，可将包名或类名加到`-ea`之后，例如：`-ea:com.foo.util`。\n\n**-da[:<packagename>...|:<classname>]/-disableassertions[:<packagename>...|:<classname>]**\n用来设置虚拟机关闭断言处理，用法与`-ea`类似。\n\n**-esa/-enablessystemassertions**\n\n设置虚拟机开启系统类的断言。\n\n**-dsa/-disablesystemassertions**\n\n设置虚拟机关闭系统类的断言。\n\n**-agentlib:<libname>[=<options>]**\n\n该参数是jdk5新引入的，用于虚拟机装载本地代理库。其中`libname`为本地代理库文件名，虚拟机的搜索路径为环境变量`path`中的路径，`options`为传给本地库启动时的参数，多个参数之间用逗号分隔。\n\n在win平台中，虚拟机搜索本地库后缀名名为`.dll`，在Unix上则为`.so`文件。例如可以用`-agentlib:hprof`来获取虚拟机的运行情况。可用`-agentlib:hprof=help`来得到使用帮助列表（确保在win平台下的jre的`lib`目录下存在`hprof.dll`文件）。\n\n**-agentpath:<jarpath>[=<options>]**\n\n设置虚拟机按全路径装载本地库，不再搜索`PATH`中的路径，其他功能同`-agentlib`。\n\n**-javaagent:<jarpath>[=<options>]**\n\n虚拟机启动时装入java语言设备代理。`jarpath`文件中的`mainfest`文件必须有`Agent-Class`属性。代理类要实现\n\n\tpublic static void premain(String agentArgs, Instrumentation inst)\n\n方法。当虚拟机初始化时，将按照代理类的说明顺序调用`premain`方法。\n\n扩展参数说明\n---\n\n**-Xmixed**\n\n设置`-client`模式虚拟机对使用频率高的方法进行`Just-In-Time`编译和执行，对其他方法使用解释方式执行，该方式是虚拟机缺省模式。\n\n**-Xint**\n\n设置`-client`模式下运行的虚拟机以解释方式执行类的字节码，不将字节码编译为本机码。\n\n**-Xbootclasspath[/a|/p]:path**\n\n改变虚拟机装载缺省系统运行包`rt.jar`的路径，从`-Xbootclasspath`中设定的搜索路径中装载运行类。除非你自己能写一个运行时，否则不会用到这个参数。\n\n其中`/a`将在缺省搜索路径后加上path中的搜索路径，而`/p`在缺省路径前先搜索path中的路径。\n\n**-Xnoclassgc**\n\n关闭虚拟机对class的垃圾回收功能。\n\n**-Xincgc**\n\n启动增量垃圾收集器，缺省是关闭的。增量垃圾收集器能减少偶尔发生的长时间的垃圾回收造成的暂停时间。但增量垃圾收集器和应用程序并发执行，因此会占用部分CPU在应用程序上的功能。\n\n**-Xloggc:<file>**\n\n将虚拟机每次垃圾回收的信息写到日志文件中，文件名由`file`指定，内容和`-verbose:gc`输出内容相同。\n\n**-Xbatch**\n\n虚拟机的缺省运行方式是在后台编译类代码，然后在前台执行代码，使用该参数将关闭虚拟机后台编译，在前台编译完成后再执行。\n\n**-Xms<size>**\n\n设置虚拟机可用内存堆的初始大小，缺省单位为字节。该大小为1024的整数倍并且要大于1MB，可用k(K)或m(M)为单位来设置较大的内存数。初始堆的大小为2MB。例如：`-Xms6400K`、`-Xms256M`\n\n**-Xmx<size>**\n\n设置虚拟机内存堆的最大可用大小，缺省单位为字节，缺省堆最大值为64MB。该值必须为1024整数倍并且要大于2MB，可用k(K)或m(M)为单位来设置较大的内存数。\n\n当应用程序申请了大内存，运行时虚拟机抛出`java.lang.OutOfMemoryError: Java heap space`错误，就需要用改参数设置更大的内存数。\n\n**-Xss<size>**\n\n设置线程栈的大小，缺省单位为字节，通常操作系统分配给线程栈的缺省大小为1MB。另外，也可以在java中创建线程对象时设置栈的大小，构造函数原型为：\n\n\tThread(ThreadGroup group, Runnable target, String name, long stackSzie)\n\n**-Xprof**\n\n输出CPU运行时的诊断信息。\n\n**-Xfuture**\n\n对类文件进行严格格式检查，以保证类代码符合类代码规范。为保证向后兼容，虚拟机缺省不进行严格的格式检查。\n\n**-Xrs**\n\n减少虚拟机中操作系统的信号的使用。该参数通常在虚拟机以后台服务方式运行时使用（如Serlet）。\n\n**-Xcheck:jni**\n\n对jni函数执行检查。\n\n**-Xshare:off**\n\n不尝试使用共享类的数据\n\n**-Xshare:auto**\n\n在可能的情况下使用共享类的数据，默认值。\n\n**-Xshare:on**\n\n要求使用共享类的数据，否则运行失败。","source":"_posts/java命令行运行参数.md","raw":"title: java命令行参数\ndate: 2014-07-28 14:53:12\ntags: \n- jvm\ncategories: java\n---\n\n妈蛋，实在是顶不住部分文章的排版，看着太让人心焦了~~所以，对一篇文章重新排版一下，希望能帮助到其他人~\n\n先发出[原文链接](http://xinklabi.iteye.com/blog/837435)，供眼神好的童鞋~~\n\n<!-- more -->\n\n下面是小弟排版后的内容：\n\nJava在运行已编译完成的类时，是通过java虚拟机来装载和执行的，java虚拟机通过操作系统命令`JAVA_HOME\"bin/\"java -option`来启动，`option`为虚拟机参数， `JAVA_HOME`为JDK安装路径，通过虚拟机参数可对虚拟机的运行状态进行调整，掌握参数的含义可对虚拟机的运行模式有更深入的理解。\n\n如何查看参数列表\n---\n虚拟机参数分为基本和扩展两类，在命令行中输入`JAVA_HOME\"bin/\"java`就可得到基本的参数列表，在命令行中输入`JAVA_HOME\"bin/\"java -X`就可以得到扩展参数列表。\n\n基本参数说明\n---\n\n**-client/-server**\n\n这两个参数用于设置虚拟机使用何种运行模式，`client`模式启动比较快，但运行时性能和内存管理效率不如`server`模式，通常用于客户端应用程序。相反，`server`模式启动稍慢，但可获得更高的运行性能。\n\n在win上，缺省的虚拟机类型为`client`模式，如果要使用`server`模式就需要在启动虚拟机时加上`-server`参数，以获得更高性能。对服务器应用，推荐采用`server`模式，尤其是多个cpu的系统。\n\n在Linux，Solaris上缺省采用的是`server`模式。\n\n**-hotspot**\n\n含义与`client`相同，jdk1.4以前使用的参数，现在已经不再使用，取而代之的是`client`。\n\n**-classpath/-cp**\n\n虚拟机在运行一个类时需要将其装入内存，搜索类的方式和顺序如下：\n\n1. Bootstrap classes\n2. Extension Classes\n3. User Classes\n\n`Bootstrap`中的路径是虚拟机自带的jar或zip文件，虚拟机首选搜索这些包文件，用下面这种方式可得到虚拟机搜索的路径：\n\n\tSystem.getProperty(\"sun.boot.class.path\")\n\n`Extension`位于jre的`lib/ext`目录下的jar文件，虚拟机在搜索完Bootstrap后就搜索该目录下的jar文件，用下面这种方式可得到虚拟机使用的Extension搜索路径：\n\n\tSystem.getProperty(\"java.ext.dirs\")\n\n`User`类搜索顺序为：\n\n1. `-classpath`指定的路径\n2. 环境变量`CLASSPATH`\n3. 当前目录\n\n在使用`-classpath/-cp`时，多个目录之间用分号分隔。推荐使用该命令来指定虚拟机要搜索的类路径，而不是依赖环境变量，以减少多个项目同时使用环境变量时存在的潜在冲突（多版本库）。\n\n可在运行时通过下面的代码获取虚拟机查找类的路径：\n\n\tSystem.getProperty(\"java.class.path\")\n\n**-D<propertyName>=value**\n\n在虚拟机的系统属性中设置属性名/值对，运行在此虚拟机上的应用程序可用：\n\n\tSystem.getProperty(\"属性名\")\n\n得到value的值。\n\n如果value中有空格，则需要用双引号将该值括起来，如：`-Dname=\"kazaf f\"`。\n\n该参数通常用于设置系统级全局变量值，如配置文件路径，保证该属性在程序中任何地方都可访问。\n\n\n**-verbose[:class|gc|jni]**\n\n在输出设备上显示虚拟机运行信息。 `-verbose`和`-verbose:class`含义相同，表示输出虚拟机装入的类的信息，格式如下：\n\n\t[Loaded java.io.FilePermission$1 from shared objects file]\n\n当虚拟机报告类找不到或类冲突时，用此参数来查看虚拟机装入类的情况。\n\n`-verbose:gc`用于在虚拟机发生内存回收时在输出设备上显示信息，格式如下：\n\n\t[Full GC 268K->168K(1984K), 0.0187390 secs]\n\n`-verbose:jni`用于在虚拟机调用native方法时在设备上输出显示信息，格式如下：\n\t\n\t[Dynamic-linking native method HelloNative.sum ... JNI]\n\n该参数用于监视虚拟机调用本地方法的情况，在发生jni错误时可以为诊断提供便利。\n\n**-ea[:<packagename>...|:<classname>]/-enableassertions[:<packagename>...|:<classname>]**\n\n从jdk1.4开始，java可支持断言机制，用于诊断运行时问题。通常在测试阶段使断言有效，在线上运行时不需要运行断言。断言后的表达式的值是一个逻辑值，为`true`时断言不运行，为`false`时断言抛出`java.lang.AssertionError`错误。\n\n这个参数就是用来设置虚拟机是否启动断言机制，缺省时虚拟机关闭断言机制，用`-ea`可打开断言机制，不加`packagename`和`classname`表示运行所有包和类中的断言，如果希望只是运行某些包或类中的断言，可将包名或类名加到`-ea`之后，例如：`-ea:com.foo.util`。\n\n**-da[:<packagename>...|:<classname>]/-disableassertions[:<packagename>...|:<classname>]**\n用来设置虚拟机关闭断言处理，用法与`-ea`类似。\n\n**-esa/-enablessystemassertions**\n\n设置虚拟机开启系统类的断言。\n\n**-dsa/-disablesystemassertions**\n\n设置虚拟机关闭系统类的断言。\n\n**-agentlib:<libname>[=<options>]**\n\n该参数是jdk5新引入的，用于虚拟机装载本地代理库。其中`libname`为本地代理库文件名，虚拟机的搜索路径为环境变量`path`中的路径，`options`为传给本地库启动时的参数，多个参数之间用逗号分隔。\n\n在win平台中，虚拟机搜索本地库后缀名名为`.dll`，在Unix上则为`.so`文件。例如可以用`-agentlib:hprof`来获取虚拟机的运行情况。可用`-agentlib:hprof=help`来得到使用帮助列表（确保在win平台下的jre的`lib`目录下存在`hprof.dll`文件）。\n\n**-agentpath:<jarpath>[=<options>]**\n\n设置虚拟机按全路径装载本地库，不再搜索`PATH`中的路径，其他功能同`-agentlib`。\n\n**-javaagent:<jarpath>[=<options>]**\n\n虚拟机启动时装入java语言设备代理。`jarpath`文件中的`mainfest`文件必须有`Agent-Class`属性。代理类要实现\n\n\tpublic static void premain(String agentArgs, Instrumentation inst)\n\n方法。当虚拟机初始化时，将按照代理类的说明顺序调用`premain`方法。\n\n扩展参数说明\n---\n\n**-Xmixed**\n\n设置`-client`模式虚拟机对使用频率高的方法进行`Just-In-Time`编译和执行，对其他方法使用解释方式执行，该方式是虚拟机缺省模式。\n\n**-Xint**\n\n设置`-client`模式下运行的虚拟机以解释方式执行类的字节码，不将字节码编译为本机码。\n\n**-Xbootclasspath[/a|/p]:path**\n\n改变虚拟机装载缺省系统运行包`rt.jar`的路径，从`-Xbootclasspath`中设定的搜索路径中装载运行类。除非你自己能写一个运行时，否则不会用到这个参数。\n\n其中`/a`将在缺省搜索路径后加上path中的搜索路径，而`/p`在缺省路径前先搜索path中的路径。\n\n**-Xnoclassgc**\n\n关闭虚拟机对class的垃圾回收功能。\n\n**-Xincgc**\n\n启动增量垃圾收集器，缺省是关闭的。增量垃圾收集器能减少偶尔发生的长时间的垃圾回收造成的暂停时间。但增量垃圾收集器和应用程序并发执行，因此会占用部分CPU在应用程序上的功能。\n\n**-Xloggc:<file>**\n\n将虚拟机每次垃圾回收的信息写到日志文件中，文件名由`file`指定，内容和`-verbose:gc`输出内容相同。\n\n**-Xbatch**\n\n虚拟机的缺省运行方式是在后台编译类代码，然后在前台执行代码，使用该参数将关闭虚拟机后台编译，在前台编译完成后再执行。\n\n**-Xms<size>**\n\n设置虚拟机可用内存堆的初始大小，缺省单位为字节。该大小为1024的整数倍并且要大于1MB，可用k(K)或m(M)为单位来设置较大的内存数。初始堆的大小为2MB。例如：`-Xms6400K`、`-Xms256M`\n\n**-Xmx<size>**\n\n设置虚拟机内存堆的最大可用大小，缺省单位为字节，缺省堆最大值为64MB。该值必须为1024整数倍并且要大于2MB，可用k(K)或m(M)为单位来设置较大的内存数。\n\n当应用程序申请了大内存，运行时虚拟机抛出`java.lang.OutOfMemoryError: Java heap space`错误，就需要用改参数设置更大的内存数。\n\n**-Xss<size>**\n\n设置线程栈的大小，缺省单位为字节，通常操作系统分配给线程栈的缺省大小为1MB。另外，也可以在java中创建线程对象时设置栈的大小，构造函数原型为：\n\n\tThread(ThreadGroup group, Runnable target, String name, long stackSzie)\n\n**-Xprof**\n\n输出CPU运行时的诊断信息。\n\n**-Xfuture**\n\n对类文件进行严格格式检查，以保证类代码符合类代码规范。为保证向后兼容，虚拟机缺省不进行严格的格式检查。\n\n**-Xrs**\n\n减少虚拟机中操作系统的信号的使用。该参数通常在虚拟机以后台服务方式运行时使用（如Serlet）。\n\n**-Xcheck:jni**\n\n对jni函数执行检查。\n\n**-Xshare:off**\n\n不尝试使用共享类的数据\n\n**-Xshare:auto**\n\n在可能的情况下使用共享类的数据，默认值。\n\n**-Xshare:on**\n\n要求使用共享类的数据，否则运行失败。","slug":"java命令行运行参数","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18yp70088gtfyxl9dwxvd","comments":1,"layout":"post","photos":[],"link":"","content":"<p>妈蛋，实在是顶不住部分文章的排版，看着太让人心焦了~~所以，对一篇文章重新排版一下，希望能帮助到其他人~</p>\n<p>先发出<a href=\"http://xinklabi.iteye.com/blog/837435\" target=\"_blank\" rel=\"external\">原文链接</a>，供眼神好的童鞋~~</p>\n<a id=\"more\"></a>\n<p>下面是小弟排版后的内容：</p>\n<p>Java在运行已编译完成的类时，是通过java虚拟机来装载和执行的，java虚拟机通过操作系统命令<code>JAVA_HOME&quot;bin/&quot;java -option</code>来启动，<code>option</code>为虚拟机参数， <code>JAVA_HOME</code>为JDK安装路径，通过虚拟机参数可对虚拟机的运行状态进行调整，掌握参数的含义可对虚拟机的运行模式有更深入的理解。</p>\n<h2 id=\"如何查看参数列表\"><a href=\"#如何查看参数列表\" class=\"headerlink\" title=\"如何查看参数列表\"></a>如何查看参数列表</h2><p>虚拟机参数分为基本和扩展两类，在命令行中输入<code>JAVA_HOME&quot;bin/&quot;java</code>就可得到基本的参数列表，在命令行中输入<code>JAVA_HOME&quot;bin/&quot;java -X</code>就可以得到扩展参数列表。</p>\n<h2 id=\"基本参数说明\"><a href=\"#基本参数说明\" class=\"headerlink\" title=\"基本参数说明\"></a>基本参数说明</h2><p><strong>-client/-server</strong></p>\n<p>这两个参数用于设置虚拟机使用何种运行模式，<code>client</code>模式启动比较快，但运行时性能和内存管理效率不如<code>server</code>模式，通常用于客户端应用程序。相反，<code>server</code>模式启动稍慢，但可获得更高的运行性能。</p>\n<p>在win上，缺省的虚拟机类型为<code>client</code>模式，如果要使用<code>server</code>模式就需要在启动虚拟机时加上<code>-server</code>参数，以获得更高性能。对服务器应用，推荐采用<code>server</code>模式，尤其是多个cpu的系统。</p>\n<p>在Linux，Solaris上缺省采用的是<code>server</code>模式。</p>\n<p><strong>-hotspot</strong></p>\n<p>含义与<code>client</code>相同，jdk1.4以前使用的参数，现在已经不再使用，取而代之的是<code>client</code>。</p>\n<p><strong>-classpath/-cp</strong></p>\n<p>虚拟机在运行一个类时需要将其装入内存，搜索类的方式和顺序如下：</p>\n<ol>\n<li>Bootstrap classes</li>\n<li>Extension Classes</li>\n<li>User Classes</li>\n</ol>\n<p><code>Bootstrap</code>中的路径是虚拟机自带的jar或zip文件，虚拟机首选搜索这些包文件，用下面这种方式可得到虚拟机搜索的路径：</p>\n<pre><code>System.getProperty(&quot;sun.boot.class.path&quot;)\n</code></pre><p><code>Extension</code>位于jre的<code>lib/ext</code>目录下的jar文件，虚拟机在搜索完Bootstrap后就搜索该目录下的jar文件，用下面这种方式可得到虚拟机使用的Extension搜索路径：</p>\n<pre><code>System.getProperty(&quot;java.ext.dirs&quot;)\n</code></pre><p><code>User</code>类搜索顺序为：</p>\n<ol>\n<li><code>-classpath</code>指定的路径</li>\n<li>环境变量<code>CLASSPATH</code></li>\n<li>当前目录</li>\n</ol>\n<p>在使用<code>-classpath/-cp</code>时，多个目录之间用分号分隔。推荐使用该命令来指定虚拟机要搜索的类路径，而不是依赖环境变量，以减少多个项目同时使用环境变量时存在的潜在冲突（多版本库）。</p>\n<p>可在运行时通过下面的代码获取虚拟机查找类的路径：</p>\n<pre><code>System.getProperty(&quot;java.class.path&quot;)\n</code></pre><p><strong>-D<propertyname>=value</propertyname></strong></p>\n<p>在虚拟机的系统属性中设置属性名/值对，运行在此虚拟机上的应用程序可用：</p>\n<pre><code>System.getProperty(&quot;属性名&quot;)\n</code></pre><p>得到value的值。</p>\n<p>如果value中有空格，则需要用双引号将该值括起来，如：<code>-Dname=&quot;kazaf f&quot;</code>。</p>\n<p>该参数通常用于设置系统级全局变量值，如配置文件路径，保证该属性在程序中任何地方都可访问。</p>\n<p><strong>-verbose[:class|gc|jni]</strong></p>\n<p>在输出设备上显示虚拟机运行信息。 <code>-verbose</code>和<code>-verbose:class</code>含义相同，表示输出虚拟机装入的类的信息，格式如下：</p>\n<pre><code>[Loaded java.io.FilePermission$1 from shared objects file]\n</code></pre><p>当虚拟机报告类找不到或类冲突时，用此参数来查看虚拟机装入类的情况。</p>\n<p><code>-verbose:gc</code>用于在虚拟机发生内存回收时在输出设备上显示信息，格式如下：</p>\n<pre><code>[Full GC 268K-&gt;168K(1984K), 0.0187390 secs]\n</code></pre><p><code>-verbose:jni</code>用于在虚拟机调用native方法时在设备上输出显示信息，格式如下：</p>\n<pre><code>[Dynamic-linking native method HelloNative.sum ... JNI]\n</code></pre><p>该参数用于监视虚拟机调用本地方法的情况，在发生jni错误时可以为诊断提供便利。</p>\n<p><strong>-ea[:<packagename>…|:<classname>]/-enableassertions[:<packagename>…|:<classname>]</classname></packagename></classname></packagename></strong></p>\n<p>从jdk1.4开始，java可支持断言机制，用于诊断运行时问题。通常在测试阶段使断言有效，在线上运行时不需要运行断言。断言后的表达式的值是一个逻辑值，为<code>true</code>时断言不运行，为<code>false</code>时断言抛出<code>java.lang.AssertionError</code>错误。</p>\n<p>这个参数就是用来设置虚拟机是否启动断言机制，缺省时虚拟机关闭断言机制，用<code>-ea</code>可打开断言机制，不加<code>packagename</code>和<code>classname</code>表示运行所有包和类中的断言，如果希望只是运行某些包或类中的断言，可将包名或类名加到<code>-ea</code>之后，例如：<code>-ea:com.foo.util</code>。</p>\n<p><strong>-da[:<packagename>…|:<classname>]/-disableassertions[:<packagename>…|:<classname>]</classname></packagename></classname></packagename></strong><br>用来设置虚拟机关闭断言处理，用法与<code>-ea</code>类似。</p>\n<p><strong>-esa/-enablessystemassertions</strong></p>\n<p>设置虚拟机开启系统类的断言。</p>\n<p><strong>-dsa/-disablesystemassertions</strong></p>\n<p>设置虚拟机关闭系统类的断言。</p>\n<p><strong>-agentlib:<libname>[=<options>]</options></libname></strong></p>\n<p>该参数是jdk5新引入的，用于虚拟机装载本地代理库。其中<code>libname</code>为本地代理库文件名，虚拟机的搜索路径为环境变量<code>path</code>中的路径，<code>options</code>为传给本地库启动时的参数，多个参数之间用逗号分隔。</p>\n<p>在win平台中，虚拟机搜索本地库后缀名名为<code>.dll</code>，在Unix上则为<code>.so</code>文件。例如可以用<code>-agentlib:hprof</code>来获取虚拟机的运行情况。可用<code>-agentlib:hprof=help</code>来得到使用帮助列表（确保在win平台下的jre的<code>lib</code>目录下存在<code>hprof.dll</code>文件）。</p>\n<p><strong>-agentpath:<jarpath>[=<options>]</options></jarpath></strong></p>\n<p>设置虚拟机按全路径装载本地库，不再搜索<code>PATH</code>中的路径，其他功能同<code>-agentlib</code>。</p>\n<p><strong>-javaagent:<jarpath>[=<options>]</options></jarpath></strong></p>\n<p>虚拟机启动时装入java语言设备代理。<code>jarpath</code>文件中的<code>mainfest</code>文件必须有<code>Agent-Class</code>属性。代理类要实现</p>\n<pre><code>public static void premain(String agentArgs, Instrumentation inst)\n</code></pre><p>方法。当虚拟机初始化时，将按照代理类的说明顺序调用<code>premain</code>方法。</p>\n<h2 id=\"扩展参数说明\"><a href=\"#扩展参数说明\" class=\"headerlink\" title=\"扩展参数说明\"></a>扩展参数说明</h2><p><strong>-Xmixed</strong></p>\n<p>设置<code>-client</code>模式虚拟机对使用频率高的方法进行<code>Just-In-Time</code>编译和执行，对其他方法使用解释方式执行，该方式是虚拟机缺省模式。</p>\n<p><strong>-Xint</strong></p>\n<p>设置<code>-client</code>模式下运行的虚拟机以解释方式执行类的字节码，不将字节码编译为本机码。</p>\n<p><strong>-Xbootclasspath[/a|/p]:path</strong></p>\n<p>改变虚拟机装载缺省系统运行包<code>rt.jar</code>的路径，从<code>-Xbootclasspath</code>中设定的搜索路径中装载运行类。除非你自己能写一个运行时，否则不会用到这个参数。</p>\n<p>其中<code>/a</code>将在缺省搜索路径后加上path中的搜索路径，而<code>/p</code>在缺省路径前先搜索path中的路径。</p>\n<p><strong>-Xnoclassgc</strong></p>\n<p>关闭虚拟机对class的垃圾回收功能。</p>\n<p><strong>-Xincgc</strong></p>\n<p>启动增量垃圾收集器，缺省是关闭的。增量垃圾收集器能减少偶尔发生的长时间的垃圾回收造成的暂停时间。但增量垃圾收集器和应用程序并发执行，因此会占用部分CPU在应用程序上的功能。</p>\n<p><strong>-Xloggc:<file></file></strong></p>\n<p>将虚拟机每次垃圾回收的信息写到日志文件中，文件名由<code>file</code>指定，内容和<code>-verbose:gc</code>输出内容相同。</p>\n<p><strong>-Xbatch</strong></p>\n<p>虚拟机的缺省运行方式是在后台编译类代码，然后在前台执行代码，使用该参数将关闭虚拟机后台编译，在前台编译完成后再执行。</p>\n<p><strong>-Xms<size></size></strong></p>\n<p>设置虚拟机可用内存堆的初始大小，缺省单位为字节。该大小为1024的整数倍并且要大于1MB，可用k(K)或m(M)为单位来设置较大的内存数。初始堆的大小为2MB。例如：<code>-Xms6400K</code>、<code>-Xms256M</code></p>\n<p><strong>-Xmx<size></size></strong></p>\n<p>设置虚拟机内存堆的最大可用大小，缺省单位为字节，缺省堆最大值为64MB。该值必须为1024整数倍并且要大于2MB，可用k(K)或m(M)为单位来设置较大的内存数。</p>\n<p>当应用程序申请了大内存，运行时虚拟机抛出<code>java.lang.OutOfMemoryError: Java heap space</code>错误，就需要用改参数设置更大的内存数。</p>\n<p><strong>-Xss<size></size></strong></p>\n<p>设置线程栈的大小，缺省单位为字节，通常操作系统分配给线程栈的缺省大小为1MB。另外，也可以在java中创建线程对象时设置栈的大小，构造函数原型为：</p>\n<pre><code>Thread(ThreadGroup group, Runnable target, String name, long stackSzie)\n</code></pre><p><strong>-Xprof</strong></p>\n<p>输出CPU运行时的诊断信息。</p>\n<p><strong>-Xfuture</strong></p>\n<p>对类文件进行严格格式检查，以保证类代码符合类代码规范。为保证向后兼容，虚拟机缺省不进行严格的格式检查。</p>\n<p><strong>-Xrs</strong></p>\n<p>减少虚拟机中操作系统的信号的使用。该参数通常在虚拟机以后台服务方式运行时使用（如Serlet）。</p>\n<p><strong>-Xcheck:jni</strong></p>\n<p>对jni函数执行检查。</p>\n<p><strong>-Xshare:off</strong></p>\n<p>不尝试使用共享类的数据</p>\n<p><strong>-Xshare:auto</strong></p>\n<p>在可能的情况下使用共享类的数据，默认值。</p>\n<p><strong>-Xshare:on</strong></p>\n<p>要求使用共享类的数据，否则运行失败。</p>\n","excerpt":"<p>妈蛋，实在是顶不住部分文章的排版，看着太让人心焦了~~所以，对一篇文章重新排版一下，希望能帮助到其他人~</p>\n<p>先发出<a href=\"http://xinklabi.iteye.com/blog/837435\">原文链接</a>，供眼神好的童鞋~~</p>","more":"<p>下面是小弟排版后的内容：</p>\n<p>Java在运行已编译完成的类时，是通过java虚拟机来装载和执行的，java虚拟机通过操作系统命令<code>JAVA_HOME&quot;bin/&quot;java -option</code>来启动，<code>option</code>为虚拟机参数， <code>JAVA_HOME</code>为JDK安装路径，通过虚拟机参数可对虚拟机的运行状态进行调整，掌握参数的含义可对虚拟机的运行模式有更深入的理解。</p>\n<h2 id=\"如何查看参数列表\"><a href=\"#如何查看参数列表\" class=\"headerlink\" title=\"如何查看参数列表\"></a>如何查看参数列表</h2><p>虚拟机参数分为基本和扩展两类，在命令行中输入<code>JAVA_HOME&quot;bin/&quot;java</code>就可得到基本的参数列表，在命令行中输入<code>JAVA_HOME&quot;bin/&quot;java -X</code>就可以得到扩展参数列表。</p>\n<h2 id=\"基本参数说明\"><a href=\"#基本参数说明\" class=\"headerlink\" title=\"基本参数说明\"></a>基本参数说明</h2><p><strong>-client/-server</strong></p>\n<p>这两个参数用于设置虚拟机使用何种运行模式，<code>client</code>模式启动比较快，但运行时性能和内存管理效率不如<code>server</code>模式，通常用于客户端应用程序。相反，<code>server</code>模式启动稍慢，但可获得更高的运行性能。</p>\n<p>在win上，缺省的虚拟机类型为<code>client</code>模式，如果要使用<code>server</code>模式就需要在启动虚拟机时加上<code>-server</code>参数，以获得更高性能。对服务器应用，推荐采用<code>server</code>模式，尤其是多个cpu的系统。</p>\n<p>在Linux，Solaris上缺省采用的是<code>server</code>模式。</p>\n<p><strong>-hotspot</strong></p>\n<p>含义与<code>client</code>相同，jdk1.4以前使用的参数，现在已经不再使用，取而代之的是<code>client</code>。</p>\n<p><strong>-classpath/-cp</strong></p>\n<p>虚拟机在运行一个类时需要将其装入内存，搜索类的方式和顺序如下：</p>\n<ol>\n<li>Bootstrap classes</li>\n<li>Extension Classes</li>\n<li>User Classes</li>\n</ol>\n<p><code>Bootstrap</code>中的路径是虚拟机自带的jar或zip文件，虚拟机首选搜索这些包文件，用下面这种方式可得到虚拟机搜索的路径：</p>\n<pre><code>System.getProperty(&quot;sun.boot.class.path&quot;)\n</code></pre><p><code>Extension</code>位于jre的<code>lib/ext</code>目录下的jar文件，虚拟机在搜索完Bootstrap后就搜索该目录下的jar文件，用下面这种方式可得到虚拟机使用的Extension搜索路径：</p>\n<pre><code>System.getProperty(&quot;java.ext.dirs&quot;)\n</code></pre><p><code>User</code>类搜索顺序为：</p>\n<ol>\n<li><code>-classpath</code>指定的路径</li>\n<li>环境变量<code>CLASSPATH</code></li>\n<li>当前目录</li>\n</ol>\n<p>在使用<code>-classpath/-cp</code>时，多个目录之间用分号分隔。推荐使用该命令来指定虚拟机要搜索的类路径，而不是依赖环境变量，以减少多个项目同时使用环境变量时存在的潜在冲突（多版本库）。</p>\n<p>可在运行时通过下面的代码获取虚拟机查找类的路径：</p>\n<pre><code>System.getProperty(&quot;java.class.path&quot;)\n</code></pre><p><strong>-D<propertyName>=value</strong></p>\n<p>在虚拟机的系统属性中设置属性名/值对，运行在此虚拟机上的应用程序可用：</p>\n<pre><code>System.getProperty(&quot;属性名&quot;)\n</code></pre><p>得到value的值。</p>\n<p>如果value中有空格，则需要用双引号将该值括起来，如：<code>-Dname=&quot;kazaf f&quot;</code>。</p>\n<p>该参数通常用于设置系统级全局变量值，如配置文件路径，保证该属性在程序中任何地方都可访问。</p>\n<p><strong>-verbose[:class|gc|jni]</strong></p>\n<p>在输出设备上显示虚拟机运行信息。 <code>-verbose</code>和<code>-verbose:class</code>含义相同，表示输出虚拟机装入的类的信息，格式如下：</p>\n<pre><code>[Loaded java.io.FilePermission$1 from shared objects file]\n</code></pre><p>当虚拟机报告类找不到或类冲突时，用此参数来查看虚拟机装入类的情况。</p>\n<p><code>-verbose:gc</code>用于在虚拟机发生内存回收时在输出设备上显示信息，格式如下：</p>\n<pre><code>[Full GC 268K-&gt;168K(1984K), 0.0187390 secs]\n</code></pre><p><code>-verbose:jni</code>用于在虚拟机调用native方法时在设备上输出显示信息，格式如下：</p>\n<pre><code>[Dynamic-linking native method HelloNative.sum ... JNI]\n</code></pre><p>该参数用于监视虚拟机调用本地方法的情况，在发生jni错误时可以为诊断提供便利。</p>\n<p><strong>-ea[:<packagename>…|:<classname>]/-enableassertions[:<packagename>…|:<classname>]</strong></p>\n<p>从jdk1.4开始，java可支持断言机制，用于诊断运行时问题。通常在测试阶段使断言有效，在线上运行时不需要运行断言。断言后的表达式的值是一个逻辑值，为<code>true</code>时断言不运行，为<code>false</code>时断言抛出<code>java.lang.AssertionError</code>错误。</p>\n<p>这个参数就是用来设置虚拟机是否启动断言机制，缺省时虚拟机关闭断言机制，用<code>-ea</code>可打开断言机制，不加<code>packagename</code>和<code>classname</code>表示运行所有包和类中的断言，如果希望只是运行某些包或类中的断言，可将包名或类名加到<code>-ea</code>之后，例如：<code>-ea:com.foo.util</code>。</p>\n<p><strong>-da[:<packagename>…|:<classname>]/-disableassertions[:<packagename>…|:<classname>]</strong><br>用来设置虚拟机关闭断言处理，用法与<code>-ea</code>类似。</p>\n<p><strong>-esa/-enablessystemassertions</strong></p>\n<p>设置虚拟机开启系统类的断言。</p>\n<p><strong>-dsa/-disablesystemassertions</strong></p>\n<p>设置虚拟机关闭系统类的断言。</p>\n<p><strong>-agentlib:<libname>[=<options>]</strong></p>\n<p>该参数是jdk5新引入的，用于虚拟机装载本地代理库。其中<code>libname</code>为本地代理库文件名，虚拟机的搜索路径为环境变量<code>path</code>中的路径，<code>options</code>为传给本地库启动时的参数，多个参数之间用逗号分隔。</p>\n<p>在win平台中，虚拟机搜索本地库后缀名名为<code>.dll</code>，在Unix上则为<code>.so</code>文件。例如可以用<code>-agentlib:hprof</code>来获取虚拟机的运行情况。可用<code>-agentlib:hprof=help</code>来得到使用帮助列表（确保在win平台下的jre的<code>lib</code>目录下存在<code>hprof.dll</code>文件）。</p>\n<p><strong>-agentpath:<jarpath>[=<options>]</strong></p>\n<p>设置虚拟机按全路径装载本地库，不再搜索<code>PATH</code>中的路径，其他功能同<code>-agentlib</code>。</p>\n<p><strong>-javaagent:<jarpath>[=<options>]</strong></p>\n<p>虚拟机启动时装入java语言设备代理。<code>jarpath</code>文件中的<code>mainfest</code>文件必须有<code>Agent-Class</code>属性。代理类要实现</p>\n<pre><code>public static void premain(String agentArgs, Instrumentation inst)\n</code></pre><p>方法。当虚拟机初始化时，将按照代理类的说明顺序调用<code>premain</code>方法。</p>\n<h2 id=\"扩展参数说明\"><a href=\"#扩展参数说明\" class=\"headerlink\" title=\"扩展参数说明\"></a>扩展参数说明</h2><p><strong>-Xmixed</strong></p>\n<p>设置<code>-client</code>模式虚拟机对使用频率高的方法进行<code>Just-In-Time</code>编译和执行，对其他方法使用解释方式执行，该方式是虚拟机缺省模式。</p>\n<p><strong>-Xint</strong></p>\n<p>设置<code>-client</code>模式下运行的虚拟机以解释方式执行类的字节码，不将字节码编译为本机码。</p>\n<p><strong>-Xbootclasspath[/a|/p]:path</strong></p>\n<p>改变虚拟机装载缺省系统运行包<code>rt.jar</code>的路径，从<code>-Xbootclasspath</code>中设定的搜索路径中装载运行类。除非你自己能写一个运行时，否则不会用到这个参数。</p>\n<p>其中<code>/a</code>将在缺省搜索路径后加上path中的搜索路径，而<code>/p</code>在缺省路径前先搜索path中的路径。</p>\n<p><strong>-Xnoclassgc</strong></p>\n<p>关闭虚拟机对class的垃圾回收功能。</p>\n<p><strong>-Xincgc</strong></p>\n<p>启动增量垃圾收集器，缺省是关闭的。增量垃圾收集器能减少偶尔发生的长时间的垃圾回收造成的暂停时间。但增量垃圾收集器和应用程序并发执行，因此会占用部分CPU在应用程序上的功能。</p>\n<p><strong>-Xloggc:<file></strong></p>\n<p>将虚拟机每次垃圾回收的信息写到日志文件中，文件名由<code>file</code>指定，内容和<code>-verbose:gc</code>输出内容相同。</p>\n<p><strong>-Xbatch</strong></p>\n<p>虚拟机的缺省运行方式是在后台编译类代码，然后在前台执行代码，使用该参数将关闭虚拟机后台编译，在前台编译完成后再执行。</p>\n<p><strong>-Xms<size></strong></p>\n<p>设置虚拟机可用内存堆的初始大小，缺省单位为字节。该大小为1024的整数倍并且要大于1MB，可用k(K)或m(M)为单位来设置较大的内存数。初始堆的大小为2MB。例如：<code>-Xms6400K</code>、<code>-Xms256M</code></p>\n<p><strong>-Xmx<size></strong></p>\n<p>设置虚拟机内存堆的最大可用大小，缺省单位为字节，缺省堆最大值为64MB。该值必须为1024整数倍并且要大于2MB，可用k(K)或m(M)为单位来设置较大的内存数。</p>\n<p>当应用程序申请了大内存，运行时虚拟机抛出<code>java.lang.OutOfMemoryError: Java heap space</code>错误，就需要用改参数设置更大的内存数。</p>\n<p><strong>-Xss<size></strong></p>\n<p>设置线程栈的大小，缺省单位为字节，通常操作系统分配给线程栈的缺省大小为1MB。另外，也可以在java中创建线程对象时设置栈的大小，构造函数原型为：</p>\n<pre><code>Thread(ThreadGroup group, Runnable target, String name, long stackSzie)\n</code></pre><p><strong>-Xprof</strong></p>\n<p>输出CPU运行时的诊断信息。</p>\n<p><strong>-Xfuture</strong></p>\n<p>对类文件进行严格格式检查，以保证类代码符合类代码规范。为保证向后兼容，虚拟机缺省不进行严格的格式检查。</p>\n<p><strong>-Xrs</strong></p>\n<p>减少虚拟机中操作系统的信号的使用。该参数通常在虚拟机以后台服务方式运行时使用（如Serlet）。</p>\n<p><strong>-Xcheck:jni</strong></p>\n<p>对jni函数执行检查。</p>\n<p><strong>-Xshare:off</strong></p>\n<p>不尝试使用共享类的数据</p>\n<p><strong>-Xshare:auto</strong></p>\n<p>在可能的情况下使用共享类的数据，默认值。</p>\n<p><strong>-Xshare:on</strong></p>\n<p>要求使用共享类的数据，否则运行失败。</p>"},{"title":"javaEE部署项目新手向","date":"2014-10-23T01:37:12.000Z","_content":"\n\n\n今天主要说的是关于java的web项目部署时候的琐碎。公司之前的几个javaEE项目我都没有参与编码，更别提部署了！不过接下来的项目我就要参与到所有环节中拉，所以趁着有时间，搞一下预备工作，都是很基础的东西，只是作为总结记录下来而已~~\n<!-- more -->\n以问题的方式来排版吧，这样便于阅读：\n\n\n\n\n项目中配置文件里使用的`classpath`到底指向哪里？\n---\n\n可以通过下面这行代码打印出来`classpath`的绝对路径：\n\n\tSystem.out.println(\"当前classpath的绝对路径：\" + Thread.currentThread().getContextClassLoader().getResource(\"\"));\n\n我用Idea13部署项目后可以看到终端中打印出：\n\n\t当前classpath的绝对路径：file:/D:/Program%20Files/apache-tomcat-7.0.53/webapps/springMVCDemo/WEB-INF/classes/\n\n可以看到`classpath`指向的是部署后的`/WEB-INF/classes/`，而这个`classes`文件夹就是存放编译后的`.class`文件的地方。\n\n而这个文件夹在部署之前是不存在的，那么IDE中配置文件里使用的`classpath:`又指向哪里呢？因为像Idea这样的吊炸天IDE都提供即时功能的，比方说我在`web.xml`中添加下面这个配置：\n\n\t...\n    <param-name>contextConfigLocation</param-name>\n    <param-value>classpath:mvc-dispatcher-servlet.xml</param-value>\n\t...\n\nIDE是会帮我检查对应文件夹下是否存在指定文件的，那我们之前说过编译前`classes`文件夹是不存在的，那么IDE又是帮我去哪找的呢？看下图：\n\n<a href=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/8VcSP.png\"><img src=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/medish.jpg\" width=\"640\" height=\"426\" border=\"0\" /></a>\n\n图中左上角中的箭头指向的那个位置就是IDE查找的位置，也就是说`java`文件夹对应着编译后的`classes`文件夹。\n\n上图中的项目是基于springMVC模板的，那文件夹这种对应关系又是在哪里设置的呢？其实不同的IDE都有自己的一套项目文件组织结构，之前公司用的是Netbeans，也有人使用Eclipse的，默认情况下它们的项目结构都不太一样，但是不管你用什么IDE，向Tomcat中部署的时候，都要输出一致的，Tomcat理解的标准目录，在Idea的`Artifacts`窗口下可以定义编译部署的项目结构，上图中下方的箭头和红框标出来的就是我们为了测试而修改`mvc-dispatcher-servlet.xml`位置后需要对应做的修改，这样才能保证IDE部署项目时导出正确的部署结构。\n\t\n\n\n\n\n如何在`Controller`中读取属性文件中的设置？\n---\n\n这个问题网上有不少贴，可以看这里：[传送门](http://kanpiaoxue.iteye.com/blog/1989026)，已经是非常具体了。可以看出，`Controller`中靠注解直接把配置文件中的键值注入到类属性中，很是NB啊！\n\n实际测试中还是需要按照第一个问题里说的那样调整一下`Artifacts`的部署结构，这里我发现在Idea13中，我把属性文件直接放在WEB-INF目录下，IDE中竟然显示找不到文件，但是部署后是正常的，就是显示红色的提示让我看着很不爽，所以才扔到`classes`下的~\n\n\n\n\nnginx代理项目中的静态资源文件\n---\n\n公司前几个小项目都出现了不同程度的性能问题，其中比较早遇见的就是关于静态文件太多导致的响应卡顿的问题！\n\n其实并不能一定断定就是Tomcat处理静态文件不利导致的，只不过看网上大家都吐槽它，还是果断放弃为好~~我们只需要搭建一个反向代理服务即可，这里第一选择肯定就是`Nginx`。\n\n我在自己的开发机上直接尝试搭建这个测试环境，大概环境如下：\n\n\twin7 64bit\n\tjdk1.7\n\ttomcat7\n\tnginx1.7.6\n\n测试项目部署完毕后的目录结构为：\n\n\tspringMVCDemo\n\t\t\t|\n\t\t\t|--images\t//这里就是我们的静态文件夹\n\t\t\t|\n\t\t\t|-WEB-INF\t\t\n\n\t\n好啦，现在直接修改Nginx的配置文件`/conf/nginx.conf`:\n\n\t server {\n        listen       80;\n        server_name  localhost;\n        root \"D:/Program Files/apache-tomcat-7.0.53/webapps/springMVCDemo\";\n\n        location / {\n            proxy_pass http://localhost:8080/springMVCDemo/;\n        }\n\n        location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ {\n\t\t\texpires 30d;\n\t\t}\n\n\t\tlocation ~ .*\\.(js|css)?$ {\n\t\t\texpires 1h;\n\t\t}\n\n很简单吧，这样就搞定了。这里面有个小插曲我需要说一下：我是直接用IDE编译打包成一个`war`文件，然后拷贝到`tomcat`的`webapps`下，由于我的天真，我一直试图尝试在`Nginx`的配置中直接指向`war`文件内部的`images`目录~~哇哈哈哈，网上找了一大圈都没有发现，结果最后才发现一个问题：`tomcat`在启动之初，如果发现需要加载`war`项目，会直接把`war`文件解压出来。阿西吧~\n\n最后，还要叮嘱一件事儿，那就是关于`nginx`的反向代理配置不当造成的安全隐患，具体细节可以看这里： [WooYun](http://drops.wooyun.org/papers/60)。\n\n\n\n\n\n\nspringMVC中静态文件的处理\n---\n\n虽然在上一个问题里我们已经把静态文件交给`Nginx`来处理了，但是我觉得那是生产环境下的配置~~在开发环境下还是要尽可能的直观一些，这样可以让配置较低的开发机更快一些，而且也可以让调试变得简单高效。\n\n其实实现的方法网上说了[好多](http://www.cnblogs.com/fangqi/archive/2012/10/28/2743108.html)，但我还是偏向于使用Spring提供的方式：\n\n\t<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        http://www.springframework.org/schema/context/spring-context.xsd\n        http://www.springframework.org/schema/mvc\n        http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd\">\n\n\t    <context:component-scan base-package=\"me.kazaff.springmvc\"/>\n\t\n\t    <mvc:annotation-driven />\n\t    <mvc:resources mapping=\"/images/**\"  location=\"/images/\" />\n\t\t\n\t\t....\n\n\t</beans>\n\n这样就可以啦，注意在头部要加上`mvc`这个命名空间的定义，一共要修改两个位置哟：\n\n- 在`beans`节点上增加：\n\t\n\txmlns:mvc=\"http://www.springframework.org/schema/mvc\n\n- 在`xsi:schemaLocation`属性上增加：\n\n\thttp://www.springframework.org/schema/mvc\n\thttp://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd\n \n其实在测试中还遇到了一个问题，就是一旦加上`mvc:resources`定义后就会造成无法访问页面，错误是：\n\t\n\t警告: No mapping found for HTTP request with URI [/springMVCDemo/] in DispatcherServlet with name 'mvc-dispatcher'\n\n所以一定要记得加上：\n\t\n\t<mvc:annotation-driven />\n\n理由可以查看这里： [传送门](http://blog.csdn.net/jbgtwang/article/details/7359592)。\n\n\n\n\n\n\n\njavaEE负载均衡环境搭建\n---\n\n接下来我们简单聊一下**高可用**和**可伸缩**的解决方案，我们可以在架构设计上做一些工作，从而使得我们的业务应用服务可以搬到集群中进行部署，至于要达到`可伸缩性`而需要解决的技术点我们暂且不表，毕竟这篇文章是新手向，我们主要聊一下集群环境下的负载均衡话题~~\n\n其实负载均衡不仅仅能做到平摊负载，牛逼一些的负载均衡软件还可以负责自动容灾处理。还拿`Nginx`来说，非常简单，看[这里](http://blog.jobbole.com/24574/)和[那里](http://saiyaren.iteye.com/blog/1914865)。能感觉到还是非常的简单明了吧？这也是`Nginx`能脱颖而出的原因：简单粗暴！\n\n但这个世界没有银弹，我们来看一下常用的负载均衡软件的优缺点：[传送门](http://www.csdn.net/article/2014-07-24/2820837)。\n\n看前辈总结了那么多，心里应该有谱了吧？！上面那一篇文章最大的价值在于描述了一个项目从小到大所处的不同阶段应该做什么样的选择，哥甚是喜欢！\n\n我还找到了一个碉堡的视频共大家观看：[传送门](http://edu.51cto.com/lesson/id-27846.html)。\n\n\n\n\n\n\n如何在一台物理机运行多个tomcat进程？\n---\n\n最后这个问题是非常有意义的，不过你可能会很好奇谁会这么做？首先，部署在同一台物理机上，就谈不上什么**高可用**，毕竟如果这台机器宕机了，所有tomcat实例都会挂掉。而且由于**进程间切换**也会导致性能上的折损，那谁会这么做呢？\n\n并非只有在开发环境或测试环境下为了模拟集群才会这么做，其实生产环境下这么做也是有目的的。\n\n我们先聊聊操作系统和JDK，一般服务器现在都会装64bit的版本，这样可以使内存突破4G的上限。而这个时候可能你就会理所应当的安装64bit版的jdk。那么，问题就来了：**目前来说，64位的jdk版本整体性能不如32位版**！这个现状会随着时间飞逝而逐渐消失。\n\n那么除了jdk本身的性能因素，还有其它问题么？\n\n我们简单的说一下关于`JVM`内存管理的内容。在我们启动tomcat时是可以设置几个和内存相关的参数的，包括：堆大小（新生代），永久代，虚拟机栈，垃圾回收器等。这些参数都是jvm性能调优的关键，我们暂不深究，只是知道它们很重要即可！\n\n刚才提到了，64位的系统和jdk版本可以使内存突破上限，这样我们的jvm相关设置就可以调的更大，理应拿到更好的性能，对吧？但其实不然，来看一下主要的问题点：\n\n- 太大的堆栈会直接导致垃圾回收时间增加，出现明显的卡顿；\n- 相同的程序下，64位比32位更吃内存（指针膨胀等）；\n- 由于内存分配过大，导致调试工具（jmap等）无法使用（dump一次会产生非常大的文件，而且分析这个文件也变得不再可行），这就要求程序必须有足够高的稳定性，确保不会出现内存泄露\n\n综上所述，目前我们可以选择64位的操作系统+32位的jdk作为搭配，但是这样的话服务器上大量的内存资源就浪费了，浪费是可耻的！\n\n所以才需要我们在一台物理机上运行多个tomcat实例，这样可以达到最佳效果。而且由于我们的目的是为了换取更大的内存使用率，所以多个tomcat进程上的多个项目镜像不需要做特殊处理（会话粘性），直接可以用`nginx`做个`ip_hash`负载均衡即可。\n\n好啦，扯了那么多，到底如何在同一台物理机上运行多个tomcat实例呢？[点我](http://www.importnew.com/12553.html)\n\n\n\n\n最后\n---\n\n目前大概也就这些，够开发用了，我会继续努力的！\n\nPS：做新人的感觉真TM爽，每天都那么充实~~\n\nPS2：推荐一款加速网页显示的[大神器](https://github.com/jiacai2050/gooreplacer4chrome#install)，你们懂的。","source":"_posts/javaEE部署项目新手向.md","raw":"title: javaEE部署项目新手向\ndate: 2014-10-23 09:37:12\ntags: \n- classpath\n- nginx\n- springMVC\n- Idea13\n- 负载均衡\n- tomcat\n- jvm\ncategories: j2ee\n---\n\n\n\n今天主要说的是关于java的web项目部署时候的琐碎。公司之前的几个javaEE项目我都没有参与编码，更别提部署了！不过接下来的项目我就要参与到所有环节中拉，所以趁着有时间，搞一下预备工作，都是很基础的东西，只是作为总结记录下来而已~~\n<!-- more -->\n以问题的方式来排版吧，这样便于阅读：\n\n\n\n\n项目中配置文件里使用的`classpath`到底指向哪里？\n---\n\n可以通过下面这行代码打印出来`classpath`的绝对路径：\n\n\tSystem.out.println(\"当前classpath的绝对路径：\" + Thread.currentThread().getContextClassLoader().getResource(\"\"));\n\n我用Idea13部署项目后可以看到终端中打印出：\n\n\t当前classpath的绝对路径：file:/D:/Program%20Files/apache-tomcat-7.0.53/webapps/springMVCDemo/WEB-INF/classes/\n\n可以看到`classpath`指向的是部署后的`/WEB-INF/classes/`，而这个`classes`文件夹就是存放编译后的`.class`文件的地方。\n\n而这个文件夹在部署之前是不存在的，那么IDE中配置文件里使用的`classpath:`又指向哪里呢？因为像Idea这样的吊炸天IDE都提供即时功能的，比方说我在`web.xml`中添加下面这个配置：\n\n\t...\n    <param-name>contextConfigLocation</param-name>\n    <param-value>classpath:mvc-dispatcher-servlet.xml</param-value>\n\t...\n\nIDE是会帮我检查对应文件夹下是否存在指定文件的，那我们之前说过编译前`classes`文件夹是不存在的，那么IDE又是帮我去哪找的呢？看下图：\n\n<a href=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/8VcSP.png\"><img src=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/medish.jpg\" width=\"640\" height=\"426\" border=\"0\" /></a>\n\n图中左上角中的箭头指向的那个位置就是IDE查找的位置，也就是说`java`文件夹对应着编译后的`classes`文件夹。\n\n上图中的项目是基于springMVC模板的，那文件夹这种对应关系又是在哪里设置的呢？其实不同的IDE都有自己的一套项目文件组织结构，之前公司用的是Netbeans，也有人使用Eclipse的，默认情况下它们的项目结构都不太一样，但是不管你用什么IDE，向Tomcat中部署的时候，都要输出一致的，Tomcat理解的标准目录，在Idea的`Artifacts`窗口下可以定义编译部署的项目结构，上图中下方的箭头和红框标出来的就是我们为了测试而修改`mvc-dispatcher-servlet.xml`位置后需要对应做的修改，这样才能保证IDE部署项目时导出正确的部署结构。\n\t\n\n\n\n\n如何在`Controller`中读取属性文件中的设置？\n---\n\n这个问题网上有不少贴，可以看这里：[传送门](http://kanpiaoxue.iteye.com/blog/1989026)，已经是非常具体了。可以看出，`Controller`中靠注解直接把配置文件中的键值注入到类属性中，很是NB啊！\n\n实际测试中还是需要按照第一个问题里说的那样调整一下`Artifacts`的部署结构，这里我发现在Idea13中，我把属性文件直接放在WEB-INF目录下，IDE中竟然显示找不到文件，但是部署后是正常的，就是显示红色的提示让我看着很不爽，所以才扔到`classes`下的~\n\n\n\n\nnginx代理项目中的静态资源文件\n---\n\n公司前几个小项目都出现了不同程度的性能问题，其中比较早遇见的就是关于静态文件太多导致的响应卡顿的问题！\n\n其实并不能一定断定就是Tomcat处理静态文件不利导致的，只不过看网上大家都吐槽它，还是果断放弃为好~~我们只需要搭建一个反向代理服务即可，这里第一选择肯定就是`Nginx`。\n\n我在自己的开发机上直接尝试搭建这个测试环境，大概环境如下：\n\n\twin7 64bit\n\tjdk1.7\n\ttomcat7\n\tnginx1.7.6\n\n测试项目部署完毕后的目录结构为：\n\n\tspringMVCDemo\n\t\t\t|\n\t\t\t|--images\t//这里就是我们的静态文件夹\n\t\t\t|\n\t\t\t|-WEB-INF\t\t\n\n\t\n好啦，现在直接修改Nginx的配置文件`/conf/nginx.conf`:\n\n\t server {\n        listen       80;\n        server_name  localhost;\n        root \"D:/Program Files/apache-tomcat-7.0.53/webapps/springMVCDemo\";\n\n        location / {\n            proxy_pass http://localhost:8080/springMVCDemo/;\n        }\n\n        location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ {\n\t\t\texpires 30d;\n\t\t}\n\n\t\tlocation ~ .*\\.(js|css)?$ {\n\t\t\texpires 1h;\n\t\t}\n\n很简单吧，这样就搞定了。这里面有个小插曲我需要说一下：我是直接用IDE编译打包成一个`war`文件，然后拷贝到`tomcat`的`webapps`下，由于我的天真，我一直试图尝试在`Nginx`的配置中直接指向`war`文件内部的`images`目录~~哇哈哈哈，网上找了一大圈都没有发现，结果最后才发现一个问题：`tomcat`在启动之初，如果发现需要加载`war`项目，会直接把`war`文件解压出来。阿西吧~\n\n最后，还要叮嘱一件事儿，那就是关于`nginx`的反向代理配置不当造成的安全隐患，具体细节可以看这里： [WooYun](http://drops.wooyun.org/papers/60)。\n\n\n\n\n\n\nspringMVC中静态文件的处理\n---\n\n虽然在上一个问题里我们已经把静态文件交给`Nginx`来处理了，但是我觉得那是生产环境下的配置~~在开发环境下还是要尽可能的直观一些，这样可以让配置较低的开发机更快一些，而且也可以让调试变得简单高效。\n\n其实实现的方法网上说了[好多](http://www.cnblogs.com/fangqi/archive/2012/10/28/2743108.html)，但我还是偏向于使用Spring提供的方式：\n\n\t<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        http://www.springframework.org/schema/context/spring-context.xsd\n        http://www.springframework.org/schema/mvc\n        http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd\">\n\n\t    <context:component-scan base-package=\"me.kazaff.springmvc\"/>\n\t\n\t    <mvc:annotation-driven />\n\t    <mvc:resources mapping=\"/images/**\"  location=\"/images/\" />\n\t\t\n\t\t....\n\n\t</beans>\n\n这样就可以啦，注意在头部要加上`mvc`这个命名空间的定义，一共要修改两个位置哟：\n\n- 在`beans`节点上增加：\n\t\n\txmlns:mvc=\"http://www.springframework.org/schema/mvc\n\n- 在`xsi:schemaLocation`属性上增加：\n\n\thttp://www.springframework.org/schema/mvc\n\thttp://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd\n \n其实在测试中还遇到了一个问题，就是一旦加上`mvc:resources`定义后就会造成无法访问页面，错误是：\n\t\n\t警告: No mapping found for HTTP request with URI [/springMVCDemo/] in DispatcherServlet with name 'mvc-dispatcher'\n\n所以一定要记得加上：\n\t\n\t<mvc:annotation-driven />\n\n理由可以查看这里： [传送门](http://blog.csdn.net/jbgtwang/article/details/7359592)。\n\n\n\n\n\n\n\njavaEE负载均衡环境搭建\n---\n\n接下来我们简单聊一下**高可用**和**可伸缩**的解决方案，我们可以在架构设计上做一些工作，从而使得我们的业务应用服务可以搬到集群中进行部署，至于要达到`可伸缩性`而需要解决的技术点我们暂且不表，毕竟这篇文章是新手向，我们主要聊一下集群环境下的负载均衡话题~~\n\n其实负载均衡不仅仅能做到平摊负载，牛逼一些的负载均衡软件还可以负责自动容灾处理。还拿`Nginx`来说，非常简单，看[这里](http://blog.jobbole.com/24574/)和[那里](http://saiyaren.iteye.com/blog/1914865)。能感觉到还是非常的简单明了吧？这也是`Nginx`能脱颖而出的原因：简单粗暴！\n\n但这个世界没有银弹，我们来看一下常用的负载均衡软件的优缺点：[传送门](http://www.csdn.net/article/2014-07-24/2820837)。\n\n看前辈总结了那么多，心里应该有谱了吧？！上面那一篇文章最大的价值在于描述了一个项目从小到大所处的不同阶段应该做什么样的选择，哥甚是喜欢！\n\n我还找到了一个碉堡的视频共大家观看：[传送门](http://edu.51cto.com/lesson/id-27846.html)。\n\n\n\n\n\n\n如何在一台物理机运行多个tomcat进程？\n---\n\n最后这个问题是非常有意义的，不过你可能会很好奇谁会这么做？首先，部署在同一台物理机上，就谈不上什么**高可用**，毕竟如果这台机器宕机了，所有tomcat实例都会挂掉。而且由于**进程间切换**也会导致性能上的折损，那谁会这么做呢？\n\n并非只有在开发环境或测试环境下为了模拟集群才会这么做，其实生产环境下这么做也是有目的的。\n\n我们先聊聊操作系统和JDK，一般服务器现在都会装64bit的版本，这样可以使内存突破4G的上限。而这个时候可能你就会理所应当的安装64bit版的jdk。那么，问题就来了：**目前来说，64位的jdk版本整体性能不如32位版**！这个现状会随着时间飞逝而逐渐消失。\n\n那么除了jdk本身的性能因素，还有其它问题么？\n\n我们简单的说一下关于`JVM`内存管理的内容。在我们启动tomcat时是可以设置几个和内存相关的参数的，包括：堆大小（新生代），永久代，虚拟机栈，垃圾回收器等。这些参数都是jvm性能调优的关键，我们暂不深究，只是知道它们很重要即可！\n\n刚才提到了，64位的系统和jdk版本可以使内存突破上限，这样我们的jvm相关设置就可以调的更大，理应拿到更好的性能，对吧？但其实不然，来看一下主要的问题点：\n\n- 太大的堆栈会直接导致垃圾回收时间增加，出现明显的卡顿；\n- 相同的程序下，64位比32位更吃内存（指针膨胀等）；\n- 由于内存分配过大，导致调试工具（jmap等）无法使用（dump一次会产生非常大的文件，而且分析这个文件也变得不再可行），这就要求程序必须有足够高的稳定性，确保不会出现内存泄露\n\n综上所述，目前我们可以选择64位的操作系统+32位的jdk作为搭配，但是这样的话服务器上大量的内存资源就浪费了，浪费是可耻的！\n\n所以才需要我们在一台物理机上运行多个tomcat实例，这样可以达到最佳效果。而且由于我们的目的是为了换取更大的内存使用率，所以多个tomcat进程上的多个项目镜像不需要做特殊处理（会话粘性），直接可以用`nginx`做个`ip_hash`负载均衡即可。\n\n好啦，扯了那么多，到底如何在同一台物理机上运行多个tomcat实例呢？[点我](http://www.importnew.com/12553.html)\n\n\n\n\n最后\n---\n\n目前大概也就这些，够开发用了，我会继续努力的！\n\nPS：做新人的感觉真TM爽，每天都那么充实~~\n\nPS2：推荐一款加速网页显示的[大神器](https://github.com/jiacai2050/gooreplacer4chrome#install)，你们懂的。","slug":"javaEE部署项目新手向","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18ypc008bgtfyflrfl7ng","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天主要说的是关于java的web项目部署时候的琐碎。公司之前的几个javaEE项目我都没有参与编码，更别提部署了！不过接下来的项目我就要参与到所有环节中拉，所以趁着有时间，搞一下预备工作，都是很基础的东西，只是作为总结记录下来而已~~<br><a id=\"more\"></a><br>以问题的方式来排版吧，这样便于阅读：</p>\n<h2 id=\"项目中配置文件里使用的classpath到底指向哪里？\"><a href=\"#项目中配置文件里使用的classpath到底指向哪里？\" class=\"headerlink\" title=\"项目中配置文件里使用的classpath到底指向哪里？\"></a>项目中配置文件里使用的<code>classpath</code>到底指向哪里？</h2><p>可以通过下面这行代码打印出来<code>classpath</code>的绝对路径：</p>\n<pre><code>System.out.println(&quot;当前classpath的绝对路径：&quot; + Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;));\n</code></pre><p>我用Idea13部署项目后可以看到终端中打印出：</p>\n<pre><code>当前classpath的绝对路径：file:/D:/Program%20Files/apache-tomcat-7.0.53/webapps/springMVCDemo/WEB-INF/classes/\n</code></pre><p>可以看到<code>classpath</code>指向的是部署后的<code>/WEB-INF/classes/</code>，而这个<code>classes</code>文件夹就是存放编译后的<code>.class</code>文件的地方。</p>\n<p>而这个文件夹在部署之前是不存在的，那么IDE中配置文件里使用的<code>classpath:</code>又指向哪里呢？因为像Idea这样的吊炸天IDE都提供即时功能的，比方说我在<code>web.xml</code>中添加下面这个配置：</p>\n<pre><code>...\n&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;\n&lt;param-value&gt;classpath:mvc-dispatcher-servlet.xml&lt;/param-value&gt;\n...\n</code></pre><p>IDE是会帮我检查对应文件夹下是否存在指定文件的，那我们之前说过编译前<code>classes</code>文件夹是不存在的，那么IDE又是帮我去哪找的呢？看下图：</p>\n<p><a href=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/8VcSP.png\" target=\"_blank\" rel=\"external\"><img src=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/medish.jpg\" width=\"640\" height=\"426\" border=\"0\"></a></p>\n<p>图中左上角中的箭头指向的那个位置就是IDE查找的位置，也就是说<code>java</code>文件夹对应着编译后的<code>classes</code>文件夹。</p>\n<p>上图中的项目是基于springMVC模板的，那文件夹这种对应关系又是在哪里设置的呢？其实不同的IDE都有自己的一套项目文件组织结构，之前公司用的是Netbeans，也有人使用Eclipse的，默认情况下它们的项目结构都不太一样，但是不管你用什么IDE，向Tomcat中部署的时候，都要输出一致的，Tomcat理解的标准目录，在Idea的<code>Artifacts</code>窗口下可以定义编译部署的项目结构，上图中下方的箭头和红框标出来的就是我们为了测试而修改<code>mvc-dispatcher-servlet.xml</code>位置后需要对应做的修改，这样才能保证IDE部署项目时导出正确的部署结构。</p>\n<h2 id=\"如何在Controller中读取属性文件中的设置？\"><a href=\"#如何在Controller中读取属性文件中的设置？\" class=\"headerlink\" title=\"如何在Controller中读取属性文件中的设置？\"></a>如何在<code>Controller</code>中读取属性文件中的设置？</h2><p>这个问题网上有不少贴，可以看这里：<a href=\"http://kanpiaoxue.iteye.com/blog/1989026\" target=\"_blank\" rel=\"external\">传送门</a>，已经是非常具体了。可以看出，<code>Controller</code>中靠注解直接把配置文件中的键值注入到类属性中，很是NB啊！</p>\n<p>实际测试中还是需要按照第一个问题里说的那样调整一下<code>Artifacts</code>的部署结构，这里我发现在Idea13中，我把属性文件直接放在WEB-INF目录下，IDE中竟然显示找不到文件，但是部署后是正常的，就是显示红色的提示让我看着很不爽，所以才扔到<code>classes</code>下的~</p>\n<h2 id=\"nginx代理项目中的静态资源文件\"><a href=\"#nginx代理项目中的静态资源文件\" class=\"headerlink\" title=\"nginx代理项目中的静态资源文件\"></a>nginx代理项目中的静态资源文件</h2><p>公司前几个小项目都出现了不同程度的性能问题，其中比较早遇见的就是关于静态文件太多导致的响应卡顿的问题！</p>\n<p>其实并不能一定断定就是Tomcat处理静态文件不利导致的，只不过看网上大家都吐槽它，还是果断放弃为好~~我们只需要搭建一个反向代理服务即可，这里第一选择肯定就是<code>Nginx</code>。</p>\n<p>我在自己的开发机上直接尝试搭建这个测试环境，大概环境如下：</p>\n<pre><code>win7 64bit\njdk1.7\ntomcat7\nnginx1.7.6\n</code></pre><p>测试项目部署完毕后的目录结构为：</p>\n<pre><code>springMVCDemo\n        |\n        |--images    //这里就是我们的静态文件夹\n        |\n        |-WEB-INF        \n</code></pre><p>好啦，现在直接修改Nginx的配置文件<code>/conf/nginx.conf</code>:</p>\n<pre><code>server {\n   listen       80;\n   server_name  localhost;\n   root &quot;D:/Program Files/apache-tomcat-7.0.53/webapps/springMVCDemo&quot;;\n\n   location / {\n       proxy_pass http://localhost:8080/springMVCDemo/;\n   }\n\n   location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ {\n       expires 30d;\n   }\n\n   location ~ .*\\.(js|css)?$ {\n       expires 1h;\n   }\n</code></pre><p>很简单吧，这样就搞定了。这里面有个小插曲我需要说一下：我是直接用IDE编译打包成一个<code>war</code>文件，然后拷贝到<code>tomcat</code>的<code>webapps</code>下，由于我的天真，我一直试图尝试在<code>Nginx</code>的配置中直接指向<code>war</code>文件内部的<code>images</code>目录~~哇哈哈哈，网上找了一大圈都没有发现，结果最后才发现一个问题：<code>tomcat</code>在启动之初，如果发现需要加载<code>war</code>项目，会直接把<code>war</code>文件解压出来。阿西吧~</p>\n<p>最后，还要叮嘱一件事儿，那就是关于<code>nginx</code>的反向代理配置不当造成的安全隐患，具体细节可以看这里： <a href=\"http://drops.wooyun.org/papers/60\" target=\"_blank\" rel=\"external\">WooYun</a>。</p>\n<h2 id=\"springMVC中静态文件的处理\"><a href=\"#springMVC中静态文件的处理\" class=\"headerlink\" title=\"springMVC中静态文件的处理\"></a>springMVC中静态文件的处理</h2><p>虽然在上一个问题里我们已经把静态文件交给<code>Nginx</code>来处理了，但是我觉得那是生产环境下的配置~~在开发环境下还是要尽可能的直观一些，这样可以让配置较低的开发机更快一些，而且也可以让调试变得简单高效。</p>\n<p>其实实现的方法网上说了<a href=\"http://www.cnblogs.com/fangqi/archive/2012/10/28/2743108.html\" target=\"_blank\" rel=\"external\">好多</a>，但我还是偏向于使用Spring提供的方式：</p>\n<pre><code>&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;\n   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n   xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;\n   xmlns:context=&quot;http://www.springframework.org/schema/context&quot;\n   xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\n    http://www.springframework.org/schema/mvc\n    http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd&quot;&gt;\n\n    &lt;context:component-scan base-package=&quot;me.kazaff.springmvc&quot;/&gt;\n\n    &lt;mvc:annotation-driven /&gt;\n    &lt;mvc:resources mapping=&quot;/images/**&quot;  location=&quot;/images/&quot; /&gt;\n\n    ....\n\n&lt;/beans&gt;\n</code></pre><p>这样就可以啦，注意在头部要加上<code>mvc</code>这个命名空间的定义，一共要修改两个位置哟：</p>\n<ul>\n<li><p>在<code>beans</code>节点上增加：</p>\n<p>  xmlns:mvc=”<a href=\"http://www.springframework.org/schema/mvc\" target=\"_blank\" rel=\"external\">http://www.springframework.org/schema/mvc</a></p>\n</li>\n<li><p>在<code>xsi:schemaLocation</code>属性上增加：</p>\n<p>  <a href=\"http://www.springframework.org/schema/mvc\" target=\"_blank\" rel=\"external\">http://www.springframework.org/schema/mvc</a><br>  <a href=\"http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd\" target=\"_blank\" rel=\"external\">http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd</a></p>\n</li>\n</ul>\n<p>其实在测试中还遇到了一个问题，就是一旦加上<code>mvc:resources</code>定义后就会造成无法访问页面，错误是：</p>\n<pre><code>警告: No mapping found for HTTP request with URI [/springMVCDemo/] in DispatcherServlet with name &apos;mvc-dispatcher&apos;\n</code></pre><p>所以一定要记得加上：</p>\n<pre><code>&lt;mvc:annotation-driven /&gt;\n</code></pre><p>理由可以查看这里： <a href=\"http://blog.csdn.net/jbgtwang/article/details/7359592\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<h2 id=\"javaEE负载均衡环境搭建\"><a href=\"#javaEE负载均衡环境搭建\" class=\"headerlink\" title=\"javaEE负载均衡环境搭建\"></a>javaEE负载均衡环境搭建</h2><p>接下来我们简单聊一下<strong>高可用</strong>和<strong>可伸缩</strong>的解决方案，我们可以在架构设计上做一些工作，从而使得我们的业务应用服务可以搬到集群中进行部署，至于要达到<code>可伸缩性</code>而需要解决的技术点我们暂且不表，毕竟这篇文章是新手向，我们主要聊一下集群环境下的负载均衡话题~~</p>\n<p>其实负载均衡不仅仅能做到平摊负载，牛逼一些的负载均衡软件还可以负责自动容灾处理。还拿<code>Nginx</code>来说，非常简单，看<a href=\"http://blog.jobbole.com/24574/\" target=\"_blank\" rel=\"external\">这里</a>和<a href=\"http://saiyaren.iteye.com/blog/1914865\" target=\"_blank\" rel=\"external\">那里</a>。能感觉到还是非常的简单明了吧？这也是<code>Nginx</code>能脱颖而出的原因：简单粗暴！</p>\n<p>但这个世界没有银弹，我们来看一下常用的负载均衡软件的优缺点：<a href=\"http://www.csdn.net/article/2014-07-24/2820837\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<p>看前辈总结了那么多，心里应该有谱了吧？！上面那一篇文章最大的价值在于描述了一个项目从小到大所处的不同阶段应该做什么样的选择，哥甚是喜欢！</p>\n<p>我还找到了一个碉堡的视频共大家观看：<a href=\"http://edu.51cto.com/lesson/id-27846.html\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<h2 id=\"如何在一台物理机运行多个tomcat进程？\"><a href=\"#如何在一台物理机运行多个tomcat进程？\" class=\"headerlink\" title=\"如何在一台物理机运行多个tomcat进程？\"></a>如何在一台物理机运行多个tomcat进程？</h2><p>最后这个问题是非常有意义的，不过你可能会很好奇谁会这么做？首先，部署在同一台物理机上，就谈不上什么<strong>高可用</strong>，毕竟如果这台机器宕机了，所有tomcat实例都会挂掉。而且由于<strong>进程间切换</strong>也会导致性能上的折损，那谁会这么做呢？</p>\n<p>并非只有在开发环境或测试环境下为了模拟集群才会这么做，其实生产环境下这么做也是有目的的。</p>\n<p>我们先聊聊操作系统和JDK，一般服务器现在都会装64bit的版本，这样可以使内存突破4G的上限。而这个时候可能你就会理所应当的安装64bit版的jdk。那么，问题就来了：<strong>目前来说，64位的jdk版本整体性能不如32位版</strong>！这个现状会随着时间飞逝而逐渐消失。</p>\n<p>那么除了jdk本身的性能因素，还有其它问题么？</p>\n<p>我们简单的说一下关于<code>JVM</code>内存管理的内容。在我们启动tomcat时是可以设置几个和内存相关的参数的，包括：堆大小（新生代），永久代，虚拟机栈，垃圾回收器等。这些参数都是jvm性能调优的关键，我们暂不深究，只是知道它们很重要即可！</p>\n<p>刚才提到了，64位的系统和jdk版本可以使内存突破上限，这样我们的jvm相关设置就可以调的更大，理应拿到更好的性能，对吧？但其实不然，来看一下主要的问题点：</p>\n<ul>\n<li>太大的堆栈会直接导致垃圾回收时间增加，出现明显的卡顿；</li>\n<li>相同的程序下，64位比32位更吃内存（指针膨胀等）；</li>\n<li>由于内存分配过大，导致调试工具（jmap等）无法使用（dump一次会产生非常大的文件，而且分析这个文件也变得不再可行），这就要求程序必须有足够高的稳定性，确保不会出现内存泄露</li>\n</ul>\n<p>综上所述，目前我们可以选择64位的操作系统+32位的jdk作为搭配，但是这样的话服务器上大量的内存资源就浪费了，浪费是可耻的！</p>\n<p>所以才需要我们在一台物理机上运行多个tomcat实例，这样可以达到最佳效果。而且由于我们的目的是为了换取更大的内存使用率，所以多个tomcat进程上的多个项目镜像不需要做特殊处理（会话粘性），直接可以用<code>nginx</code>做个<code>ip_hash</code>负载均衡即可。</p>\n<p>好啦，扯了那么多，到底如何在同一台物理机上运行多个tomcat实例呢？<a href=\"http://www.importnew.com/12553.html\" target=\"_blank\" rel=\"external\">点我</a></p>\n<h2 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h2><p>目前大概也就这些，够开发用了，我会继续努力的！</p>\n<p>PS：做新人的感觉真TM爽，每天都那么充实~~</p>\n<p>PS2：推荐一款加速网页显示的<a href=\"https://github.com/jiacai2050/gooreplacer4chrome#install\" target=\"_blank\" rel=\"external\">大神器</a>，你们懂的。</p>\n","excerpt":"<p>今天主要说的是关于java的web项目部署时候的琐碎。公司之前的几个javaEE项目我都没有参与编码，更别提部署了！不过接下来的项目我就要参与到所有环节中拉，所以趁着有时间，搞一下预备工作，都是很基础的东西，只是作为总结记录下来而已~~<br>","more":"<br>以问题的方式来排版吧，这样便于阅读：</p>\n<h2 id=\"项目中配置文件里使用的classpath到底指向哪里？\"><a href=\"#项目中配置文件里使用的classpath到底指向哪里？\" class=\"headerlink\" title=\"项目中配置文件里使用的classpath到底指向哪里？\"></a>项目中配置文件里使用的<code>classpath</code>到底指向哪里？</h2><p>可以通过下面这行代码打印出来<code>classpath</code>的绝对路径：</p>\n<pre><code>System.out.println(&quot;当前classpath的绝对路径：&quot; + Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;));\n</code></pre><p>我用Idea13部署项目后可以看到终端中打印出：</p>\n<pre><code>当前classpath的绝对路径：file:/D:/Program%20Files/apache-tomcat-7.0.53/webapps/springMVCDemo/WEB-INF/classes/\n</code></pre><p>可以看到<code>classpath</code>指向的是部署后的<code>/WEB-INF/classes/</code>，而这个<code>classes</code>文件夹就是存放编译后的<code>.class</code>文件的地方。</p>\n<p>而这个文件夹在部署之前是不存在的，那么IDE中配置文件里使用的<code>classpath:</code>又指向哪里呢？因为像Idea这样的吊炸天IDE都提供即时功能的，比方说我在<code>web.xml</code>中添加下面这个配置：</p>\n<pre><code>...\n&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;\n&lt;param-value&gt;classpath:mvc-dispatcher-servlet.xml&lt;/param-value&gt;\n...\n</code></pre><p>IDE是会帮我检查对应文件夹下是否存在指定文件的，那我们之前说过编译前<code>classes</code>文件夹是不存在的，那么IDE又是帮我去哪找的呢？看下图：</p>\n<p><a href=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/8VcSP.png\"><img src=\"http://pic.yupoo.com/kazaff/E9bw5Lp6/medish.jpg\" width=\"640\" height=\"426\" border=\"0\" /></a></p>\n<p>图中左上角中的箭头指向的那个位置就是IDE查找的位置，也就是说<code>java</code>文件夹对应着编译后的<code>classes</code>文件夹。</p>\n<p>上图中的项目是基于springMVC模板的，那文件夹这种对应关系又是在哪里设置的呢？其实不同的IDE都有自己的一套项目文件组织结构，之前公司用的是Netbeans，也有人使用Eclipse的，默认情况下它们的项目结构都不太一样，但是不管你用什么IDE，向Tomcat中部署的时候，都要输出一致的，Tomcat理解的标准目录，在Idea的<code>Artifacts</code>窗口下可以定义编译部署的项目结构，上图中下方的箭头和红框标出来的就是我们为了测试而修改<code>mvc-dispatcher-servlet.xml</code>位置后需要对应做的修改，这样才能保证IDE部署项目时导出正确的部署结构。</p>\n<h2 id=\"如何在Controller中读取属性文件中的设置？\"><a href=\"#如何在Controller中读取属性文件中的设置？\" class=\"headerlink\" title=\"如何在Controller中读取属性文件中的设置？\"></a>如何在<code>Controller</code>中读取属性文件中的设置？</h2><p>这个问题网上有不少贴，可以看这里：<a href=\"http://kanpiaoxue.iteye.com/blog/1989026\">传送门</a>，已经是非常具体了。可以看出，<code>Controller</code>中靠注解直接把配置文件中的键值注入到类属性中，很是NB啊！</p>\n<p>实际测试中还是需要按照第一个问题里说的那样调整一下<code>Artifacts</code>的部署结构，这里我发现在Idea13中，我把属性文件直接放在WEB-INF目录下，IDE中竟然显示找不到文件，但是部署后是正常的，就是显示红色的提示让我看着很不爽，所以才扔到<code>classes</code>下的~</p>\n<h2 id=\"nginx代理项目中的静态资源文件\"><a href=\"#nginx代理项目中的静态资源文件\" class=\"headerlink\" title=\"nginx代理项目中的静态资源文件\"></a>nginx代理项目中的静态资源文件</h2><p>公司前几个小项目都出现了不同程度的性能问题，其中比较早遇见的就是关于静态文件太多导致的响应卡顿的问题！</p>\n<p>其实并不能一定断定就是Tomcat处理静态文件不利导致的，只不过看网上大家都吐槽它，还是果断放弃为好~~我们只需要搭建一个反向代理服务即可，这里第一选择肯定就是<code>Nginx</code>。</p>\n<p>我在自己的开发机上直接尝试搭建这个测试环境，大概环境如下：</p>\n<pre><code>win7 64bit\njdk1.7\ntomcat7\nnginx1.7.6\n</code></pre><p>测试项目部署完毕后的目录结构为：</p>\n<pre><code>springMVCDemo\n        |\n        |--images    //这里就是我们的静态文件夹\n        |\n        |-WEB-INF        \n</code></pre><p>好啦，现在直接修改Nginx的配置文件<code>/conf/nginx.conf</code>:</p>\n<pre><code>server {\n   listen       80;\n   server_name  localhost;\n   root &quot;D:/Program Files/apache-tomcat-7.0.53/webapps/springMVCDemo&quot;;\n\n   location / {\n       proxy_pass http://localhost:8080/springMVCDemo/;\n   }\n\n   location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ {\n       expires 30d;\n   }\n\n   location ~ .*\\.(js|css)?$ {\n       expires 1h;\n   }\n</code></pre><p>很简单吧，这样就搞定了。这里面有个小插曲我需要说一下：我是直接用IDE编译打包成一个<code>war</code>文件，然后拷贝到<code>tomcat</code>的<code>webapps</code>下，由于我的天真，我一直试图尝试在<code>Nginx</code>的配置中直接指向<code>war</code>文件内部的<code>images</code>目录~~哇哈哈哈，网上找了一大圈都没有发现，结果最后才发现一个问题：<code>tomcat</code>在启动之初，如果发现需要加载<code>war</code>项目，会直接把<code>war</code>文件解压出来。阿西吧~</p>\n<p>最后，还要叮嘱一件事儿，那就是关于<code>nginx</code>的反向代理配置不当造成的安全隐患，具体细节可以看这里： <a href=\"http://drops.wooyun.org/papers/60\">WooYun</a>。</p>\n<h2 id=\"springMVC中静态文件的处理\"><a href=\"#springMVC中静态文件的处理\" class=\"headerlink\" title=\"springMVC中静态文件的处理\"></a>springMVC中静态文件的处理</h2><p>虽然在上一个问题里我们已经把静态文件交给<code>Nginx</code>来处理了，但是我觉得那是生产环境下的配置~~在开发环境下还是要尽可能的直观一些，这样可以让配置较低的开发机更快一些，而且也可以让调试变得简单高效。</p>\n<p>其实实现的方法网上说了<a href=\"http://www.cnblogs.com/fangqi/archive/2012/10/28/2743108.html\">好多</a>，但我还是偏向于使用Spring提供的方式：</p>\n<pre><code>&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;\n   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n   xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;\n   xmlns:context=&quot;http://www.springframework.org/schema/context&quot;\n   xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\n    http://www.springframework.org/schema/mvc\n    http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd&quot;&gt;\n\n    &lt;context:component-scan base-package=&quot;me.kazaff.springmvc&quot;/&gt;\n\n    &lt;mvc:annotation-driven /&gt;\n    &lt;mvc:resources mapping=&quot;/images/**&quot;  location=&quot;/images/&quot; /&gt;\n\n    ....\n\n&lt;/beans&gt;\n</code></pre><p>这样就可以啦，注意在头部要加上<code>mvc</code>这个命名空间的定义，一共要修改两个位置哟：</p>\n<ul>\n<li><p>在<code>beans</code>节点上增加：</p>\n<p>  xmlns:mvc=”<a href=\"http://www.springframework.org/schema/mvc\">http://www.springframework.org/schema/mvc</a></p>\n</li>\n<li><p>在<code>xsi:schemaLocation</code>属性上增加：</p>\n<p>  <a href=\"http://www.springframework.org/schema/mvc\">http://www.springframework.org/schema/mvc</a><br>  <a href=\"http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd\">http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd</a></p>\n</li>\n</ul>\n<p>其实在测试中还遇到了一个问题，就是一旦加上<code>mvc:resources</code>定义后就会造成无法访问页面，错误是：</p>\n<pre><code>警告: No mapping found for HTTP request with URI [/springMVCDemo/] in DispatcherServlet with name &apos;mvc-dispatcher&apos;\n</code></pre><p>所以一定要记得加上：</p>\n<pre><code>&lt;mvc:annotation-driven /&gt;\n</code></pre><p>理由可以查看这里： <a href=\"http://blog.csdn.net/jbgtwang/article/details/7359592\">传送门</a>。</p>\n<h2 id=\"javaEE负载均衡环境搭建\"><a href=\"#javaEE负载均衡环境搭建\" class=\"headerlink\" title=\"javaEE负载均衡环境搭建\"></a>javaEE负载均衡环境搭建</h2><p>接下来我们简单聊一下<strong>高可用</strong>和<strong>可伸缩</strong>的解决方案，我们可以在架构设计上做一些工作，从而使得我们的业务应用服务可以搬到集群中进行部署，至于要达到<code>可伸缩性</code>而需要解决的技术点我们暂且不表，毕竟这篇文章是新手向，我们主要聊一下集群环境下的负载均衡话题~~</p>\n<p>其实负载均衡不仅仅能做到平摊负载，牛逼一些的负载均衡软件还可以负责自动容灾处理。还拿<code>Nginx</code>来说，非常简单，看<a href=\"http://blog.jobbole.com/24574/\">这里</a>和<a href=\"http://saiyaren.iteye.com/blog/1914865\">那里</a>。能感觉到还是非常的简单明了吧？这也是<code>Nginx</code>能脱颖而出的原因：简单粗暴！</p>\n<p>但这个世界没有银弹，我们来看一下常用的负载均衡软件的优缺点：<a href=\"http://www.csdn.net/article/2014-07-24/2820837\">传送门</a>。</p>\n<p>看前辈总结了那么多，心里应该有谱了吧？！上面那一篇文章最大的价值在于描述了一个项目从小到大所处的不同阶段应该做什么样的选择，哥甚是喜欢！</p>\n<p>我还找到了一个碉堡的视频共大家观看：<a href=\"http://edu.51cto.com/lesson/id-27846.html\">传送门</a>。</p>\n<h2 id=\"如何在一台物理机运行多个tomcat进程？\"><a href=\"#如何在一台物理机运行多个tomcat进程？\" class=\"headerlink\" title=\"如何在一台物理机运行多个tomcat进程？\"></a>如何在一台物理机运行多个tomcat进程？</h2><p>最后这个问题是非常有意义的，不过你可能会很好奇谁会这么做？首先，部署在同一台物理机上，就谈不上什么<strong>高可用</strong>，毕竟如果这台机器宕机了，所有tomcat实例都会挂掉。而且由于<strong>进程间切换</strong>也会导致性能上的折损，那谁会这么做呢？</p>\n<p>并非只有在开发环境或测试环境下为了模拟集群才会这么做，其实生产环境下这么做也是有目的的。</p>\n<p>我们先聊聊操作系统和JDK，一般服务器现在都会装64bit的版本，这样可以使内存突破4G的上限。而这个时候可能你就会理所应当的安装64bit版的jdk。那么，问题就来了：<strong>目前来说，64位的jdk版本整体性能不如32位版</strong>！这个现状会随着时间飞逝而逐渐消失。</p>\n<p>那么除了jdk本身的性能因素，还有其它问题么？</p>\n<p>我们简单的说一下关于<code>JVM</code>内存管理的内容。在我们启动tomcat时是可以设置几个和内存相关的参数的，包括：堆大小（新生代），永久代，虚拟机栈，垃圾回收器等。这些参数都是jvm性能调优的关键，我们暂不深究，只是知道它们很重要即可！</p>\n<p>刚才提到了，64位的系统和jdk版本可以使内存突破上限，这样我们的jvm相关设置就可以调的更大，理应拿到更好的性能，对吧？但其实不然，来看一下主要的问题点：</p>\n<ul>\n<li>太大的堆栈会直接导致垃圾回收时间增加，出现明显的卡顿；</li>\n<li>相同的程序下，64位比32位更吃内存（指针膨胀等）；</li>\n<li>由于内存分配过大，导致调试工具（jmap等）无法使用（dump一次会产生非常大的文件，而且分析这个文件也变得不再可行），这就要求程序必须有足够高的稳定性，确保不会出现内存泄露</li>\n</ul>\n<p>综上所述，目前我们可以选择64位的操作系统+32位的jdk作为搭配，但是这样的话服务器上大量的内存资源就浪费了，浪费是可耻的！</p>\n<p>所以才需要我们在一台物理机上运行多个tomcat实例，这样可以达到最佳效果。而且由于我们的目的是为了换取更大的内存使用率，所以多个tomcat进程上的多个项目镜像不需要做特殊处理（会话粘性），直接可以用<code>nginx</code>做个<code>ip_hash</code>负载均衡即可。</p>\n<p>好啦，扯了那么多，到底如何在同一台物理机上运行多个tomcat实例呢？<a href=\"http://www.importnew.com/12553.html\">点我</a></p>\n<h2 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h2><p>目前大概也就这些，够开发用了，我会继续努力的！</p>\n<p>PS：做新人的感觉真TM爽，每天都那么充实~~</p>\n<p>PS2：推荐一款加速网页显示的<a href=\"https://github.com/jiacai2050/gooreplacer4chrome#install\">大神器</a>，你们懂的。</p>"},{"title":"java web中的session新手向","date":"2014-10-24T01:37:12.000Z","_content":"\n前几天又一遍熟悉了一下常用的负载均衡软件，比方说Nginx，还挺顺利的。既然有了负载均衡，那就要求应用能具备良好的伸缩性，而要达到这一点，就要解决多个应用镜像之间的数据共享问题，说白了就是会话状态的共享！\n<!--more-->\n其实**无会话状态**才是服务追求的目标，搞过RESTful的童鞋应该知道这一点！之前玩PHP的时候，要做到Session共享其实不难，只需要把[session存储到mysql中](http://blog.csdn.net/eflyq/article/details/12081281)，这事儿就搞定一多半了，剩下的就是设置session的作用域等参数，能够保证客户端请求时携带任意一台服务器为它创建的session_id即可！~那，在javaEE下又该怎么做呢？\n\n先从基础知识讲起吧，看一下这些文章：[传送门1](http://blog.csdn.net/ghsau/article/details/13023425)，[传送门2](http://www.cnblogs.com/EvanLiu/p/3356925.html)。其实和PHP里定义的Session差不多，这也很正常，本来这个概念就不是由语言提出来的，而是由HTTP引出的，所以语言相关性不大。而且类比apache+php，其实在java web中，session也是交给tomcat这种容器来管理的，而servlet只是提供了相关的接口定义而已，想了解这其中的内部细节的童鞋可以看一下这篇[文章](http://gearever.iteye.com/blog/1546423)。\n\n好了，到这里为止基本上已经算是熟悉java下的session了！接下来我们就可以直奔主题了，其实实作方式应该也和php的差不多，只不过需要写成tomcat的“插件”，具体细节其实已经有相关的扩展了，我这里直接找到一篇非常实战的文章供大家操作：[传送门](http://zhangqiaoqifgdqsn.iteye.com/blog/1975797)。\n\n这篇文章就到这里吧，虽然感觉上并没有写什么，哇哈哈哈，毕竟作为新手能遇到的问题都应该被前辈大妞们解决了，我们只需要拼命的学习就行啦！\n\n\n\n","source":"_posts/java web中的session新手向.md","raw":"title: java web中的session新手向\ndate: 2014-10-24 09:37:12\ntags: \n- session\n- 负载均衡\n- 会话亲和性\ncategories: j2ee\n---\n\n前几天又一遍熟悉了一下常用的负载均衡软件，比方说Nginx，还挺顺利的。既然有了负载均衡，那就要求应用能具备良好的伸缩性，而要达到这一点，就要解决多个应用镜像之间的数据共享问题，说白了就是会话状态的共享！\n<!--more-->\n其实**无会话状态**才是服务追求的目标，搞过RESTful的童鞋应该知道这一点！之前玩PHP的时候，要做到Session共享其实不难，只需要把[session存储到mysql中](http://blog.csdn.net/eflyq/article/details/12081281)，这事儿就搞定一多半了，剩下的就是设置session的作用域等参数，能够保证客户端请求时携带任意一台服务器为它创建的session_id即可！~那，在javaEE下又该怎么做呢？\n\n先从基础知识讲起吧，看一下这些文章：[传送门1](http://blog.csdn.net/ghsau/article/details/13023425)，[传送门2](http://www.cnblogs.com/EvanLiu/p/3356925.html)。其实和PHP里定义的Session差不多，这也很正常，本来这个概念就不是由语言提出来的，而是由HTTP引出的，所以语言相关性不大。而且类比apache+php，其实在java web中，session也是交给tomcat这种容器来管理的，而servlet只是提供了相关的接口定义而已，想了解这其中的内部细节的童鞋可以看一下这篇[文章](http://gearever.iteye.com/blog/1546423)。\n\n好了，到这里为止基本上已经算是熟悉java下的session了！接下来我们就可以直奔主题了，其实实作方式应该也和php的差不多，只不过需要写成tomcat的“插件”，具体细节其实已经有相关的扩展了，我这里直接找到一篇非常实战的文章供大家操作：[传送门](http://zhangqiaoqifgdqsn.iteye.com/blog/1975797)。\n\n这篇文章就到这里吧，虽然感觉上并没有写什么，哇哈哈哈，毕竟作为新手能遇到的问题都应该被前辈大妞们解决了，我们只需要拼命的学习就行啦！\n\n\n\n","slug":"java web中的session新手向","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18ypi008ogtfyoak2sfws","comments":1,"layout":"post","photos":[],"link":"","content":"<p>前几天又一遍熟悉了一下常用的负载均衡软件，比方说Nginx，还挺顺利的。既然有了负载均衡，那就要求应用能具备良好的伸缩性，而要达到这一点，就要解决多个应用镜像之间的数据共享问题，说白了就是会话状态的共享！<br><a id=\"more\"></a><br>其实<strong>无会话状态</strong>才是服务追求的目标，搞过RESTful的童鞋应该知道这一点！之前玩PHP的时候，要做到Session共享其实不难，只需要把<a href=\"http://blog.csdn.net/eflyq/article/details/12081281\" target=\"_blank\" rel=\"external\">session存储到mysql中</a>，这事儿就搞定一多半了，剩下的就是设置session的作用域等参数，能够保证客户端请求时携带任意一台服务器为它创建的session_id即可！~那，在javaEE下又该怎么做呢？</p>\n<p>先从基础知识讲起吧，看一下这些文章：<a href=\"http://blog.csdn.net/ghsau/article/details/13023425\" target=\"_blank\" rel=\"external\">传送门1</a>，<a href=\"http://www.cnblogs.com/EvanLiu/p/3356925.html\" target=\"_blank\" rel=\"external\">传送门2</a>。其实和PHP里定义的Session差不多，这也很正常，本来这个概念就不是由语言提出来的，而是由HTTP引出的，所以语言相关性不大。而且类比apache+php，其实在java web中，session也是交给tomcat这种容器来管理的，而servlet只是提供了相关的接口定义而已，想了解这其中的内部细节的童鞋可以看一下这篇<a href=\"http://gearever.iteye.com/blog/1546423\" target=\"_blank\" rel=\"external\">文章</a>。</p>\n<p>好了，到这里为止基本上已经算是熟悉java下的session了！接下来我们就可以直奔主题了，其实实作方式应该也和php的差不多，只不过需要写成tomcat的“插件”，具体细节其实已经有相关的扩展了，我这里直接找到一篇非常实战的文章供大家操作：<a href=\"http://zhangqiaoqifgdqsn.iteye.com/blog/1975797\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<p>这篇文章就到这里吧，虽然感觉上并没有写什么，哇哈哈哈，毕竟作为新手能遇到的问题都应该被前辈大妞们解决了，我们只需要拼命的学习就行啦！</p>\n","excerpt":"<p>前几天又一遍熟悉了一下常用的负载均衡软件，比方说Nginx，还挺顺利的。既然有了负载均衡，那就要求应用能具备良好的伸缩性，而要达到这一点，就要解决多个应用镜像之间的数据共享问题，说白了就是会话状态的共享！<br>","more":"<br>其实<strong>无会话状态</strong>才是服务追求的目标，搞过RESTful的童鞋应该知道这一点！之前玩PHP的时候，要做到Session共享其实不难，只需要把<a href=\"http://blog.csdn.net/eflyq/article/details/12081281\">session存储到mysql中</a>，这事儿就搞定一多半了，剩下的就是设置session的作用域等参数，能够保证客户端请求时携带任意一台服务器为它创建的session_id即可！~那，在javaEE下又该怎么做呢？</p>\n<p>先从基础知识讲起吧，看一下这些文章：<a href=\"http://blog.csdn.net/ghsau/article/details/13023425\">传送门1</a>，<a href=\"http://www.cnblogs.com/EvanLiu/p/3356925.html\">传送门2</a>。其实和PHP里定义的Session差不多，这也很正常，本来这个概念就不是由语言提出来的，而是由HTTP引出的，所以语言相关性不大。而且类比apache+php，其实在java web中，session也是交给tomcat这种容器来管理的，而servlet只是提供了相关的接口定义而已，想了解这其中的内部细节的童鞋可以看一下这篇<a href=\"http://gearever.iteye.com/blog/1546423\">文章</a>。</p>\n<p>好了，到这里为止基本上已经算是熟悉java下的session了！接下来我们就可以直奔主题了，其实实作方式应该也和php的差不多，只不过需要写成tomcat的“插件”，具体细节其实已经有相关的扩展了，我这里直接找到一篇非常实战的文章供大家操作：<a href=\"http://zhangqiaoqifgdqsn.iteye.com/blog/1975797\">传送门</a>。</p>\n<p>这篇文章就到这里吧，虽然感觉上并没有写什么，哇哈哈哈，毕竟作为新手能遇到的问题都应该被前辈大妞们解决了，我们只需要拼命的学习就行啦！</p>"},{"title":"https情结","date":"2015-06-01T01:37:12.000Z","_content":"\n早在几年前，我就一直想在自己的博客用上https，不要问我为什么，虽然并没有什么卵用。\n<!--more-->\n\n随着http2.0的宣传，大量的关于web性能和安全的信息跃然纸上，这让我对https更加的向往~工作了这么多年，一直想给公司开发的系统配置上ssl，最近刚好看到一篇写的不错的文章，跟着大牛测了一下，还真配成了。\n\n首先大家知道，想搭建https，你是需要购买证书的，不然用户访问你的https的时候还需要手动安装证书，这会让一些不明真相的用户感到反感，而且由于你的私人证书没有什么信用可言，所以更多的人会选择放弃访问你的系统，而这是我们最不希望看到的。\n\n不过免费提供证书的机构还是存在的，StartSSL就是这样的公司，下面的两个参考链接分别介绍了如何搭建https服务和如何申请免费的证书，希望大家都能早日用上https~\n\n参考\n---\n\n[NGINX 配置 SSL 证书 + 搭建 HTTPS 网站教程](https://s.how/nginx-ssl/)\n\n[Apache + WordPress + SSL 完全指南](http://ttt.tt/9/)","source":"_posts/https情结.md","raw":"title: https情结\ndate: 2015-06-01 09:37:12\ntags: \n- https\n- ssl\n- 证书\ncategories: 运维\n---\n\n早在几年前，我就一直想在自己的博客用上https，不要问我为什么，虽然并没有什么卵用。\n<!--more-->\n\n随着http2.0的宣传，大量的关于web性能和安全的信息跃然纸上，这让我对https更加的向往~工作了这么多年，一直想给公司开发的系统配置上ssl，最近刚好看到一篇写的不错的文章，跟着大牛测了一下，还真配成了。\n\n首先大家知道，想搭建https，你是需要购买证书的，不然用户访问你的https的时候还需要手动安装证书，这会让一些不明真相的用户感到反感，而且由于你的私人证书没有什么信用可言，所以更多的人会选择放弃访问你的系统，而这是我们最不希望看到的。\n\n不过免费提供证书的机构还是存在的，StartSSL就是这样的公司，下面的两个参考链接分别介绍了如何搭建https服务和如何申请免费的证书，希望大家都能早日用上https~\n\n参考\n---\n\n[NGINX 配置 SSL 证书 + 搭建 HTTPS 网站教程](https://s.how/nginx-ssl/)\n\n[Apache + WordPress + SSL 完全指南](http://ttt.tt/9/)","slug":"https情结","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ypq008vgtfyullwdm9m","comments":1,"layout":"post","photos":[],"link":"","content":"<p>早在几年前，我就一直想在自己的博客用上https，不要问我为什么，虽然并没有什么卵用。<br><a id=\"more\"></a></p>\n<p>随着http2.0的宣传，大量的关于web性能和安全的信息跃然纸上，这让我对https更加的向往~工作了这么多年，一直想给公司开发的系统配置上ssl，最近刚好看到一篇写的不错的文章，跟着大牛测了一下，还真配成了。</p>\n<p>首先大家知道，想搭建https，你是需要购买证书的，不然用户访问你的https的时候还需要手动安装证书，这会让一些不明真相的用户感到反感，而且由于你的私人证书没有什么信用可言，所以更多的人会选择放弃访问你的系统，而这是我们最不希望看到的。</p>\n<p>不过免费提供证书的机构还是存在的，StartSSL就是这样的公司，下面的两个参考链接分别介绍了如何搭建https服务和如何申请免费的证书，希望大家都能早日用上https~</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://s.how/nginx-ssl/\" target=\"_blank\" rel=\"external\">NGINX 配置 SSL 证书 + 搭建 HTTPS 网站教程</a></p>\n<p><a href=\"http://ttt.tt/9/\" target=\"_blank\" rel=\"external\">Apache + WordPress + SSL 完全指南</a></p>\n","excerpt":"<p>早在几年前，我就一直想在自己的博客用上https，不要问我为什么，虽然并没有什么卵用。<br>","more":"</p>\n<p>随着http2.0的宣传，大量的关于web性能和安全的信息跃然纸上，这让我对https更加的向往~工作了这么多年，一直想给公司开发的系统配置上ssl，最近刚好看到一篇写的不错的文章，跟着大牛测了一下，还真配成了。</p>\n<p>首先大家知道，想搭建https，你是需要购买证书的，不然用户访问你的https的时候还需要手动安装证书，这会让一些不明真相的用户感到反感，而且由于你的私人证书没有什么信用可言，所以更多的人会选择放弃访问你的系统，而这是我们最不希望看到的。</p>\n<p>不过免费提供证书的机构还是存在的，StartSSL就是这样的公司，下面的两个参考链接分别介绍了如何搭建https服务和如何申请免费的证书，希望大家都能早日用上https~</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://s.how/nginx-ssl/\">NGINX 配置 SSL 证书 + 搭建 HTTPS 网站教程</a></p>\n<p><a href=\"http://ttt.tt/9/\">Apache + WordPress + SSL 完全指南</a></p>"},{"title":"Hello World","date":"2014-05-08T02:54:30.000Z","_content":"\n其实一直想把博客好好整理一下，不过总是拖延~\n\n今天偶然间看到另一个基于nodejs的静态博客系统 [*hexo*](http://blog.fens.me/hexo-blog-github/) ，感觉很喜欢~趁着热情就部署了一下~\n\n现在就是头疼老文章迁移问题，还有就是博客皮肤！一点一点来吧！","source":"_posts/hello-world.md","raw":"title: Hello World\ndate: 2014-05-08 10:54:30\ntags: hello\n---\n\n其实一直想把博客好好整理一下，不过总是拖延~\n\n今天偶然间看到另一个基于nodejs的静态博客系统 [*hexo*](http://blog.fens.me/hexo-blog-github/) ，感觉很喜欢~趁着热情就部署了一下~\n\n现在就是头疼老文章迁移问题，还有就是博客皮肤！一点一点来吧！","slug":"hello-world","published":1,"updated":"2016-05-14T07:46:18.000Z","_id":"cica18ypx0093gtfycvttnytb","comments":1,"layout":"post","photos":[],"link":"","content":"<p>其实一直想把博客好好整理一下，不过总是拖延~</p>\n<p>今天偶然间看到另一个基于nodejs的静态博客系统 <a href=\"http://blog.fens.me/hexo-blog-github/\" target=\"_blank\" rel=\"external\"><em>hexo</em></a> ，感觉很喜欢~趁着热情就部署了一下~</p>\n<p>现在就是头疼老文章迁移问题，还有就是博客皮肤！一点一点来吧！</p>\n","excerpt":"","more":"<p>其实一直想把博客好好整理一下，不过总是拖延~</p>\n<p>今天偶然间看到另一个基于nodejs的静态博客系统 <a href=\"http://blog.fens.me/hexo-blog-github/\"><em>hexo</em></a> ，感觉很喜欢~趁着热情就部署了一下~</p>\n<p>现在就是头疼老文章迁移问题，还有就是博客皮肤！一点一点来吧！</p>\n"},{"title":"dubbo的通信模型","date":"2015-04-01T07:54:30.000Z","_content":"\n\n上接[dubbo的编解码，序列化和通信](http://blog.kazaff.me/2015/02/01/dubbo%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%EF%BC%8C%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E9%80%9A%E4%BF%A1/)。\n\n<!--more-->\n\n在上面那一篇文章中，大致的介绍了一下dubbo的通信机制。不过感觉说的有点乱，总结了下面一张图：\n\n![](http://pic.yupoo.com/kazaff/EwVU804K/78m8v.png)\n\n图中的从“外到内”对应着“从dubbo底层到应用的业务逻辑层”，我把在这个过程中起到关键作用的类都标注了出来，**注意：**这里还是基于dubbo的默认协议dubbo，默认通信框架netty，以及默认的序列化方式dubbocodec。\n\n这里我想讨论的是，注意看图中的“AllChannelHandler”类的职责之一：\n\n> 把对应事件（connected、disconnected、received、caught）的执行业务分配给线程池中可使用线程\n\ndubbo处理handler所使用的线程并非来自netty提供的I/O Work线程，而是dubbo自身来维护的一个java原生线程池，源码见**com.alibaba.dubbo.remoting.transport.dispatcher.WrappedChannelHandler**。why？\n\n但从[netty线程模型](http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point)的分析中，可以认为netty提供的那些nio工作线程主要被用于消息链路的读取、解码、编码和发送。而dubbo把业务逻辑的执行放在自身维护的线程池中是否就是为了贯彻netty的这一原则呢？\n\n从上面给的链接中可以注意到下面这段话：\n\n> Netty是个异步高性能的NIO框架，它并不是个业务运行容器，因此它不需要也不应该提供业务容器和业务线程。合理的设计模式是Netty只负责提供和管理NIO线程，其它的业务层线程模型由用户自己集成，Netty不应该提供此类功能，只要将分层划分清楚，就会更有利于用户集成和扩展。\n\n正如文中所说，dubbo这么做有利于分离通信层，方便的替换掉netty。至于是否还有更高深的理由，我就不清楚了，希望大牛赐教。\n\n另外dubbo在进行数据的读取和解析上做了很多工作，体现出了开发人员的功底，由于我在这部分没有经验，勉强看得懂就已经不错了，谈不上分析，就不瞎掰了。\n\n","source":"_posts/dubbo的通信模型.md","raw":"title: dubbo的通信模型\ndate: 2015-04-01 15:54:30\ntags:\n- dubbox\n- dubbo\n- netty\n- nio\n\ncategories: j2ee\n---\n\n\n上接[dubbo的编解码，序列化和通信](http://blog.kazaff.me/2015/02/01/dubbo%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%EF%BC%8C%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E9%80%9A%E4%BF%A1/)。\n\n<!--more-->\n\n在上面那一篇文章中，大致的介绍了一下dubbo的通信机制。不过感觉说的有点乱，总结了下面一张图：\n\n![](http://pic.yupoo.com/kazaff/EwVU804K/78m8v.png)\n\n图中的从“外到内”对应着“从dubbo底层到应用的业务逻辑层”，我把在这个过程中起到关键作用的类都标注了出来，**注意：**这里还是基于dubbo的默认协议dubbo，默认通信框架netty，以及默认的序列化方式dubbocodec。\n\n这里我想讨论的是，注意看图中的“AllChannelHandler”类的职责之一：\n\n> 把对应事件（connected、disconnected、received、caught）的执行业务分配给线程池中可使用线程\n\ndubbo处理handler所使用的线程并非来自netty提供的I/O Work线程，而是dubbo自身来维护的一个java原生线程池，源码见**com.alibaba.dubbo.remoting.transport.dispatcher.WrappedChannelHandler**。why？\n\n但从[netty线程模型](http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point)的分析中，可以认为netty提供的那些nio工作线程主要被用于消息链路的读取、解码、编码和发送。而dubbo把业务逻辑的执行放在自身维护的线程池中是否就是为了贯彻netty的这一原则呢？\n\n从上面给的链接中可以注意到下面这段话：\n\n> Netty是个异步高性能的NIO框架，它并不是个业务运行容器，因此它不需要也不应该提供业务容器和业务线程。合理的设计模式是Netty只负责提供和管理NIO线程，其它的业务层线程模型由用户自己集成，Netty不应该提供此类功能，只要将分层划分清楚，就会更有利于用户集成和扩展。\n\n正如文中所说，dubbo这么做有利于分离通信层，方便的替换掉netty。至于是否还有更高深的理由，我就不清楚了，希望大牛赐教。\n\n另外dubbo在进行数据的读取和解析上做了很多工作，体现出了开发人员的功底，由于我在这部分没有经验，勉强看得懂就已经不错了，谈不上分析，就不瞎掰了。\n\n","slug":"dubbo的通信模型","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yq00096gtfy9rygcwt3","comments":1,"layout":"post","photos":[],"link":"","content":"<p>上接<a href=\"http://blog.kazaff.me/2015/02/01/dubbo%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%EF%BC%8C%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E9%80%9A%E4%BF%A1/\">dubbo的编解码，序列化和通信</a>。</p>\n<a id=\"more\"></a>\n<p>在上面那一篇文章中，大致的介绍了一下dubbo的通信机制。不过感觉说的有点乱，总结了下面一张图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EwVU804K/78m8v.png\" alt=\"\"></p>\n<p>图中的从“外到内”对应着“从dubbo底层到应用的业务逻辑层”，我把在这个过程中起到关键作用的类都标注了出来，<strong>注意：</strong>这里还是基于dubbo的默认协议dubbo，默认通信框架netty，以及默认的序列化方式dubbocodec。</p>\n<p>这里我想讨论的是，注意看图中的“AllChannelHandler”类的职责之一：</p>\n<blockquote>\n<p>把对应事件（connected、disconnected、received、caught）的执行业务分配给线程池中可使用线程</p>\n</blockquote>\n<p>dubbo处理handler所使用的线程并非来自netty提供的I/O Work线程，而是dubbo自身来维护的一个java原生线程池，源码见<strong>com.alibaba.dubbo.remoting.transport.dispatcher.WrappedChannelHandler</strong>。why？</p>\n<p>但从<a href=\"http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point\" target=\"_blank\" rel=\"external\">netty线程模型</a>的分析中，可以认为netty提供的那些nio工作线程主要被用于消息链路的读取、解码、编码和发送。而dubbo把业务逻辑的执行放在自身维护的线程池中是否就是为了贯彻netty的这一原则呢？</p>\n<p>从上面给的链接中可以注意到下面这段话：</p>\n<blockquote>\n<p>Netty是个异步高性能的NIO框架，它并不是个业务运行容器，因此它不需要也不应该提供业务容器和业务线程。合理的设计模式是Netty只负责提供和管理NIO线程，其它的业务层线程模型由用户自己集成，Netty不应该提供此类功能，只要将分层划分清楚，就会更有利于用户集成和扩展。</p>\n</blockquote>\n<p>正如文中所说，dubbo这么做有利于分离通信层，方便的替换掉netty。至于是否还有更高深的理由，我就不清楚了，希望大牛赐教。</p>\n<p>另外dubbo在进行数据的读取和解析上做了很多工作，体现出了开发人员的功底，由于我在这部分没有经验，勉强看得懂就已经不错了，谈不上分析，就不瞎掰了。</p>\n","excerpt":"<p>上接<a href=\"http://blog.kazaff.me/2015/02/01/dubbo%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%EF%BC%8C%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E9%80%9A%E4%BF%A1/\">dubbo的编解码，序列化和通信</a>。</p>","more":"<p>在上面那一篇文章中，大致的介绍了一下dubbo的通信机制。不过感觉说的有点乱，总结了下面一张图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EwVU804K/78m8v.png\" alt=\"\"></p>\n<p>图中的从“外到内”对应着“从dubbo底层到应用的业务逻辑层”，我把在这个过程中起到关键作用的类都标注了出来，<strong>注意：</strong>这里还是基于dubbo的默认协议dubbo，默认通信框架netty，以及默认的序列化方式dubbocodec。</p>\n<p>这里我想讨论的是，注意看图中的“AllChannelHandler”类的职责之一：</p>\n<blockquote>\n<p>把对应事件（connected、disconnected、received、caught）的执行业务分配给线程池中可使用线程</p>\n</blockquote>\n<p>dubbo处理handler所使用的线程并非来自netty提供的I/O Work线程，而是dubbo自身来维护的一个java原生线程池，源码见<strong>com.alibaba.dubbo.remoting.transport.dispatcher.WrappedChannelHandler</strong>。why？</p>\n<p>但从<a href=\"http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point\">netty线程模型</a>的分析中，可以认为netty提供的那些nio工作线程主要被用于消息链路的读取、解码、编码和发送。而dubbo把业务逻辑的执行放在自身维护的线程池中是否就是为了贯彻netty的这一原则呢？</p>\n<p>从上面给的链接中可以注意到下面这段话：</p>\n<blockquote>\n<p>Netty是个异步高性能的NIO框架，它并不是个业务运行容器，因此它不需要也不应该提供业务容器和业务线程。合理的设计模式是Netty只负责提供和管理NIO线程，其它的业务层线程模型由用户自己集成，Netty不应该提供此类功能，只要将分层划分清楚，就会更有利于用户集成和扩展。</p>\n</blockquote>\n<p>正如文中所说，dubbo这么做有利于分离通信层，方便的替换掉netty。至于是否还有更高深的理由，我就不清楚了，希望大牛赐教。</p>\n<p>另外dubbo在进行数据的读取和解析上做了很多工作，体现出了开发人员的功底，由于我在这部分没有经验，勉强看得懂就已经不错了，谈不上分析，就不瞎掰了。</p>"},{"title":"dubbo的编解码，序列化和通信","date":"2015-02-11T07:54:30.000Z","_content":"\n\ndubbo的调研已经快完结了（按照我自己拟定的计划），计划内剩下的内容就只有：\n\n- 序列化\n- 编解码\n- 通信实现\n<!--more-->\n打算写在一篇里，年前彻底搞定dubbo[x]的调研，过完年来了就要投入使用了，好紧张哇~~哟呵呵呵呵！其实前两块的内容并没有啥好讲的，毕竟咱目的是了解源码来辅佐如何使用，而非像当当网的团队那样做dubbo的升级开发。\n\n按照源码的阅读习惯，我们按照上面列表的逆序来一个一个的分析。废话不多说，走着~\n\n\n通信实现\n---\n\n我们主要基于dubbo推荐默认使用的通信框架：netty，来了解一下dubbo是如何完成两端通信的。我们直接从`DubboProtocol`类开始看起：\n\n\texport()  -->  openServer()  -->  createServer()\n\t   \t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t+-->  server = Exchangers.bind(url, requestHandler);  //创建服务\n\n\t\n\ndubbo从要暴漏的服务的URL中取得相关的配置（host，port等）进行服务端server的创建，并且保证相同的配置（host+port）下只会开启一个server，这和netty提供的模型有关（NIO），这个我们后面再说。\n\n我们先来继续看`Exchangers`的相关部分，\n\n\t......\n\t public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n        if (url == null) {\n            throw new IllegalArgumentException(\"url == null\");\n        }\n        if (handler == null) {\n            throw new IllegalArgumentException(\"handler == null\");\n        }\n        url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\");\t//这里尝试配置了编解码的方式\n        return getExchanger(url).bind(url, handler);\n    }\n\t......\n\tpublic static Exchanger getExchanger(URL url) {\n        String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER);\t//默认使用HeaderExchanger\n        return getExchanger(type);\n    }\n\t......\n\tpublic static Exchanger getExchanger(String type) {\n        return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type);\n    }\n\t......\n\n\n可以看出，`Exchangers`只是根据URL的参数提供了策略模式。我们依然以dubbo默认的处理方式为主，接下来代码执行到`HeaderExchanger`类：\n\n\tpublic class HeaderExchanger implements Exchanger {\n    \n\t    public static final String NAME = \"header\";\n\t\n\t    public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {\n\t        return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n\t    }\n\t\n\t    public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n\t        return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n\t    }\t\n\t}\n\n这些代码看起来非常的**设计模式**：\n\n\treturn new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n\t\t\t\t\t\t|\t\t\t\t\t\t  |\t\t\t\t\t |\t\t\t\t\t|\t\t\t\t  |\n\t\t\t\t\t\tV\t\t\t\t\t\t  |\t\t\t\t\t |\t\t\t\t\t|\t\t\t\t  V\n\t\t\t\t1.提供统一的服务操作接口\t\t\t  |\t\t\t\t\t |\t\t\t\t\t|\t\t\t\t利用装饰器模式，这个才是最靠近业务的逻辑（直接调用相关的invoker）\n\t\t\t\t2.创建心跳定时任务\t\t\t\t  V\t\t\t\t\t |\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t1.利于扩展点机制选择通信框架\t |\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t2.格式化回调函数\t\t\t\t |\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t V\t\t\t\t\tV\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    消息的解码???\t     处理dubbo的通信模型：单向，双向，异步等通信模型\n\n\n\n要想理解现在的内容，就得先搞清楚[JAVA NIO channel概念](http://ifeve.com/channels/)，搞清楚netty的[NIO线程模型](http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point)。\n\n了解了这两个基础知识点，那么我们就可以继续分析源码了，上面那一行代码中`Transporters.bind()`默认会调用`NettyTransporter`：\n\n\tpublic class NettyTransporter implements Transporter {\n\n\t    public static final String NAME = \"netty\";\n\t    \n\t    public Server bind(URL url, ChannelHandler listener) throws RemotingException {\n\t        return new NettyServer(url, listener);\n\t    }\n\t\n\t    public Client connect(URL url, ChannelHandler listener) throws RemotingException {\n\t        return new NettyClient(url, listener);\n\t    }\n\t}\n\n接下来我们就真正进入到了netty的世界，我们先来看一下`NettyServer`的家谱：\n\n![](http://pic.yupoo.com/kazaff/EqfbO3HE/NAsri.png)\n\n要时刻记着，dubbo是一个非常灵活的框架，我们不仅可以使用netty作为底层通信组件，也可以仅靠url参数就可以改变底层通信的实现，这种架构设计彰显了开发人员对代码的驾驭能力。\n\n`AbstractServer`抽象父类把创建server所需的公共逻辑抽离出来集中完成，而需要根据特定通信框架的逻辑则交给特定子类（NettyServer）利用重载（doOpen）完成，这样的代码结构在dubbo中随处可见。\n\n\t@Override\n    protected void doOpen() throws Throwable {\n        NettyHelper.setNettyLoggerFactory();\n        ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerBoss\", true));\n        ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerWorker\", true));\n        ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS));\n        bootstrap = new ServerBootstrap(channelFactory);\n        \n        final NettyHandler nettyHandler = new NettyHandler(getUrl(), this);\n        channels = nettyHandler.getChannels();\n        // https://issues.jboss.org/browse/NETTY-365\n        // https://issues.jboss.org/browse/NETTY-379\n        // final Timer timer = new HashedWheelTimer(new NamedThreadFactory(\"NettyIdleTimer\", true));\n        bootstrap.setPipelineFactory(new ChannelPipelineFactory() {\n            public ChannelPipeline getPipeline() {\n                NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n                ChannelPipeline pipeline = Channels.pipeline();\n                /*int idleTimeout = getIdleTimeout();\n                if (idleTimeout > 10000) {\n                    pipeline.addLast(\"timer\", new IdleStateHandler(timer, idleTimeout / 1000, 0, 0));\n                }*/\n                pipeline.addLast(\"decoder\", adapter.getDecoder());  //Upstream\n                pipeline.addLast(\"encoder\", adapter.getEncoder());  //Downstream\n                pipeline.addLast(\"handler\", nettyHandler);          //Upstream & Downstream\n                return pipeline;\n            }\n        });\n        // bind\n        channel = bootstrap.bind(getBindAddress());\n    }\n\n如果是熟悉netty的童鞋，肯定早已习惯这个方法的写法，就是创建了netty的server嘛，不过需要注意的是，netty本身是基于事件的，留意一下上面的`NettyServer`的继承关系，其中`ChannelHandler`并不是netty的那个`ChannelHandler`，这就意味着要让前者转换成后者，才可以供netty使用，这也就是`NettyHandler`的意义，同样，类似这样的做法也可以在dubbo中找到多处。\n\n同时也要注意，`NettyServer`和`NettyHandler`都有同一个用于记录**打开中**的channel的集合：\n\n\tprivate final Map<String, Channel> channels = new ConcurrentHashMap<String, Channel>(); // <ip:port, channel>，其中ip:port指的是调用端的ip和端口号\n\n其中的`Channel`类型也并非netty的`Channel`，而是dubbo的`NettyChannel`，该类负责把netty的`Channel`，dubbo自身的`url`和`handler`映射起来，依赖这样的设计思想，就可以完全把业务和底层基础实现很好的隔离开来，灵活性大大提高，当然，复杂度也随之增加了，这是架构师需要权衡的一个哲学问题。\n\ndubbo封装netty就介绍到这里，我们的分析并没有深入到netty太多，因为小弟我对netty的了解也是非常的皮毛，为了避免误人子弟，所以更多的细节就留给高手来分享吧。\n\n\n\n\n\n编解码\n---\n\nsocket通信中有一个很好玩儿的部分，就是定义消息头，作用非常重大，例如解决粘包问题。dubbo借助netty这样的第三方框架来完成底层通信，这样一部分工作就委托出去了，不过还是有一些工作是需要dubbo好好规划的，我们来看一张官方提供的消息头格式：\n\n![](http://pic.yupoo.com/kazaff/EqdnuPxV/oqq2m.jpg)\n\n只有搞清楚了消息头结构设计，才能完成消息体的编码解码，才能交给底层通信框架去收发。上图中我们其实只需要关注Dubbo部分，其部分意义已经在[这篇文章](http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/)中阐述过了，我们这里只关注代码实现，再来看一下`NettyServer`类：\n\n\n\t@Override\n    protected void doOpen() throws Throwable {\n    \t......\n\t\t\t\tNettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n                ChannelPipeline pipeline = Channels.pipeline();\n                pipeline.addLast(\"decoder\", adapter.getDecoder());  //Upstream\n                pipeline.addLast(\"encoder\", adapter.getEncoder());  //Downstream\n                pipeline.addLast(\"handler\", nettyHandler);          //Upstream & Downstream\n                return pipeline;\n\t\t......\n    }\n\n注意看我在每一行后面加的注释，参见这一篇[关于netty的流处理顺序](http://www.cnblogs.com/montya/archive/2012/12/26/2834279.html)的文章，我们就可以理解dubbo的编码解码是如何配置的。下面接着看一下`getCodec()`方法：\n\n\t protected static Codec2 getChannelCodec(URL url) {\n        String codecName = url.getParameter(Constants.CODEC_KEY, \"telnet\");\t\t//这里的codecName值为dubbo\n        if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) {\n            return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName);\n        } else {\n            //应该是向下兼容 或者 阿里内部才会执行的代码\n            return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class)\n                                               .getExtension(codecName));\n        }\n    }\n\n\n这里又一次尝试根据url中的codec参数来确定最终使用的编解码类，不过我们可以在`DubboProtocol`类的定义中看到，其实这个参数已经被硬编码了：\n\n\t//这里强行设置编码方式，有点硬啊\n    url = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME);\n\n注意这里`Version.isCompatibleVersion()`会去查找是否存在\"com/taobao/remoting/impl/ConnectionRequest.class\"，但我们知道，这是taobao内部的实现。\n\n根据参数，我们看一下对应的配置文件：\n\n\ttransport=com.alibaba.dubbo.remoting.transport.codec.TransportCodec\n\ttelnet=com.alibaba.dubbo.remoting.telnet.codec.TelnetCodec\n\texchange=com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec\n\tdubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboCountCodec\t\t#使用的是这个\n\tthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftCodec\n\n再看回来，`NettyCodecAdapter`完成了把netty和dubbo隔离的任务，使在后面进行编码解码时使用的channel不再是特定的通信框架提供的，而是dubbo提供的抽象实现。\n\n再往下深挖，就会看到dubbo是如何处理数据包的拆装，由于过于琐碎，我决定暂时不继续下去了，日后如果在使用时出现问题，会单独拿出来讲讲。\n\n\n\n\n\n序列化\n---\n\ndubbo本身支持多种序列化方式，当当的duubox也在序列化方面做了新的工作，PRC中要解决跨进程通信的一个首要问题就是对象的系列化问题，业界各大佬公司和开源组织也都开源了很多优秀的项目，而要了解所有的序列化库是需要花大量时间的，我们依旧只关注dubbo是如何在代码层面触发序列化工作的。只有序列化算法本身，还是交给大家去对应官网进行深度学习吧。\n\n序列化是在向对端发送数据前的重要工作，事实上我是在`DubboCodec`类中发现序列化工作的入口的：\n\n\tprotected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException {\n        ......\n        Serialization s = CodecSupport.getSerialization(channel.getUrl(), proto);   //获取对应的序列化库\n\t\t......\n\t\tdecodeEventData(channel, deserialize(s, channel.getUrl(), is));\n\t\t......\n\t\t\n\t}\n\n\tprivate ObjectInput deserialize(Serialization serialization, URL url, InputStream is)\n            throws IOException {\n        return serialization.deserialize(url, is);\n    }\n\n\n\t//该方法继承自ExchangeCodec父类\n\tprotected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException {\n\t\tSerialization serialization = getSerialization(channel);\n\t\t......\n        ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer);\n        ObjectOutput out = serialization.serialize(channel.getUrl(), bos);\n\t\t......\n\t}\n\n\n而从dubbo的配置文件中看，dubbo[x]支持的序列化方式包括：\n\n\tdubbo=com.alibaba.dubbo.common.serialize.support.dubbo.DubboSerialization\n\thessian2=com.alibaba.dubbo.common.serialize.support.hessian.Hessian2Serialization\n\tjava=com.alibaba.dubbo.common.serialize.support.java.JavaSerialization\n\tcompactedjava=com.alibaba.dubbo.common.serialize.support.java.CompactedJavaSerialization\n\tjson=com.alibaba.dubbo.common.serialize.support.json.JsonSerialization\n\tfastjson=com.alibaba.dubbo.common.serialize.support.json.FastJsonSerialization\n\tnativejava=com.alibaba.dubbo.common.serialize.support.nativejava.NativeJavaSerialization\n\tkryo=com.alibaba.dubbo.common.serialize.support.kryo.KryoSerialization\n\tfst=com.alibaba.dubbo.common.serialize.support.fst.FstSerialization\n\tjackson=com.alibaba.dubbo.common.serialize.support.json.JacksonSerialization\n\n\n\n---\n好吧，到此为止，我们就算了解dubbo啦，如果有什么遗漏的地方，可以留言提醒小弟，一起学习进步。","source":"_posts/dubbo的编解码，序列化和通信.md","raw":"title: dubbo的编解码，序列化和通信\ndate: 2015-02-011 15:54:30\ntags:\n- dubbo\n- dubbox\n- 编码\n- 序列化\n- netty\n\ncategories: j2ee\n---\n\n\ndubbo的调研已经快完结了（按照我自己拟定的计划），计划内剩下的内容就只有：\n\n- 序列化\n- 编解码\n- 通信实现\n<!--more-->\n打算写在一篇里，年前彻底搞定dubbo[x]的调研，过完年来了就要投入使用了，好紧张哇~~哟呵呵呵呵！其实前两块的内容并没有啥好讲的，毕竟咱目的是了解源码来辅佐如何使用，而非像当当网的团队那样做dubbo的升级开发。\n\n按照源码的阅读习惯，我们按照上面列表的逆序来一个一个的分析。废话不多说，走着~\n\n\n通信实现\n---\n\n我们主要基于dubbo推荐默认使用的通信框架：netty，来了解一下dubbo是如何完成两端通信的。我们直接从`DubboProtocol`类开始看起：\n\n\texport()  -->  openServer()  -->  createServer()\n\t   \t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t+-->  server = Exchangers.bind(url, requestHandler);  //创建服务\n\n\t\n\ndubbo从要暴漏的服务的URL中取得相关的配置（host，port等）进行服务端server的创建，并且保证相同的配置（host+port）下只会开启一个server，这和netty提供的模型有关（NIO），这个我们后面再说。\n\n我们先来继续看`Exchangers`的相关部分，\n\n\t......\n\t public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n        if (url == null) {\n            throw new IllegalArgumentException(\"url == null\");\n        }\n        if (handler == null) {\n            throw new IllegalArgumentException(\"handler == null\");\n        }\n        url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\");\t//这里尝试配置了编解码的方式\n        return getExchanger(url).bind(url, handler);\n    }\n\t......\n\tpublic static Exchanger getExchanger(URL url) {\n        String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER);\t//默认使用HeaderExchanger\n        return getExchanger(type);\n    }\n\t......\n\tpublic static Exchanger getExchanger(String type) {\n        return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type);\n    }\n\t......\n\n\n可以看出，`Exchangers`只是根据URL的参数提供了策略模式。我们依然以dubbo默认的处理方式为主，接下来代码执行到`HeaderExchanger`类：\n\n\tpublic class HeaderExchanger implements Exchanger {\n    \n\t    public static final String NAME = \"header\";\n\t\n\t    public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {\n\t        return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n\t    }\n\t\n\t    public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n\t        return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n\t    }\t\n\t}\n\n这些代码看起来非常的**设计模式**：\n\n\treturn new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n\t\t\t\t\t\t|\t\t\t\t\t\t  |\t\t\t\t\t |\t\t\t\t\t|\t\t\t\t  |\n\t\t\t\t\t\tV\t\t\t\t\t\t  |\t\t\t\t\t |\t\t\t\t\t|\t\t\t\t  V\n\t\t\t\t1.提供统一的服务操作接口\t\t\t  |\t\t\t\t\t |\t\t\t\t\t|\t\t\t\t利用装饰器模式，这个才是最靠近业务的逻辑（直接调用相关的invoker）\n\t\t\t\t2.创建心跳定时任务\t\t\t\t  V\t\t\t\t\t |\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t1.利于扩展点机制选择通信框架\t |\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t2.格式化回调函数\t\t\t\t |\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t V\t\t\t\t\tV\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    消息的解码???\t     处理dubbo的通信模型：单向，双向，异步等通信模型\n\n\n\n要想理解现在的内容，就得先搞清楚[JAVA NIO channel概念](http://ifeve.com/channels/)，搞清楚netty的[NIO线程模型](http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point)。\n\n了解了这两个基础知识点，那么我们就可以继续分析源码了，上面那一行代码中`Transporters.bind()`默认会调用`NettyTransporter`：\n\n\tpublic class NettyTransporter implements Transporter {\n\n\t    public static final String NAME = \"netty\";\n\t    \n\t    public Server bind(URL url, ChannelHandler listener) throws RemotingException {\n\t        return new NettyServer(url, listener);\n\t    }\n\t\n\t    public Client connect(URL url, ChannelHandler listener) throws RemotingException {\n\t        return new NettyClient(url, listener);\n\t    }\n\t}\n\n接下来我们就真正进入到了netty的世界，我们先来看一下`NettyServer`的家谱：\n\n![](http://pic.yupoo.com/kazaff/EqfbO3HE/NAsri.png)\n\n要时刻记着，dubbo是一个非常灵活的框架，我们不仅可以使用netty作为底层通信组件，也可以仅靠url参数就可以改变底层通信的实现，这种架构设计彰显了开发人员对代码的驾驭能力。\n\n`AbstractServer`抽象父类把创建server所需的公共逻辑抽离出来集中完成，而需要根据特定通信框架的逻辑则交给特定子类（NettyServer）利用重载（doOpen）完成，这样的代码结构在dubbo中随处可见。\n\n\t@Override\n    protected void doOpen() throws Throwable {\n        NettyHelper.setNettyLoggerFactory();\n        ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerBoss\", true));\n        ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerWorker\", true));\n        ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS));\n        bootstrap = new ServerBootstrap(channelFactory);\n        \n        final NettyHandler nettyHandler = new NettyHandler(getUrl(), this);\n        channels = nettyHandler.getChannels();\n        // https://issues.jboss.org/browse/NETTY-365\n        // https://issues.jboss.org/browse/NETTY-379\n        // final Timer timer = new HashedWheelTimer(new NamedThreadFactory(\"NettyIdleTimer\", true));\n        bootstrap.setPipelineFactory(new ChannelPipelineFactory() {\n            public ChannelPipeline getPipeline() {\n                NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n                ChannelPipeline pipeline = Channels.pipeline();\n                /*int idleTimeout = getIdleTimeout();\n                if (idleTimeout > 10000) {\n                    pipeline.addLast(\"timer\", new IdleStateHandler(timer, idleTimeout / 1000, 0, 0));\n                }*/\n                pipeline.addLast(\"decoder\", adapter.getDecoder());  //Upstream\n                pipeline.addLast(\"encoder\", adapter.getEncoder());  //Downstream\n                pipeline.addLast(\"handler\", nettyHandler);          //Upstream & Downstream\n                return pipeline;\n            }\n        });\n        // bind\n        channel = bootstrap.bind(getBindAddress());\n    }\n\n如果是熟悉netty的童鞋，肯定早已习惯这个方法的写法，就是创建了netty的server嘛，不过需要注意的是，netty本身是基于事件的，留意一下上面的`NettyServer`的继承关系，其中`ChannelHandler`并不是netty的那个`ChannelHandler`，这就意味着要让前者转换成后者，才可以供netty使用，这也就是`NettyHandler`的意义，同样，类似这样的做法也可以在dubbo中找到多处。\n\n同时也要注意，`NettyServer`和`NettyHandler`都有同一个用于记录**打开中**的channel的集合：\n\n\tprivate final Map<String, Channel> channels = new ConcurrentHashMap<String, Channel>(); // <ip:port, channel>，其中ip:port指的是调用端的ip和端口号\n\n其中的`Channel`类型也并非netty的`Channel`，而是dubbo的`NettyChannel`，该类负责把netty的`Channel`，dubbo自身的`url`和`handler`映射起来，依赖这样的设计思想，就可以完全把业务和底层基础实现很好的隔离开来，灵活性大大提高，当然，复杂度也随之增加了，这是架构师需要权衡的一个哲学问题。\n\ndubbo封装netty就介绍到这里，我们的分析并没有深入到netty太多，因为小弟我对netty的了解也是非常的皮毛，为了避免误人子弟，所以更多的细节就留给高手来分享吧。\n\n\n\n\n\n编解码\n---\n\nsocket通信中有一个很好玩儿的部分，就是定义消息头，作用非常重大，例如解决粘包问题。dubbo借助netty这样的第三方框架来完成底层通信，这样一部分工作就委托出去了，不过还是有一些工作是需要dubbo好好规划的，我们来看一张官方提供的消息头格式：\n\n![](http://pic.yupoo.com/kazaff/EqdnuPxV/oqq2m.jpg)\n\n只有搞清楚了消息头结构设计，才能完成消息体的编码解码，才能交给底层通信框架去收发。上图中我们其实只需要关注Dubbo部分，其部分意义已经在[这篇文章](http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/)中阐述过了，我们这里只关注代码实现，再来看一下`NettyServer`类：\n\n\n\t@Override\n    protected void doOpen() throws Throwable {\n    \t......\n\t\t\t\tNettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n                ChannelPipeline pipeline = Channels.pipeline();\n                pipeline.addLast(\"decoder\", adapter.getDecoder());  //Upstream\n                pipeline.addLast(\"encoder\", adapter.getEncoder());  //Downstream\n                pipeline.addLast(\"handler\", nettyHandler);          //Upstream & Downstream\n                return pipeline;\n\t\t......\n    }\n\n注意看我在每一行后面加的注释，参见这一篇[关于netty的流处理顺序](http://www.cnblogs.com/montya/archive/2012/12/26/2834279.html)的文章，我们就可以理解dubbo的编码解码是如何配置的。下面接着看一下`getCodec()`方法：\n\n\t protected static Codec2 getChannelCodec(URL url) {\n        String codecName = url.getParameter(Constants.CODEC_KEY, \"telnet\");\t\t//这里的codecName值为dubbo\n        if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) {\n            return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName);\n        } else {\n            //应该是向下兼容 或者 阿里内部才会执行的代码\n            return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class)\n                                               .getExtension(codecName));\n        }\n    }\n\n\n这里又一次尝试根据url中的codec参数来确定最终使用的编解码类，不过我们可以在`DubboProtocol`类的定义中看到，其实这个参数已经被硬编码了：\n\n\t//这里强行设置编码方式，有点硬啊\n    url = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME);\n\n注意这里`Version.isCompatibleVersion()`会去查找是否存在\"com/taobao/remoting/impl/ConnectionRequest.class\"，但我们知道，这是taobao内部的实现。\n\n根据参数，我们看一下对应的配置文件：\n\n\ttransport=com.alibaba.dubbo.remoting.transport.codec.TransportCodec\n\ttelnet=com.alibaba.dubbo.remoting.telnet.codec.TelnetCodec\n\texchange=com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec\n\tdubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboCountCodec\t\t#使用的是这个\n\tthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftCodec\n\n再看回来，`NettyCodecAdapter`完成了把netty和dubbo隔离的任务，使在后面进行编码解码时使用的channel不再是特定的通信框架提供的，而是dubbo提供的抽象实现。\n\n再往下深挖，就会看到dubbo是如何处理数据包的拆装，由于过于琐碎，我决定暂时不继续下去了，日后如果在使用时出现问题，会单独拿出来讲讲。\n\n\n\n\n\n序列化\n---\n\ndubbo本身支持多种序列化方式，当当的duubox也在序列化方面做了新的工作，PRC中要解决跨进程通信的一个首要问题就是对象的系列化问题，业界各大佬公司和开源组织也都开源了很多优秀的项目，而要了解所有的序列化库是需要花大量时间的，我们依旧只关注dubbo是如何在代码层面触发序列化工作的。只有序列化算法本身，还是交给大家去对应官网进行深度学习吧。\n\n序列化是在向对端发送数据前的重要工作，事实上我是在`DubboCodec`类中发现序列化工作的入口的：\n\n\tprotected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException {\n        ......\n        Serialization s = CodecSupport.getSerialization(channel.getUrl(), proto);   //获取对应的序列化库\n\t\t......\n\t\tdecodeEventData(channel, deserialize(s, channel.getUrl(), is));\n\t\t......\n\t\t\n\t}\n\n\tprivate ObjectInput deserialize(Serialization serialization, URL url, InputStream is)\n            throws IOException {\n        return serialization.deserialize(url, is);\n    }\n\n\n\t//该方法继承自ExchangeCodec父类\n\tprotected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException {\n\t\tSerialization serialization = getSerialization(channel);\n\t\t......\n        ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer);\n        ObjectOutput out = serialization.serialize(channel.getUrl(), bos);\n\t\t......\n\t}\n\n\n而从dubbo的配置文件中看，dubbo[x]支持的序列化方式包括：\n\n\tdubbo=com.alibaba.dubbo.common.serialize.support.dubbo.DubboSerialization\n\thessian2=com.alibaba.dubbo.common.serialize.support.hessian.Hessian2Serialization\n\tjava=com.alibaba.dubbo.common.serialize.support.java.JavaSerialization\n\tcompactedjava=com.alibaba.dubbo.common.serialize.support.java.CompactedJavaSerialization\n\tjson=com.alibaba.dubbo.common.serialize.support.json.JsonSerialization\n\tfastjson=com.alibaba.dubbo.common.serialize.support.json.FastJsonSerialization\n\tnativejava=com.alibaba.dubbo.common.serialize.support.nativejava.NativeJavaSerialization\n\tkryo=com.alibaba.dubbo.common.serialize.support.kryo.KryoSerialization\n\tfst=com.alibaba.dubbo.common.serialize.support.fst.FstSerialization\n\tjackson=com.alibaba.dubbo.common.serialize.support.json.JacksonSerialization\n\n\n\n---\n好吧，到此为止，我们就算了解dubbo啦，如果有什么遗漏的地方，可以留言提醒小弟，一起学习进步。","slug":"dubbo的编解码，序列化和通信","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yq5009egtfyrxn02gmq","comments":1,"layout":"post","photos":[],"link":"","content":"<p>dubbo的调研已经快完结了（按照我自己拟定的计划），计划内剩下的内容就只有：</p>\n<ul>\n<li>序列化</li>\n<li>编解码</li>\n<li>通信实现<a id=\"more\"></a>\n打算写在一篇里，年前彻底搞定dubbo[x]的调研，过完年来了就要投入使用了，好紧张哇~~哟呵呵呵呵！其实前两块的内容并没有啥好讲的，毕竟咱目的是了解源码来辅佐如何使用，而非像当当网的团队那样做dubbo的升级开发。</li>\n</ul>\n<p>按照源码的阅读习惯，我们按照上面列表的逆序来一个一个的分析。废话不多说，走着~</p>\n<h2 id=\"通信实现\"><a href=\"#通信实现\" class=\"headerlink\" title=\"通信实现\"></a>通信实现</h2><p>我们主要基于dubbo推荐默认使用的通信框架：netty，来了解一下dubbo是如何完成两端通信的。我们直接从<code>DubboProtocol</code>类开始看起：</p>\n<pre><code>export()  --&gt;  openServer()  --&gt;  createServer()\n                                           |\n                                        +--&gt;  server = Exchangers.bind(url, requestHandler);  //创建服务\n</code></pre><p>dubbo从要暴漏的服务的URL中取得相关的配置（host，port等）进行服务端server的创建，并且保证相同的配置（host+port）下只会开启一个server，这和netty提供的模型有关（NIO），这个我们后面再说。</p>\n<p>我们先来继续看<code>Exchangers</code>的相关部分，</p>\n<pre><code>......\n public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n    if (url == null) {\n        throw new IllegalArgumentException(&quot;url == null&quot;);\n    }\n    if (handler == null) {\n        throw new IllegalArgumentException(&quot;handler == null&quot;);\n    }\n    url = url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;);    //这里尝试配置了编解码的方式\n    return getExchanger(url).bind(url, handler);\n}\n......\npublic static Exchanger getExchanger(URL url) {\n    String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER);    //默认使用HeaderExchanger\n    return getExchanger(type);\n}\n......\npublic static Exchanger getExchanger(String type) {\n    return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type);\n}\n......\n</code></pre><p>可以看出，<code>Exchangers</code>只是根据URL的参数提供了策略模式。我们依然以dubbo默认的处理方式为主，接下来代码执行到<code>HeaderExchanger</code>类：</p>\n<pre><code>public class HeaderExchanger implements Exchanger {\n\n    public static final String NAME = &quot;header&quot;;\n\n    public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {\n        return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n    }\n\n    public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n        return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n    }    \n}\n</code></pre><p>这些代码看起来非常的<strong>设计模式</strong>：</p>\n<pre><code>return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n                    |                          |                     |                    |                  |\n                    V                          |                     |                    |                  V\n            1.提供统一的服务操作接口              |                     |                    |                利用装饰器模式，这个才是最靠近业务的逻辑（直接调用相关的invoker）\n            2.创建心跳定时任务                  V                     |                    |\n                                    1.利于扩展点机制选择通信框架     |                    |\n                                    2.格式化回调函数                 |                    |\n                                                                 V                    V\n                                                            消息的解码???         处理dubbo的通信模型：单向，双向，异步等通信模型\n</code></pre><p>要想理解现在的内容，就得先搞清楚<a href=\"http://ifeve.com/channels/\" target=\"_blank\" rel=\"external\">JAVA NIO channel概念</a>，搞清楚netty的<a href=\"http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point\" target=\"_blank\" rel=\"external\">NIO线程模型</a>。</p>\n<p>了解了这两个基础知识点，那么我们就可以继续分析源码了，上面那一行代码中<code>Transporters.bind()</code>默认会调用<code>NettyTransporter</code>：</p>\n<pre><code>public class NettyTransporter implements Transporter {\n\n    public static final String NAME = &quot;netty&quot;;\n\n    public Server bind(URL url, ChannelHandler listener) throws RemotingException {\n        return new NettyServer(url, listener);\n    }\n\n    public Client connect(URL url, ChannelHandler listener) throws RemotingException {\n        return new NettyClient(url, listener);\n    }\n}\n</code></pre><p>接下来我们就真正进入到了netty的世界，我们先来看一下<code>NettyServer</code>的家谱：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EqfbO3HE/NAsri.png\" alt=\"\"></p>\n<p>要时刻记着，dubbo是一个非常灵活的框架，我们不仅可以使用netty作为底层通信组件，也可以仅靠url参数就可以改变底层通信的实现，这种架构设计彰显了开发人员对代码的驾驭能力。</p>\n<p><code>AbstractServer</code>抽象父类把创建server所需的公共逻辑抽离出来集中完成，而需要根据特定通信框架的逻辑则交给特定子类（NettyServer）利用重载（doOpen）完成，这样的代码结构在dubbo中随处可见。</p>\n<pre><code>@Override\nprotected void doOpen() throws Throwable {\n    NettyHelper.setNettyLoggerFactory();\n    ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerBoss&quot;, true));\n    ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerWorker&quot;, true));\n    ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS));\n    bootstrap = new ServerBootstrap(channelFactory);\n\n    final NettyHandler nettyHandler = new NettyHandler(getUrl(), this);\n    channels = nettyHandler.getChannels();\n    // https://issues.jboss.org/browse/NETTY-365\n    // https://issues.jboss.org/browse/NETTY-379\n    // final Timer timer = new HashedWheelTimer(new NamedThreadFactory(&quot;NettyIdleTimer&quot;, true));\n    bootstrap.setPipelineFactory(new ChannelPipelineFactory() {\n        public ChannelPipeline getPipeline() {\n            NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n            ChannelPipeline pipeline = Channels.pipeline();\n            /*int idleTimeout = getIdleTimeout();\n            if (idleTimeout &gt; 10000) {\n                pipeline.addLast(&quot;timer&quot;, new IdleStateHandler(timer, idleTimeout / 1000, 0, 0));\n            }*/\n            pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder());  //Upstream\n            pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder());  //Downstream\n            pipeline.addLast(&quot;handler&quot;, nettyHandler);          //Upstream &amp; Downstream\n            return pipeline;\n        }\n    });\n    // bind\n    channel = bootstrap.bind(getBindAddress());\n}\n</code></pre><p>如果是熟悉netty的童鞋，肯定早已习惯这个方法的写法，就是创建了netty的server嘛，不过需要注意的是，netty本身是基于事件的，留意一下上面的<code>NettyServer</code>的继承关系，其中<code>ChannelHandler</code>并不是netty的那个<code>ChannelHandler</code>，这就意味着要让前者转换成后者，才可以供netty使用，这也就是<code>NettyHandler</code>的意义，同样，类似这样的做法也可以在dubbo中找到多处。</p>\n<p>同时也要注意，<code>NettyServer</code>和<code>NettyHandler</code>都有同一个用于记录<strong>打开中</strong>的channel的集合：</p>\n<pre><code>private final Map&lt;String, Channel&gt; channels = new ConcurrentHashMap&lt;String, Channel&gt;(); // &lt;ip:port, channel&gt;，其中ip:port指的是调用端的ip和端口号\n</code></pre><p>其中的<code>Channel</code>类型也并非netty的<code>Channel</code>，而是dubbo的<code>NettyChannel</code>，该类负责把netty的<code>Channel</code>，dubbo自身的<code>url</code>和<code>handler</code>映射起来，依赖这样的设计思想，就可以完全把业务和底层基础实现很好的隔离开来，灵活性大大提高，当然，复杂度也随之增加了，这是架构师需要权衡的一个哲学问题。</p>\n<p>dubbo封装netty就介绍到这里，我们的分析并没有深入到netty太多，因为小弟我对netty的了解也是非常的皮毛，为了避免误人子弟，所以更多的细节就留给高手来分享吧。</p>\n<h2 id=\"编解码\"><a href=\"#编解码\" class=\"headerlink\" title=\"编解码\"></a>编解码</h2><p>socket通信中有一个很好玩儿的部分，就是定义消息头，作用非常重大，例如解决粘包问题。dubbo借助netty这样的第三方框架来完成底层通信，这样一部分工作就委托出去了，不过还是有一些工作是需要dubbo好好规划的，我们来看一张官方提供的消息头格式：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EqdnuPxV/oqq2m.jpg\" alt=\"\"></p>\n<p>只有搞清楚了消息头结构设计，才能完成消息体的编码解码，才能交给底层通信框架去收发。上图中我们其实只需要关注Dubbo部分，其部分意义已经在<a href=\"http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/\">这篇文章</a>中阐述过了，我们这里只关注代码实现，再来看一下<code>NettyServer</code>类：</p>\n<pre><code>@Override\nprotected void doOpen() throws Throwable {\n    ......\n            NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n            ChannelPipeline pipeline = Channels.pipeline();\n            pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder());  //Upstream\n            pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder());  //Downstream\n            pipeline.addLast(&quot;handler&quot;, nettyHandler);          //Upstream &amp; Downstream\n            return pipeline;\n    ......\n}\n</code></pre><p>注意看我在每一行后面加的注释，参见这一篇<a href=\"http://www.cnblogs.com/montya/archive/2012/12/26/2834279.html\" target=\"_blank\" rel=\"external\">关于netty的流处理顺序</a>的文章，我们就可以理解dubbo的编码解码是如何配置的。下面接着看一下<code>getCodec()</code>方法：</p>\n<pre><code> protected static Codec2 getChannelCodec(URL url) {\n    String codecName = url.getParameter(Constants.CODEC_KEY, &quot;telnet&quot;);        //这里的codecName值为dubbo\n    if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) {\n        return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName);\n    } else {\n        //应该是向下兼容 或者 阿里内部才会执行的代码\n        return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class)\n                                           .getExtension(codecName));\n    }\n}\n</code></pre><p>这里又一次尝试根据url中的codec参数来确定最终使用的编解码类，不过我们可以在<code>DubboProtocol</code>类的定义中看到，其实这个参数已经被硬编码了：</p>\n<pre><code>//这里强行设置编码方式，有点硬啊\nurl = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME);\n</code></pre><p>注意这里<code>Version.isCompatibleVersion()</code>会去查找是否存在”com/taobao/remoting/impl/ConnectionRequest.class”，但我们知道，这是taobao内部的实现。</p>\n<p>根据参数，我们看一下对应的配置文件：</p>\n<pre><code>transport=com.alibaba.dubbo.remoting.transport.codec.TransportCodec\ntelnet=com.alibaba.dubbo.remoting.telnet.codec.TelnetCodec\nexchange=com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec\ndubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboCountCodec        #使用的是这个\nthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftCodec\n</code></pre><p>再看回来，<code>NettyCodecAdapter</code>完成了把netty和dubbo隔离的任务，使在后面进行编码解码时使用的channel不再是特定的通信框架提供的，而是dubbo提供的抽象实现。</p>\n<p>再往下深挖，就会看到dubbo是如何处理数据包的拆装，由于过于琐碎，我决定暂时不继续下去了，日后如果在使用时出现问题，会单独拿出来讲讲。</p>\n<h2 id=\"序列化\"><a href=\"#序列化\" class=\"headerlink\" title=\"序列化\"></a>序列化</h2><p>dubbo本身支持多种序列化方式，当当的duubox也在序列化方面做了新的工作，PRC中要解决跨进程通信的一个首要问题就是对象的系列化问题，业界各大佬公司和开源组织也都开源了很多优秀的项目，而要了解所有的序列化库是需要花大量时间的，我们依旧只关注dubbo是如何在代码层面触发序列化工作的。只有序列化算法本身，还是交给大家去对应官网进行深度学习吧。</p>\n<p>序列化是在向对端发送数据前的重要工作，事实上我是在<code>DubboCodec</code>类中发现序列化工作的入口的：</p>\n<pre><code>protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException {\n    ......\n    Serialization s = CodecSupport.getSerialization(channel.getUrl(), proto);   //获取对应的序列化库\n    ......\n    decodeEventData(channel, deserialize(s, channel.getUrl(), is));\n    ......\n\n}\n\nprivate ObjectInput deserialize(Serialization serialization, URL url, InputStream is)\n        throws IOException {\n    return serialization.deserialize(url, is);\n}\n\n\n//该方法继承自ExchangeCodec父类\nprotected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException {\n    Serialization serialization = getSerialization(channel);\n    ......\n    ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer);\n    ObjectOutput out = serialization.serialize(channel.getUrl(), bos);\n    ......\n}\n</code></pre><p>而从dubbo的配置文件中看，dubbo[x]支持的序列化方式包括：</p>\n<pre><code>dubbo=com.alibaba.dubbo.common.serialize.support.dubbo.DubboSerialization\nhessian2=com.alibaba.dubbo.common.serialize.support.hessian.Hessian2Serialization\njava=com.alibaba.dubbo.common.serialize.support.java.JavaSerialization\ncompactedjava=com.alibaba.dubbo.common.serialize.support.java.CompactedJavaSerialization\njson=com.alibaba.dubbo.common.serialize.support.json.JsonSerialization\nfastjson=com.alibaba.dubbo.common.serialize.support.json.FastJsonSerialization\nnativejava=com.alibaba.dubbo.common.serialize.support.nativejava.NativeJavaSerialization\nkryo=com.alibaba.dubbo.common.serialize.support.kryo.KryoSerialization\nfst=com.alibaba.dubbo.common.serialize.support.fst.FstSerialization\njackson=com.alibaba.dubbo.common.serialize.support.json.JacksonSerialization\n</code></pre><hr>\n<p>好吧，到此为止，我们就算了解dubbo啦，如果有什么遗漏的地方，可以留言提醒小弟，一起学习进步。</p>\n","excerpt":"<p>dubbo的调研已经快完结了（按照我自己拟定的计划），计划内剩下的内容就只有：</p>\n<ul>\n<li>序列化</li>\n<li>编解码</li>\n<li>通信实现","more":"打算写在一篇里，年前彻底搞定dubbo[x]的调研，过完年来了就要投入使用了，好紧张哇~~哟呵呵呵呵！其实前两块的内容并没有啥好讲的，毕竟咱目的是了解源码来辅佐如何使用，而非像当当网的团队那样做dubbo的升级开发。</li>\n</ul>\n<p>按照源码的阅读习惯，我们按照上面列表的逆序来一个一个的分析。废话不多说，走着~</p>\n<h2 id=\"通信实现\"><a href=\"#通信实现\" class=\"headerlink\" title=\"通信实现\"></a>通信实现</h2><p>我们主要基于dubbo推荐默认使用的通信框架：netty，来了解一下dubbo是如何完成两端通信的。我们直接从<code>DubboProtocol</code>类开始看起：</p>\n<pre><code>export()  --&gt;  openServer()  --&gt;  createServer()\n                                           |\n                                        +--&gt;  server = Exchangers.bind(url, requestHandler);  //创建服务\n</code></pre><p>dubbo从要暴漏的服务的URL中取得相关的配置（host，port等）进行服务端server的创建，并且保证相同的配置（host+port）下只会开启一个server，这和netty提供的模型有关（NIO），这个我们后面再说。</p>\n<p>我们先来继续看<code>Exchangers</code>的相关部分，</p>\n<pre><code>......\n public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n    if (url == null) {\n        throw new IllegalArgumentException(&quot;url == null&quot;);\n    }\n    if (handler == null) {\n        throw new IllegalArgumentException(&quot;handler == null&quot;);\n    }\n    url = url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;);    //这里尝试配置了编解码的方式\n    return getExchanger(url).bind(url, handler);\n}\n......\npublic static Exchanger getExchanger(URL url) {\n    String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER);    //默认使用HeaderExchanger\n    return getExchanger(type);\n}\n......\npublic static Exchanger getExchanger(String type) {\n    return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type);\n}\n......\n</code></pre><p>可以看出，<code>Exchangers</code>只是根据URL的参数提供了策略模式。我们依然以dubbo默认的处理方式为主，接下来代码执行到<code>HeaderExchanger</code>类：</p>\n<pre><code>public class HeaderExchanger implements Exchanger {\n\n    public static final String NAME = &quot;header&quot;;\n\n    public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {\n        return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n    }\n\n    public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {\n        return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n    }    \n}\n</code></pre><p>这些代码看起来非常的<strong>设计模式</strong>：</p>\n<pre><code>return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));\n                    |                          |                     |                    |                  |\n                    V                          |                     |                    |                  V\n            1.提供统一的服务操作接口              |                     |                    |                利用装饰器模式，这个才是最靠近业务的逻辑（直接调用相关的invoker）\n            2.创建心跳定时任务                  V                     |                    |\n                                    1.利于扩展点机制选择通信框架     |                    |\n                                    2.格式化回调函数                 |                    |\n                                                                 V                    V\n                                                            消息的解码???         处理dubbo的通信模型：单向，双向，异步等通信模型\n</code></pre><p>要想理解现在的内容，就得先搞清楚<a href=\"http://ifeve.com/channels/\">JAVA NIO channel概念</a>，搞清楚netty的<a href=\"http://www.infoq.com/cn/articles/netty-threading-model/#show-last-Point\">NIO线程模型</a>。</p>\n<p>了解了这两个基础知识点，那么我们就可以继续分析源码了，上面那一行代码中<code>Transporters.bind()</code>默认会调用<code>NettyTransporter</code>：</p>\n<pre><code>public class NettyTransporter implements Transporter {\n\n    public static final String NAME = &quot;netty&quot;;\n\n    public Server bind(URL url, ChannelHandler listener) throws RemotingException {\n        return new NettyServer(url, listener);\n    }\n\n    public Client connect(URL url, ChannelHandler listener) throws RemotingException {\n        return new NettyClient(url, listener);\n    }\n}\n</code></pre><p>接下来我们就真正进入到了netty的世界，我们先来看一下<code>NettyServer</code>的家谱：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EqfbO3HE/NAsri.png\" alt=\"\"></p>\n<p>要时刻记着，dubbo是一个非常灵活的框架，我们不仅可以使用netty作为底层通信组件，也可以仅靠url参数就可以改变底层通信的实现，这种架构设计彰显了开发人员对代码的驾驭能力。</p>\n<p><code>AbstractServer</code>抽象父类把创建server所需的公共逻辑抽离出来集中完成，而需要根据特定通信框架的逻辑则交给特定子类（NettyServer）利用重载（doOpen）完成，这样的代码结构在dubbo中随处可见。</p>\n<pre><code>@Override\nprotected void doOpen() throws Throwable {\n    NettyHelper.setNettyLoggerFactory();\n    ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerBoss&quot;, true));\n    ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerWorker&quot;, true));\n    ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS));\n    bootstrap = new ServerBootstrap(channelFactory);\n\n    final NettyHandler nettyHandler = new NettyHandler(getUrl(), this);\n    channels = nettyHandler.getChannels();\n    // https://issues.jboss.org/browse/NETTY-365\n    // https://issues.jboss.org/browse/NETTY-379\n    // final Timer timer = new HashedWheelTimer(new NamedThreadFactory(&quot;NettyIdleTimer&quot;, true));\n    bootstrap.setPipelineFactory(new ChannelPipelineFactory() {\n        public ChannelPipeline getPipeline() {\n            NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n            ChannelPipeline pipeline = Channels.pipeline();\n            /*int idleTimeout = getIdleTimeout();\n            if (idleTimeout &gt; 10000) {\n                pipeline.addLast(&quot;timer&quot;, new IdleStateHandler(timer, idleTimeout / 1000, 0, 0));\n            }*/\n            pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder());  //Upstream\n            pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder());  //Downstream\n            pipeline.addLast(&quot;handler&quot;, nettyHandler);          //Upstream &amp; Downstream\n            return pipeline;\n        }\n    });\n    // bind\n    channel = bootstrap.bind(getBindAddress());\n}\n</code></pre><p>如果是熟悉netty的童鞋，肯定早已习惯这个方法的写法，就是创建了netty的server嘛，不过需要注意的是，netty本身是基于事件的，留意一下上面的<code>NettyServer</code>的继承关系，其中<code>ChannelHandler</code>并不是netty的那个<code>ChannelHandler</code>，这就意味着要让前者转换成后者，才可以供netty使用，这也就是<code>NettyHandler</code>的意义，同样，类似这样的做法也可以在dubbo中找到多处。</p>\n<p>同时也要注意，<code>NettyServer</code>和<code>NettyHandler</code>都有同一个用于记录<strong>打开中</strong>的channel的集合：</p>\n<pre><code>private final Map&lt;String, Channel&gt; channels = new ConcurrentHashMap&lt;String, Channel&gt;(); // &lt;ip:port, channel&gt;，其中ip:port指的是调用端的ip和端口号\n</code></pre><p>其中的<code>Channel</code>类型也并非netty的<code>Channel</code>，而是dubbo的<code>NettyChannel</code>，该类负责把netty的<code>Channel</code>，dubbo自身的<code>url</code>和<code>handler</code>映射起来，依赖这样的设计思想，就可以完全把业务和底层基础实现很好的隔离开来，灵活性大大提高，当然，复杂度也随之增加了，这是架构师需要权衡的一个哲学问题。</p>\n<p>dubbo封装netty就介绍到这里，我们的分析并没有深入到netty太多，因为小弟我对netty的了解也是非常的皮毛，为了避免误人子弟，所以更多的细节就留给高手来分享吧。</p>\n<h2 id=\"编解码\"><a href=\"#编解码\" class=\"headerlink\" title=\"编解码\"></a>编解码</h2><p>socket通信中有一个很好玩儿的部分，就是定义消息头，作用非常重大，例如解决粘包问题。dubbo借助netty这样的第三方框架来完成底层通信，这样一部分工作就委托出去了，不过还是有一些工作是需要dubbo好好规划的，我们来看一张官方提供的消息头格式：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EqdnuPxV/oqq2m.jpg\" alt=\"\"></p>\n<p>只有搞清楚了消息头结构设计，才能完成消息体的编码解码，才能交给底层通信框架去收发。上图中我们其实只需要关注Dubbo部分，其部分意义已经在<a href=\"http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/\">这篇文章</a>中阐述过了，我们这里只关注代码实现，再来看一下<code>NettyServer</code>类：</p>\n<pre><code>@Override\nprotected void doOpen() throws Throwable {\n    ......\n            NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this);\n            ChannelPipeline pipeline = Channels.pipeline();\n            pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder());  //Upstream\n            pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder());  //Downstream\n            pipeline.addLast(&quot;handler&quot;, nettyHandler);          //Upstream &amp; Downstream\n            return pipeline;\n    ......\n}\n</code></pre><p>注意看我在每一行后面加的注释，参见这一篇<a href=\"http://www.cnblogs.com/montya/archive/2012/12/26/2834279.html\">关于netty的流处理顺序</a>的文章，我们就可以理解dubbo的编码解码是如何配置的。下面接着看一下<code>getCodec()</code>方法：</p>\n<pre><code> protected static Codec2 getChannelCodec(URL url) {\n    String codecName = url.getParameter(Constants.CODEC_KEY, &quot;telnet&quot;);        //这里的codecName值为dubbo\n    if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) {\n        return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName);\n    } else {\n        //应该是向下兼容 或者 阿里内部才会执行的代码\n        return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class)\n                                           .getExtension(codecName));\n    }\n}\n</code></pre><p>这里又一次尝试根据url中的codec参数来确定最终使用的编解码类，不过我们可以在<code>DubboProtocol</code>类的定义中看到，其实这个参数已经被硬编码了：</p>\n<pre><code>//这里强行设置编码方式，有点硬啊\nurl = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME);\n</code></pre><p>注意这里<code>Version.isCompatibleVersion()</code>会去查找是否存在”com/taobao/remoting/impl/ConnectionRequest.class”，但我们知道，这是taobao内部的实现。</p>\n<p>根据参数，我们看一下对应的配置文件：</p>\n<pre><code>transport=com.alibaba.dubbo.remoting.transport.codec.TransportCodec\ntelnet=com.alibaba.dubbo.remoting.telnet.codec.TelnetCodec\nexchange=com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec\ndubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboCountCodec        #使用的是这个\nthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftCodec\n</code></pre><p>再看回来，<code>NettyCodecAdapter</code>完成了把netty和dubbo隔离的任务，使在后面进行编码解码时使用的channel不再是特定的通信框架提供的，而是dubbo提供的抽象实现。</p>\n<p>再往下深挖，就会看到dubbo是如何处理数据包的拆装，由于过于琐碎，我决定暂时不继续下去了，日后如果在使用时出现问题，会单独拿出来讲讲。</p>\n<h2 id=\"序列化\"><a href=\"#序列化\" class=\"headerlink\" title=\"序列化\"></a>序列化</h2><p>dubbo本身支持多种序列化方式，当当的duubox也在序列化方面做了新的工作，PRC中要解决跨进程通信的一个首要问题就是对象的系列化问题，业界各大佬公司和开源组织也都开源了很多优秀的项目，而要了解所有的序列化库是需要花大量时间的，我们依旧只关注dubbo是如何在代码层面触发序列化工作的。只有序列化算法本身，还是交给大家去对应官网进行深度学习吧。</p>\n<p>序列化是在向对端发送数据前的重要工作，事实上我是在<code>DubboCodec</code>类中发现序列化工作的入口的：</p>\n<pre><code>protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException {\n    ......\n    Serialization s = CodecSupport.getSerialization(channel.getUrl(), proto);   //获取对应的序列化库\n    ......\n    decodeEventData(channel, deserialize(s, channel.getUrl(), is));\n    ......\n\n}\n\nprivate ObjectInput deserialize(Serialization serialization, URL url, InputStream is)\n        throws IOException {\n    return serialization.deserialize(url, is);\n}\n\n\n//该方法继承自ExchangeCodec父类\nprotected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException {\n    Serialization serialization = getSerialization(channel);\n    ......\n    ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer);\n    ObjectOutput out = serialization.serialize(channel.getUrl(), bos);\n    ......\n}\n</code></pre><p>而从dubbo的配置文件中看，dubbo[x]支持的序列化方式包括：</p>\n<pre><code>dubbo=com.alibaba.dubbo.common.serialize.support.dubbo.DubboSerialization\nhessian2=com.alibaba.dubbo.common.serialize.support.hessian.Hessian2Serialization\njava=com.alibaba.dubbo.common.serialize.support.java.JavaSerialization\ncompactedjava=com.alibaba.dubbo.common.serialize.support.java.CompactedJavaSerialization\njson=com.alibaba.dubbo.common.serialize.support.json.JsonSerialization\nfastjson=com.alibaba.dubbo.common.serialize.support.json.FastJsonSerialization\nnativejava=com.alibaba.dubbo.common.serialize.support.nativejava.NativeJavaSerialization\nkryo=com.alibaba.dubbo.common.serialize.support.kryo.KryoSerialization\nfst=com.alibaba.dubbo.common.serialize.support.fst.FstSerialization\njackson=com.alibaba.dubbo.common.serialize.support.json.JacksonSerialization\n</code></pre><hr>\n<p>好吧，到此为止，我们就算了解dubbo啦，如果有什么遗漏的地方，可以留言提醒小弟，一起学习进步。</p>"},{"title":"dubbo的缓存分析","date":"2015-03-13T07:54:30.000Z","_content":"\n这次的目标是缓存，没错，绝壁常用的一个知识点，我们怎么能不了解一下它的内部实现源码呢？！\n<!-- more -->\n\ndubbo的官方描述很[简洁](http://alibaba.github.io/dubbo-doc-static/Result+Cache-zh.htm)，好的封装就是这么强大， 让你用起来丝毫不费力。我们今天就费力的看一下dubbo是如何提供cache功能的。有想直接使用的童鞋，就可以跳过下面内容直面看官方提供的[简单例子](https://github.com/alibaba/dubbo/tree/master/dubbo-test/dubbo-test-examples/src/main/java/com/alibaba/dubbo/examples/cache)。\n\n按照SPI的要求，我们从配置文件中可以看到dubbo提供的三种缓存接口的入口：\n\n\tthreadlocal=com.alibaba.dubbo.cache.support.threadlocal.ThreadLocalCacheFactory\n\tlru=com.alibaba.dubbo.cache.support.lru.LruCacheFactory\n\tjcache=com.alibaba.dubbo.cache.support.jcache.JCacheFactory\n\n先来看一下dubbo提供的`AbstractCacheFactory`的细节：\n\n\tpublic abstract class AbstractCacheFactory implements CacheFactory {\n    \n\t    private final ConcurrentMap<String, Cache> caches = new ConcurrentHashMap<String, Cache>();\n\t\n\t    public Cache getCache(URL url) {\n\t        String key = url.toFullString();\n\t        Cache cache = caches.get(key);\n\t        if (cache == null) {\n\t            caches.put(key, createCache(url));\n\t            cache = caches.get(key);\n\t        }\n\t        return cache;\n\t    }\n\t\n\t    protected abstract Cache createCache(URL url);\n\t\n\t}\n\n很直观的看得出，该类完成了具体cache实现的实例化工作（注意`getCache`的返回类型Cache，该接口规范了不同缓存的实现），接下来我们就分三部分来具体看一下不同的缓存接口的具体实现。\n\n\n\n\nThreadLocal\n---\n\n如果你的配置如下：\n\t\n\t<dubbo:reference interface=\"com.foo.BarService\" cache=\"threadlocal\" />\n\n那就表明你使用的是该类型的缓存，根据SPI机制，会执行下面这个工厂类：\n\n\tpublic class ThreadLocalCacheFactory extends AbstractCacheFactory {\n\n\t    protected Cache createCache(URL url) {\n\t        return new ThreadLocalCache(url);\n\t    }\n\t}\n\n注意该类继承了上面提到的`AbstractCacheFactory`。可以看出，真正实例化的具体缓存层实现是`ThreadLocalCache`类型。由于此类型是基于线程本地变量的，所以非常简单：\n\n\tpublic class ThreadLocalCache implements Cache {\n\n\t    private final ThreadLocal<Map<Object, Object>> store;\n\t\n\t    public ThreadLocalCache(URL url) {\n\t        this.store = new ThreadLocal<Map<Object, Object>>() {\n\t            @Override\n\t            protected Map<Object, Object> initialValue() {\n\t                return new HashMap<Object, Object>();\n\t            }\n\t        };\n\t    }\n\t\n\t    public void put(Object key, Object value) {\n\t        store.get().put(key, value);\n\t    }\n\t\n\t    public Object get(Object key) {\n\t        return store.get().get(key);\n\t    }\n\t}\n\n这里注意的是，为了遵循接口定义才需要初始化时传入`url`参数，但其实该类型的缓存实现是完全不需要额外参数的。\n\n最后要叮嘱的是，该缓存应用场景为：\n\n> 比如一个页面渲染，用到很多portal，每个portal都要去查用户信息，通过线程缓存，可以减少这种多余访问。\n\n场景描述的核心内容是**当前请求的上下文**，可以结合dubbo的线程模型来更好的消化这一点。也许我们以后还会单独来分析这个主题。\n\n\n\n\nLRU\n---\n\n类似ThreadLocal，我们就不再重复列举对应的工厂方法了，直接看`LruCache`类的实现：\n\n\tpublic class LruCache implements Cache {\n\t    \n\t    private final Map<Object, Object> store;\n\t\n\t    public LruCache(URL url) {\n\t        final int max = url.getParameter(\"cache.size\", 1000);   //定义了缓存的容量\n\t        this.store = new LinkedHashMap<Object, Object>() {\n\t            private static final long serialVersionUID = -3834209229668463829L;\n\t            @Override\n\t            protected boolean removeEldestEntry(Entry<Object, Object> eldest) { //jdk提供的接口，用于移除最旧条目的需求\n\t                return size() > max;\n\t            }\n\t        };\n\t    }\n\t\n\t    public void put(Object key, Object value) {\n\t        synchronized (store) {  //注意这里的同步条件\n\t            store.put(key, value);\n\t        }\n\t    }\n\t\n\t    public Object get(Object key) {\n\t        synchronized (store) {  //注意这里的同步条件\n\t            return store.get(key);\n\t        }\n\t    }\n\t}\n\n相比ThreadLocal，可以看出，该类型的缓存是跨线程的，也匹配我们常见的缓存场景。\n\n\n\n\n\nJCache\n---\n\n对于我这种java新手，什么是JCache，显然需要科普一下，这里给出了我找到的几篇不错的文章：[官府](http://docs.oracle.com/middleware/1213/coherence/tutorial/jcache.htm#COHTU1006)，[草根](http://stackoverflow.com/questions/25506110/memcached-vs-memcache-vs-jcache)，[小栗子](http://java.dzone.com/articles/introduction-jcache-jsr-107)，[注解篇](https://spring.io/blog/2014/04/14/cache-abstraction-jcache-jsr-107-annotations-support)，[中文完美篇](http://jinnianshilongnian.iteye.com/blog/2001040)。由于内容太多，我就不胡乱翻译了~~\n\n由于这部分的代码太简单，节省篇幅就不列源码了。不过我们的项目缓存是基于redis的，而我并没有找到支持JCache的redis客户端，不知道大家有没有推荐的啊~？？\n\n\n\n\n如何解析“cache”属性\n---\n\n那么，cache层的逻辑是如何一步一步“注入”到我们的业务逻辑里呢？这还是要追溯到dubbo的[过滤器](http://blog.kazaff.me/2015/02/06/dubbo%E7%9A%84%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E7%9B%91%E5%90%AC%E5%99%A8/)上，我们知道在dubbo初始化指定protocol的时候，会使用装饰器模式把所有需要加载的过滤器封装到目标protocol上，这个细节指引我来查看`ProtocolFilterWrapper`类：\n\n\trefer() --->  buildInvokerChain（）\n\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\tV\n\n\tprivate static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {\n        Invoker<T> last = invoker;\n        List<Filter> filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);\n        if (filters.size() > 0) {\n            for (int i = filters.size() - 1; i >= 0; i --) {\n                final Filter filter = filters.get(i);\n                final Invoker<T> next = last;\n                last = new Invoker<T>() {\n\n                    public Class<T> getInterface() {\n                        return invoker.getInterface();\n                    }\n\n                    public URL getUrl() {\n                        return invoker.getUrl();\n                    }\n\n                    public boolean isAvailable() {\n                        return invoker.isAvailable();\n                    }\n\n                    public Result invoke(Invocation invocation) throws RpcException {\n                        return filter.invoke(next, invocation);\n                    }\n\n                    public void destroy() {\n                        invoker.destroy();\n                    }\n\n                    @Override\n                    public String toString() {\n                        return invoker.toString();\n                    }\n                };\n            }\n        }\n        return last;\n    }\n\n\n注意`ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);`这一行，单步调试可以得知它会返回所有需要“注入”的Filter逻辑，当然也包含我们关注的缓存：`com.alibaba.dubbo.cache.filter.CacheFilter`。\n\n注意看该类声明的开头：\n\n\t@Activate(group = {Constants.CONSUMER, Constants.PROVIDER}, value = Constants.CACHE_KEY)\n\n这一行是关键哟，上面提到的`getActivateExtension`方法就是靠这一行注解工作的。dubbo以这种设计风格完成了大多数的功能，所以对于研究dubbo源码的童鞋，一定要多多注意。\n\n经历了这一圈下来，所有过滤器就已经注入到我们的服务当中了。\n\n\n\n\n\n业务层如何使用cache\n---\n\n最后再来仔细看一下`com.alibaba.dubbo.cache.filter.CacheFilter`类的invoke方法：\n\n\tpublic Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {\n        if (cacheFactory != null && ConfigUtils.isNotEmpty(invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.CACHE_KEY))) {\n            Cache cache = cacheFactory.getCache(invoker.getUrl().addParameter(Constants.METHOD_KEY, invocation.getMethodName()));\n            if (cache != null) {\n                String key = StringUtils.toArgumentString(invocation.getArguments());\n                if (cache != null && key != null) {\n                    Object value = cache.get(key);\n                    if (value != null) {\n                        return new RpcResult(value);\n                    }\n                    Result result = invoker.invoke(invocation);\n                    if (! result.hasException()) {\n                        cache.put(key, result.getValue());\n                    }\n                    return result;\n                }\n            }\n        }\n        return invoker.invoke(invocation);\n    }\n\n可以看出，这里根据不同的配置会初始化并使用不同的缓存实现，好了，关于缓存的分析就到此为止。","source":"_posts/dubbo的缓存实现.md","raw":"title: dubbo的缓存分析\ndate: 2015-03-13 15:54:30\ntags:\n- cache\n- dubbox\n- dubbo\n- threadlocal\n- JCache\n- Filter\n\ncategories: j2ee\n---\n\n这次的目标是缓存，没错，绝壁常用的一个知识点，我们怎么能不了解一下它的内部实现源码呢？！\n<!-- more -->\n\ndubbo的官方描述很[简洁](http://alibaba.github.io/dubbo-doc-static/Result+Cache-zh.htm)，好的封装就是这么强大， 让你用起来丝毫不费力。我们今天就费力的看一下dubbo是如何提供cache功能的。有想直接使用的童鞋，就可以跳过下面内容直面看官方提供的[简单例子](https://github.com/alibaba/dubbo/tree/master/dubbo-test/dubbo-test-examples/src/main/java/com/alibaba/dubbo/examples/cache)。\n\n按照SPI的要求，我们从配置文件中可以看到dubbo提供的三种缓存接口的入口：\n\n\tthreadlocal=com.alibaba.dubbo.cache.support.threadlocal.ThreadLocalCacheFactory\n\tlru=com.alibaba.dubbo.cache.support.lru.LruCacheFactory\n\tjcache=com.alibaba.dubbo.cache.support.jcache.JCacheFactory\n\n先来看一下dubbo提供的`AbstractCacheFactory`的细节：\n\n\tpublic abstract class AbstractCacheFactory implements CacheFactory {\n    \n\t    private final ConcurrentMap<String, Cache> caches = new ConcurrentHashMap<String, Cache>();\n\t\n\t    public Cache getCache(URL url) {\n\t        String key = url.toFullString();\n\t        Cache cache = caches.get(key);\n\t        if (cache == null) {\n\t            caches.put(key, createCache(url));\n\t            cache = caches.get(key);\n\t        }\n\t        return cache;\n\t    }\n\t\n\t    protected abstract Cache createCache(URL url);\n\t\n\t}\n\n很直观的看得出，该类完成了具体cache实现的实例化工作（注意`getCache`的返回类型Cache，该接口规范了不同缓存的实现），接下来我们就分三部分来具体看一下不同的缓存接口的具体实现。\n\n\n\n\nThreadLocal\n---\n\n如果你的配置如下：\n\t\n\t<dubbo:reference interface=\"com.foo.BarService\" cache=\"threadlocal\" />\n\n那就表明你使用的是该类型的缓存，根据SPI机制，会执行下面这个工厂类：\n\n\tpublic class ThreadLocalCacheFactory extends AbstractCacheFactory {\n\n\t    protected Cache createCache(URL url) {\n\t        return new ThreadLocalCache(url);\n\t    }\n\t}\n\n注意该类继承了上面提到的`AbstractCacheFactory`。可以看出，真正实例化的具体缓存层实现是`ThreadLocalCache`类型。由于此类型是基于线程本地变量的，所以非常简单：\n\n\tpublic class ThreadLocalCache implements Cache {\n\n\t    private final ThreadLocal<Map<Object, Object>> store;\n\t\n\t    public ThreadLocalCache(URL url) {\n\t        this.store = new ThreadLocal<Map<Object, Object>>() {\n\t            @Override\n\t            protected Map<Object, Object> initialValue() {\n\t                return new HashMap<Object, Object>();\n\t            }\n\t        };\n\t    }\n\t\n\t    public void put(Object key, Object value) {\n\t        store.get().put(key, value);\n\t    }\n\t\n\t    public Object get(Object key) {\n\t        return store.get().get(key);\n\t    }\n\t}\n\n这里注意的是，为了遵循接口定义才需要初始化时传入`url`参数，但其实该类型的缓存实现是完全不需要额外参数的。\n\n最后要叮嘱的是，该缓存应用场景为：\n\n> 比如一个页面渲染，用到很多portal，每个portal都要去查用户信息，通过线程缓存，可以减少这种多余访问。\n\n场景描述的核心内容是**当前请求的上下文**，可以结合dubbo的线程模型来更好的消化这一点。也许我们以后还会单独来分析这个主题。\n\n\n\n\nLRU\n---\n\n类似ThreadLocal，我们就不再重复列举对应的工厂方法了，直接看`LruCache`类的实现：\n\n\tpublic class LruCache implements Cache {\n\t    \n\t    private final Map<Object, Object> store;\n\t\n\t    public LruCache(URL url) {\n\t        final int max = url.getParameter(\"cache.size\", 1000);   //定义了缓存的容量\n\t        this.store = new LinkedHashMap<Object, Object>() {\n\t            private static final long serialVersionUID = -3834209229668463829L;\n\t            @Override\n\t            protected boolean removeEldestEntry(Entry<Object, Object> eldest) { //jdk提供的接口，用于移除最旧条目的需求\n\t                return size() > max;\n\t            }\n\t        };\n\t    }\n\t\n\t    public void put(Object key, Object value) {\n\t        synchronized (store) {  //注意这里的同步条件\n\t            store.put(key, value);\n\t        }\n\t    }\n\t\n\t    public Object get(Object key) {\n\t        synchronized (store) {  //注意这里的同步条件\n\t            return store.get(key);\n\t        }\n\t    }\n\t}\n\n相比ThreadLocal，可以看出，该类型的缓存是跨线程的，也匹配我们常见的缓存场景。\n\n\n\n\n\nJCache\n---\n\n对于我这种java新手，什么是JCache，显然需要科普一下，这里给出了我找到的几篇不错的文章：[官府](http://docs.oracle.com/middleware/1213/coherence/tutorial/jcache.htm#COHTU1006)，[草根](http://stackoverflow.com/questions/25506110/memcached-vs-memcache-vs-jcache)，[小栗子](http://java.dzone.com/articles/introduction-jcache-jsr-107)，[注解篇](https://spring.io/blog/2014/04/14/cache-abstraction-jcache-jsr-107-annotations-support)，[中文完美篇](http://jinnianshilongnian.iteye.com/blog/2001040)。由于内容太多，我就不胡乱翻译了~~\n\n由于这部分的代码太简单，节省篇幅就不列源码了。不过我们的项目缓存是基于redis的，而我并没有找到支持JCache的redis客户端，不知道大家有没有推荐的啊~？？\n\n\n\n\n如何解析“cache”属性\n---\n\n那么，cache层的逻辑是如何一步一步“注入”到我们的业务逻辑里呢？这还是要追溯到dubbo的[过滤器](http://blog.kazaff.me/2015/02/06/dubbo%E7%9A%84%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E7%9B%91%E5%90%AC%E5%99%A8/)上，我们知道在dubbo初始化指定protocol的时候，会使用装饰器模式把所有需要加载的过滤器封装到目标protocol上，这个细节指引我来查看`ProtocolFilterWrapper`类：\n\n\trefer() --->  buildInvokerChain（）\n\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\tV\n\n\tprivate static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {\n        Invoker<T> last = invoker;\n        List<Filter> filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);\n        if (filters.size() > 0) {\n            for (int i = filters.size() - 1; i >= 0; i --) {\n                final Filter filter = filters.get(i);\n                final Invoker<T> next = last;\n                last = new Invoker<T>() {\n\n                    public Class<T> getInterface() {\n                        return invoker.getInterface();\n                    }\n\n                    public URL getUrl() {\n                        return invoker.getUrl();\n                    }\n\n                    public boolean isAvailable() {\n                        return invoker.isAvailable();\n                    }\n\n                    public Result invoke(Invocation invocation) throws RpcException {\n                        return filter.invoke(next, invocation);\n                    }\n\n                    public void destroy() {\n                        invoker.destroy();\n                    }\n\n                    @Override\n                    public String toString() {\n                        return invoker.toString();\n                    }\n                };\n            }\n        }\n        return last;\n    }\n\n\n注意`ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);`这一行，单步调试可以得知它会返回所有需要“注入”的Filter逻辑，当然也包含我们关注的缓存：`com.alibaba.dubbo.cache.filter.CacheFilter`。\n\n注意看该类声明的开头：\n\n\t@Activate(group = {Constants.CONSUMER, Constants.PROVIDER}, value = Constants.CACHE_KEY)\n\n这一行是关键哟，上面提到的`getActivateExtension`方法就是靠这一行注解工作的。dubbo以这种设计风格完成了大多数的功能，所以对于研究dubbo源码的童鞋，一定要多多注意。\n\n经历了这一圈下来，所有过滤器就已经注入到我们的服务当中了。\n\n\n\n\n\n业务层如何使用cache\n---\n\n最后再来仔细看一下`com.alibaba.dubbo.cache.filter.CacheFilter`类的invoke方法：\n\n\tpublic Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {\n        if (cacheFactory != null && ConfigUtils.isNotEmpty(invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.CACHE_KEY))) {\n            Cache cache = cacheFactory.getCache(invoker.getUrl().addParameter(Constants.METHOD_KEY, invocation.getMethodName()));\n            if (cache != null) {\n                String key = StringUtils.toArgumentString(invocation.getArguments());\n                if (cache != null && key != null) {\n                    Object value = cache.get(key);\n                    if (value != null) {\n                        return new RpcResult(value);\n                    }\n                    Result result = invoker.invoke(invocation);\n                    if (! result.hasException()) {\n                        cache.put(key, result.getValue());\n                    }\n                    return result;\n                }\n            }\n        }\n        return invoker.invoke(invocation);\n    }\n\n可以看出，这里根据不同的配置会初始化并使用不同的缓存实现，好了，关于缓存的分析就到此为止。","slug":"dubbo的缓存实现","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yq9009lgtfy9qk1ndw0","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这次的目标是缓存，没错，绝壁常用的一个知识点，我们怎么能不了解一下它的内部实现源码呢？！<br><a id=\"more\"></a></p>\n<p>dubbo的官方描述很<a href=\"http://alibaba.github.io/dubbo-doc-static/Result+Cache-zh.htm\" target=\"_blank\" rel=\"external\">简洁</a>，好的封装就是这么强大， 让你用起来丝毫不费力。我们今天就费力的看一下dubbo是如何提供cache功能的。有想直接使用的童鞋，就可以跳过下面内容直面看官方提供的<a href=\"https://github.com/alibaba/dubbo/tree/master/dubbo-test/dubbo-test-examples/src/main/java/com/alibaba/dubbo/examples/cache\" target=\"_blank\" rel=\"external\">简单例子</a>。</p>\n<p>按照SPI的要求，我们从配置文件中可以看到dubbo提供的三种缓存接口的入口：</p>\n<pre><code>threadlocal=com.alibaba.dubbo.cache.support.threadlocal.ThreadLocalCacheFactory\nlru=com.alibaba.dubbo.cache.support.lru.LruCacheFactory\njcache=com.alibaba.dubbo.cache.support.jcache.JCacheFactory\n</code></pre><p>先来看一下dubbo提供的<code>AbstractCacheFactory</code>的细节：</p>\n<pre><code>public abstract class AbstractCacheFactory implements CacheFactory {\n\n    private final ConcurrentMap&lt;String, Cache&gt; caches = new ConcurrentHashMap&lt;String, Cache&gt;();\n\n    public Cache getCache(URL url) {\n        String key = url.toFullString();\n        Cache cache = caches.get(key);\n        if (cache == null) {\n            caches.put(key, createCache(url));\n            cache = caches.get(key);\n        }\n        return cache;\n    }\n\n    protected abstract Cache createCache(URL url);\n\n}\n</code></pre><p>很直观的看得出，该类完成了具体cache实现的实例化工作（注意<code>getCache</code>的返回类型Cache，该接口规范了不同缓存的实现），接下来我们就分三部分来具体看一下不同的缓存接口的具体实现。</p>\n<h2 id=\"ThreadLocal\"><a href=\"#ThreadLocal\" class=\"headerlink\" title=\"ThreadLocal\"></a>ThreadLocal</h2><p>如果你的配置如下：</p>\n<pre><code>&lt;dubbo:reference interface=&quot;com.foo.BarService&quot; cache=&quot;threadlocal&quot; /&gt;\n</code></pre><p>那就表明你使用的是该类型的缓存，根据SPI机制，会执行下面这个工厂类：</p>\n<pre><code>public class ThreadLocalCacheFactory extends AbstractCacheFactory {\n\n    protected Cache createCache(URL url) {\n        return new ThreadLocalCache(url);\n    }\n}\n</code></pre><p>注意该类继承了上面提到的<code>AbstractCacheFactory</code>。可以看出，真正实例化的具体缓存层实现是<code>ThreadLocalCache</code>类型。由于此类型是基于线程本地变量的，所以非常简单：</p>\n<pre><code>public class ThreadLocalCache implements Cache {\n\n    private final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; store;\n\n    public ThreadLocalCache(URL url) {\n        this.store = new ThreadLocal&lt;Map&lt;Object, Object&gt;&gt;() {\n            @Override\n            protected Map&lt;Object, Object&gt; initialValue() {\n                return new HashMap&lt;Object, Object&gt;();\n            }\n        };\n    }\n\n    public void put(Object key, Object value) {\n        store.get().put(key, value);\n    }\n\n    public Object get(Object key) {\n        return store.get().get(key);\n    }\n}\n</code></pre><p>这里注意的是，为了遵循接口定义才需要初始化时传入<code>url</code>参数，但其实该类型的缓存实现是完全不需要额外参数的。</p>\n<p>最后要叮嘱的是，该缓存应用场景为：</p>\n<blockquote>\n<p>比如一个页面渲染，用到很多portal，每个portal都要去查用户信息，通过线程缓存，可以减少这种多余访问。</p>\n</blockquote>\n<p>场景描述的核心内容是<strong>当前请求的上下文</strong>，可以结合dubbo的线程模型来更好的消化这一点。也许我们以后还会单独来分析这个主题。</p>\n<h2 id=\"LRU\"><a href=\"#LRU\" class=\"headerlink\" title=\"LRU\"></a>LRU</h2><p>类似ThreadLocal，我们就不再重复列举对应的工厂方法了，直接看<code>LruCache</code>类的实现：</p>\n<pre><code>public class LruCache implements Cache {\n\n    private final Map&lt;Object, Object&gt; store;\n\n    public LruCache(URL url) {\n        final int max = url.getParameter(&quot;cache.size&quot;, 1000);   //定义了缓存的容量\n        this.store = new LinkedHashMap&lt;Object, Object&gt;() {\n            private static final long serialVersionUID = -3834209229668463829L;\n            @Override\n            protected boolean removeEldestEntry(Entry&lt;Object, Object&gt; eldest) { //jdk提供的接口，用于移除最旧条目的需求\n                return size() &gt; max;\n            }\n        };\n    }\n\n    public void put(Object key, Object value) {\n        synchronized (store) {  //注意这里的同步条件\n            store.put(key, value);\n        }\n    }\n\n    public Object get(Object key) {\n        synchronized (store) {  //注意这里的同步条件\n            return store.get(key);\n        }\n    }\n}\n</code></pre><p>相比ThreadLocal，可以看出，该类型的缓存是跨线程的，也匹配我们常见的缓存场景。</p>\n<h2 id=\"JCache\"><a href=\"#JCache\" class=\"headerlink\" title=\"JCache\"></a>JCache</h2><p>对于我这种java新手，什么是JCache，显然需要科普一下，这里给出了我找到的几篇不错的文章：<a href=\"http://docs.oracle.com/middleware/1213/coherence/tutorial/jcache.htm#COHTU1006\" target=\"_blank\" rel=\"external\">官府</a>，<a href=\"http://stackoverflow.com/questions/25506110/memcached-vs-memcache-vs-jcache\" target=\"_blank\" rel=\"external\">草根</a>，<a href=\"http://java.dzone.com/articles/introduction-jcache-jsr-107\" target=\"_blank\" rel=\"external\">小栗子</a>，<a href=\"https://spring.io/blog/2014/04/14/cache-abstraction-jcache-jsr-107-annotations-support\" target=\"_blank\" rel=\"external\">注解篇</a>，<a href=\"http://jinnianshilongnian.iteye.com/blog/2001040\" target=\"_blank\" rel=\"external\">中文完美篇</a>。由于内容太多，我就不胡乱翻译了~~</p>\n<p>由于这部分的代码太简单，节省篇幅就不列源码了。不过我们的项目缓存是基于redis的，而我并没有找到支持JCache的redis客户端，不知道大家有没有推荐的啊~？？</p>\n<h2 id=\"如何解析“cache”属性\"><a href=\"#如何解析“cache”属性\" class=\"headerlink\" title=\"如何解析“cache”属性\"></a>如何解析“cache”属性</h2><p>那么，cache层的逻辑是如何一步一步“注入”到我们的业务逻辑里呢？这还是要追溯到dubbo的<a href=\"http://blog.kazaff.me/2015/02/06/dubbo%E7%9A%84%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E7%9B%91%E5%90%AC%E5%99%A8/\">过滤器</a>上，我们知道在dubbo初始化指定protocol的时候，会使用装饰器模式把所有需要加载的过滤器封装到目标protocol上，这个细节指引我来查看<code>ProtocolFilterWrapper</code>类：</p>\n<pre><code>refer() ---&gt;  buildInvokerChain（）\n                        |\n                        V\n\nprivate static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) {\n    Invoker&lt;T&gt; last = invoker;\n    List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);\n    if (filters.size() &gt; 0) {\n        for (int i = filters.size() - 1; i &gt;= 0; i --) {\n            final Filter filter = filters.get(i);\n            final Invoker&lt;T&gt; next = last;\n            last = new Invoker&lt;T&gt;() {\n\n                public Class&lt;T&gt; getInterface() {\n                    return invoker.getInterface();\n                }\n\n                public URL getUrl() {\n                    return invoker.getUrl();\n                }\n\n                public boolean isAvailable() {\n                    return invoker.isAvailable();\n                }\n\n                public Result invoke(Invocation invocation) throws RpcException {\n                    return filter.invoke(next, invocation);\n                }\n\n                public void destroy() {\n                    invoker.destroy();\n                }\n\n                @Override\n                public String toString() {\n                    return invoker.toString();\n                }\n            };\n        }\n    }\n    return last;\n}\n</code></pre><p>注意<code>ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);</code>这一行，单步调试可以得知它会返回所有需要“注入”的Filter逻辑，当然也包含我们关注的缓存：<code>com.alibaba.dubbo.cache.filter.CacheFilter</code>。</p>\n<p>注意看该类声明的开头：</p>\n<pre><code>@Activate(group = {Constants.CONSUMER, Constants.PROVIDER}, value = Constants.CACHE_KEY)\n</code></pre><p>这一行是关键哟，上面提到的<code>getActivateExtension</code>方法就是靠这一行注解工作的。dubbo以这种设计风格完成了大多数的功能，所以对于研究dubbo源码的童鞋，一定要多多注意。</p>\n<p>经历了这一圈下来，所有过滤器就已经注入到我们的服务当中了。</p>\n<h2 id=\"业务层如何使用cache\"><a href=\"#业务层如何使用cache\" class=\"headerlink\" title=\"业务层如何使用cache\"></a>业务层如何使用cache</h2><p>最后再来仔细看一下<code>com.alibaba.dubbo.cache.filter.CacheFilter</code>类的invoke方法：</p>\n<pre><code>public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException {\n    if (cacheFactory != null &amp;&amp; ConfigUtils.isNotEmpty(invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.CACHE_KEY))) {\n        Cache cache = cacheFactory.getCache(invoker.getUrl().addParameter(Constants.METHOD_KEY, invocation.getMethodName()));\n        if (cache != null) {\n            String key = StringUtils.toArgumentString(invocation.getArguments());\n            if (cache != null &amp;&amp; key != null) {\n                Object value = cache.get(key);\n                if (value != null) {\n                    return new RpcResult(value);\n                }\n                Result result = invoker.invoke(invocation);\n                if (! result.hasException()) {\n                    cache.put(key, result.getValue());\n                }\n                return result;\n            }\n        }\n    }\n    return invoker.invoke(invocation);\n}\n</code></pre><p>可以看出，这里根据不同的配置会初始化并使用不同的缓存实现，好了，关于缓存的分析就到此为止。</p>\n","excerpt":"<p>这次的目标是缓存，没错，绝壁常用的一个知识点，我们怎么能不了解一下它的内部实现源码呢？！<br>","more":"</p>\n<p>dubbo的官方描述很<a href=\"http://alibaba.github.io/dubbo-doc-static/Result+Cache-zh.htm\">简洁</a>，好的封装就是这么强大， 让你用起来丝毫不费力。我们今天就费力的看一下dubbo是如何提供cache功能的。有想直接使用的童鞋，就可以跳过下面内容直面看官方提供的<a href=\"https://github.com/alibaba/dubbo/tree/master/dubbo-test/dubbo-test-examples/src/main/java/com/alibaba/dubbo/examples/cache\">简单例子</a>。</p>\n<p>按照SPI的要求，我们从配置文件中可以看到dubbo提供的三种缓存接口的入口：</p>\n<pre><code>threadlocal=com.alibaba.dubbo.cache.support.threadlocal.ThreadLocalCacheFactory\nlru=com.alibaba.dubbo.cache.support.lru.LruCacheFactory\njcache=com.alibaba.dubbo.cache.support.jcache.JCacheFactory\n</code></pre><p>先来看一下dubbo提供的<code>AbstractCacheFactory</code>的细节：</p>\n<pre><code>public abstract class AbstractCacheFactory implements CacheFactory {\n\n    private final ConcurrentMap&lt;String, Cache&gt; caches = new ConcurrentHashMap&lt;String, Cache&gt;();\n\n    public Cache getCache(URL url) {\n        String key = url.toFullString();\n        Cache cache = caches.get(key);\n        if (cache == null) {\n            caches.put(key, createCache(url));\n            cache = caches.get(key);\n        }\n        return cache;\n    }\n\n    protected abstract Cache createCache(URL url);\n\n}\n</code></pre><p>很直观的看得出，该类完成了具体cache实现的实例化工作（注意<code>getCache</code>的返回类型Cache，该接口规范了不同缓存的实现），接下来我们就分三部分来具体看一下不同的缓存接口的具体实现。</p>\n<h2 id=\"ThreadLocal\"><a href=\"#ThreadLocal\" class=\"headerlink\" title=\"ThreadLocal\"></a>ThreadLocal</h2><p>如果你的配置如下：</p>\n<pre><code>&lt;dubbo:reference interface=&quot;com.foo.BarService&quot; cache=&quot;threadlocal&quot; /&gt;\n</code></pre><p>那就表明你使用的是该类型的缓存，根据SPI机制，会执行下面这个工厂类：</p>\n<pre><code>public class ThreadLocalCacheFactory extends AbstractCacheFactory {\n\n    protected Cache createCache(URL url) {\n        return new ThreadLocalCache(url);\n    }\n}\n</code></pre><p>注意该类继承了上面提到的<code>AbstractCacheFactory</code>。可以看出，真正实例化的具体缓存层实现是<code>ThreadLocalCache</code>类型。由于此类型是基于线程本地变量的，所以非常简单：</p>\n<pre><code>public class ThreadLocalCache implements Cache {\n\n    private final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; store;\n\n    public ThreadLocalCache(URL url) {\n        this.store = new ThreadLocal&lt;Map&lt;Object, Object&gt;&gt;() {\n            @Override\n            protected Map&lt;Object, Object&gt; initialValue() {\n                return new HashMap&lt;Object, Object&gt;();\n            }\n        };\n    }\n\n    public void put(Object key, Object value) {\n        store.get().put(key, value);\n    }\n\n    public Object get(Object key) {\n        return store.get().get(key);\n    }\n}\n</code></pre><p>这里注意的是，为了遵循接口定义才需要初始化时传入<code>url</code>参数，但其实该类型的缓存实现是完全不需要额外参数的。</p>\n<p>最后要叮嘱的是，该缓存应用场景为：</p>\n<blockquote>\n<p>比如一个页面渲染，用到很多portal，每个portal都要去查用户信息，通过线程缓存，可以减少这种多余访问。</p>\n</blockquote>\n<p>场景描述的核心内容是<strong>当前请求的上下文</strong>，可以结合dubbo的线程模型来更好的消化这一点。也许我们以后还会单独来分析这个主题。</p>\n<h2 id=\"LRU\"><a href=\"#LRU\" class=\"headerlink\" title=\"LRU\"></a>LRU</h2><p>类似ThreadLocal，我们就不再重复列举对应的工厂方法了，直接看<code>LruCache</code>类的实现：</p>\n<pre><code>public class LruCache implements Cache {\n\n    private final Map&lt;Object, Object&gt; store;\n\n    public LruCache(URL url) {\n        final int max = url.getParameter(&quot;cache.size&quot;, 1000);   //定义了缓存的容量\n        this.store = new LinkedHashMap&lt;Object, Object&gt;() {\n            private static final long serialVersionUID = -3834209229668463829L;\n            @Override\n            protected boolean removeEldestEntry(Entry&lt;Object, Object&gt; eldest) { //jdk提供的接口，用于移除最旧条目的需求\n                return size() &gt; max;\n            }\n        };\n    }\n\n    public void put(Object key, Object value) {\n        synchronized (store) {  //注意这里的同步条件\n            store.put(key, value);\n        }\n    }\n\n    public Object get(Object key) {\n        synchronized (store) {  //注意这里的同步条件\n            return store.get(key);\n        }\n    }\n}\n</code></pre><p>相比ThreadLocal，可以看出，该类型的缓存是跨线程的，也匹配我们常见的缓存场景。</p>\n<h2 id=\"JCache\"><a href=\"#JCache\" class=\"headerlink\" title=\"JCache\"></a>JCache</h2><p>对于我这种java新手，什么是JCache，显然需要科普一下，这里给出了我找到的几篇不错的文章：<a href=\"http://docs.oracle.com/middleware/1213/coherence/tutorial/jcache.htm#COHTU1006\">官府</a>，<a href=\"http://stackoverflow.com/questions/25506110/memcached-vs-memcache-vs-jcache\">草根</a>，<a href=\"http://java.dzone.com/articles/introduction-jcache-jsr-107\">小栗子</a>，<a href=\"https://spring.io/blog/2014/04/14/cache-abstraction-jcache-jsr-107-annotations-support\">注解篇</a>，<a href=\"http://jinnianshilongnian.iteye.com/blog/2001040\">中文完美篇</a>。由于内容太多，我就不胡乱翻译了~~</p>\n<p>由于这部分的代码太简单，节省篇幅就不列源码了。不过我们的项目缓存是基于redis的，而我并没有找到支持JCache的redis客户端，不知道大家有没有推荐的啊~？？</p>\n<h2 id=\"如何解析“cache”属性\"><a href=\"#如何解析“cache”属性\" class=\"headerlink\" title=\"如何解析“cache”属性\"></a>如何解析“cache”属性</h2><p>那么，cache层的逻辑是如何一步一步“注入”到我们的业务逻辑里呢？这还是要追溯到dubbo的<a href=\"http://blog.kazaff.me/2015/02/06/dubbo%E7%9A%84%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E7%9B%91%E5%90%AC%E5%99%A8/\">过滤器</a>上，我们知道在dubbo初始化指定protocol的时候，会使用装饰器模式把所有需要加载的过滤器封装到目标protocol上，这个细节指引我来查看<code>ProtocolFilterWrapper</code>类：</p>\n<pre><code>refer() ---&gt;  buildInvokerChain（）\n                        |\n                        V\n\nprivate static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) {\n    Invoker&lt;T&gt; last = invoker;\n    List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);\n    if (filters.size() &gt; 0) {\n        for (int i = filters.size() - 1; i &gt;= 0; i --) {\n            final Filter filter = filters.get(i);\n            final Invoker&lt;T&gt; next = last;\n            last = new Invoker&lt;T&gt;() {\n\n                public Class&lt;T&gt; getInterface() {\n                    return invoker.getInterface();\n                }\n\n                public URL getUrl() {\n                    return invoker.getUrl();\n                }\n\n                public boolean isAvailable() {\n                    return invoker.isAvailable();\n                }\n\n                public Result invoke(Invocation invocation) throws RpcException {\n                    return filter.invoke(next, invocation);\n                }\n\n                public void destroy() {\n                    invoker.destroy();\n                }\n\n                @Override\n                public String toString() {\n                    return invoker.toString();\n                }\n            };\n        }\n    }\n    return last;\n}\n</code></pre><p>注意<code>ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);</code>这一行，单步调试可以得知它会返回所有需要“注入”的Filter逻辑，当然也包含我们关注的缓存：<code>com.alibaba.dubbo.cache.filter.CacheFilter</code>。</p>\n<p>注意看该类声明的开头：</p>\n<pre><code>@Activate(group = {Constants.CONSUMER, Constants.PROVIDER}, value = Constants.CACHE_KEY)\n</code></pre><p>这一行是关键哟，上面提到的<code>getActivateExtension</code>方法就是靠这一行注解工作的。dubbo以这种设计风格完成了大多数的功能，所以对于研究dubbo源码的童鞋，一定要多多注意。</p>\n<p>经历了这一圈下来，所有过滤器就已经注入到我们的服务当中了。</p>\n<h2 id=\"业务层如何使用cache\"><a href=\"#业务层如何使用cache\" class=\"headerlink\" title=\"业务层如何使用cache\"></a>业务层如何使用cache</h2><p>最后再来仔细看一下<code>com.alibaba.dubbo.cache.filter.CacheFilter</code>类的invoke方法：</p>\n<pre><code>public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException {\n    if (cacheFactory != null &amp;&amp; ConfigUtils.isNotEmpty(invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.CACHE_KEY))) {\n        Cache cache = cacheFactory.getCache(invoker.getUrl().addParameter(Constants.METHOD_KEY, invocation.getMethodName()));\n        if (cache != null) {\n            String key = StringUtils.toArgumentString(invocation.getArguments());\n            if (cache != null &amp;&amp; key != null) {\n                Object value = cache.get(key);\n                if (value != null) {\n                    return new RpcResult(value);\n                }\n                Result result = invoker.invoke(invocation);\n                if (! result.hasException()) {\n                    cache.put(key, result.getValue());\n                }\n                return result;\n            }\n        }\n    }\n    return invoker.invoke(invocation);\n}\n</code></pre><p>可以看出，这里根据不同的配置会初始化并使用不同的缓存实现，好了，关于缓存的分析就到此为止。</p>"},{"title":"dubbo的服务治理细节","date":"2015-02-02T07:54:30.000Z","_content":"\n\n如果说单单只完成远程调用的话，dubbo还算不上是一个合格的SOA服务架构，而它之所以那么碉堡，是因为它还提供了服务治理的功能，今天就让我们来研究一下关于服务治理，dubbo都做了什么。\n<!-- more -->\n听起来服务治理挺高大上的，但其实做的都是一些非常琐碎的事儿，了解了dubbo的做法，你就会发觉其实一切并没有想的那么复杂。远程调用要解决的最本质的问题是通信，通信就好像人和人之间的互动，有效的沟通建立在双方彼此了解的基础上（我们团队在沟通上就有死穴），同样道理，服务提供方和消费方之间要相互了解对方的基本情况，才能做到更好的完成远程调用。这里面就要提到dubbo的做法：**URL**。\n\n前几篇中大量提到dubbo的分层之间是依靠什么纽带工作的：invoker，没错，比invoker更low的就是URL，这是dubbo带给我的另一个非常重要的经验。才疏学浅，并不知道dubbo是借鉴的哪里，但影响了全世界的WEB就是依赖URL机制建立了互联网帝国的！\n\n依赖URL机制，dubbo不仅打通了通信两端，而且还靠URL机制完成了服务治理的任务。我们可以先看一下这些内容：\n\n- [路由规则](http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm)\n- [配置规则](http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm)\n- [服务降级](http://alibaba.github.io/dubbo-doc-static/Service+Degradation-zh.htm)\n- [负载均衡](http://alibaba.github.io/dubbo-doc-static/Load+Balance-zh.htm)\n\n其实dubbo的路由和集群是在服务暴露，服务发现，服务引用中透明完成的，暴露给其他层的是同一个接口类型：Invoker。[dubbo官方](http://alibaba.github.io/dubbo-doc-static/Fault+Tolerance-zh.htm)提供了一张巨清晰无比的图：\n\n![](http://pic.yupoo.com/kazaff/EopVm33y/Rzbmx.jpg)\n\n这张图是站在服务消费方的视角来看的（**dubbo的服务治理都是针对服务消费方的**），当业务逻辑中需要调用一个服务时，你真正调用的其实是dubbo创建的一个proxy，该proxy会把调用转化成调用指定的invoker（cluster封装过的）。而在这一系列的委托调用的过程里就完成了服务治理的逻辑，最终完成调用。\n\n\n\n集群\n---\n\n当相同服务由多个提供方同时提供时，消费方就需要有个选择的步骤，就好比你去电商平台买一本书，你自然会看一下哪儿买的最便宜。同样，消费方也需要根据需求选择到底使用哪个提供方的服务，而集群的主要作用就是从**容错**的维度来帮我们选择合适的服务提供方。\n\n我们需要从`Protocol`接口的部分定义开始：\n\n\t\n\t/**\n     * 引用远程服务：<br>\n     * 1. 当用户调用refer()所返回的Invoker对象的invoke()方法时，协议需相应执行同URL远端export()传入的Invoker对象的invoke()方法。<br>\n     * 2. refer()返回的Invoker由协议实现，协议通常需要在此Invoker中发送远程请求。<br>\n     * 3. 当url中有设置check=false时，连接失败不能抛出异常，并内部自动恢复。<br>\n     * \n     * @param <T> 服务的类型\n     * @param type 服务的类型\n     * @param url 远程服务的URL地址\n     * @return invoker 服务的本地代理\n     * @throws RpcException 当连接服务提供方失败时抛出\n     */\n    @Adaptive\n    <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException;\n\n注意这个方法的返回值，根据我们这一系列文章一直使用的场景（有注册中心），看一下`RegistryProtocol.doRefer`方法的最后一行：\n\n\treturn cluster.join(directory);\n\n之前的文章提到过这个`directory`，它在后面我们会再次提到，这里你只需要知道它不是我们需要的invoker类型，那么这个`cluster`对象又是什么呢？根据dubbo的SPI机制，我们知道，这里的cluster是动态创建的自适应扩展点：\n\n\tpackage com.alibaba.dubbo.rpc.cluster;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\t\n\tpublic class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster {\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory {\n\t\t\t\n\t\t\tif (arg0 == null)\n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.cluster.Directory argument == null\");\n\t\t\n\t\t\tif (arg0.getUrl() == null)\n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = url.getParameter(\"cluster\", \"failover\");\t//默认使用failover实现\n\t\t\n\t\t\tif(extName == null)\n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(\" + url.toString() + \") use keys([cluster])\");\n\t\t\n\t\t\tcom.alibaba.dubbo.rpc.cluster.Cluster extension = (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName);\n\t\t\n\t\t\treturn extension.join(arg0);\n\t\t}\n\t}\n\n我们再来看一下默认使用的`FailoverCluster`定义：\n\n\t/**\n\t * 失败转移，当出现失败，重试其它服务器，通常用于读操作，但重试会带来更长延迟。 \n\t * \n\t * <a href=\"http://en.wikipedia.org/wiki/Failover\">Failover</a>\n\t * \n\t * @author william.liangf\n\t */\n\tpublic class FailoverCluster implements Cluster {\n\t\n\t    public final static String NAME = \"failover\";\n\t\n\t    public <T> Invoker<T> join(Directory<T> directory) throws RpcException {\n\t        return new FailoverClusterInvoker<T>(directory);\n\t    }\n\t}\n\n\n看到了吗，这就是一开始图上的所表明的，**cluster把存有多个invoker的directory对象封装成了单个的invoker**。我们在来看一下`FailoverClusterInvoker`类的UML图：\n\n![](http://pic.yupoo.com/kazaff/EpluFFDn/KIoh9.png)\n\n根据官方文档的说明，dubbo提供了多种集群容错方案供我们直接使用，至于各种集群容错模式算法可以交给大家自己阅读源码来消化了，后面只会以`FailoverClusterInvoker`为基准来讨论。\n\n\n\n\n路由和配置\n---\n\n如果说集群帮我们以容错的维度来完成选择，那么路由和配置是在更细颗粒度的层面做的选择，具体有多细，可以从官方文档和dubbo-admin管理后台来了解，如下多图：\n\n![](http://pic.yupoo.com/kazaff/EplGoQvX/HGn7S.png)\n\n![](http://pic.yupoo.com/kazaff/EplGpS9R/s9XJ2.png)\n\n![](http://pic.yupoo.com/kazaff/EplGqBu7/wFdrA.png)\n\n![](http://pic.yupoo.com/kazaff/EplH3FBD/n5KTo.png)\n\n![](http://pic.yupoo.com/kazaff/EplGCTY9/BtehS.png)\n\n总之很细吧，这么多配置参数最终都会交给谁来管理呢？\n\n\n我们需要从`Directory`接口出发，你应该想到了该接口的一个实现类：\n\n![](http://pic.yupoo.com/kazaff/Epl1KPlv/RI5VI.png)\n\n没错，就是这个`RegistryDirectory`，它在服务引用时被创建，用于充当url与多invoer的代理（或者叫目录类更合适），从源码可以看出，当服务引用时，对应该服务的目录类实例会负责向注册中心（zookeeper）订阅该服务，第一次订阅会同步拿到当前服务节点的详细信息（也就是所有提供服务的提供方信息，包括：地址，配置，路由等），然后该目录实例会根据这些信息来为后续的服务调用提供支撑。\n\n根据描述我们可以锁定代码位置，`RegistryDirectory.notify`：\n\n\t......\n\t// configurators 更新缓存的服务提供方动态配置规则\n    if (configuratorUrls != null && configuratorUrls.size() >0 ){\n        this.configurators = toConfigurators(configuratorUrls);\n    }\n    // routers  更新缓存的路由配置规则\n    if (routerUrls != null && routerUrls.size() >0 ){\n        List<Router> routers = toRouters(routerUrls);\n        if(routers != null){ // null - do nothing\n            setRouters(routers);\n        }\n    }\n\t......\n\n这些配置在什么时候发挥作用呢？往下看~\n\n前面说到当调用invoker时，其实调用的是集群模块封装过的代理invoker，那么以我们的场景为例，最终会被调用的是`FailoverClusterInvoker.invoke`：\n\n\tpublic Result invoke(final Invocation invocation) throws RpcException {\n\n        checkWheatherDestoried();\n\n        LoadBalance loadbalance;\n\n\t\t//这里就是路由，配置等发挥作用地方，返回所有合法的invoker供集群做下一步的筛选        \n        List<Invoker<T>> invokers = list(invocation);\n\n        if (invokers != null && invokers.size() > 0) {\n            loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n                    .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n        } else {\n            loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n        }\n        RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n        return doInvoke(invocation, invokers, loadbalance);\n    }\n\n再来看一下这个`list`方法的定义：\n\n\tprotected  List<Invoker<T>> list(Invocation invocation) throws RpcException {\n    \tList<Invoker<T>> invokers = directory.list(invocation);\n    \treturn invokers;\n    }\n\n很直接的把选择合法invoker的工作交给了我们的目录类实例，再来看一下directory是怎么list的：\n\n\tpublic List<Invoker<T>> list(Invocation invocation) throws RpcException {\n        if (destroyed){\n            throw new RpcException(\"Directory already destroyed .url: \"+ getUrl());\n        }\n\n        //根据请求服务的相关参数（方法名等）返回对应的invoker列表\n        List<Invoker<T>> invokers = doList(invocation);\n\n        List<Router> localRouters = this.routers; // local reference\n        if (localRouters != null && localRouters.size() > 0) {\n            for (Router router: localRouters){\n                try {\n                    //是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。\n                    //如果用了参数路由，必须设为true，需要注意设置会影响调用的性能，可不填，缺省为flase。\n                    if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) {\n                        invokers = router.route(invokers, getConsumerUrl(), invocation);\n                    }\n                } catch (Throwable t) {\n                    logger.error(\"Failed to execute router: \" + getUrl() + \", cause: \" + t.getMessage(), t);\n                }\n            }\n        }\n\n        return invokers;\n    }\n\n到这里我们就已经把路由和配置的相关流程介绍完了，至于路由和配置的具体参数是如何发挥效果的，这个大家可以结合文档提供的实例直接阅读源码即可。\n\n\n\n\n负载均衡\n---\n\n到了负载均衡环节，维度就成了**性能**，这个词你可以从gg里搜索大量的相关文献，我就不在这里卖弄了。把焦点拉回到`FailoverClusterInvoker.invoke`方法：\n\n\t......\n\tif (invokers != null && invokers.size() > 0) {\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n                .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n    } else {\t\n\t\t//todo 如果invokers为空，还有必要往下走么？\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n    }\n\n    RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n\n    return doInvoke(invocation, invokers, loadbalance);\n\t......\n\n\n可以看到，这里就创建了要使用的负载均衡算法，我们接下来看一下到底是怎么使用这个`loadbalance`对象的，一路跟踪到`AbstractClusterInvoker.doselect`方法：\n\n\t......\n\tInvoker<T> invoker = loadbalance.select(invokers, getUrl(), invocation);\n\t......\n\n（其实本人并不喜欢这样截取部分代码展示，因为会让读者很窘迫，不过请相信我，这里这么做可以很好的排除干扰。）可见，最终是依靠负载均衡这最后一道关卡我们总算拿到了要调用的invoker。我们依然不去过多在意算法细节，到目前为止，负载均衡的流程也介绍完了。\n\n\n\n---\n\n其实dubbo服务治理相关的内容还有很多，官方文档也提供了详细的[说明](http://alibaba.github.io/dubbo-doc-static/User+Guide-zh.htm#UserGuide-zh-%E7%A4%BA%E4%BE%8B)，希望大家都能成为dubbo大牛，bye~","source":"_posts/dubbo的服务治理细节.md","raw":"title: dubbo的服务治理细节\ndate: 2015-02-02 15:54:30\ntags:\n- dubbo\n- dubbox\n- soa\n- 负载均衡\n- 路由\n- 集群\n\ncategories: j2ee\n---\n\n\n如果说单单只完成远程调用的话，dubbo还算不上是一个合格的SOA服务架构，而它之所以那么碉堡，是因为它还提供了服务治理的功能，今天就让我们来研究一下关于服务治理，dubbo都做了什么。\n<!-- more -->\n听起来服务治理挺高大上的，但其实做的都是一些非常琐碎的事儿，了解了dubbo的做法，你就会发觉其实一切并没有想的那么复杂。远程调用要解决的最本质的问题是通信，通信就好像人和人之间的互动，有效的沟通建立在双方彼此了解的基础上（我们团队在沟通上就有死穴），同样道理，服务提供方和消费方之间要相互了解对方的基本情况，才能做到更好的完成远程调用。这里面就要提到dubbo的做法：**URL**。\n\n前几篇中大量提到dubbo的分层之间是依靠什么纽带工作的：invoker，没错，比invoker更low的就是URL，这是dubbo带给我的另一个非常重要的经验。才疏学浅，并不知道dubbo是借鉴的哪里，但影响了全世界的WEB就是依赖URL机制建立了互联网帝国的！\n\n依赖URL机制，dubbo不仅打通了通信两端，而且还靠URL机制完成了服务治理的任务。我们可以先看一下这些内容：\n\n- [路由规则](http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm)\n- [配置规则](http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm)\n- [服务降级](http://alibaba.github.io/dubbo-doc-static/Service+Degradation-zh.htm)\n- [负载均衡](http://alibaba.github.io/dubbo-doc-static/Load+Balance-zh.htm)\n\n其实dubbo的路由和集群是在服务暴露，服务发现，服务引用中透明完成的，暴露给其他层的是同一个接口类型：Invoker。[dubbo官方](http://alibaba.github.io/dubbo-doc-static/Fault+Tolerance-zh.htm)提供了一张巨清晰无比的图：\n\n![](http://pic.yupoo.com/kazaff/EopVm33y/Rzbmx.jpg)\n\n这张图是站在服务消费方的视角来看的（**dubbo的服务治理都是针对服务消费方的**），当业务逻辑中需要调用一个服务时，你真正调用的其实是dubbo创建的一个proxy，该proxy会把调用转化成调用指定的invoker（cluster封装过的）。而在这一系列的委托调用的过程里就完成了服务治理的逻辑，最终完成调用。\n\n\n\n集群\n---\n\n当相同服务由多个提供方同时提供时，消费方就需要有个选择的步骤，就好比你去电商平台买一本书，你自然会看一下哪儿买的最便宜。同样，消费方也需要根据需求选择到底使用哪个提供方的服务，而集群的主要作用就是从**容错**的维度来帮我们选择合适的服务提供方。\n\n我们需要从`Protocol`接口的部分定义开始：\n\n\t\n\t/**\n     * 引用远程服务：<br>\n     * 1. 当用户调用refer()所返回的Invoker对象的invoke()方法时，协议需相应执行同URL远端export()传入的Invoker对象的invoke()方法。<br>\n     * 2. refer()返回的Invoker由协议实现，协议通常需要在此Invoker中发送远程请求。<br>\n     * 3. 当url中有设置check=false时，连接失败不能抛出异常，并内部自动恢复。<br>\n     * \n     * @param <T> 服务的类型\n     * @param type 服务的类型\n     * @param url 远程服务的URL地址\n     * @return invoker 服务的本地代理\n     * @throws RpcException 当连接服务提供方失败时抛出\n     */\n    @Adaptive\n    <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException;\n\n注意这个方法的返回值，根据我们这一系列文章一直使用的场景（有注册中心），看一下`RegistryProtocol.doRefer`方法的最后一行：\n\n\treturn cluster.join(directory);\n\n之前的文章提到过这个`directory`，它在后面我们会再次提到，这里你只需要知道它不是我们需要的invoker类型，那么这个`cluster`对象又是什么呢？根据dubbo的SPI机制，我们知道，这里的cluster是动态创建的自适应扩展点：\n\n\tpackage com.alibaba.dubbo.rpc.cluster;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\t\n\tpublic class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster {\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory {\n\t\t\t\n\t\t\tif (arg0 == null)\n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.cluster.Directory argument == null\");\n\t\t\n\t\t\tif (arg0.getUrl() == null)\n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = url.getParameter(\"cluster\", \"failover\");\t//默认使用failover实现\n\t\t\n\t\t\tif(extName == null)\n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(\" + url.toString() + \") use keys([cluster])\");\n\t\t\n\t\t\tcom.alibaba.dubbo.rpc.cluster.Cluster extension = (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName);\n\t\t\n\t\t\treturn extension.join(arg0);\n\t\t}\n\t}\n\n我们再来看一下默认使用的`FailoverCluster`定义：\n\n\t/**\n\t * 失败转移，当出现失败，重试其它服务器，通常用于读操作，但重试会带来更长延迟。 \n\t * \n\t * <a href=\"http://en.wikipedia.org/wiki/Failover\">Failover</a>\n\t * \n\t * @author william.liangf\n\t */\n\tpublic class FailoverCluster implements Cluster {\n\t\n\t    public final static String NAME = \"failover\";\n\t\n\t    public <T> Invoker<T> join(Directory<T> directory) throws RpcException {\n\t        return new FailoverClusterInvoker<T>(directory);\n\t    }\n\t}\n\n\n看到了吗，这就是一开始图上的所表明的，**cluster把存有多个invoker的directory对象封装成了单个的invoker**。我们在来看一下`FailoverClusterInvoker`类的UML图：\n\n![](http://pic.yupoo.com/kazaff/EpluFFDn/KIoh9.png)\n\n根据官方文档的说明，dubbo提供了多种集群容错方案供我们直接使用，至于各种集群容错模式算法可以交给大家自己阅读源码来消化了，后面只会以`FailoverClusterInvoker`为基准来讨论。\n\n\n\n\n路由和配置\n---\n\n如果说集群帮我们以容错的维度来完成选择，那么路由和配置是在更细颗粒度的层面做的选择，具体有多细，可以从官方文档和dubbo-admin管理后台来了解，如下多图：\n\n![](http://pic.yupoo.com/kazaff/EplGoQvX/HGn7S.png)\n\n![](http://pic.yupoo.com/kazaff/EplGpS9R/s9XJ2.png)\n\n![](http://pic.yupoo.com/kazaff/EplGqBu7/wFdrA.png)\n\n![](http://pic.yupoo.com/kazaff/EplH3FBD/n5KTo.png)\n\n![](http://pic.yupoo.com/kazaff/EplGCTY9/BtehS.png)\n\n总之很细吧，这么多配置参数最终都会交给谁来管理呢？\n\n\n我们需要从`Directory`接口出发，你应该想到了该接口的一个实现类：\n\n![](http://pic.yupoo.com/kazaff/Epl1KPlv/RI5VI.png)\n\n没错，就是这个`RegistryDirectory`，它在服务引用时被创建，用于充当url与多invoer的代理（或者叫目录类更合适），从源码可以看出，当服务引用时，对应该服务的目录类实例会负责向注册中心（zookeeper）订阅该服务，第一次订阅会同步拿到当前服务节点的详细信息（也就是所有提供服务的提供方信息，包括：地址，配置，路由等），然后该目录实例会根据这些信息来为后续的服务调用提供支撑。\n\n根据描述我们可以锁定代码位置，`RegistryDirectory.notify`：\n\n\t......\n\t// configurators 更新缓存的服务提供方动态配置规则\n    if (configuratorUrls != null && configuratorUrls.size() >0 ){\n        this.configurators = toConfigurators(configuratorUrls);\n    }\n    // routers  更新缓存的路由配置规则\n    if (routerUrls != null && routerUrls.size() >0 ){\n        List<Router> routers = toRouters(routerUrls);\n        if(routers != null){ // null - do nothing\n            setRouters(routers);\n        }\n    }\n\t......\n\n这些配置在什么时候发挥作用呢？往下看~\n\n前面说到当调用invoker时，其实调用的是集群模块封装过的代理invoker，那么以我们的场景为例，最终会被调用的是`FailoverClusterInvoker.invoke`：\n\n\tpublic Result invoke(final Invocation invocation) throws RpcException {\n\n        checkWheatherDestoried();\n\n        LoadBalance loadbalance;\n\n\t\t//这里就是路由，配置等发挥作用地方，返回所有合法的invoker供集群做下一步的筛选        \n        List<Invoker<T>> invokers = list(invocation);\n\n        if (invokers != null && invokers.size() > 0) {\n            loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n                    .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n        } else {\n            loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n        }\n        RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n        return doInvoke(invocation, invokers, loadbalance);\n    }\n\n再来看一下这个`list`方法的定义：\n\n\tprotected  List<Invoker<T>> list(Invocation invocation) throws RpcException {\n    \tList<Invoker<T>> invokers = directory.list(invocation);\n    \treturn invokers;\n    }\n\n很直接的把选择合法invoker的工作交给了我们的目录类实例，再来看一下directory是怎么list的：\n\n\tpublic List<Invoker<T>> list(Invocation invocation) throws RpcException {\n        if (destroyed){\n            throw new RpcException(\"Directory already destroyed .url: \"+ getUrl());\n        }\n\n        //根据请求服务的相关参数（方法名等）返回对应的invoker列表\n        List<Invoker<T>> invokers = doList(invocation);\n\n        List<Router> localRouters = this.routers; // local reference\n        if (localRouters != null && localRouters.size() > 0) {\n            for (Router router: localRouters){\n                try {\n                    //是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。\n                    //如果用了参数路由，必须设为true，需要注意设置会影响调用的性能，可不填，缺省为flase。\n                    if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) {\n                        invokers = router.route(invokers, getConsumerUrl(), invocation);\n                    }\n                } catch (Throwable t) {\n                    logger.error(\"Failed to execute router: \" + getUrl() + \", cause: \" + t.getMessage(), t);\n                }\n            }\n        }\n\n        return invokers;\n    }\n\n到这里我们就已经把路由和配置的相关流程介绍完了，至于路由和配置的具体参数是如何发挥效果的，这个大家可以结合文档提供的实例直接阅读源码即可。\n\n\n\n\n负载均衡\n---\n\n到了负载均衡环节，维度就成了**性能**，这个词你可以从gg里搜索大量的相关文献，我就不在这里卖弄了。把焦点拉回到`FailoverClusterInvoker.invoke`方法：\n\n\t......\n\tif (invokers != null && invokers.size() > 0) {\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n                .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n    } else {\t\n\t\t//todo 如果invokers为空，还有必要往下走么？\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n    }\n\n    RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n\n    return doInvoke(invocation, invokers, loadbalance);\n\t......\n\n\n可以看到，这里就创建了要使用的负载均衡算法，我们接下来看一下到底是怎么使用这个`loadbalance`对象的，一路跟踪到`AbstractClusterInvoker.doselect`方法：\n\n\t......\n\tInvoker<T> invoker = loadbalance.select(invokers, getUrl(), invocation);\n\t......\n\n（其实本人并不喜欢这样截取部分代码展示，因为会让读者很窘迫，不过请相信我，这里这么做可以很好的排除干扰。）可见，最终是依靠负载均衡这最后一道关卡我们总算拿到了要调用的invoker。我们依然不去过多在意算法细节，到目前为止，负载均衡的流程也介绍完了。\n\n\n\n---\n\n其实dubbo服务治理相关的内容还有很多，官方文档也提供了详细的[说明](http://alibaba.github.io/dubbo-doc-static/User+Guide-zh.htm#UserGuide-zh-%E7%A4%BA%E4%BE%8B)，希望大家都能成为dubbo大牛，bye~","slug":"dubbo的服务治理细节","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yqf009xgtfy1k3w6i66","comments":1,"layout":"post","photos":[],"link":"","content":"<p>如果说单单只完成远程调用的话，dubbo还算不上是一个合格的SOA服务架构，而它之所以那么碉堡，是因为它还提供了服务治理的功能，今天就让我们来研究一下关于服务治理，dubbo都做了什么。<br><a id=\"more\"></a><br>听起来服务治理挺高大上的，但其实做的都是一些非常琐碎的事儿，了解了dubbo的做法，你就会发觉其实一切并没有想的那么复杂。远程调用要解决的最本质的问题是通信，通信就好像人和人之间的互动，有效的沟通建立在双方彼此了解的基础上（我们团队在沟通上就有死穴），同样道理，服务提供方和消费方之间要相互了解对方的基本情况，才能做到更好的完成远程调用。这里面就要提到dubbo的做法：<strong>URL</strong>。</p>\n<p>前几篇中大量提到dubbo的分层之间是依靠什么纽带工作的：invoker，没错，比invoker更low的就是URL，这是dubbo带给我的另一个非常重要的经验。才疏学浅，并不知道dubbo是借鉴的哪里，但影响了全世界的WEB就是依赖URL机制建立了互联网帝国的！</p>\n<p>依赖URL机制，dubbo不仅打通了通信两端，而且还靠URL机制完成了服务治理的任务。我们可以先看一下这些内容：</p>\n<ul>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm\" target=\"_blank\" rel=\"external\">路由规则</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm\" target=\"_blank\" rel=\"external\">配置规则</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Service+Degradation-zh.htm\" target=\"_blank\" rel=\"external\">服务降级</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Load+Balance-zh.htm\" target=\"_blank\" rel=\"external\">负载均衡</a></li>\n</ul>\n<p>其实dubbo的路由和集群是在服务暴露，服务发现，服务引用中透明完成的，暴露给其他层的是同一个接口类型：Invoker。<a href=\"http://alibaba.github.io/dubbo-doc-static/Fault+Tolerance-zh.htm\" target=\"_blank\" rel=\"external\">dubbo官方</a>提供了一张巨清晰无比的图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EopVm33y/Rzbmx.jpg\" alt=\"\"></p>\n<p>这张图是站在服务消费方的视角来看的（<strong>dubbo的服务治理都是针对服务消费方的</strong>），当业务逻辑中需要调用一个服务时，你真正调用的其实是dubbo创建的一个proxy，该proxy会把调用转化成调用指定的invoker（cluster封装过的）。而在这一系列的委托调用的过程里就完成了服务治理的逻辑，最终完成调用。</p>\n<h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><p>当相同服务由多个提供方同时提供时，消费方就需要有个选择的步骤，就好比你去电商平台买一本书，你自然会看一下哪儿买的最便宜。同样，消费方也需要根据需求选择到底使用哪个提供方的服务，而集群的主要作用就是从<strong>容错</strong>的维度来帮我们选择合适的服务提供方。</p>\n<p>我们需要从<code>Protocol</code>接口的部分定义开始：</p>\n<pre><code>/**\n * 引用远程服务：&lt;br&gt;\n * 1. 当用户调用refer()所返回的Invoker对象的invoke()方法时，协议需相应执行同URL远端export()传入的Invoker对象的invoke()方法。&lt;br&gt;\n * 2. refer()返回的Invoker由协议实现，协议通常需要在此Invoker中发送远程请求。&lt;br&gt;\n * 3. 当url中有设置check=false时，连接失败不能抛出异常，并内部自动恢复。&lt;br&gt;\n * \n * @param &lt;T&gt; 服务的类型\n * @param type 服务的类型\n * @param url 远程服务的URL地址\n * @return invoker 服务的本地代理\n * @throws RpcException 当连接服务提供方失败时抛出\n */\n@Adaptive\n&lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException;\n</code></pre><p>注意这个方法的返回值，根据我们这一系列文章一直使用的场景（有注册中心），看一下<code>RegistryProtocol.doRefer</code>方法的最后一行：</p>\n<pre><code>return cluster.join(directory);\n</code></pre><p>之前的文章提到过这个<code>directory</code>，它在后面我们会再次提到，这里你只需要知道它不是我们需要的invoker类型，那么这个<code>cluster</code>对象又是什么呢？根据dubbo的SPI机制，我们知道，这里的cluster是动态创建的自适应扩展点：</p>\n<pre><code>package com.alibaba.dubbo.rpc.cluster;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster {\n\n    public com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory {\n\n        if (arg0 == null)\n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument == null&quot;);\n\n        if (arg0.getUrl() == null)\n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = url.getParameter(&quot;cluster&quot;, &quot;failover&quot;);    //默认使用failover实现\n\n        if(extName == null)\n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(&quot; + url.toString() + &quot;) use keys([cluster])&quot;);\n\n        com.alibaba.dubbo.rpc.cluster.Cluster extension = (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName);\n\n        return extension.join(arg0);\n    }\n}\n</code></pre><p>我们再来看一下默认使用的<code>FailoverCluster</code>定义：</p>\n<pre><code>/**\n * 失败转移，当出现失败，重试其它服务器，通常用于读操作，但重试会带来更长延迟。 \n * \n * &lt;a href=&quot;http://en.wikipedia.org/wiki/Failover&quot;&gt;Failover&lt;/a&gt;\n * \n * @author william.liangf\n */\npublic class FailoverCluster implements Cluster {\n\n    public final static String NAME = &quot;failover&quot;;\n\n    public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException {\n        return new FailoverClusterInvoker&lt;T&gt;(directory);\n    }\n}\n</code></pre><p>看到了吗，这就是一开始图上的所表明的，<strong>cluster把存有多个invoker的directory对象封装成了单个的invoker</strong>。我们在来看一下<code>FailoverClusterInvoker</code>类的UML图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EpluFFDn/KIoh9.png\" alt=\"\"></p>\n<p>根据官方文档的说明，dubbo提供了多种集群容错方案供我们直接使用，至于各种集群容错模式算法可以交给大家自己阅读源码来消化了，后面只会以<code>FailoverClusterInvoker</code>为基准来讨论。</p>\n<h2 id=\"路由和配置\"><a href=\"#路由和配置\" class=\"headerlink\" title=\"路由和配置\"></a>路由和配置</h2><p>如果说集群帮我们以容错的维度来完成选择，那么路由和配置是在更细颗粒度的层面做的选择，具体有多细，可以从官方文档和dubbo-admin管理后台来了解，如下多图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGoQvX/HGn7S.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGpS9R/s9XJ2.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGqBu7/wFdrA.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplH3FBD/n5KTo.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGCTY9/BtehS.png\" alt=\"\"></p>\n<p>总之很细吧，这么多配置参数最终都会交给谁来管理呢？</p>\n<p>我们需要从<code>Directory</code>接口出发，你应该想到了该接口的一个实现类：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Epl1KPlv/RI5VI.png\" alt=\"\"></p>\n<p>没错，就是这个<code>RegistryDirectory</code>，它在服务引用时被创建，用于充当url与多invoer的代理（或者叫目录类更合适），从源码可以看出，当服务引用时，对应该服务的目录类实例会负责向注册中心（zookeeper）订阅该服务，第一次订阅会同步拿到当前服务节点的详细信息（也就是所有提供服务的提供方信息，包括：地址，配置，路由等），然后该目录实例会根据这些信息来为后续的服务调用提供支撑。</p>\n<p>根据描述我们可以锁定代码位置，<code>RegistryDirectory.notify</code>：</p>\n<pre><code>......\n// configurators 更新缓存的服务提供方动态配置规则\nif (configuratorUrls != null &amp;&amp; configuratorUrls.size() &gt;0 ){\n    this.configurators = toConfigurators(configuratorUrls);\n}\n// routers  更新缓存的路由配置规则\nif (routerUrls != null &amp;&amp; routerUrls.size() &gt;0 ){\n    List&lt;Router&gt; routers = toRouters(routerUrls);\n    if(routers != null){ // null - do nothing\n        setRouters(routers);\n    }\n}\n......\n</code></pre><p>这些配置在什么时候发挥作用呢？往下看~</p>\n<p>前面说到当调用invoker时，其实调用的是集群模块封装过的代理invoker，那么以我们的场景为例，最终会被调用的是<code>FailoverClusterInvoker.invoke</code>：</p>\n<pre><code>public Result invoke(final Invocation invocation) throws RpcException {\n\n    checkWheatherDestoried();\n\n    LoadBalance loadbalance;\n\n    //这里就是路由，配置等发挥作用地方，返回所有合法的invoker供集群做下一步的筛选        \n    List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation);\n\n    if (invokers != null &amp;&amp; invokers.size() &gt; 0) {\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n                .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n    } else {\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n    }\n    RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n    return doInvoke(invocation, invokers, loadbalance);\n}\n</code></pre><p>再来看一下这个<code>list</code>方法的定义：</p>\n<pre><code>protected  List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException {\n    List&lt;Invoker&lt;T&gt;&gt; invokers = directory.list(invocation);\n    return invokers;\n}\n</code></pre><p>很直接的把选择合法invoker的工作交给了我们的目录类实例，再来看一下directory是怎么list的：</p>\n<pre><code>public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException {\n    if (destroyed){\n        throw new RpcException(&quot;Directory already destroyed .url: &quot;+ getUrl());\n    }\n\n    //根据请求服务的相关参数（方法名等）返回对应的invoker列表\n    List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation);\n\n    List&lt;Router&gt; localRouters = this.routers; // local reference\n    if (localRouters != null &amp;&amp; localRouters.size() &gt; 0) {\n        for (Router router: localRouters){\n            try {\n                //是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。\n                //如果用了参数路由，必须设为true，需要注意设置会影响调用的性能，可不填，缺省为flase。\n                if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) {\n                    invokers = router.route(invokers, getConsumerUrl(), invocation);\n                }\n            } catch (Throwable t) {\n                logger.error(&quot;Failed to execute router: &quot; + getUrl() + &quot;, cause: &quot; + t.getMessage(), t);\n            }\n        }\n    }\n\n    return invokers;\n}\n</code></pre><p>到这里我们就已经把路由和配置的相关流程介绍完了，至于路由和配置的具体参数是如何发挥效果的，这个大家可以结合文档提供的实例直接阅读源码即可。</p>\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><p>到了负载均衡环节，维度就成了<strong>性能</strong>，这个词你可以从gg里搜索大量的相关文献，我就不在这里卖弄了。把焦点拉回到<code>FailoverClusterInvoker.invoke</code>方法：</p>\n<pre><code>......\nif (invokers != null &amp;&amp; invokers.size() &gt; 0) {\n    loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n            .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n} else {    \n    //todo 如果invokers为空，还有必要往下走么？\n    loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n}\n\nRpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n\nreturn doInvoke(invocation, invokers, loadbalance);\n......\n</code></pre><p>可以看到，这里就创建了要使用的负载均衡算法，我们接下来看一下到底是怎么使用这个<code>loadbalance</code>对象的，一路跟踪到<code>AbstractClusterInvoker.doselect</code>方法：</p>\n<pre><code>......\nInvoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation);\n......\n</code></pre><p>（其实本人并不喜欢这样截取部分代码展示，因为会让读者很窘迫，不过请相信我，这里这么做可以很好的排除干扰。）可见，最终是依靠负载均衡这最后一道关卡我们总算拿到了要调用的invoker。我们依然不去过多在意算法细节，到目前为止，负载均衡的流程也介绍完了。</p>\n<hr>\n<p>其实dubbo服务治理相关的内容还有很多，官方文档也提供了详细的<a href=\"http://alibaba.github.io/dubbo-doc-static/User+Guide-zh.htm#UserGuide-zh-%E7%A4%BA%E4%BE%8B\" target=\"_blank\" rel=\"external\">说明</a>，希望大家都能成为dubbo大牛，bye~</p>\n","excerpt":"<p>如果说单单只完成远程调用的话，dubbo还算不上是一个合格的SOA服务架构，而它之所以那么碉堡，是因为它还提供了服务治理的功能，今天就让我们来研究一下关于服务治理，dubbo都做了什么。<br>","more":"<br>听起来服务治理挺高大上的，但其实做的都是一些非常琐碎的事儿，了解了dubbo的做法，你就会发觉其实一切并没有想的那么复杂。远程调用要解决的最本质的问题是通信，通信就好像人和人之间的互动，有效的沟通建立在双方彼此了解的基础上（我们团队在沟通上就有死穴），同样道理，服务提供方和消费方之间要相互了解对方的基本情况，才能做到更好的完成远程调用。这里面就要提到dubbo的做法：<strong>URL</strong>。</p>\n<p>前几篇中大量提到dubbo的分层之间是依靠什么纽带工作的：invoker，没错，比invoker更low的就是URL，这是dubbo带给我的另一个非常重要的经验。才疏学浅，并不知道dubbo是借鉴的哪里，但影响了全世界的WEB就是依赖URL机制建立了互联网帝国的！</p>\n<p>依赖URL机制，dubbo不仅打通了通信两端，而且还靠URL机制完成了服务治理的任务。我们可以先看一下这些内容：</p>\n<ul>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm\">路由规则</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm\">配置规则</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Service+Degradation-zh.htm\">服务降级</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Load+Balance-zh.htm\">负载均衡</a></li>\n</ul>\n<p>其实dubbo的路由和集群是在服务暴露，服务发现，服务引用中透明完成的，暴露给其他层的是同一个接口类型：Invoker。<a href=\"http://alibaba.github.io/dubbo-doc-static/Fault+Tolerance-zh.htm\">dubbo官方</a>提供了一张巨清晰无比的图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EopVm33y/Rzbmx.jpg\" alt=\"\"></p>\n<p>这张图是站在服务消费方的视角来看的（<strong>dubbo的服务治理都是针对服务消费方的</strong>），当业务逻辑中需要调用一个服务时，你真正调用的其实是dubbo创建的一个proxy，该proxy会把调用转化成调用指定的invoker（cluster封装过的）。而在这一系列的委托调用的过程里就完成了服务治理的逻辑，最终完成调用。</p>\n<h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><p>当相同服务由多个提供方同时提供时，消费方就需要有个选择的步骤，就好比你去电商平台买一本书，你自然会看一下哪儿买的最便宜。同样，消费方也需要根据需求选择到底使用哪个提供方的服务，而集群的主要作用就是从<strong>容错</strong>的维度来帮我们选择合适的服务提供方。</p>\n<p>我们需要从<code>Protocol</code>接口的部分定义开始：</p>\n<pre><code>/**\n * 引用远程服务：&lt;br&gt;\n * 1. 当用户调用refer()所返回的Invoker对象的invoke()方法时，协议需相应执行同URL远端export()传入的Invoker对象的invoke()方法。&lt;br&gt;\n * 2. refer()返回的Invoker由协议实现，协议通常需要在此Invoker中发送远程请求。&lt;br&gt;\n * 3. 当url中有设置check=false时，连接失败不能抛出异常，并内部自动恢复。&lt;br&gt;\n * \n * @param &lt;T&gt; 服务的类型\n * @param type 服务的类型\n * @param url 远程服务的URL地址\n * @return invoker 服务的本地代理\n * @throws RpcException 当连接服务提供方失败时抛出\n */\n@Adaptive\n&lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException;\n</code></pre><p>注意这个方法的返回值，根据我们这一系列文章一直使用的场景（有注册中心），看一下<code>RegistryProtocol.doRefer</code>方法的最后一行：</p>\n<pre><code>return cluster.join(directory);\n</code></pre><p>之前的文章提到过这个<code>directory</code>，它在后面我们会再次提到，这里你只需要知道它不是我们需要的invoker类型，那么这个<code>cluster</code>对象又是什么呢？根据dubbo的SPI机制，我们知道，这里的cluster是动态创建的自适应扩展点：</p>\n<pre><code>package com.alibaba.dubbo.rpc.cluster;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster {\n\n    public com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory {\n\n        if (arg0 == null)\n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument == null&quot;);\n\n        if (arg0.getUrl() == null)\n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = url.getParameter(&quot;cluster&quot;, &quot;failover&quot;);    //默认使用failover实现\n\n        if(extName == null)\n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(&quot; + url.toString() + &quot;) use keys([cluster])&quot;);\n\n        com.alibaba.dubbo.rpc.cluster.Cluster extension = (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName);\n\n        return extension.join(arg0);\n    }\n}\n</code></pre><p>我们再来看一下默认使用的<code>FailoverCluster</code>定义：</p>\n<pre><code>/**\n * 失败转移，当出现失败，重试其它服务器，通常用于读操作，但重试会带来更长延迟。 \n * \n * &lt;a href=&quot;http://en.wikipedia.org/wiki/Failover&quot;&gt;Failover&lt;/a&gt;\n * \n * @author william.liangf\n */\npublic class FailoverCluster implements Cluster {\n\n    public final static String NAME = &quot;failover&quot;;\n\n    public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException {\n        return new FailoverClusterInvoker&lt;T&gt;(directory);\n    }\n}\n</code></pre><p>看到了吗，这就是一开始图上的所表明的，<strong>cluster把存有多个invoker的directory对象封装成了单个的invoker</strong>。我们在来看一下<code>FailoverClusterInvoker</code>类的UML图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EpluFFDn/KIoh9.png\" alt=\"\"></p>\n<p>根据官方文档的说明，dubbo提供了多种集群容错方案供我们直接使用，至于各种集群容错模式算法可以交给大家自己阅读源码来消化了，后面只会以<code>FailoverClusterInvoker</code>为基准来讨论。</p>\n<h2 id=\"路由和配置\"><a href=\"#路由和配置\" class=\"headerlink\" title=\"路由和配置\"></a>路由和配置</h2><p>如果说集群帮我们以容错的维度来完成选择，那么路由和配置是在更细颗粒度的层面做的选择，具体有多细，可以从官方文档和dubbo-admin管理后台来了解，如下多图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGoQvX/HGn7S.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGpS9R/s9XJ2.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGqBu7/wFdrA.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplH3FBD/n5KTo.png\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EplGCTY9/BtehS.png\" alt=\"\"></p>\n<p>总之很细吧，这么多配置参数最终都会交给谁来管理呢？</p>\n<p>我们需要从<code>Directory</code>接口出发，你应该想到了该接口的一个实现类：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Epl1KPlv/RI5VI.png\" alt=\"\"></p>\n<p>没错，就是这个<code>RegistryDirectory</code>，它在服务引用时被创建，用于充当url与多invoer的代理（或者叫目录类更合适），从源码可以看出，当服务引用时，对应该服务的目录类实例会负责向注册中心（zookeeper）订阅该服务，第一次订阅会同步拿到当前服务节点的详细信息（也就是所有提供服务的提供方信息，包括：地址，配置，路由等），然后该目录实例会根据这些信息来为后续的服务调用提供支撑。</p>\n<p>根据描述我们可以锁定代码位置，<code>RegistryDirectory.notify</code>：</p>\n<pre><code>......\n// configurators 更新缓存的服务提供方动态配置规则\nif (configuratorUrls != null &amp;&amp; configuratorUrls.size() &gt;0 ){\n    this.configurators = toConfigurators(configuratorUrls);\n}\n// routers  更新缓存的路由配置规则\nif (routerUrls != null &amp;&amp; routerUrls.size() &gt;0 ){\n    List&lt;Router&gt; routers = toRouters(routerUrls);\n    if(routers != null){ // null - do nothing\n        setRouters(routers);\n    }\n}\n......\n</code></pre><p>这些配置在什么时候发挥作用呢？往下看~</p>\n<p>前面说到当调用invoker时，其实调用的是集群模块封装过的代理invoker，那么以我们的场景为例，最终会被调用的是<code>FailoverClusterInvoker.invoke</code>：</p>\n<pre><code>public Result invoke(final Invocation invocation) throws RpcException {\n\n    checkWheatherDestoried();\n\n    LoadBalance loadbalance;\n\n    //这里就是路由，配置等发挥作用地方，返回所有合法的invoker供集群做下一步的筛选        \n    List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation);\n\n    if (invokers != null &amp;&amp; invokers.size() &gt; 0) {\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n                .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n    } else {\n        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n    }\n    RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n    return doInvoke(invocation, invokers, loadbalance);\n}\n</code></pre><p>再来看一下这个<code>list</code>方法的定义：</p>\n<pre><code>protected  List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException {\n    List&lt;Invoker&lt;T&gt;&gt; invokers = directory.list(invocation);\n    return invokers;\n}\n</code></pre><p>很直接的把选择合法invoker的工作交给了我们的目录类实例，再来看一下directory是怎么list的：</p>\n<pre><code>public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException {\n    if (destroyed){\n        throw new RpcException(&quot;Directory already destroyed .url: &quot;+ getUrl());\n    }\n\n    //根据请求服务的相关参数（方法名等）返回对应的invoker列表\n    List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation);\n\n    List&lt;Router&gt; localRouters = this.routers; // local reference\n    if (localRouters != null &amp;&amp; localRouters.size() &gt; 0) {\n        for (Router router: localRouters){\n            try {\n                //是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。\n                //如果用了参数路由，必须设为true，需要注意设置会影响调用的性能，可不填，缺省为flase。\n                if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) {\n                    invokers = router.route(invokers, getConsumerUrl(), invocation);\n                }\n            } catch (Throwable t) {\n                logger.error(&quot;Failed to execute router: &quot; + getUrl() + &quot;, cause: &quot; + t.getMessage(), t);\n            }\n        }\n    }\n\n    return invokers;\n}\n</code></pre><p>到这里我们就已经把路由和配置的相关流程介绍完了，至于路由和配置的具体参数是如何发挥效果的，这个大家可以结合文档提供的实例直接阅读源码即可。</p>\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><p>到了负载均衡环节，维度就成了<strong>性能</strong>，这个词你可以从gg里搜索大量的相关文献，我就不在这里卖弄了。把焦点拉回到<code>FailoverClusterInvoker.invoke</code>方法：</p>\n<pre><code>......\nif (invokers != null &amp;&amp; invokers.size() &gt; 0) {\n    loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl()\n            .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE));\n} else {    \n    //todo 如果invokers为空，还有必要往下走么？\n    loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE);\n}\n\nRpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);\n\nreturn doInvoke(invocation, invokers, loadbalance);\n......\n</code></pre><p>可以看到，这里就创建了要使用的负载均衡算法，我们接下来看一下到底是怎么使用这个<code>loadbalance</code>对象的，一路跟踪到<code>AbstractClusterInvoker.doselect</code>方法：</p>\n<pre><code>......\nInvoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation);\n......\n</code></pre><p>（其实本人并不喜欢这样截取部分代码展示，因为会让读者很窘迫，不过请相信我，这里这么做可以很好的排除干扰。）可见，最终是依靠负载均衡这最后一道关卡我们总算拿到了要调用的invoker。我们依然不去过多在意算法细节，到目前为止，负载均衡的流程也介绍完了。</p>\n<hr>\n<p>其实dubbo服务治理相关的内容还有很多，官方文档也提供了详细的<a href=\"http://alibaba.github.io/dubbo-doc-static/User+Guide-zh.htm#UserGuide-zh-%E7%A4%BA%E4%BE%8B\">说明</a>，希望大家都能成为dubbo大牛，bye~</p>"},{"title":"dubbo的服务发现细节","date":"2015-01-31T07:54:30.000Z","_content":"\n\n对于分布式服务架构，解决服务的发现问题，引入了注册中心中间件，从而很好的解决了服务双方（消费方和提供方）的直接依赖问题。这种解耦的意义是非凡的，不仅在程序运行时保证了灵活性，在开发阶段也使得快速迭代成为了可能，甚至在运维层面也提供了非常好的自由度。\n<!-- more -->\n夸了这么多，但要实现一个完美的注册中心系统却不是一件那么容易的事儿，你必须时刻注意关注它的可用性（包括**稳定，实时和高效**），这一点在任何一款分布式系统中都是件很复杂的事儿。当然这篇文章并不是打算摆平这么个庞然大物，我们只是从dubbo和zookeeper之间的关系来了解一下在dubbo架构中注册中心的相关知识：\n\n![](http://pic.yupoo.com/kazaff/EogBsej0/gvnAo.jpg)\n\n上图是官方给出的一张描述服务提供方、服务消费方和注册中心的关系图，其实dubbo提供多种注册中心实现，不过常用的就是zookeeper，我们也就拿它来当例子来分析。从图中可见，**消费方远程调用服务方是不通过注册中心的**，这有效的降低了注册中心的负载，也不会存在明显的单点瓶颈（尽管可以搭建注册中心的集群，但每次调用都走注册中心的话肯定对性能产生较大的伤害）。\n\n官方提供的规则是：\n\n- 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小；\n- 注册中心，服务提供者，服务消费者三者之间均为长连接；\n- 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者；\n- 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者；\n- 注册中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表；\n- 注册中心是可选的，服务消费者可以直连服务提供者；\n- 注册中心对等集群，任意一台宕掉后，将自动切换到另一台。\n\n好啦，更多的理论我就不转载了，官方已经描述的非常详细了，我们按照老套路，从代码级别看一下dubbo到底是怎样实现的。\n\n\n\nregister\n---\n\n我们需要承接之前的[文章](http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/)里的例子，从拿到需要暴露成服务的url开始：\n\n\tregistry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&dubbo=2.0.0&export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&organization=dubbox&owner=programmer&pid=3872&registry=zookeeper&timestamp=1422240274186\n\n以这个url为基准暴露服务的话，dubbo会首先会根据指定协议（`registry`）拿到对应的protocol（`RegistryProtocol`），这部分是怎么做到的呢？还是之前通过IDE拿到的dubbo动态创建的protocol自适应扩展点，我们重点看`export`方法：\n\n\n\tpackage com.alibaba.dubbo.rpc;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\t\n\tpublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\t\t\n\t\t......\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n\t\t\tif (arg0 == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\");\n\t\t\t\n\t\t\tif (arg0.getUrl() == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\t//注意这句，根据我们的例子，extName=registry\n\t\t\t\n\t\t\tif(extName == null) \n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\t//根据扩展点加载规则，最终拿到RegistryProtocol实例。\n\t\t\t\n\t\t\treturn extension.export(arg0);\n\t\t}\n\t\t\n\t\t......\n\t}\n\n\n\t\n我们需要注意`RegistryProtocol`的私有属性：\n\n\tprivate Protocol protocol;\n    \n    public void setProtocol(Protocol protocol) {\n        this.protocol = protocol;   //由SPI机制为其赋予一个protocol的自适应扩展点（动态创建的）\n    }\n\n这个属性真正被赋值的地方是在SPI机制中为扩展点注入的阶段（`injectExtension`方法）：\n\n\tprivate T injectExtension(T instance) {\n        try {\n            if (objectFactory != null) {\n                for (Method method : instance.getClass().getMethods()) {\n                    if (method.getName().startsWith(\"set\")\n                            && method.getParameterTypes().length == 1\n                            && Modifier.isPublic(method.getModifiers())) {\n                        Class<?> pt = method.getParameterTypes()[0];\n                        try {\n                            String property = method.getName().length() > 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\";\n                            Object object = objectFactory.getExtension(pt, property);\t//注意这里，我们的例子中，这个object会是SPI动态创建的自适应扩展点实例：Protocol$Adpative\n                            if (object != null) {\n                                method.invoke(instance, object);\n                            }\n                        } catch (Exception e) {\n                            logger.error(\"fail to inject via method \" + method.getName()\n                                    + \" of interface \" + type.getName() + \": \" + e.getMessage(), e);\n                        }\n                    }\n                }\n            }\n        } catch (Exception e) {\n            logger.error(e.getMessage(), e);\n        }\n        return instance;\n    }\n\n有点乱，回到`RegistryProtocol`类，我们知道，在服务暴露阶段，会调用它的`export`方法，在这个方法里会完成服务的注册逻辑：\n\n\tpublic <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException {\n        //export invoker\n        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker); //完成真正的服务暴露逻辑：默认以netty创建server服务来处理远程调用，打算回头专门写一下dubbo使用netty的细节\n\n        //registry provider\n        final Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\n        final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\n        registry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n\n        // 订阅override数据\n        // FIXME 提供者订阅时，会影响同一JVM既暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。\n        final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl);\n        final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl);\n        overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);\n        registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);\n\n        //保证每次export都返回一个新的exporter实例\n        return new Exporter<T>() {\n            public Invoker<T> getInvoker() {\n                return exporter.getInvoker();\n            }\n            public void unexport() {\n            \ttry {\n            \t\texporter.unexport();\n            \t} catch (Throwable t) {\n                \tlogger.warn(t.getMessage(), t);\n                }\n                try {\n                \tregistry.unregister(registedProviderUrl);\n                } catch (Throwable t) {\n                \tlogger.warn(t.getMessage(), t);\n                }\n                try {\n                \toverrideListeners.remove(overrideSubscribeUrl);\n                \tregistry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener);\n                } catch (Throwable t) {\n                \tlogger.warn(t.getMessage(), t);\n                }\n            }\n        };\n\t}\n\n\n到这里，主线轮廓已经勾勒出来了，我们接下来看一下dubbo和zookeeper之间在服务注册阶段的通信细节，要从上面这个方法中的下面三行下手：\n\n\t//registry provider\n    final Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\n    final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\n    registry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n\n正如注释标明的，第一行会获取invoker中url指定的注册中心实例，我们的情况就是拿到`zookeeperRegistry`。第二行其实就是过滤掉url中的注册中心相关参数，以及过滤器，监控中心等参数，按照我们上面的例子，`registedProviderUrl`大概应该如下：\n\n\tdubbo://192.168.153.1:20880/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&application=demo-provider&dubbo=2.0.0&generic=false&interface=com.alibaba.dubbo.demo.bid.BidService&methods=throwNPE,bid&optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&organization=dubbox&owner=programmer&pid=3872&serialization=kryo&side=provider&timestamp=1422241023451\n\n我们主要看第三行，真正完成向zookeeper中注册的工作就是靠register方法完成的，先来看一下zookeeperRegistry的继承关系：\n\n![](http://pic.yupoo.com/kazaff/Ep8RFf0S/7imCY.png)\n\n真正声明register方法的是zookeeperRegistry的父类：FailbackRegistry，从名字就能直观的看出它的作用，主要就是负责注册中心失效重试逻辑的。我们不打算在这里展开说这个话题。好吧，我们继续看zookeeperRegistry的doRegister方法（FailbackRegistry的register方法会调用zookeeperRegistry的doRegister的方法）：\n\n\tprotected void doRegister(URL url) {\n        try {\n        \tzkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true));     //参见：http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm\n        } catch (Throwable e) {\n            throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e);\n        }\n    }\n\n到这里就已经可以告一段落了，需要叮嘱的是`toUrlPath`方法，它的作用就是把url格式化成最终存储在zookeeper中的数据格式，尤其要注意`category`参数，它表示注册类型，如下图：\n\n![](http://pic.yupoo.com/kazaff/Ep8ZmnoV/RmZZL.jpg)\n\n在我们的例子中，最终这次注册就会在对应serverInterface下的providers下创建一个url节点。\n\n\n\n\nsubscribe\n---\n\n我们再来看看服务消费方对所引用服务的订阅细节，与服务提供方大致一样（忽略集群逻辑），只不过到达`RegistryProtocol`后调用的是`refer`方法：\n\n\tpublic <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {\n        //处理注册中心的协议，用url中registry参数的值作为真实的注册中心协议\n        url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY);\n        Registry registry = registryFactory.getRegistry(url);   //拿到真正的注册中心实例，我们的例子中就是zookeeperRegistry\n\n        if (RegistryService.class.equals(type)) {   //todo 不太理解，貌似是注册中心服务本身的暴露\n        \treturn proxyFactory.getInvoker((T) registry, type, url);\n        }\n\n        //分组聚合处理，http://alibaba.github.io/dubbo-doc-static/Merge+By+Group-zh.htm\n        // group=\"a,b\" or group=\"*\"\n        Map<String, String> qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY));\n        String group = qs.get(Constants.GROUP_KEY);\n        if (group != null && group.length() > 0 ) {\n            if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length > 1\n                    || \"*\".equals( group ) ) {\n                return doRefer( getMergeableCluster(), registry, type, url );\n            }\n        }\n\n        return doRefer(cluster, registry, type, url);\n    }\n\n真正完成订阅是在`doRefer`方法中：\n\n\t private <T> Invoker<T> doRefer(Cluster cluster, Registry registry, Class<T> type, URL url) {\n        RegistryDirectory<T> directory = new RegistryDirectory<T>(type, url);   //这个directory把同一个serviceInterface对应的多个invoker管理起来提供概念上的化多为单一，供路由、均衡算法等使用\n        directory.setRegistry(registry);\n        directory.setProtocol(protocol);\n        URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters());\n\n        //注册自己\n        if (! Constants.ANY_VALUE.equals(url.getServiceInterface())\n                && url.getParameter(Constants.REGISTER_KEY, true)) {\n            registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY,\n                    Constants.CHECK_KEY, String.valueOf(false)));\n        }\n\n        //订阅目标服务提供方\n        directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, \n                Constants.PROVIDERS_CATEGORY \n                + \",\" + Constants.CONFIGURATORS_CATEGORY \n                + \",\" + Constants.ROUTERS_CATEGORY));\n\n        return cluster.join(directory); //合并所有相同invoker\n    }\n\n\n可见代码和上面给的那个图很吻合，服务消费方不仅会订阅相关的服务，也会注册自身供其他层使用（服务治理）。特别要注意的是订阅时，同时订阅了三个分类类型：**providers，routers，configurators**。目前我们不打算说另外两种类型的意义（因为我也不清楚），后面分析道路由和集群的时候再来扯淡。\n\n继续深挖dubbo中服务消费方订阅服务的细节，上面方法中最终把订阅细节委托给`RegistryDirectory.subscribe`方法，注意，这个方法接受的参数，此时的url已经把`category`设置为`providers，routers，configurators`：\n\n\tpublic void subscribe(URL url) {\n        setConsumerUrl(url);\n        registry.subscribe(url, this);\n    }\n\n这里`registry`就是zookeeperRegistry，这在`doRefer`方法可以看到明确的注入。然后和注册服务时一样，订阅会先由`FailbackRegistry`完成失效重试的处理，最终会交给`zookeeperRegistry.doSubscribe`方法。zookeeperRegistry实例拥有ZookeeperClient类型引用，该类型对象封装了和zookeeper通信的逻辑（默认是使用zkclient客户端），这里需要注意的一点，小爷我就被这里的一个数据结构卡住了一整天：\n\n\tprivate final ConcurrentMap<URL, ConcurrentMap<NotifyListener, ChildListener>> zkListeners = new ConcurrentHashMap<URL, ConcurrentMap<NotifyListener, ChildListener>>();\n\n一开始很不理解，为何要在url和NotifyListener之间再搞一个ChildListener接口出来，后来反复查看zkclient的文档说明和dubbo注册中心的设计，才悟出来点门道。这个**ChildListener接口用于把zkclient的事件（IZkChildListener）转换到registry事件（NotifyListener）**。这么做的深意不是特别的理解，可能是因为我并没有太多zookeeper的使用经验导致的，这里的做法**可以更好的把zkclient的api和dubbo真身的注册中心逻辑分离开**，毕竟dubbo除了zkclient以外还可以选择curator。从dubbo源码中可以看出，架构师和开发人员对面向对象和设计模式的理解非常的深刻，合理的运用继承和组合，打造了非常灵活的一套系统，保证概念统一的前提下展现了非常强大的多态性，感叹！\n\n这样走一圈下来，关于服务订阅的大致流程就描述清楚了，部分问题需要留到未来再解决了。\n\n\n\nnotify\n---\n\n最后看一下注册推送细节，在订阅时你会注意到，订阅真正操作的是用`RegistryDirectory`类型封装过的对象，这个类型实现了一个接口`NotifyListener`（前面我们已经提到这个接口了），该接口用于描述支持推送通知逻辑：\n\t\n\tpublic interface NotifyListener {\n\t\n\t    /**\n\t     * 当收到服务变更通知时触发。\n\t     * \n\t     * 通知需处理契约：<br>\n\t     * 1. 总是以服务接口和数据类型为维度全量通知，即不会通知一个服务的同类型的部分数据，用户不需要对比上一次通知结果。<br>\n\t     * 2. 订阅时的第一次通知，必须是一个服务的所有类型数据的全量通知。<br>\n\t     * 3. 中途变更时，允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。<br>\n\t     * 4. 如果一种类型的数据为空，需通知一个empty协议并带category参数的标识性URL数据。<br>\n\t     * 5. 通知者(即注册中心实现)需保证通知的顺序，比如：单线程推送，队列串行化，带版本对比。<br>\n\t     * \n\t     * @param urls 已注册信息列表，总不为空，含义同{@link com.alibaba.dubbo.registry.RegistryService#lookup(URL)}的返回值。\n\t     */\n\t    void notify(List<URL> urls);\n\t}\n\n前面提到了ChildListener接口，dubbo靠它把zkclient的事件转换成自己的事件类型，如果从代码上来看确实有点绕，事件的流程我手绘了一下：\n\n[![](http://pic.yupoo.com/kazaff/Epc4RElK/medish.jpg)](http://pic.yupoo.com/kazaff/Epc4RElK/TJLi1.png)\n\n我们主要看一下RegistryDirectory的notify方法：\n\n\tpublic synchronized void notify(List<URL> urls) {\n        List<URL> invokerUrls = new ArrayList<URL>();\n        List<URL> routerUrls = new ArrayList<URL>();\n        List<URL> configuratorUrls = new ArrayList<URL>();\n        for (URL url : urls) {\n            String protocol = url.getProtocol();\n            //允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。\n            String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);\n            if (Constants.ROUTERS_CATEGORY.equals(category) \n                    || Constants.ROUTE_PROTOCOL.equals(protocol)) {\n                routerUrls.add(url);\n            } else if (Constants.CONFIGURATORS_CATEGORY.equals(category) \n                    || Constants.OVERRIDE_PROTOCOL.equals(protocol)) {\n                configuratorUrls.add(url);\n            } else if (Constants.PROVIDERS_CATEGORY.equals(category)) {\n                invokerUrls.add(url);\n            } else {\n                logger.warn(\"Unsupported category \" + category + \" in notified url: \" + url + \" from registry \" + getUrl().getAddress() + \" to consumer \" + NetUtils.getLocalHost());\n            }\n        }\n        // configurators 更新缓存的服务提供方配置规则\n        if (configuratorUrls != null && configuratorUrls.size() >0 ){\n            this.configurators = toConfigurators(configuratorUrls);\n        }\n        // routers  更新缓存的路由配置规则\n        if (routerUrls != null && routerUrls.size() >0 ){\n            List<Router> routers = toRouters(routerUrls);\n            if(routers != null){ // null - do nothing\n                setRouters(routers);\n            }\n        }\n\n        // 合并override参数\n        List<Configurator> localConfigurators = this.configurators; // local reference\n        this.overrideDirectoryUrl = directoryUrl;\n        if (localConfigurators != null && localConfigurators.size() > 0) {\n            for (Configurator configurator : localConfigurators) {\n                this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);\n            }\n        }\n\n        // providers\n        refreshInvoker(invokerUrls);\n    }\n\ndubbo提供了强大的服务治理功能，所以这里在每次消费方接受到注册中心的通知后，大概会做下面这些事儿：\n\n- [更新服务提供方配置规则](http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm)\n- [更新路由规则](http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm)\n- 重建invoker实例\n\n前两件事儿我们放在分析路由，过滤器，集群的时候再讲，我们这里主要看dubbo如何“重建invoker实例”，也就是最后一行代码调用的方法`refreshInvoker`：\n\n\tprivate void refreshInvoker(List<URL> invokerUrls){\n        if (invokerUrls != null && invokerUrls.size() == 1 && invokerUrls.get(0) != null\n                && Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) { //如果传入的参数只包含一个empty://协议的url，表明禁用当前服务\n            this.forbidden = true; // 禁止访问\n            this.methodInvokerMap = null; // 置空列表\n            destroyAllInvokers(); // 关闭所有Invoker\n        } else {\n            this.forbidden = false; // 允许访问\n            Map<String, Invoker<T>> oldUrlInvokerMap = this.urlInvokerMap; // local reference\n\n            if (invokerUrls.size() == 0 && this.cachedInvokerUrls != null){ //如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用\n                invokerUrls.addAll(this.cachedInvokerUrls);\n            } else {\n                this.cachedInvokerUrls = new HashSet<URL>();\n                this.cachedInvokerUrls.addAll(invokerUrls);//缓存invokerUrls列表，便于交叉对比\n            }\n\n            if (invokerUrls.size() ==0 ){\n            \treturn;\n            }\n\n            Map<String, Invoker<T>> newUrlInvokerMap = toInvokers(invokerUrls) ;// 将URL列表转成Invoker列表\n            Map<String, List<Invoker<T>>> newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表\n\n            // state change\n            //如果计算错误，则不进行处理.\n            if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0 ){\n                logger.error(new IllegalStateException(\"urls to invokers error .invokerUrls.size :\"+invokerUrls.size() + \", invoker.size :0. urls :\"+invokerUrls.toString()));\n                return ;\n            }\n\n            this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap;\n            this.urlInvokerMap = newUrlInvokerMap;\n\n            try{\n                destroyUnusedInvokers(oldUrlInvokerMap,newUrlInvokerMap); // 关闭未使用的Invoker\n            }catch (Exception e) {\n                logger.warn(\"destroyUnusedInvokers error. \", e);\n            }\n        }\n    }\n\n\n好吧，到这里我们已经完成了服务通知的业务逻辑，有兴趣的童鞋可以深究一下`toInvokers`方法，它又会走一遍**url->invoker**的逻辑（服务引用）。\n\n\n那么，就先到这里吧，再会~\n\n\n","source":"_posts/dubbo的服务发现细节.md","raw":"title: dubbo的服务发现细节\ndate: 2015-01-31 15:54:30\ntags:\n- dubbo\n- dubbox\n- soa\n- 分布式\n- 注册中心\n- zookeeper\n\ncategories: j2ee\n---\n\n\n对于分布式服务架构，解决服务的发现问题，引入了注册中心中间件，从而很好的解决了服务双方（消费方和提供方）的直接依赖问题。这种解耦的意义是非凡的，不仅在程序运行时保证了灵活性，在开发阶段也使得快速迭代成为了可能，甚至在运维层面也提供了非常好的自由度。\n<!-- more -->\n夸了这么多，但要实现一个完美的注册中心系统却不是一件那么容易的事儿，你必须时刻注意关注它的可用性（包括**稳定，实时和高效**），这一点在任何一款分布式系统中都是件很复杂的事儿。当然这篇文章并不是打算摆平这么个庞然大物，我们只是从dubbo和zookeeper之间的关系来了解一下在dubbo架构中注册中心的相关知识：\n\n![](http://pic.yupoo.com/kazaff/EogBsej0/gvnAo.jpg)\n\n上图是官方给出的一张描述服务提供方、服务消费方和注册中心的关系图，其实dubbo提供多种注册中心实现，不过常用的就是zookeeper，我们也就拿它来当例子来分析。从图中可见，**消费方远程调用服务方是不通过注册中心的**，这有效的降低了注册中心的负载，也不会存在明显的单点瓶颈（尽管可以搭建注册中心的集群，但每次调用都走注册中心的话肯定对性能产生较大的伤害）。\n\n官方提供的规则是：\n\n- 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小；\n- 注册中心，服务提供者，服务消费者三者之间均为长连接；\n- 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者；\n- 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者；\n- 注册中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表；\n- 注册中心是可选的，服务消费者可以直连服务提供者；\n- 注册中心对等集群，任意一台宕掉后，将自动切换到另一台。\n\n好啦，更多的理论我就不转载了，官方已经描述的非常详细了，我们按照老套路，从代码级别看一下dubbo到底是怎样实现的。\n\n\n\nregister\n---\n\n我们需要承接之前的[文章](http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/)里的例子，从拿到需要暴露成服务的url开始：\n\n\tregistry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&dubbo=2.0.0&export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&organization=dubbox&owner=programmer&pid=3872&registry=zookeeper&timestamp=1422240274186\n\n以这个url为基准暴露服务的话，dubbo会首先会根据指定协议（`registry`）拿到对应的protocol（`RegistryProtocol`），这部分是怎么做到的呢？还是之前通过IDE拿到的dubbo动态创建的protocol自适应扩展点，我们重点看`export`方法：\n\n\n\tpackage com.alibaba.dubbo.rpc;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\t\n\tpublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\t\t\n\t\t......\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n\t\t\tif (arg0 == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\");\n\t\t\t\n\t\t\tif (arg0.getUrl() == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\t//注意这句，根据我们的例子，extName=registry\n\t\t\t\n\t\t\tif(extName == null) \n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\t//根据扩展点加载规则，最终拿到RegistryProtocol实例。\n\t\t\t\n\t\t\treturn extension.export(arg0);\n\t\t}\n\t\t\n\t\t......\n\t}\n\n\n\t\n我们需要注意`RegistryProtocol`的私有属性：\n\n\tprivate Protocol protocol;\n    \n    public void setProtocol(Protocol protocol) {\n        this.protocol = protocol;   //由SPI机制为其赋予一个protocol的自适应扩展点（动态创建的）\n    }\n\n这个属性真正被赋值的地方是在SPI机制中为扩展点注入的阶段（`injectExtension`方法）：\n\n\tprivate T injectExtension(T instance) {\n        try {\n            if (objectFactory != null) {\n                for (Method method : instance.getClass().getMethods()) {\n                    if (method.getName().startsWith(\"set\")\n                            && method.getParameterTypes().length == 1\n                            && Modifier.isPublic(method.getModifiers())) {\n                        Class<?> pt = method.getParameterTypes()[0];\n                        try {\n                            String property = method.getName().length() > 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\";\n                            Object object = objectFactory.getExtension(pt, property);\t//注意这里，我们的例子中，这个object会是SPI动态创建的自适应扩展点实例：Protocol$Adpative\n                            if (object != null) {\n                                method.invoke(instance, object);\n                            }\n                        } catch (Exception e) {\n                            logger.error(\"fail to inject via method \" + method.getName()\n                                    + \" of interface \" + type.getName() + \": \" + e.getMessage(), e);\n                        }\n                    }\n                }\n            }\n        } catch (Exception e) {\n            logger.error(e.getMessage(), e);\n        }\n        return instance;\n    }\n\n有点乱，回到`RegistryProtocol`类，我们知道，在服务暴露阶段，会调用它的`export`方法，在这个方法里会完成服务的注册逻辑：\n\n\tpublic <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException {\n        //export invoker\n        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker); //完成真正的服务暴露逻辑：默认以netty创建server服务来处理远程调用，打算回头专门写一下dubbo使用netty的细节\n\n        //registry provider\n        final Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\n        final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\n        registry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n\n        // 订阅override数据\n        // FIXME 提供者订阅时，会影响同一JVM既暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。\n        final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl);\n        final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl);\n        overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);\n        registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);\n\n        //保证每次export都返回一个新的exporter实例\n        return new Exporter<T>() {\n            public Invoker<T> getInvoker() {\n                return exporter.getInvoker();\n            }\n            public void unexport() {\n            \ttry {\n            \t\texporter.unexport();\n            \t} catch (Throwable t) {\n                \tlogger.warn(t.getMessage(), t);\n                }\n                try {\n                \tregistry.unregister(registedProviderUrl);\n                } catch (Throwable t) {\n                \tlogger.warn(t.getMessage(), t);\n                }\n                try {\n                \toverrideListeners.remove(overrideSubscribeUrl);\n                \tregistry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener);\n                } catch (Throwable t) {\n                \tlogger.warn(t.getMessage(), t);\n                }\n            }\n        };\n\t}\n\n\n到这里，主线轮廓已经勾勒出来了，我们接下来看一下dubbo和zookeeper之间在服务注册阶段的通信细节，要从上面这个方法中的下面三行下手：\n\n\t//registry provider\n    final Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\n    final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\n    registry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n\n正如注释标明的，第一行会获取invoker中url指定的注册中心实例，我们的情况就是拿到`zookeeperRegistry`。第二行其实就是过滤掉url中的注册中心相关参数，以及过滤器，监控中心等参数，按照我们上面的例子，`registedProviderUrl`大概应该如下：\n\n\tdubbo://192.168.153.1:20880/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&application=demo-provider&dubbo=2.0.0&generic=false&interface=com.alibaba.dubbo.demo.bid.BidService&methods=throwNPE,bid&optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&organization=dubbox&owner=programmer&pid=3872&serialization=kryo&side=provider&timestamp=1422241023451\n\n我们主要看第三行，真正完成向zookeeper中注册的工作就是靠register方法完成的，先来看一下zookeeperRegistry的继承关系：\n\n![](http://pic.yupoo.com/kazaff/Ep8RFf0S/7imCY.png)\n\n真正声明register方法的是zookeeperRegistry的父类：FailbackRegistry，从名字就能直观的看出它的作用，主要就是负责注册中心失效重试逻辑的。我们不打算在这里展开说这个话题。好吧，我们继续看zookeeperRegistry的doRegister方法（FailbackRegistry的register方法会调用zookeeperRegistry的doRegister的方法）：\n\n\tprotected void doRegister(URL url) {\n        try {\n        \tzkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true));     //参见：http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm\n        } catch (Throwable e) {\n            throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e);\n        }\n    }\n\n到这里就已经可以告一段落了，需要叮嘱的是`toUrlPath`方法，它的作用就是把url格式化成最终存储在zookeeper中的数据格式，尤其要注意`category`参数，它表示注册类型，如下图：\n\n![](http://pic.yupoo.com/kazaff/Ep8ZmnoV/RmZZL.jpg)\n\n在我们的例子中，最终这次注册就会在对应serverInterface下的providers下创建一个url节点。\n\n\n\n\nsubscribe\n---\n\n我们再来看看服务消费方对所引用服务的订阅细节，与服务提供方大致一样（忽略集群逻辑），只不过到达`RegistryProtocol`后调用的是`refer`方法：\n\n\tpublic <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {\n        //处理注册中心的协议，用url中registry参数的值作为真实的注册中心协议\n        url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY);\n        Registry registry = registryFactory.getRegistry(url);   //拿到真正的注册中心实例，我们的例子中就是zookeeperRegistry\n\n        if (RegistryService.class.equals(type)) {   //todo 不太理解，貌似是注册中心服务本身的暴露\n        \treturn proxyFactory.getInvoker((T) registry, type, url);\n        }\n\n        //分组聚合处理，http://alibaba.github.io/dubbo-doc-static/Merge+By+Group-zh.htm\n        // group=\"a,b\" or group=\"*\"\n        Map<String, String> qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY));\n        String group = qs.get(Constants.GROUP_KEY);\n        if (group != null && group.length() > 0 ) {\n            if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length > 1\n                    || \"*\".equals( group ) ) {\n                return doRefer( getMergeableCluster(), registry, type, url );\n            }\n        }\n\n        return doRefer(cluster, registry, type, url);\n    }\n\n真正完成订阅是在`doRefer`方法中：\n\n\t private <T> Invoker<T> doRefer(Cluster cluster, Registry registry, Class<T> type, URL url) {\n        RegistryDirectory<T> directory = new RegistryDirectory<T>(type, url);   //这个directory把同一个serviceInterface对应的多个invoker管理起来提供概念上的化多为单一，供路由、均衡算法等使用\n        directory.setRegistry(registry);\n        directory.setProtocol(protocol);\n        URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters());\n\n        //注册自己\n        if (! Constants.ANY_VALUE.equals(url.getServiceInterface())\n                && url.getParameter(Constants.REGISTER_KEY, true)) {\n            registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY,\n                    Constants.CHECK_KEY, String.valueOf(false)));\n        }\n\n        //订阅目标服务提供方\n        directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, \n                Constants.PROVIDERS_CATEGORY \n                + \",\" + Constants.CONFIGURATORS_CATEGORY \n                + \",\" + Constants.ROUTERS_CATEGORY));\n\n        return cluster.join(directory); //合并所有相同invoker\n    }\n\n\n可见代码和上面给的那个图很吻合，服务消费方不仅会订阅相关的服务，也会注册自身供其他层使用（服务治理）。特别要注意的是订阅时，同时订阅了三个分类类型：**providers，routers，configurators**。目前我们不打算说另外两种类型的意义（因为我也不清楚），后面分析道路由和集群的时候再来扯淡。\n\n继续深挖dubbo中服务消费方订阅服务的细节，上面方法中最终把订阅细节委托给`RegistryDirectory.subscribe`方法，注意，这个方法接受的参数，此时的url已经把`category`设置为`providers，routers，configurators`：\n\n\tpublic void subscribe(URL url) {\n        setConsumerUrl(url);\n        registry.subscribe(url, this);\n    }\n\n这里`registry`就是zookeeperRegistry，这在`doRefer`方法可以看到明确的注入。然后和注册服务时一样，订阅会先由`FailbackRegistry`完成失效重试的处理，最终会交给`zookeeperRegistry.doSubscribe`方法。zookeeperRegistry实例拥有ZookeeperClient类型引用，该类型对象封装了和zookeeper通信的逻辑（默认是使用zkclient客户端），这里需要注意的一点，小爷我就被这里的一个数据结构卡住了一整天：\n\n\tprivate final ConcurrentMap<URL, ConcurrentMap<NotifyListener, ChildListener>> zkListeners = new ConcurrentHashMap<URL, ConcurrentMap<NotifyListener, ChildListener>>();\n\n一开始很不理解，为何要在url和NotifyListener之间再搞一个ChildListener接口出来，后来反复查看zkclient的文档说明和dubbo注册中心的设计，才悟出来点门道。这个**ChildListener接口用于把zkclient的事件（IZkChildListener）转换到registry事件（NotifyListener）**。这么做的深意不是特别的理解，可能是因为我并没有太多zookeeper的使用经验导致的，这里的做法**可以更好的把zkclient的api和dubbo真身的注册中心逻辑分离开**，毕竟dubbo除了zkclient以外还可以选择curator。从dubbo源码中可以看出，架构师和开发人员对面向对象和设计模式的理解非常的深刻，合理的运用继承和组合，打造了非常灵活的一套系统，保证概念统一的前提下展现了非常强大的多态性，感叹！\n\n这样走一圈下来，关于服务订阅的大致流程就描述清楚了，部分问题需要留到未来再解决了。\n\n\n\nnotify\n---\n\n最后看一下注册推送细节，在订阅时你会注意到，订阅真正操作的是用`RegistryDirectory`类型封装过的对象，这个类型实现了一个接口`NotifyListener`（前面我们已经提到这个接口了），该接口用于描述支持推送通知逻辑：\n\t\n\tpublic interface NotifyListener {\n\t\n\t    /**\n\t     * 当收到服务变更通知时触发。\n\t     * \n\t     * 通知需处理契约：<br>\n\t     * 1. 总是以服务接口和数据类型为维度全量通知，即不会通知一个服务的同类型的部分数据，用户不需要对比上一次通知结果。<br>\n\t     * 2. 订阅时的第一次通知，必须是一个服务的所有类型数据的全量通知。<br>\n\t     * 3. 中途变更时，允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。<br>\n\t     * 4. 如果一种类型的数据为空，需通知一个empty协议并带category参数的标识性URL数据。<br>\n\t     * 5. 通知者(即注册中心实现)需保证通知的顺序，比如：单线程推送，队列串行化，带版本对比。<br>\n\t     * \n\t     * @param urls 已注册信息列表，总不为空，含义同{@link com.alibaba.dubbo.registry.RegistryService#lookup(URL)}的返回值。\n\t     */\n\t    void notify(List<URL> urls);\n\t}\n\n前面提到了ChildListener接口，dubbo靠它把zkclient的事件转换成自己的事件类型，如果从代码上来看确实有点绕，事件的流程我手绘了一下：\n\n[![](http://pic.yupoo.com/kazaff/Epc4RElK/medish.jpg)](http://pic.yupoo.com/kazaff/Epc4RElK/TJLi1.png)\n\n我们主要看一下RegistryDirectory的notify方法：\n\n\tpublic synchronized void notify(List<URL> urls) {\n        List<URL> invokerUrls = new ArrayList<URL>();\n        List<URL> routerUrls = new ArrayList<URL>();\n        List<URL> configuratorUrls = new ArrayList<URL>();\n        for (URL url : urls) {\n            String protocol = url.getProtocol();\n            //允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。\n            String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);\n            if (Constants.ROUTERS_CATEGORY.equals(category) \n                    || Constants.ROUTE_PROTOCOL.equals(protocol)) {\n                routerUrls.add(url);\n            } else if (Constants.CONFIGURATORS_CATEGORY.equals(category) \n                    || Constants.OVERRIDE_PROTOCOL.equals(protocol)) {\n                configuratorUrls.add(url);\n            } else if (Constants.PROVIDERS_CATEGORY.equals(category)) {\n                invokerUrls.add(url);\n            } else {\n                logger.warn(\"Unsupported category \" + category + \" in notified url: \" + url + \" from registry \" + getUrl().getAddress() + \" to consumer \" + NetUtils.getLocalHost());\n            }\n        }\n        // configurators 更新缓存的服务提供方配置规则\n        if (configuratorUrls != null && configuratorUrls.size() >0 ){\n            this.configurators = toConfigurators(configuratorUrls);\n        }\n        // routers  更新缓存的路由配置规则\n        if (routerUrls != null && routerUrls.size() >0 ){\n            List<Router> routers = toRouters(routerUrls);\n            if(routers != null){ // null - do nothing\n                setRouters(routers);\n            }\n        }\n\n        // 合并override参数\n        List<Configurator> localConfigurators = this.configurators; // local reference\n        this.overrideDirectoryUrl = directoryUrl;\n        if (localConfigurators != null && localConfigurators.size() > 0) {\n            for (Configurator configurator : localConfigurators) {\n                this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);\n            }\n        }\n\n        // providers\n        refreshInvoker(invokerUrls);\n    }\n\ndubbo提供了强大的服务治理功能，所以这里在每次消费方接受到注册中心的通知后，大概会做下面这些事儿：\n\n- [更新服务提供方配置规则](http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm)\n- [更新路由规则](http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm)\n- 重建invoker实例\n\n前两件事儿我们放在分析路由，过滤器，集群的时候再讲，我们这里主要看dubbo如何“重建invoker实例”，也就是最后一行代码调用的方法`refreshInvoker`：\n\n\tprivate void refreshInvoker(List<URL> invokerUrls){\n        if (invokerUrls != null && invokerUrls.size() == 1 && invokerUrls.get(0) != null\n                && Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) { //如果传入的参数只包含一个empty://协议的url，表明禁用当前服务\n            this.forbidden = true; // 禁止访问\n            this.methodInvokerMap = null; // 置空列表\n            destroyAllInvokers(); // 关闭所有Invoker\n        } else {\n            this.forbidden = false; // 允许访问\n            Map<String, Invoker<T>> oldUrlInvokerMap = this.urlInvokerMap; // local reference\n\n            if (invokerUrls.size() == 0 && this.cachedInvokerUrls != null){ //如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用\n                invokerUrls.addAll(this.cachedInvokerUrls);\n            } else {\n                this.cachedInvokerUrls = new HashSet<URL>();\n                this.cachedInvokerUrls.addAll(invokerUrls);//缓存invokerUrls列表，便于交叉对比\n            }\n\n            if (invokerUrls.size() ==0 ){\n            \treturn;\n            }\n\n            Map<String, Invoker<T>> newUrlInvokerMap = toInvokers(invokerUrls) ;// 将URL列表转成Invoker列表\n            Map<String, List<Invoker<T>>> newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表\n\n            // state change\n            //如果计算错误，则不进行处理.\n            if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0 ){\n                logger.error(new IllegalStateException(\"urls to invokers error .invokerUrls.size :\"+invokerUrls.size() + \", invoker.size :0. urls :\"+invokerUrls.toString()));\n                return ;\n            }\n\n            this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap;\n            this.urlInvokerMap = newUrlInvokerMap;\n\n            try{\n                destroyUnusedInvokers(oldUrlInvokerMap,newUrlInvokerMap); // 关闭未使用的Invoker\n            }catch (Exception e) {\n                logger.warn(\"destroyUnusedInvokers error. \", e);\n            }\n        }\n    }\n\n\n好吧，到这里我们已经完成了服务通知的业务逻辑，有兴趣的童鞋可以深究一下`toInvokers`方法，它又会走一遍**url->invoker**的逻辑（服务引用）。\n\n\n那么，就先到这里吧，再会~\n\n\n","slug":"dubbo的服务发现细节","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yqj00a6gtfy1846vfxj","comments":1,"layout":"post","photos":[],"link":"","content":"<p>对于分布式服务架构，解决服务的发现问题，引入了注册中心中间件，从而很好的解决了服务双方（消费方和提供方）的直接依赖问题。这种解耦的意义是非凡的，不仅在程序运行时保证了灵活性，在开发阶段也使得快速迭代成为了可能，甚至在运维层面也提供了非常好的自由度。<br><a id=\"more\"></a><br>夸了这么多，但要实现一个完美的注册中心系统却不是一件那么容易的事儿，你必须时刻注意关注它的可用性（包括<strong>稳定，实时和高效</strong>），这一点在任何一款分布式系统中都是件很复杂的事儿。当然这篇文章并不是打算摆平这么个庞然大物，我们只是从dubbo和zookeeper之间的关系来了解一下在dubbo架构中注册中心的相关知识：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EogBsej0/gvnAo.jpg\" alt=\"\"></p>\n<p>上图是官方给出的一张描述服务提供方、服务消费方和注册中心的关系图，其实dubbo提供多种注册中心实现，不过常用的就是zookeeper，我们也就拿它来当例子来分析。从图中可见，<strong>消费方远程调用服务方是不通过注册中心的</strong>，这有效的降低了注册中心的负载，也不会存在明显的单点瓶颈（尽管可以搭建注册中心的集群，但每次调用都走注册中心的话肯定对性能产生较大的伤害）。</p>\n<p>官方提供的规则是：</p>\n<ul>\n<li>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小；</li>\n<li>注册中心，服务提供者，服务消费者三者之间均为长连接；</li>\n<li>注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者；</li>\n<li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者；</li>\n<li>注册中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表；</li>\n<li>注册中心是可选的，服务消费者可以直连服务提供者；</li>\n<li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台。</li>\n</ul>\n<p>好啦，更多的理论我就不转载了，官方已经描述的非常详细了，我们按照老套路，从代码级别看一下dubbo到底是怎样实现的。</p>\n<h2 id=\"register\"><a href=\"#register\" class=\"headerlink\" title=\"register\"></a>register</h2><p>我们需要承接之前的<a href=\"http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/\">文章</a>里的例子，从拿到需要暴露成服务的url开始：</p>\n<pre><code>registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&amp;dubbo=2.0.0&amp;export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;registry=zookeeper&amp;timestamp=1422240274186\n</code></pre><p>以这个url为基准暴露服务的话，dubbo会首先会根据指定协议（<code>registry</code>）拿到对应的protocol（<code>RegistryProtocol</code>），这部分是怎么做到的呢？还是之前通过IDE拿到的dubbo动态创建的protocol自适应扩展点，我们重点看<code>export</code>方法：</p>\n<pre><code>package com.alibaba.dubbo.rpc;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\n    ......\n\n    public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n        if (arg0 == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;);\n\n        if (arg0.getUrl() == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );    //注意这句，根据我们的例子，extName=registry\n\n        if(extName == null) \n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n        com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);    //根据扩展点加载规则，最终拿到RegistryProtocol实例。\n\n        return extension.export(arg0);\n    }\n\n    ......\n}\n</code></pre><p>我们需要注意<code>RegistryProtocol</code>的私有属性：</p>\n<pre><code>private Protocol protocol;\n\npublic void setProtocol(Protocol protocol) {\n    this.protocol = protocol;   //由SPI机制为其赋予一个protocol的自适应扩展点（动态创建的）\n}\n</code></pre><p>这个属性真正被赋值的地方是在SPI机制中为扩展点注入的阶段（<code>injectExtension</code>方法）：</p>\n<pre><code>private T injectExtension(T instance) {\n    try {\n        if (objectFactory != null) {\n            for (Method method : instance.getClass().getMethods()) {\n                if (method.getName().startsWith(&quot;set&quot;)\n                        &amp;&amp; method.getParameterTypes().length == 1\n                        &amp;&amp; Modifier.isPublic(method.getModifiers())) {\n                    Class&lt;?&gt; pt = method.getParameterTypes()[0];\n                    try {\n                        String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : &quot;&quot;;\n                        Object object = objectFactory.getExtension(pt, property);    //注意这里，我们的例子中，这个object会是SPI动态创建的自适应扩展点实例：Protocol$Adpative\n                        if (object != null) {\n                            method.invoke(instance, object);\n                        }\n                    } catch (Exception e) {\n                        logger.error(&quot;fail to inject via method &quot; + method.getName()\n                                + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e);\n                    }\n                }\n            }\n        }\n    } catch (Exception e) {\n        logger.error(e.getMessage(), e);\n    }\n    return instance;\n}\n</code></pre><p>有点乱，回到<code>RegistryProtocol</code>类，我们知道，在服务暴露阶段，会调用它的<code>export</code>方法，在这个方法里会完成服务的注册逻辑：</p>\n<pre><code>public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException {\n    //export invoker\n    final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); //完成真正的服务暴露逻辑：默认以netty创建server服务来处理远程调用，打算回头专门写一下dubbo使用netty的细节\n\n    //registry provider\n    final Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\n    final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\n    registry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n\n    // 订阅override数据\n    // FIXME 提供者订阅时，会影响同一JVM既暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。\n    final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl);\n    final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl);\n    overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);\n    registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);\n\n    //保证每次export都返回一个新的exporter实例\n    return new Exporter&lt;T&gt;() {\n        public Invoker&lt;T&gt; getInvoker() {\n            return exporter.getInvoker();\n        }\n        public void unexport() {\n            try {\n                exporter.unexport();\n            } catch (Throwable t) {\n                logger.warn(t.getMessage(), t);\n            }\n            try {\n                registry.unregister(registedProviderUrl);\n            } catch (Throwable t) {\n                logger.warn(t.getMessage(), t);\n            }\n            try {\n                overrideListeners.remove(overrideSubscribeUrl);\n                registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener);\n            } catch (Throwable t) {\n                logger.warn(t.getMessage(), t);\n            }\n        }\n    };\n}\n</code></pre><p>到这里，主线轮廓已经勾勒出来了，我们接下来看一下dubbo和zookeeper之间在服务注册阶段的通信细节，要从上面这个方法中的下面三行下手：</p>\n<pre><code>//registry provider\nfinal Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\nfinal URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\nregistry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n</code></pre><p>正如注释标明的，第一行会获取invoker中url指定的注册中心实例，我们的情况就是拿到<code>zookeeperRegistry</code>。第二行其实就是过滤掉url中的注册中心相关参数，以及过滤器，监控中心等参数，按照我们上面的例子，<code>registedProviderUrl</code>大概应该如下：</p>\n<pre><code>dubbo://192.168.153.1:20880/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.0&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.bid.BidService&amp;methods=throwNPE,bid&amp;optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;serialization=kryo&amp;side=provider&amp;timestamp=1422241023451\n</code></pre><p>我们主要看第三行，真正完成向zookeeper中注册的工作就是靠register方法完成的，先来看一下zookeeperRegistry的继承关系：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Ep8RFf0S/7imCY.png\" alt=\"\"></p>\n<p>真正声明register方法的是zookeeperRegistry的父类：FailbackRegistry，从名字就能直观的看出它的作用，主要就是负责注册中心失效重试逻辑的。我们不打算在这里展开说这个话题。好吧，我们继续看zookeeperRegistry的doRegister方法（FailbackRegistry的register方法会调用zookeeperRegistry的doRegister的方法）：</p>\n<pre><code>protected void doRegister(URL url) {\n    try {\n        zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true));     //参见：http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm\n    } catch (Throwable e) {\n        throw new RpcException(&quot;Failed to register &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e);\n    }\n}\n</code></pre><p>到这里就已经可以告一段落了，需要叮嘱的是<code>toUrlPath</code>方法，它的作用就是把url格式化成最终存储在zookeeper中的数据格式，尤其要注意<code>category</code>参数，它表示注册类型，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Ep8ZmnoV/RmZZL.jpg\" alt=\"\"></p>\n<p>在我们的例子中，最终这次注册就会在对应serverInterface下的providers下创建一个url节点。</p>\n<h2 id=\"subscribe\"><a href=\"#subscribe\" class=\"headerlink\" title=\"subscribe\"></a>subscribe</h2><p>我们再来看看服务消费方对所引用服务的订阅细节，与服务提供方大致一样（忽略集群逻辑），只不过到达<code>RegistryProtocol</code>后调用的是<code>refer</code>方法：</p>\n<pre><code>public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException {\n    //处理注册中心的协议，用url中registry参数的值作为真实的注册中心协议\n    url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY);\n    Registry registry = registryFactory.getRegistry(url);   //拿到真正的注册中心实例，我们的例子中就是zookeeperRegistry\n\n    if (RegistryService.class.equals(type)) {   //todo 不太理解，貌似是注册中心服务本身的暴露\n        return proxyFactory.getInvoker((T) registry, type, url);\n    }\n\n    //分组聚合处理，http://alibaba.github.io/dubbo-doc-static/Merge+By+Group-zh.htm\n    // group=&quot;a,b&quot; or group=&quot;*&quot;\n    Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY));\n    String group = qs.get(Constants.GROUP_KEY);\n    if (group != null &amp;&amp; group.length() &gt; 0 ) {\n        if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1\n                || &quot;*&quot;.equals( group ) ) {\n            return doRefer( getMergeableCluster(), registry, type, url );\n        }\n    }\n\n    return doRefer(cluster, registry, type, url);\n}\n</code></pre><p>真正完成订阅是在<code>doRefer</code>方法中：</p>\n<pre><code> private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) {\n    RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url);   //这个directory把同一个serviceInterface对应的多个invoker管理起来提供概念上的化多为单一，供路由、均衡算法等使用\n    directory.setRegistry(registry);\n    directory.setProtocol(protocol);\n    URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters());\n\n    //注册自己\n    if (! Constants.ANY_VALUE.equals(url.getServiceInterface())\n            &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) {\n        registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY,\n                Constants.CHECK_KEY, String.valueOf(false)));\n    }\n\n    //订阅目标服务提供方\n    directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, \n            Constants.PROVIDERS_CATEGORY \n            + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY \n            + &quot;,&quot; + Constants.ROUTERS_CATEGORY));\n\n    return cluster.join(directory); //合并所有相同invoker\n}\n</code></pre><p>可见代码和上面给的那个图很吻合，服务消费方不仅会订阅相关的服务，也会注册自身供其他层使用（服务治理）。特别要注意的是订阅时，同时订阅了三个分类类型：<strong>providers，routers，configurators</strong>。目前我们不打算说另外两种类型的意义（因为我也不清楚），后面分析道路由和集群的时候再来扯淡。</p>\n<p>继续深挖dubbo中服务消费方订阅服务的细节，上面方法中最终把订阅细节委托给<code>RegistryDirectory.subscribe</code>方法，注意，这个方法接受的参数，此时的url已经把<code>category</code>设置为<code>providers，routers，configurators</code>：</p>\n<pre><code>public void subscribe(URL url) {\n    setConsumerUrl(url);\n    registry.subscribe(url, this);\n}\n</code></pre><p>这里<code>registry</code>就是zookeeperRegistry，这在<code>doRefer</code>方法可以看到明确的注入。然后和注册服务时一样，订阅会先由<code>FailbackRegistry</code>完成失效重试的处理，最终会交给<code>zookeeperRegistry.doSubscribe</code>方法。zookeeperRegistry实例拥有ZookeeperClient类型引用，该类型对象封装了和zookeeper通信的逻辑（默认是使用zkclient客户端），这里需要注意的一点，小爷我就被这里的一个数据结构卡住了一整天：</p>\n<pre><code>private final ConcurrentMap&lt;URL, ConcurrentMap&lt;NotifyListener, ChildListener&gt;&gt; zkListeners = new ConcurrentHashMap&lt;URL, ConcurrentMap&lt;NotifyListener, ChildListener&gt;&gt;();\n</code></pre><p>一开始很不理解，为何要在url和NotifyListener之间再搞一个ChildListener接口出来，后来反复查看zkclient的文档说明和dubbo注册中心的设计，才悟出来点门道。这个<strong>ChildListener接口用于把zkclient的事件（IZkChildListener）转换到registry事件（NotifyListener）</strong>。这么做的深意不是特别的理解，可能是因为我并没有太多zookeeper的使用经验导致的，这里的做法<strong>可以更好的把zkclient的api和dubbo真身的注册中心逻辑分离开</strong>，毕竟dubbo除了zkclient以外还可以选择curator。从dubbo源码中可以看出，架构师和开发人员对面向对象和设计模式的理解非常的深刻，合理的运用继承和组合，打造了非常灵活的一套系统，保证概念统一的前提下展现了非常强大的多态性，感叹！</p>\n<p>这样走一圈下来，关于服务订阅的大致流程就描述清楚了，部分问题需要留到未来再解决了。</p>\n<h2 id=\"notify\"><a href=\"#notify\" class=\"headerlink\" title=\"notify\"></a>notify</h2><p>最后看一下注册推送细节，在订阅时你会注意到，订阅真正操作的是用<code>RegistryDirectory</code>类型封装过的对象，这个类型实现了一个接口<code>NotifyListener</code>（前面我们已经提到这个接口了），该接口用于描述支持推送通知逻辑：</p>\n<pre><code>public interface NotifyListener {\n\n    /**\n     * 当收到服务变更通知时触发。\n     * \n     * 通知需处理契约：&lt;br&gt;\n     * 1. 总是以服务接口和数据类型为维度全量通知，即不会通知一个服务的同类型的部分数据，用户不需要对比上一次通知结果。&lt;br&gt;\n     * 2. 订阅时的第一次通知，必须是一个服务的所有类型数据的全量通知。&lt;br&gt;\n     * 3. 中途变更时，允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。&lt;br&gt;\n     * 4. 如果一种类型的数据为空，需通知一个empty协议并带category参数的标识性URL数据。&lt;br&gt;\n     * 5. 通知者(即注册中心实现)需保证通知的顺序，比如：单线程推送，队列串行化，带版本对比。&lt;br&gt;\n     * \n     * @param urls 已注册信息列表，总不为空，含义同{@link com.alibaba.dubbo.registry.RegistryService#lookup(URL)}的返回值。\n     */\n    void notify(List&lt;URL&gt; urls);\n}\n</code></pre><p>前面提到了ChildListener接口，dubbo靠它把zkclient的事件转换成自己的事件类型，如果从代码上来看确实有点绕，事件的流程我手绘了一下：</p>\n<p><a href=\"http://pic.yupoo.com/kazaff/Epc4RElK/TJLi1.png\" target=\"_blank\" rel=\"external\"><img src=\"http://pic.yupoo.com/kazaff/Epc4RElK/medish.jpg\" alt=\"\"></a></p>\n<p>我们主要看一下RegistryDirectory的notify方法：</p>\n<pre><code>public synchronized void notify(List&lt;URL&gt; urls) {\n    List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;();\n    List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;();\n    List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;();\n    for (URL url : urls) {\n        String protocol = url.getProtocol();\n        //允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。\n        String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);\n        if (Constants.ROUTERS_CATEGORY.equals(category) \n                || Constants.ROUTE_PROTOCOL.equals(protocol)) {\n            routerUrls.add(url);\n        } else if (Constants.CONFIGURATORS_CATEGORY.equals(category) \n                || Constants.OVERRIDE_PROTOCOL.equals(protocol)) {\n            configuratorUrls.add(url);\n        } else if (Constants.PROVIDERS_CATEGORY.equals(category)) {\n            invokerUrls.add(url);\n        } else {\n            logger.warn(&quot;Unsupported category &quot; + category + &quot; in notified url: &quot; + url + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost());\n        }\n    }\n    // configurators 更新缓存的服务提供方配置规则\n    if (configuratorUrls != null &amp;&amp; configuratorUrls.size() &gt;0 ){\n        this.configurators = toConfigurators(configuratorUrls);\n    }\n    // routers  更新缓存的路由配置规则\n    if (routerUrls != null &amp;&amp; routerUrls.size() &gt;0 ){\n        List&lt;Router&gt; routers = toRouters(routerUrls);\n        if(routers != null){ // null - do nothing\n            setRouters(routers);\n        }\n    }\n\n    // 合并override参数\n    List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference\n    this.overrideDirectoryUrl = directoryUrl;\n    if (localConfigurators != null &amp;&amp; localConfigurators.size() &gt; 0) {\n        for (Configurator configurator : localConfigurators) {\n            this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);\n        }\n    }\n\n    // providers\n    refreshInvoker(invokerUrls);\n}\n</code></pre><p>dubbo提供了强大的服务治理功能，所以这里在每次消费方接受到注册中心的通知后，大概会做下面这些事儿：</p>\n<ul>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm\" target=\"_blank\" rel=\"external\">更新服务提供方配置规则</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm\" target=\"_blank\" rel=\"external\">更新路由规则</a></li>\n<li>重建invoker实例</li>\n</ul>\n<p>前两件事儿我们放在分析路由，过滤器，集群的时候再讲，我们这里主要看dubbo如何“重建invoker实例”，也就是最后一行代码调用的方法<code>refreshInvoker</code>：</p>\n<pre><code>private void refreshInvoker(List&lt;URL&gt; invokerUrls){\n    if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null\n            &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) { //如果传入的参数只包含一个empty://协议的url，表明禁用当前服务\n        this.forbidden = true; // 禁止访问\n        this.methodInvokerMap = null; // 置空列表\n        destroyAllInvokers(); // 关闭所有Invoker\n    } else {\n        this.forbidden = false; // 允许访问\n        Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference\n\n        if (invokerUrls.size() == 0 &amp;&amp; this.cachedInvokerUrls != null){ //如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用\n            invokerUrls.addAll(this.cachedInvokerUrls);\n        } else {\n            this.cachedInvokerUrls = new HashSet&lt;URL&gt;();\n            this.cachedInvokerUrls.addAll(invokerUrls);//缓存invokerUrls列表，便于交叉对比\n        }\n\n        if (invokerUrls.size() ==0 ){\n            return;\n        }\n\n        Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls) ;// 将URL列表转成Invoker列表\n        Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表\n\n        // state change\n        //如果计算错误，则不进行处理.\n        if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0 ){\n            logger.error(new IllegalStateException(&quot;urls to invokers error .invokerUrls.size :&quot;+invokerUrls.size() + &quot;, invoker.size :0. urls :&quot;+invokerUrls.toString()));\n            return ;\n        }\n\n        this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap;\n        this.urlInvokerMap = newUrlInvokerMap;\n\n        try{\n            destroyUnusedInvokers(oldUrlInvokerMap,newUrlInvokerMap); // 关闭未使用的Invoker\n        }catch (Exception e) {\n            logger.warn(&quot;destroyUnusedInvokers error. &quot;, e);\n        }\n    }\n}\n</code></pre><p>好吧，到这里我们已经完成了服务通知的业务逻辑，有兴趣的童鞋可以深究一下<code>toInvokers</code>方法，它又会走一遍<strong>url-&gt;invoker</strong>的逻辑（服务引用）。</p>\n<p>那么，就先到这里吧，再会~</p>\n","excerpt":"<p>对于分布式服务架构，解决服务的发现问题，引入了注册中心中间件，从而很好的解决了服务双方（消费方和提供方）的直接依赖问题。这种解耦的意义是非凡的，不仅在程序运行时保证了灵活性，在开发阶段也使得快速迭代成为了可能，甚至在运维层面也提供了非常好的自由度。<br>","more":"<br>夸了这么多，但要实现一个完美的注册中心系统却不是一件那么容易的事儿，你必须时刻注意关注它的可用性（包括<strong>稳定，实时和高效</strong>），这一点在任何一款分布式系统中都是件很复杂的事儿。当然这篇文章并不是打算摆平这么个庞然大物，我们只是从dubbo和zookeeper之间的关系来了解一下在dubbo架构中注册中心的相关知识：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EogBsej0/gvnAo.jpg\" alt=\"\"></p>\n<p>上图是官方给出的一张描述服务提供方、服务消费方和注册中心的关系图，其实dubbo提供多种注册中心实现，不过常用的就是zookeeper，我们也就拿它来当例子来分析。从图中可见，<strong>消费方远程调用服务方是不通过注册中心的</strong>，这有效的降低了注册中心的负载，也不会存在明显的单点瓶颈（尽管可以搭建注册中心的集群，但每次调用都走注册中心的话肯定对性能产生较大的伤害）。</p>\n<p>官方提供的规则是：</p>\n<ul>\n<li>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小；</li>\n<li>注册中心，服务提供者，服务消费者三者之间均为长连接；</li>\n<li>注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者；</li>\n<li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者；</li>\n<li>注册中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表；</li>\n<li>注册中心是可选的，服务消费者可以直连服务提供者；</li>\n<li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台。</li>\n</ul>\n<p>好啦，更多的理论我就不转载了，官方已经描述的非常详细了，我们按照老套路，从代码级别看一下dubbo到底是怎样实现的。</p>\n<h2 id=\"register\"><a href=\"#register\" class=\"headerlink\" title=\"register\"></a>register</h2><p>我们需要承接之前的<a href=\"http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/\">文章</a>里的例子，从拿到需要暴露成服务的url开始：</p>\n<pre><code>registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&amp;dubbo=2.0.0&amp;export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;registry=zookeeper&amp;timestamp=1422240274186\n</code></pre><p>以这个url为基准暴露服务的话，dubbo会首先会根据指定协议（<code>registry</code>）拿到对应的protocol（<code>RegistryProtocol</code>），这部分是怎么做到的呢？还是之前通过IDE拿到的dubbo动态创建的protocol自适应扩展点，我们重点看<code>export</code>方法：</p>\n<pre><code>package com.alibaba.dubbo.rpc;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\n    ......\n\n    public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n        if (arg0 == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;);\n\n        if (arg0.getUrl() == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );    //注意这句，根据我们的例子，extName=registry\n\n        if(extName == null) \n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n        com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);    //根据扩展点加载规则，最终拿到RegistryProtocol实例。\n\n        return extension.export(arg0);\n    }\n\n    ......\n}\n</code></pre><p>我们需要注意<code>RegistryProtocol</code>的私有属性：</p>\n<pre><code>private Protocol protocol;\n\npublic void setProtocol(Protocol protocol) {\n    this.protocol = protocol;   //由SPI机制为其赋予一个protocol的自适应扩展点（动态创建的）\n}\n</code></pre><p>这个属性真正被赋值的地方是在SPI机制中为扩展点注入的阶段（<code>injectExtension</code>方法）：</p>\n<pre><code>private T injectExtension(T instance) {\n    try {\n        if (objectFactory != null) {\n            for (Method method : instance.getClass().getMethods()) {\n                if (method.getName().startsWith(&quot;set&quot;)\n                        &amp;&amp; method.getParameterTypes().length == 1\n                        &amp;&amp; Modifier.isPublic(method.getModifiers())) {\n                    Class&lt;?&gt; pt = method.getParameterTypes()[0];\n                    try {\n                        String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : &quot;&quot;;\n                        Object object = objectFactory.getExtension(pt, property);    //注意这里，我们的例子中，这个object会是SPI动态创建的自适应扩展点实例：Protocol$Adpative\n                        if (object != null) {\n                            method.invoke(instance, object);\n                        }\n                    } catch (Exception e) {\n                        logger.error(&quot;fail to inject via method &quot; + method.getName()\n                                + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e);\n                    }\n                }\n            }\n        }\n    } catch (Exception e) {\n        logger.error(e.getMessage(), e);\n    }\n    return instance;\n}\n</code></pre><p>有点乱，回到<code>RegistryProtocol</code>类，我们知道，在服务暴露阶段，会调用它的<code>export</code>方法，在这个方法里会完成服务的注册逻辑：</p>\n<pre><code>public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException {\n    //export invoker\n    final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); //完成真正的服务暴露逻辑：默认以netty创建server服务来处理远程调用，打算回头专门写一下dubbo使用netty的细节\n\n    //registry provider\n    final Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\n    final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\n    registry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n\n    // 订阅override数据\n    // FIXME 提供者订阅时，会影响同一JVM既暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。\n    final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl);\n    final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl);\n    overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);\n    registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);\n\n    //保证每次export都返回一个新的exporter实例\n    return new Exporter&lt;T&gt;() {\n        public Invoker&lt;T&gt; getInvoker() {\n            return exporter.getInvoker();\n        }\n        public void unexport() {\n            try {\n                exporter.unexport();\n            } catch (Throwable t) {\n                logger.warn(t.getMessage(), t);\n            }\n            try {\n                registry.unregister(registedProviderUrl);\n            } catch (Throwable t) {\n                logger.warn(t.getMessage(), t);\n            }\n            try {\n                overrideListeners.remove(overrideSubscribeUrl);\n                registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener);\n            } catch (Throwable t) {\n                logger.warn(t.getMessage(), t);\n            }\n        }\n    };\n}\n</code></pre><p>到这里，主线轮廓已经勾勒出来了，我们接下来看一下dubbo和zookeeper之间在服务注册阶段的通信细节，要从上面这个方法中的下面三行下手：</p>\n<pre><code>//registry provider\nfinal Registry registry = getRegistry(originInvoker);  //根据url参数获取对应的注册中心服务实例，这里就是ZookeeperRegistry\n\nfinal URL registedProviderUrl = getRegistedProviderUrl(originInvoker);\nregistry.register(registedProviderUrl); //向注册中心注册当前暴露的服务的URL\n</code></pre><p>正如注释标明的，第一行会获取invoker中url指定的注册中心实例，我们的情况就是拿到<code>zookeeperRegistry</code>。第二行其实就是过滤掉url中的注册中心相关参数，以及过滤器，监控中心等参数，按照我们上面的例子，<code>registedProviderUrl</code>大概应该如下：</p>\n<pre><code>dubbo://192.168.153.1:20880/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.0&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.bid.BidService&amp;methods=throwNPE,bid&amp;optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;serialization=kryo&amp;side=provider&amp;timestamp=1422241023451\n</code></pre><p>我们主要看第三行，真正完成向zookeeper中注册的工作就是靠register方法完成的，先来看一下zookeeperRegistry的继承关系：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Ep8RFf0S/7imCY.png\" alt=\"\"></p>\n<p>真正声明register方法的是zookeeperRegistry的父类：FailbackRegistry，从名字就能直观的看出它的作用，主要就是负责注册中心失效重试逻辑的。我们不打算在这里展开说这个话题。好吧，我们继续看zookeeperRegistry的doRegister方法（FailbackRegistry的register方法会调用zookeeperRegistry的doRegister的方法）：</p>\n<pre><code>protected void doRegister(URL url) {\n    try {\n        zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true));     //参见：http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm\n    } catch (Throwable e) {\n        throw new RpcException(&quot;Failed to register &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e);\n    }\n}\n</code></pre><p>到这里就已经可以告一段落了，需要叮嘱的是<code>toUrlPath</code>方法，它的作用就是把url格式化成最终存储在zookeeper中的数据格式，尤其要注意<code>category</code>参数，它表示注册类型，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Ep8ZmnoV/RmZZL.jpg\" alt=\"\"></p>\n<p>在我们的例子中，最终这次注册就会在对应serverInterface下的providers下创建一个url节点。</p>\n<h2 id=\"subscribe\"><a href=\"#subscribe\" class=\"headerlink\" title=\"subscribe\"></a>subscribe</h2><p>我们再来看看服务消费方对所引用服务的订阅细节，与服务提供方大致一样（忽略集群逻辑），只不过到达<code>RegistryProtocol</code>后调用的是<code>refer</code>方法：</p>\n<pre><code>public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException {\n    //处理注册中心的协议，用url中registry参数的值作为真实的注册中心协议\n    url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY);\n    Registry registry = registryFactory.getRegistry(url);   //拿到真正的注册中心实例，我们的例子中就是zookeeperRegistry\n\n    if (RegistryService.class.equals(type)) {   //todo 不太理解，貌似是注册中心服务本身的暴露\n        return proxyFactory.getInvoker((T) registry, type, url);\n    }\n\n    //分组聚合处理，http://alibaba.github.io/dubbo-doc-static/Merge+By+Group-zh.htm\n    // group=&quot;a,b&quot; or group=&quot;*&quot;\n    Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY));\n    String group = qs.get(Constants.GROUP_KEY);\n    if (group != null &amp;&amp; group.length() &gt; 0 ) {\n        if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1\n                || &quot;*&quot;.equals( group ) ) {\n            return doRefer( getMergeableCluster(), registry, type, url );\n        }\n    }\n\n    return doRefer(cluster, registry, type, url);\n}\n</code></pre><p>真正完成订阅是在<code>doRefer</code>方法中：</p>\n<pre><code> private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) {\n    RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url);   //这个directory把同一个serviceInterface对应的多个invoker管理起来提供概念上的化多为单一，供路由、均衡算法等使用\n    directory.setRegistry(registry);\n    directory.setProtocol(protocol);\n    URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters());\n\n    //注册自己\n    if (! Constants.ANY_VALUE.equals(url.getServiceInterface())\n            &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) {\n        registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY,\n                Constants.CHECK_KEY, String.valueOf(false)));\n    }\n\n    //订阅目标服务提供方\n    directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, \n            Constants.PROVIDERS_CATEGORY \n            + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY \n            + &quot;,&quot; + Constants.ROUTERS_CATEGORY));\n\n    return cluster.join(directory); //合并所有相同invoker\n}\n</code></pre><p>可见代码和上面给的那个图很吻合，服务消费方不仅会订阅相关的服务，也会注册自身供其他层使用（服务治理）。特别要注意的是订阅时，同时订阅了三个分类类型：<strong>providers，routers，configurators</strong>。目前我们不打算说另外两种类型的意义（因为我也不清楚），后面分析道路由和集群的时候再来扯淡。</p>\n<p>继续深挖dubbo中服务消费方订阅服务的细节，上面方法中最终把订阅细节委托给<code>RegistryDirectory.subscribe</code>方法，注意，这个方法接受的参数，此时的url已经把<code>category</code>设置为<code>providers，routers，configurators</code>：</p>\n<pre><code>public void subscribe(URL url) {\n    setConsumerUrl(url);\n    registry.subscribe(url, this);\n}\n</code></pre><p>这里<code>registry</code>就是zookeeperRegistry，这在<code>doRefer</code>方法可以看到明确的注入。然后和注册服务时一样，订阅会先由<code>FailbackRegistry</code>完成失效重试的处理，最终会交给<code>zookeeperRegistry.doSubscribe</code>方法。zookeeperRegistry实例拥有ZookeeperClient类型引用，该类型对象封装了和zookeeper通信的逻辑（默认是使用zkclient客户端），这里需要注意的一点，小爷我就被这里的一个数据结构卡住了一整天：</p>\n<pre><code>private final ConcurrentMap&lt;URL, ConcurrentMap&lt;NotifyListener, ChildListener&gt;&gt; zkListeners = new ConcurrentHashMap&lt;URL, ConcurrentMap&lt;NotifyListener, ChildListener&gt;&gt;();\n</code></pre><p>一开始很不理解，为何要在url和NotifyListener之间再搞一个ChildListener接口出来，后来反复查看zkclient的文档说明和dubbo注册中心的设计，才悟出来点门道。这个<strong>ChildListener接口用于把zkclient的事件（IZkChildListener）转换到registry事件（NotifyListener）</strong>。这么做的深意不是特别的理解，可能是因为我并没有太多zookeeper的使用经验导致的，这里的做法<strong>可以更好的把zkclient的api和dubbo真身的注册中心逻辑分离开</strong>，毕竟dubbo除了zkclient以外还可以选择curator。从dubbo源码中可以看出，架构师和开发人员对面向对象和设计模式的理解非常的深刻，合理的运用继承和组合，打造了非常灵活的一套系统，保证概念统一的前提下展现了非常强大的多态性，感叹！</p>\n<p>这样走一圈下来，关于服务订阅的大致流程就描述清楚了，部分问题需要留到未来再解决了。</p>\n<h2 id=\"notify\"><a href=\"#notify\" class=\"headerlink\" title=\"notify\"></a>notify</h2><p>最后看一下注册推送细节，在订阅时你会注意到，订阅真正操作的是用<code>RegistryDirectory</code>类型封装过的对象，这个类型实现了一个接口<code>NotifyListener</code>（前面我们已经提到这个接口了），该接口用于描述支持推送通知逻辑：</p>\n<pre><code>public interface NotifyListener {\n\n    /**\n     * 当收到服务变更通知时触发。\n     * \n     * 通知需处理契约：&lt;br&gt;\n     * 1. 总是以服务接口和数据类型为维度全量通知，即不会通知一个服务的同类型的部分数据，用户不需要对比上一次通知结果。&lt;br&gt;\n     * 2. 订阅时的第一次通知，必须是一个服务的所有类型数据的全量通知。&lt;br&gt;\n     * 3. 中途变更时，允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。&lt;br&gt;\n     * 4. 如果一种类型的数据为空，需通知一个empty协议并带category参数的标识性URL数据。&lt;br&gt;\n     * 5. 通知者(即注册中心实现)需保证通知的顺序，比如：单线程推送，队列串行化，带版本对比。&lt;br&gt;\n     * \n     * @param urls 已注册信息列表，总不为空，含义同{@link com.alibaba.dubbo.registry.RegistryService#lookup(URL)}的返回值。\n     */\n    void notify(List&lt;URL&gt; urls);\n}\n</code></pre><p>前面提到了ChildListener接口，dubbo靠它把zkclient的事件转换成自己的事件类型，如果从代码上来看确实有点绕，事件的流程我手绘了一下：</p>\n<p><a href=\"http://pic.yupoo.com/kazaff/Epc4RElK/TJLi1.png\"><img src=\"http://pic.yupoo.com/kazaff/Epc4RElK/medish.jpg\" alt=\"\"></a></p>\n<p>我们主要看一下RegistryDirectory的notify方法：</p>\n<pre><code>public synchronized void notify(List&lt;URL&gt; urls) {\n    List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;();\n    List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;();\n    List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;();\n    for (URL url : urls) {\n        String protocol = url.getProtocol();\n        //允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。\n        String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);\n        if (Constants.ROUTERS_CATEGORY.equals(category) \n                || Constants.ROUTE_PROTOCOL.equals(protocol)) {\n            routerUrls.add(url);\n        } else if (Constants.CONFIGURATORS_CATEGORY.equals(category) \n                || Constants.OVERRIDE_PROTOCOL.equals(protocol)) {\n            configuratorUrls.add(url);\n        } else if (Constants.PROVIDERS_CATEGORY.equals(category)) {\n            invokerUrls.add(url);\n        } else {\n            logger.warn(&quot;Unsupported category &quot; + category + &quot; in notified url: &quot; + url + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost());\n        }\n    }\n    // configurators 更新缓存的服务提供方配置规则\n    if (configuratorUrls != null &amp;&amp; configuratorUrls.size() &gt;0 ){\n        this.configurators = toConfigurators(configuratorUrls);\n    }\n    // routers  更新缓存的路由配置规则\n    if (routerUrls != null &amp;&amp; routerUrls.size() &gt;0 ){\n        List&lt;Router&gt; routers = toRouters(routerUrls);\n        if(routers != null){ // null - do nothing\n            setRouters(routers);\n        }\n    }\n\n    // 合并override参数\n    List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference\n    this.overrideDirectoryUrl = directoryUrl;\n    if (localConfigurators != null &amp;&amp; localConfigurators.size() &gt; 0) {\n        for (Configurator configurator : localConfigurators) {\n            this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);\n        }\n    }\n\n    // providers\n    refreshInvoker(invokerUrls);\n}\n</code></pre><p>dubbo提供了强大的服务治理功能，所以这里在每次消费方接受到注册中心的通知后，大概会做下面这些事儿：</p>\n<ul>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Configurator+Rule-zh.htm\">更新服务提供方配置规则</a></li>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Router+Rule-zh.htm\">更新路由规则</a></li>\n<li>重建invoker实例</li>\n</ul>\n<p>前两件事儿我们放在分析路由，过滤器，集群的时候再讲，我们这里主要看dubbo如何“重建invoker实例”，也就是最后一行代码调用的方法<code>refreshInvoker</code>：</p>\n<pre><code>private void refreshInvoker(List&lt;URL&gt; invokerUrls){\n    if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null\n            &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) { //如果传入的参数只包含一个empty://协议的url，表明禁用当前服务\n        this.forbidden = true; // 禁止访问\n        this.methodInvokerMap = null; // 置空列表\n        destroyAllInvokers(); // 关闭所有Invoker\n    } else {\n        this.forbidden = false; // 允许访问\n        Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference\n\n        if (invokerUrls.size() == 0 &amp;&amp; this.cachedInvokerUrls != null){ //如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用\n            invokerUrls.addAll(this.cachedInvokerUrls);\n        } else {\n            this.cachedInvokerUrls = new HashSet&lt;URL&gt;();\n            this.cachedInvokerUrls.addAll(invokerUrls);//缓存invokerUrls列表，便于交叉对比\n        }\n\n        if (invokerUrls.size() ==0 ){\n            return;\n        }\n\n        Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls) ;// 将URL列表转成Invoker列表\n        Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表\n\n        // state change\n        //如果计算错误，则不进行处理.\n        if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0 ){\n            logger.error(new IllegalStateException(&quot;urls to invokers error .invokerUrls.size :&quot;+invokerUrls.size() + &quot;, invoker.size :0. urls :&quot;+invokerUrls.toString()));\n            return ;\n        }\n\n        this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap;\n        this.urlInvokerMap = newUrlInvokerMap;\n\n        try{\n            destroyUnusedInvokers(oldUrlInvokerMap,newUrlInvokerMap); // 关闭未使用的Invoker\n        }catch (Exception e) {\n            logger.warn(&quot;destroyUnusedInvokers error. &quot;, e);\n        }\n    }\n}\n</code></pre><p>好吧，到这里我们已经完成了服务通知的业务逻辑，有兴趣的童鞋可以深究一下<code>toInvokers</code>方法，它又会走一遍<strong>url-&gt;invoker</strong>的逻辑（服务引用）。</p>\n<p>那么，就先到这里吧，再会~</p>"},{"title":"dubbo的拦截器和监听器","date":"2015-02-06T07:54:30.000Z","_content":"\n\n今天要聊一个可能被其他dubbo源码研究的童鞋容易忽略的话题：Filter和Listener。\n<!-- more -->\n我们先来看一下这两个概念的官方手册：\n\n- [拦截器](http://alibaba.github.io/dubbo-doc-static/Filter+SPI-zh.htm)\n- 监听器：[引用监听器](http://alibaba.github.io/dubbo-doc-static/InvokerListener+SPI-zh.htm)和[暴露监听器](http://alibaba.github.io/dubbo-doc-static/ExporterListener+SPI-zh.htm)\n\n\n老实说，依赖之前的源码分析经验，导致我饶了很大的弯路，一直找不到`filter`和`listener`被使用的位置。看过前几篇文章的朋友应该也有这个疑惑，为什么按照url参数去匹配框架的执行流程，死活找不到dubbo注入拦截器和监听器的位置呢？\n\n\tReferenceConfig -->  RegistryProtocol --> DubboProtocol  -->  invoker  -->  exporter\n\n按照这个调用流程，没错啊，可每一个环节都没有使用`filter`和`listener`属性的痕迹，有点抓瞎了啊。要说用好IDE确实很重要啊，光靠脑子想真的很伤身，下面来看一下谜底。\n\n\n先来回忆一下dubbo的SPI机制，根据接口类型，dubbo会去读取并解析对应的配置文件，从中拿到对应的扩展点实现，好，我们先来看一下`Protocol`接口对应的配置文件：\n\n\tregistry=com.alibaba.dubbo.registry.integration.RegistryProtocol\n\tdubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol\t\t\t\n\tfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper\t\t\t#注意这一行\n\tlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper\t\t#注意这一行\n\tmock=com.alibaba.dubbo.rpc.support.MockProtocol\n\tinjvm=com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocol\n\trmi=com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocol\n\thessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocol\n\tcom.alibaba.dubbo.rpc.protocol.http.HttpProtocol\n\tcom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocol\n\tthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocol\n\tmemcached=com.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocol\n\tredis=com.alibaba.dubbo.rpc.protocol.redis.RedisProtocol\n\trest=com.alibaba.dubbo.rpc.protocol.rest.RestProtocol\n\n\n我们已经找到了`filter`和`listener`对应的扩展点了。接下来看一下它们是怎么一步一步的被注入到上面的流程里的。\n\n在`ReferenceConfig`类中我们会引用和暴露对应的服务，我们以服务引用为场景来分析：\n\n\tget()  -->  init()  -->   createProxy()\n\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t+--->  invoker = refprotocol.refer(interfaceClass, urls.get(0));\n\n\n注意上面提到的这一行代码，这里的`refprotocol`是引用的`Protocol$Adpative`，这个类是dubbo的SPI机制动态创建的自适应扩展点，我们在之前的文章中已经介绍过，看一下它的`refer`方法细节：\n\n\tpublic com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n\t\tif (arg1 == null)\n\t\t\tthrow new IllegalArgumentException(\"url == null\");\n\t\t\n\t\tcom.alibaba.dubbo.common.URL url = arg1;\n\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\n\t\t\n\t\tif(extName == null) \n\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\n\t\t//注意这一行，根据url的协议名称选择对应的扩展点实现\n\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\t\t\n\t\treturn extension.refer(arg0, arg1);\n\t}\n\n乍一看，并没有感觉有什么蹊跷，不过在单步调试中就会出现\"诡异\"现象（由于该类是动态创建的，所以该方法并不会被单步到，所以为分析带来了一定的干扰），我们得再往回倒一下，之前在[dubbo中SPI的基础](http://blog.kazaff.me/2015/01/15/dubbo%E4%B8%ADSPI%E7%9A%84%E5%9F%BA%E7%A1%80--Cooma%E5%BE%AE%E5%AE%B9%E5%99%A8/)中曾经分析过`ExtensionLoader`的源码，但是当时由于了解的不够确实忽略了一些细节。\n\n我们再来看一下它的执行流程：\n\n\tgetExtension()  -->  createExtension()\n\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t+-->  \t......\n\t\t\t\t\t\t\t\t\t\tSet<Class<?>> wrapperClasses = cachedWrapperClasses;\n\t\t\t\t\t\t\t            if (wrapperClasses != null && wrapperClasses.size() > 0) {\n\t\t\t\t\t\t\t                for (Class<?> wrapperClass : wrapperClasses) {  //装饰器模式\n\t\t\t\t\t\t\t                    instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));\n\t\t\t\t\t\t\t                }\n\t\t\t\t\t\t\t            }\n\t\t\t\t\t\t\t\t\t\t......\n\n\n一看到这行代码，就知道关键点在这里，这种写法刚好就是和常见的拦截器和监听器的实现方法吻合，而且事实证明也确实是在这个地方完成的注入，那么我们就需要看一下这个`cachedWrapperClasses`到到底存了什么？\n\n我们最后看一下`ExtensionLoader.loadFile`方法，它是负责解析我们开头提到的那个SPI扩展点配置文件的，它会依次扫描配置文件的每一行，然后根据配置内容完成等号两边的键值对应关系，例如：\n\n\ttest=com.alibaba.dubbo.rpc.filter.TestFilter\n\n`loadFile`的任务就是把`test`和解析过以后的`TestFilter`类关系对应上，供以后的`getExtension`查找使用。注意看其中的这几行代码：\n\n\t......\n\t clazz.getConstructor(type); //判断是否为wrapper实现\n    Set<Class<?>> wrappers = cachedWrapperClasses;\n    if (wrappers == null) {\n        cachedWrapperClasses = new ConcurrentHashSet<Class<?>>();\n        wrappers = cachedWrapperClasses;\n    }\n    wrappers.add(clazz);\n\t......\n\n这里就完成了`cachedWrapperClasses`的初始化，它根据查看配置文件中定义的扩展点实现是否包含一个带有当前类型的构造方法为条件，确定哪些是wrapper，这样我们就可以发现：\n\n\tfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper\n\tlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper\n\n这两行命中了。这也是之后在真正获取`protocol`扩展点时会动态注入的两个重要包装类，前者完成拦截器，后者完成监听器。\n\n\n\n至于拦截器和监听器的使用方法，我实在不知道除了官方提到的内容以外还有什么好补充的了，那就写到这里吧~\n","source":"_posts/dubbo的拦截器和监听器.md","raw":"title: dubbo的拦截器和监听器\ndate: 2015-02-06 15:54:30\ntags:\n- dubbo\n- dubbox\n- soa\n- 拦截器\n- 监听器\n- SPI\n\ncategories: j2ee\n---\n\n\n今天要聊一个可能被其他dubbo源码研究的童鞋容易忽略的话题：Filter和Listener。\n<!-- more -->\n我们先来看一下这两个概念的官方手册：\n\n- [拦截器](http://alibaba.github.io/dubbo-doc-static/Filter+SPI-zh.htm)\n- 监听器：[引用监听器](http://alibaba.github.io/dubbo-doc-static/InvokerListener+SPI-zh.htm)和[暴露监听器](http://alibaba.github.io/dubbo-doc-static/ExporterListener+SPI-zh.htm)\n\n\n老实说，依赖之前的源码分析经验，导致我饶了很大的弯路，一直找不到`filter`和`listener`被使用的位置。看过前几篇文章的朋友应该也有这个疑惑，为什么按照url参数去匹配框架的执行流程，死活找不到dubbo注入拦截器和监听器的位置呢？\n\n\tReferenceConfig -->  RegistryProtocol --> DubboProtocol  -->  invoker  -->  exporter\n\n按照这个调用流程，没错啊，可每一个环节都没有使用`filter`和`listener`属性的痕迹，有点抓瞎了啊。要说用好IDE确实很重要啊，光靠脑子想真的很伤身，下面来看一下谜底。\n\n\n先来回忆一下dubbo的SPI机制，根据接口类型，dubbo会去读取并解析对应的配置文件，从中拿到对应的扩展点实现，好，我们先来看一下`Protocol`接口对应的配置文件：\n\n\tregistry=com.alibaba.dubbo.registry.integration.RegistryProtocol\n\tdubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol\t\t\t\n\tfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper\t\t\t#注意这一行\n\tlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper\t\t#注意这一行\n\tmock=com.alibaba.dubbo.rpc.support.MockProtocol\n\tinjvm=com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocol\n\trmi=com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocol\n\thessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocol\n\tcom.alibaba.dubbo.rpc.protocol.http.HttpProtocol\n\tcom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocol\n\tthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocol\n\tmemcached=com.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocol\n\tredis=com.alibaba.dubbo.rpc.protocol.redis.RedisProtocol\n\trest=com.alibaba.dubbo.rpc.protocol.rest.RestProtocol\n\n\n我们已经找到了`filter`和`listener`对应的扩展点了。接下来看一下它们是怎么一步一步的被注入到上面的流程里的。\n\n在`ReferenceConfig`类中我们会引用和暴露对应的服务，我们以服务引用为场景来分析：\n\n\tget()  -->  init()  -->   createProxy()\n\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t+--->  invoker = refprotocol.refer(interfaceClass, urls.get(0));\n\n\n注意上面提到的这一行代码，这里的`refprotocol`是引用的`Protocol$Adpative`，这个类是dubbo的SPI机制动态创建的自适应扩展点，我们在之前的文章中已经介绍过，看一下它的`refer`方法细节：\n\n\tpublic com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n\t\tif (arg1 == null)\n\t\t\tthrow new IllegalArgumentException(\"url == null\");\n\t\t\n\t\tcom.alibaba.dubbo.common.URL url = arg1;\n\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\n\t\t\n\t\tif(extName == null) \n\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\n\t\t//注意这一行，根据url的协议名称选择对应的扩展点实现\n\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\t\t\n\t\treturn extension.refer(arg0, arg1);\n\t}\n\n乍一看，并没有感觉有什么蹊跷，不过在单步调试中就会出现\"诡异\"现象（由于该类是动态创建的，所以该方法并不会被单步到，所以为分析带来了一定的干扰），我们得再往回倒一下，之前在[dubbo中SPI的基础](http://blog.kazaff.me/2015/01/15/dubbo%E4%B8%ADSPI%E7%9A%84%E5%9F%BA%E7%A1%80--Cooma%E5%BE%AE%E5%AE%B9%E5%99%A8/)中曾经分析过`ExtensionLoader`的源码，但是当时由于了解的不够确实忽略了一些细节。\n\n我们再来看一下它的执行流程：\n\n\tgetExtension()  -->  createExtension()\n\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t+-->  \t......\n\t\t\t\t\t\t\t\t\t\tSet<Class<?>> wrapperClasses = cachedWrapperClasses;\n\t\t\t\t\t\t\t            if (wrapperClasses != null && wrapperClasses.size() > 0) {\n\t\t\t\t\t\t\t                for (Class<?> wrapperClass : wrapperClasses) {  //装饰器模式\n\t\t\t\t\t\t\t                    instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));\n\t\t\t\t\t\t\t                }\n\t\t\t\t\t\t\t            }\n\t\t\t\t\t\t\t\t\t\t......\n\n\n一看到这行代码，就知道关键点在这里，这种写法刚好就是和常见的拦截器和监听器的实现方法吻合，而且事实证明也确实是在这个地方完成的注入，那么我们就需要看一下这个`cachedWrapperClasses`到到底存了什么？\n\n我们最后看一下`ExtensionLoader.loadFile`方法，它是负责解析我们开头提到的那个SPI扩展点配置文件的，它会依次扫描配置文件的每一行，然后根据配置内容完成等号两边的键值对应关系，例如：\n\n\ttest=com.alibaba.dubbo.rpc.filter.TestFilter\n\n`loadFile`的任务就是把`test`和解析过以后的`TestFilter`类关系对应上，供以后的`getExtension`查找使用。注意看其中的这几行代码：\n\n\t......\n\t clazz.getConstructor(type); //判断是否为wrapper实现\n    Set<Class<?>> wrappers = cachedWrapperClasses;\n    if (wrappers == null) {\n        cachedWrapperClasses = new ConcurrentHashSet<Class<?>>();\n        wrappers = cachedWrapperClasses;\n    }\n    wrappers.add(clazz);\n\t......\n\n这里就完成了`cachedWrapperClasses`的初始化，它根据查看配置文件中定义的扩展点实现是否包含一个带有当前类型的构造方法为条件，确定哪些是wrapper，这样我们就可以发现：\n\n\tfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper\n\tlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper\n\n这两行命中了。这也是之后在真正获取`protocol`扩展点时会动态注入的两个重要包装类，前者完成拦截器，后者完成监听器。\n\n\n\n至于拦截器和监听器的使用方法，我实在不知道除了官方提到的内容以外还有什么好补充的了，那就写到这里吧~\n","slug":"dubbo的拦截器和监听器","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yqo00aggtfysz1yll54","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天要聊一个可能被其他dubbo源码研究的童鞋容易忽略的话题：Filter和Listener。<br><a id=\"more\"></a><br>我们先来看一下这两个概念的官方手册：</p>\n<ul>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Filter+SPI-zh.htm\" target=\"_blank\" rel=\"external\">拦截器</a></li>\n<li>监听器：<a href=\"http://alibaba.github.io/dubbo-doc-static/InvokerListener+SPI-zh.htm\" target=\"_blank\" rel=\"external\">引用监听器</a>和<a href=\"http://alibaba.github.io/dubbo-doc-static/ExporterListener+SPI-zh.htm\" target=\"_blank\" rel=\"external\">暴露监听器</a></li>\n</ul>\n<p>老实说，依赖之前的源码分析经验，导致我饶了很大的弯路，一直找不到<code>filter</code>和<code>listener</code>被使用的位置。看过前几篇文章的朋友应该也有这个疑惑，为什么按照url参数去匹配框架的执行流程，死活找不到dubbo注入拦截器和监听器的位置呢？</p>\n<pre><code>ReferenceConfig --&gt;  RegistryProtocol --&gt; DubboProtocol  --&gt;  invoker  --&gt;  exporter\n</code></pre><p>按照这个调用流程，没错啊，可每一个环节都没有使用<code>filter</code>和<code>listener</code>属性的痕迹，有点抓瞎了啊。要说用好IDE确实很重要啊，光靠脑子想真的很伤身，下面来看一下谜底。</p>\n<p>先来回忆一下dubbo的SPI机制，根据接口类型，dubbo会去读取并解析对应的配置文件，从中拿到对应的扩展点实现，好，我们先来看一下<code>Protocol</code>接口对应的配置文件：</p>\n<pre><code>registry=com.alibaba.dubbo.registry.integration.RegistryProtocol\ndubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol            \nfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper            #注意这一行\nlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper        #注意这一行\nmock=com.alibaba.dubbo.rpc.support.MockProtocol\ninjvm=com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocol\nrmi=com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocol\nhessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocol\ncom.alibaba.dubbo.rpc.protocol.http.HttpProtocol\ncom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocol\nthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocol\nmemcached=com.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocol\nredis=com.alibaba.dubbo.rpc.protocol.redis.RedisProtocol\nrest=com.alibaba.dubbo.rpc.protocol.rest.RestProtocol\n</code></pre><p>我们已经找到了<code>filter</code>和<code>listener</code>对应的扩展点了。接下来看一下它们是怎么一步一步的被注入到上面的流程里的。</p>\n<p>在<code>ReferenceConfig</code>类中我们会引用和暴露对应的服务，我们以服务引用为场景来分析：</p>\n<pre><code>get()  --&gt;  init()  --&gt;   createProxy()\n                                |\n                                +---&gt;  invoker = refprotocol.refer(interfaceClass, urls.get(0));\n</code></pre><p>注意上面提到的这一行代码，这里的<code>refprotocol</code>是引用的<code>Protocol$Adpative</code>，这个类是dubbo的SPI机制动态创建的自适应扩展点，我们在之前的文章中已经介绍过，看一下它的<code>refer</code>方法细节：</p>\n<pre><code>public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n    if (arg1 == null)\n        throw new IllegalArgumentException(&quot;url == null&quot;);\n\n    com.alibaba.dubbo.common.URL url = arg1;\n    String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );\n\n    if(extName == null) \n        throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n    //注意这一行，根据url的协议名称选择对应的扩展点实现\n    com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\n    return extension.refer(arg0, arg1);\n}\n</code></pre><p>乍一看，并没有感觉有什么蹊跷，不过在单步调试中就会出现”诡异”现象（由于该类是动态创建的，所以该方法并不会被单步到，所以为分析带来了一定的干扰），我们得再往回倒一下，之前在<a href=\"http://blog.kazaff.me/2015/01/15/dubbo%E4%B8%ADSPI%E7%9A%84%E5%9F%BA%E7%A1%80--Cooma%E5%BE%AE%E5%AE%B9%E5%99%A8/\">dubbo中SPI的基础</a>中曾经分析过<code>ExtensionLoader</code>的源码，但是当时由于了解的不够确实忽略了一些细节。</p>\n<p>我们再来看一下它的执行流程：</p>\n<pre><code>getExtension()  --&gt;  createExtension()\n                            |\n                            +--&gt;      ......\n                                    Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses;\n                                    if (wrapperClasses != null &amp;&amp; wrapperClasses.size() &gt; 0) {\n                                        for (Class&lt;?&gt; wrapperClass : wrapperClasses) {  //装饰器模式\n                                            instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));\n                                        }\n                                    }\n                                    ......\n</code></pre><p>一看到这行代码，就知道关键点在这里，这种写法刚好就是和常见的拦截器和监听器的实现方法吻合，而且事实证明也确实是在这个地方完成的注入，那么我们就需要看一下这个<code>cachedWrapperClasses</code>到到底存了什么？</p>\n<p>我们最后看一下<code>ExtensionLoader.loadFile</code>方法，它是负责解析我们开头提到的那个SPI扩展点配置文件的，它会依次扫描配置文件的每一行，然后根据配置内容完成等号两边的键值对应关系，例如：</p>\n<pre><code>test=com.alibaba.dubbo.rpc.filter.TestFilter\n</code></pre><p><code>loadFile</code>的任务就是把<code>test</code>和解析过以后的<code>TestFilter</code>类关系对应上，供以后的<code>getExtension</code>查找使用。注意看其中的这几行代码：</p>\n<pre><code>......\n clazz.getConstructor(type); //判断是否为wrapper实现\nSet&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses;\nif (wrappers == null) {\n    cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;();\n    wrappers = cachedWrapperClasses;\n}\nwrappers.add(clazz);\n......\n</code></pre><p>这里就完成了<code>cachedWrapperClasses</code>的初始化，它根据查看配置文件中定义的扩展点实现是否包含一个带有当前类型的构造方法为条件，确定哪些是wrapper，这样我们就可以发现：</p>\n<pre><code>filter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper\nlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper\n</code></pre><p>这两行命中了。这也是之后在真正获取<code>protocol</code>扩展点时会动态注入的两个重要包装类，前者完成拦截器，后者完成监听器。</p>\n<p>至于拦截器和监听器的使用方法，我实在不知道除了官方提到的内容以外还有什么好补充的了，那就写到这里吧~</p>\n","excerpt":"<p>今天要聊一个可能被其他dubbo源码研究的童鞋容易忽略的话题：Filter和Listener。<br>","more":"<br>我们先来看一下这两个概念的官方手册：</p>\n<ul>\n<li><a href=\"http://alibaba.github.io/dubbo-doc-static/Filter+SPI-zh.htm\">拦截器</a></li>\n<li>监听器：<a href=\"http://alibaba.github.io/dubbo-doc-static/InvokerListener+SPI-zh.htm\">引用监听器</a>和<a href=\"http://alibaba.github.io/dubbo-doc-static/ExporterListener+SPI-zh.htm\">暴露监听器</a></li>\n</ul>\n<p>老实说，依赖之前的源码分析经验，导致我饶了很大的弯路，一直找不到<code>filter</code>和<code>listener</code>被使用的位置。看过前几篇文章的朋友应该也有这个疑惑，为什么按照url参数去匹配框架的执行流程，死活找不到dubbo注入拦截器和监听器的位置呢？</p>\n<pre><code>ReferenceConfig --&gt;  RegistryProtocol --&gt; DubboProtocol  --&gt;  invoker  --&gt;  exporter\n</code></pre><p>按照这个调用流程，没错啊，可每一个环节都没有使用<code>filter</code>和<code>listener</code>属性的痕迹，有点抓瞎了啊。要说用好IDE确实很重要啊，光靠脑子想真的很伤身，下面来看一下谜底。</p>\n<p>先来回忆一下dubbo的SPI机制，根据接口类型，dubbo会去读取并解析对应的配置文件，从中拿到对应的扩展点实现，好，我们先来看一下<code>Protocol</code>接口对应的配置文件：</p>\n<pre><code>registry=com.alibaba.dubbo.registry.integration.RegistryProtocol\ndubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol            \nfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper            #注意这一行\nlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper        #注意这一行\nmock=com.alibaba.dubbo.rpc.support.MockProtocol\ninjvm=com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocol\nrmi=com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocol\nhessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocol\ncom.alibaba.dubbo.rpc.protocol.http.HttpProtocol\ncom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocol\nthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocol\nmemcached=com.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocol\nredis=com.alibaba.dubbo.rpc.protocol.redis.RedisProtocol\nrest=com.alibaba.dubbo.rpc.protocol.rest.RestProtocol\n</code></pre><p>我们已经找到了<code>filter</code>和<code>listener</code>对应的扩展点了。接下来看一下它们是怎么一步一步的被注入到上面的流程里的。</p>\n<p>在<code>ReferenceConfig</code>类中我们会引用和暴露对应的服务，我们以服务引用为场景来分析：</p>\n<pre><code>get()  --&gt;  init()  --&gt;   createProxy()\n                                |\n                                +---&gt;  invoker = refprotocol.refer(interfaceClass, urls.get(0));\n</code></pre><p>注意上面提到的这一行代码，这里的<code>refprotocol</code>是引用的<code>Protocol$Adpative</code>，这个类是dubbo的SPI机制动态创建的自适应扩展点，我们在之前的文章中已经介绍过，看一下它的<code>refer</code>方法细节：</p>\n<pre><code>public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n    if (arg1 == null)\n        throw new IllegalArgumentException(&quot;url == null&quot;);\n\n    com.alibaba.dubbo.common.URL url = arg1;\n    String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );\n\n    if(extName == null) \n        throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n    //注意这一行，根据url的协议名称选择对应的扩展点实现\n    com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\n    return extension.refer(arg0, arg1);\n}\n</code></pre><p>乍一看，并没有感觉有什么蹊跷，不过在单步调试中就会出现”诡异”现象（由于该类是动态创建的，所以该方法并不会被单步到，所以为分析带来了一定的干扰），我们得再往回倒一下，之前在<a href=\"http://blog.kazaff.me/2015/01/15/dubbo%E4%B8%ADSPI%E7%9A%84%E5%9F%BA%E7%A1%80--Cooma%E5%BE%AE%E5%AE%B9%E5%99%A8/\">dubbo中SPI的基础</a>中曾经分析过<code>ExtensionLoader</code>的源码，但是当时由于了解的不够确实忽略了一些细节。</p>\n<p>我们再来看一下它的执行流程：</p>\n<pre><code>getExtension()  --&gt;  createExtension()\n                            |\n                            +--&gt;      ......\n                                    Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses;\n                                    if (wrapperClasses != null &amp;&amp; wrapperClasses.size() &gt; 0) {\n                                        for (Class&lt;?&gt; wrapperClass : wrapperClasses) {  //装饰器模式\n                                            instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));\n                                        }\n                                    }\n                                    ......\n</code></pre><p>一看到这行代码，就知道关键点在这里，这种写法刚好就是和常见的拦截器和监听器的实现方法吻合，而且事实证明也确实是在这个地方完成的注入，那么我们就需要看一下这个<code>cachedWrapperClasses</code>到到底存了什么？</p>\n<p>我们最后看一下<code>ExtensionLoader.loadFile</code>方法，它是负责解析我们开头提到的那个SPI扩展点配置文件的，它会依次扫描配置文件的每一行，然后根据配置内容完成等号两边的键值对应关系，例如：</p>\n<pre><code>test=com.alibaba.dubbo.rpc.filter.TestFilter\n</code></pre><p><code>loadFile</code>的任务就是把<code>test</code>和解析过以后的<code>TestFilter</code>类关系对应上，供以后的<code>getExtension</code>查找使用。注意看其中的这几行代码：</p>\n<pre><code>......\n clazz.getConstructor(type); //判断是否为wrapper实现\nSet&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses;\nif (wrappers == null) {\n    cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;();\n    wrappers = cachedWrapperClasses;\n}\nwrappers.add(clazz);\n......\n</code></pre><p>这里就完成了<code>cachedWrapperClasses</code>的初始化，它根据查看配置文件中定义的扩展点实现是否包含一个带有当前类型的构造方法为条件，确定哪些是wrapper，这样我们就可以发现：</p>\n<pre><code>filter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper\nlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper\n</code></pre><p>这两行命中了。这也是之后在真正获取<code>protocol</code>扩展点时会动态注入的两个重要包装类，前者完成拦截器，后者完成监听器。</p>\n<p>至于拦截器和监听器的使用方法，我实在不知道除了官方提到的内容以外还有什么好补充的了，那就写到这里吧~</p>"},{"title":"dubbo如何一步一步拿到bean","date":"2015-01-26T10:54:30.000Z","_content":"\n\ndubbo依赖了spring提供的现成机制完成了bean的创建，我们来看一下这其中的汰渍。\n\n<!-- more -->\n\n配置\n---\n\n关于dubbo的配置相关细节，官方已经给了一个无比详细的[文档](http://alibaba.github.io/dubbo-doc-static/Configuration+Reference-zh.htm)，[文档2](http://alibaba.github.io/dubbo-doc-static/Configs-zh.htm)。不过由于dubbo可供配置的参数非常多，这也是让我们新手一开始感到最为头疼的，这也是SOA复杂的表象之一。\n\n\nxml -> beanDefinition\n---\n对于我这种小学生，需要先补习一个基础知识点：[基于Spring可扩展Schema提供自定义配置支持](http://www.cnblogs.com/jifeng/archive/2011/09/14/2176599.html)。dubbo是依赖spring提供的这种机制来处理配置文件解析的，理解起来没什么难度。\n\n看一下dubbo-congfig的目录结构：\n\n![](http://pic.yupoo.com/kazaff/EllS0JnY/lFpRv.png)\n\n我们来看一下dubbo是如何按照spring提供的机制来处理配置文件的：\n\n\t#spring.handlers\n\thttp\\://code.alibabatech.com/schema/dubbo=com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler\n\n\t#spring.schemas\n\thttp\\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd\n\n这样我们就锁定了要分析的类：\n\n\tpackage com.alibaba.dubbo.config.spring.schema;\n\n\tpublic class DubboNamespaceHandler extends NamespaceHandlerSupport {\n\n\t\tstatic {\n\t\t\tVersion.checkDuplicate(DubboNamespaceHandler.class); //确保系统中只存在一份解析处理器类定义\n\t\t}\n\t\n\t\tpublic void init() {\n\t\t    registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true));\n\t        registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true));\n\t        registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true));\n\t        registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true));\n\t        registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true));\n\t        registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true));\n\t        registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true));\n\t        registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true));\n\t        registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false));\n\t        registerBeanDefinitionParser(\"annotation\", new DubboBeanDefinitionParser(AnnotationBean.class, true));\n\t    }\n\t}\n\n按照spring提供的机制，dubbo把每个自定义的可使用配置元素和对应的解析器绑定到一起。而真正负责把配置文件中声明的内容解析成对应的BeanDefinition（可以想象为Bean的模子）是靠`DubboBeanDefinitionParser.parse`类完成，我们就来严肃的分析一下这个方法。\n\t\n\t/**\n\t * AbstractBeanDefinitionParser\n\t * \n\t * @author william.liangf\n\t * @export\n\t */\n\tpublic class DubboBeanDefinitionParser implements BeanDefinitionParser {\n\t    \n\t    private static final Logger logger = LoggerFactory.getLogger(DubboBeanDefinitionParser.class);\n\t\t\n\t    private final Class<?> beanClass;\n\t    \n\t    private final boolean required;\n\t\n\t    public DubboBeanDefinitionParser(Class<?> beanClass, boolean required) {\n\t        this.beanClass = beanClass;\n\t        this.required = required;\n\t    }\n\t\n\t    public BeanDefinition parse(Element element, ParserContext parserContext) {\n\t        return parse(element, parserContext, beanClass, required);\n\t    }\n\t    \n\t    @SuppressWarnings(\"unchecked\")\n\t    private static BeanDefinition parse(Element element, ParserContext parserContext, Class<?> beanClass, boolean required) {\n\t        //初始化BeanDefiniion\n\t        RootBeanDefinition beanDefinition = new RootBeanDefinition();\n\t        beanDefinition.setBeanClass(beanClass);\n\t        beanDefinition.setLazyInit(false);\n\t\n\t        String id = element.getAttribute(\"id\");\n\t        if ((id == null || id.length() == 0) && required) {\n\t        \tString generatedBeanName = element.getAttribute(\"name\");\n\t        \tif (generatedBeanName == null || generatedBeanName.length() == 0) {\n\t        \t    if (ProtocolConfig.class.equals(beanClass)) {   //如果当前解析的类型是ProtocolConfig，则设置默认id为dubbo\n\t        \t        generatedBeanName = \"dubbo\";\n\t        \t    } else {\n\t        \t        generatedBeanName = element.getAttribute(\"interface\");  //其他情况，默认id为接口类型\n\t        \t    }\n\t        \t}\n\t        \tif (generatedBeanName == null || generatedBeanName.length() == 0) {\n\t        \t\tgeneratedBeanName = beanClass.getName();    //如果该节点没有interface属性（包含：registry,monitor,provider,consumer），则使用该节点的类型为id值\n\t        \t}\n\t            id = generatedBeanName; \n\t            int counter = 2;\n\t            while(parserContext.getRegistry().containsBeanDefinition(id)) { //生成不重复的id\n\t                id = generatedBeanName + (counter ++);\n\t            }\n\t        }\n\t        if (id != null && id.length() > 0) {    //目前这个判断不知道啥意义，目测必定会返回true\n\t            if (parserContext.getRegistry().containsBeanDefinition(id))  {  //这个判断应该用于防止并发\n\t        \t\tthrow new IllegalStateException(\"Duplicate spring bean id \" + id);\n\t        \t}\n\t            //注册beanDefinition，BeanDefinitionRegistry相当于一张注册表\n\t            parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);\n\t            beanDefinition.getPropertyValues().addPropertyValue(\"id\", id);\n\t        }\n\t        //下面这几个if-else分别针对不同类型做特殊处理\n\t        if (ProtocolConfig.class.equals(beanClass)) {\n\t            //这段代码的逻辑是用来适配：当<dubbo:protocol>声明出现在配置文件中使用该协议的bean声明的后面时，解决它们之间的依赖关系的。\n\t            for (String name : parserContext.getRegistry().getBeanDefinitionNames()) {\n\t                BeanDefinition definition = parserContext.getRegistry().getBeanDefinition(name);\n\t                PropertyValue property = definition.getPropertyValues().getPropertyValue(\"protocol\");\n\t                if (property != null) {\n\t                    Object value = property.getValue();\n\t                    //如果被检查的bean确实使用当前协议，则建立它们之间的依赖关系\n\t                    if (value instanceof ProtocolConfig && id.equals(((ProtocolConfig) value).getName())) {\n\t                        definition.getPropertyValues().addPropertyValue(\"protocol\", new RuntimeBeanReference(id));\n\t                    }\n\t                }\n\t            }\n\t        } else if (ServiceBean.class.equals(beanClass)) {\n\t            String className = element.getAttribute(\"class\");   //虽然文档上没有标注该配置支持class参数，但是在dubbo.xsd上却能看到这个属性的定义，类似这样的情况还有很多。\n\t            if(className != null && className.length() > 0) {   //下面的处理方式应该算是语法糖吧，它支持直接把定义bean和创建serviceConfig压缩成一行\n\t                RootBeanDefinition classDefinition = new RootBeanDefinition();\n\t                classDefinition.setBeanClass(ReflectUtils.forName(className));\n\t                classDefinition.setLazyInit(false);\n\t                parseProperties(element.getChildNodes(), classDefinition);  //完成bean的初始化工作（注入等）\n\t                beanDefinition.getPropertyValues().addPropertyValue(\"ref\", new BeanDefinitionHolder(classDefinition, id + \"Impl\")); //关联bean和serviceConfig\n\t            }\n\t        } else if (ProviderConfig.class.equals(beanClass)) {    //按照providerConfig的定义解析并关联其影响的相关serviceConfig\n\t            parseNested(element, parserContext, ServiceBean.class, true, \"service\", \"provider\", id, beanDefinition);\n\t        } else if (ConsumerConfig.class.equals(beanClass)) {    //按照consumerConfig的定义解析并关联其影响的相关referenceConfig\n\t            parseNested(element, parserContext, ReferenceBean.class, false, \"reference\", \"consumer\", id, beanDefinition);\n\t        }\n\t        Set<String> props = new HashSet<String>();\n\t        ManagedMap parameters = null;\n\t        for (Method setter : beanClass.getMethods()) {  //利用反射拿到指定类型的所有用于注入的方法\n\t            String name = setter.getName();\n\t            if (name.length() > 3 && name.startsWith(\"set\")\n\t                    && Modifier.isPublic(setter.getModifiers())\n\t                    && setter.getParameterTypes().length == 1) {    //注入方法的特征是：以set字母开头，是公共方法，且参数个数为1\n\t                Class<?> type = setter.getParameterTypes()[0];\n\t                String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), \"-\");    //把方法名字的驼峰格式改成-分割格式\n\t                props.add(property);\n\t                Method getter = null;\n\t                try {\n\t                    getter = beanClass.getMethod(\"get\" + name.substring(3), new Class<?>[0]);\n\t                } catch (NoSuchMethodException e) {\n\t                    try {\n\t                        getter = beanClass.getMethod(\"is\" + name.substring(3), new Class<?>[0]);\n\t                    } catch (NoSuchMethodException e2) {\n\t                    }\n\t                }\n\t                if (getter == null \n\t                        || ! Modifier.isPublic(getter.getModifiers())\n\t                        || ! type.equals(getter.getReturnType())) { //如果没有满足条件的对应getter方法存在，则直接跳过该setter方法\n\t                    continue;\n\t                }\n\t\n\t                if (\"parameters\".equals(property)) {    //从配置文件中解析出parameter配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用，parameter的值当string类型解析\n\t                    parameters = parseParameters(element.getChildNodes(), beanDefinition);\n\t                } else if (\"methods\".equals(property)) {    //注入对应的method配置\n\t                    parseMethods(id, element.getChildNodes(), beanDefinition, parserContext);\n\t                } else if (\"arguments\".equals(property)) {  //为method注入对应的argument配置\n\t                    parseArguments(id, element.getChildNodes(), beanDefinition, parserContext);\n\t                } else {\n\t                    String value = element.getAttribute(property);  //检查该setter方法所适配要注入的属性是否在配置中明确定义\n\t                    if (value != null) {    //若存在定义，则完成其注入解析\n\t                    \tvalue = value.trim();\n\t                    \tif (value.length() > 0) {\n\t                    \t\tif (\"registry\".equals(property) && RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(value)) {   //处理无注册中心的情况\n\t                            \tRegistryConfig registryConfig = new RegistryConfig();\n\t                            \tregistryConfig.setAddress(RegistryConfig.NO_AVAILABLE);\n\t                            \tbeanDefinition.getPropertyValues().addPropertyValue(property, registryConfig);\n\t                            } else if (\"registry\".equals(property) && value.indexOf(',') != -1) {   //处理多注册中心的情况\n\t                    \t\t\tparseMultiRef(\"registries\", value, beanDefinition, parserContext);\n\t                            } else if (\"provider\".equals(property) && value.indexOf(',') != -1) {   //处理继承多个provider的情况，缺使用第一个provider配置\n\t                            \tparseMultiRef(\"providers\", value, beanDefinition, parserContext);\n\t                            } else if (\"protocol\".equals(property) && value.indexOf(',') != -1) {   //处理多协议暴露\n\t                                parseMultiRef(\"protocols\", value, beanDefinition, parserContext);\n\t                            } else {\n\t                                Object reference;\n\t                                if (isPrimitive(type)) {    //如果setter的参数类型为jdk原始类型，直接当string注入到对应属性中去\n\t                                    if (\"async\".equals(property) && \"false\".equals(value)\n\t                                            || \"timeout\".equals(property) && \"0\".equals(value)\n\t                                            || \"delay\".equals(property) && \"0\".equals(value)\n\t                                            || \"version\".equals(property) && \"0.0.0\".equals(value)\n\t                                            || \"stat\".equals(property) && \"-1\".equals(value)\n\t                                            || \"reliable\".equals(property) && \"false\".equals(value)) {\n\t                                        // 兼容旧版本xsd中的default值\n\t                                        value = null;\n\t                                    }\n\t                                    reference = value;\n\t                                } else if (\"protocol\".equals(property) \n\t                                        && ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(value)   //是否存在指定的扩展点定义\n\t                                        && (! parserContext.getRegistry().containsBeanDefinition(value) //检查当前解析出的要使用协议对应的protocolConfig是否已经被初始化\n\t                                                || ! ProtocolConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n\t                                    if (\"dubbo:provider\".equals(element.getTagName())) {\n\t                                        logger.warn(\"Recommended replace <dubbo:provider protocol=\\\"\" + value + \"\\\" ... /> to <dubbo:protocol name=\\\"\" + value + \"\\\" ... />\");\n\t                                    }\n\t                                    // 兼容旧版本配置\n\t                                    ProtocolConfig protocol = new ProtocolConfig();\n\t                                    protocol.setName(value);\n\t                                    reference = protocol;\n\t                                } else if (\"monitor\".equals(property) \n\t                                        && (! parserContext.getRegistry().containsBeanDefinition(value)\n\t                                                || ! MonitorConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n\t                                    // 兼容旧版本配置\n\t                                    reference = convertMonitor(value);\n\t                                } else if (\"onreturn\".equals(property)) {   //对应methodConfig中的返回拦截\n\t                                    int index = value.lastIndexOf(\".\");\n\t                                    String returnRef = value.substring(0, index);\n\t                                    String returnMethod = value.substring(index + 1);\n\t                                    reference = new RuntimeBeanReference(returnRef);\n\t                                    beanDefinition.getPropertyValues().addPropertyValue(\"onreturnMethod\", returnMethod);\n\t                                } else if (\"onthrow\".equals(property)) {    //对应methodConfig中的异常拦截\n\t                                    int index = value.lastIndexOf(\".\");\n\t                                    String throwRef = value.substring(0, index);\n\t                                    String throwMethod = value.substring(index + 1);\n\t                                    reference = new RuntimeBeanReference(throwRef);\n\t                                    beanDefinition.getPropertyValues().addPropertyValue(\"onthrowMethod\", throwMethod);\n\t                                } else {\n\t                                    if (\"ref\".equals(property) && parserContext.getRegistry().containsBeanDefinition(value)) {\n\t                                        BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(value);\n\t                                        if (! refBean.isSingleton()) {\n\t                                            throw new IllegalStateException(\"The exported service ref \" + value + \" must be singleton! Please set the \" + value + \" bean scope to singleton, eg: <bean id=\\\"\" + value+ \"\\\" scope=\\\"singleton\\\" ...>\");\n\t                                        }\n\t                                    }\n\t                                    reference = new RuntimeBeanReference(value);\n\t                                }\n\t\t\t                        beanDefinition.getPropertyValues().addPropertyValue(property, reference);\n\t                            }\n\t                    \t}\n\t                    }\n\t                }\n\t            }\n\t        }\n\t        NamedNodeMap attributes = element.getAttributes();\n\t        int len = attributes.getLength();\n\t        for (int i = 0; i < len; i++) {\n\t            Node node = attributes.item(i);\n\t            String name = node.getLocalName();\n\t            if (! props.contains(name)) {   //处理配置中声明的没有满足注入条件的剩余属性\n\t                if (parameters == null) {\n\t                    parameters = new ManagedMap();\n\t                }\n\t                String value = node.getNodeValue();\n\t                parameters.put(name, new TypedStringValue(value, String.class));\n\t            }\n\t        }\n\t        if (parameters != null) {\n\t            beanDefinition.getPropertyValues().addPropertyValue(\"parameters\", parameters);\n\t        }\n\t        return beanDefinition;\n\t    }\n\t\n\t    private static final Pattern GROUP_AND_VERION = Pattern.compile(\"^[\\\\-.0-9_a-zA-Z]+(\\\\:[\\\\-.0-9_a-zA-Z]+)?$\");\n\t    \n\t    protected static MonitorConfig convertMonitor(String monitor) {\n\t        if (monitor == null || monitor.length() == 0) {\n\t            return null;\n\t        }\n\t        if (GROUP_AND_VERION.matcher(monitor).matches()) {\n\t            String group;\n\t            String version;\n\t            int i = monitor.indexOf(':');\n\t            if (i > 0) {\n\t                group = monitor.substring(0, i);\n\t                version = monitor.substring(i + 1);\n\t            } else {\n\t                group = monitor;\n\t                version = null;\n\t            }\n\t            MonitorConfig monitorConfig = new MonitorConfig();\n\t            monitorConfig.setGroup(group);\n\t            monitorConfig.setVersion(version);\n\t            return monitorConfig;\n\t        }\n\t        return null;\n\t    }\n\t \n\t    private static boolean isPrimitive(Class<?> cls) {\n\t        return cls.isPrimitive() || cls == Boolean.class || cls == Byte.class\n\t                || cls == Character.class || cls == Short.class || cls == Integer.class\n\t                || cls == Long.class || cls == Float.class || cls == Double.class\n\t                || cls == String.class || cls == Date.class || cls == Class.class;\n\t    }\n\t    \n\t    @SuppressWarnings(\"unchecked\")\n\t\tprivate static void parseMultiRef(String property, String value, RootBeanDefinition beanDefinition,\n\t            ParserContext parserContext) {\n\t    \tString[] values = value.split(\"\\\\s*[,]+\\\\s*\");\n\t\t\tManagedList list = null;\n\t        for (int i = 0; i < values.length; i++) {\n\t            String v = values[i];\n\t            if (v != null && v.length() > 0) {\n\t            \tif (list == null) {\n\t                    list = new ManagedList();\n\t                }\n\t            \tlist.add(new RuntimeBeanReference(v));\n\t            }\n\t        }\n\t        beanDefinition.getPropertyValues().addPropertyValue(property, list);\n\t    }\n\t    \n\t    private static void parseNested(Element element,\n\t                                    ParserContext parserContext,\n\t                                    Class<?> beanClass,\n\t                                    boolean required,\n\t                                    String tag,\n\t                                    String property,\n\t                                    String ref,\n\t                                    BeanDefinition beanDefinition) {\n\t        NodeList nodeList = element.getChildNodes();\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            boolean first = true;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    if (tag.equals(node.getNodeName())\n\t                            || tag.equals(node.getLocalName())) {\n\t                        if (first) {\n\t                            //如果该providerBean没有设置default开关，且子节点中定义了serviceBean，则明确赋值该参数为false，也就是说该providerBean只作为其子serviceBean节点的默认协议\n\t                            //这样就不会让该providerBean的作用范围盲目扩大（成为所有serviceBean的默认协议）\n\t                            first = false;\n\t                            String isDefault = element.getAttribute(\"default\");\n\t                            if (isDefault == null || isDefault.length() == 0) {\n\t                                beanDefinition.getPropertyValues().addPropertyValue(\"default\", \"false\");\n\t                            }\n\t                        }\n\t                        //所有子serviceBean定义节点全部解析并引用该providerBean作为默认值配置\n\t                        BeanDefinition subDefinition = parse((Element) node, parserContext, beanClass, required);\n\t                        if (subDefinition != null && ref != null && ref.length() > 0) {\n\t                            subDefinition.getPropertyValues().addPropertyValue(property, new RuntimeBeanReference(ref));\n\t                        }\n\t                    }\n\t                }\n\t            }\n\t        }\n\t    }\n\t\n\t    private static void parseProperties(NodeList nodeList, RootBeanDefinition beanDefinition) {\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    if (\"property\".equals(node.getNodeName())\n\t                            || \"property\".equals(node.getLocalName())) {\n\t                        String name = ((Element) node).getAttribute(\"name\");\n\t                        if (name != null && name.length() > 0) {\n\t                            String value = ((Element) node).getAttribute(\"value\");  //java基础类型\n\t                            String ref = ((Element) node).getAttribute(\"ref\");  //引用其他bean\n\t                            if (value != null && value.length() > 0) {\n\t                                beanDefinition.getPropertyValues().addPropertyValue(name, value);\n\t                            } else if (ref != null && ref.length() > 0) {\n\t                                beanDefinition.getPropertyValues().addPropertyValue(name, new RuntimeBeanReference(ref));\n\t                            } else {\n\t                                throw new UnsupportedOperationException(\"Unsupported <property name=\\\"\" + name + \"\\\"> sub tag, Only supported <property name=\\\"\" + name + \"\\\" ref=\\\"...\\\" /> or <property name=\\\"\" + name + \"\\\" value=\\\"...\\\" />\");\n\t                            }\n\t                        }\n\t                    }\n\t                }\n\t            }\n\t        }\n\t    }\n\t\n\t    @SuppressWarnings(\"unchecked\")\n\t    private static ManagedMap parseParameters(NodeList nodeList, RootBeanDefinition beanDefinition) {   //解析参数配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用。\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            ManagedMap parameters = null;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    if (\"parameter\".equals(node.getNodeName())\n\t                            || \"parameter\".equals(node.getLocalName())) {\n\t                        if (parameters == null) {\n\t                            parameters = new ManagedMap();\n\t                        }\n\t                        String key = ((Element) node).getAttribute(\"key\");\n\t                        String value = ((Element) node).getAttribute(\"value\");\n\t                        boolean hide = \"true\".equals(((Element) node).getAttribute(\"hide\"));\n\t                        if (hide) {\n\t                            key = Constants.HIDE_KEY_PREFIX + key;\n\t                        }\n\t                        parameters.put(key, new TypedStringValue(value, String.class)); //注意parameter的值都是string类型\n\t                    }\n\t                }\n\t            }\n\t            return parameters;\n\t        }\n\t        return null;\n\t    }\n\t\n\t    @SuppressWarnings(\"unchecked\")\n\t    private static void parseMethods(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n\t                              ParserContext parserContext) {\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            ManagedList methods = null;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    Element element = (Element) node;\n\t                    if (\"method\".equals(node.getNodeName()) || \"method\".equals(node.getLocalName())) {\n\t                        String methodName = element.getAttribute(\"name\");\n\t                        if (methodName == null || methodName.length() == 0) {   //name为必填项，这一点在文档里也表明\n\t                            throw new IllegalStateException(\"<dubbo:method> name attribute == null\");\n\t                        }\n\t                        if (methods == null) {\n\t                            methods = new ManagedList();\n\t                        }\n\t                        BeanDefinition methodBeanDefinition = parse(((Element) node),\n\t                                parserContext, MethodConfig.class, false);  //解析methodConfig\n\t                        String name = id + \".\" + methodName;    //注意这里，方法的名称前会加上bean的id\n\t                        BeanDefinitionHolder methodBeanDefinitionHolder = new BeanDefinitionHolder(\n\t                                methodBeanDefinition, name);\n\t                        methods.add(methodBeanDefinitionHolder);\n\t                    }\n\t                }\n\t            }\n\t            if (methods != null) {\n\t                beanDefinition.getPropertyValues().addPropertyValue(\"methods\", methods);    //关联bean和其method\n\t            }\n\t        }\n\t    }\n\t    \n\t    @SuppressWarnings(\"unchecked\")\n\t    private static void parseArguments(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n\t                              ParserContext parserContext) {\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            ManagedList arguments = null;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    Element element = (Element) node;\n\t                    if (\"argument\".equals(node.getNodeName()) || \"argument\".equals(node.getLocalName())) {\n\t                        String argumentIndex = element.getAttribute(\"index\");   //不清楚这里为何没有必填校验\n\t                        if (arguments == null) {\n\t                            arguments = new ManagedList();\n\t                        }\n\t                        BeanDefinition argumentBeanDefinition = parse(((Element) node),\n\t                                parserContext, ArgumentConfig.class, false);\n\t                        String name = id + \".\" + argumentIndex;\n\t                        BeanDefinitionHolder argumentBeanDefinitionHolder = new BeanDefinitionHolder(\n\t                                argumentBeanDefinition, name);\n\t                        arguments.add(argumentBeanDefinitionHolder);\n\t                    }\n\t                }\n\t            }\n\t            if (arguments != null) {\n\t                beanDefinition.getPropertyValues().addPropertyValue(\"arguments\", arguments);    //关联arguments和其method\n\t            }\n\t        }\n\t    }\n\t\n\t}\n\n现在，我们的dubbo就已经把配置文件中定义的bean全部解析成对应的**beanDefinition**，为spring的getBean做好准备工作。\n\n\nbeanDefinition -> bean\n---\n\n其实也就是从beanDefinition转换成bean的过程，我在网上找了[一幅图](http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/)，可以辅助我们了解spring内部是如何初始化bean的：\n\n![](http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/origin_image012.gif)\n\n这里也有一篇不错的[文章](http://songzi0206.iteye.com/blog/1430239#show-last-Point)，从代码的角度描述了spring内部是如何使用BeanDefinition生成Bean的，dubbo就是委托给spring来管理bean的生命周期的。\n\n那么dubbo自定义schemas所产生的beanDefinition，spring是如何将其转换成dubbo需要的bean呢？毕竟我们从上面的解析中看到，解析生成的beanDefinition中包含太多dubbo特殊的配置方式。这里我有两个猜测：\n\n- dubbo在spring提供的相关扩展点上实现了自己的getBean逻辑，可我却在dubbo的源码中找不到对应实现；\n- **spring解析生成的beanDefinition并没有dubbo特殊性，交给默认的BeanFactory没啥问题**（这都怪我spring太差啊~）\n\n带着疑问我进行了严酷的单步调试，事实证明是第二种路数。到目前为止，dubbo已经按照我们提供的配置文件把所有需要的**bean**初始化完成，这部分基本上都是交给spring来搞定的。\n\n这还不够，我们还不知道这些bean是怎么服务于业务！\n\n\n\nbean -> service\n---\n\n那么到底是哪些bean最终会被dubbo直接拿来使用呢？其实`DubboNamespaceHandler.init`中的那些就是答案。我们先看一下这些类的关系：\n\n![](http://alibaba.github.io/dubbo-doc-static/dubbo-config.jpg-version=1&modificationDate=1330708121000.jpg)\n\n其实这么复杂的关系最终都会被转换成字符串以`URL`的形式交给dubbo的底层最终暴露成服务。我们先来重点看一下`ServiceBean`的实现，了解一下服务提供方的细节。\n\n按照上面uml图来看，这些**xxxConfig**类的关系已经很清楚了（谁继承谁，谁聚合谁，谁依赖谁）。不过图里并没有出现我们的目标：**ServiceBean**，补充下图：\n\n![](http://pic.yupoo.com/kazaff/En3pJXbV/NqlfS.png)\n\n除了继承父类外，我们也要注意`ServiceBean`实现的相关接口：\n\n\tpublic class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware \n\n这里我们着重看`InitializingBean`接口，该接口为spring留给开发者的一个hook，用来执行初始化bean的个性化逻辑的回调，详情可以看这篇[文章](http://www.cnblogs.com/zrtqsk/p/3735273.html#show-last-Point)。\n\n既然我们的`ServiceBean`实现了这个接口，意味着当spring进行容器初始化任务过程中，会执行我们在`ServiceBean.afterPropertiesSet`方法中安排的逻辑，这也是bean导出为服务的关键入口，先把本尊注释过的代码贴出来：\n\n\tpublic class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware {\n\t\n\t\tprivate static final long serialVersionUID = 213195494150089726L;\n\t\n\t    private static transient ApplicationContext SPRING_CONTEXT;\n\t    \n\t\tprivate transient ApplicationContext applicationContext;\n\t\n\t    private transient String beanName;\n\t\n\t    private transient boolean supportedApplicationListener;\n\t    \n\t\tpublic ServiceBean() {\n\t        super();\n\t    }\n\t\n\t    public ServiceBean(Service service) {\n\t        super(service);\n\t    }\n\t\n\t    public static ApplicationContext getSpringContext() {\n\t\t    return SPRING_CONTEXT;\n\t\t}\n\t\n\t\tpublic void setApplicationContext(ApplicationContext applicationContext) {\n\t\t\tthis.applicationContext = applicationContext;\n\t\n\t        //把该应用上下文存储在SpringExtensionFactory（dubbo的SPI扩展点机制）中\n\t        //把原先spring通过ApplicationContext获取bean的方式封装了一下，以dubbo统一的SPI扩展点机制风格接口暴露给业务使用\n\t\t\tSpringExtensionFactory.addApplicationContext(applicationContext);\n\t\t\tif (applicationContext != null) {\n\t\t\t    SPRING_CONTEXT = applicationContext;\n\t\t\t    try {\n\t                //把所有serviceBean都加入到ApplicationContext的事件通知中\n\t\t            Method method = applicationContext.getClass().getMethod(\"addApplicationListener\", new Class<?>[]{ApplicationListener.class}); // 兼容Spring2.0.1\n\t\t            method.invoke(applicationContext, new Object[] {this});\n\t\t            supportedApplicationListener = true;\n\t\t        } catch (Throwable t) {\n\t                if (applicationContext instanceof AbstractApplicationContext) {\n\t    \t            try {\n\t    \t                Method method = AbstractApplicationContext.class.getDeclaredMethod(\"addListener\", new Class<?>[]{ApplicationListener.class}); // 兼容Spring2.0.1\n\t                        if (! method.isAccessible()) {\n\t                            method.setAccessible(true);\n\t                        }\n\t    \t                method.invoke(applicationContext, new Object[] {this});\n\t                        supportedApplicationListener = true;\n\t    \t            } catch (Throwable t2) {\n\t    \t            }\n\t\t            }\n\t\t        }\n\t\t\t}\n\t\t}\n\t\n\t    public void setBeanName(String name) {\n\t        this.beanName = name;\n\t    }\n\t\n\t    //如果配置serviceBean时声明了延迟暴露（例如：<dubbo:service delay=\"-1\" />），则会依赖监听spring提供的相关事件来触发export\n\t    public void onApplicationEvent(ApplicationEvent event) {\n\t        if (ContextRefreshedEvent.class.getName().equals(event.getClass().getName())) { //监听ContextRefreshedEvent事件（容器发生初始化或更新时触发）\n\t        \tif (isDelay() && ! isExported() && ! isUnexported()) {  //如果已导出过或者已手工放弃导出则不会执行export逻辑\n\t                if (logger.isInfoEnabled()) {\n\t                    logger.info(\"The service ready on spring started. service: \" + getInterface());\n\t                }\n\t                export();\n\t            }\n\t        }\n\t    }\n\t    \n\t    private boolean isDelay() {\n\t        Integer delay = getDelay();\n\t        ProviderConfig provider = getProvider();\n\t        if (delay == null && provider != null) {    //若没有明确指定延迟，则尝试继承provider配置\n\t            delay = provider.getDelay();\n\t        }\n\t        return supportedApplicationListener && (delay == null || delay.intValue() == -1);   //注意这里对delay值的条件很奇怪，如果我设置delay为5000毫秒时，难道不算是延迟么？请参考\\com\\alibaba\\dubbo\\config\\ServiceConfig.java的132行\n\t    }\n\t\n\t    @SuppressWarnings({ \"unchecked\", \"deprecation\" })\n\t\tpublic void afterPropertiesSet() throws Exception {\n\t        if (getProvider() == null) {    //如果当前serviceBean并没有指定provider，则下面的逻辑为其指定默认的providerConfig（如果存在的话）\n\t            Map<String, ProviderConfig> providerConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProviderConfig.class, false, false);\n\t            if (providerConfigMap != null && providerConfigMap.size() > 0) {\n\t                Map<String, ProtocolConfig> protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n\t                if ((protocolConfigMap == null || protocolConfigMap.size() == 0)\n\t                        && providerConfigMap.size() > 1) { // 兼容旧版本\n\t                    List<ProviderConfig> providerConfigs = new ArrayList<ProviderConfig>();\n\t                    for (ProviderConfig config : providerConfigMap.values()) {\n\t                        if (config.isDefault() != null && config.isDefault().booleanValue()) {  //把所有指定为默认范围的providerConfig拿到，跳转到下面\n\t                            providerConfigs.add(config);\n\t                        }\n\t                    }\n\t                    if (providerConfigs.size() > 0) {\n\t                        setProviders(providerConfigs);  //接着上面，把所有指定为默认范围的providerConfig中与protocol相关的配置封装成protocolConfig并存入serviceConfig对应属性中\n\t                    }\n\t                } else {\n\t                    ProviderConfig providerConfig = null;\n\t                    for (ProviderConfig config : providerConfigMap.values()) {\n\t                        //如果某个provider配置包含子node（ServiceBean），且没有明确指定default，也会被当成默认配置么？这个疑问请参看：com\\alibaba\\dubbo\\config\\spring\\schema\\DubboBeanDefinitionParser.java中330行注解\n\t                        if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                            if (providerConfig != null) {   //只能有一个provider设置为默认\n\t                                throw new IllegalStateException(\"Duplicate provider configs: \" + providerConfig + \" and \" + config);\n\t                            }\n\t                            providerConfig = config;\n\t                        }\n\t                    }\n\t                    if (providerConfig != null) {\n\t                        setProvider(providerConfig);    //为serviceBean绑定继承的providerConfig\n\t                    }\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Application且其继承的provider也没有指定Application，则下面的逻辑为其指定默认的applicationConfig（如果存在的话）\n\t        if (getApplication() == null\n\t                && (getProvider() == null || getProvider().getApplication() == null)) {\n\t            Map<String, ApplicationConfig> applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false);\n\t            if (applicationConfigMap != null && applicationConfigMap.size() > 0) {\n\t                ApplicationConfig applicationConfig = null;\n\t                for (ApplicationConfig config : applicationConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        if (applicationConfig != null) {    //只能有一个Application设置为默认\n\t                            throw new IllegalStateException(\"Duplicate application configs: \" + applicationConfig + \" and \" + config);\n\t                        }\n\t                        applicationConfig = config;\n\t                    }\n\t                }\n\t                if (applicationConfig != null) {\n\t                    setApplication(applicationConfig);  //为serviceBean绑定applicationConfig\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Module且其继承的provider也没有指定Module，则下面的逻辑为其指定默认的moduleConfig（如果存在的话）\n\t        if (getModule() == null\n\t                && (getProvider() == null || getProvider().getModule() == null)) {\n\t            Map<String, ModuleConfig> moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false);\n\t            if (moduleConfigMap != null && moduleConfigMap.size() > 0) {\n\t                ModuleConfig moduleConfig = null;\n\t                for (ModuleConfig config : moduleConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        if (moduleConfig != null) { //只能有一个Module设置为默认\n\t                            throw new IllegalStateException(\"Duplicate module configs: \" + moduleConfig + \" and \" + config);\n\t                        }\n\t                        moduleConfig = config;\n\t                    }\n\t                }\n\t                if (moduleConfig != null) {\n\t                    setModule(moduleConfig);    //为serviceBean绑定moduleConfig\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Registry且其继承的provider,application也没有指定Registry，则下面的逻辑为其指定默认的registryConfig（如果存在的话）\n\t        if ((getRegistries() == null || getRegistries().size() == 0)\n\t                && (getProvider() == null || getProvider().getRegistries() == null || getProvider().getRegistries().size() == 0)\n\t                && (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().size() == 0)) {\n\t            Map<String, RegistryConfig> registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false);\n\t            if (registryConfigMap != null && registryConfigMap.size() > 0) {\n\t                List<RegistryConfig> registryConfigs = new ArrayList<RegistryConfig>();\n\t                for (RegistryConfig config : registryConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {  //允许为serviceBean指定多个Registry\n\t                        registryConfigs.add(config);\n\t                    }\n\t                }\n\t                if (registryConfigs != null && registryConfigs.size() > 0) {\n\t                    super.setRegistries(registryConfigs);\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Monitor且其继承的provider,application也没有指定Monitor，则下面的逻辑为其指定默认的monitorConfig（如果存在的话）\n\t        if (getMonitor() == null\n\t                && (getProvider() == null || getProvider().getMonitor() == null)\n\t                && (getApplication() == null || getApplication().getMonitor() == null)) {\n\t            Map<String, MonitorConfig> monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false);\n\t            if (monitorConfigMap != null && monitorConfigMap.size() > 0) {\n\t                MonitorConfig monitorConfig = null;\n\t                for (MonitorConfig config : monitorConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        if (monitorConfig != null) {    //只能有一个Monitor设置为默认\n\t                            throw new IllegalStateException(\"Duplicate monitor configs: \" + monitorConfig + \" and \" + config);\n\t                        }\n\t                        monitorConfig = config;\n\t                    }\n\t                }\n\t                if (monitorConfig != null) {\n\t                    setMonitor(monitorConfig);  //为serviceBean绑定monitorConfig\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Protocol且其继承的provider也没有指定Protocol，则下面的逻辑为其指定默认的protocolConfig（如果存在的话）\n\t        if ((getProtocols() == null || getProtocols().size() == 0)\n\t                && (getProvider() == null || getProvider().getProtocols() == null || getProvider().getProtocols().size() == 0)) {\n\t            Map<String, ProtocolConfig> protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n\t            if (protocolConfigMap != null && protocolConfigMap.size() > 0) {\n\t                List<ProtocolConfig> protocolConfigs = new ArrayList<ProtocolConfig>();\n\t                for (ProtocolConfig config : protocolConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        protocolConfigs.add(config);    //允许为serviceBean指定多个Protocol\n\t                    }\n\t                }\n\t                if (protocolConfigs != null && protocolConfigs.size() > 0) {\n\t                    super.setProtocols(protocolConfigs);\n\t                }\n\t            }\n\t        }\n\t        //设置服务路径，默认使用的是该bean在spring容器中注册的beanName，这也是该类继承BeanNameAware的原因\n\t        if (getPath() == null || getPath().length() == 0) {\n\t            if (beanName != null && beanName.length() > 0 \n\t                    && getInterface() != null && getInterface().length() > 0\n\t                    && beanName.startsWith(getInterface())) {\n\t                setPath(beanName);\n\t            }\n\t        }\n\t        //若不是延迟加载，就上演好戏\n\t        if (! isDelay()) {\n\t            export();\n\t        }\n\t    }\n\t\n\t    public void destroy() throws Exception {\n\t        unexport();\n\t    }\n\t}\n\n这里就明白为何ServiceBean和其父类ServiceConfig不在同一个包内，因为前者是为了适配spring而提供的适配器。ServiceBean依赖spring提供的相关hook接口完成了bean的初始化，最终`export`逻辑交给`ServiceConfig`来完成，这才是dubbo的核心服务配置类，这也解释了为何上面UML图中没有画ServiceBean的原因。\n\n我们继续跟着线索来看一下`ServiceConfig.export`：\n\n\tpublic synchronized void export() {\n        //从provider中继承一些必要但没有明确设置的参数\n        if (provider != null) {\n            if (export == null) {\n                export = provider.getExport();\n            }\n            if (delay == null) {\n                delay = provider.getDelay();\n            }\n        }\n        if (export != null && ! export.booleanValue()) {    //如果不需要暴露该服务，则就此结束\n            return;\n        }\n        if (delay != null && delay > 0) {   //如果明确指定了想要延迟的时间差，则依赖线程休眠来完成延迟暴露，delay的值只有为-1或null才依赖spring的事件机制完成延迟暴露\n            Thread thread = new Thread(new Runnable() {\n                public void run() {\n                    try {\n                        Thread.sleep(delay);\n                    } catch (Throwable e) {\n                    }\n                    doExport();\n                }\n            });\n            thread.setDaemon(true);\n            thread.setName(\"DelayExportServiceThread\");\n            thread.start();\n        } else {\n            doExport();\n        }\n    }\n\n一目了然，这个方法主要就是解决了到底暴露不暴露的问题，并且到底是不是延迟暴露的问题。接下来看看`doExport`方法：\n\n\tprotected synchronized void doExport() {\n        if (unexported) {\n            throw new IllegalStateException(\"Already unexported!\");\n        }\n        if (exported) {\n            return;\n        }\n\n        exported = true;    //修改暴露状态\n\n        if (interfaceName == null || interfaceName.length() == 0) {\n            throw new IllegalStateException(\"<dubbo:service interface=\\\"\\\" /> interface not allow null!\");\n        }\n\n        checkDefault(); //根据文档中提到的参数优先级，决定最终使用的配置值，在spring的xml解析阶段只是简单解析xml的配置值，在真正使用前，还需要看一下：-D和properties文件\n\n        //下面根据文档中的优先级创建对应的继承链\n        if (provider != null) { //todo 这里必然成立吧？\n            if (application == null) {\n                application = provider.getApplication();\n            }\n            if (module == null) {\n                module = provider.getModule();\n            }\n            if (registries == null) {\n                registries = provider.getRegistries();\n            }\n            if (monitor == null) {\n                monitor = provider.getMonitor();\n            }\n            if (protocols == null) {\n                protocols = provider.getProtocols();\n            }\n        }\n        if (module != null) {\n            if (registries == null) {\n                registries = module.getRegistries();\n            }\n            if (monitor == null) {\n                monitor = module.getMonitor();\n            }\n        }\n        if (application != null) {\n            if (registries == null) {\n                registries = application.getRegistries();\n            }\n            if (monitor == null) {\n                monitor = application.getMonitor();\n            }\n        }\n\n        if (ref instanceof GenericService) {    //泛接口实现方式主要用于服务器端没有API接口及模型类元的情况，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如：实现一个通用的远程服务Mock框架，可通过实现GenericService接口处理所有服务请求。\n            interfaceClass = GenericService.class;\n            if (StringUtils.isEmpty(generic)) {\n                generic = Boolean.TRUE.toString();\n            }\n        } else {\n            try {\n                interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                        .getContextClassLoader());\n            } catch (ClassNotFoundException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            checkInterfaceAndMethods(interfaceClass, methods);  //检查接口和方法的匹配情况\n            checkRef(); //检查接口和实现的匹配情况\n            generic = Boolean.FALSE.toString();\n        }\n\n        if(local !=null){   //todo 文档中并没有与local相关的参数解释\n            if(local==\"true\"){\n                local=interfaceName+\"Local\";\n            }\n            Class<?> localClass;\n            try {\n                localClass = ClassHelper.forNameWithThreadContextClassLoader(local);\n            } catch (ClassNotFoundException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            if(!interfaceClass.isAssignableFrom(localClass)){\n                throw new IllegalStateException(\"The local implemention class \" + localClass.getName() + \" not implement interface \" + interfaceName);\n            }\n        }\n\n        //本地存根，http://alibaba.github.io/dubbo-doc-static/Stub+Proxy-zh.htm\n        if(stub !=null){\n            if(stub==\"true\"){\n                stub=interfaceName+\"Stub\";  //todo 这里文档中的解释貌似有错误：http://alibaba.github.io/dubbo-doc-static/Service+Config-zh.htm\n            }\n            Class<?> stubClass;\n            try {\n                stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub);\n            } catch (ClassNotFoundException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            if(!interfaceClass.isAssignableFrom(stubClass)){\n                throw new IllegalStateException(\"The stub implemention class \" + stubClass.getName() + \" not implement interface \" + interfaceName);\n            }\n        }\n\n        //作用雷同于上面的checkDefault()，根据文档中提到的参数优先级来选择使用的配置参数\n        checkApplication();\n        checkRegistry();\n        checkProtocol();\n        appendProperties(this);\n\n        checkStubAndMock(interfaceClass);   //检查local，stub和mock的有效性\n\n        if (path == null || path.length() == 0) {   //此时path如果还为空，这使用interfaceName\n            path = interfaceName;\n        }\n        \n        doExportUrls();\n    }\n\n木牛错，`doExport`方法依然是在做预备工作，感觉越来越靠近真像了，目前为止，我们已经按照规定的优先级最终确定了要暴露成为服务的bean的\"大部分\"相关配置参数，并校验了相关参数的有效性（例如：ref，method，stub，mock，path等）。再来看一下`doExportUrls`方法：\n\n\tprivate void doExportUrls() {\n        List<URL> registryURLs = loadRegistries(true);  //获取所有的注册中心地址\n        for (ProtocolConfig protocolConfig : protocols) {\n            doExportUrlsFor1Protocol(protocolConfig, registryURLs);\n        }\n    }\n\n好，是该真刀真枪干一架的时候了，`doExportUrlsFor1Protocol`应该就是今次的Boss，解决掉它我们就回家。\n\n\tprivate void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {\n        String name = protocolConfig.getName();\n        if (name == null || name.length() == 0) {\n            name = \"dubbo\"; //N多次的检查，N多次的赋值，这算是严谨呢？还是重复？\n        }\n\n        String host = protocolConfig.getHost();\n        if (provider != null && (host == null || host.length() == 0)) {\n            host = provider.getHost();\n        }\n        boolean anyhost = false;\n        if (NetUtils.isInvalidLocalHost(host)) {    //检查host是否为本地ip，或者无效的\n            anyhost = true;\n            try {\n                host = InetAddress.getLocalHost().getHostAddress();\n            } catch (UnknownHostException e) {\n                logger.warn(e.getMessage(), e);\n            }\n            if (NetUtils.isInvalidLocalHost(host)) {    //如果拿到的还是本地地址，就只能出杀手锏了\n                if (registryURLs != null && registryURLs.size() > 0) {\n                    for (URL registryURL : registryURLs) {\n                        try {\n                            Socket socket = new Socket();\n                            try {\n                                //尝试连接注册中心，选用连接时使用的ip地址\n                                SocketAddress addr = new InetSocketAddress(registryURL.getHost(), registryURL.getPort());\n                                socket.connect(addr, 1000);\n                                host = socket.getLocalAddress().getHostAddress();\n                                break;\n                            } finally {\n                                try {\n                                    socket.close();\n                                } catch (Throwable e) {}\n                            }\n                        } catch (Exception e) {\n                            logger.warn(e.getMessage(), e);\n                        }\n                    }\n                }\n                if (NetUtils.isInvalidLocalHost(host)) {\n                    host = NetUtils.getLocalHost(); //实在不行，就只能使用本机上第一个找到的合法ip了\n                }\n            }\n        }\n\n        Integer port = protocolConfig.getPort();\n        if (provider != null && (port == null || port == 0)) {\n            port = provider.getPort();\n        }\n        final int defaultPort = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(name).getDefaultPort();\n        if (port == null || port == 0) {\n            port = defaultPort;\n        }\n        if (port == null || port <= 0) {\n            port = getRandomPort(name);\n            if (port == null || port < 0) {\n                port = NetUtils.getAvailablePort(defaultPort);  //到这里如果还没有拿到port，就直接随机拿个能用的端口\n                putRandomPort(name, port);  //这一步很讲究，意味着相同协议使用相同的端口，要理解这个就需要先消化dubbo底层通信方式。\n            }\n            logger.warn(\"Use random available port(\" + port + \") for protocol \" + name);\n        }\n\n        Map<String, String> map = new HashMap<String, String>();\n        if (anyhost) {\n            map.put(Constants.ANYHOST_KEY, \"true\");\n        }\n        map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE);\n        map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion());\n        map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));\n        if (ConfigUtils.getPid() > 0) {\n            map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));\n        }\n\n        //获取相关的配置参数用于后面的url生成，注意优先级顺序哟\n        appendParameters(map, application);\n        appendParameters(map, module);\n        appendParameters(map, provider, Constants.DEFAULT_KEY);\n        appendParameters(map, protocolConfig);\n        appendParameters(map, this);\n\n        if (methods != null && methods.size() > 0) {\n            for (MethodConfig method : methods) {\n                appendParameters(map, method, method.getName());\n\n                //处理重试设置\n                String retryKey = method.getName() + \".retry\";\n                if (map.containsKey(retryKey)) {\n                    String retryValue = map.remove(retryKey);\n                    if (\"false\".equals(retryValue)) {\n                        map.put(method.getName() + \".retries\", \"0\");\n                    }\n                }\n\n                List<ArgumentConfig> arguments = method.getArguments();\n                if (arguments != null && arguments.size() > 0) {\n                    for (ArgumentConfig argument : arguments) { //ArgumentConfig作用主要就是用来完成事件回调机制。\n                        //类型自动转换.\n                        if(argument.getType() != null && argument.getType().length() >0){\n                            Method[] methods = interfaceClass.getMethods();\n                            //遍历所有方法\n                            if(methods != null && methods.length > 0){\n                                for (int i = 0; i < methods.length; i++) {\n                                    String methodName = methods[i].getName();\n                                    //匹配方法名称，获取方法签名.\n                                    if(methodName.equals(method.getName())){    //注意方法重载情况\n                                        Class<?>[] argtypes = methods[i].getParameterTypes();\n                                        //一个方法中单个callback\n                                        if (argument.getIndex() != -1 ){    //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                            if (argtypes[argument.getIndex()].getName().equals(argument.getType())){\n                                                appendParameters(map, argument, method.getName() + \".\" + argument.getIndex());\n                                            }else {\n                                                throw new IllegalArgumentException(\"argument config error : the index attribute and type attirbute not match :index :\"+argument.getIndex() + \", type:\" + argument.getType());\n                                            }\n                                        } else {\n                                            //一个方法中多个callback\n                                            for (int j = 0 ;j<argtypes.length ;j++) {   //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                                Class<?> argclazz = argtypes[j];\n                                                if (argclazz.getName().equals(argument.getType())){\n                                                    appendParameters(map, argument, method.getName() + \".\" + j);\n                                                    if (argument.getIndex() != -1 && argument.getIndex() != j){\n                                                        throw new IllegalArgumentException(\"argument config error : the index attribute and type attirbute not match :index :\"+argument.getIndex() + \", type:\" + argument.getType());\n                                                    }\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }else if(argument.getIndex() != -1){\n                            appendParameters(map, argument, method.getName() + \".\" + argument.getIndex());\n                        }else {\n                            throw new IllegalArgumentException(\"argument config must set index or type attribute.eg: <dubbo:argument index='0' .../> or <dubbo:argument type=xxx .../>\");\n                        }\n\n                    }\n                }\n            } // end of methods for\n        }\n\n        if (ProtocolUtils.isGeneric(generic)) { //处理泛化\n            map.put(\"generic\", generic);\n            map.put(\"methods\", Constants.ANY_VALUE);\n        } else {\n            String revision = Version.getVersion(interfaceClass, version);\n            if (revision != null && revision.length() > 0) {\n                map.put(\"revision\", revision);  //todo 为什么是revision?\n            }\n\n            String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); //todo 动态封装interfaceClass，目前不知道干啥用，猜测dubbo直接操作的都是这个封装后的wrapper\n            if(methods.length == 0) {\n                logger.warn(\"NO method found in service interface \" + interfaceClass.getName());\n                map.put(\"methods\", Constants.ANY_VALUE);\n            }\n            else {\n                map.put(\"methods\", StringUtils.join(new HashSet<String>(Arrays.asList(methods)), \",\"));\n            }\n        }\n\n        //令牌验证，为空表示不开启，如果为true，表示随机生成动态令牌，否则使用静态令牌，令牌的作用是防止消费者绕过注册中心直接访问，保证注册中心的授权功能有效，如果使用点对点调用，需关闭令牌功能\n        if (! ConfigUtils.isEmpty(token)) {\n            if (ConfigUtils.isDefault(token)) {\n                map.put(\"token\", UUID.randomUUID().toString());\n            } else {\n                map.put(\"token\", token);\n            }\n        }\n\n        //injvm表示不会跨进程，所以不需要注册中心\n        if (\"injvm\".equals(protocolConfig.getName())) {\n            protocolConfig.setRegister(false);\n            map.put(\"notify\", \"false\");\n        }\n\n        // 导出服务\n        String contextPath = protocolConfig.getContextpath();\n        if ((contextPath == null || contextPath.length() == 0) && provider != null) {\n            contextPath = provider.getContextpath();\n        }\n        URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? \"\" : contextPath + \"/\") + path, map);   //拿到服务的url\n\n        if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n                .hasExtension(url.getProtocol())) {\n            url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n                    .getExtension(url.getProtocol()).getConfigurator(url).configure(url);\n        }\n\n        String scope = url.getParameter(Constants.SCOPE_KEY);\n        //配置为none不暴露\n        if (! Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) {\n\n            //配置不是remote的情况下做本地暴露 (配置为remote，则表示只暴露远程服务)\n            if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) {\n                exportLocal(url);\n            }\n            //如果配置不是local则暴露为远程服务.(配置为local，则表示只暴露远程服务)\n            if (! Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope) ){\n                if (logger.isInfoEnabled()) {\n                    logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to url \" + url);\n                }\n                if (registryURLs != null && registryURLs.size() > 0\n                        && url.getParameter(\"register\", true)) {\n                    for (URL registryURL : registryURLs) {\n                        url = url.addParameterIfAbsent(\"dynamic\", registryURL.getParameter(\"dynamic\"));\n                        URL monitorUrl = loadMonitor(registryURL);\n                        if (monitorUrl != null) {\n                            url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString());\n                        }\n                        if (logger.isInfoEnabled()) {\n                            logger.info(\"Register dubbo service \" + interfaceClass.getName() + \" url \" + url + \" to registry \" + registryURL);\n                        }\n                        //todo 暴露为何要封装一层代理呢？\n                        Invoker<?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()));\n\n                        Exporter<?> exporter = protocol.export(invoker);\n                        exporters.add(exporter);\n                    }\n                } else {\n                    //todo 暴露为何要封装一层代理呢？\n                    Invoker<?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\n                    Exporter<?> exporter = protocol.export(invoker);\n                    exporters.add(exporter);\n                }\n            }\n        }\n        this.urls.add(url);\n    }\n\n一路走来可以发现，dubbo会为每个有效协议暴露一份服务，并且会注册到所有有效的注册中心里。而bean转变为service中最重要的就是映射出来的`URL`，也就是说我们在配置文件中进行的相关配置都会映射成对应url中的相关部分，举个例子：\n\n\t<dubbo:application name=\"demo-provider\" owner=\"programmer\" organization=\"dubbox\"/>\n    <dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/>\n\t<dubbo:protocol name=\"dubbo\" serialization=\"kryo\" optimizer=\"com.alibaba.dubbo.demo.SerializationOptimizerImpl\"/>\n\n\t<bean id=\"bidService\" class=\"com.alibaba.dubbo.demo.bid.BidServiceImpl\" />\n\t<dubbo:service interface=\"com.alibaba.dubbo.demo.bid.BidService\" ref=\"bidService\"  protocol=\"dubbo\" />\n\n我们通过debug看一下最终它映射出来的url是什么：\n\n\t//exportLocal\n\tinjvm://127.0.0.1/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&application=demo-provider&dubbo=2.0.0&generic=false&interface=com.alibaba.dubbo.demo.bid.BidService&methods=throwNPE,bid&optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&organization=dubbox&owner=programmer&pid=3872&serialization=kryo&side=provider&timestamp=1422241023451\n\n\t//exportRemote\n\tregistry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&dubbo=2.0.0&export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&organization=dubbox&owner=programmer&pid=3872&registry=zookeeper&timestamp=1422240274186\n\n那么这个`url`的作用是什么呢？官方给出的[解释](http://alibaba.github.io/dubbo-doc-static/Init+Detail-zh.htm)很明确，这个url作为解耦的通信数据（跨层调用的参数），有了它dubbo就可以更容易做到业务逻辑实现的替换。除此之外可以看到url中还包含了大量的辅助参数（例如：timeout，version，organization等）供服务治理使用，这些都是根据真实需求一步一步补充完善的，可见，**好的架构是演化而来的**。\n\n\n可以看到贴出来的代码中包含很多todo项，其中一些问题我们从代码层面是很难找到答案的，我们需要上升到业务，运维甚至架构师高度才能消化得了，小弟将在后续的分析中慢慢的尝试解开谜团。","source":"_posts/dubbo如何一步一步拿到bean.md","raw":"title: dubbo如何一步一步拿到bean\ndate: 2015-01-26 18:54:30\ntags:\n- dubbo\n- dubbox\n- spring\n\ncategories: j2ee\n---\n\n\ndubbo依赖了spring提供的现成机制完成了bean的创建，我们来看一下这其中的汰渍。\n\n<!-- more -->\n\n配置\n---\n\n关于dubbo的配置相关细节，官方已经给了一个无比详细的[文档](http://alibaba.github.io/dubbo-doc-static/Configuration+Reference-zh.htm)，[文档2](http://alibaba.github.io/dubbo-doc-static/Configs-zh.htm)。不过由于dubbo可供配置的参数非常多，这也是让我们新手一开始感到最为头疼的，这也是SOA复杂的表象之一。\n\n\nxml -> beanDefinition\n---\n对于我这种小学生，需要先补习一个基础知识点：[基于Spring可扩展Schema提供自定义配置支持](http://www.cnblogs.com/jifeng/archive/2011/09/14/2176599.html)。dubbo是依赖spring提供的这种机制来处理配置文件解析的，理解起来没什么难度。\n\n看一下dubbo-congfig的目录结构：\n\n![](http://pic.yupoo.com/kazaff/EllS0JnY/lFpRv.png)\n\n我们来看一下dubbo是如何按照spring提供的机制来处理配置文件的：\n\n\t#spring.handlers\n\thttp\\://code.alibabatech.com/schema/dubbo=com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler\n\n\t#spring.schemas\n\thttp\\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd\n\n这样我们就锁定了要分析的类：\n\n\tpackage com.alibaba.dubbo.config.spring.schema;\n\n\tpublic class DubboNamespaceHandler extends NamespaceHandlerSupport {\n\n\t\tstatic {\n\t\t\tVersion.checkDuplicate(DubboNamespaceHandler.class); //确保系统中只存在一份解析处理器类定义\n\t\t}\n\t\n\t\tpublic void init() {\n\t\t    registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true));\n\t        registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true));\n\t        registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true));\n\t        registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true));\n\t        registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true));\n\t        registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true));\n\t        registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true));\n\t        registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true));\n\t        registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false));\n\t        registerBeanDefinitionParser(\"annotation\", new DubboBeanDefinitionParser(AnnotationBean.class, true));\n\t    }\n\t}\n\n按照spring提供的机制，dubbo把每个自定义的可使用配置元素和对应的解析器绑定到一起。而真正负责把配置文件中声明的内容解析成对应的BeanDefinition（可以想象为Bean的模子）是靠`DubboBeanDefinitionParser.parse`类完成，我们就来严肃的分析一下这个方法。\n\t\n\t/**\n\t * AbstractBeanDefinitionParser\n\t * \n\t * @author william.liangf\n\t * @export\n\t */\n\tpublic class DubboBeanDefinitionParser implements BeanDefinitionParser {\n\t    \n\t    private static final Logger logger = LoggerFactory.getLogger(DubboBeanDefinitionParser.class);\n\t\t\n\t    private final Class<?> beanClass;\n\t    \n\t    private final boolean required;\n\t\n\t    public DubboBeanDefinitionParser(Class<?> beanClass, boolean required) {\n\t        this.beanClass = beanClass;\n\t        this.required = required;\n\t    }\n\t\n\t    public BeanDefinition parse(Element element, ParserContext parserContext) {\n\t        return parse(element, parserContext, beanClass, required);\n\t    }\n\t    \n\t    @SuppressWarnings(\"unchecked\")\n\t    private static BeanDefinition parse(Element element, ParserContext parserContext, Class<?> beanClass, boolean required) {\n\t        //初始化BeanDefiniion\n\t        RootBeanDefinition beanDefinition = new RootBeanDefinition();\n\t        beanDefinition.setBeanClass(beanClass);\n\t        beanDefinition.setLazyInit(false);\n\t\n\t        String id = element.getAttribute(\"id\");\n\t        if ((id == null || id.length() == 0) && required) {\n\t        \tString generatedBeanName = element.getAttribute(\"name\");\n\t        \tif (generatedBeanName == null || generatedBeanName.length() == 0) {\n\t        \t    if (ProtocolConfig.class.equals(beanClass)) {   //如果当前解析的类型是ProtocolConfig，则设置默认id为dubbo\n\t        \t        generatedBeanName = \"dubbo\";\n\t        \t    } else {\n\t        \t        generatedBeanName = element.getAttribute(\"interface\");  //其他情况，默认id为接口类型\n\t        \t    }\n\t        \t}\n\t        \tif (generatedBeanName == null || generatedBeanName.length() == 0) {\n\t        \t\tgeneratedBeanName = beanClass.getName();    //如果该节点没有interface属性（包含：registry,monitor,provider,consumer），则使用该节点的类型为id值\n\t        \t}\n\t            id = generatedBeanName; \n\t            int counter = 2;\n\t            while(parserContext.getRegistry().containsBeanDefinition(id)) { //生成不重复的id\n\t                id = generatedBeanName + (counter ++);\n\t            }\n\t        }\n\t        if (id != null && id.length() > 0) {    //目前这个判断不知道啥意义，目测必定会返回true\n\t            if (parserContext.getRegistry().containsBeanDefinition(id))  {  //这个判断应该用于防止并发\n\t        \t\tthrow new IllegalStateException(\"Duplicate spring bean id \" + id);\n\t        \t}\n\t            //注册beanDefinition，BeanDefinitionRegistry相当于一张注册表\n\t            parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);\n\t            beanDefinition.getPropertyValues().addPropertyValue(\"id\", id);\n\t        }\n\t        //下面这几个if-else分别针对不同类型做特殊处理\n\t        if (ProtocolConfig.class.equals(beanClass)) {\n\t            //这段代码的逻辑是用来适配：当<dubbo:protocol>声明出现在配置文件中使用该协议的bean声明的后面时，解决它们之间的依赖关系的。\n\t            for (String name : parserContext.getRegistry().getBeanDefinitionNames()) {\n\t                BeanDefinition definition = parserContext.getRegistry().getBeanDefinition(name);\n\t                PropertyValue property = definition.getPropertyValues().getPropertyValue(\"protocol\");\n\t                if (property != null) {\n\t                    Object value = property.getValue();\n\t                    //如果被检查的bean确实使用当前协议，则建立它们之间的依赖关系\n\t                    if (value instanceof ProtocolConfig && id.equals(((ProtocolConfig) value).getName())) {\n\t                        definition.getPropertyValues().addPropertyValue(\"protocol\", new RuntimeBeanReference(id));\n\t                    }\n\t                }\n\t            }\n\t        } else if (ServiceBean.class.equals(beanClass)) {\n\t            String className = element.getAttribute(\"class\");   //虽然文档上没有标注该配置支持class参数，但是在dubbo.xsd上却能看到这个属性的定义，类似这样的情况还有很多。\n\t            if(className != null && className.length() > 0) {   //下面的处理方式应该算是语法糖吧，它支持直接把定义bean和创建serviceConfig压缩成一行\n\t                RootBeanDefinition classDefinition = new RootBeanDefinition();\n\t                classDefinition.setBeanClass(ReflectUtils.forName(className));\n\t                classDefinition.setLazyInit(false);\n\t                parseProperties(element.getChildNodes(), classDefinition);  //完成bean的初始化工作（注入等）\n\t                beanDefinition.getPropertyValues().addPropertyValue(\"ref\", new BeanDefinitionHolder(classDefinition, id + \"Impl\")); //关联bean和serviceConfig\n\t            }\n\t        } else if (ProviderConfig.class.equals(beanClass)) {    //按照providerConfig的定义解析并关联其影响的相关serviceConfig\n\t            parseNested(element, parserContext, ServiceBean.class, true, \"service\", \"provider\", id, beanDefinition);\n\t        } else if (ConsumerConfig.class.equals(beanClass)) {    //按照consumerConfig的定义解析并关联其影响的相关referenceConfig\n\t            parseNested(element, parserContext, ReferenceBean.class, false, \"reference\", \"consumer\", id, beanDefinition);\n\t        }\n\t        Set<String> props = new HashSet<String>();\n\t        ManagedMap parameters = null;\n\t        for (Method setter : beanClass.getMethods()) {  //利用反射拿到指定类型的所有用于注入的方法\n\t            String name = setter.getName();\n\t            if (name.length() > 3 && name.startsWith(\"set\")\n\t                    && Modifier.isPublic(setter.getModifiers())\n\t                    && setter.getParameterTypes().length == 1) {    //注入方法的特征是：以set字母开头，是公共方法，且参数个数为1\n\t                Class<?> type = setter.getParameterTypes()[0];\n\t                String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), \"-\");    //把方法名字的驼峰格式改成-分割格式\n\t                props.add(property);\n\t                Method getter = null;\n\t                try {\n\t                    getter = beanClass.getMethod(\"get\" + name.substring(3), new Class<?>[0]);\n\t                } catch (NoSuchMethodException e) {\n\t                    try {\n\t                        getter = beanClass.getMethod(\"is\" + name.substring(3), new Class<?>[0]);\n\t                    } catch (NoSuchMethodException e2) {\n\t                    }\n\t                }\n\t                if (getter == null \n\t                        || ! Modifier.isPublic(getter.getModifiers())\n\t                        || ! type.equals(getter.getReturnType())) { //如果没有满足条件的对应getter方法存在，则直接跳过该setter方法\n\t                    continue;\n\t                }\n\t\n\t                if (\"parameters\".equals(property)) {    //从配置文件中解析出parameter配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用，parameter的值当string类型解析\n\t                    parameters = parseParameters(element.getChildNodes(), beanDefinition);\n\t                } else if (\"methods\".equals(property)) {    //注入对应的method配置\n\t                    parseMethods(id, element.getChildNodes(), beanDefinition, parserContext);\n\t                } else if (\"arguments\".equals(property)) {  //为method注入对应的argument配置\n\t                    parseArguments(id, element.getChildNodes(), beanDefinition, parserContext);\n\t                } else {\n\t                    String value = element.getAttribute(property);  //检查该setter方法所适配要注入的属性是否在配置中明确定义\n\t                    if (value != null) {    //若存在定义，则完成其注入解析\n\t                    \tvalue = value.trim();\n\t                    \tif (value.length() > 0) {\n\t                    \t\tif (\"registry\".equals(property) && RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(value)) {   //处理无注册中心的情况\n\t                            \tRegistryConfig registryConfig = new RegistryConfig();\n\t                            \tregistryConfig.setAddress(RegistryConfig.NO_AVAILABLE);\n\t                            \tbeanDefinition.getPropertyValues().addPropertyValue(property, registryConfig);\n\t                            } else if (\"registry\".equals(property) && value.indexOf(',') != -1) {   //处理多注册中心的情况\n\t                    \t\t\tparseMultiRef(\"registries\", value, beanDefinition, parserContext);\n\t                            } else if (\"provider\".equals(property) && value.indexOf(',') != -1) {   //处理继承多个provider的情况，缺使用第一个provider配置\n\t                            \tparseMultiRef(\"providers\", value, beanDefinition, parserContext);\n\t                            } else if (\"protocol\".equals(property) && value.indexOf(',') != -1) {   //处理多协议暴露\n\t                                parseMultiRef(\"protocols\", value, beanDefinition, parserContext);\n\t                            } else {\n\t                                Object reference;\n\t                                if (isPrimitive(type)) {    //如果setter的参数类型为jdk原始类型，直接当string注入到对应属性中去\n\t                                    if (\"async\".equals(property) && \"false\".equals(value)\n\t                                            || \"timeout\".equals(property) && \"0\".equals(value)\n\t                                            || \"delay\".equals(property) && \"0\".equals(value)\n\t                                            || \"version\".equals(property) && \"0.0.0\".equals(value)\n\t                                            || \"stat\".equals(property) && \"-1\".equals(value)\n\t                                            || \"reliable\".equals(property) && \"false\".equals(value)) {\n\t                                        // 兼容旧版本xsd中的default值\n\t                                        value = null;\n\t                                    }\n\t                                    reference = value;\n\t                                } else if (\"protocol\".equals(property) \n\t                                        && ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(value)   //是否存在指定的扩展点定义\n\t                                        && (! parserContext.getRegistry().containsBeanDefinition(value) //检查当前解析出的要使用协议对应的protocolConfig是否已经被初始化\n\t                                                || ! ProtocolConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n\t                                    if (\"dubbo:provider\".equals(element.getTagName())) {\n\t                                        logger.warn(\"Recommended replace <dubbo:provider protocol=\\\"\" + value + \"\\\" ... /> to <dubbo:protocol name=\\\"\" + value + \"\\\" ... />\");\n\t                                    }\n\t                                    // 兼容旧版本配置\n\t                                    ProtocolConfig protocol = new ProtocolConfig();\n\t                                    protocol.setName(value);\n\t                                    reference = protocol;\n\t                                } else if (\"monitor\".equals(property) \n\t                                        && (! parserContext.getRegistry().containsBeanDefinition(value)\n\t                                                || ! MonitorConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n\t                                    // 兼容旧版本配置\n\t                                    reference = convertMonitor(value);\n\t                                } else if (\"onreturn\".equals(property)) {   //对应methodConfig中的返回拦截\n\t                                    int index = value.lastIndexOf(\".\");\n\t                                    String returnRef = value.substring(0, index);\n\t                                    String returnMethod = value.substring(index + 1);\n\t                                    reference = new RuntimeBeanReference(returnRef);\n\t                                    beanDefinition.getPropertyValues().addPropertyValue(\"onreturnMethod\", returnMethod);\n\t                                } else if (\"onthrow\".equals(property)) {    //对应methodConfig中的异常拦截\n\t                                    int index = value.lastIndexOf(\".\");\n\t                                    String throwRef = value.substring(0, index);\n\t                                    String throwMethod = value.substring(index + 1);\n\t                                    reference = new RuntimeBeanReference(throwRef);\n\t                                    beanDefinition.getPropertyValues().addPropertyValue(\"onthrowMethod\", throwMethod);\n\t                                } else {\n\t                                    if (\"ref\".equals(property) && parserContext.getRegistry().containsBeanDefinition(value)) {\n\t                                        BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(value);\n\t                                        if (! refBean.isSingleton()) {\n\t                                            throw new IllegalStateException(\"The exported service ref \" + value + \" must be singleton! Please set the \" + value + \" bean scope to singleton, eg: <bean id=\\\"\" + value+ \"\\\" scope=\\\"singleton\\\" ...>\");\n\t                                        }\n\t                                    }\n\t                                    reference = new RuntimeBeanReference(value);\n\t                                }\n\t\t\t                        beanDefinition.getPropertyValues().addPropertyValue(property, reference);\n\t                            }\n\t                    \t}\n\t                    }\n\t                }\n\t            }\n\t        }\n\t        NamedNodeMap attributes = element.getAttributes();\n\t        int len = attributes.getLength();\n\t        for (int i = 0; i < len; i++) {\n\t            Node node = attributes.item(i);\n\t            String name = node.getLocalName();\n\t            if (! props.contains(name)) {   //处理配置中声明的没有满足注入条件的剩余属性\n\t                if (parameters == null) {\n\t                    parameters = new ManagedMap();\n\t                }\n\t                String value = node.getNodeValue();\n\t                parameters.put(name, new TypedStringValue(value, String.class));\n\t            }\n\t        }\n\t        if (parameters != null) {\n\t            beanDefinition.getPropertyValues().addPropertyValue(\"parameters\", parameters);\n\t        }\n\t        return beanDefinition;\n\t    }\n\t\n\t    private static final Pattern GROUP_AND_VERION = Pattern.compile(\"^[\\\\-.0-9_a-zA-Z]+(\\\\:[\\\\-.0-9_a-zA-Z]+)?$\");\n\t    \n\t    protected static MonitorConfig convertMonitor(String monitor) {\n\t        if (monitor == null || monitor.length() == 0) {\n\t            return null;\n\t        }\n\t        if (GROUP_AND_VERION.matcher(monitor).matches()) {\n\t            String group;\n\t            String version;\n\t            int i = monitor.indexOf(':');\n\t            if (i > 0) {\n\t                group = monitor.substring(0, i);\n\t                version = monitor.substring(i + 1);\n\t            } else {\n\t                group = monitor;\n\t                version = null;\n\t            }\n\t            MonitorConfig monitorConfig = new MonitorConfig();\n\t            monitorConfig.setGroup(group);\n\t            monitorConfig.setVersion(version);\n\t            return monitorConfig;\n\t        }\n\t        return null;\n\t    }\n\t \n\t    private static boolean isPrimitive(Class<?> cls) {\n\t        return cls.isPrimitive() || cls == Boolean.class || cls == Byte.class\n\t                || cls == Character.class || cls == Short.class || cls == Integer.class\n\t                || cls == Long.class || cls == Float.class || cls == Double.class\n\t                || cls == String.class || cls == Date.class || cls == Class.class;\n\t    }\n\t    \n\t    @SuppressWarnings(\"unchecked\")\n\t\tprivate static void parseMultiRef(String property, String value, RootBeanDefinition beanDefinition,\n\t            ParserContext parserContext) {\n\t    \tString[] values = value.split(\"\\\\s*[,]+\\\\s*\");\n\t\t\tManagedList list = null;\n\t        for (int i = 0; i < values.length; i++) {\n\t            String v = values[i];\n\t            if (v != null && v.length() > 0) {\n\t            \tif (list == null) {\n\t                    list = new ManagedList();\n\t                }\n\t            \tlist.add(new RuntimeBeanReference(v));\n\t            }\n\t        }\n\t        beanDefinition.getPropertyValues().addPropertyValue(property, list);\n\t    }\n\t    \n\t    private static void parseNested(Element element,\n\t                                    ParserContext parserContext,\n\t                                    Class<?> beanClass,\n\t                                    boolean required,\n\t                                    String tag,\n\t                                    String property,\n\t                                    String ref,\n\t                                    BeanDefinition beanDefinition) {\n\t        NodeList nodeList = element.getChildNodes();\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            boolean first = true;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    if (tag.equals(node.getNodeName())\n\t                            || tag.equals(node.getLocalName())) {\n\t                        if (first) {\n\t                            //如果该providerBean没有设置default开关，且子节点中定义了serviceBean，则明确赋值该参数为false，也就是说该providerBean只作为其子serviceBean节点的默认协议\n\t                            //这样就不会让该providerBean的作用范围盲目扩大（成为所有serviceBean的默认协议）\n\t                            first = false;\n\t                            String isDefault = element.getAttribute(\"default\");\n\t                            if (isDefault == null || isDefault.length() == 0) {\n\t                                beanDefinition.getPropertyValues().addPropertyValue(\"default\", \"false\");\n\t                            }\n\t                        }\n\t                        //所有子serviceBean定义节点全部解析并引用该providerBean作为默认值配置\n\t                        BeanDefinition subDefinition = parse((Element) node, parserContext, beanClass, required);\n\t                        if (subDefinition != null && ref != null && ref.length() > 0) {\n\t                            subDefinition.getPropertyValues().addPropertyValue(property, new RuntimeBeanReference(ref));\n\t                        }\n\t                    }\n\t                }\n\t            }\n\t        }\n\t    }\n\t\n\t    private static void parseProperties(NodeList nodeList, RootBeanDefinition beanDefinition) {\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    if (\"property\".equals(node.getNodeName())\n\t                            || \"property\".equals(node.getLocalName())) {\n\t                        String name = ((Element) node).getAttribute(\"name\");\n\t                        if (name != null && name.length() > 0) {\n\t                            String value = ((Element) node).getAttribute(\"value\");  //java基础类型\n\t                            String ref = ((Element) node).getAttribute(\"ref\");  //引用其他bean\n\t                            if (value != null && value.length() > 0) {\n\t                                beanDefinition.getPropertyValues().addPropertyValue(name, value);\n\t                            } else if (ref != null && ref.length() > 0) {\n\t                                beanDefinition.getPropertyValues().addPropertyValue(name, new RuntimeBeanReference(ref));\n\t                            } else {\n\t                                throw new UnsupportedOperationException(\"Unsupported <property name=\\\"\" + name + \"\\\"> sub tag, Only supported <property name=\\\"\" + name + \"\\\" ref=\\\"...\\\" /> or <property name=\\\"\" + name + \"\\\" value=\\\"...\\\" />\");\n\t                            }\n\t                        }\n\t                    }\n\t                }\n\t            }\n\t        }\n\t    }\n\t\n\t    @SuppressWarnings(\"unchecked\")\n\t    private static ManagedMap parseParameters(NodeList nodeList, RootBeanDefinition beanDefinition) {   //解析参数配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用。\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            ManagedMap parameters = null;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    if (\"parameter\".equals(node.getNodeName())\n\t                            || \"parameter\".equals(node.getLocalName())) {\n\t                        if (parameters == null) {\n\t                            parameters = new ManagedMap();\n\t                        }\n\t                        String key = ((Element) node).getAttribute(\"key\");\n\t                        String value = ((Element) node).getAttribute(\"value\");\n\t                        boolean hide = \"true\".equals(((Element) node).getAttribute(\"hide\"));\n\t                        if (hide) {\n\t                            key = Constants.HIDE_KEY_PREFIX + key;\n\t                        }\n\t                        parameters.put(key, new TypedStringValue(value, String.class)); //注意parameter的值都是string类型\n\t                    }\n\t                }\n\t            }\n\t            return parameters;\n\t        }\n\t        return null;\n\t    }\n\t\n\t    @SuppressWarnings(\"unchecked\")\n\t    private static void parseMethods(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n\t                              ParserContext parserContext) {\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            ManagedList methods = null;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    Element element = (Element) node;\n\t                    if (\"method\".equals(node.getNodeName()) || \"method\".equals(node.getLocalName())) {\n\t                        String methodName = element.getAttribute(\"name\");\n\t                        if (methodName == null || methodName.length() == 0) {   //name为必填项，这一点在文档里也表明\n\t                            throw new IllegalStateException(\"<dubbo:method> name attribute == null\");\n\t                        }\n\t                        if (methods == null) {\n\t                            methods = new ManagedList();\n\t                        }\n\t                        BeanDefinition methodBeanDefinition = parse(((Element) node),\n\t                                parserContext, MethodConfig.class, false);  //解析methodConfig\n\t                        String name = id + \".\" + methodName;    //注意这里，方法的名称前会加上bean的id\n\t                        BeanDefinitionHolder methodBeanDefinitionHolder = new BeanDefinitionHolder(\n\t                                methodBeanDefinition, name);\n\t                        methods.add(methodBeanDefinitionHolder);\n\t                    }\n\t                }\n\t            }\n\t            if (methods != null) {\n\t                beanDefinition.getPropertyValues().addPropertyValue(\"methods\", methods);    //关联bean和其method\n\t            }\n\t        }\n\t    }\n\t    \n\t    @SuppressWarnings(\"unchecked\")\n\t    private static void parseArguments(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n\t                              ParserContext parserContext) {\n\t        if (nodeList != null && nodeList.getLength() > 0) {\n\t            ManagedList arguments = null;\n\t            for (int i = 0; i < nodeList.getLength(); i++) {\n\t                Node node = nodeList.item(i);\n\t                if (node instanceof Element) {\n\t                    Element element = (Element) node;\n\t                    if (\"argument\".equals(node.getNodeName()) || \"argument\".equals(node.getLocalName())) {\n\t                        String argumentIndex = element.getAttribute(\"index\");   //不清楚这里为何没有必填校验\n\t                        if (arguments == null) {\n\t                            arguments = new ManagedList();\n\t                        }\n\t                        BeanDefinition argumentBeanDefinition = parse(((Element) node),\n\t                                parserContext, ArgumentConfig.class, false);\n\t                        String name = id + \".\" + argumentIndex;\n\t                        BeanDefinitionHolder argumentBeanDefinitionHolder = new BeanDefinitionHolder(\n\t                                argumentBeanDefinition, name);\n\t                        arguments.add(argumentBeanDefinitionHolder);\n\t                    }\n\t                }\n\t            }\n\t            if (arguments != null) {\n\t                beanDefinition.getPropertyValues().addPropertyValue(\"arguments\", arguments);    //关联arguments和其method\n\t            }\n\t        }\n\t    }\n\t\n\t}\n\n现在，我们的dubbo就已经把配置文件中定义的bean全部解析成对应的**beanDefinition**，为spring的getBean做好准备工作。\n\n\nbeanDefinition -> bean\n---\n\n其实也就是从beanDefinition转换成bean的过程，我在网上找了[一幅图](http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/)，可以辅助我们了解spring内部是如何初始化bean的：\n\n![](http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/origin_image012.gif)\n\n这里也有一篇不错的[文章](http://songzi0206.iteye.com/blog/1430239#show-last-Point)，从代码的角度描述了spring内部是如何使用BeanDefinition生成Bean的，dubbo就是委托给spring来管理bean的生命周期的。\n\n那么dubbo自定义schemas所产生的beanDefinition，spring是如何将其转换成dubbo需要的bean呢？毕竟我们从上面的解析中看到，解析生成的beanDefinition中包含太多dubbo特殊的配置方式。这里我有两个猜测：\n\n- dubbo在spring提供的相关扩展点上实现了自己的getBean逻辑，可我却在dubbo的源码中找不到对应实现；\n- **spring解析生成的beanDefinition并没有dubbo特殊性，交给默认的BeanFactory没啥问题**（这都怪我spring太差啊~）\n\n带着疑问我进行了严酷的单步调试，事实证明是第二种路数。到目前为止，dubbo已经按照我们提供的配置文件把所有需要的**bean**初始化完成，这部分基本上都是交给spring来搞定的。\n\n这还不够，我们还不知道这些bean是怎么服务于业务！\n\n\n\nbean -> service\n---\n\n那么到底是哪些bean最终会被dubbo直接拿来使用呢？其实`DubboNamespaceHandler.init`中的那些就是答案。我们先看一下这些类的关系：\n\n![](http://alibaba.github.io/dubbo-doc-static/dubbo-config.jpg-version=1&modificationDate=1330708121000.jpg)\n\n其实这么复杂的关系最终都会被转换成字符串以`URL`的形式交给dubbo的底层最终暴露成服务。我们先来重点看一下`ServiceBean`的实现，了解一下服务提供方的细节。\n\n按照上面uml图来看，这些**xxxConfig**类的关系已经很清楚了（谁继承谁，谁聚合谁，谁依赖谁）。不过图里并没有出现我们的目标：**ServiceBean**，补充下图：\n\n![](http://pic.yupoo.com/kazaff/En3pJXbV/NqlfS.png)\n\n除了继承父类外，我们也要注意`ServiceBean`实现的相关接口：\n\n\tpublic class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware \n\n这里我们着重看`InitializingBean`接口，该接口为spring留给开发者的一个hook，用来执行初始化bean的个性化逻辑的回调，详情可以看这篇[文章](http://www.cnblogs.com/zrtqsk/p/3735273.html#show-last-Point)。\n\n既然我们的`ServiceBean`实现了这个接口，意味着当spring进行容器初始化任务过程中，会执行我们在`ServiceBean.afterPropertiesSet`方法中安排的逻辑，这也是bean导出为服务的关键入口，先把本尊注释过的代码贴出来：\n\n\tpublic class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware {\n\t\n\t\tprivate static final long serialVersionUID = 213195494150089726L;\n\t\n\t    private static transient ApplicationContext SPRING_CONTEXT;\n\t    \n\t\tprivate transient ApplicationContext applicationContext;\n\t\n\t    private transient String beanName;\n\t\n\t    private transient boolean supportedApplicationListener;\n\t    \n\t\tpublic ServiceBean() {\n\t        super();\n\t    }\n\t\n\t    public ServiceBean(Service service) {\n\t        super(service);\n\t    }\n\t\n\t    public static ApplicationContext getSpringContext() {\n\t\t    return SPRING_CONTEXT;\n\t\t}\n\t\n\t\tpublic void setApplicationContext(ApplicationContext applicationContext) {\n\t\t\tthis.applicationContext = applicationContext;\n\t\n\t        //把该应用上下文存储在SpringExtensionFactory（dubbo的SPI扩展点机制）中\n\t        //把原先spring通过ApplicationContext获取bean的方式封装了一下，以dubbo统一的SPI扩展点机制风格接口暴露给业务使用\n\t\t\tSpringExtensionFactory.addApplicationContext(applicationContext);\n\t\t\tif (applicationContext != null) {\n\t\t\t    SPRING_CONTEXT = applicationContext;\n\t\t\t    try {\n\t                //把所有serviceBean都加入到ApplicationContext的事件通知中\n\t\t            Method method = applicationContext.getClass().getMethod(\"addApplicationListener\", new Class<?>[]{ApplicationListener.class}); // 兼容Spring2.0.1\n\t\t            method.invoke(applicationContext, new Object[] {this});\n\t\t            supportedApplicationListener = true;\n\t\t        } catch (Throwable t) {\n\t                if (applicationContext instanceof AbstractApplicationContext) {\n\t    \t            try {\n\t    \t                Method method = AbstractApplicationContext.class.getDeclaredMethod(\"addListener\", new Class<?>[]{ApplicationListener.class}); // 兼容Spring2.0.1\n\t                        if (! method.isAccessible()) {\n\t                            method.setAccessible(true);\n\t                        }\n\t    \t                method.invoke(applicationContext, new Object[] {this});\n\t                        supportedApplicationListener = true;\n\t    \t            } catch (Throwable t2) {\n\t    \t            }\n\t\t            }\n\t\t        }\n\t\t\t}\n\t\t}\n\t\n\t    public void setBeanName(String name) {\n\t        this.beanName = name;\n\t    }\n\t\n\t    //如果配置serviceBean时声明了延迟暴露（例如：<dubbo:service delay=\"-1\" />），则会依赖监听spring提供的相关事件来触发export\n\t    public void onApplicationEvent(ApplicationEvent event) {\n\t        if (ContextRefreshedEvent.class.getName().equals(event.getClass().getName())) { //监听ContextRefreshedEvent事件（容器发生初始化或更新时触发）\n\t        \tif (isDelay() && ! isExported() && ! isUnexported()) {  //如果已导出过或者已手工放弃导出则不会执行export逻辑\n\t                if (logger.isInfoEnabled()) {\n\t                    logger.info(\"The service ready on spring started. service: \" + getInterface());\n\t                }\n\t                export();\n\t            }\n\t        }\n\t    }\n\t    \n\t    private boolean isDelay() {\n\t        Integer delay = getDelay();\n\t        ProviderConfig provider = getProvider();\n\t        if (delay == null && provider != null) {    //若没有明确指定延迟，则尝试继承provider配置\n\t            delay = provider.getDelay();\n\t        }\n\t        return supportedApplicationListener && (delay == null || delay.intValue() == -1);   //注意这里对delay值的条件很奇怪，如果我设置delay为5000毫秒时，难道不算是延迟么？请参考\\com\\alibaba\\dubbo\\config\\ServiceConfig.java的132行\n\t    }\n\t\n\t    @SuppressWarnings({ \"unchecked\", \"deprecation\" })\n\t\tpublic void afterPropertiesSet() throws Exception {\n\t        if (getProvider() == null) {    //如果当前serviceBean并没有指定provider，则下面的逻辑为其指定默认的providerConfig（如果存在的话）\n\t            Map<String, ProviderConfig> providerConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProviderConfig.class, false, false);\n\t            if (providerConfigMap != null && providerConfigMap.size() > 0) {\n\t                Map<String, ProtocolConfig> protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n\t                if ((protocolConfigMap == null || protocolConfigMap.size() == 0)\n\t                        && providerConfigMap.size() > 1) { // 兼容旧版本\n\t                    List<ProviderConfig> providerConfigs = new ArrayList<ProviderConfig>();\n\t                    for (ProviderConfig config : providerConfigMap.values()) {\n\t                        if (config.isDefault() != null && config.isDefault().booleanValue()) {  //把所有指定为默认范围的providerConfig拿到，跳转到下面\n\t                            providerConfigs.add(config);\n\t                        }\n\t                    }\n\t                    if (providerConfigs.size() > 0) {\n\t                        setProviders(providerConfigs);  //接着上面，把所有指定为默认范围的providerConfig中与protocol相关的配置封装成protocolConfig并存入serviceConfig对应属性中\n\t                    }\n\t                } else {\n\t                    ProviderConfig providerConfig = null;\n\t                    for (ProviderConfig config : providerConfigMap.values()) {\n\t                        //如果某个provider配置包含子node（ServiceBean），且没有明确指定default，也会被当成默认配置么？这个疑问请参看：com\\alibaba\\dubbo\\config\\spring\\schema\\DubboBeanDefinitionParser.java中330行注解\n\t                        if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                            if (providerConfig != null) {   //只能有一个provider设置为默认\n\t                                throw new IllegalStateException(\"Duplicate provider configs: \" + providerConfig + \" and \" + config);\n\t                            }\n\t                            providerConfig = config;\n\t                        }\n\t                    }\n\t                    if (providerConfig != null) {\n\t                        setProvider(providerConfig);    //为serviceBean绑定继承的providerConfig\n\t                    }\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Application且其继承的provider也没有指定Application，则下面的逻辑为其指定默认的applicationConfig（如果存在的话）\n\t        if (getApplication() == null\n\t                && (getProvider() == null || getProvider().getApplication() == null)) {\n\t            Map<String, ApplicationConfig> applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false);\n\t            if (applicationConfigMap != null && applicationConfigMap.size() > 0) {\n\t                ApplicationConfig applicationConfig = null;\n\t                for (ApplicationConfig config : applicationConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        if (applicationConfig != null) {    //只能有一个Application设置为默认\n\t                            throw new IllegalStateException(\"Duplicate application configs: \" + applicationConfig + \" and \" + config);\n\t                        }\n\t                        applicationConfig = config;\n\t                    }\n\t                }\n\t                if (applicationConfig != null) {\n\t                    setApplication(applicationConfig);  //为serviceBean绑定applicationConfig\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Module且其继承的provider也没有指定Module，则下面的逻辑为其指定默认的moduleConfig（如果存在的话）\n\t        if (getModule() == null\n\t                && (getProvider() == null || getProvider().getModule() == null)) {\n\t            Map<String, ModuleConfig> moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false);\n\t            if (moduleConfigMap != null && moduleConfigMap.size() > 0) {\n\t                ModuleConfig moduleConfig = null;\n\t                for (ModuleConfig config : moduleConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        if (moduleConfig != null) { //只能有一个Module设置为默认\n\t                            throw new IllegalStateException(\"Duplicate module configs: \" + moduleConfig + \" and \" + config);\n\t                        }\n\t                        moduleConfig = config;\n\t                    }\n\t                }\n\t                if (moduleConfig != null) {\n\t                    setModule(moduleConfig);    //为serviceBean绑定moduleConfig\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Registry且其继承的provider,application也没有指定Registry，则下面的逻辑为其指定默认的registryConfig（如果存在的话）\n\t        if ((getRegistries() == null || getRegistries().size() == 0)\n\t                && (getProvider() == null || getProvider().getRegistries() == null || getProvider().getRegistries().size() == 0)\n\t                && (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().size() == 0)) {\n\t            Map<String, RegistryConfig> registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false);\n\t            if (registryConfigMap != null && registryConfigMap.size() > 0) {\n\t                List<RegistryConfig> registryConfigs = new ArrayList<RegistryConfig>();\n\t                for (RegistryConfig config : registryConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {  //允许为serviceBean指定多个Registry\n\t                        registryConfigs.add(config);\n\t                    }\n\t                }\n\t                if (registryConfigs != null && registryConfigs.size() > 0) {\n\t                    super.setRegistries(registryConfigs);\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Monitor且其继承的provider,application也没有指定Monitor，则下面的逻辑为其指定默认的monitorConfig（如果存在的话）\n\t        if (getMonitor() == null\n\t                && (getProvider() == null || getProvider().getMonitor() == null)\n\t                && (getApplication() == null || getApplication().getMonitor() == null)) {\n\t            Map<String, MonitorConfig> monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false);\n\t            if (monitorConfigMap != null && monitorConfigMap.size() > 0) {\n\t                MonitorConfig monitorConfig = null;\n\t                for (MonitorConfig config : monitorConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        if (monitorConfig != null) {    //只能有一个Monitor设置为默认\n\t                            throw new IllegalStateException(\"Duplicate monitor configs: \" + monitorConfig + \" and \" + config);\n\t                        }\n\t                        monitorConfig = config;\n\t                    }\n\t                }\n\t                if (monitorConfig != null) {\n\t                    setMonitor(monitorConfig);  //为serviceBean绑定monitorConfig\n\t                }\n\t            }\n\t        }\n\t        //如果当前serviceBean并没有指定Protocol且其继承的provider也没有指定Protocol，则下面的逻辑为其指定默认的protocolConfig（如果存在的话）\n\t        if ((getProtocols() == null || getProtocols().size() == 0)\n\t                && (getProvider() == null || getProvider().getProtocols() == null || getProvider().getProtocols().size() == 0)) {\n\t            Map<String, ProtocolConfig> protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n\t            if (protocolConfigMap != null && protocolConfigMap.size() > 0) {\n\t                List<ProtocolConfig> protocolConfigs = new ArrayList<ProtocolConfig>();\n\t                for (ProtocolConfig config : protocolConfigMap.values()) {\n\t                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n\t                        protocolConfigs.add(config);    //允许为serviceBean指定多个Protocol\n\t                    }\n\t                }\n\t                if (protocolConfigs != null && protocolConfigs.size() > 0) {\n\t                    super.setProtocols(protocolConfigs);\n\t                }\n\t            }\n\t        }\n\t        //设置服务路径，默认使用的是该bean在spring容器中注册的beanName，这也是该类继承BeanNameAware的原因\n\t        if (getPath() == null || getPath().length() == 0) {\n\t            if (beanName != null && beanName.length() > 0 \n\t                    && getInterface() != null && getInterface().length() > 0\n\t                    && beanName.startsWith(getInterface())) {\n\t                setPath(beanName);\n\t            }\n\t        }\n\t        //若不是延迟加载，就上演好戏\n\t        if (! isDelay()) {\n\t            export();\n\t        }\n\t    }\n\t\n\t    public void destroy() throws Exception {\n\t        unexport();\n\t    }\n\t}\n\n这里就明白为何ServiceBean和其父类ServiceConfig不在同一个包内，因为前者是为了适配spring而提供的适配器。ServiceBean依赖spring提供的相关hook接口完成了bean的初始化，最终`export`逻辑交给`ServiceConfig`来完成，这才是dubbo的核心服务配置类，这也解释了为何上面UML图中没有画ServiceBean的原因。\n\n我们继续跟着线索来看一下`ServiceConfig.export`：\n\n\tpublic synchronized void export() {\n        //从provider中继承一些必要但没有明确设置的参数\n        if (provider != null) {\n            if (export == null) {\n                export = provider.getExport();\n            }\n            if (delay == null) {\n                delay = provider.getDelay();\n            }\n        }\n        if (export != null && ! export.booleanValue()) {    //如果不需要暴露该服务，则就此结束\n            return;\n        }\n        if (delay != null && delay > 0) {   //如果明确指定了想要延迟的时间差，则依赖线程休眠来完成延迟暴露，delay的值只有为-1或null才依赖spring的事件机制完成延迟暴露\n            Thread thread = new Thread(new Runnable() {\n                public void run() {\n                    try {\n                        Thread.sleep(delay);\n                    } catch (Throwable e) {\n                    }\n                    doExport();\n                }\n            });\n            thread.setDaemon(true);\n            thread.setName(\"DelayExportServiceThread\");\n            thread.start();\n        } else {\n            doExport();\n        }\n    }\n\n一目了然，这个方法主要就是解决了到底暴露不暴露的问题，并且到底是不是延迟暴露的问题。接下来看看`doExport`方法：\n\n\tprotected synchronized void doExport() {\n        if (unexported) {\n            throw new IllegalStateException(\"Already unexported!\");\n        }\n        if (exported) {\n            return;\n        }\n\n        exported = true;    //修改暴露状态\n\n        if (interfaceName == null || interfaceName.length() == 0) {\n            throw new IllegalStateException(\"<dubbo:service interface=\\\"\\\" /> interface not allow null!\");\n        }\n\n        checkDefault(); //根据文档中提到的参数优先级，决定最终使用的配置值，在spring的xml解析阶段只是简单解析xml的配置值，在真正使用前，还需要看一下：-D和properties文件\n\n        //下面根据文档中的优先级创建对应的继承链\n        if (provider != null) { //todo 这里必然成立吧？\n            if (application == null) {\n                application = provider.getApplication();\n            }\n            if (module == null) {\n                module = provider.getModule();\n            }\n            if (registries == null) {\n                registries = provider.getRegistries();\n            }\n            if (monitor == null) {\n                monitor = provider.getMonitor();\n            }\n            if (protocols == null) {\n                protocols = provider.getProtocols();\n            }\n        }\n        if (module != null) {\n            if (registries == null) {\n                registries = module.getRegistries();\n            }\n            if (monitor == null) {\n                monitor = module.getMonitor();\n            }\n        }\n        if (application != null) {\n            if (registries == null) {\n                registries = application.getRegistries();\n            }\n            if (monitor == null) {\n                monitor = application.getMonitor();\n            }\n        }\n\n        if (ref instanceof GenericService) {    //泛接口实现方式主要用于服务器端没有API接口及模型类元的情况，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如：实现一个通用的远程服务Mock框架，可通过实现GenericService接口处理所有服务请求。\n            interfaceClass = GenericService.class;\n            if (StringUtils.isEmpty(generic)) {\n                generic = Boolean.TRUE.toString();\n            }\n        } else {\n            try {\n                interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                        .getContextClassLoader());\n            } catch (ClassNotFoundException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            checkInterfaceAndMethods(interfaceClass, methods);  //检查接口和方法的匹配情况\n            checkRef(); //检查接口和实现的匹配情况\n            generic = Boolean.FALSE.toString();\n        }\n\n        if(local !=null){   //todo 文档中并没有与local相关的参数解释\n            if(local==\"true\"){\n                local=interfaceName+\"Local\";\n            }\n            Class<?> localClass;\n            try {\n                localClass = ClassHelper.forNameWithThreadContextClassLoader(local);\n            } catch (ClassNotFoundException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            if(!interfaceClass.isAssignableFrom(localClass)){\n                throw new IllegalStateException(\"The local implemention class \" + localClass.getName() + \" not implement interface \" + interfaceName);\n            }\n        }\n\n        //本地存根，http://alibaba.github.io/dubbo-doc-static/Stub+Proxy-zh.htm\n        if(stub !=null){\n            if(stub==\"true\"){\n                stub=interfaceName+\"Stub\";  //todo 这里文档中的解释貌似有错误：http://alibaba.github.io/dubbo-doc-static/Service+Config-zh.htm\n            }\n            Class<?> stubClass;\n            try {\n                stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub);\n            } catch (ClassNotFoundException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            if(!interfaceClass.isAssignableFrom(stubClass)){\n                throw new IllegalStateException(\"The stub implemention class \" + stubClass.getName() + \" not implement interface \" + interfaceName);\n            }\n        }\n\n        //作用雷同于上面的checkDefault()，根据文档中提到的参数优先级来选择使用的配置参数\n        checkApplication();\n        checkRegistry();\n        checkProtocol();\n        appendProperties(this);\n\n        checkStubAndMock(interfaceClass);   //检查local，stub和mock的有效性\n\n        if (path == null || path.length() == 0) {   //此时path如果还为空，这使用interfaceName\n            path = interfaceName;\n        }\n        \n        doExportUrls();\n    }\n\n木牛错，`doExport`方法依然是在做预备工作，感觉越来越靠近真像了，目前为止，我们已经按照规定的优先级最终确定了要暴露成为服务的bean的\"大部分\"相关配置参数，并校验了相关参数的有效性（例如：ref，method，stub，mock，path等）。再来看一下`doExportUrls`方法：\n\n\tprivate void doExportUrls() {\n        List<URL> registryURLs = loadRegistries(true);  //获取所有的注册中心地址\n        for (ProtocolConfig protocolConfig : protocols) {\n            doExportUrlsFor1Protocol(protocolConfig, registryURLs);\n        }\n    }\n\n好，是该真刀真枪干一架的时候了，`doExportUrlsFor1Protocol`应该就是今次的Boss，解决掉它我们就回家。\n\n\tprivate void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {\n        String name = protocolConfig.getName();\n        if (name == null || name.length() == 0) {\n            name = \"dubbo\"; //N多次的检查，N多次的赋值，这算是严谨呢？还是重复？\n        }\n\n        String host = protocolConfig.getHost();\n        if (provider != null && (host == null || host.length() == 0)) {\n            host = provider.getHost();\n        }\n        boolean anyhost = false;\n        if (NetUtils.isInvalidLocalHost(host)) {    //检查host是否为本地ip，或者无效的\n            anyhost = true;\n            try {\n                host = InetAddress.getLocalHost().getHostAddress();\n            } catch (UnknownHostException e) {\n                logger.warn(e.getMessage(), e);\n            }\n            if (NetUtils.isInvalidLocalHost(host)) {    //如果拿到的还是本地地址，就只能出杀手锏了\n                if (registryURLs != null && registryURLs.size() > 0) {\n                    for (URL registryURL : registryURLs) {\n                        try {\n                            Socket socket = new Socket();\n                            try {\n                                //尝试连接注册中心，选用连接时使用的ip地址\n                                SocketAddress addr = new InetSocketAddress(registryURL.getHost(), registryURL.getPort());\n                                socket.connect(addr, 1000);\n                                host = socket.getLocalAddress().getHostAddress();\n                                break;\n                            } finally {\n                                try {\n                                    socket.close();\n                                } catch (Throwable e) {}\n                            }\n                        } catch (Exception e) {\n                            logger.warn(e.getMessage(), e);\n                        }\n                    }\n                }\n                if (NetUtils.isInvalidLocalHost(host)) {\n                    host = NetUtils.getLocalHost(); //实在不行，就只能使用本机上第一个找到的合法ip了\n                }\n            }\n        }\n\n        Integer port = protocolConfig.getPort();\n        if (provider != null && (port == null || port == 0)) {\n            port = provider.getPort();\n        }\n        final int defaultPort = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(name).getDefaultPort();\n        if (port == null || port == 0) {\n            port = defaultPort;\n        }\n        if (port == null || port <= 0) {\n            port = getRandomPort(name);\n            if (port == null || port < 0) {\n                port = NetUtils.getAvailablePort(defaultPort);  //到这里如果还没有拿到port，就直接随机拿个能用的端口\n                putRandomPort(name, port);  //这一步很讲究，意味着相同协议使用相同的端口，要理解这个就需要先消化dubbo底层通信方式。\n            }\n            logger.warn(\"Use random available port(\" + port + \") for protocol \" + name);\n        }\n\n        Map<String, String> map = new HashMap<String, String>();\n        if (anyhost) {\n            map.put(Constants.ANYHOST_KEY, \"true\");\n        }\n        map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE);\n        map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion());\n        map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));\n        if (ConfigUtils.getPid() > 0) {\n            map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));\n        }\n\n        //获取相关的配置参数用于后面的url生成，注意优先级顺序哟\n        appendParameters(map, application);\n        appendParameters(map, module);\n        appendParameters(map, provider, Constants.DEFAULT_KEY);\n        appendParameters(map, protocolConfig);\n        appendParameters(map, this);\n\n        if (methods != null && methods.size() > 0) {\n            for (MethodConfig method : methods) {\n                appendParameters(map, method, method.getName());\n\n                //处理重试设置\n                String retryKey = method.getName() + \".retry\";\n                if (map.containsKey(retryKey)) {\n                    String retryValue = map.remove(retryKey);\n                    if (\"false\".equals(retryValue)) {\n                        map.put(method.getName() + \".retries\", \"0\");\n                    }\n                }\n\n                List<ArgumentConfig> arguments = method.getArguments();\n                if (arguments != null && arguments.size() > 0) {\n                    for (ArgumentConfig argument : arguments) { //ArgumentConfig作用主要就是用来完成事件回调机制。\n                        //类型自动转换.\n                        if(argument.getType() != null && argument.getType().length() >0){\n                            Method[] methods = interfaceClass.getMethods();\n                            //遍历所有方法\n                            if(methods != null && methods.length > 0){\n                                for (int i = 0; i < methods.length; i++) {\n                                    String methodName = methods[i].getName();\n                                    //匹配方法名称，获取方法签名.\n                                    if(methodName.equals(method.getName())){    //注意方法重载情况\n                                        Class<?>[] argtypes = methods[i].getParameterTypes();\n                                        //一个方法中单个callback\n                                        if (argument.getIndex() != -1 ){    //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                            if (argtypes[argument.getIndex()].getName().equals(argument.getType())){\n                                                appendParameters(map, argument, method.getName() + \".\" + argument.getIndex());\n                                            }else {\n                                                throw new IllegalArgumentException(\"argument config error : the index attribute and type attirbute not match :index :\"+argument.getIndex() + \", type:\" + argument.getType());\n                                            }\n                                        } else {\n                                            //一个方法中多个callback\n                                            for (int j = 0 ;j<argtypes.length ;j++) {   //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                                Class<?> argclazz = argtypes[j];\n                                                if (argclazz.getName().equals(argument.getType())){\n                                                    appendParameters(map, argument, method.getName() + \".\" + j);\n                                                    if (argument.getIndex() != -1 && argument.getIndex() != j){\n                                                        throw new IllegalArgumentException(\"argument config error : the index attribute and type attirbute not match :index :\"+argument.getIndex() + \", type:\" + argument.getType());\n                                                    }\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }else if(argument.getIndex() != -1){\n                            appendParameters(map, argument, method.getName() + \".\" + argument.getIndex());\n                        }else {\n                            throw new IllegalArgumentException(\"argument config must set index or type attribute.eg: <dubbo:argument index='0' .../> or <dubbo:argument type=xxx .../>\");\n                        }\n\n                    }\n                }\n            } // end of methods for\n        }\n\n        if (ProtocolUtils.isGeneric(generic)) { //处理泛化\n            map.put(\"generic\", generic);\n            map.put(\"methods\", Constants.ANY_VALUE);\n        } else {\n            String revision = Version.getVersion(interfaceClass, version);\n            if (revision != null && revision.length() > 0) {\n                map.put(\"revision\", revision);  //todo 为什么是revision?\n            }\n\n            String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); //todo 动态封装interfaceClass，目前不知道干啥用，猜测dubbo直接操作的都是这个封装后的wrapper\n            if(methods.length == 0) {\n                logger.warn(\"NO method found in service interface \" + interfaceClass.getName());\n                map.put(\"methods\", Constants.ANY_VALUE);\n            }\n            else {\n                map.put(\"methods\", StringUtils.join(new HashSet<String>(Arrays.asList(methods)), \",\"));\n            }\n        }\n\n        //令牌验证，为空表示不开启，如果为true，表示随机生成动态令牌，否则使用静态令牌，令牌的作用是防止消费者绕过注册中心直接访问，保证注册中心的授权功能有效，如果使用点对点调用，需关闭令牌功能\n        if (! ConfigUtils.isEmpty(token)) {\n            if (ConfigUtils.isDefault(token)) {\n                map.put(\"token\", UUID.randomUUID().toString());\n            } else {\n                map.put(\"token\", token);\n            }\n        }\n\n        //injvm表示不会跨进程，所以不需要注册中心\n        if (\"injvm\".equals(protocolConfig.getName())) {\n            protocolConfig.setRegister(false);\n            map.put(\"notify\", \"false\");\n        }\n\n        // 导出服务\n        String contextPath = protocolConfig.getContextpath();\n        if ((contextPath == null || contextPath.length() == 0) && provider != null) {\n            contextPath = provider.getContextpath();\n        }\n        URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? \"\" : contextPath + \"/\") + path, map);   //拿到服务的url\n\n        if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n                .hasExtension(url.getProtocol())) {\n            url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n                    .getExtension(url.getProtocol()).getConfigurator(url).configure(url);\n        }\n\n        String scope = url.getParameter(Constants.SCOPE_KEY);\n        //配置为none不暴露\n        if (! Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) {\n\n            //配置不是remote的情况下做本地暴露 (配置为remote，则表示只暴露远程服务)\n            if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) {\n                exportLocal(url);\n            }\n            //如果配置不是local则暴露为远程服务.(配置为local，则表示只暴露远程服务)\n            if (! Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope) ){\n                if (logger.isInfoEnabled()) {\n                    logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to url \" + url);\n                }\n                if (registryURLs != null && registryURLs.size() > 0\n                        && url.getParameter(\"register\", true)) {\n                    for (URL registryURL : registryURLs) {\n                        url = url.addParameterIfAbsent(\"dynamic\", registryURL.getParameter(\"dynamic\"));\n                        URL monitorUrl = loadMonitor(registryURL);\n                        if (monitorUrl != null) {\n                            url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString());\n                        }\n                        if (logger.isInfoEnabled()) {\n                            logger.info(\"Register dubbo service \" + interfaceClass.getName() + \" url \" + url + \" to registry \" + registryURL);\n                        }\n                        //todo 暴露为何要封装一层代理呢？\n                        Invoker<?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()));\n\n                        Exporter<?> exporter = protocol.export(invoker);\n                        exporters.add(exporter);\n                    }\n                } else {\n                    //todo 暴露为何要封装一层代理呢？\n                    Invoker<?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\n                    Exporter<?> exporter = protocol.export(invoker);\n                    exporters.add(exporter);\n                }\n            }\n        }\n        this.urls.add(url);\n    }\n\n一路走来可以发现，dubbo会为每个有效协议暴露一份服务，并且会注册到所有有效的注册中心里。而bean转变为service中最重要的就是映射出来的`URL`，也就是说我们在配置文件中进行的相关配置都会映射成对应url中的相关部分，举个例子：\n\n\t<dubbo:application name=\"demo-provider\" owner=\"programmer\" organization=\"dubbox\"/>\n    <dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/>\n\t<dubbo:protocol name=\"dubbo\" serialization=\"kryo\" optimizer=\"com.alibaba.dubbo.demo.SerializationOptimizerImpl\"/>\n\n\t<bean id=\"bidService\" class=\"com.alibaba.dubbo.demo.bid.BidServiceImpl\" />\n\t<dubbo:service interface=\"com.alibaba.dubbo.demo.bid.BidService\" ref=\"bidService\"  protocol=\"dubbo\" />\n\n我们通过debug看一下最终它映射出来的url是什么：\n\n\t//exportLocal\n\tinjvm://127.0.0.1/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&application=demo-provider&dubbo=2.0.0&generic=false&interface=com.alibaba.dubbo.demo.bid.BidService&methods=throwNPE,bid&optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&organization=dubbox&owner=programmer&pid=3872&serialization=kryo&side=provider&timestamp=1422241023451\n\n\t//exportRemote\n\tregistry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&dubbo=2.0.0&export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&organization=dubbox&owner=programmer&pid=3872&registry=zookeeper&timestamp=1422240274186\n\n那么这个`url`的作用是什么呢？官方给出的[解释](http://alibaba.github.io/dubbo-doc-static/Init+Detail-zh.htm)很明确，这个url作为解耦的通信数据（跨层调用的参数），有了它dubbo就可以更容易做到业务逻辑实现的替换。除此之外可以看到url中还包含了大量的辅助参数（例如：timeout，version，organization等）供服务治理使用，这些都是根据真实需求一步一步补充完善的，可见，**好的架构是演化而来的**。\n\n\n可以看到贴出来的代码中包含很多todo项，其中一些问题我们从代码层面是很难找到答案的，我们需要上升到业务，运维甚至架构师高度才能消化得了，小弟将在后续的分析中慢慢的尝试解开谜团。","slug":"dubbo如何一步一步拿到bean","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yqv00argtfypf8mgesa","comments":1,"layout":"post","photos":[],"link":"","content":"<p>dubbo依赖了spring提供的现成机制完成了bean的创建，我们来看一下这其中的汰渍。</p>\n<a id=\"more\"></a>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><p>关于dubbo的配置相关细节，官方已经给了一个无比详细的<a href=\"http://alibaba.github.io/dubbo-doc-static/Configuration+Reference-zh.htm\" target=\"_blank\" rel=\"external\">文档</a>，<a href=\"http://alibaba.github.io/dubbo-doc-static/Configs-zh.htm\" target=\"_blank\" rel=\"external\">文档2</a>。不过由于dubbo可供配置的参数非常多，这也是让我们新手一开始感到最为头疼的，这也是SOA复杂的表象之一。</p>\n<h2 id=\"xml-gt-beanDefinition\"><a href=\"#xml-gt-beanDefinition\" class=\"headerlink\" title=\"xml -&gt; beanDefinition\"></a>xml -&gt; beanDefinition</h2><p>对于我这种小学生，需要先补习一个基础知识点：<a href=\"http://www.cnblogs.com/jifeng/archive/2011/09/14/2176599.html\" target=\"_blank\" rel=\"external\">基于Spring可扩展Schema提供自定义配置支持</a>。dubbo是依赖spring提供的这种机制来处理配置文件解析的，理解起来没什么难度。</p>\n<p>看一下dubbo-congfig的目录结构：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EllS0JnY/lFpRv.png\" alt=\"\"></p>\n<p>我们来看一下dubbo是如何按照spring提供的机制来处理配置文件的：</p>\n<pre><code>#spring.handlers\nhttp\\://code.alibabatech.com/schema/dubbo=com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler\n\n#spring.schemas\nhttp\\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd\n</code></pre><p>这样我们就锁定了要分析的类：</p>\n<pre><code>package com.alibaba.dubbo.config.spring.schema;\n\npublic class DubboNamespaceHandler extends NamespaceHandlerSupport {\n\n    static {\n        Version.checkDuplicate(DubboNamespaceHandler.class); //确保系统中只存在一份解析处理器类定义\n    }\n\n    public void init() {\n        registerBeanDefinitionParser(&quot;application&quot;, new DubboBeanDefinitionParser(ApplicationConfig.class, true));\n        registerBeanDefinitionParser(&quot;module&quot;, new DubboBeanDefinitionParser(ModuleConfig.class, true));\n        registerBeanDefinitionParser(&quot;registry&quot;, new DubboBeanDefinitionParser(RegistryConfig.class, true));\n        registerBeanDefinitionParser(&quot;monitor&quot;, new DubboBeanDefinitionParser(MonitorConfig.class, true));\n        registerBeanDefinitionParser(&quot;provider&quot;, new DubboBeanDefinitionParser(ProviderConfig.class, true));\n        registerBeanDefinitionParser(&quot;consumer&quot;, new DubboBeanDefinitionParser(ConsumerConfig.class, true));\n        registerBeanDefinitionParser(&quot;protocol&quot;, new DubboBeanDefinitionParser(ProtocolConfig.class, true));\n        registerBeanDefinitionParser(&quot;service&quot;, new DubboBeanDefinitionParser(ServiceBean.class, true));\n        registerBeanDefinitionParser(&quot;reference&quot;, new DubboBeanDefinitionParser(ReferenceBean.class, false));\n        registerBeanDefinitionParser(&quot;annotation&quot;, new DubboBeanDefinitionParser(AnnotationBean.class, true));\n    }\n}\n</code></pre><p>按照spring提供的机制，dubbo把每个自定义的可使用配置元素和对应的解析器绑定到一起。而真正负责把配置文件中声明的内容解析成对应的BeanDefinition（可以想象为Bean的模子）是靠<code>DubboBeanDefinitionParser.parse</code>类完成，我们就来严肃的分析一下这个方法。</p>\n<pre><code>/**\n * AbstractBeanDefinitionParser\n * \n * @author william.liangf\n * @export\n */\npublic class DubboBeanDefinitionParser implements BeanDefinitionParser {\n\n    private static final Logger logger = LoggerFactory.getLogger(DubboBeanDefinitionParser.class);\n\n    private final Class&lt;?&gt; beanClass;\n\n    private final boolean required;\n\n    public DubboBeanDefinitionParser(Class&lt;?&gt; beanClass, boolean required) {\n        this.beanClass = beanClass;\n        this.required = required;\n    }\n\n    public BeanDefinition parse(Element element, ParserContext parserContext) {\n        return parse(element, parserContext, beanClass, required);\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) {\n        //初始化BeanDefiniion\n        RootBeanDefinition beanDefinition = new RootBeanDefinition();\n        beanDefinition.setBeanClass(beanClass);\n        beanDefinition.setLazyInit(false);\n\n        String id = element.getAttribute(&quot;id&quot;);\n        if ((id == null || id.length() == 0) &amp;&amp; required) {\n            String generatedBeanName = element.getAttribute(&quot;name&quot;);\n            if (generatedBeanName == null || generatedBeanName.length() == 0) {\n                if (ProtocolConfig.class.equals(beanClass)) {   //如果当前解析的类型是ProtocolConfig，则设置默认id为dubbo\n                    generatedBeanName = &quot;dubbo&quot;;\n                } else {\n                    generatedBeanName = element.getAttribute(&quot;interface&quot;);  //其他情况，默认id为接口类型\n                }\n            }\n            if (generatedBeanName == null || generatedBeanName.length() == 0) {\n                generatedBeanName = beanClass.getName();    //如果该节点没有interface属性（包含：registry,monitor,provider,consumer），则使用该节点的类型为id值\n            }\n            id = generatedBeanName; \n            int counter = 2;\n            while(parserContext.getRegistry().containsBeanDefinition(id)) { //生成不重复的id\n                id = generatedBeanName + (counter ++);\n            }\n        }\n        if (id != null &amp;&amp; id.length() &gt; 0) {    //目前这个判断不知道啥意义，目测必定会返回true\n            if (parserContext.getRegistry().containsBeanDefinition(id))  {  //这个判断应该用于防止并发\n                throw new IllegalStateException(&quot;Duplicate spring bean id &quot; + id);\n            }\n            //注册beanDefinition，BeanDefinitionRegistry相当于一张注册表\n            parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);\n            beanDefinition.getPropertyValues().addPropertyValue(&quot;id&quot;, id);\n        }\n        //下面这几个if-else分别针对不同类型做特殊处理\n        if (ProtocolConfig.class.equals(beanClass)) {\n            //这段代码的逻辑是用来适配：当&lt;dubbo:protocol&gt;声明出现在配置文件中使用该协议的bean声明的后面时，解决它们之间的依赖关系的。\n            for (String name : parserContext.getRegistry().getBeanDefinitionNames()) {\n                BeanDefinition definition = parserContext.getRegistry().getBeanDefinition(name);\n                PropertyValue property = definition.getPropertyValues().getPropertyValue(&quot;protocol&quot;);\n                if (property != null) {\n                    Object value = property.getValue();\n                    //如果被检查的bean确实使用当前协议，则建立它们之间的依赖关系\n                    if (value instanceof ProtocolConfig &amp;&amp; id.equals(((ProtocolConfig) value).getName())) {\n                        definition.getPropertyValues().addPropertyValue(&quot;protocol&quot;, new RuntimeBeanReference(id));\n                    }\n                }\n            }\n        } else if (ServiceBean.class.equals(beanClass)) {\n            String className = element.getAttribute(&quot;class&quot;);   //虽然文档上没有标注该配置支持class参数，但是在dubbo.xsd上却能看到这个属性的定义，类似这样的情况还有很多。\n            if(className != null &amp;&amp; className.length() &gt; 0) {   //下面的处理方式应该算是语法糖吧，它支持直接把定义bean和创建serviceConfig压缩成一行\n                RootBeanDefinition classDefinition = new RootBeanDefinition();\n                classDefinition.setBeanClass(ReflectUtils.forName(className));\n                classDefinition.setLazyInit(false);\n                parseProperties(element.getChildNodes(), classDefinition);  //完成bean的初始化工作（注入等）\n                beanDefinition.getPropertyValues().addPropertyValue(&quot;ref&quot;, new BeanDefinitionHolder(classDefinition, id + &quot;Impl&quot;)); //关联bean和serviceConfig\n            }\n        } else if (ProviderConfig.class.equals(beanClass)) {    //按照providerConfig的定义解析并关联其影响的相关serviceConfig\n            parseNested(element, parserContext, ServiceBean.class, true, &quot;service&quot;, &quot;provider&quot;, id, beanDefinition);\n        } else if (ConsumerConfig.class.equals(beanClass)) {    //按照consumerConfig的定义解析并关联其影响的相关referenceConfig\n            parseNested(element, parserContext, ReferenceBean.class, false, &quot;reference&quot;, &quot;consumer&quot;, id, beanDefinition);\n        }\n        Set&lt;String&gt; props = new HashSet&lt;String&gt;();\n        ManagedMap parameters = null;\n        for (Method setter : beanClass.getMethods()) {  //利用反射拿到指定类型的所有用于注入的方法\n            String name = setter.getName();\n            if (name.length() &gt; 3 &amp;&amp; name.startsWith(&quot;set&quot;)\n                    &amp;&amp; Modifier.isPublic(setter.getModifiers())\n                    &amp;&amp; setter.getParameterTypes().length == 1) {    //注入方法的特征是：以set字母开头，是公共方法，且参数个数为1\n                Class&lt;?&gt; type = setter.getParameterTypes()[0];\n                String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), &quot;-&quot;);    //把方法名字的驼峰格式改成-分割格式\n                props.add(property);\n                Method getter = null;\n                try {\n                    getter = beanClass.getMethod(&quot;get&quot; + name.substring(3), new Class&lt;?&gt;[0]);\n                } catch (NoSuchMethodException e) {\n                    try {\n                        getter = beanClass.getMethod(&quot;is&quot; + name.substring(3), new Class&lt;?&gt;[0]);\n                    } catch (NoSuchMethodException e2) {\n                    }\n                }\n                if (getter == null \n                        || ! Modifier.isPublic(getter.getModifiers())\n                        || ! type.equals(getter.getReturnType())) { //如果没有满足条件的对应getter方法存在，则直接跳过该setter方法\n                    continue;\n                }\n\n                if (&quot;parameters&quot;.equals(property)) {    //从配置文件中解析出parameter配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用，parameter的值当string类型解析\n                    parameters = parseParameters(element.getChildNodes(), beanDefinition);\n                } else if (&quot;methods&quot;.equals(property)) {    //注入对应的method配置\n                    parseMethods(id, element.getChildNodes(), beanDefinition, parserContext);\n                } else if (&quot;arguments&quot;.equals(property)) {  //为method注入对应的argument配置\n                    parseArguments(id, element.getChildNodes(), beanDefinition, parserContext);\n                } else {\n                    String value = element.getAttribute(property);  //检查该setter方法所适配要注入的属性是否在配置中明确定义\n                    if (value != null) {    //若存在定义，则完成其注入解析\n                        value = value.trim();\n                        if (value.length() &gt; 0) {\n                            if (&quot;registry&quot;.equals(property) &amp;&amp; RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(value)) {   //处理无注册中心的情况\n                                RegistryConfig registryConfig = new RegistryConfig();\n                                registryConfig.setAddress(RegistryConfig.NO_AVAILABLE);\n                                beanDefinition.getPropertyValues().addPropertyValue(property, registryConfig);\n                            } else if (&quot;registry&quot;.equals(property) &amp;&amp; value.indexOf(&apos;,&apos;) != -1) {   //处理多注册中心的情况\n                                parseMultiRef(&quot;registries&quot;, value, beanDefinition, parserContext);\n                            } else if (&quot;provider&quot;.equals(property) &amp;&amp; value.indexOf(&apos;,&apos;) != -1) {   //处理继承多个provider的情况，缺使用第一个provider配置\n                                parseMultiRef(&quot;providers&quot;, value, beanDefinition, parserContext);\n                            } else if (&quot;protocol&quot;.equals(property) &amp;&amp; value.indexOf(&apos;,&apos;) != -1) {   //处理多协议暴露\n                                parseMultiRef(&quot;protocols&quot;, value, beanDefinition, parserContext);\n                            } else {\n                                Object reference;\n                                if (isPrimitive(type)) {    //如果setter的参数类型为jdk原始类型，直接当string注入到对应属性中去\n                                    if (&quot;async&quot;.equals(property) &amp;&amp; &quot;false&quot;.equals(value)\n                                            || &quot;timeout&quot;.equals(property) &amp;&amp; &quot;0&quot;.equals(value)\n                                            || &quot;delay&quot;.equals(property) &amp;&amp; &quot;0&quot;.equals(value)\n                                            || &quot;version&quot;.equals(property) &amp;&amp; &quot;0.0.0&quot;.equals(value)\n                                            || &quot;stat&quot;.equals(property) &amp;&amp; &quot;-1&quot;.equals(value)\n                                            || &quot;reliable&quot;.equals(property) &amp;&amp; &quot;false&quot;.equals(value)) {\n                                        // 兼容旧版本xsd中的default值\n                                        value = null;\n                                    }\n                                    reference = value;\n                                } else if (&quot;protocol&quot;.equals(property) \n                                        &amp;&amp; ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(value)   //是否存在指定的扩展点定义\n                                        &amp;&amp; (! parserContext.getRegistry().containsBeanDefinition(value) //检查当前解析出的要使用协议对应的protocolConfig是否已经被初始化\n                                                || ! ProtocolConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n                                    if (&quot;dubbo:provider&quot;.equals(element.getTagName())) {\n                                        logger.warn(&quot;Recommended replace &lt;dubbo:provider protocol=\\&quot;&quot; + value + &quot;\\&quot; ... /&gt; to &lt;dubbo:protocol name=\\&quot;&quot; + value + &quot;\\&quot; ... /&gt;&quot;);\n                                    }\n                                    // 兼容旧版本配置\n                                    ProtocolConfig protocol = new ProtocolConfig();\n                                    protocol.setName(value);\n                                    reference = protocol;\n                                } else if (&quot;monitor&quot;.equals(property) \n                                        &amp;&amp; (! parserContext.getRegistry().containsBeanDefinition(value)\n                                                || ! MonitorConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n                                    // 兼容旧版本配置\n                                    reference = convertMonitor(value);\n                                } else if (&quot;onreturn&quot;.equals(property)) {   //对应methodConfig中的返回拦截\n                                    int index = value.lastIndexOf(&quot;.&quot;);\n                                    String returnRef = value.substring(0, index);\n                                    String returnMethod = value.substring(index + 1);\n                                    reference = new RuntimeBeanReference(returnRef);\n                                    beanDefinition.getPropertyValues().addPropertyValue(&quot;onreturnMethod&quot;, returnMethod);\n                                } else if (&quot;onthrow&quot;.equals(property)) {    //对应methodConfig中的异常拦截\n                                    int index = value.lastIndexOf(&quot;.&quot;);\n                                    String throwRef = value.substring(0, index);\n                                    String throwMethod = value.substring(index + 1);\n                                    reference = new RuntimeBeanReference(throwRef);\n                                    beanDefinition.getPropertyValues().addPropertyValue(&quot;onthrowMethod&quot;, throwMethod);\n                                } else {\n                                    if (&quot;ref&quot;.equals(property) &amp;&amp; parserContext.getRegistry().containsBeanDefinition(value)) {\n                                        BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(value);\n                                        if (! refBean.isSingleton()) {\n                                            throw new IllegalStateException(&quot;The exported service ref &quot; + value + &quot; must be singleton! Please set the &quot; + value + &quot; bean scope to singleton, eg: &lt;bean id=\\&quot;&quot; + value+ &quot;\\&quot; scope=\\&quot;singleton\\&quot; ...&gt;&quot;);\n                                        }\n                                    }\n                                    reference = new RuntimeBeanReference(value);\n                                }\n                                beanDefinition.getPropertyValues().addPropertyValue(property, reference);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        NamedNodeMap attributes = element.getAttributes();\n        int len = attributes.getLength();\n        for (int i = 0; i &lt; len; i++) {\n            Node node = attributes.item(i);\n            String name = node.getLocalName();\n            if (! props.contains(name)) {   //处理配置中声明的没有满足注入条件的剩余属性\n                if (parameters == null) {\n                    parameters = new ManagedMap();\n                }\n                String value = node.getNodeValue();\n                parameters.put(name, new TypedStringValue(value, String.class));\n            }\n        }\n        if (parameters != null) {\n            beanDefinition.getPropertyValues().addPropertyValue(&quot;parameters&quot;, parameters);\n        }\n        return beanDefinition;\n    }\n\n    private static final Pattern GROUP_AND_VERION = Pattern.compile(&quot;^[\\\\-.0-9_a-zA-Z]+(\\\\:[\\\\-.0-9_a-zA-Z]+)?$&quot;);\n\n    protected static MonitorConfig convertMonitor(String monitor) {\n        if (monitor == null || monitor.length() == 0) {\n            return null;\n        }\n        if (GROUP_AND_VERION.matcher(monitor).matches()) {\n            String group;\n            String version;\n            int i = monitor.indexOf(&apos;:&apos;);\n            if (i &gt; 0) {\n                group = monitor.substring(0, i);\n                version = monitor.substring(i + 1);\n            } else {\n                group = monitor;\n                version = null;\n            }\n            MonitorConfig monitorConfig = new MonitorConfig();\n            monitorConfig.setGroup(group);\n            monitorConfig.setVersion(version);\n            return monitorConfig;\n        }\n        return null;\n    }\n\n    private static boolean isPrimitive(Class&lt;?&gt; cls) {\n        return cls.isPrimitive() || cls == Boolean.class || cls == Byte.class\n                || cls == Character.class || cls == Short.class || cls == Integer.class\n                || cls == Long.class || cls == Float.class || cls == Double.class\n                || cls == String.class || cls == Date.class || cls == Class.class;\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static void parseMultiRef(String property, String value, RootBeanDefinition beanDefinition,\n            ParserContext parserContext) {\n        String[] values = value.split(&quot;\\\\s*[,]+\\\\s*&quot;);\n        ManagedList list = null;\n        for (int i = 0; i &lt; values.length; i++) {\n            String v = values[i];\n            if (v != null &amp;&amp; v.length() &gt; 0) {\n                if (list == null) {\n                    list = new ManagedList();\n                }\n                list.add(new RuntimeBeanReference(v));\n            }\n        }\n        beanDefinition.getPropertyValues().addPropertyValue(property, list);\n    }\n\n    private static void parseNested(Element element,\n                                    ParserContext parserContext,\n                                    Class&lt;?&gt; beanClass,\n                                    boolean required,\n                                    String tag,\n                                    String property,\n                                    String ref,\n                                    BeanDefinition beanDefinition) {\n        NodeList nodeList = element.getChildNodes();\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            boolean first = true;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    if (tag.equals(node.getNodeName())\n                            || tag.equals(node.getLocalName())) {\n                        if (first) {\n                            //如果该providerBean没有设置default开关，且子节点中定义了serviceBean，则明确赋值该参数为false，也就是说该providerBean只作为其子serviceBean节点的默认协议\n                            //这样就不会让该providerBean的作用范围盲目扩大（成为所有serviceBean的默认协议）\n                            first = false;\n                            String isDefault = element.getAttribute(&quot;default&quot;);\n                            if (isDefault == null || isDefault.length() == 0) {\n                                beanDefinition.getPropertyValues().addPropertyValue(&quot;default&quot;, &quot;false&quot;);\n                            }\n                        }\n                        //所有子serviceBean定义节点全部解析并引用该providerBean作为默认值配置\n                        BeanDefinition subDefinition = parse((Element) node, parserContext, beanClass, required);\n                        if (subDefinition != null &amp;&amp; ref != null &amp;&amp; ref.length() &gt; 0) {\n                            subDefinition.getPropertyValues().addPropertyValue(property, new RuntimeBeanReference(ref));\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    private static void parseProperties(NodeList nodeList, RootBeanDefinition beanDefinition) {\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    if (&quot;property&quot;.equals(node.getNodeName())\n                            || &quot;property&quot;.equals(node.getLocalName())) {\n                        String name = ((Element) node).getAttribute(&quot;name&quot;);\n                        if (name != null &amp;&amp; name.length() &gt; 0) {\n                            String value = ((Element) node).getAttribute(&quot;value&quot;);  //java基础类型\n                            String ref = ((Element) node).getAttribute(&quot;ref&quot;);  //引用其他bean\n                            if (value != null &amp;&amp; value.length() &gt; 0) {\n                                beanDefinition.getPropertyValues().addPropertyValue(name, value);\n                            } else if (ref != null &amp;&amp; ref.length() &gt; 0) {\n                                beanDefinition.getPropertyValues().addPropertyValue(name, new RuntimeBeanReference(ref));\n                            } else {\n                                throw new UnsupportedOperationException(&quot;Unsupported &lt;property name=\\&quot;&quot; + name + &quot;\\&quot;&gt; sub tag, Only supported &lt;property name=\\&quot;&quot; + name + &quot;\\&quot; ref=\\&quot;...\\&quot; /&gt; or &lt;property name=\\&quot;&quot; + name + &quot;\\&quot; value=\\&quot;...\\&quot; /&gt;&quot;);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static ManagedMap parseParameters(NodeList nodeList, RootBeanDefinition beanDefinition) {   //解析参数配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用。\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            ManagedMap parameters = null;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    if (&quot;parameter&quot;.equals(node.getNodeName())\n                            || &quot;parameter&quot;.equals(node.getLocalName())) {\n                        if (parameters == null) {\n                            parameters = new ManagedMap();\n                        }\n                        String key = ((Element) node).getAttribute(&quot;key&quot;);\n                        String value = ((Element) node).getAttribute(&quot;value&quot;);\n                        boolean hide = &quot;true&quot;.equals(((Element) node).getAttribute(&quot;hide&quot;));\n                        if (hide) {\n                            key = Constants.HIDE_KEY_PREFIX + key;\n                        }\n                        parameters.put(key, new TypedStringValue(value, String.class)); //注意parameter的值都是string类型\n                    }\n                }\n            }\n            return parameters;\n        }\n        return null;\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static void parseMethods(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n                              ParserContext parserContext) {\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            ManagedList methods = null;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    Element element = (Element) node;\n                    if (&quot;method&quot;.equals(node.getNodeName()) || &quot;method&quot;.equals(node.getLocalName())) {\n                        String methodName = element.getAttribute(&quot;name&quot;);\n                        if (methodName == null || methodName.length() == 0) {   //name为必填项，这一点在文档里也表明\n                            throw new IllegalStateException(&quot;&lt;dubbo:method&gt; name attribute == null&quot;);\n                        }\n                        if (methods == null) {\n                            methods = new ManagedList();\n                        }\n                        BeanDefinition methodBeanDefinition = parse(((Element) node),\n                                parserContext, MethodConfig.class, false);  //解析methodConfig\n                        String name = id + &quot;.&quot; + methodName;    //注意这里，方法的名称前会加上bean的id\n                        BeanDefinitionHolder methodBeanDefinitionHolder = new BeanDefinitionHolder(\n                                methodBeanDefinition, name);\n                        methods.add(methodBeanDefinitionHolder);\n                    }\n                }\n            }\n            if (methods != null) {\n                beanDefinition.getPropertyValues().addPropertyValue(&quot;methods&quot;, methods);    //关联bean和其method\n            }\n        }\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static void parseArguments(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n                              ParserContext parserContext) {\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            ManagedList arguments = null;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    Element element = (Element) node;\n                    if (&quot;argument&quot;.equals(node.getNodeName()) || &quot;argument&quot;.equals(node.getLocalName())) {\n                        String argumentIndex = element.getAttribute(&quot;index&quot;);   //不清楚这里为何没有必填校验\n                        if (arguments == null) {\n                            arguments = new ManagedList();\n                        }\n                        BeanDefinition argumentBeanDefinition = parse(((Element) node),\n                                parserContext, ArgumentConfig.class, false);\n                        String name = id + &quot;.&quot; + argumentIndex;\n                        BeanDefinitionHolder argumentBeanDefinitionHolder = new BeanDefinitionHolder(\n                                argumentBeanDefinition, name);\n                        arguments.add(argumentBeanDefinitionHolder);\n                    }\n                }\n            }\n            if (arguments != null) {\n                beanDefinition.getPropertyValues().addPropertyValue(&quot;arguments&quot;, arguments);    //关联arguments和其method\n            }\n        }\n    }\n\n}\n</code></pre><p>现在，我们的dubbo就已经把配置文件中定义的bean全部解析成对应的<strong>beanDefinition</strong>，为spring的getBean做好准备工作。</p>\n<h2 id=\"beanDefinition-gt-bean\"><a href=\"#beanDefinition-gt-bean\" class=\"headerlink\" title=\"beanDefinition -&gt; bean\"></a>beanDefinition -&gt; bean</h2><p>其实也就是从beanDefinition转换成bean的过程，我在网上找了<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/\" target=\"_blank\" rel=\"external\">一幅图</a>，可以辅助我们了解spring内部是如何初始化bean的：</p>\n<p><img src=\"http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/origin_image012.gif\" alt=\"\"></p>\n<p>这里也有一篇不错的<a href=\"http://songzi0206.iteye.com/blog/1430239#show-last-Point\" target=\"_blank\" rel=\"external\">文章</a>，从代码的角度描述了spring内部是如何使用BeanDefinition生成Bean的，dubbo就是委托给spring来管理bean的生命周期的。</p>\n<p>那么dubbo自定义schemas所产生的beanDefinition，spring是如何将其转换成dubbo需要的bean呢？毕竟我们从上面的解析中看到，解析生成的beanDefinition中包含太多dubbo特殊的配置方式。这里我有两个猜测：</p>\n<ul>\n<li>dubbo在spring提供的相关扩展点上实现了自己的getBean逻辑，可我却在dubbo的源码中找不到对应实现；</li>\n<li><strong>spring解析生成的beanDefinition并没有dubbo特殊性，交给默认的BeanFactory没啥问题</strong>（这都怪我spring太差啊~）</li>\n</ul>\n<p>带着疑问我进行了严酷的单步调试，事实证明是第二种路数。到目前为止，dubbo已经按照我们提供的配置文件把所有需要的<strong>bean</strong>初始化完成，这部分基本上都是交给spring来搞定的。</p>\n<p>这还不够，我们还不知道这些bean是怎么服务于业务！</p>\n<h2 id=\"bean-gt-service\"><a href=\"#bean-gt-service\" class=\"headerlink\" title=\"bean -&gt; service\"></a>bean -&gt; service</h2><p>那么到底是哪些bean最终会被dubbo直接拿来使用呢？其实<code>DubboNamespaceHandler.init</code>中的那些就是答案。我们先看一下这些类的关系：</p>\n<p><img src=\"http://alibaba.github.io/dubbo-doc-static/dubbo-config.jpg-version=1&amp;modificationDate=1330708121000.jpg\" alt=\"\"></p>\n<p>其实这么复杂的关系最终都会被转换成字符串以<code>URL</code>的形式交给dubbo的底层最终暴露成服务。我们先来重点看一下<code>ServiceBean</code>的实现，了解一下服务提供方的细节。</p>\n<p>按照上面uml图来看，这些<strong>xxxConfig</strong>类的关系已经很清楚了（谁继承谁，谁聚合谁，谁依赖谁）。不过图里并没有出现我们的目标：<strong>ServiceBean</strong>，补充下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/En3pJXbV/NqlfS.png\" alt=\"\"></p>\n<p>除了继承父类外，我们也要注意<code>ServiceBean</code>实现的相关接口：</p>\n<pre><code>public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware \n</code></pre><p>这里我们着重看<code>InitializingBean</code>接口，该接口为spring留给开发者的一个hook，用来执行初始化bean的个性化逻辑的回调，详情可以看这篇<a href=\"http://www.cnblogs.com/zrtqsk/p/3735273.html#show-last-Point\" target=\"_blank\" rel=\"external\">文章</a>。</p>\n<p>既然我们的<code>ServiceBean</code>实现了这个接口，意味着当spring进行容器初始化任务过程中，会执行我们在<code>ServiceBean.afterPropertiesSet</code>方法中安排的逻辑，这也是bean导出为服务的关键入口，先把本尊注释过的代码贴出来：</p>\n<pre><code>public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware {\n\n    private static final long serialVersionUID = 213195494150089726L;\n\n    private static transient ApplicationContext SPRING_CONTEXT;\n\n    private transient ApplicationContext applicationContext;\n\n    private transient String beanName;\n\n    private transient boolean supportedApplicationListener;\n\n    public ServiceBean() {\n        super();\n    }\n\n    public ServiceBean(Service service) {\n        super(service);\n    }\n\n    public static ApplicationContext getSpringContext() {\n        return SPRING_CONTEXT;\n    }\n\n    public void setApplicationContext(ApplicationContext applicationContext) {\n        this.applicationContext = applicationContext;\n\n        //把该应用上下文存储在SpringExtensionFactory（dubbo的SPI扩展点机制）中\n        //把原先spring通过ApplicationContext获取bean的方式封装了一下，以dubbo统一的SPI扩展点机制风格接口暴露给业务使用\n        SpringExtensionFactory.addApplicationContext(applicationContext);\n        if (applicationContext != null) {\n            SPRING_CONTEXT = applicationContext;\n            try {\n                //把所有serviceBean都加入到ApplicationContext的事件通知中\n                Method method = applicationContext.getClass().getMethod(&quot;addApplicationListener&quot;, new Class&lt;?&gt;[]{ApplicationListener.class}); // 兼容Spring2.0.1\n                method.invoke(applicationContext, new Object[] {this});\n                supportedApplicationListener = true;\n            } catch (Throwable t) {\n                if (applicationContext instanceof AbstractApplicationContext) {\n                    try {\n                        Method method = AbstractApplicationContext.class.getDeclaredMethod(&quot;addListener&quot;, new Class&lt;?&gt;[]{ApplicationListener.class}); // 兼容Spring2.0.1\n                        if (! method.isAccessible()) {\n                            method.setAccessible(true);\n                        }\n                        method.invoke(applicationContext, new Object[] {this});\n                        supportedApplicationListener = true;\n                    } catch (Throwable t2) {\n                    }\n                }\n            }\n        }\n    }\n\n    public void setBeanName(String name) {\n        this.beanName = name;\n    }\n\n    //如果配置serviceBean时声明了延迟暴露（例如：&lt;dubbo:service delay=&quot;-1&quot; /&gt;），则会依赖监听spring提供的相关事件来触发export\n    public void onApplicationEvent(ApplicationEvent event) {\n        if (ContextRefreshedEvent.class.getName().equals(event.getClass().getName())) { //监听ContextRefreshedEvent事件（容器发生初始化或更新时触发）\n            if (isDelay() &amp;&amp; ! isExported() &amp;&amp; ! isUnexported()) {  //如果已导出过或者已手工放弃导出则不会执行export逻辑\n                if (logger.isInfoEnabled()) {\n                    logger.info(&quot;The service ready on spring started. service: &quot; + getInterface());\n                }\n                export();\n            }\n        }\n    }\n\n    private boolean isDelay() {\n        Integer delay = getDelay();\n        ProviderConfig provider = getProvider();\n        if (delay == null &amp;&amp; provider != null) {    //若没有明确指定延迟，则尝试继承provider配置\n            delay = provider.getDelay();\n        }\n        return supportedApplicationListener &amp;&amp; (delay == null || delay.intValue() == -1);   //注意这里对delay值的条件很奇怪，如果我设置delay为5000毫秒时，难道不算是延迟么？请参考\\com\\alibaba\\dubbo\\config\\ServiceConfig.java的132行\n    }\n\n    @SuppressWarnings({ &quot;unchecked&quot;, &quot;deprecation&quot; })\n    public void afterPropertiesSet() throws Exception {\n        if (getProvider() == null) {    //如果当前serviceBean并没有指定provider，则下面的逻辑为其指定默认的providerConfig（如果存在的话）\n            Map&lt;String, ProviderConfig&gt; providerConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProviderConfig.class, false, false);\n            if (providerConfigMap != null &amp;&amp; providerConfigMap.size() &gt; 0) {\n                Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n                if ((protocolConfigMap == null || protocolConfigMap.size() == 0)\n                        &amp;&amp; providerConfigMap.size() &gt; 1) { // 兼容旧版本\n                    List&lt;ProviderConfig&gt; providerConfigs = new ArrayList&lt;ProviderConfig&gt;();\n                    for (ProviderConfig config : providerConfigMap.values()) {\n                        if (config.isDefault() != null &amp;&amp; config.isDefault().booleanValue()) {  //把所有指定为默认范围的providerConfig拿到，跳转到下面\n                            providerConfigs.add(config);\n                        }\n                    }\n                    if (providerConfigs.size() &gt; 0) {\n                        setProviders(providerConfigs);  //接着上面，把所有指定为默认范围的providerConfig中与protocol相关的配置封装成protocolConfig并存入serviceConfig对应属性中\n                    }\n                } else {\n                    ProviderConfig providerConfig = null;\n                    for (ProviderConfig config : providerConfigMap.values()) {\n                        //如果某个provider配置包含子node（ServiceBean），且没有明确指定default，也会被当成默认配置么？这个疑问请参看：com\\alibaba\\dubbo\\config\\spring\\schema\\DubboBeanDefinitionParser.java中330行注解\n                        if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                            if (providerConfig != null) {   //只能有一个provider设置为默认\n                                throw new IllegalStateException(&quot;Duplicate provider configs: &quot; + providerConfig + &quot; and &quot; + config);\n                            }\n                            providerConfig = config;\n                        }\n                    }\n                    if (providerConfig != null) {\n                        setProvider(providerConfig);    //为serviceBean绑定继承的providerConfig\n                    }\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Application且其继承的provider也没有指定Application，则下面的逻辑为其指定默认的applicationConfig（如果存在的话）\n        if (getApplication() == null\n                &amp;&amp; (getProvider() == null || getProvider().getApplication() == null)) {\n            Map&lt;String, ApplicationConfig&gt; applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false);\n            if (applicationConfigMap != null &amp;&amp; applicationConfigMap.size() &gt; 0) {\n                ApplicationConfig applicationConfig = null;\n                for (ApplicationConfig config : applicationConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        if (applicationConfig != null) {    //只能有一个Application设置为默认\n                            throw new IllegalStateException(&quot;Duplicate application configs: &quot; + applicationConfig + &quot; and &quot; + config);\n                        }\n                        applicationConfig = config;\n                    }\n                }\n                if (applicationConfig != null) {\n                    setApplication(applicationConfig);  //为serviceBean绑定applicationConfig\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Module且其继承的provider也没有指定Module，则下面的逻辑为其指定默认的moduleConfig（如果存在的话）\n        if (getModule() == null\n                &amp;&amp; (getProvider() == null || getProvider().getModule() == null)) {\n            Map&lt;String, ModuleConfig&gt; moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false);\n            if (moduleConfigMap != null &amp;&amp; moduleConfigMap.size() &gt; 0) {\n                ModuleConfig moduleConfig = null;\n                for (ModuleConfig config : moduleConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        if (moduleConfig != null) { //只能有一个Module设置为默认\n                            throw new IllegalStateException(&quot;Duplicate module configs: &quot; + moduleConfig + &quot; and &quot; + config);\n                        }\n                        moduleConfig = config;\n                    }\n                }\n                if (moduleConfig != null) {\n                    setModule(moduleConfig);    //为serviceBean绑定moduleConfig\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Registry且其继承的provider,application也没有指定Registry，则下面的逻辑为其指定默认的registryConfig（如果存在的话）\n        if ((getRegistries() == null || getRegistries().size() == 0)\n                &amp;&amp; (getProvider() == null || getProvider().getRegistries() == null || getProvider().getRegistries().size() == 0)\n                &amp;&amp; (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().size() == 0)) {\n            Map&lt;String, RegistryConfig&gt; registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false);\n            if (registryConfigMap != null &amp;&amp; registryConfigMap.size() &gt; 0) {\n                List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;();\n                for (RegistryConfig config : registryConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {  //允许为serviceBean指定多个Registry\n                        registryConfigs.add(config);\n                    }\n                }\n                if (registryConfigs != null &amp;&amp; registryConfigs.size() &gt; 0) {\n                    super.setRegistries(registryConfigs);\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Monitor且其继承的provider,application也没有指定Monitor，则下面的逻辑为其指定默认的monitorConfig（如果存在的话）\n        if (getMonitor() == null\n                &amp;&amp; (getProvider() == null || getProvider().getMonitor() == null)\n                &amp;&amp; (getApplication() == null || getApplication().getMonitor() == null)) {\n            Map&lt;String, MonitorConfig&gt; monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false);\n            if (monitorConfigMap != null &amp;&amp; monitorConfigMap.size() &gt; 0) {\n                MonitorConfig monitorConfig = null;\n                for (MonitorConfig config : monitorConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        if (monitorConfig != null) {    //只能有一个Monitor设置为默认\n                            throw new IllegalStateException(&quot;Duplicate monitor configs: &quot; + monitorConfig + &quot; and &quot; + config);\n                        }\n                        monitorConfig = config;\n                    }\n                }\n                if (monitorConfig != null) {\n                    setMonitor(monitorConfig);  //为serviceBean绑定monitorConfig\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Protocol且其继承的provider也没有指定Protocol，则下面的逻辑为其指定默认的protocolConfig（如果存在的话）\n        if ((getProtocols() == null || getProtocols().size() == 0)\n                &amp;&amp; (getProvider() == null || getProvider().getProtocols() == null || getProvider().getProtocols().size() == 0)) {\n            Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n            if (protocolConfigMap != null &amp;&amp; protocolConfigMap.size() &gt; 0) {\n                List&lt;ProtocolConfig&gt; protocolConfigs = new ArrayList&lt;ProtocolConfig&gt;();\n                for (ProtocolConfig config : protocolConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        protocolConfigs.add(config);    //允许为serviceBean指定多个Protocol\n                    }\n                }\n                if (protocolConfigs != null &amp;&amp; protocolConfigs.size() &gt; 0) {\n                    super.setProtocols(protocolConfigs);\n                }\n            }\n        }\n        //设置服务路径，默认使用的是该bean在spring容器中注册的beanName，这也是该类继承BeanNameAware的原因\n        if (getPath() == null || getPath().length() == 0) {\n            if (beanName != null &amp;&amp; beanName.length() &gt; 0 \n                    &amp;&amp; getInterface() != null &amp;&amp; getInterface().length() &gt; 0\n                    &amp;&amp; beanName.startsWith(getInterface())) {\n                setPath(beanName);\n            }\n        }\n        //若不是延迟加载，就上演好戏\n        if (! isDelay()) {\n            export();\n        }\n    }\n\n    public void destroy() throws Exception {\n        unexport();\n    }\n}\n</code></pre><p>这里就明白为何ServiceBean和其父类ServiceConfig不在同一个包内，因为前者是为了适配spring而提供的适配器。ServiceBean依赖spring提供的相关hook接口完成了bean的初始化，最终<code>export</code>逻辑交给<code>ServiceConfig</code>来完成，这才是dubbo的核心服务配置类，这也解释了为何上面UML图中没有画ServiceBean的原因。</p>\n<p>我们继续跟着线索来看一下<code>ServiceConfig.export</code>：</p>\n<pre><code>public synchronized void export() {\n    //从provider中继承一些必要但没有明确设置的参数\n    if (provider != null) {\n        if (export == null) {\n            export = provider.getExport();\n        }\n        if (delay == null) {\n            delay = provider.getDelay();\n        }\n    }\n    if (export != null &amp;&amp; ! export.booleanValue()) {    //如果不需要暴露该服务，则就此结束\n        return;\n    }\n    if (delay != null &amp;&amp; delay &gt; 0) {   //如果明确指定了想要延迟的时间差，则依赖线程休眠来完成延迟暴露，delay的值只有为-1或null才依赖spring的事件机制完成延迟暴露\n        Thread thread = new Thread(new Runnable() {\n            public void run() {\n                try {\n                    Thread.sleep(delay);\n                } catch (Throwable e) {\n                }\n                doExport();\n            }\n        });\n        thread.setDaemon(true);\n        thread.setName(&quot;DelayExportServiceThread&quot;);\n        thread.start();\n    } else {\n        doExport();\n    }\n}\n</code></pre><p>一目了然，这个方法主要就是解决了到底暴露不暴露的问题，并且到底是不是延迟暴露的问题。接下来看看<code>doExport</code>方法：</p>\n<pre><code>protected synchronized void doExport() {\n    if (unexported) {\n        throw new IllegalStateException(&quot;Already unexported!&quot;);\n    }\n    if (exported) {\n        return;\n    }\n\n    exported = true;    //修改暴露状态\n\n    if (interfaceName == null || interfaceName.length() == 0) {\n        throw new IllegalStateException(&quot;&lt;dubbo:service interface=\\&quot;\\&quot; /&gt; interface not allow null!&quot;);\n    }\n\n    checkDefault(); //根据文档中提到的参数优先级，决定最终使用的配置值，在spring的xml解析阶段只是简单解析xml的配置值，在真正使用前，还需要看一下：-D和properties文件\n\n    //下面根据文档中的优先级创建对应的继承链\n    if (provider != null) { //todo 这里必然成立吧？\n        if (application == null) {\n            application = provider.getApplication();\n        }\n        if (module == null) {\n            module = provider.getModule();\n        }\n        if (registries == null) {\n            registries = provider.getRegistries();\n        }\n        if (monitor == null) {\n            monitor = provider.getMonitor();\n        }\n        if (protocols == null) {\n            protocols = provider.getProtocols();\n        }\n    }\n    if (module != null) {\n        if (registries == null) {\n            registries = module.getRegistries();\n        }\n        if (monitor == null) {\n            monitor = module.getMonitor();\n        }\n    }\n    if (application != null) {\n        if (registries == null) {\n            registries = application.getRegistries();\n        }\n        if (monitor == null) {\n            monitor = application.getMonitor();\n        }\n    }\n\n    if (ref instanceof GenericService) {    //泛接口实现方式主要用于服务器端没有API接口及模型类元的情况，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如：实现一个通用的远程服务Mock框架，可通过实现GenericService接口处理所有服务请求。\n        interfaceClass = GenericService.class;\n        if (StringUtils.isEmpty(generic)) {\n            generic = Boolean.TRUE.toString();\n        }\n    } else {\n        try {\n            interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                    .getContextClassLoader());\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        checkInterfaceAndMethods(interfaceClass, methods);  //检查接口和方法的匹配情况\n        checkRef(); //检查接口和实现的匹配情况\n        generic = Boolean.FALSE.toString();\n    }\n\n    if(local !=null){   //todo 文档中并没有与local相关的参数解释\n        if(local==&quot;true&quot;){\n            local=interfaceName+&quot;Local&quot;;\n        }\n        Class&lt;?&gt; localClass;\n        try {\n            localClass = ClassHelper.forNameWithThreadContextClassLoader(local);\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        if(!interfaceClass.isAssignableFrom(localClass)){\n            throw new IllegalStateException(&quot;The local implemention class &quot; + localClass.getName() + &quot; not implement interface &quot; + interfaceName);\n        }\n    }\n\n    //本地存根，http://alibaba.github.io/dubbo-doc-static/Stub+Proxy-zh.htm\n    if(stub !=null){\n        if(stub==&quot;true&quot;){\n            stub=interfaceName+&quot;Stub&quot;;  //todo 这里文档中的解释貌似有错误：http://alibaba.github.io/dubbo-doc-static/Service+Config-zh.htm\n        }\n        Class&lt;?&gt; stubClass;\n        try {\n            stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub);\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        if(!interfaceClass.isAssignableFrom(stubClass)){\n            throw new IllegalStateException(&quot;The stub implemention class &quot; + stubClass.getName() + &quot; not implement interface &quot; + interfaceName);\n        }\n    }\n\n    //作用雷同于上面的checkDefault()，根据文档中提到的参数优先级来选择使用的配置参数\n    checkApplication();\n    checkRegistry();\n    checkProtocol();\n    appendProperties(this);\n\n    checkStubAndMock(interfaceClass);   //检查local，stub和mock的有效性\n\n    if (path == null || path.length() == 0) {   //此时path如果还为空，这使用interfaceName\n        path = interfaceName;\n    }\n\n    doExportUrls();\n}\n</code></pre><p>木牛错，<code>doExport</code>方法依然是在做预备工作，感觉越来越靠近真像了，目前为止，我们已经按照规定的优先级最终确定了要暴露成为服务的bean的”大部分”相关配置参数，并校验了相关参数的有效性（例如：ref，method，stub，mock，path等）。再来看一下<code>doExportUrls</code>方法：</p>\n<pre><code>private void doExportUrls() {\n    List&lt;URL&gt; registryURLs = loadRegistries(true);  //获取所有的注册中心地址\n    for (ProtocolConfig protocolConfig : protocols) {\n        doExportUrlsFor1Protocol(protocolConfig, registryURLs);\n    }\n}\n</code></pre><p>好，是该真刀真枪干一架的时候了，<code>doExportUrlsFor1Protocol</code>应该就是今次的Boss，解决掉它我们就回家。</p>\n<pre><code>private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) {\n    String name = protocolConfig.getName();\n    if (name == null || name.length() == 0) {\n        name = &quot;dubbo&quot;; //N多次的检查，N多次的赋值，这算是严谨呢？还是重复？\n    }\n\n    String host = protocolConfig.getHost();\n    if (provider != null &amp;&amp; (host == null || host.length() == 0)) {\n        host = provider.getHost();\n    }\n    boolean anyhost = false;\n    if (NetUtils.isInvalidLocalHost(host)) {    //检查host是否为本地ip，或者无效的\n        anyhost = true;\n        try {\n            host = InetAddress.getLocalHost().getHostAddress();\n        } catch (UnknownHostException e) {\n            logger.warn(e.getMessage(), e);\n        }\n        if (NetUtils.isInvalidLocalHost(host)) {    //如果拿到的还是本地地址，就只能出杀手锏了\n            if (registryURLs != null &amp;&amp; registryURLs.size() &gt; 0) {\n                for (URL registryURL : registryURLs) {\n                    try {\n                        Socket socket = new Socket();\n                        try {\n                            //尝试连接注册中心，选用连接时使用的ip地址\n                            SocketAddress addr = new InetSocketAddress(registryURL.getHost(), registryURL.getPort());\n                            socket.connect(addr, 1000);\n                            host = socket.getLocalAddress().getHostAddress();\n                            break;\n                        } finally {\n                            try {\n                                socket.close();\n                            } catch (Throwable e) {}\n                        }\n                    } catch (Exception e) {\n                        logger.warn(e.getMessage(), e);\n                    }\n                }\n            }\n            if (NetUtils.isInvalidLocalHost(host)) {\n                host = NetUtils.getLocalHost(); //实在不行，就只能使用本机上第一个找到的合法ip了\n            }\n        }\n    }\n\n    Integer port = protocolConfig.getPort();\n    if (provider != null &amp;&amp; (port == null || port == 0)) {\n        port = provider.getPort();\n    }\n    final int defaultPort = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(name).getDefaultPort();\n    if (port == null || port == 0) {\n        port = defaultPort;\n    }\n    if (port == null || port &lt;= 0) {\n        port = getRandomPort(name);\n        if (port == null || port &lt; 0) {\n            port = NetUtils.getAvailablePort(defaultPort);  //到这里如果还没有拿到port，就直接随机拿个能用的端口\n            putRandomPort(name, port);  //这一步很讲究，意味着相同协议使用相同的端口，要理解这个就需要先消化dubbo底层通信方式。\n        }\n        logger.warn(&quot;Use random available port(&quot; + port + &quot;) for protocol &quot; + name);\n    }\n\n    Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();\n    if (anyhost) {\n        map.put(Constants.ANYHOST_KEY, &quot;true&quot;);\n    }\n    map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE);\n    map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion());\n    map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));\n    if (ConfigUtils.getPid() &gt; 0) {\n        map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));\n    }\n\n    //获取相关的配置参数用于后面的url生成，注意优先级顺序哟\n    appendParameters(map, application);\n    appendParameters(map, module);\n    appendParameters(map, provider, Constants.DEFAULT_KEY);\n    appendParameters(map, protocolConfig);\n    appendParameters(map, this);\n\n    if (methods != null &amp;&amp; methods.size() &gt; 0) {\n        for (MethodConfig method : methods) {\n            appendParameters(map, method, method.getName());\n\n            //处理重试设置\n            String retryKey = method.getName() + &quot;.retry&quot;;\n            if (map.containsKey(retryKey)) {\n                String retryValue = map.remove(retryKey);\n                if (&quot;false&quot;.equals(retryValue)) {\n                    map.put(method.getName() + &quot;.retries&quot;, &quot;0&quot;);\n                }\n            }\n\n            List&lt;ArgumentConfig&gt; arguments = method.getArguments();\n            if (arguments != null &amp;&amp; arguments.size() &gt; 0) {\n                for (ArgumentConfig argument : arguments) { //ArgumentConfig作用主要就是用来完成事件回调机制。\n                    //类型自动转换.\n                    if(argument.getType() != null &amp;&amp; argument.getType().length() &gt;0){\n                        Method[] methods = interfaceClass.getMethods();\n                        //遍历所有方法\n                        if(methods != null &amp;&amp; methods.length &gt; 0){\n                            for (int i = 0; i &lt; methods.length; i++) {\n                                String methodName = methods[i].getName();\n                                //匹配方法名称，获取方法签名.\n                                if(methodName.equals(method.getName())){    //注意方法重载情况\n                                    Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes();\n                                    //一个方法中单个callback\n                                    if (argument.getIndex() != -1 ){    //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                        if (argtypes[argument.getIndex()].getName().equals(argument.getType())){\n                                            appendParameters(map, argument, method.getName() + &quot;.&quot; + argument.getIndex());\n                                        }else {\n                                            throw new IllegalArgumentException(&quot;argument config error : the index attribute and type attirbute not match :index :&quot;+argument.getIndex() + &quot;, type:&quot; + argument.getType());\n                                        }\n                                    } else {\n                                        //一个方法中多个callback\n                                        for (int j = 0 ;j&lt;argtypes.length ;j++) {   //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                            Class&lt;?&gt; argclazz = argtypes[j];\n                                            if (argclazz.getName().equals(argument.getType())){\n                                                appendParameters(map, argument, method.getName() + &quot;.&quot; + j);\n                                                if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j){\n                                                    throw new IllegalArgumentException(&quot;argument config error : the index attribute and type attirbute not match :index :&quot;+argument.getIndex() + &quot;, type:&quot; + argument.getType());\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }else if(argument.getIndex() != -1){\n                        appendParameters(map, argument, method.getName() + &quot;.&quot; + argument.getIndex());\n                    }else {\n                        throw new IllegalArgumentException(&quot;argument config must set index or type attribute.eg: &lt;dubbo:argument index=&apos;0&apos; .../&gt; or &lt;dubbo:argument type=xxx .../&gt;&quot;);\n                    }\n\n                }\n            }\n        } // end of methods for\n    }\n\n    if (ProtocolUtils.isGeneric(generic)) { //处理泛化\n        map.put(&quot;generic&quot;, generic);\n        map.put(&quot;methods&quot;, Constants.ANY_VALUE);\n    } else {\n        String revision = Version.getVersion(interfaceClass, version);\n        if (revision != null &amp;&amp; revision.length() &gt; 0) {\n            map.put(&quot;revision&quot;, revision);  //todo 为什么是revision?\n        }\n\n        String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); //todo 动态封装interfaceClass，目前不知道干啥用，猜测dubbo直接操作的都是这个封装后的wrapper\n        if(methods.length == 0) {\n            logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName());\n            map.put(&quot;methods&quot;, Constants.ANY_VALUE);\n        }\n        else {\n            map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;));\n        }\n    }\n\n    //令牌验证，为空表示不开启，如果为true，表示随机生成动态令牌，否则使用静态令牌，令牌的作用是防止消费者绕过注册中心直接访问，保证注册中心的授权功能有效，如果使用点对点调用，需关闭令牌功能\n    if (! ConfigUtils.isEmpty(token)) {\n        if (ConfigUtils.isDefault(token)) {\n            map.put(&quot;token&quot;, UUID.randomUUID().toString());\n        } else {\n            map.put(&quot;token&quot;, token);\n        }\n    }\n\n    //injvm表示不会跨进程，所以不需要注册中心\n    if (&quot;injvm&quot;.equals(protocolConfig.getName())) {\n        protocolConfig.setRegister(false);\n        map.put(&quot;notify&quot;, &quot;false&quot;);\n    }\n\n    // 导出服务\n    String contextPath = protocolConfig.getContextpath();\n    if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) {\n        contextPath = provider.getContextpath();\n    }\n    URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? &quot;&quot; : contextPath + &quot;/&quot;) + path, map);   //拿到服务的url\n\n    if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n            .hasExtension(url.getProtocol())) {\n        url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n                .getExtension(url.getProtocol()).getConfigurator(url).configure(url);\n    }\n\n    String scope = url.getParameter(Constants.SCOPE_KEY);\n    //配置为none不暴露\n    if (! Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) {\n\n        //配置不是remote的情况下做本地暴露 (配置为remote，则表示只暴露远程服务)\n        if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) {\n            exportLocal(url);\n        }\n        //如果配置不是local则暴露为远程服务.(配置为local，则表示只暴露远程服务)\n        if (! Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope) ){\n            if (logger.isInfoEnabled()) {\n                logger.info(&quot;Export dubbo service &quot; + interfaceClass.getName() + &quot; to url &quot; + url);\n            }\n            if (registryURLs != null &amp;&amp; registryURLs.size() &gt; 0\n                    &amp;&amp; url.getParameter(&quot;register&quot;, true)) {\n                for (URL registryURL : registryURLs) {\n                    url = url.addParameterIfAbsent(&quot;dynamic&quot;, registryURL.getParameter(&quot;dynamic&quot;));\n                    URL monitorUrl = loadMonitor(registryURL);\n                    if (monitorUrl != null) {\n                        url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString());\n                    }\n                    if (logger.isInfoEnabled()) {\n                        logger.info(&quot;Register dubbo service &quot; + interfaceClass.getName() + &quot; url &quot; + url + &quot; to registry &quot; + registryURL);\n                    }\n                    //todo 暴露为何要封装一层代理呢？\n                    Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()));\n\n                    Exporter&lt;?&gt; exporter = protocol.export(invoker);\n                    exporters.add(exporter);\n                }\n            } else {\n                //todo 暴露为何要封装一层代理呢？\n                Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\n                Exporter&lt;?&gt; exporter = protocol.export(invoker);\n                exporters.add(exporter);\n            }\n        }\n    }\n    this.urls.add(url);\n}\n</code></pre><p>一路走来可以发现，dubbo会为每个有效协议暴露一份服务，并且会注册到所有有效的注册中心里。而bean转变为service中最重要的就是映射出来的<code>URL</code>，也就是说我们在配置文件中进行的相关配置都会映射成对应url中的相关部分，举个例子：</p>\n<pre><code>&lt;dubbo:application name=&quot;demo-provider&quot; owner=&quot;programmer&quot; organization=&quot;dubbox&quot;/&gt;\n&lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot;/&gt;\n&lt;dubbo:protocol name=&quot;dubbo&quot; serialization=&quot;kryo&quot; optimizer=&quot;com.alibaba.dubbo.demo.SerializationOptimizerImpl&quot;/&gt;\n\n&lt;bean id=&quot;bidService&quot; class=&quot;com.alibaba.dubbo.demo.bid.BidServiceImpl&quot; /&gt;\n&lt;dubbo:service interface=&quot;com.alibaba.dubbo.demo.bid.BidService&quot; ref=&quot;bidService&quot;  protocol=&quot;dubbo&quot; /&gt;\n</code></pre><p>我们通过debug看一下最终它映射出来的url是什么：</p>\n<pre><code>//exportLocal\ninjvm://127.0.0.1/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.0&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.bid.BidService&amp;methods=throwNPE,bid&amp;optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;serialization=kryo&amp;side=provider&amp;timestamp=1422241023451\n\n//exportRemote\nregistry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&amp;dubbo=2.0.0&amp;export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;registry=zookeeper&amp;timestamp=1422240274186\n</code></pre><p>那么这个<code>url</code>的作用是什么呢？官方给出的<a href=\"http://alibaba.github.io/dubbo-doc-static/Init+Detail-zh.htm\" target=\"_blank\" rel=\"external\">解释</a>很明确，这个url作为解耦的通信数据（跨层调用的参数），有了它dubbo就可以更容易做到业务逻辑实现的替换。除此之外可以看到url中还包含了大量的辅助参数（例如：timeout，version，organization等）供服务治理使用，这些都是根据真实需求一步一步补充完善的，可见，<strong>好的架构是演化而来的</strong>。</p>\n<p>可以看到贴出来的代码中包含很多todo项，其中一些问题我们从代码层面是很难找到答案的，我们需要上升到业务，运维甚至架构师高度才能消化得了，小弟将在后续的分析中慢慢的尝试解开谜团。</p>\n","excerpt":"<p>dubbo依赖了spring提供的现成机制完成了bean的创建，我们来看一下这其中的汰渍。</p>","more":"<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><p>关于dubbo的配置相关细节，官方已经给了一个无比详细的<a href=\"http://alibaba.github.io/dubbo-doc-static/Configuration+Reference-zh.htm\">文档</a>，<a href=\"http://alibaba.github.io/dubbo-doc-static/Configs-zh.htm\">文档2</a>。不过由于dubbo可供配置的参数非常多，这也是让我们新手一开始感到最为头疼的，这也是SOA复杂的表象之一。</p>\n<h2 id=\"xml-gt-beanDefinition\"><a href=\"#xml-gt-beanDefinition\" class=\"headerlink\" title=\"xml -&gt; beanDefinition\"></a>xml -&gt; beanDefinition</h2><p>对于我这种小学生，需要先补习一个基础知识点：<a href=\"http://www.cnblogs.com/jifeng/archive/2011/09/14/2176599.html\">基于Spring可扩展Schema提供自定义配置支持</a>。dubbo是依赖spring提供的这种机制来处理配置文件解析的，理解起来没什么难度。</p>\n<p>看一下dubbo-congfig的目录结构：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EllS0JnY/lFpRv.png\" alt=\"\"></p>\n<p>我们来看一下dubbo是如何按照spring提供的机制来处理配置文件的：</p>\n<pre><code>#spring.handlers\nhttp\\://code.alibabatech.com/schema/dubbo=com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler\n\n#spring.schemas\nhttp\\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd\n</code></pre><p>这样我们就锁定了要分析的类：</p>\n<pre><code>package com.alibaba.dubbo.config.spring.schema;\n\npublic class DubboNamespaceHandler extends NamespaceHandlerSupport {\n\n    static {\n        Version.checkDuplicate(DubboNamespaceHandler.class); //确保系统中只存在一份解析处理器类定义\n    }\n\n    public void init() {\n        registerBeanDefinitionParser(&quot;application&quot;, new DubboBeanDefinitionParser(ApplicationConfig.class, true));\n        registerBeanDefinitionParser(&quot;module&quot;, new DubboBeanDefinitionParser(ModuleConfig.class, true));\n        registerBeanDefinitionParser(&quot;registry&quot;, new DubboBeanDefinitionParser(RegistryConfig.class, true));\n        registerBeanDefinitionParser(&quot;monitor&quot;, new DubboBeanDefinitionParser(MonitorConfig.class, true));\n        registerBeanDefinitionParser(&quot;provider&quot;, new DubboBeanDefinitionParser(ProviderConfig.class, true));\n        registerBeanDefinitionParser(&quot;consumer&quot;, new DubboBeanDefinitionParser(ConsumerConfig.class, true));\n        registerBeanDefinitionParser(&quot;protocol&quot;, new DubboBeanDefinitionParser(ProtocolConfig.class, true));\n        registerBeanDefinitionParser(&quot;service&quot;, new DubboBeanDefinitionParser(ServiceBean.class, true));\n        registerBeanDefinitionParser(&quot;reference&quot;, new DubboBeanDefinitionParser(ReferenceBean.class, false));\n        registerBeanDefinitionParser(&quot;annotation&quot;, new DubboBeanDefinitionParser(AnnotationBean.class, true));\n    }\n}\n</code></pre><p>按照spring提供的机制，dubbo把每个自定义的可使用配置元素和对应的解析器绑定到一起。而真正负责把配置文件中声明的内容解析成对应的BeanDefinition（可以想象为Bean的模子）是靠<code>DubboBeanDefinitionParser.parse</code>类完成，我们就来严肃的分析一下这个方法。</p>\n<pre><code>/**\n * AbstractBeanDefinitionParser\n * \n * @author william.liangf\n * @export\n */\npublic class DubboBeanDefinitionParser implements BeanDefinitionParser {\n\n    private static final Logger logger = LoggerFactory.getLogger(DubboBeanDefinitionParser.class);\n\n    private final Class&lt;?&gt; beanClass;\n\n    private final boolean required;\n\n    public DubboBeanDefinitionParser(Class&lt;?&gt; beanClass, boolean required) {\n        this.beanClass = beanClass;\n        this.required = required;\n    }\n\n    public BeanDefinition parse(Element element, ParserContext parserContext) {\n        return parse(element, parserContext, beanClass, required);\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) {\n        //初始化BeanDefiniion\n        RootBeanDefinition beanDefinition = new RootBeanDefinition();\n        beanDefinition.setBeanClass(beanClass);\n        beanDefinition.setLazyInit(false);\n\n        String id = element.getAttribute(&quot;id&quot;);\n        if ((id == null || id.length() == 0) &amp;&amp; required) {\n            String generatedBeanName = element.getAttribute(&quot;name&quot;);\n            if (generatedBeanName == null || generatedBeanName.length() == 0) {\n                if (ProtocolConfig.class.equals(beanClass)) {   //如果当前解析的类型是ProtocolConfig，则设置默认id为dubbo\n                    generatedBeanName = &quot;dubbo&quot;;\n                } else {\n                    generatedBeanName = element.getAttribute(&quot;interface&quot;);  //其他情况，默认id为接口类型\n                }\n            }\n            if (generatedBeanName == null || generatedBeanName.length() == 0) {\n                generatedBeanName = beanClass.getName();    //如果该节点没有interface属性（包含：registry,monitor,provider,consumer），则使用该节点的类型为id值\n            }\n            id = generatedBeanName; \n            int counter = 2;\n            while(parserContext.getRegistry().containsBeanDefinition(id)) { //生成不重复的id\n                id = generatedBeanName + (counter ++);\n            }\n        }\n        if (id != null &amp;&amp; id.length() &gt; 0) {    //目前这个判断不知道啥意义，目测必定会返回true\n            if (parserContext.getRegistry().containsBeanDefinition(id))  {  //这个判断应该用于防止并发\n                throw new IllegalStateException(&quot;Duplicate spring bean id &quot; + id);\n            }\n            //注册beanDefinition，BeanDefinitionRegistry相当于一张注册表\n            parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);\n            beanDefinition.getPropertyValues().addPropertyValue(&quot;id&quot;, id);\n        }\n        //下面这几个if-else分别针对不同类型做特殊处理\n        if (ProtocolConfig.class.equals(beanClass)) {\n            //这段代码的逻辑是用来适配：当&lt;dubbo:protocol&gt;声明出现在配置文件中使用该协议的bean声明的后面时，解决它们之间的依赖关系的。\n            for (String name : parserContext.getRegistry().getBeanDefinitionNames()) {\n                BeanDefinition definition = parserContext.getRegistry().getBeanDefinition(name);\n                PropertyValue property = definition.getPropertyValues().getPropertyValue(&quot;protocol&quot;);\n                if (property != null) {\n                    Object value = property.getValue();\n                    //如果被检查的bean确实使用当前协议，则建立它们之间的依赖关系\n                    if (value instanceof ProtocolConfig &amp;&amp; id.equals(((ProtocolConfig) value).getName())) {\n                        definition.getPropertyValues().addPropertyValue(&quot;protocol&quot;, new RuntimeBeanReference(id));\n                    }\n                }\n            }\n        } else if (ServiceBean.class.equals(beanClass)) {\n            String className = element.getAttribute(&quot;class&quot;);   //虽然文档上没有标注该配置支持class参数，但是在dubbo.xsd上却能看到这个属性的定义，类似这样的情况还有很多。\n            if(className != null &amp;&amp; className.length() &gt; 0) {   //下面的处理方式应该算是语法糖吧，它支持直接把定义bean和创建serviceConfig压缩成一行\n                RootBeanDefinition classDefinition = new RootBeanDefinition();\n                classDefinition.setBeanClass(ReflectUtils.forName(className));\n                classDefinition.setLazyInit(false);\n                parseProperties(element.getChildNodes(), classDefinition);  //完成bean的初始化工作（注入等）\n                beanDefinition.getPropertyValues().addPropertyValue(&quot;ref&quot;, new BeanDefinitionHolder(classDefinition, id + &quot;Impl&quot;)); //关联bean和serviceConfig\n            }\n        } else if (ProviderConfig.class.equals(beanClass)) {    //按照providerConfig的定义解析并关联其影响的相关serviceConfig\n            parseNested(element, parserContext, ServiceBean.class, true, &quot;service&quot;, &quot;provider&quot;, id, beanDefinition);\n        } else if (ConsumerConfig.class.equals(beanClass)) {    //按照consumerConfig的定义解析并关联其影响的相关referenceConfig\n            parseNested(element, parserContext, ReferenceBean.class, false, &quot;reference&quot;, &quot;consumer&quot;, id, beanDefinition);\n        }\n        Set&lt;String&gt; props = new HashSet&lt;String&gt;();\n        ManagedMap parameters = null;\n        for (Method setter : beanClass.getMethods()) {  //利用反射拿到指定类型的所有用于注入的方法\n            String name = setter.getName();\n            if (name.length() &gt; 3 &amp;&amp; name.startsWith(&quot;set&quot;)\n                    &amp;&amp; Modifier.isPublic(setter.getModifiers())\n                    &amp;&amp; setter.getParameterTypes().length == 1) {    //注入方法的特征是：以set字母开头，是公共方法，且参数个数为1\n                Class&lt;?&gt; type = setter.getParameterTypes()[0];\n                String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), &quot;-&quot;);    //把方法名字的驼峰格式改成-分割格式\n                props.add(property);\n                Method getter = null;\n                try {\n                    getter = beanClass.getMethod(&quot;get&quot; + name.substring(3), new Class&lt;?&gt;[0]);\n                } catch (NoSuchMethodException e) {\n                    try {\n                        getter = beanClass.getMethod(&quot;is&quot; + name.substring(3), new Class&lt;?&gt;[0]);\n                    } catch (NoSuchMethodException e2) {\n                    }\n                }\n                if (getter == null \n                        || ! Modifier.isPublic(getter.getModifiers())\n                        || ! type.equals(getter.getReturnType())) { //如果没有满足条件的对应getter方法存在，则直接跳过该setter方法\n                    continue;\n                }\n\n                if (&quot;parameters&quot;.equals(property)) {    //从配置文件中解析出parameter配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用，parameter的值当string类型解析\n                    parameters = parseParameters(element.getChildNodes(), beanDefinition);\n                } else if (&quot;methods&quot;.equals(property)) {    //注入对应的method配置\n                    parseMethods(id, element.getChildNodes(), beanDefinition, parserContext);\n                } else if (&quot;arguments&quot;.equals(property)) {  //为method注入对应的argument配置\n                    parseArguments(id, element.getChildNodes(), beanDefinition, parserContext);\n                } else {\n                    String value = element.getAttribute(property);  //检查该setter方法所适配要注入的属性是否在配置中明确定义\n                    if (value != null) {    //若存在定义，则完成其注入解析\n                        value = value.trim();\n                        if (value.length() &gt; 0) {\n                            if (&quot;registry&quot;.equals(property) &amp;&amp; RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(value)) {   //处理无注册中心的情况\n                                RegistryConfig registryConfig = new RegistryConfig();\n                                registryConfig.setAddress(RegistryConfig.NO_AVAILABLE);\n                                beanDefinition.getPropertyValues().addPropertyValue(property, registryConfig);\n                            } else if (&quot;registry&quot;.equals(property) &amp;&amp; value.indexOf(&apos;,&apos;) != -1) {   //处理多注册中心的情况\n                                parseMultiRef(&quot;registries&quot;, value, beanDefinition, parserContext);\n                            } else if (&quot;provider&quot;.equals(property) &amp;&amp; value.indexOf(&apos;,&apos;) != -1) {   //处理继承多个provider的情况，缺使用第一个provider配置\n                                parseMultiRef(&quot;providers&quot;, value, beanDefinition, parserContext);\n                            } else if (&quot;protocol&quot;.equals(property) &amp;&amp; value.indexOf(&apos;,&apos;) != -1) {   //处理多协议暴露\n                                parseMultiRef(&quot;protocols&quot;, value, beanDefinition, parserContext);\n                            } else {\n                                Object reference;\n                                if (isPrimitive(type)) {    //如果setter的参数类型为jdk原始类型，直接当string注入到对应属性中去\n                                    if (&quot;async&quot;.equals(property) &amp;&amp; &quot;false&quot;.equals(value)\n                                            || &quot;timeout&quot;.equals(property) &amp;&amp; &quot;0&quot;.equals(value)\n                                            || &quot;delay&quot;.equals(property) &amp;&amp; &quot;0&quot;.equals(value)\n                                            || &quot;version&quot;.equals(property) &amp;&amp; &quot;0.0.0&quot;.equals(value)\n                                            || &quot;stat&quot;.equals(property) &amp;&amp; &quot;-1&quot;.equals(value)\n                                            || &quot;reliable&quot;.equals(property) &amp;&amp; &quot;false&quot;.equals(value)) {\n                                        // 兼容旧版本xsd中的default值\n                                        value = null;\n                                    }\n                                    reference = value;\n                                } else if (&quot;protocol&quot;.equals(property) \n                                        &amp;&amp; ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(value)   //是否存在指定的扩展点定义\n                                        &amp;&amp; (! parserContext.getRegistry().containsBeanDefinition(value) //检查当前解析出的要使用协议对应的protocolConfig是否已经被初始化\n                                                || ! ProtocolConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n                                    if (&quot;dubbo:provider&quot;.equals(element.getTagName())) {\n                                        logger.warn(&quot;Recommended replace &lt;dubbo:provider protocol=\\&quot;&quot; + value + &quot;\\&quot; ... /&gt; to &lt;dubbo:protocol name=\\&quot;&quot; + value + &quot;\\&quot; ... /&gt;&quot;);\n                                    }\n                                    // 兼容旧版本配置\n                                    ProtocolConfig protocol = new ProtocolConfig();\n                                    protocol.setName(value);\n                                    reference = protocol;\n                                } else if (&quot;monitor&quot;.equals(property) \n                                        &amp;&amp; (! parserContext.getRegistry().containsBeanDefinition(value)\n                                                || ! MonitorConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) {\n                                    // 兼容旧版本配置\n                                    reference = convertMonitor(value);\n                                } else if (&quot;onreturn&quot;.equals(property)) {   //对应methodConfig中的返回拦截\n                                    int index = value.lastIndexOf(&quot;.&quot;);\n                                    String returnRef = value.substring(0, index);\n                                    String returnMethod = value.substring(index + 1);\n                                    reference = new RuntimeBeanReference(returnRef);\n                                    beanDefinition.getPropertyValues().addPropertyValue(&quot;onreturnMethod&quot;, returnMethod);\n                                } else if (&quot;onthrow&quot;.equals(property)) {    //对应methodConfig中的异常拦截\n                                    int index = value.lastIndexOf(&quot;.&quot;);\n                                    String throwRef = value.substring(0, index);\n                                    String throwMethod = value.substring(index + 1);\n                                    reference = new RuntimeBeanReference(throwRef);\n                                    beanDefinition.getPropertyValues().addPropertyValue(&quot;onthrowMethod&quot;, throwMethod);\n                                } else {\n                                    if (&quot;ref&quot;.equals(property) &amp;&amp; parserContext.getRegistry().containsBeanDefinition(value)) {\n                                        BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(value);\n                                        if (! refBean.isSingleton()) {\n                                            throw new IllegalStateException(&quot;The exported service ref &quot; + value + &quot; must be singleton! Please set the &quot; + value + &quot; bean scope to singleton, eg: &lt;bean id=\\&quot;&quot; + value+ &quot;\\&quot; scope=\\&quot;singleton\\&quot; ...&gt;&quot;);\n                                        }\n                                    }\n                                    reference = new RuntimeBeanReference(value);\n                                }\n                                beanDefinition.getPropertyValues().addPropertyValue(property, reference);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        NamedNodeMap attributes = element.getAttributes();\n        int len = attributes.getLength();\n        for (int i = 0; i &lt; len; i++) {\n            Node node = attributes.item(i);\n            String name = node.getLocalName();\n            if (! props.contains(name)) {   //处理配置中声明的没有满足注入条件的剩余属性\n                if (parameters == null) {\n                    parameters = new ManagedMap();\n                }\n                String value = node.getNodeValue();\n                parameters.put(name, new TypedStringValue(value, String.class));\n            }\n        }\n        if (parameters != null) {\n            beanDefinition.getPropertyValues().addPropertyValue(&quot;parameters&quot;, parameters);\n        }\n        return beanDefinition;\n    }\n\n    private static final Pattern GROUP_AND_VERION = Pattern.compile(&quot;^[\\\\-.0-9_a-zA-Z]+(\\\\:[\\\\-.0-9_a-zA-Z]+)?$&quot;);\n\n    protected static MonitorConfig convertMonitor(String monitor) {\n        if (monitor == null || monitor.length() == 0) {\n            return null;\n        }\n        if (GROUP_AND_VERION.matcher(monitor).matches()) {\n            String group;\n            String version;\n            int i = monitor.indexOf(&apos;:&apos;);\n            if (i &gt; 0) {\n                group = monitor.substring(0, i);\n                version = monitor.substring(i + 1);\n            } else {\n                group = monitor;\n                version = null;\n            }\n            MonitorConfig monitorConfig = new MonitorConfig();\n            monitorConfig.setGroup(group);\n            monitorConfig.setVersion(version);\n            return monitorConfig;\n        }\n        return null;\n    }\n\n    private static boolean isPrimitive(Class&lt;?&gt; cls) {\n        return cls.isPrimitive() || cls == Boolean.class || cls == Byte.class\n                || cls == Character.class || cls == Short.class || cls == Integer.class\n                || cls == Long.class || cls == Float.class || cls == Double.class\n                || cls == String.class || cls == Date.class || cls == Class.class;\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static void parseMultiRef(String property, String value, RootBeanDefinition beanDefinition,\n            ParserContext parserContext) {\n        String[] values = value.split(&quot;\\\\s*[,]+\\\\s*&quot;);\n        ManagedList list = null;\n        for (int i = 0; i &lt; values.length; i++) {\n            String v = values[i];\n            if (v != null &amp;&amp; v.length() &gt; 0) {\n                if (list == null) {\n                    list = new ManagedList();\n                }\n                list.add(new RuntimeBeanReference(v));\n            }\n        }\n        beanDefinition.getPropertyValues().addPropertyValue(property, list);\n    }\n\n    private static void parseNested(Element element,\n                                    ParserContext parserContext,\n                                    Class&lt;?&gt; beanClass,\n                                    boolean required,\n                                    String tag,\n                                    String property,\n                                    String ref,\n                                    BeanDefinition beanDefinition) {\n        NodeList nodeList = element.getChildNodes();\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            boolean first = true;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    if (tag.equals(node.getNodeName())\n                            || tag.equals(node.getLocalName())) {\n                        if (first) {\n                            //如果该providerBean没有设置default开关，且子节点中定义了serviceBean，则明确赋值该参数为false，也就是说该providerBean只作为其子serviceBean节点的默认协议\n                            //这样就不会让该providerBean的作用范围盲目扩大（成为所有serviceBean的默认协议）\n                            first = false;\n                            String isDefault = element.getAttribute(&quot;default&quot;);\n                            if (isDefault == null || isDefault.length() == 0) {\n                                beanDefinition.getPropertyValues().addPropertyValue(&quot;default&quot;, &quot;false&quot;);\n                            }\n                        }\n                        //所有子serviceBean定义节点全部解析并引用该providerBean作为默认值配置\n                        BeanDefinition subDefinition = parse((Element) node, parserContext, beanClass, required);\n                        if (subDefinition != null &amp;&amp; ref != null &amp;&amp; ref.length() &gt; 0) {\n                            subDefinition.getPropertyValues().addPropertyValue(property, new RuntimeBeanReference(ref));\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    private static void parseProperties(NodeList nodeList, RootBeanDefinition beanDefinition) {\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    if (&quot;property&quot;.equals(node.getNodeName())\n                            || &quot;property&quot;.equals(node.getLocalName())) {\n                        String name = ((Element) node).getAttribute(&quot;name&quot;);\n                        if (name != null &amp;&amp; name.length() &gt; 0) {\n                            String value = ((Element) node).getAttribute(&quot;value&quot;);  //java基础类型\n                            String ref = ((Element) node).getAttribute(&quot;ref&quot;);  //引用其他bean\n                            if (value != null &amp;&amp; value.length() &gt; 0) {\n                                beanDefinition.getPropertyValues().addPropertyValue(name, value);\n                            } else if (ref != null &amp;&amp; ref.length() &gt; 0) {\n                                beanDefinition.getPropertyValues().addPropertyValue(name, new RuntimeBeanReference(ref));\n                            } else {\n                                throw new UnsupportedOperationException(&quot;Unsupported &lt;property name=\\&quot;&quot; + name + &quot;\\&quot;&gt; sub tag, Only supported &lt;property name=\\&quot;&quot; + name + &quot;\\&quot; ref=\\&quot;...\\&quot; /&gt; or &lt;property name=\\&quot;&quot; + name + &quot;\\&quot; value=\\&quot;...\\&quot; /&gt;&quot;);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static ManagedMap parseParameters(NodeList nodeList, RootBeanDefinition beanDefinition) {   //解析参数配置，用于配置自定义参数，该配置项将作为扩展点设置自定义参数使用。\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            ManagedMap parameters = null;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    if (&quot;parameter&quot;.equals(node.getNodeName())\n                            || &quot;parameter&quot;.equals(node.getLocalName())) {\n                        if (parameters == null) {\n                            parameters = new ManagedMap();\n                        }\n                        String key = ((Element) node).getAttribute(&quot;key&quot;);\n                        String value = ((Element) node).getAttribute(&quot;value&quot;);\n                        boolean hide = &quot;true&quot;.equals(((Element) node).getAttribute(&quot;hide&quot;));\n                        if (hide) {\n                            key = Constants.HIDE_KEY_PREFIX + key;\n                        }\n                        parameters.put(key, new TypedStringValue(value, String.class)); //注意parameter的值都是string类型\n                    }\n                }\n            }\n            return parameters;\n        }\n        return null;\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static void parseMethods(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n                              ParserContext parserContext) {\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            ManagedList methods = null;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    Element element = (Element) node;\n                    if (&quot;method&quot;.equals(node.getNodeName()) || &quot;method&quot;.equals(node.getLocalName())) {\n                        String methodName = element.getAttribute(&quot;name&quot;);\n                        if (methodName == null || methodName.length() == 0) {   //name为必填项，这一点在文档里也表明\n                            throw new IllegalStateException(&quot;&lt;dubbo:method&gt; name attribute == null&quot;);\n                        }\n                        if (methods == null) {\n                            methods = new ManagedList();\n                        }\n                        BeanDefinition methodBeanDefinition = parse(((Element) node),\n                                parserContext, MethodConfig.class, false);  //解析methodConfig\n                        String name = id + &quot;.&quot; + methodName;    //注意这里，方法的名称前会加上bean的id\n                        BeanDefinitionHolder methodBeanDefinitionHolder = new BeanDefinitionHolder(\n                                methodBeanDefinition, name);\n                        methods.add(methodBeanDefinitionHolder);\n                    }\n                }\n            }\n            if (methods != null) {\n                beanDefinition.getPropertyValues().addPropertyValue(&quot;methods&quot;, methods);    //关联bean和其method\n            }\n        }\n    }\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    private static void parseArguments(String id, NodeList nodeList, RootBeanDefinition beanDefinition,\n                              ParserContext parserContext) {\n        if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) {\n            ManagedList arguments = null;\n            for (int i = 0; i &lt; nodeList.getLength(); i++) {\n                Node node = nodeList.item(i);\n                if (node instanceof Element) {\n                    Element element = (Element) node;\n                    if (&quot;argument&quot;.equals(node.getNodeName()) || &quot;argument&quot;.equals(node.getLocalName())) {\n                        String argumentIndex = element.getAttribute(&quot;index&quot;);   //不清楚这里为何没有必填校验\n                        if (arguments == null) {\n                            arguments = new ManagedList();\n                        }\n                        BeanDefinition argumentBeanDefinition = parse(((Element) node),\n                                parserContext, ArgumentConfig.class, false);\n                        String name = id + &quot;.&quot; + argumentIndex;\n                        BeanDefinitionHolder argumentBeanDefinitionHolder = new BeanDefinitionHolder(\n                                argumentBeanDefinition, name);\n                        arguments.add(argumentBeanDefinitionHolder);\n                    }\n                }\n            }\n            if (arguments != null) {\n                beanDefinition.getPropertyValues().addPropertyValue(&quot;arguments&quot;, arguments);    //关联arguments和其method\n            }\n        }\n    }\n\n}\n</code></pre><p>现在，我们的dubbo就已经把配置文件中定义的bean全部解析成对应的<strong>beanDefinition</strong>，为spring的getBean做好准备工作。</p>\n<h2 id=\"beanDefinition-gt-bean\"><a href=\"#beanDefinition-gt-bean\" class=\"headerlink\" title=\"beanDefinition -&gt; bean\"></a>beanDefinition -&gt; bean</h2><p>其实也就是从beanDefinition转换成bean的过程，我在网上找了<a href=\"http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/\">一幅图</a>，可以辅助我们了解spring内部是如何初始化bean的：</p>\n<p><img src=\"http://www.ibm.com/developerworks/cn/java/j-lo-spring-principle/origin_image012.gif\" alt=\"\"></p>\n<p>这里也有一篇不错的<a href=\"http://songzi0206.iteye.com/blog/1430239#show-last-Point\">文章</a>，从代码的角度描述了spring内部是如何使用BeanDefinition生成Bean的，dubbo就是委托给spring来管理bean的生命周期的。</p>\n<p>那么dubbo自定义schemas所产生的beanDefinition，spring是如何将其转换成dubbo需要的bean呢？毕竟我们从上面的解析中看到，解析生成的beanDefinition中包含太多dubbo特殊的配置方式。这里我有两个猜测：</p>\n<ul>\n<li>dubbo在spring提供的相关扩展点上实现了自己的getBean逻辑，可我却在dubbo的源码中找不到对应实现；</li>\n<li><strong>spring解析生成的beanDefinition并没有dubbo特殊性，交给默认的BeanFactory没啥问题</strong>（这都怪我spring太差啊~）</li>\n</ul>\n<p>带着疑问我进行了严酷的单步调试，事实证明是第二种路数。到目前为止，dubbo已经按照我们提供的配置文件把所有需要的<strong>bean</strong>初始化完成，这部分基本上都是交给spring来搞定的。</p>\n<p>这还不够，我们还不知道这些bean是怎么服务于业务！</p>\n<h2 id=\"bean-gt-service\"><a href=\"#bean-gt-service\" class=\"headerlink\" title=\"bean -&gt; service\"></a>bean -&gt; service</h2><p>那么到底是哪些bean最终会被dubbo直接拿来使用呢？其实<code>DubboNamespaceHandler.init</code>中的那些就是答案。我们先看一下这些类的关系：</p>\n<p><img src=\"http://alibaba.github.io/dubbo-doc-static/dubbo-config.jpg-version=1&amp;modificationDate=1330708121000.jpg\" alt=\"\"></p>\n<p>其实这么复杂的关系最终都会被转换成字符串以<code>URL</code>的形式交给dubbo的底层最终暴露成服务。我们先来重点看一下<code>ServiceBean</code>的实现，了解一下服务提供方的细节。</p>\n<p>按照上面uml图来看，这些<strong>xxxConfig</strong>类的关系已经很清楚了（谁继承谁，谁聚合谁，谁依赖谁）。不过图里并没有出现我们的目标：<strong>ServiceBean</strong>，补充下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/En3pJXbV/NqlfS.png\" alt=\"\"></p>\n<p>除了继承父类外，我们也要注意<code>ServiceBean</code>实现的相关接口：</p>\n<pre><code>public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware \n</code></pre><p>这里我们着重看<code>InitializingBean</code>接口，该接口为spring留给开发者的一个hook，用来执行初始化bean的个性化逻辑的回调，详情可以看这篇<a href=\"http://www.cnblogs.com/zrtqsk/p/3735273.html#show-last-Point\">文章</a>。</p>\n<p>既然我们的<code>ServiceBean</code>实现了这个接口，意味着当spring进行容器初始化任务过程中，会执行我们在<code>ServiceBean.afterPropertiesSet</code>方法中安排的逻辑，这也是bean导出为服务的关键入口，先把本尊注释过的代码贴出来：</p>\n<pre><code>public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware {\n\n    private static final long serialVersionUID = 213195494150089726L;\n\n    private static transient ApplicationContext SPRING_CONTEXT;\n\n    private transient ApplicationContext applicationContext;\n\n    private transient String beanName;\n\n    private transient boolean supportedApplicationListener;\n\n    public ServiceBean() {\n        super();\n    }\n\n    public ServiceBean(Service service) {\n        super(service);\n    }\n\n    public static ApplicationContext getSpringContext() {\n        return SPRING_CONTEXT;\n    }\n\n    public void setApplicationContext(ApplicationContext applicationContext) {\n        this.applicationContext = applicationContext;\n\n        //把该应用上下文存储在SpringExtensionFactory（dubbo的SPI扩展点机制）中\n        //把原先spring通过ApplicationContext获取bean的方式封装了一下，以dubbo统一的SPI扩展点机制风格接口暴露给业务使用\n        SpringExtensionFactory.addApplicationContext(applicationContext);\n        if (applicationContext != null) {\n            SPRING_CONTEXT = applicationContext;\n            try {\n                //把所有serviceBean都加入到ApplicationContext的事件通知中\n                Method method = applicationContext.getClass().getMethod(&quot;addApplicationListener&quot;, new Class&lt;?&gt;[]{ApplicationListener.class}); // 兼容Spring2.0.1\n                method.invoke(applicationContext, new Object[] {this});\n                supportedApplicationListener = true;\n            } catch (Throwable t) {\n                if (applicationContext instanceof AbstractApplicationContext) {\n                    try {\n                        Method method = AbstractApplicationContext.class.getDeclaredMethod(&quot;addListener&quot;, new Class&lt;?&gt;[]{ApplicationListener.class}); // 兼容Spring2.0.1\n                        if (! method.isAccessible()) {\n                            method.setAccessible(true);\n                        }\n                        method.invoke(applicationContext, new Object[] {this});\n                        supportedApplicationListener = true;\n                    } catch (Throwable t2) {\n                    }\n                }\n            }\n        }\n    }\n\n    public void setBeanName(String name) {\n        this.beanName = name;\n    }\n\n    //如果配置serviceBean时声明了延迟暴露（例如：&lt;dubbo:service delay=&quot;-1&quot; /&gt;），则会依赖监听spring提供的相关事件来触发export\n    public void onApplicationEvent(ApplicationEvent event) {\n        if (ContextRefreshedEvent.class.getName().equals(event.getClass().getName())) { //监听ContextRefreshedEvent事件（容器发生初始化或更新时触发）\n            if (isDelay() &amp;&amp; ! isExported() &amp;&amp; ! isUnexported()) {  //如果已导出过或者已手工放弃导出则不会执行export逻辑\n                if (logger.isInfoEnabled()) {\n                    logger.info(&quot;The service ready on spring started. service: &quot; + getInterface());\n                }\n                export();\n            }\n        }\n    }\n\n    private boolean isDelay() {\n        Integer delay = getDelay();\n        ProviderConfig provider = getProvider();\n        if (delay == null &amp;&amp; provider != null) {    //若没有明确指定延迟，则尝试继承provider配置\n            delay = provider.getDelay();\n        }\n        return supportedApplicationListener &amp;&amp; (delay == null || delay.intValue() == -1);   //注意这里对delay值的条件很奇怪，如果我设置delay为5000毫秒时，难道不算是延迟么？请参考\\com\\alibaba\\dubbo\\config\\ServiceConfig.java的132行\n    }\n\n    @SuppressWarnings({ &quot;unchecked&quot;, &quot;deprecation&quot; })\n    public void afterPropertiesSet() throws Exception {\n        if (getProvider() == null) {    //如果当前serviceBean并没有指定provider，则下面的逻辑为其指定默认的providerConfig（如果存在的话）\n            Map&lt;String, ProviderConfig&gt; providerConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProviderConfig.class, false, false);\n            if (providerConfigMap != null &amp;&amp; providerConfigMap.size() &gt; 0) {\n                Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n                if ((protocolConfigMap == null || protocolConfigMap.size() == 0)\n                        &amp;&amp; providerConfigMap.size() &gt; 1) { // 兼容旧版本\n                    List&lt;ProviderConfig&gt; providerConfigs = new ArrayList&lt;ProviderConfig&gt;();\n                    for (ProviderConfig config : providerConfigMap.values()) {\n                        if (config.isDefault() != null &amp;&amp; config.isDefault().booleanValue()) {  //把所有指定为默认范围的providerConfig拿到，跳转到下面\n                            providerConfigs.add(config);\n                        }\n                    }\n                    if (providerConfigs.size() &gt; 0) {\n                        setProviders(providerConfigs);  //接着上面，把所有指定为默认范围的providerConfig中与protocol相关的配置封装成protocolConfig并存入serviceConfig对应属性中\n                    }\n                } else {\n                    ProviderConfig providerConfig = null;\n                    for (ProviderConfig config : providerConfigMap.values()) {\n                        //如果某个provider配置包含子node（ServiceBean），且没有明确指定default，也会被当成默认配置么？这个疑问请参看：com\\alibaba\\dubbo\\config\\spring\\schema\\DubboBeanDefinitionParser.java中330行注解\n                        if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                            if (providerConfig != null) {   //只能有一个provider设置为默认\n                                throw new IllegalStateException(&quot;Duplicate provider configs: &quot; + providerConfig + &quot; and &quot; + config);\n                            }\n                            providerConfig = config;\n                        }\n                    }\n                    if (providerConfig != null) {\n                        setProvider(providerConfig);    //为serviceBean绑定继承的providerConfig\n                    }\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Application且其继承的provider也没有指定Application，则下面的逻辑为其指定默认的applicationConfig（如果存在的话）\n        if (getApplication() == null\n                &amp;&amp; (getProvider() == null || getProvider().getApplication() == null)) {\n            Map&lt;String, ApplicationConfig&gt; applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false);\n            if (applicationConfigMap != null &amp;&amp; applicationConfigMap.size() &gt; 0) {\n                ApplicationConfig applicationConfig = null;\n                for (ApplicationConfig config : applicationConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        if (applicationConfig != null) {    //只能有一个Application设置为默认\n                            throw new IllegalStateException(&quot;Duplicate application configs: &quot; + applicationConfig + &quot; and &quot; + config);\n                        }\n                        applicationConfig = config;\n                    }\n                }\n                if (applicationConfig != null) {\n                    setApplication(applicationConfig);  //为serviceBean绑定applicationConfig\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Module且其继承的provider也没有指定Module，则下面的逻辑为其指定默认的moduleConfig（如果存在的话）\n        if (getModule() == null\n                &amp;&amp; (getProvider() == null || getProvider().getModule() == null)) {\n            Map&lt;String, ModuleConfig&gt; moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false);\n            if (moduleConfigMap != null &amp;&amp; moduleConfigMap.size() &gt; 0) {\n                ModuleConfig moduleConfig = null;\n                for (ModuleConfig config : moduleConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        if (moduleConfig != null) { //只能有一个Module设置为默认\n                            throw new IllegalStateException(&quot;Duplicate module configs: &quot; + moduleConfig + &quot; and &quot; + config);\n                        }\n                        moduleConfig = config;\n                    }\n                }\n                if (moduleConfig != null) {\n                    setModule(moduleConfig);    //为serviceBean绑定moduleConfig\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Registry且其继承的provider,application也没有指定Registry，则下面的逻辑为其指定默认的registryConfig（如果存在的话）\n        if ((getRegistries() == null || getRegistries().size() == 0)\n                &amp;&amp; (getProvider() == null || getProvider().getRegistries() == null || getProvider().getRegistries().size() == 0)\n                &amp;&amp; (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().size() == 0)) {\n            Map&lt;String, RegistryConfig&gt; registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false);\n            if (registryConfigMap != null &amp;&amp; registryConfigMap.size() &gt; 0) {\n                List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;();\n                for (RegistryConfig config : registryConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {  //允许为serviceBean指定多个Registry\n                        registryConfigs.add(config);\n                    }\n                }\n                if (registryConfigs != null &amp;&amp; registryConfigs.size() &gt; 0) {\n                    super.setRegistries(registryConfigs);\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Monitor且其继承的provider,application也没有指定Monitor，则下面的逻辑为其指定默认的monitorConfig（如果存在的话）\n        if (getMonitor() == null\n                &amp;&amp; (getProvider() == null || getProvider().getMonitor() == null)\n                &amp;&amp; (getApplication() == null || getApplication().getMonitor() == null)) {\n            Map&lt;String, MonitorConfig&gt; monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false);\n            if (monitorConfigMap != null &amp;&amp; monitorConfigMap.size() &gt; 0) {\n                MonitorConfig monitorConfig = null;\n                for (MonitorConfig config : monitorConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        if (monitorConfig != null) {    //只能有一个Monitor设置为默认\n                            throw new IllegalStateException(&quot;Duplicate monitor configs: &quot; + monitorConfig + &quot; and &quot; + config);\n                        }\n                        monitorConfig = config;\n                    }\n                }\n                if (monitorConfig != null) {\n                    setMonitor(monitorConfig);  //为serviceBean绑定monitorConfig\n                }\n            }\n        }\n        //如果当前serviceBean并没有指定Protocol且其继承的provider也没有指定Protocol，则下面的逻辑为其指定默认的protocolConfig（如果存在的话）\n        if ((getProtocols() == null || getProtocols().size() == 0)\n                &amp;&amp; (getProvider() == null || getProvider().getProtocols() == null || getProvider().getProtocols().size() == 0)) {\n            Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null  : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false);\n            if (protocolConfigMap != null &amp;&amp; protocolConfigMap.size() &gt; 0) {\n                List&lt;ProtocolConfig&gt; protocolConfigs = new ArrayList&lt;ProtocolConfig&gt;();\n                for (ProtocolConfig config : protocolConfigMap.values()) {\n                    if (config.isDefault() == null || config.isDefault().booleanValue()) {\n                        protocolConfigs.add(config);    //允许为serviceBean指定多个Protocol\n                    }\n                }\n                if (protocolConfigs != null &amp;&amp; protocolConfigs.size() &gt; 0) {\n                    super.setProtocols(protocolConfigs);\n                }\n            }\n        }\n        //设置服务路径，默认使用的是该bean在spring容器中注册的beanName，这也是该类继承BeanNameAware的原因\n        if (getPath() == null || getPath().length() == 0) {\n            if (beanName != null &amp;&amp; beanName.length() &gt; 0 \n                    &amp;&amp; getInterface() != null &amp;&amp; getInterface().length() &gt; 0\n                    &amp;&amp; beanName.startsWith(getInterface())) {\n                setPath(beanName);\n            }\n        }\n        //若不是延迟加载，就上演好戏\n        if (! isDelay()) {\n            export();\n        }\n    }\n\n    public void destroy() throws Exception {\n        unexport();\n    }\n}\n</code></pre><p>这里就明白为何ServiceBean和其父类ServiceConfig不在同一个包内，因为前者是为了适配spring而提供的适配器。ServiceBean依赖spring提供的相关hook接口完成了bean的初始化，最终<code>export</code>逻辑交给<code>ServiceConfig</code>来完成，这才是dubbo的核心服务配置类，这也解释了为何上面UML图中没有画ServiceBean的原因。</p>\n<p>我们继续跟着线索来看一下<code>ServiceConfig.export</code>：</p>\n<pre><code>public synchronized void export() {\n    //从provider中继承一些必要但没有明确设置的参数\n    if (provider != null) {\n        if (export == null) {\n            export = provider.getExport();\n        }\n        if (delay == null) {\n            delay = provider.getDelay();\n        }\n    }\n    if (export != null &amp;&amp; ! export.booleanValue()) {    //如果不需要暴露该服务，则就此结束\n        return;\n    }\n    if (delay != null &amp;&amp; delay &gt; 0) {   //如果明确指定了想要延迟的时间差，则依赖线程休眠来完成延迟暴露，delay的值只有为-1或null才依赖spring的事件机制完成延迟暴露\n        Thread thread = new Thread(new Runnable() {\n            public void run() {\n                try {\n                    Thread.sleep(delay);\n                } catch (Throwable e) {\n                }\n                doExport();\n            }\n        });\n        thread.setDaemon(true);\n        thread.setName(&quot;DelayExportServiceThread&quot;);\n        thread.start();\n    } else {\n        doExport();\n    }\n}\n</code></pre><p>一目了然，这个方法主要就是解决了到底暴露不暴露的问题，并且到底是不是延迟暴露的问题。接下来看看<code>doExport</code>方法：</p>\n<pre><code>protected synchronized void doExport() {\n    if (unexported) {\n        throw new IllegalStateException(&quot;Already unexported!&quot;);\n    }\n    if (exported) {\n        return;\n    }\n\n    exported = true;    //修改暴露状态\n\n    if (interfaceName == null || interfaceName.length() == 0) {\n        throw new IllegalStateException(&quot;&lt;dubbo:service interface=\\&quot;\\&quot; /&gt; interface not allow null!&quot;);\n    }\n\n    checkDefault(); //根据文档中提到的参数优先级，决定最终使用的配置值，在spring的xml解析阶段只是简单解析xml的配置值，在真正使用前，还需要看一下：-D和properties文件\n\n    //下面根据文档中的优先级创建对应的继承链\n    if (provider != null) { //todo 这里必然成立吧？\n        if (application == null) {\n            application = provider.getApplication();\n        }\n        if (module == null) {\n            module = provider.getModule();\n        }\n        if (registries == null) {\n            registries = provider.getRegistries();\n        }\n        if (monitor == null) {\n            monitor = provider.getMonitor();\n        }\n        if (protocols == null) {\n            protocols = provider.getProtocols();\n        }\n    }\n    if (module != null) {\n        if (registries == null) {\n            registries = module.getRegistries();\n        }\n        if (monitor == null) {\n            monitor = module.getMonitor();\n        }\n    }\n    if (application != null) {\n        if (registries == null) {\n            registries = application.getRegistries();\n        }\n        if (monitor == null) {\n            monitor = application.getMonitor();\n        }\n    }\n\n    if (ref instanceof GenericService) {    //泛接口实现方式主要用于服务器端没有API接口及模型类元的情况，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如：实现一个通用的远程服务Mock框架，可通过实现GenericService接口处理所有服务请求。\n        interfaceClass = GenericService.class;\n        if (StringUtils.isEmpty(generic)) {\n            generic = Boolean.TRUE.toString();\n        }\n    } else {\n        try {\n            interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                    .getContextClassLoader());\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        checkInterfaceAndMethods(interfaceClass, methods);  //检查接口和方法的匹配情况\n        checkRef(); //检查接口和实现的匹配情况\n        generic = Boolean.FALSE.toString();\n    }\n\n    if(local !=null){   //todo 文档中并没有与local相关的参数解释\n        if(local==&quot;true&quot;){\n            local=interfaceName+&quot;Local&quot;;\n        }\n        Class&lt;?&gt; localClass;\n        try {\n            localClass = ClassHelper.forNameWithThreadContextClassLoader(local);\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        if(!interfaceClass.isAssignableFrom(localClass)){\n            throw new IllegalStateException(&quot;The local implemention class &quot; + localClass.getName() + &quot; not implement interface &quot; + interfaceName);\n        }\n    }\n\n    //本地存根，http://alibaba.github.io/dubbo-doc-static/Stub+Proxy-zh.htm\n    if(stub !=null){\n        if(stub==&quot;true&quot;){\n            stub=interfaceName+&quot;Stub&quot;;  //todo 这里文档中的解释貌似有错误：http://alibaba.github.io/dubbo-doc-static/Service+Config-zh.htm\n        }\n        Class&lt;?&gt; stubClass;\n        try {\n            stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub);\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        if(!interfaceClass.isAssignableFrom(stubClass)){\n            throw new IllegalStateException(&quot;The stub implemention class &quot; + stubClass.getName() + &quot; not implement interface &quot; + interfaceName);\n        }\n    }\n\n    //作用雷同于上面的checkDefault()，根据文档中提到的参数优先级来选择使用的配置参数\n    checkApplication();\n    checkRegistry();\n    checkProtocol();\n    appendProperties(this);\n\n    checkStubAndMock(interfaceClass);   //检查local，stub和mock的有效性\n\n    if (path == null || path.length() == 0) {   //此时path如果还为空，这使用interfaceName\n        path = interfaceName;\n    }\n\n    doExportUrls();\n}\n</code></pre><p>木牛错，<code>doExport</code>方法依然是在做预备工作，感觉越来越靠近真像了，目前为止，我们已经按照规定的优先级最终确定了要暴露成为服务的bean的”大部分”相关配置参数，并校验了相关参数的有效性（例如：ref，method，stub，mock，path等）。再来看一下<code>doExportUrls</code>方法：</p>\n<pre><code>private void doExportUrls() {\n    List&lt;URL&gt; registryURLs = loadRegistries(true);  //获取所有的注册中心地址\n    for (ProtocolConfig protocolConfig : protocols) {\n        doExportUrlsFor1Protocol(protocolConfig, registryURLs);\n    }\n}\n</code></pre><p>好，是该真刀真枪干一架的时候了，<code>doExportUrlsFor1Protocol</code>应该就是今次的Boss，解决掉它我们就回家。</p>\n<pre><code>private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) {\n    String name = protocolConfig.getName();\n    if (name == null || name.length() == 0) {\n        name = &quot;dubbo&quot;; //N多次的检查，N多次的赋值，这算是严谨呢？还是重复？\n    }\n\n    String host = protocolConfig.getHost();\n    if (provider != null &amp;&amp; (host == null || host.length() == 0)) {\n        host = provider.getHost();\n    }\n    boolean anyhost = false;\n    if (NetUtils.isInvalidLocalHost(host)) {    //检查host是否为本地ip，或者无效的\n        anyhost = true;\n        try {\n            host = InetAddress.getLocalHost().getHostAddress();\n        } catch (UnknownHostException e) {\n            logger.warn(e.getMessage(), e);\n        }\n        if (NetUtils.isInvalidLocalHost(host)) {    //如果拿到的还是本地地址，就只能出杀手锏了\n            if (registryURLs != null &amp;&amp; registryURLs.size() &gt; 0) {\n                for (URL registryURL : registryURLs) {\n                    try {\n                        Socket socket = new Socket();\n                        try {\n                            //尝试连接注册中心，选用连接时使用的ip地址\n                            SocketAddress addr = new InetSocketAddress(registryURL.getHost(), registryURL.getPort());\n                            socket.connect(addr, 1000);\n                            host = socket.getLocalAddress().getHostAddress();\n                            break;\n                        } finally {\n                            try {\n                                socket.close();\n                            } catch (Throwable e) {}\n                        }\n                    } catch (Exception e) {\n                        logger.warn(e.getMessage(), e);\n                    }\n                }\n            }\n            if (NetUtils.isInvalidLocalHost(host)) {\n                host = NetUtils.getLocalHost(); //实在不行，就只能使用本机上第一个找到的合法ip了\n            }\n        }\n    }\n\n    Integer port = protocolConfig.getPort();\n    if (provider != null &amp;&amp; (port == null || port == 0)) {\n        port = provider.getPort();\n    }\n    final int defaultPort = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(name).getDefaultPort();\n    if (port == null || port == 0) {\n        port = defaultPort;\n    }\n    if (port == null || port &lt;= 0) {\n        port = getRandomPort(name);\n        if (port == null || port &lt; 0) {\n            port = NetUtils.getAvailablePort(defaultPort);  //到这里如果还没有拿到port，就直接随机拿个能用的端口\n            putRandomPort(name, port);  //这一步很讲究，意味着相同协议使用相同的端口，要理解这个就需要先消化dubbo底层通信方式。\n        }\n        logger.warn(&quot;Use random available port(&quot; + port + &quot;) for protocol &quot; + name);\n    }\n\n    Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();\n    if (anyhost) {\n        map.put(Constants.ANYHOST_KEY, &quot;true&quot;);\n    }\n    map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE);\n    map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion());\n    map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));\n    if (ConfigUtils.getPid() &gt; 0) {\n        map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));\n    }\n\n    //获取相关的配置参数用于后面的url生成，注意优先级顺序哟\n    appendParameters(map, application);\n    appendParameters(map, module);\n    appendParameters(map, provider, Constants.DEFAULT_KEY);\n    appendParameters(map, protocolConfig);\n    appendParameters(map, this);\n\n    if (methods != null &amp;&amp; methods.size() &gt; 0) {\n        for (MethodConfig method : methods) {\n            appendParameters(map, method, method.getName());\n\n            //处理重试设置\n            String retryKey = method.getName() + &quot;.retry&quot;;\n            if (map.containsKey(retryKey)) {\n                String retryValue = map.remove(retryKey);\n                if (&quot;false&quot;.equals(retryValue)) {\n                    map.put(method.getName() + &quot;.retries&quot;, &quot;0&quot;);\n                }\n            }\n\n            List&lt;ArgumentConfig&gt; arguments = method.getArguments();\n            if (arguments != null &amp;&amp; arguments.size() &gt; 0) {\n                for (ArgumentConfig argument : arguments) { //ArgumentConfig作用主要就是用来完成事件回调机制。\n                    //类型自动转换.\n                    if(argument.getType() != null &amp;&amp; argument.getType().length() &gt;0){\n                        Method[] methods = interfaceClass.getMethods();\n                        //遍历所有方法\n                        if(methods != null &amp;&amp; methods.length &gt; 0){\n                            for (int i = 0; i &lt; methods.length; i++) {\n                                String methodName = methods[i].getName();\n                                //匹配方法名称，获取方法签名.\n                                if(methodName.equals(method.getName())){    //注意方法重载情况\n                                    Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes();\n                                    //一个方法中单个callback\n                                    if (argument.getIndex() != -1 ){    //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                        if (argtypes[argument.getIndex()].getName().equals(argument.getType())){\n                                            appendParameters(map, argument, method.getName() + &quot;.&quot; + argument.getIndex());\n                                        }else {\n                                            throw new IllegalArgumentException(&quot;argument config error : the index attribute and type attirbute not match :index :&quot;+argument.getIndex() + &quot;, type:&quot; + argument.getType());\n                                        }\n                                    } else {\n                                        //一个方法中多个callback\n                                        for (int j = 0 ;j&lt;argtypes.length ;j++) {   //todo 这部分和文档写的有出入，不过这也不是第一次了。。\n                                            Class&lt;?&gt; argclazz = argtypes[j];\n                                            if (argclazz.getName().equals(argument.getType())){\n                                                appendParameters(map, argument, method.getName() + &quot;.&quot; + j);\n                                                if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j){\n                                                    throw new IllegalArgumentException(&quot;argument config error : the index attribute and type attirbute not match :index :&quot;+argument.getIndex() + &quot;, type:&quot; + argument.getType());\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }else if(argument.getIndex() != -1){\n                        appendParameters(map, argument, method.getName() + &quot;.&quot; + argument.getIndex());\n                    }else {\n                        throw new IllegalArgumentException(&quot;argument config must set index or type attribute.eg: &lt;dubbo:argument index=&apos;0&apos; .../&gt; or &lt;dubbo:argument type=xxx .../&gt;&quot;);\n                    }\n\n                }\n            }\n        } // end of methods for\n    }\n\n    if (ProtocolUtils.isGeneric(generic)) { //处理泛化\n        map.put(&quot;generic&quot;, generic);\n        map.put(&quot;methods&quot;, Constants.ANY_VALUE);\n    } else {\n        String revision = Version.getVersion(interfaceClass, version);\n        if (revision != null &amp;&amp; revision.length() &gt; 0) {\n            map.put(&quot;revision&quot;, revision);  //todo 为什么是revision?\n        }\n\n        String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); //todo 动态封装interfaceClass，目前不知道干啥用，猜测dubbo直接操作的都是这个封装后的wrapper\n        if(methods.length == 0) {\n            logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName());\n            map.put(&quot;methods&quot;, Constants.ANY_VALUE);\n        }\n        else {\n            map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;));\n        }\n    }\n\n    //令牌验证，为空表示不开启，如果为true，表示随机生成动态令牌，否则使用静态令牌，令牌的作用是防止消费者绕过注册中心直接访问，保证注册中心的授权功能有效，如果使用点对点调用，需关闭令牌功能\n    if (! ConfigUtils.isEmpty(token)) {\n        if (ConfigUtils.isDefault(token)) {\n            map.put(&quot;token&quot;, UUID.randomUUID().toString());\n        } else {\n            map.put(&quot;token&quot;, token);\n        }\n    }\n\n    //injvm表示不会跨进程，所以不需要注册中心\n    if (&quot;injvm&quot;.equals(protocolConfig.getName())) {\n        protocolConfig.setRegister(false);\n        map.put(&quot;notify&quot;, &quot;false&quot;);\n    }\n\n    // 导出服务\n    String contextPath = protocolConfig.getContextpath();\n    if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) {\n        contextPath = provider.getContextpath();\n    }\n    URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? &quot;&quot; : contextPath + &quot;/&quot;) + path, map);   //拿到服务的url\n\n    if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n            .hasExtension(url.getProtocol())) {\n        url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class)\n                .getExtension(url.getProtocol()).getConfigurator(url).configure(url);\n    }\n\n    String scope = url.getParameter(Constants.SCOPE_KEY);\n    //配置为none不暴露\n    if (! Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) {\n\n        //配置不是remote的情况下做本地暴露 (配置为remote，则表示只暴露远程服务)\n        if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) {\n            exportLocal(url);\n        }\n        //如果配置不是local则暴露为远程服务.(配置为local，则表示只暴露远程服务)\n        if (! Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope) ){\n            if (logger.isInfoEnabled()) {\n                logger.info(&quot;Export dubbo service &quot; + interfaceClass.getName() + &quot; to url &quot; + url);\n            }\n            if (registryURLs != null &amp;&amp; registryURLs.size() &gt; 0\n                    &amp;&amp; url.getParameter(&quot;register&quot;, true)) {\n                for (URL registryURL : registryURLs) {\n                    url = url.addParameterIfAbsent(&quot;dynamic&quot;, registryURL.getParameter(&quot;dynamic&quot;));\n                    URL monitorUrl = loadMonitor(registryURL);\n                    if (monitorUrl != null) {\n                        url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString());\n                    }\n                    if (logger.isInfoEnabled()) {\n                        logger.info(&quot;Register dubbo service &quot; + interfaceClass.getName() + &quot; url &quot; + url + &quot; to registry &quot; + registryURL);\n                    }\n                    //todo 暴露为何要封装一层代理呢？\n                    Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()));\n\n                    Exporter&lt;?&gt; exporter = protocol.export(invoker);\n                    exporters.add(exporter);\n                }\n            } else {\n                //todo 暴露为何要封装一层代理呢？\n                Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\n                Exporter&lt;?&gt; exporter = protocol.export(invoker);\n                exporters.add(exporter);\n            }\n        }\n    }\n    this.urls.add(url);\n}\n</code></pre><p>一路走来可以发现，dubbo会为每个有效协议暴露一份服务，并且会注册到所有有效的注册中心里。而bean转变为service中最重要的就是映射出来的<code>URL</code>，也就是说我们在配置文件中进行的相关配置都会映射成对应url中的相关部分，举个例子：</p>\n<pre><code>&lt;dubbo:application name=&quot;demo-provider&quot; owner=&quot;programmer&quot; organization=&quot;dubbox&quot;/&gt;\n&lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot;/&gt;\n&lt;dubbo:protocol name=&quot;dubbo&quot; serialization=&quot;kryo&quot; optimizer=&quot;com.alibaba.dubbo.demo.SerializationOptimizerImpl&quot;/&gt;\n\n&lt;bean id=&quot;bidService&quot; class=&quot;com.alibaba.dubbo.demo.bid.BidServiceImpl&quot; /&gt;\n&lt;dubbo:service interface=&quot;com.alibaba.dubbo.demo.bid.BidService&quot; ref=&quot;bidService&quot;  protocol=&quot;dubbo&quot; /&gt;\n</code></pre><p>我们通过debug看一下最终它映射出来的url是什么：</p>\n<pre><code>//exportLocal\ninjvm://127.0.0.1/com.alibaba.dubbo.demo.bid.BidService?anyhost=true&amp;application=demo-provider&amp;dubbo=2.0.0&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.bid.BidService&amp;methods=throwNPE,bid&amp;optimizer=com.alibaba.dubbo.demo.SerializationOptimizerImpl&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;serialization=kryo&amp;side=provider&amp;timestamp=1422241023451\n\n//exportRemote\nregistry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider&amp;dubbo=2.0.0&amp;export=dubbo%3A%2F%2F192.168.153.1%3A20880%2Fcom.alibaba.dubbo.demo.bid.BidService%3Fanyhost%3Dtrue%26application%3Ddemo-provider%26dubbo%3D2.0.0%26generic%3Dfalse%26interface%3Dcom.alibaba.dubbo.demo.bid.BidService%26methods%3DthrowNPE%2Cbid%26optimizer%3Dcom.alibaba.dubbo.demo.SerializationOptimizerImpl%26organization%3Ddubbox%26owner%3Dprogrammer%26pid%3D3872%26serialization%3Dkryo%26side%3Dprovider%26timestamp%3D1422241023451&amp;organization=dubbox&amp;owner=programmer&amp;pid=3872&amp;registry=zookeeper&amp;timestamp=1422240274186\n</code></pre><p>那么这个<code>url</code>的作用是什么呢？官方给出的<a href=\"http://alibaba.github.io/dubbo-doc-static/Init+Detail-zh.htm\">解释</a>很明确，这个url作为解耦的通信数据（跨层调用的参数），有了它dubbo就可以更容易做到业务逻辑实现的替换。除此之外可以看到url中还包含了大量的辅助参数（例如：timeout，version，organization等）供服务治理使用，这些都是根据真实需求一步一步补充完善的，可见，<strong>好的架构是演化而来的</strong>。</p>\n<p>可以看到贴出来的代码中包含很多todo项，其中一些问题我们从代码层面是很难找到答案的，我们需要上升到业务，运维甚至架构师高度才能消化得了，小弟将在后续的分析中慢慢的尝试解开谜团。</p>"},{"title":"dubbo协议下的单一长连接与多线程并发如何协同工作","date":"2014-09-20T07:54:30.000Z","_content":"\n上班的路上突然就冒出了这么个问题：既然在[dubbo中描述](http://alibaba.github.io/dubbo-doc-static/Dubbo+Protocol-zh.htm)消费者和提供者之间采用的是单一长连接，那么如果消费者端是高并发多线程模型的web应用，单一长连接如何解决多线程并发请求问题呢？\n<!-- more -->\n其实如果不太了解socket或者多线程编程的相关知识，不太容易理解这个问题。传统的最简单的RPC方式，应该是为每次远程调用请求创建一个对应的线程，我们先不说这种方式的缺点。至少优点很明显，就是简单。简单体现在哪儿？\n\n> 通信双方一对一（相比NIO来说）。\n\n通俗点来说，socket通信的双方发送和接受数据不会被其它（线程）干扰，这种干扰不同于数数据包的“粘包问题”。其实说白了就相当于**电话线路**的场景：\n\n> 试想一下如果多个人同时对着同一个话筒大喊，对方接受到的声音就会是重叠且杂乱的。\n\n对于单一的socket通道来说，如果发送方多线程的话，不加控制就会导致通道中的数据乱七八糟，接收端无法区分数据的单位，也就无法正确的处理请求。\n\n乍一看，似乎dubbo协议所说的单一长连接与客户端多线程并发请求之间，是水火不容的。但其实稍加设计，就可以让它们和谐相处。\n\nsocket中的粘包问题是怎么解决的？用的最多的其实是定义一个定长的数据包头，其中包含了完整数据包的长度，以此来完成服务器端拆包工作。\n\n那么解决多线程使用单一长连接并发请求时包干扰的方法也有点雷同，就是给包头中添加一个标识id，服务器端响应请求时也要携带这个id，供客户端多线程领取对应的响应数据提供线索。\n\n其实如果不考虑性能的话，dubbo完全也可以为每个客户端线程创建一个对应的服务器端线程，但这是海量高并发场景所不能接受的~~\n\n那么脑补一张图：\n\n![](http://pic.yupoo.com/kazaff_v/E38Ivr2W/jp9OS.png)\n\n下面咱们试图从代码中找到痕迹。\n\n一路追踪，我们来到这个类：`com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.java`，先来看看其中的`request`方法，大概在第101行左右：\n\n\n \tpublic ResponseFuture request(Object request, int timeout) throws RemotingException {\n        if (closed) {\n            throw new RemotingException(this.getLocalAddress(), null, \"Failed to send request \" + request + \", cause: The channel \" + this + \" is closed!\");\n        }\n        // create request.\n        Request req = new Request();\n        req.setVersion(\"2.0.0\");\n        req.setTwoWay(true);\n        req.setData(request);\n\n\t\t//这个future就是前面我们提到的：客户端并发请求线程阻塞的对象\n        DefaultFuture future = new DefaultFuture(channel, req, timeout);\n        try{\n            channel.send(req);  //非阻塞调用\n        }catch (RemotingException e) {\n            future.cancel();\n            throw e;\n        }\n        return future;\n    }\n\n注意这个方法返回的`ResponseFuture`对象，当前处理客户端请求的线程在经过一系列调用后，会拿到`ResponseFuture`对象，最终该线程会阻塞在这个对象的下面这个方法调用上，如下：\n\n\n\tpublic Object get(int timeout) throws RemotingException {\n        if (timeout <= 0) {\n            timeout = Constants.DEFAULT_TIMEOUT;\n        }\n        if (! isDone()) {\n            long start = System.currentTimeMillis();\n            lock.lock();\n            try {\n                while (! isDone()) {\t//无限连\n                    done.await(timeout, TimeUnit.MILLISECONDS);\n                    if (isDone() || System.currentTimeMillis() - start > timeout) {\n                        break;\n                    }\n                }\n            } catch (InterruptedException e) {\n                throw new RuntimeException(e);\n            } finally {\n                lock.unlock();\n            }\n            if (! isDone()) {\n                throw new TimeoutException(sent > 0, channel, getTimeoutMessage(false));\n            }\n        }\n        return returnFromResponse();\n    }\n\n上面我已经看到请求线程已经阻塞，那么又是如何被唤醒的呢？再看一下`com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.java`，其实所有实现了`ChannelHandler`接口的类都被设计为装饰器模式，所以你可以看到类似这样的代码：\n\n\t protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) {\n        return new MultiMessageHandler(\n                new HeartbeatHandler(\n                        ExtensionLoader.getExtensionLoader(Dispather.class).getAdaptiveExtension().dispath(handler, url)\n                ));\n    }\n\n现在来仔细看一下`HeaderExchangeHandler`类的定义，先看一下它定义的`received`方法，下面是代码片段：\n\n\tpublic void received(Channel channel, Object message) throws RemotingException {\n        channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis());\n        ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel);\n        try {\n            if (message instanceof Request) {\n              .....\n            } else if (message instanceof Response) {   \n\t\t\t\t//这里就是作为消费者的dubbo客户端在接收到响应后，触发通知对应等待线程的起点\n                handleResponse(channel, (Response) message);\n            } else if (message instanceof String) {\n               .....\n            } else {\n                handler.received(exchangeChannel, message);\n            }\n        } finally {\n            HeaderExchangeChannel.removeChannelIfDisconnected(channel);\n        }\n    }\n\n我们主要看中间的那个条件分支，它是用来处理响应消息的，也就是说当dubbo客户端接收到来自服务端的响应后会执行到这个分支，它简单的调用了`handleResponse`方法，我们追过去看看：\n\n\tstatic void handleResponse(Channel channel, Response response) throws RemotingException {\n        if (response != null && !response.isHeartbeat()) {  //排除心跳类型的响应\n            DefaultFuture.received(channel, response);\n        }\n    }\n\n熟悉的身影：`DefaultFuture`，它是实现了我们上面说的`ResponseFuture`接口类型，实际上细心的童鞋应该可以看到，上面`request`方法中其实实例化的就是这个`DefaultFutrue`对象：\n\n\tDefaultFuture future = new DefaultFuture(channel, req, timeout);\n\n那么我们可以继续来看一下`DefaultFuture.received`方法的实现细节：\n\n\tpublic static void received(Channel channel, Response response) {\n        try {\n            DefaultFuture future = FUTURES.remove(response.getId());\n            if (future != null) {\n                future.doReceived(response);\n            } else {\n                logger.warn(\"The timeout response finally returned at \" \n                            + (new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\").format(new Date())) \n                            + \", response \" + response \n                            + (channel == null ? \"\" : \", channel: \" + channel.getLocalAddress() \n                                + \" -> \" + channel.getRemoteAddress()));\n            }\n        } finally {\n            CHANNELS.remove(response.getId());\n        }\n    }\n\n留一下我们之前提到的**id**的作用，这里可以看到它已经开始发挥作用了。通过`id`，`DefaultFuture.FUTURES`可以拿到具体的那个`DefaultFuture`对象，它就是上面我们提到的，阻塞请求线程的那个对象。好，找到目标后，调用它的`doReceived`方法，这就是标准的java多线程编程知识了：\n\n\tprivate void doReceived(Response res) {\n        lock.lock();\n        try {\n            response = res;\n            if (done != null) {\n                done.signal();\n            }\n        } finally {\n            lock.unlock();\n        }\n        if (callback != null) {\n            invokeCallback(callback);\n        }\n    }\n\n\n这样我们就可以证实上图中左边的绿色箭头所标注的两点。\n\n---\n\n接下来我们再来看看右边绿色箭头提到的两点是如何实现的？其实dubbo在NIO的实现上默认依赖的是netty，也就是说真正在长连接两端发包和接包的苦力是netty。由于哥们我对netty不是很熟悉，所以暂时我们就直接把netty当做黑箱，只需要知道它可以很好的完成NIO通信即可。\n\n\n参考：\n\n[Dubbo基本原理机制](http://blog.csdn.net/paul_wei2008/article/details/19355681)\n\n[ALIBABA DUBBO框架同步调用原理分析](http://www.blogjava.net/xiaomage234/archive/2014/05/09/413465.html)\n\n","source":"_posts/dubbo协议下的单一长连接与多线程并发如何协同工作.md","raw":"title: dubbo协议下的单一长连接与多线程并发如何协同工作\ndate: 2014-09-20 15:54:30\ntags:\n- dubbo\n- NIO\n- 多线程\n- Netty\ncategories: j2ee\n---\n\n上班的路上突然就冒出了这么个问题：既然在[dubbo中描述](http://alibaba.github.io/dubbo-doc-static/Dubbo+Protocol-zh.htm)消费者和提供者之间采用的是单一长连接，那么如果消费者端是高并发多线程模型的web应用，单一长连接如何解决多线程并发请求问题呢？\n<!-- more -->\n其实如果不太了解socket或者多线程编程的相关知识，不太容易理解这个问题。传统的最简单的RPC方式，应该是为每次远程调用请求创建一个对应的线程，我们先不说这种方式的缺点。至少优点很明显，就是简单。简单体现在哪儿？\n\n> 通信双方一对一（相比NIO来说）。\n\n通俗点来说，socket通信的双方发送和接受数据不会被其它（线程）干扰，这种干扰不同于数数据包的“粘包问题”。其实说白了就相当于**电话线路**的场景：\n\n> 试想一下如果多个人同时对着同一个话筒大喊，对方接受到的声音就会是重叠且杂乱的。\n\n对于单一的socket通道来说，如果发送方多线程的话，不加控制就会导致通道中的数据乱七八糟，接收端无法区分数据的单位，也就无法正确的处理请求。\n\n乍一看，似乎dubbo协议所说的单一长连接与客户端多线程并发请求之间，是水火不容的。但其实稍加设计，就可以让它们和谐相处。\n\nsocket中的粘包问题是怎么解决的？用的最多的其实是定义一个定长的数据包头，其中包含了完整数据包的长度，以此来完成服务器端拆包工作。\n\n那么解决多线程使用单一长连接并发请求时包干扰的方法也有点雷同，就是给包头中添加一个标识id，服务器端响应请求时也要携带这个id，供客户端多线程领取对应的响应数据提供线索。\n\n其实如果不考虑性能的话，dubbo完全也可以为每个客户端线程创建一个对应的服务器端线程，但这是海量高并发场景所不能接受的~~\n\n那么脑补一张图：\n\n![](http://pic.yupoo.com/kazaff_v/E38Ivr2W/jp9OS.png)\n\n下面咱们试图从代码中找到痕迹。\n\n一路追踪，我们来到这个类：`com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.java`，先来看看其中的`request`方法，大概在第101行左右：\n\n\n \tpublic ResponseFuture request(Object request, int timeout) throws RemotingException {\n        if (closed) {\n            throw new RemotingException(this.getLocalAddress(), null, \"Failed to send request \" + request + \", cause: The channel \" + this + \" is closed!\");\n        }\n        // create request.\n        Request req = new Request();\n        req.setVersion(\"2.0.0\");\n        req.setTwoWay(true);\n        req.setData(request);\n\n\t\t//这个future就是前面我们提到的：客户端并发请求线程阻塞的对象\n        DefaultFuture future = new DefaultFuture(channel, req, timeout);\n        try{\n            channel.send(req);  //非阻塞调用\n        }catch (RemotingException e) {\n            future.cancel();\n            throw e;\n        }\n        return future;\n    }\n\n注意这个方法返回的`ResponseFuture`对象，当前处理客户端请求的线程在经过一系列调用后，会拿到`ResponseFuture`对象，最终该线程会阻塞在这个对象的下面这个方法调用上，如下：\n\n\n\tpublic Object get(int timeout) throws RemotingException {\n        if (timeout <= 0) {\n            timeout = Constants.DEFAULT_TIMEOUT;\n        }\n        if (! isDone()) {\n            long start = System.currentTimeMillis();\n            lock.lock();\n            try {\n                while (! isDone()) {\t//无限连\n                    done.await(timeout, TimeUnit.MILLISECONDS);\n                    if (isDone() || System.currentTimeMillis() - start > timeout) {\n                        break;\n                    }\n                }\n            } catch (InterruptedException e) {\n                throw new RuntimeException(e);\n            } finally {\n                lock.unlock();\n            }\n            if (! isDone()) {\n                throw new TimeoutException(sent > 0, channel, getTimeoutMessage(false));\n            }\n        }\n        return returnFromResponse();\n    }\n\n上面我已经看到请求线程已经阻塞，那么又是如何被唤醒的呢？再看一下`com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.java`，其实所有实现了`ChannelHandler`接口的类都被设计为装饰器模式，所以你可以看到类似这样的代码：\n\n\t protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) {\n        return new MultiMessageHandler(\n                new HeartbeatHandler(\n                        ExtensionLoader.getExtensionLoader(Dispather.class).getAdaptiveExtension().dispath(handler, url)\n                ));\n    }\n\n现在来仔细看一下`HeaderExchangeHandler`类的定义，先看一下它定义的`received`方法，下面是代码片段：\n\n\tpublic void received(Channel channel, Object message) throws RemotingException {\n        channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis());\n        ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel);\n        try {\n            if (message instanceof Request) {\n              .....\n            } else if (message instanceof Response) {   \n\t\t\t\t//这里就是作为消费者的dubbo客户端在接收到响应后，触发通知对应等待线程的起点\n                handleResponse(channel, (Response) message);\n            } else if (message instanceof String) {\n               .....\n            } else {\n                handler.received(exchangeChannel, message);\n            }\n        } finally {\n            HeaderExchangeChannel.removeChannelIfDisconnected(channel);\n        }\n    }\n\n我们主要看中间的那个条件分支，它是用来处理响应消息的，也就是说当dubbo客户端接收到来自服务端的响应后会执行到这个分支，它简单的调用了`handleResponse`方法，我们追过去看看：\n\n\tstatic void handleResponse(Channel channel, Response response) throws RemotingException {\n        if (response != null && !response.isHeartbeat()) {  //排除心跳类型的响应\n            DefaultFuture.received(channel, response);\n        }\n    }\n\n熟悉的身影：`DefaultFuture`，它是实现了我们上面说的`ResponseFuture`接口类型，实际上细心的童鞋应该可以看到，上面`request`方法中其实实例化的就是这个`DefaultFutrue`对象：\n\n\tDefaultFuture future = new DefaultFuture(channel, req, timeout);\n\n那么我们可以继续来看一下`DefaultFuture.received`方法的实现细节：\n\n\tpublic static void received(Channel channel, Response response) {\n        try {\n            DefaultFuture future = FUTURES.remove(response.getId());\n            if (future != null) {\n                future.doReceived(response);\n            } else {\n                logger.warn(\"The timeout response finally returned at \" \n                            + (new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\").format(new Date())) \n                            + \", response \" + response \n                            + (channel == null ? \"\" : \", channel: \" + channel.getLocalAddress() \n                                + \" -> \" + channel.getRemoteAddress()));\n            }\n        } finally {\n            CHANNELS.remove(response.getId());\n        }\n    }\n\n留一下我们之前提到的**id**的作用，这里可以看到它已经开始发挥作用了。通过`id`，`DefaultFuture.FUTURES`可以拿到具体的那个`DefaultFuture`对象，它就是上面我们提到的，阻塞请求线程的那个对象。好，找到目标后，调用它的`doReceived`方法，这就是标准的java多线程编程知识了：\n\n\tprivate void doReceived(Response res) {\n        lock.lock();\n        try {\n            response = res;\n            if (done != null) {\n                done.signal();\n            }\n        } finally {\n            lock.unlock();\n        }\n        if (callback != null) {\n            invokeCallback(callback);\n        }\n    }\n\n\n这样我们就可以证实上图中左边的绿色箭头所标注的两点。\n\n---\n\n接下来我们再来看看右边绿色箭头提到的两点是如何实现的？其实dubbo在NIO的实现上默认依赖的是netty，也就是说真正在长连接两端发包和接包的苦力是netty。由于哥们我对netty不是很熟悉，所以暂时我们就直接把netty当做黑箱，只需要知道它可以很好的完成NIO通信即可。\n\n\n参考：\n\n[Dubbo基本原理机制](http://blog.csdn.net/paul_wei2008/article/details/19355681)\n\n[ALIBABA DUBBO框架同步调用原理分析](http://www.blogjava.net/xiaomage234/archive/2014/05/09/413465.html)\n\n","slug":"dubbo协议下的单一长连接与多线程并发如何协同工作","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yqz00axgtfy5avtaw7h","comments":1,"layout":"post","photos":[],"link":"","content":"<p>上班的路上突然就冒出了这么个问题：既然在<a href=\"http://alibaba.github.io/dubbo-doc-static/Dubbo+Protocol-zh.htm\" target=\"_blank\" rel=\"external\">dubbo中描述</a>消费者和提供者之间采用的是单一长连接，那么如果消费者端是高并发多线程模型的web应用，单一长连接如何解决多线程并发请求问题呢？<br><a id=\"more\"></a><br>其实如果不太了解socket或者多线程编程的相关知识，不太容易理解这个问题。传统的最简单的RPC方式，应该是为每次远程调用请求创建一个对应的线程，我们先不说这种方式的缺点。至少优点很明显，就是简单。简单体现在哪儿？</p>\n<blockquote>\n<p>通信双方一对一（相比NIO来说）。</p>\n</blockquote>\n<p>通俗点来说，socket通信的双方发送和接受数据不会被其它（线程）干扰，这种干扰不同于数数据包的“粘包问题”。其实说白了就相当于<strong>电话线路</strong>的场景：</p>\n<blockquote>\n<p>试想一下如果多个人同时对着同一个话筒大喊，对方接受到的声音就会是重叠且杂乱的。</p>\n</blockquote>\n<p>对于单一的socket通道来说，如果发送方多线程的话，不加控制就会导致通道中的数据乱七八糟，接收端无法区分数据的单位，也就无法正确的处理请求。</p>\n<p>乍一看，似乎dubbo协议所说的单一长连接与客户端多线程并发请求之间，是水火不容的。但其实稍加设计，就可以让它们和谐相处。</p>\n<p>socket中的粘包问题是怎么解决的？用的最多的其实是定义一个定长的数据包头，其中包含了完整数据包的长度，以此来完成服务器端拆包工作。</p>\n<p>那么解决多线程使用单一长连接并发请求时包干扰的方法也有点雷同，就是给包头中添加一个标识id，服务器端响应请求时也要携带这个id，供客户端多线程领取对应的响应数据提供线索。</p>\n<p>其实如果不考虑性能的话，dubbo完全也可以为每个客户端线程创建一个对应的服务器端线程，但这是海量高并发场景所不能接受的~~</p>\n<p>那么脑补一张图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E38Ivr2W/jp9OS.png\" alt=\"\"></p>\n<p>下面咱们试图从代码中找到痕迹。</p>\n<p>一路追踪，我们来到这个类：<code>com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.java</code>，先来看看其中的<code>request</code>方法，大概在第101行左右：</p>\n<pre><code> public ResponseFuture request(Object request, int timeout) throws RemotingException {\n    if (closed) {\n        throw new RemotingException(this.getLocalAddress(), null, &quot;Failed to send request &quot; + request + &quot;, cause: The channel &quot; + this + &quot; is closed!&quot;);\n    }\n    // create request.\n    Request req = new Request();\n    req.setVersion(&quot;2.0.0&quot;);\n    req.setTwoWay(true);\n    req.setData(request);\n\n    //这个future就是前面我们提到的：客户端并发请求线程阻塞的对象\n    DefaultFuture future = new DefaultFuture(channel, req, timeout);\n    try{\n        channel.send(req);  //非阻塞调用\n    }catch (RemotingException e) {\n        future.cancel();\n        throw e;\n    }\n    return future;\n}\n</code></pre><p>注意这个方法返回的<code>ResponseFuture</code>对象，当前处理客户端请求的线程在经过一系列调用后，会拿到<code>ResponseFuture</code>对象，最终该线程会阻塞在这个对象的下面这个方法调用上，如下：</p>\n<pre><code>public Object get(int timeout) throws RemotingException {\n    if (timeout &lt;= 0) {\n        timeout = Constants.DEFAULT_TIMEOUT;\n    }\n    if (! isDone()) {\n        long start = System.currentTimeMillis();\n        lock.lock();\n        try {\n            while (! isDone()) {    //无限连\n                done.await(timeout, TimeUnit.MILLISECONDS);\n                if (isDone() || System.currentTimeMillis() - start &gt; timeout) {\n                    break;\n                }\n            }\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        } finally {\n            lock.unlock();\n        }\n        if (! isDone()) {\n            throw new TimeoutException(sent &gt; 0, channel, getTimeoutMessage(false));\n        }\n    }\n    return returnFromResponse();\n}\n</code></pre><p>上面我已经看到请求线程已经阻塞，那么又是如何被唤醒的呢？再看一下<code>com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.java</code>，其实所有实现了<code>ChannelHandler</code>接口的类都被设计为装饰器模式，所以你可以看到类似这样的代码：</p>\n<pre><code> protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) {\n    return new MultiMessageHandler(\n            new HeartbeatHandler(\n                    ExtensionLoader.getExtensionLoader(Dispather.class).getAdaptiveExtension().dispath(handler, url)\n            ));\n}\n</code></pre><p>现在来仔细看一下<code>HeaderExchangeHandler</code>类的定义，先看一下它定义的<code>received</code>方法，下面是代码片段：</p>\n<pre><code>public void received(Channel channel, Object message) throws RemotingException {\n    channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis());\n    ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel);\n    try {\n        if (message instanceof Request) {\n          .....\n        } else if (message instanceof Response) {   \n            //这里就是作为消费者的dubbo客户端在接收到响应后，触发通知对应等待线程的起点\n            handleResponse(channel, (Response) message);\n        } else if (message instanceof String) {\n           .....\n        } else {\n            handler.received(exchangeChannel, message);\n        }\n    } finally {\n        HeaderExchangeChannel.removeChannelIfDisconnected(channel);\n    }\n}\n</code></pre><p>我们主要看中间的那个条件分支，它是用来处理响应消息的，也就是说当dubbo客户端接收到来自服务端的响应后会执行到这个分支，它简单的调用了<code>handleResponse</code>方法，我们追过去看看：</p>\n<pre><code>static void handleResponse(Channel channel, Response response) throws RemotingException {\n    if (response != null &amp;&amp; !response.isHeartbeat()) {  //排除心跳类型的响应\n        DefaultFuture.received(channel, response);\n    }\n}\n</code></pre><p>熟悉的身影：<code>DefaultFuture</code>，它是实现了我们上面说的<code>ResponseFuture</code>接口类型，实际上细心的童鞋应该可以看到，上面<code>request</code>方法中其实实例化的就是这个<code>DefaultFutrue</code>对象：</p>\n<pre><code>DefaultFuture future = new DefaultFuture(channel, req, timeout);\n</code></pre><p>那么我们可以继续来看一下<code>DefaultFuture.received</code>方法的实现细节：</p>\n<pre><code>public static void received(Channel channel, Response response) {\n    try {\n        DefaultFuture future = FUTURES.remove(response.getId());\n        if (future != null) {\n            future.doReceived(response);\n        } else {\n            logger.warn(&quot;The timeout response finally returned at &quot; \n                        + (new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss.SSS&quot;).format(new Date())) \n                        + &quot;, response &quot; + response \n                        + (channel == null ? &quot;&quot; : &quot;, channel: &quot; + channel.getLocalAddress() \n                            + &quot; -&gt; &quot; + channel.getRemoteAddress()));\n        }\n    } finally {\n        CHANNELS.remove(response.getId());\n    }\n}\n</code></pre><p>留一下我们之前提到的<strong>id</strong>的作用，这里可以看到它已经开始发挥作用了。通过<code>id</code>，<code>DefaultFuture.FUTURES</code>可以拿到具体的那个<code>DefaultFuture</code>对象，它就是上面我们提到的，阻塞请求线程的那个对象。好，找到目标后，调用它的<code>doReceived</code>方法，这就是标准的java多线程编程知识了：</p>\n<pre><code>private void doReceived(Response res) {\n    lock.lock();\n    try {\n        response = res;\n        if (done != null) {\n            done.signal();\n        }\n    } finally {\n        lock.unlock();\n    }\n    if (callback != null) {\n        invokeCallback(callback);\n    }\n}\n</code></pre><p>这样我们就可以证实上图中左边的绿色箭头所标注的两点。</p>\n<hr>\n<p>接下来我们再来看看右边绿色箭头提到的两点是如何实现的？其实dubbo在NIO的实现上默认依赖的是netty，也就是说真正在长连接两端发包和接包的苦力是netty。由于哥们我对netty不是很熟悉，所以暂时我们就直接把netty当做黑箱，只需要知道它可以很好的完成NIO通信即可。</p>\n<p>参考：</p>\n<p><a href=\"http://blog.csdn.net/paul_wei2008/article/details/19355681\" target=\"_blank\" rel=\"external\">Dubbo基本原理机制</a></p>\n<p><a href=\"http://www.blogjava.net/xiaomage234/archive/2014/05/09/413465.html\" target=\"_blank\" rel=\"external\">ALIBABA DUBBO框架同步调用原理分析</a></p>\n","excerpt":"<p>上班的路上突然就冒出了这么个问题：既然在<a href=\"http://alibaba.github.io/dubbo-doc-static/Dubbo+Protocol-zh.htm\">dubbo中描述</a>消费者和提供者之间采用的是单一长连接，那么如果消费者端是高并发多线程模型的web应用，单一长连接如何解决多线程并发请求问题呢？<br>","more":"<br>其实如果不太了解socket或者多线程编程的相关知识，不太容易理解这个问题。传统的最简单的RPC方式，应该是为每次远程调用请求创建一个对应的线程，我们先不说这种方式的缺点。至少优点很明显，就是简单。简单体现在哪儿？</p>\n<blockquote>\n<p>通信双方一对一（相比NIO来说）。</p>\n</blockquote>\n<p>通俗点来说，socket通信的双方发送和接受数据不会被其它（线程）干扰，这种干扰不同于数数据包的“粘包问题”。其实说白了就相当于<strong>电话线路</strong>的场景：</p>\n<blockquote>\n<p>试想一下如果多个人同时对着同一个话筒大喊，对方接受到的声音就会是重叠且杂乱的。</p>\n</blockquote>\n<p>对于单一的socket通道来说，如果发送方多线程的话，不加控制就会导致通道中的数据乱七八糟，接收端无法区分数据的单位，也就无法正确的处理请求。</p>\n<p>乍一看，似乎dubbo协议所说的单一长连接与客户端多线程并发请求之间，是水火不容的。但其实稍加设计，就可以让它们和谐相处。</p>\n<p>socket中的粘包问题是怎么解决的？用的最多的其实是定义一个定长的数据包头，其中包含了完整数据包的长度，以此来完成服务器端拆包工作。</p>\n<p>那么解决多线程使用单一长连接并发请求时包干扰的方法也有点雷同，就是给包头中添加一个标识id，服务器端响应请求时也要携带这个id，供客户端多线程领取对应的响应数据提供线索。</p>\n<p>其实如果不考虑性能的话，dubbo完全也可以为每个客户端线程创建一个对应的服务器端线程，但这是海量高并发场景所不能接受的~~</p>\n<p>那么脑补一张图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff_v/E38Ivr2W/jp9OS.png\" alt=\"\"></p>\n<p>下面咱们试图从代码中找到痕迹。</p>\n<p>一路追踪，我们来到这个类：<code>com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.java</code>，先来看看其中的<code>request</code>方法，大概在第101行左右：</p>\n<pre><code> public ResponseFuture request(Object request, int timeout) throws RemotingException {\n    if (closed) {\n        throw new RemotingException(this.getLocalAddress(), null, &quot;Failed to send request &quot; + request + &quot;, cause: The channel &quot; + this + &quot; is closed!&quot;);\n    }\n    // create request.\n    Request req = new Request();\n    req.setVersion(&quot;2.0.0&quot;);\n    req.setTwoWay(true);\n    req.setData(request);\n\n    //这个future就是前面我们提到的：客户端并发请求线程阻塞的对象\n    DefaultFuture future = new DefaultFuture(channel, req, timeout);\n    try{\n        channel.send(req);  //非阻塞调用\n    }catch (RemotingException e) {\n        future.cancel();\n        throw e;\n    }\n    return future;\n}\n</code></pre><p>注意这个方法返回的<code>ResponseFuture</code>对象，当前处理客户端请求的线程在经过一系列调用后，会拿到<code>ResponseFuture</code>对象，最终该线程会阻塞在这个对象的下面这个方法调用上，如下：</p>\n<pre><code>public Object get(int timeout) throws RemotingException {\n    if (timeout &lt;= 0) {\n        timeout = Constants.DEFAULT_TIMEOUT;\n    }\n    if (! isDone()) {\n        long start = System.currentTimeMillis();\n        lock.lock();\n        try {\n            while (! isDone()) {    //无限连\n                done.await(timeout, TimeUnit.MILLISECONDS);\n                if (isDone() || System.currentTimeMillis() - start &gt; timeout) {\n                    break;\n                }\n            }\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        } finally {\n            lock.unlock();\n        }\n        if (! isDone()) {\n            throw new TimeoutException(sent &gt; 0, channel, getTimeoutMessage(false));\n        }\n    }\n    return returnFromResponse();\n}\n</code></pre><p>上面我已经看到请求线程已经阻塞，那么又是如何被唤醒的呢？再看一下<code>com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.java</code>，其实所有实现了<code>ChannelHandler</code>接口的类都被设计为装饰器模式，所以你可以看到类似这样的代码：</p>\n<pre><code> protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) {\n    return new MultiMessageHandler(\n            new HeartbeatHandler(\n                    ExtensionLoader.getExtensionLoader(Dispather.class).getAdaptiveExtension().dispath(handler, url)\n            ));\n}\n</code></pre><p>现在来仔细看一下<code>HeaderExchangeHandler</code>类的定义，先看一下它定义的<code>received</code>方法，下面是代码片段：</p>\n<pre><code>public void received(Channel channel, Object message) throws RemotingException {\n    channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis());\n    ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel);\n    try {\n        if (message instanceof Request) {\n          .....\n        } else if (message instanceof Response) {   \n            //这里就是作为消费者的dubbo客户端在接收到响应后，触发通知对应等待线程的起点\n            handleResponse(channel, (Response) message);\n        } else if (message instanceof String) {\n           .....\n        } else {\n            handler.received(exchangeChannel, message);\n        }\n    } finally {\n        HeaderExchangeChannel.removeChannelIfDisconnected(channel);\n    }\n}\n</code></pre><p>我们主要看中间的那个条件分支，它是用来处理响应消息的，也就是说当dubbo客户端接收到来自服务端的响应后会执行到这个分支，它简单的调用了<code>handleResponse</code>方法，我们追过去看看：</p>\n<pre><code>static void handleResponse(Channel channel, Response response) throws RemotingException {\n    if (response != null &amp;&amp; !response.isHeartbeat()) {  //排除心跳类型的响应\n        DefaultFuture.received(channel, response);\n    }\n}\n</code></pre><p>熟悉的身影：<code>DefaultFuture</code>，它是实现了我们上面说的<code>ResponseFuture</code>接口类型，实际上细心的童鞋应该可以看到，上面<code>request</code>方法中其实实例化的就是这个<code>DefaultFutrue</code>对象：</p>\n<pre><code>DefaultFuture future = new DefaultFuture(channel, req, timeout);\n</code></pre><p>那么我们可以继续来看一下<code>DefaultFuture.received</code>方法的实现细节：</p>\n<pre><code>public static void received(Channel channel, Response response) {\n    try {\n        DefaultFuture future = FUTURES.remove(response.getId());\n        if (future != null) {\n            future.doReceived(response);\n        } else {\n            logger.warn(&quot;The timeout response finally returned at &quot; \n                        + (new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss.SSS&quot;).format(new Date())) \n                        + &quot;, response &quot; + response \n                        + (channel == null ? &quot;&quot; : &quot;, channel: &quot; + channel.getLocalAddress() \n                            + &quot; -&gt; &quot; + channel.getRemoteAddress()));\n        }\n    } finally {\n        CHANNELS.remove(response.getId());\n    }\n}\n</code></pre><p>留一下我们之前提到的<strong>id</strong>的作用，这里可以看到它已经开始发挥作用了。通过<code>id</code>，<code>DefaultFuture.FUTURES</code>可以拿到具体的那个<code>DefaultFuture</code>对象，它就是上面我们提到的，阻塞请求线程的那个对象。好，找到目标后，调用它的<code>doReceived</code>方法，这就是标准的java多线程编程知识了：</p>\n<pre><code>private void doReceived(Response res) {\n    lock.lock();\n    try {\n        response = res;\n        if (done != null) {\n            done.signal();\n        }\n    } finally {\n        lock.unlock();\n    }\n    if (callback != null) {\n        invokeCallback(callback);\n    }\n}\n</code></pre><p>这样我们就可以证实上图中左边的绿色箭头所标注的两点。</p>\n<hr>\n<p>接下来我们再来看看右边绿色箭头提到的两点是如何实现的？其实dubbo在NIO的实现上默认依赖的是netty，也就是说真正在长连接两端发包和接包的苦力是netty。由于哥们我对netty不是很熟悉，所以暂时我们就直接把netty当做黑箱，只需要知道它可以很好的完成NIO通信即可。</p>\n<p>参考：</p>\n<p><a href=\"http://blog.csdn.net/paul_wei2008/article/details/19355681\">Dubbo基本原理机制</a></p>\n<p><a href=\"http://www.blogjava.net/xiaomage234/archive/2014/05/09/413465.html\">ALIBABA DUBBO框架同步调用原理分析</a></p>"},{"title":"dubbo的服务暴露细节","date":"2015-01-27T02:54:30.000Z","_content":"\n\n[前一篇](http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/)文章只是分析了一下从xml到service的代码流程细节，从中我们发现了一些架构层面的设计，小弟我非常的在意。所以我们这次在原先的基础上再深挖一点，看看能否出油。\n\n<!-- more -->\n\n这篇文字里会出现大量本尊的瞎掰（其实每篇都挺能瞎掰的），希望大家多多提醒，打脸什么的我丫根本就不怕。\n\n服务接口类型的Wrapper处理\n---\n\n在ServiceConfig.java中的doExportUrlsFor1Protocol方法中，我们看到，在得到最终URL之前，会执行下面的代码逻辑：\n\n\tString[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();\n    if(methods.length == 0) {\n        logger.warn(\"NO method found in service interface \" + interfaceClass.getName());\n        map.put(\"methods\", Constants.ANY_VALUE);\n    }\n    else {\n        map.put(\"methods\", StringUtils.join(new HashSet<String>(Arrays.asList(methods)), \",\"));\n    }\n\n那么这个`Wrapper.getWrapper()`的作用是什么呢？从代码层面来看，它按照dubbo自身的需求完成了类似java反射的工作，无非就是**根据给定的服务实现接口类型，按照dubbo的要求提供读取该类型的相关类型信息的方法**，有些绕口。这么做，可以让dubbo更自由的控制获取类型信息的相关操作，同时也一定程度的统一了调用方式。举个例子，wrapper后的对象可以在其他业务调时有效的屏蔽那些不希望被感知的原类型数据信息，对应设计模式的“[适配器模式](http://blog.chinaunix.net/uid-22283027-id-3488042.html)”。\n\n除此之外，`Wrapper`还提供了对象缓存池的概念来提升性能：\n\n\tWrapper ret = WRAPPER_MAP.get(c);\n    if( ret == null )\n    {\n        ret = makeWrapper(c);\n        WRAPPER_MAP.put(c,ret);\n    }\n    return ret;\n\n至于还有没有其他更深层次的作用，期待您的补充。\n\n\n暴露前的proxy处理\n---\n\n回顾之前提过的bean转service过程，我们当时提到了`url`，它作为不同层之间通信的keyword起到了重要的作用，但仅仅有key是不够的，**如何通过key找到实际提供服务的bean才是本质**。\n\ndubbo的[Invoker](http://alibaba.github.io/dubbo-doc-static/RPC+Detail-zh.htm)模型是非常关键的概念，看下图：\n\n![](http://pic.yupoo.com/kazaff/Eo4DsJLe/10mLOC.png)\n\n图中可以很清楚的看到`url`，`ref`，`interface`，`ProxyFactory`，`Protocol`和`Invoker`之间的关系，代码上来看，就是下面这两行：\n\n\t......\n\tInvoker<?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\n    Exporter<?> exporter = protocol.export(invoker);\n\t......\n\n\n看似简单的两次调用之中，其实执行了非常多的逻辑。我们先来看一下这里`proxyFactory`对象是怎么拿到的（在`ServiceConfig`中声明了该静态属性）：\n\n\tprivate static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\n\n对，没错，扩展点加载规则。不过较为麻烦的是从`ProxyFactory`接口中只能看出其使用的默认扩展点为\"javassist\"，可代码中却指定使用的是自适应扩展点，看一下配置文件中定义了什么：\n\n\tstub=com.alibaba.dubbo.rpc.proxy.wrapper.StubProxyFactoryWrapper\n\tjdk=com.alibaba.dubbo.rpc.proxy.jdk.JdkProxyFactory\n\tjavassist=com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory\n\n依次查阅这三个类的源码，并没有发现自适应扩展点的痕迹，也就是说最终dubbo会动态创建一个自适应扩展点类，这里作为外行新手，需要吐槽一下，**dubbo中大量的动态类生产方式采用的是字符串拼接源码方式**，这给代码审阅带来了非常大的困难，我相信即便是项目开发人员很难一次就写正确所有的逻辑。\n\n不过幸好，我们有聪明的[IDE](http://www.jetbrains.com/products.html)，在辅助工具的帮助下，我们可以还原出dubbo针对ProxyFactory所动态创建的自适应扩展点类的完整代码：\n\n\tpackage com.alibaba.dubbo.rpc;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\n\tpublic class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory {\n\t\n\t\tpublic java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n\t\t\tif (arg0 == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\");\n\t\n\t\t\tif (arg0.getUrl() == null)\n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = url.getParameter(\"proxy\", \"javassist\");\n\t\t\tif(extName == null)\n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\t\t\t\n\t\t\treturn extension.getProxy(arg0);\n\t\t}\n\t\n\t\tpublic com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object {\n\t\t\tif (arg2 == null)\n\t\t\t\tthrow new IllegalArgumentException(\"url == null\");\n\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg2;\n\t\t\tString extName = url.getParameter(\"proxy\", \"javassist\");\n\t\t\tif(extName == null)\n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\");\n\t\n\t\t\tcom.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\t\n\t\t\treturn extension.getInvoker(arg0, arg1, arg2);\n\t\t}\n\t}\n\n最终我们可以看出，dubbo会默认调用`com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory`作为proxyFactory的实际逻辑：\n\n\t public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {\n        // TODO Wrapper类不能正确处理带$的类名\n        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);\n        return new AbstractProxyInvoker<T>(proxy, type, url) {\n            @Override\n            protected Object doInvoke(T proxy, String methodName, \n                                      Class<?>[] parameterTypes, \n                                      Object[] arguments) throws Throwable {\n                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);\n            }\n        };\n    }\n\n哇塞，一下子就通透了。之所以命名为`JavassistProxyFactory`，就是因为它使用的是前面提到的`Wrapper`实例。逻辑很简单，直接完成了Invoker实例的创建，我们前面说了，Invoker是个很关键的概念，它的一个抽象定义如下：\n\n\tpublic abstract class AbstractProxyInvoker<T> implements Invoker<T> {\n    \n\t    private final T proxy;\n\t    \n\t    private final Class<T> type;\n\t    \n\t    private final URL url;\n\t\n\t    public AbstractProxyInvoker(T proxy, Class<T> type, URL url){\n\t        if (proxy == null) {\n\t            throw new IllegalArgumentException(\"proxy == null\");\n\t        }\n\t        if (type == null) {\n\t            throw new IllegalArgumentException(\"interface == null\");\n\t        }\n\t        if (! type.isInstance(proxy)) {\n\t            throw new IllegalArgumentException(proxy.getClass().getName() + \" not implement interface \" + type);\n\t        }\n\t        this.proxy = proxy;\n\t        this.type = type;\n\t        this.url = url;\n\t    }\n\t\n\t    public Class<T> getInterface() {\n\t        return type;\n\t    }\n\t\n\t    public URL getUrl() {\n\t        return url;\n\t    }\n\t\n\t    public boolean isAvailable() {\n\t        return true;\n\t    }\n\t\n\t    public void destroy() {\n\t    }\n\t\n\t    public Result invoke(Invocation invocation) throws RpcException {\n\t        try {\n\t            return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()));\n\t        } catch (InvocationTargetException e) {\n\t            return new RpcResult(e.getTargetException());\n\t        } catch (Throwable e) {\n\t            throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e);\n\t        }\n\t    }\n\t    \n\t    protected abstract Object doInvoke(T proxy, String methodName, Class<?>[] parameterTypes, Object[] arguments) throws Throwable;\n\t\n\t    @Override\n\t    public String toString() {\n\t        return getInterface() + \" -> \" + getUrl()==null?\" \":getUrl().toString();\n\t    }\n\t}\n\n\n也挺简单的，值得关注的是`invoke`方法，该方法是Invoker真正可以被其他对象调用的方法，逻辑也很简单，主要注意它的参数和返回值类型。\n\n目前为止，我们已经完成了Invoker的转换，剩下的就是暴露服务的底层实现了。\n\n\n服务暴露的底层实现\n---\n\n老规矩，为了更好的理解代码意图，我们利用IDE把dubbo动态创建的protocol自适应扩展点类的代码还原：\n\n\tpackage com.alibaba.dubbo.rpc;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\t\n\tpublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\t\t\n\t\tpublic int getDefaultPort() {\n\t\t\tthrow new UnsupportedOperationException(\"method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!\");\n\t\t}\n\t\t\n\t\tpublic void destroy() {\n\t\t\tthrow new UnsupportedOperationException(\"method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!\");\n\t\t}\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n\t\t\tif (arg0 == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\");\n\t\t\t\n\t\t\tif (arg0.getUrl() == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\n\t\t\t\n\t\t\tif(extName == null) \n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\t\t\t\n\t\t\treturn extension.export(arg0);\n\t\t}\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n\t\t\tif (arg1 == null)\n\t\t\t\tthrow new IllegalArgumentException(\"url == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg1;\n\t\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\n\t\t\t\n\t\t\tif(extName == null) \n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\t\t\t\n\t\t\treturn extension.refer(arg0, arg1);\n\t\t}\n\t}\n\n目前我们主要关注`export`方法，可以看出这个自适应扩展点的逻辑也很简单，从url中找出适配的协议参数，并获取指定协议的扩展点实现，并调用其`export`方法，一气呵成。\n\n我们主要分析默认协议`dubbo`，所以接下来要分析的是`DubboProtocol.java`：\n\n\tpublic <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {\n        URL url = invoker.getUrl(); //拿到url，可见url的重要性\n        \n        // export service.\n        String key = serviceKey(url);   //根据url中的设置拿到能够唯一标识该exporter的key\n        DubboExporter<T> exporter = new DubboExporter<T>(invoker, key, exporterMap);    //其实export只是简单的在invoker上封装了一层，提供了更“语义”的接口\n        exporterMap.put(key, exporter);\n        \n        //export an stub service for dispaching event\n        Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT);\n        Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false);\n        if (isStubSupportEvent && !isCallbackservice){\n            String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY);\n            if (stubServiceMethods == null || stubServiceMethods.length() == 0 ){\n                if (logger.isWarnEnabled()){\n                    logger.warn(new IllegalStateException(\"consumer [\" +url.getParameter(Constants.INTERFACE_KEY) +\n                            \"], has set stubproxy support event ,but no stub methods founded.\"));\n                }\n            } else {\n                stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods);\n            }\n        }\n\n        openServer(url);    //根据url中定义的相关参数（协议，host，port等）创建服务，默认使用的是netty\n\n        // modified by lishen\n        optimizeSerialization(url);\n\n        return exporter;\n    }\n\n其实`exporter`从代码层面来看只是对invoker封装了一层调用接口而已，并没有做其他什么转化操作，当然可以利用这一层封装来完成一些自定义逻辑，例如`DubboExporter`只是做了一层缓存处理。\n\n到目前为止，我们可以知道，每个serviceConfig实例会根据配置中定义的注册中心和协议最终得到多个exporter实例。当有调用过来时，dubbo会通过请求消息中的相关信息来确定调用的exporter，并最终调用其封装的invoker的invoke方法完成业务逻辑。\n\n更多的细节，推荐看一下之前发的这篇文章：[dubbo协议下的单一长连接与多线程并发如何协同工作](http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/)\n\n不打算继续挖下去了，因为打算另起一篇专门聊dubbo中使用netty的文章。那就先瞎扯到这里吧，希望大牛能对上面的错误之处能够无情的给予打击。","source":"_posts/dubbo中服务暴露的细节.md","raw":"title: dubbo的服务暴露细节\ndate: 2015-01-27 10:54:30\ntags:\n- dubbo\n- dubbox\n\ncategories: j2ee\n---\n\n\n[前一篇](http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/)文章只是分析了一下从xml到service的代码流程细节，从中我们发现了一些架构层面的设计，小弟我非常的在意。所以我们这次在原先的基础上再深挖一点，看看能否出油。\n\n<!-- more -->\n\n这篇文字里会出现大量本尊的瞎掰（其实每篇都挺能瞎掰的），希望大家多多提醒，打脸什么的我丫根本就不怕。\n\n服务接口类型的Wrapper处理\n---\n\n在ServiceConfig.java中的doExportUrlsFor1Protocol方法中，我们看到，在得到最终URL之前，会执行下面的代码逻辑：\n\n\tString[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();\n    if(methods.length == 0) {\n        logger.warn(\"NO method found in service interface \" + interfaceClass.getName());\n        map.put(\"methods\", Constants.ANY_VALUE);\n    }\n    else {\n        map.put(\"methods\", StringUtils.join(new HashSet<String>(Arrays.asList(methods)), \",\"));\n    }\n\n那么这个`Wrapper.getWrapper()`的作用是什么呢？从代码层面来看，它按照dubbo自身的需求完成了类似java反射的工作，无非就是**根据给定的服务实现接口类型，按照dubbo的要求提供读取该类型的相关类型信息的方法**，有些绕口。这么做，可以让dubbo更自由的控制获取类型信息的相关操作，同时也一定程度的统一了调用方式。举个例子，wrapper后的对象可以在其他业务调时有效的屏蔽那些不希望被感知的原类型数据信息，对应设计模式的“[适配器模式](http://blog.chinaunix.net/uid-22283027-id-3488042.html)”。\n\n除此之外，`Wrapper`还提供了对象缓存池的概念来提升性能：\n\n\tWrapper ret = WRAPPER_MAP.get(c);\n    if( ret == null )\n    {\n        ret = makeWrapper(c);\n        WRAPPER_MAP.put(c,ret);\n    }\n    return ret;\n\n至于还有没有其他更深层次的作用，期待您的补充。\n\n\n暴露前的proxy处理\n---\n\n回顾之前提过的bean转service过程，我们当时提到了`url`，它作为不同层之间通信的keyword起到了重要的作用，但仅仅有key是不够的，**如何通过key找到实际提供服务的bean才是本质**。\n\ndubbo的[Invoker](http://alibaba.github.io/dubbo-doc-static/RPC+Detail-zh.htm)模型是非常关键的概念，看下图：\n\n![](http://pic.yupoo.com/kazaff/Eo4DsJLe/10mLOC.png)\n\n图中可以很清楚的看到`url`，`ref`，`interface`，`ProxyFactory`，`Protocol`和`Invoker`之间的关系，代码上来看，就是下面这两行：\n\n\t......\n\tInvoker<?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\n    Exporter<?> exporter = protocol.export(invoker);\n\t......\n\n\n看似简单的两次调用之中，其实执行了非常多的逻辑。我们先来看一下这里`proxyFactory`对象是怎么拿到的（在`ServiceConfig`中声明了该静态属性）：\n\n\tprivate static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\n\n对，没错，扩展点加载规则。不过较为麻烦的是从`ProxyFactory`接口中只能看出其使用的默认扩展点为\"javassist\"，可代码中却指定使用的是自适应扩展点，看一下配置文件中定义了什么：\n\n\tstub=com.alibaba.dubbo.rpc.proxy.wrapper.StubProxyFactoryWrapper\n\tjdk=com.alibaba.dubbo.rpc.proxy.jdk.JdkProxyFactory\n\tjavassist=com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory\n\n依次查阅这三个类的源码，并没有发现自适应扩展点的痕迹，也就是说最终dubbo会动态创建一个自适应扩展点类，这里作为外行新手，需要吐槽一下，**dubbo中大量的动态类生产方式采用的是字符串拼接源码方式**，这给代码审阅带来了非常大的困难，我相信即便是项目开发人员很难一次就写正确所有的逻辑。\n\n不过幸好，我们有聪明的[IDE](http://www.jetbrains.com/products.html)，在辅助工具的帮助下，我们可以还原出dubbo针对ProxyFactory所动态创建的自适应扩展点类的完整代码：\n\n\tpackage com.alibaba.dubbo.rpc;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\n\tpublic class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory {\n\t\n\t\tpublic java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n\t\t\tif (arg0 == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\");\n\t\n\t\t\tif (arg0.getUrl() == null)\n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = url.getParameter(\"proxy\", \"javassist\");\n\t\t\tif(extName == null)\n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\t\t\t\n\t\t\treturn extension.getProxy(arg0);\n\t\t}\n\t\n\t\tpublic com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object {\n\t\t\tif (arg2 == null)\n\t\t\t\tthrow new IllegalArgumentException(\"url == null\");\n\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg2;\n\t\t\tString extName = url.getParameter(\"proxy\", \"javassist\");\n\t\t\tif(extName == null)\n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\");\n\t\n\t\t\tcom.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\t\n\t\t\treturn extension.getInvoker(arg0, arg1, arg2);\n\t\t}\n\t}\n\n最终我们可以看出，dubbo会默认调用`com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory`作为proxyFactory的实际逻辑：\n\n\t public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {\n        // TODO Wrapper类不能正确处理带$的类名\n        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);\n        return new AbstractProxyInvoker<T>(proxy, type, url) {\n            @Override\n            protected Object doInvoke(T proxy, String methodName, \n                                      Class<?>[] parameterTypes, \n                                      Object[] arguments) throws Throwable {\n                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);\n            }\n        };\n    }\n\n哇塞，一下子就通透了。之所以命名为`JavassistProxyFactory`，就是因为它使用的是前面提到的`Wrapper`实例。逻辑很简单，直接完成了Invoker实例的创建，我们前面说了，Invoker是个很关键的概念，它的一个抽象定义如下：\n\n\tpublic abstract class AbstractProxyInvoker<T> implements Invoker<T> {\n    \n\t    private final T proxy;\n\t    \n\t    private final Class<T> type;\n\t    \n\t    private final URL url;\n\t\n\t    public AbstractProxyInvoker(T proxy, Class<T> type, URL url){\n\t        if (proxy == null) {\n\t            throw new IllegalArgumentException(\"proxy == null\");\n\t        }\n\t        if (type == null) {\n\t            throw new IllegalArgumentException(\"interface == null\");\n\t        }\n\t        if (! type.isInstance(proxy)) {\n\t            throw new IllegalArgumentException(proxy.getClass().getName() + \" not implement interface \" + type);\n\t        }\n\t        this.proxy = proxy;\n\t        this.type = type;\n\t        this.url = url;\n\t    }\n\t\n\t    public Class<T> getInterface() {\n\t        return type;\n\t    }\n\t\n\t    public URL getUrl() {\n\t        return url;\n\t    }\n\t\n\t    public boolean isAvailable() {\n\t        return true;\n\t    }\n\t\n\t    public void destroy() {\n\t    }\n\t\n\t    public Result invoke(Invocation invocation) throws RpcException {\n\t        try {\n\t            return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()));\n\t        } catch (InvocationTargetException e) {\n\t            return new RpcResult(e.getTargetException());\n\t        } catch (Throwable e) {\n\t            throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e);\n\t        }\n\t    }\n\t    \n\t    protected abstract Object doInvoke(T proxy, String methodName, Class<?>[] parameterTypes, Object[] arguments) throws Throwable;\n\t\n\t    @Override\n\t    public String toString() {\n\t        return getInterface() + \" -> \" + getUrl()==null?\" \":getUrl().toString();\n\t    }\n\t}\n\n\n也挺简单的，值得关注的是`invoke`方法，该方法是Invoker真正可以被其他对象调用的方法，逻辑也很简单，主要注意它的参数和返回值类型。\n\n目前为止，我们已经完成了Invoker的转换，剩下的就是暴露服务的底层实现了。\n\n\n服务暴露的底层实现\n---\n\n老规矩，为了更好的理解代码意图，我们利用IDE把dubbo动态创建的protocol自适应扩展点类的代码还原：\n\n\tpackage com.alibaba.dubbo.rpc;\n\timport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\t\n\tpublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\t\t\n\t\tpublic int getDefaultPort() {\n\t\t\tthrow new UnsupportedOperationException(\"method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!\");\n\t\t}\n\t\t\n\t\tpublic void destroy() {\n\t\t\tthrow new UnsupportedOperationException(\"method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!\");\n\t\t}\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n\t\t\tif (arg0 == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\");\n\t\t\t\n\t\t\tif (arg0.getUrl() == null) \n\t\t\t\tthrow new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg0.getUrl();\n\t\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\n\t\t\t\n\t\t\tif(extName == null) \n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\t\t\t\n\t\t\treturn extension.export(arg0);\n\t\t}\n\t\t\n\t\tpublic com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n\t\t\tif (arg1 == null)\n\t\t\t\tthrow new IllegalArgumentException(\"url == null\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.common.URL url = arg1;\n\t\t\tString extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() );\n\t\t\t\n\t\t\tif(extName == null) \n\t\t\t\tthrow new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\");\n\t\t\t\n\t\t\tcom.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\t\t\t\n\t\t\treturn extension.refer(arg0, arg1);\n\t\t}\n\t}\n\n目前我们主要关注`export`方法，可以看出这个自适应扩展点的逻辑也很简单，从url中找出适配的协议参数，并获取指定协议的扩展点实现，并调用其`export`方法，一气呵成。\n\n我们主要分析默认协议`dubbo`，所以接下来要分析的是`DubboProtocol.java`：\n\n\tpublic <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {\n        URL url = invoker.getUrl(); //拿到url，可见url的重要性\n        \n        // export service.\n        String key = serviceKey(url);   //根据url中的设置拿到能够唯一标识该exporter的key\n        DubboExporter<T> exporter = new DubboExporter<T>(invoker, key, exporterMap);    //其实export只是简单的在invoker上封装了一层，提供了更“语义”的接口\n        exporterMap.put(key, exporter);\n        \n        //export an stub service for dispaching event\n        Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT);\n        Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false);\n        if (isStubSupportEvent && !isCallbackservice){\n            String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY);\n            if (stubServiceMethods == null || stubServiceMethods.length() == 0 ){\n                if (logger.isWarnEnabled()){\n                    logger.warn(new IllegalStateException(\"consumer [\" +url.getParameter(Constants.INTERFACE_KEY) +\n                            \"], has set stubproxy support event ,but no stub methods founded.\"));\n                }\n            } else {\n                stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods);\n            }\n        }\n\n        openServer(url);    //根据url中定义的相关参数（协议，host，port等）创建服务，默认使用的是netty\n\n        // modified by lishen\n        optimizeSerialization(url);\n\n        return exporter;\n    }\n\n其实`exporter`从代码层面来看只是对invoker封装了一层调用接口而已，并没有做其他什么转化操作，当然可以利用这一层封装来完成一些自定义逻辑，例如`DubboExporter`只是做了一层缓存处理。\n\n到目前为止，我们可以知道，每个serviceConfig实例会根据配置中定义的注册中心和协议最终得到多个exporter实例。当有调用过来时，dubbo会通过请求消息中的相关信息来确定调用的exporter，并最终调用其封装的invoker的invoke方法完成业务逻辑。\n\n更多的细节，推荐看一下之前发的这篇文章：[dubbo协议下的单一长连接与多线程并发如何协同工作](http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/)\n\n不打算继续挖下去了，因为打算另起一篇专门聊dubbo中使用netty的文章。那就先瞎扯到这里吧，希望大牛能对上面的错误之处能够无情的给予打击。","slug":"dubbo中服务暴露的细节","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yr300b6gtfyus3puwdg","comments":1,"layout":"post","photos":[],"link":"","content":"<p><a href=\"http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/\">前一篇</a>文章只是分析了一下从xml到service的代码流程细节，从中我们发现了一些架构层面的设计，小弟我非常的在意。所以我们这次在原先的基础上再深挖一点，看看能否出油。</p>\n<a id=\"more\"></a>\n<p>这篇文字里会出现大量本尊的瞎掰（其实每篇都挺能瞎掰的），希望大家多多提醒，打脸什么的我丫根本就不怕。</p>\n<h2 id=\"服务接口类型的Wrapper处理\"><a href=\"#服务接口类型的Wrapper处理\" class=\"headerlink\" title=\"服务接口类型的Wrapper处理\"></a>服务接口类型的Wrapper处理</h2><p>在ServiceConfig.java中的doExportUrlsFor1Protocol方法中，我们看到，在得到最终URL之前，会执行下面的代码逻辑：</p>\n<pre><code>String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();\nif(methods.length == 0) {\n    logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName());\n    map.put(&quot;methods&quot;, Constants.ANY_VALUE);\n}\nelse {\n    map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;));\n}\n</code></pre><p>那么这个<code>Wrapper.getWrapper()</code>的作用是什么呢？从代码层面来看，它按照dubbo自身的需求完成了类似java反射的工作，无非就是<strong>根据给定的服务实现接口类型，按照dubbo的要求提供读取该类型的相关类型信息的方法</strong>，有些绕口。这么做，可以让dubbo更自由的控制获取类型信息的相关操作，同时也一定程度的统一了调用方式。举个例子，wrapper后的对象可以在其他业务调时有效的屏蔽那些不希望被感知的原类型数据信息，对应设计模式的“<a href=\"http://blog.chinaunix.net/uid-22283027-id-3488042.html\" target=\"_blank\" rel=\"external\">适配器模式</a>”。</p>\n<p>除此之外，<code>Wrapper</code>还提供了对象缓存池的概念来提升性能：</p>\n<pre><code>Wrapper ret = WRAPPER_MAP.get(c);\nif( ret == null )\n{\n    ret = makeWrapper(c);\n    WRAPPER_MAP.put(c,ret);\n}\nreturn ret;\n</code></pre><p>至于还有没有其他更深层次的作用，期待您的补充。</p>\n<h2 id=\"暴露前的proxy处理\"><a href=\"#暴露前的proxy处理\" class=\"headerlink\" title=\"暴露前的proxy处理\"></a>暴露前的proxy处理</h2><p>回顾之前提过的bean转service过程，我们当时提到了<code>url</code>，它作为不同层之间通信的keyword起到了重要的作用，但仅仅有key是不够的，<strong>如何通过key找到实际提供服务的bean才是本质</strong>。</p>\n<p>dubbo的<a href=\"http://alibaba.github.io/dubbo-doc-static/RPC+Detail-zh.htm\" target=\"_blank\" rel=\"external\">Invoker</a>模型是非常关键的概念，看下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Eo4DsJLe/10mLOC.png\" alt=\"\"></p>\n<p>图中可以很清楚的看到<code>url</code>，<code>ref</code>，<code>interface</code>，<code>ProxyFactory</code>，<code>Protocol</code>和<code>Invoker</code>之间的关系，代码上来看，就是下面这两行：</p>\n<pre><code>......\nInvoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\nExporter&lt;?&gt; exporter = protocol.export(invoker);\n......\n</code></pre><p>看似简单的两次调用之中，其实执行了非常多的逻辑。我们先来看一下这里<code>proxyFactory</code>对象是怎么拿到的（在<code>ServiceConfig</code>中声明了该静态属性）：</p>\n<pre><code>private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\n</code></pre><p>对，没错，扩展点加载规则。不过较为麻烦的是从<code>ProxyFactory</code>接口中只能看出其使用的默认扩展点为”javassist”，可代码中却指定使用的是自适应扩展点，看一下配置文件中定义了什么：</p>\n<pre><code>stub=com.alibaba.dubbo.rpc.proxy.wrapper.StubProxyFactoryWrapper\njdk=com.alibaba.dubbo.rpc.proxy.jdk.JdkProxyFactory\njavassist=com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory\n</code></pre><p>依次查阅这三个类的源码，并没有发现自适应扩展点的痕迹，也就是说最终dubbo会动态创建一个自适应扩展点类，这里作为外行新手，需要吐槽一下，<strong>dubbo中大量的动态类生产方式采用的是字符串拼接源码方式</strong>，这给代码审阅带来了非常大的困难，我相信即便是项目开发人员很难一次就写正确所有的逻辑。</p>\n<p>不过幸好，我们有聪明的<a href=\"http://www.jetbrains.com/products.html\" target=\"_blank\" rel=\"external\">IDE</a>，在辅助工具的帮助下，我们可以还原出dubbo针对ProxyFactory所动态创建的自适应扩展点类的完整代码：</p>\n<pre><code>package com.alibaba.dubbo.rpc;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory {\n\n    public java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n        if (arg0 == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;);\n\n        if (arg0.getUrl() == null)\n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;);\n        if(extName == null)\n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;);\n\n        com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\n        return extension.getProxy(arg0);\n    }\n\n    public com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object {\n        if (arg2 == null)\n            throw new IllegalArgumentException(&quot;url == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg2;\n        String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;);\n        if(extName == null)\n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;);\n\n        com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\n        return extension.getInvoker(arg0, arg1, arg2);\n    }\n}\n</code></pre><p>最终我们可以看出，dubbo会默认调用<code>com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory</code>作为proxyFactory的实际逻辑：</p>\n<pre><code> public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) {\n    // TODO Wrapper类不能正确处理带$的类名\n    final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&apos;$&apos;) &lt; 0 ? proxy.getClass() : type);\n    return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) {\n        @Override\n        protected Object doInvoke(T proxy, String methodName, \n                                  Class&lt;?&gt;[] parameterTypes, \n                                  Object[] arguments) throws Throwable {\n            return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);\n        }\n    };\n}\n</code></pre><p>哇塞，一下子就通透了。之所以命名为<code>JavassistProxyFactory</code>，就是因为它使用的是前面提到的<code>Wrapper</code>实例。逻辑很简单，直接完成了Invoker实例的创建，我们前面说了，Invoker是个很关键的概念，它的一个抽象定义如下：</p>\n<pre><code>public abstract class AbstractProxyInvoker&lt;T&gt; implements Invoker&lt;T&gt; {\n\n    private final T proxy;\n\n    private final Class&lt;T&gt; type;\n\n    private final URL url;\n\n    public AbstractProxyInvoker(T proxy, Class&lt;T&gt; type, URL url){\n        if (proxy == null) {\n            throw new IllegalArgumentException(&quot;proxy == null&quot;);\n        }\n        if (type == null) {\n            throw new IllegalArgumentException(&quot;interface == null&quot;);\n        }\n        if (! type.isInstance(proxy)) {\n            throw new IllegalArgumentException(proxy.getClass().getName() + &quot; not implement interface &quot; + type);\n        }\n        this.proxy = proxy;\n        this.type = type;\n        this.url = url;\n    }\n\n    public Class&lt;T&gt; getInterface() {\n        return type;\n    }\n\n    public URL getUrl() {\n        return url;\n    }\n\n    public boolean isAvailable() {\n        return true;\n    }\n\n    public void destroy() {\n    }\n\n    public Result invoke(Invocation invocation) throws RpcException {\n        try {\n            return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()));\n        } catch (InvocationTargetException e) {\n            return new RpcResult(e.getTargetException());\n        } catch (Throwable e) {\n            throw new RpcException(&quot;Failed to invoke remote proxy method &quot; + invocation.getMethodName() + &quot; to &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e);\n        }\n    }\n\n    protected abstract Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable;\n\n    @Override\n    public String toString() {\n        return getInterface() + &quot; -&gt; &quot; + getUrl()==null?&quot; &quot;:getUrl().toString();\n    }\n}\n</code></pre><p>也挺简单的，值得关注的是<code>invoke</code>方法，该方法是Invoker真正可以被其他对象调用的方法，逻辑也很简单，主要注意它的参数和返回值类型。</p>\n<p>目前为止，我们已经完成了Invoker的转换，剩下的就是暴露服务的底层实现了。</p>\n<h2 id=\"服务暴露的底层实现\"><a href=\"#服务暴露的底层实现\" class=\"headerlink\" title=\"服务暴露的底层实现\"></a>服务暴露的底层实现</h2><p>老规矩，为了更好的理解代码意图，我们利用IDE把dubbo动态创建的protocol自适应扩展点类的代码还原：</p>\n<pre><code>package com.alibaba.dubbo.rpc;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\n    public int getDefaultPort() {\n        throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;);\n    }\n\n    public void destroy() {\n        throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;);\n    }\n\n    public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n        if (arg0 == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;);\n\n        if (arg0.getUrl() == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );\n\n        if(extName == null) \n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n        com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\n        return extension.export(arg0);\n    }\n\n    public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n        if (arg1 == null)\n            throw new IllegalArgumentException(&quot;url == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg1;\n        String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );\n\n        if(extName == null) \n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n        com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\n        return extension.refer(arg0, arg1);\n    }\n}\n</code></pre><p>目前我们主要关注<code>export</code>方法，可以看出这个自适应扩展点的逻辑也很简单，从url中找出适配的协议参数，并获取指定协议的扩展点实现，并调用其<code>export</code>方法，一气呵成。</p>\n<p>我们主要分析默认协议<code>dubbo</code>，所以接下来要分析的是<code>DubboProtocol.java</code>：</p>\n<pre><code>public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException {\n    URL url = invoker.getUrl(); //拿到url，可见url的重要性\n\n    // export service.\n    String key = serviceKey(url);   //根据url中的设置拿到能够唯一标识该exporter的key\n    DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap);    //其实export只是简单的在invoker上封装了一层，提供了更“语义”的接口\n    exporterMap.put(key, exporter);\n\n    //export an stub service for dispaching event\n    Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT);\n    Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false);\n    if (isStubSupportEvent &amp;&amp; !isCallbackservice){\n        String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY);\n        if (stubServiceMethods == null || stubServiceMethods.length() == 0 ){\n            if (logger.isWarnEnabled()){\n                logger.warn(new IllegalStateException(&quot;consumer [&quot; +url.getParameter(Constants.INTERFACE_KEY) +\n                        &quot;], has set stubproxy support event ,but no stub methods founded.&quot;));\n            }\n        } else {\n            stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods);\n        }\n    }\n\n    openServer(url);    //根据url中定义的相关参数（协议，host，port等）创建服务，默认使用的是netty\n\n    // modified by lishen\n    optimizeSerialization(url);\n\n    return exporter;\n}\n</code></pre><p>其实<code>exporter</code>从代码层面来看只是对invoker封装了一层调用接口而已，并没有做其他什么转化操作，当然可以利用这一层封装来完成一些自定义逻辑，例如<code>DubboExporter</code>只是做了一层缓存处理。</p>\n<p>到目前为止，我们可以知道，每个serviceConfig实例会根据配置中定义的注册中心和协议最终得到多个exporter实例。当有调用过来时，dubbo会通过请求消息中的相关信息来确定调用的exporter，并最终调用其封装的invoker的invoke方法完成业务逻辑。</p>\n<p>更多的细节，推荐看一下之前发的这篇文章：<a href=\"http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/\">dubbo协议下的单一长连接与多线程并发如何协同工作</a></p>\n<p>不打算继续挖下去了，因为打算另起一篇专门聊dubbo中使用netty的文章。那就先瞎扯到这里吧，希望大牛能对上面的错误之处能够无情的给予打击。</p>\n","excerpt":"<p><a href=\"http://blog.kazaff.me/2015/01/26/dubbo%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%8B%BF%E5%88%B0bean/\">前一篇</a>文章只是分析了一下从xml到service的代码流程细节，从中我们发现了一些架构层面的设计，小弟我非常的在意。所以我们这次在原先的基础上再深挖一点，看看能否出油。</p>","more":"<p>这篇文字里会出现大量本尊的瞎掰（其实每篇都挺能瞎掰的），希望大家多多提醒，打脸什么的我丫根本就不怕。</p>\n<h2 id=\"服务接口类型的Wrapper处理\"><a href=\"#服务接口类型的Wrapper处理\" class=\"headerlink\" title=\"服务接口类型的Wrapper处理\"></a>服务接口类型的Wrapper处理</h2><p>在ServiceConfig.java中的doExportUrlsFor1Protocol方法中，我们看到，在得到最终URL之前，会执行下面的代码逻辑：</p>\n<pre><code>String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();\nif(methods.length == 0) {\n    logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName());\n    map.put(&quot;methods&quot;, Constants.ANY_VALUE);\n}\nelse {\n    map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;));\n}\n</code></pre><p>那么这个<code>Wrapper.getWrapper()</code>的作用是什么呢？从代码层面来看，它按照dubbo自身的需求完成了类似java反射的工作，无非就是<strong>根据给定的服务实现接口类型，按照dubbo的要求提供读取该类型的相关类型信息的方法</strong>，有些绕口。这么做，可以让dubbo更自由的控制获取类型信息的相关操作，同时也一定程度的统一了调用方式。举个例子，wrapper后的对象可以在其他业务调时有效的屏蔽那些不希望被感知的原类型数据信息，对应设计模式的“<a href=\"http://blog.chinaunix.net/uid-22283027-id-3488042.html\">适配器模式</a>”。</p>\n<p>除此之外，<code>Wrapper</code>还提供了对象缓存池的概念来提升性能：</p>\n<pre><code>Wrapper ret = WRAPPER_MAP.get(c);\nif( ret == null )\n{\n    ret = makeWrapper(c);\n    WRAPPER_MAP.put(c,ret);\n}\nreturn ret;\n</code></pre><p>至于还有没有其他更深层次的作用，期待您的补充。</p>\n<h2 id=\"暴露前的proxy处理\"><a href=\"#暴露前的proxy处理\" class=\"headerlink\" title=\"暴露前的proxy处理\"></a>暴露前的proxy处理</h2><p>回顾之前提过的bean转service过程，我们当时提到了<code>url</code>，它作为不同层之间通信的keyword起到了重要的作用，但仅仅有key是不够的，<strong>如何通过key找到实际提供服务的bean才是本质</strong>。</p>\n<p>dubbo的<a href=\"http://alibaba.github.io/dubbo-doc-static/RPC+Detail-zh.htm\">Invoker</a>模型是非常关键的概念，看下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Eo4DsJLe/10mLOC.png\" alt=\"\"></p>\n<p>图中可以很清楚的看到<code>url</code>，<code>ref</code>，<code>interface</code>，<code>ProxyFactory</code>，<code>Protocol</code>和<code>Invoker</code>之间的关系，代码上来看，就是下面这两行：</p>\n<pre><code>......\nInvoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url);\n\nExporter&lt;?&gt; exporter = protocol.export(invoker);\n......\n</code></pre><p>看似简单的两次调用之中，其实执行了非常多的逻辑。我们先来看一下这里<code>proxyFactory</code>对象是怎么拿到的（在<code>ServiceConfig</code>中声明了该静态属性）：</p>\n<pre><code>private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\n</code></pre><p>对，没错，扩展点加载规则。不过较为麻烦的是从<code>ProxyFactory</code>接口中只能看出其使用的默认扩展点为”javassist”，可代码中却指定使用的是自适应扩展点，看一下配置文件中定义了什么：</p>\n<pre><code>stub=com.alibaba.dubbo.rpc.proxy.wrapper.StubProxyFactoryWrapper\njdk=com.alibaba.dubbo.rpc.proxy.jdk.JdkProxyFactory\njavassist=com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory\n</code></pre><p>依次查阅这三个类的源码，并没有发现自适应扩展点的痕迹，也就是说最终dubbo会动态创建一个自适应扩展点类，这里作为外行新手，需要吐槽一下，<strong>dubbo中大量的动态类生产方式采用的是字符串拼接源码方式</strong>，这给代码审阅带来了非常大的困难，我相信即便是项目开发人员很难一次就写正确所有的逻辑。</p>\n<p>不过幸好，我们有聪明的<a href=\"http://www.jetbrains.com/products.html\">IDE</a>，在辅助工具的帮助下，我们可以还原出dubbo针对ProxyFactory所动态创建的自适应扩展点类的完整代码：</p>\n<pre><code>package com.alibaba.dubbo.rpc;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory {\n\n    public java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n        if (arg0 == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;);\n\n        if (arg0.getUrl() == null)\n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;);\n        if(extName == null)\n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;);\n\n        com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\n        return extension.getProxy(arg0);\n    }\n\n    public com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object {\n        if (arg2 == null)\n            throw new IllegalArgumentException(&quot;url == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg2;\n        String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;);\n        if(extName == null)\n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;);\n\n        com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName);\n\n        return extension.getInvoker(arg0, arg1, arg2);\n    }\n}\n</code></pre><p>最终我们可以看出，dubbo会默认调用<code>com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory</code>作为proxyFactory的实际逻辑：</p>\n<pre><code> public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) {\n    // TODO Wrapper类不能正确处理带$的类名\n    final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&apos;$&apos;) &lt; 0 ? proxy.getClass() : type);\n    return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) {\n        @Override\n        protected Object doInvoke(T proxy, String methodName, \n                                  Class&lt;?&gt;[] parameterTypes, \n                                  Object[] arguments) throws Throwable {\n            return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);\n        }\n    };\n}\n</code></pre><p>哇塞，一下子就通透了。之所以命名为<code>JavassistProxyFactory</code>，就是因为它使用的是前面提到的<code>Wrapper</code>实例。逻辑很简单，直接完成了Invoker实例的创建，我们前面说了，Invoker是个很关键的概念，它的一个抽象定义如下：</p>\n<pre><code>public abstract class AbstractProxyInvoker&lt;T&gt; implements Invoker&lt;T&gt; {\n\n    private final T proxy;\n\n    private final Class&lt;T&gt; type;\n\n    private final URL url;\n\n    public AbstractProxyInvoker(T proxy, Class&lt;T&gt; type, URL url){\n        if (proxy == null) {\n            throw new IllegalArgumentException(&quot;proxy == null&quot;);\n        }\n        if (type == null) {\n            throw new IllegalArgumentException(&quot;interface == null&quot;);\n        }\n        if (! type.isInstance(proxy)) {\n            throw new IllegalArgumentException(proxy.getClass().getName() + &quot; not implement interface &quot; + type);\n        }\n        this.proxy = proxy;\n        this.type = type;\n        this.url = url;\n    }\n\n    public Class&lt;T&gt; getInterface() {\n        return type;\n    }\n\n    public URL getUrl() {\n        return url;\n    }\n\n    public boolean isAvailable() {\n        return true;\n    }\n\n    public void destroy() {\n    }\n\n    public Result invoke(Invocation invocation) throws RpcException {\n        try {\n            return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()));\n        } catch (InvocationTargetException e) {\n            return new RpcResult(e.getTargetException());\n        } catch (Throwable e) {\n            throw new RpcException(&quot;Failed to invoke remote proxy method &quot; + invocation.getMethodName() + &quot; to &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e);\n        }\n    }\n\n    protected abstract Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable;\n\n    @Override\n    public String toString() {\n        return getInterface() + &quot; -&gt; &quot; + getUrl()==null?&quot; &quot;:getUrl().toString();\n    }\n}\n</code></pre><p>也挺简单的，值得关注的是<code>invoke</code>方法，该方法是Invoker真正可以被其他对象调用的方法，逻辑也很简单，主要注意它的参数和返回值类型。</p>\n<p>目前为止，我们已经完成了Invoker的转换，剩下的就是暴露服务的底层实现了。</p>\n<h2 id=\"服务暴露的底层实现\"><a href=\"#服务暴露的底层实现\" class=\"headerlink\" title=\"服务暴露的底层实现\"></a>服务暴露的底层实现</h2><p>老规矩，为了更好的理解代码意图，我们利用IDE把dubbo动态创建的protocol自适应扩展点类的代码还原：</p>\n<pre><code>package com.alibaba.dubbo.rpc;\nimport com.alibaba.dubbo.common.extension.ExtensionLoader;\n\npublic class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol {\n\n    public int getDefaultPort() {\n        throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;);\n    }\n\n    public void destroy() {\n        throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;);\n    }\n\n    public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker {\n        if (arg0 == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;);\n\n        if (arg0.getUrl() == null) \n            throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg0.getUrl();\n        String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );\n\n        if(extName == null) \n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n        com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\n        return extension.export(arg0);\n    }\n\n    public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class {\n        if (arg1 == null)\n            throw new IllegalArgumentException(&quot;url == null&quot;);\n\n        com.alibaba.dubbo.common.URL url = arg1;\n        String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() );\n\n        if(extName == null) \n            throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;);\n\n        com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName);\n\n        return extension.refer(arg0, arg1);\n    }\n}\n</code></pre><p>目前我们主要关注<code>export</code>方法，可以看出这个自适应扩展点的逻辑也很简单，从url中找出适配的协议参数，并获取指定协议的扩展点实现，并调用其<code>export</code>方法，一气呵成。</p>\n<p>我们主要分析默认协议<code>dubbo</code>，所以接下来要分析的是<code>DubboProtocol.java</code>：</p>\n<pre><code>public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException {\n    URL url = invoker.getUrl(); //拿到url，可见url的重要性\n\n    // export service.\n    String key = serviceKey(url);   //根据url中的设置拿到能够唯一标识该exporter的key\n    DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap);    //其实export只是简单的在invoker上封装了一层，提供了更“语义”的接口\n    exporterMap.put(key, exporter);\n\n    //export an stub service for dispaching event\n    Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT);\n    Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false);\n    if (isStubSupportEvent &amp;&amp; !isCallbackservice){\n        String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY);\n        if (stubServiceMethods == null || stubServiceMethods.length() == 0 ){\n            if (logger.isWarnEnabled()){\n                logger.warn(new IllegalStateException(&quot;consumer [&quot; +url.getParameter(Constants.INTERFACE_KEY) +\n                        &quot;], has set stubproxy support event ,but no stub methods founded.&quot;));\n            }\n        } else {\n            stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods);\n        }\n    }\n\n    openServer(url);    //根据url中定义的相关参数（协议，host，port等）创建服务，默认使用的是netty\n\n    // modified by lishen\n    optimizeSerialization(url);\n\n    return exporter;\n}\n</code></pre><p>其实<code>exporter</code>从代码层面来看只是对invoker封装了一层调用接口而已，并没有做其他什么转化操作，当然可以利用这一层封装来完成一些自定义逻辑，例如<code>DubboExporter</code>只是做了一层缓存处理。</p>\n<p>到目前为止，我们可以知道，每个serviceConfig实例会根据配置中定义的注册中心和协议最终得到多个exporter实例。当有调用过来时，dubbo会通过请求消息中的相关信息来确定调用的exporter，并最终调用其封装的invoker的invoke方法完成业务逻辑。</p>\n<p>更多的细节，推荐看一下之前发的这篇文章：<a href=\"http://blog.kazaff.me/2014/09/20/dubbo%E5%8D%8F%E8%AE%AE%E4%B8%8B%E7%9A%84%E5%8D%95%E4%B8%80%E9%95%BF%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%A6%82%E4%BD%95%E5%8D%8F%E5%90%8C%E5%B7%A5%E4%BD%9C/\">dubbo协议下的单一长连接与多线程并发如何协同工作</a></p>\n<p>不打算继续挖下去了，因为打算另起一篇专门聊dubbo中使用netty的文章。那就先瞎扯到这里吧，希望大牛能对上面的错误之处能够无情的给予打击。</p>"},{"title":"dubbo中SPI的基础--Cooma微容器","date":"2015-01-15T07:54:30.000Z","_content":"\n\n断断续续研究[dubbo](http://alibaba.github.io/dubbo-doc-static/Home-zh.htm)其实有一段时间了，总是搁浅的原因和工作安排有很大关系，不过我始终保持着学习它的兴趣。随着[dubbox](http://dangdangdotcom.github.io/dubbox/)项目的更新，我决定再一次尝试学习这个项目。\n<!-- more -->\n之前把玩的时候自己甚至连一本完整的javaEE资料都没有看完过，虽然现在也还是入门级新手，不过在其他项目中的工作也让我有了比之前更多的积累，应该可以看得更透一些。\n\n从哪里开始呢？我个人认为应该从dubbo的SPI理念开始，由于dubbo的项目Leader一开始就把其定义成一个方便扩展的服务框架，所以在dubbo的架构设计中始终保持了良好的依赖扩展机制：**微内核+插件**。简而言之就是让扩展者可以和项目开发者拥有一样的灵活度，这也是dubbo得以迅速流行的一个必要条件。\n\n要想实现这种自由度，除了在架构分层组件上要保持高内聚低耦合外，底层也需要一套强大的类管理工具。在javaEE世界里，把这份工作做到极致的也已经有成熟的标准规范：OSGi。不过OSGi并不完全适配dubbo的需求，而且这玩意儿也有些过于重了，所以在此基础上，dubbo结合JDK标准的SPI机制设计出来一个轻量级的实现：[Cooma](https://github.com/alibaba/cooma/wiki)。\n\n这篇文章，我就打算从Cooma说起，官方介绍的已经非常详细了，不过它在从dubbo独立出来发布之前是做过修改优化的，在dubbo项目中使用时可能会存在些许的不同，我们就从dubbo内部来研读这部分实现的代码，并结合dubbo中的上下文来了解一下dubbo是如何使用SPI的。\n\n我们把目标定位在dubbo的这个包上：\n\n> com.alibaba.dubbo.common.extension\n\n看一下这个包的目录结构：\n\n\tcom.alibaba.dubbo.common.extension\n\t |\n\t |--factory\n\t |     |--AdaptiveExtensionFactory   #稍后解释\n\t |     |--SpiExtensionFactory        #稍后解释\n\t |\n\t |--support\n\t |     |--ActivateComparator\n\t |\n\t |--Activate  #自动激活加载扩展的注解\n\t |--Adaptive  #自适应扩展点的注解\n\t |--ExtensionFactory  #扩展点对象生成工厂接口\n\t |--ExtensionLoader   #扩展点加载器，扩展点的查找，校验，加载等核心逻辑的实现类\n\t |--SPI   #扩展点注解\n\n我们通过对照dubbo如何使用扩展点机制来完成扩展点工厂实例的选择与加载来了解一下扩展点实现的细节，这句话很拗口，有点递归的味道，我们不妨直接从代码中来理解：\n\n\tpublic class ExtensionLoader<T> {\n\t\t...\n\t\tprivate static final ConcurrentMap<Class<?>, ExtensionLoader<?>> EXTENSION_LOADERS = new ConcurrentHashMap<Class<?>, ExtensionLoader<?>>();\n\t\tprivate final Class<?> type;\t\t\n\t\t...\n\t\t@SuppressWarnings(\"unchecked\")\n\t    public static <T> ExtensionLoader<T> getExtensionLoader(Class<T> type) {\n\t        if (type == null)\n\t            throw new IllegalArgumentException(\"Extension type == null\");\n\t        if(!type.isInterface()) {\n\t            throw new IllegalArgumentException(\"Extension type(\" + type + \") is not interface!\");\n\t        }\n\t        if(!withExtensionAnnotation(type)) {\n\t            throw new IllegalArgumentException(\"Extension type(\" + type + \n\t                    \") is not extension, because WITHOUT @\" + SPI.class.getSimpleName() + \" Annotation!\");\n\t        }\n\t        \n\t        ExtensionLoader<T> loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);\n\t        if (loader == null) {\n\t            EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader<T>(type));\n\t            loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);\n\t        }\n\t        return loader;\n\t    }\n\t\n\t    private ExtensionLoader(Class<?> type) {\n\t        this.type = type;\n\t        objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());\n\t    }\t\t\n\t\t...\n\t}\n\n我们主要看`ExtensionLoader`构造方法，其中它初始化了`type`和`objectFactory`，前者为要作为扩展点的接口类型，后者表示要如何获取指定名称的扩展点实例（工厂类），目前dubbo提供了2个实现类，上面在包结构图上已经标注过了。\n\n\t@SuppressWarnings(\"unchecked\")\n    public T getAdaptiveExtension() {\n        Object instance = cachedAdaptiveInstance.get();\n        if (instance == null) {\n            if(createAdaptiveInstanceError == null) {\n                synchronized (cachedAdaptiveInstance) {\n                    instance = cachedAdaptiveInstance.get();\n                    if (instance == null) {\n                        try {\n                            instance = createAdaptiveExtension();\n                            cachedAdaptiveInstance.set(instance);\n                        } catch (Throwable t) {\n                            createAdaptiveInstanceError = t;\n                            throw new IllegalStateException(\"fail to create adaptive instance: \" + t.toString(), t);\n                        }\n                    }\n                }\n            }\n            else {\n                throw new IllegalStateException(\"fail to create adaptive instance: \" + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError);\n            }\n        }\n\n        return (T) instance;\n    }\n\n上面这个方法是用来获取自适应扩展类实例的，但其实它只是封装了一层缓存而已，真正完成创建实例的是`createAdaptiveExtension`方法。由于调用关系太深，请看下面的图：\n\n![](http://pic.yupoo.com/kazaff/Elc1xnHk/7eCGH.png)\n\n上图中给出的路径，缺少了查找扩展点实现的细节，也就是并没有展开`getExtensionClasses`方法，该方法会根据指定位置的配置文件扫描并解析拿到所有可用的扩展点实现，代码如下：\n\n\tprivate Map<String, Class<?>> getExtensionClasses() {\n        Map<String, Class<?>> classes = cachedClasses.get();\n        if (classes == null) {\n            synchronized (cachedClasses) {\n                classes = cachedClasses.get();\n                if (classes == null) {\n                    classes = loadExtensionClasses();\n                    cachedClasses.set(classes);\n                }\n            }\n        }\n        return classes;\n\t}\n\n可见它也只是封装了一层缓存而已，我们继续深挖`loadExtensionClasses`方法：\n\n\t// 此方法已经getExtensionClasses方法同步过。\n    private Map<String, Class<?>> loadExtensionClasses() {\n\t\t//检查并获取该接口类型声明的默认扩展点实现\n        final SPI defaultAnnotation = type.getAnnotation(SPI.class);\n        if(defaultAnnotation != null) {\n            String value = defaultAnnotation.value();\n            if(value != null && (value = value.trim()).length() > 0) {\n                String[] names = NAME_SEPARATOR.split(value);\n                if(names.length > 1) {\n                    throw new IllegalStateException(\"more than 1 default extension name on extension \" + type.getName()\n                            + \": \" + Arrays.toString(names));\n                }\n                if(names.length == 1) cachedDefaultName = names[0];\n            }\n        }\n        \n\t\t//去三个指定的位置查找配置文件并解析拿到扩展点键值映射关系\n        Map<String, Class<?>> extensionClasses = new HashMap<String, Class<?>>();\n        loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY);\n        loadFile(extensionClasses, DUBBO_DIRECTORY);\n        loadFile(extensionClasses, SERVICES_DIRECTORY);\n\n        return extensionClasses;\n    }\n\n我们先来看一下配置文件的格式：\n\n\tadaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactory\n\tspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactory\n\n`loadFile`方法会从指定位置（`META-INF/dubbo/internal/`）根据指定接口类型（`type`）为文件名称查找目标配置文件，然后解析并校验，最终拿到匹配的扩展点类的所有`Class`实例。对应上面给出的配置文件，也就是`AdaptiveExtensionFactory`和`SpiExtensionFactory`，它们已经在包结构图上提到过了。\n\n现在我们来着重看一下这两个类，它们到底是做什么用的呢？首先，`AdaptiveExtensionFactory`定义上有`@Adaptive`注解标识，很明显，它就是自适应扩展点的实现，从`loadFile`方法中可以留意到：**同一个接口类型只能存在一个自适应扩展点实现**：\n\n\t@Adaptive\n\tpublic class AdaptiveExtensionFactory implements ExtensionFactory {\n\t    \n    \tprivate final List<ExtensionFactory> factories;\n    \n\t    public AdaptiveExtensionFactory() {\n\t        ExtensionLoader<ExtensionFactory> loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class);\n\t        List<ExtensionFactory> list = new ArrayList<ExtensionFactory>();\n\t        for (String name : loader.getSupportedExtensions()) {\n\t            list.add(loader.getExtension(name));\n\t        }\n\t        factories = Collections.unmodifiableList(list);\n\t    }\n\n\t    //从这个方法定义来看，这个自适应扩展点实现类并没有做任何事儿，唯一的工作就是把真正获取扩展点实例的逻辑依次交给\n\t    //框架中声明的所有ExtensionFactory扩展点实例，默认也就是SpiExtensionFactory\n\t    public <T> T getExtension(Class<T> type, String name) {\n\t        for (ExtensionFactory factory : factories) {\n\t            T extension = factory.getExtension(type, name);\n\t            if (extension != null) {\n\t                return extension;\n\t            }\n\t        }\n\t        return null;\n\t    }\n\t}\n\n可以看到，`AdaptiveExtensionFactory`把逻辑委托给`SpiExtensionFactory`来做，而后者又是怎么做的呢：\n\n\tpublic class SpiExtensionFactory implements ExtensionFactory {\n\n\t    public <T> T getExtension(Class<T> type, String name) {\n\t        if (type.isInterface() && type.isAnnotationPresent(SPI.class)) {\n\t            ExtensionLoader<T> loader = ExtensionLoader.getExtensionLoader(type);\n\t            if (loader.getSupportedExtensions().size() > 0) {\n\t\t\t\t\t//获取自适应扩展点实例，这是dubbo默认的行为，\n\t\t\t\t\t//也可以自己写一个ExtensionFactory来按照要求加载扩展点\n\t                return loader.getAdaptiveExtension();   \n\t            }\n\t        }\n\t        return null;\n\t    }\n\t}\n\n而`objectFactory`（真实工作的也就是`SpiExtensionFactory.getExtension`）只是用在ExtendLoader的注入方法（`injectExtension`）中，该方法用于为选定的扩展点实现注入相关的其他扩展点实例。\n\n目前为止，我们已经大概了解在dubbo内部，是以什么样的规则来使用扩展点机制，也为以后学习dubbo的其它方面提供了基础。","source":"_posts/dubbo中SPI的基础--Cooma微容器.md","raw":"title: dubbo中SPI的基础--Cooma微容器\ndate: 2015-01-15 15:54:30\ntags:\n- dubbo\n- cooma\n- dubbox\n- 微内核\n\ncategories: j2ee\n---\n\n\n断断续续研究[dubbo](http://alibaba.github.io/dubbo-doc-static/Home-zh.htm)其实有一段时间了，总是搁浅的原因和工作安排有很大关系，不过我始终保持着学习它的兴趣。随着[dubbox](http://dangdangdotcom.github.io/dubbox/)项目的更新，我决定再一次尝试学习这个项目。\n<!-- more -->\n之前把玩的时候自己甚至连一本完整的javaEE资料都没有看完过，虽然现在也还是入门级新手，不过在其他项目中的工作也让我有了比之前更多的积累，应该可以看得更透一些。\n\n从哪里开始呢？我个人认为应该从dubbo的SPI理念开始，由于dubbo的项目Leader一开始就把其定义成一个方便扩展的服务框架，所以在dubbo的架构设计中始终保持了良好的依赖扩展机制：**微内核+插件**。简而言之就是让扩展者可以和项目开发者拥有一样的灵活度，这也是dubbo得以迅速流行的一个必要条件。\n\n要想实现这种自由度，除了在架构分层组件上要保持高内聚低耦合外，底层也需要一套强大的类管理工具。在javaEE世界里，把这份工作做到极致的也已经有成熟的标准规范：OSGi。不过OSGi并不完全适配dubbo的需求，而且这玩意儿也有些过于重了，所以在此基础上，dubbo结合JDK标准的SPI机制设计出来一个轻量级的实现：[Cooma](https://github.com/alibaba/cooma/wiki)。\n\n这篇文章，我就打算从Cooma说起，官方介绍的已经非常详细了，不过它在从dubbo独立出来发布之前是做过修改优化的，在dubbo项目中使用时可能会存在些许的不同，我们就从dubbo内部来研读这部分实现的代码，并结合dubbo中的上下文来了解一下dubbo是如何使用SPI的。\n\n我们把目标定位在dubbo的这个包上：\n\n> com.alibaba.dubbo.common.extension\n\n看一下这个包的目录结构：\n\n\tcom.alibaba.dubbo.common.extension\n\t |\n\t |--factory\n\t |     |--AdaptiveExtensionFactory   #稍后解释\n\t |     |--SpiExtensionFactory        #稍后解释\n\t |\n\t |--support\n\t |     |--ActivateComparator\n\t |\n\t |--Activate  #自动激活加载扩展的注解\n\t |--Adaptive  #自适应扩展点的注解\n\t |--ExtensionFactory  #扩展点对象生成工厂接口\n\t |--ExtensionLoader   #扩展点加载器，扩展点的查找，校验，加载等核心逻辑的实现类\n\t |--SPI   #扩展点注解\n\n我们通过对照dubbo如何使用扩展点机制来完成扩展点工厂实例的选择与加载来了解一下扩展点实现的细节，这句话很拗口，有点递归的味道，我们不妨直接从代码中来理解：\n\n\tpublic class ExtensionLoader<T> {\n\t\t...\n\t\tprivate static final ConcurrentMap<Class<?>, ExtensionLoader<?>> EXTENSION_LOADERS = new ConcurrentHashMap<Class<?>, ExtensionLoader<?>>();\n\t\tprivate final Class<?> type;\t\t\n\t\t...\n\t\t@SuppressWarnings(\"unchecked\")\n\t    public static <T> ExtensionLoader<T> getExtensionLoader(Class<T> type) {\n\t        if (type == null)\n\t            throw new IllegalArgumentException(\"Extension type == null\");\n\t        if(!type.isInterface()) {\n\t            throw new IllegalArgumentException(\"Extension type(\" + type + \") is not interface!\");\n\t        }\n\t        if(!withExtensionAnnotation(type)) {\n\t            throw new IllegalArgumentException(\"Extension type(\" + type + \n\t                    \") is not extension, because WITHOUT @\" + SPI.class.getSimpleName() + \" Annotation!\");\n\t        }\n\t        \n\t        ExtensionLoader<T> loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);\n\t        if (loader == null) {\n\t            EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader<T>(type));\n\t            loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);\n\t        }\n\t        return loader;\n\t    }\n\t\n\t    private ExtensionLoader(Class<?> type) {\n\t        this.type = type;\n\t        objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());\n\t    }\t\t\n\t\t...\n\t}\n\n我们主要看`ExtensionLoader`构造方法，其中它初始化了`type`和`objectFactory`，前者为要作为扩展点的接口类型，后者表示要如何获取指定名称的扩展点实例（工厂类），目前dubbo提供了2个实现类，上面在包结构图上已经标注过了。\n\n\t@SuppressWarnings(\"unchecked\")\n    public T getAdaptiveExtension() {\n        Object instance = cachedAdaptiveInstance.get();\n        if (instance == null) {\n            if(createAdaptiveInstanceError == null) {\n                synchronized (cachedAdaptiveInstance) {\n                    instance = cachedAdaptiveInstance.get();\n                    if (instance == null) {\n                        try {\n                            instance = createAdaptiveExtension();\n                            cachedAdaptiveInstance.set(instance);\n                        } catch (Throwable t) {\n                            createAdaptiveInstanceError = t;\n                            throw new IllegalStateException(\"fail to create adaptive instance: \" + t.toString(), t);\n                        }\n                    }\n                }\n            }\n            else {\n                throw new IllegalStateException(\"fail to create adaptive instance: \" + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError);\n            }\n        }\n\n        return (T) instance;\n    }\n\n上面这个方法是用来获取自适应扩展类实例的，但其实它只是封装了一层缓存而已，真正完成创建实例的是`createAdaptiveExtension`方法。由于调用关系太深，请看下面的图：\n\n![](http://pic.yupoo.com/kazaff/Elc1xnHk/7eCGH.png)\n\n上图中给出的路径，缺少了查找扩展点实现的细节，也就是并没有展开`getExtensionClasses`方法，该方法会根据指定位置的配置文件扫描并解析拿到所有可用的扩展点实现，代码如下：\n\n\tprivate Map<String, Class<?>> getExtensionClasses() {\n        Map<String, Class<?>> classes = cachedClasses.get();\n        if (classes == null) {\n            synchronized (cachedClasses) {\n                classes = cachedClasses.get();\n                if (classes == null) {\n                    classes = loadExtensionClasses();\n                    cachedClasses.set(classes);\n                }\n            }\n        }\n        return classes;\n\t}\n\n可见它也只是封装了一层缓存而已，我们继续深挖`loadExtensionClasses`方法：\n\n\t// 此方法已经getExtensionClasses方法同步过。\n    private Map<String, Class<?>> loadExtensionClasses() {\n\t\t//检查并获取该接口类型声明的默认扩展点实现\n        final SPI defaultAnnotation = type.getAnnotation(SPI.class);\n        if(defaultAnnotation != null) {\n            String value = defaultAnnotation.value();\n            if(value != null && (value = value.trim()).length() > 0) {\n                String[] names = NAME_SEPARATOR.split(value);\n                if(names.length > 1) {\n                    throw new IllegalStateException(\"more than 1 default extension name on extension \" + type.getName()\n                            + \": \" + Arrays.toString(names));\n                }\n                if(names.length == 1) cachedDefaultName = names[0];\n            }\n        }\n        \n\t\t//去三个指定的位置查找配置文件并解析拿到扩展点键值映射关系\n        Map<String, Class<?>> extensionClasses = new HashMap<String, Class<?>>();\n        loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY);\n        loadFile(extensionClasses, DUBBO_DIRECTORY);\n        loadFile(extensionClasses, SERVICES_DIRECTORY);\n\n        return extensionClasses;\n    }\n\n我们先来看一下配置文件的格式：\n\n\tadaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactory\n\tspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactory\n\n`loadFile`方法会从指定位置（`META-INF/dubbo/internal/`）根据指定接口类型（`type`）为文件名称查找目标配置文件，然后解析并校验，最终拿到匹配的扩展点类的所有`Class`实例。对应上面给出的配置文件，也就是`AdaptiveExtensionFactory`和`SpiExtensionFactory`，它们已经在包结构图上提到过了。\n\n现在我们来着重看一下这两个类，它们到底是做什么用的呢？首先，`AdaptiveExtensionFactory`定义上有`@Adaptive`注解标识，很明显，它就是自适应扩展点的实现，从`loadFile`方法中可以留意到：**同一个接口类型只能存在一个自适应扩展点实现**：\n\n\t@Adaptive\n\tpublic class AdaptiveExtensionFactory implements ExtensionFactory {\n\t    \n    \tprivate final List<ExtensionFactory> factories;\n    \n\t    public AdaptiveExtensionFactory() {\n\t        ExtensionLoader<ExtensionFactory> loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class);\n\t        List<ExtensionFactory> list = new ArrayList<ExtensionFactory>();\n\t        for (String name : loader.getSupportedExtensions()) {\n\t            list.add(loader.getExtension(name));\n\t        }\n\t        factories = Collections.unmodifiableList(list);\n\t    }\n\n\t    //从这个方法定义来看，这个自适应扩展点实现类并没有做任何事儿，唯一的工作就是把真正获取扩展点实例的逻辑依次交给\n\t    //框架中声明的所有ExtensionFactory扩展点实例，默认也就是SpiExtensionFactory\n\t    public <T> T getExtension(Class<T> type, String name) {\n\t        for (ExtensionFactory factory : factories) {\n\t            T extension = factory.getExtension(type, name);\n\t            if (extension != null) {\n\t                return extension;\n\t            }\n\t        }\n\t        return null;\n\t    }\n\t}\n\n可以看到，`AdaptiveExtensionFactory`把逻辑委托给`SpiExtensionFactory`来做，而后者又是怎么做的呢：\n\n\tpublic class SpiExtensionFactory implements ExtensionFactory {\n\n\t    public <T> T getExtension(Class<T> type, String name) {\n\t        if (type.isInterface() && type.isAnnotationPresent(SPI.class)) {\n\t            ExtensionLoader<T> loader = ExtensionLoader.getExtensionLoader(type);\n\t            if (loader.getSupportedExtensions().size() > 0) {\n\t\t\t\t\t//获取自适应扩展点实例，这是dubbo默认的行为，\n\t\t\t\t\t//也可以自己写一个ExtensionFactory来按照要求加载扩展点\n\t                return loader.getAdaptiveExtension();   \n\t            }\n\t        }\n\t        return null;\n\t    }\n\t}\n\n而`objectFactory`（真实工作的也就是`SpiExtensionFactory.getExtension`）只是用在ExtendLoader的注入方法（`injectExtension`）中，该方法用于为选定的扩展点实现注入相关的其他扩展点实例。\n\n目前为止，我们已经大概了解在dubbo内部，是以什么样的规则来使用扩展点机制，也为以后学习dubbo的其它方面提供了基础。","slug":"dubbo中SPI的基础--Cooma微容器","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yr700bagtfysnl7xmpk","comments":1,"layout":"post","photos":[],"link":"","content":"<p>断断续续研究<a href=\"http://alibaba.github.io/dubbo-doc-static/Home-zh.htm\" target=\"_blank\" rel=\"external\">dubbo</a>其实有一段时间了，总是搁浅的原因和工作安排有很大关系，不过我始终保持着学习它的兴趣。随着<a href=\"http://dangdangdotcom.github.io/dubbox/\" target=\"_blank\" rel=\"external\">dubbox</a>项目的更新，我决定再一次尝试学习这个项目。<br><a id=\"more\"></a><br>之前把玩的时候自己甚至连一本完整的javaEE资料都没有看完过，虽然现在也还是入门级新手，不过在其他项目中的工作也让我有了比之前更多的积累，应该可以看得更透一些。</p>\n<p>从哪里开始呢？我个人认为应该从dubbo的SPI理念开始，由于dubbo的项目Leader一开始就把其定义成一个方便扩展的服务框架，所以在dubbo的架构设计中始终保持了良好的依赖扩展机制：<strong>微内核+插件</strong>。简而言之就是让扩展者可以和项目开发者拥有一样的灵活度，这也是dubbo得以迅速流行的一个必要条件。</p>\n<p>要想实现这种自由度，除了在架构分层组件上要保持高内聚低耦合外，底层也需要一套强大的类管理工具。在javaEE世界里，把这份工作做到极致的也已经有成熟的标准规范：OSGi。不过OSGi并不完全适配dubbo的需求，而且这玩意儿也有些过于重了，所以在此基础上，dubbo结合JDK标准的SPI机制设计出来一个轻量级的实现：<a href=\"https://github.com/alibaba/cooma/wiki\" target=\"_blank\" rel=\"external\">Cooma</a>。</p>\n<p>这篇文章，我就打算从Cooma说起，官方介绍的已经非常详细了，不过它在从dubbo独立出来发布之前是做过修改优化的，在dubbo项目中使用时可能会存在些许的不同，我们就从dubbo内部来研读这部分实现的代码，并结合dubbo中的上下文来了解一下dubbo是如何使用SPI的。</p>\n<p>我们把目标定位在dubbo的这个包上：</p>\n<blockquote>\n<p>com.alibaba.dubbo.common.extension</p>\n</blockquote>\n<p>看一下这个包的目录结构：</p>\n<pre><code>com.alibaba.dubbo.common.extension\n |\n |--factory\n |     |--AdaptiveExtensionFactory   #稍后解释\n |     |--SpiExtensionFactory        #稍后解释\n |\n |--support\n |     |--ActivateComparator\n |\n |--Activate  #自动激活加载扩展的注解\n |--Adaptive  #自适应扩展点的注解\n |--ExtensionFactory  #扩展点对象生成工厂接口\n |--ExtensionLoader   #扩展点加载器，扩展点的查找，校验，加载等核心逻辑的实现类\n |--SPI   #扩展点注解\n</code></pre><p>我们通过对照dubbo如何使用扩展点机制来完成扩展点工厂实例的选择与加载来了解一下扩展点实现的细节，这句话很拗口，有点递归的味道，我们不妨直接从代码中来理解：</p>\n<pre><code>public class ExtensionLoader&lt;T&gt; {\n    ...\n    private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;();\n    private final Class&lt;?&gt; type;        \n    ...\n    @SuppressWarnings(&quot;unchecked&quot;)\n    public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) {\n        if (type == null)\n            throw new IllegalArgumentException(&quot;Extension type == null&quot;);\n        if(!type.isInterface()) {\n            throw new IllegalArgumentException(&quot;Extension type(&quot; + type + &quot;) is not interface!&quot;);\n        }\n        if(!withExtensionAnnotation(type)) {\n            throw new IllegalArgumentException(&quot;Extension type(&quot; + type + \n                    &quot;) is not extension, because WITHOUT @&quot; + SPI.class.getSimpleName() + &quot; Annotation!&quot;);\n        }\n\n        ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type);\n        if (loader == null) {\n            EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type));\n            loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type);\n        }\n        return loader;\n    }\n\n    private ExtensionLoader(Class&lt;?&gt; type) {\n        this.type = type;\n        objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());\n    }        \n    ...\n}\n</code></pre><p>我们主要看<code>ExtensionLoader</code>构造方法，其中它初始化了<code>type</code>和<code>objectFactory</code>，前者为要作为扩展点的接口类型，后者表示要如何获取指定名称的扩展点实例（工厂类），目前dubbo提供了2个实现类，上面在包结构图上已经标注过了。</p>\n<pre><code>@SuppressWarnings(&quot;unchecked&quot;)\npublic T getAdaptiveExtension() {\n    Object instance = cachedAdaptiveInstance.get();\n    if (instance == null) {\n        if(createAdaptiveInstanceError == null) {\n            synchronized (cachedAdaptiveInstance) {\n                instance = cachedAdaptiveInstance.get();\n                if (instance == null) {\n                    try {\n                        instance = createAdaptiveExtension();\n                        cachedAdaptiveInstance.set(instance);\n                    } catch (Throwable t) {\n                        createAdaptiveInstanceError = t;\n                        throw new IllegalStateException(&quot;fail to create adaptive instance: &quot; + t.toString(), t);\n                    }\n                }\n            }\n        }\n        else {\n            throw new IllegalStateException(&quot;fail to create adaptive instance: &quot; + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError);\n        }\n    }\n\n    return (T) instance;\n}\n</code></pre><p>上面这个方法是用来获取自适应扩展类实例的，但其实它只是封装了一层缓存而已，真正完成创建实例的是<code>createAdaptiveExtension</code>方法。由于调用关系太深，请看下面的图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Elc1xnHk/7eCGH.png\" alt=\"\"></p>\n<p>上图中给出的路径，缺少了查找扩展点实现的细节，也就是并没有展开<code>getExtensionClasses</code>方法，该方法会根据指定位置的配置文件扫描并解析拿到所有可用的扩展点实现，代码如下：</p>\n<pre><code>private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() {\n    Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get();\n    if (classes == null) {\n        synchronized (cachedClasses) {\n            classes = cachedClasses.get();\n            if (classes == null) {\n                classes = loadExtensionClasses();\n                cachedClasses.set(classes);\n            }\n        }\n    }\n    return classes;\n}\n</code></pre><p>可见它也只是封装了一层缓存而已，我们继续深挖<code>loadExtensionClasses</code>方法：</p>\n<pre><code>// 此方法已经getExtensionClasses方法同步过。\nprivate Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() {\n    //检查并获取该接口类型声明的默认扩展点实现\n    final SPI defaultAnnotation = type.getAnnotation(SPI.class);\n    if(defaultAnnotation != null) {\n        String value = defaultAnnotation.value();\n        if(value != null &amp;&amp; (value = value.trim()).length() &gt; 0) {\n            String[] names = NAME_SEPARATOR.split(value);\n            if(names.length &gt; 1) {\n                throw new IllegalStateException(&quot;more than 1 default extension name on extension &quot; + type.getName()\n                        + &quot;: &quot; + Arrays.toString(names));\n            }\n            if(names.length == 1) cachedDefaultName = names[0];\n        }\n    }\n\n    //去三个指定的位置查找配置文件并解析拿到扩展点键值映射关系\n    Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;();\n    loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY);\n    loadFile(extensionClasses, DUBBO_DIRECTORY);\n    loadFile(extensionClasses, SERVICES_DIRECTORY);\n\n    return extensionClasses;\n}\n</code></pre><p>我们先来看一下配置文件的格式：</p>\n<pre><code>adaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactory\nspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactory\n</code></pre><p><code>loadFile</code>方法会从指定位置（<code>META-INF/dubbo/internal/</code>）根据指定接口类型（<code>type</code>）为文件名称查找目标配置文件，然后解析并校验，最终拿到匹配的扩展点类的所有<code>Class</code>实例。对应上面给出的配置文件，也就是<code>AdaptiveExtensionFactory</code>和<code>SpiExtensionFactory</code>，它们已经在包结构图上提到过了。</p>\n<p>现在我们来着重看一下这两个类，它们到底是做什么用的呢？首先，<code>AdaptiveExtensionFactory</code>定义上有<code>@Adaptive</code>注解标识，很明显，它就是自适应扩展点的实现，从<code>loadFile</code>方法中可以留意到：<strong>同一个接口类型只能存在一个自适应扩展点实现</strong>：</p>\n<pre><code>@Adaptive\npublic class AdaptiveExtensionFactory implements ExtensionFactory {\n\n    private final List&lt;ExtensionFactory&gt; factories;\n\n    public AdaptiveExtensionFactory() {\n        ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class);\n        List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;();\n        for (String name : loader.getSupportedExtensions()) {\n            list.add(loader.getExtension(name));\n        }\n        factories = Collections.unmodifiableList(list);\n    }\n\n    //从这个方法定义来看，这个自适应扩展点实现类并没有做任何事儿，唯一的工作就是把真正获取扩展点实例的逻辑依次交给\n    //框架中声明的所有ExtensionFactory扩展点实例，默认也就是SpiExtensionFactory\n    public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) {\n        for (ExtensionFactory factory : factories) {\n            T extension = factory.getExtension(type, name);\n            if (extension != null) {\n                return extension;\n            }\n        }\n        return null;\n    }\n}\n</code></pre><p>可以看到，<code>AdaptiveExtensionFactory</code>把逻辑委托给<code>SpiExtensionFactory</code>来做，而后者又是怎么做的呢：</p>\n<pre><code>public class SpiExtensionFactory implements ExtensionFactory {\n\n    public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) {\n        if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) {\n            ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type);\n            if (loader.getSupportedExtensions().size() &gt; 0) {\n                //获取自适应扩展点实例，这是dubbo默认的行为，\n                //也可以自己写一个ExtensionFactory来按照要求加载扩展点\n                return loader.getAdaptiveExtension();   \n            }\n        }\n        return null;\n    }\n}\n</code></pre><p>而<code>objectFactory</code>（真实工作的也就是<code>SpiExtensionFactory.getExtension</code>）只是用在ExtendLoader的注入方法（<code>injectExtension</code>）中，该方法用于为选定的扩展点实现注入相关的其他扩展点实例。</p>\n<p>目前为止，我们已经大概了解在dubbo内部，是以什么样的规则来使用扩展点机制，也为以后学习dubbo的其它方面提供了基础。</p>\n","excerpt":"<p>断断续续研究<a href=\"http://alibaba.github.io/dubbo-doc-static/Home-zh.htm\">dubbo</a>其实有一段时间了，总是搁浅的原因和工作安排有很大关系，不过我始终保持着学习它的兴趣。随着<a href=\"http://dangdangdotcom.github.io/dubbox/\">dubbox</a>项目的更新，我决定再一次尝试学习这个项目。<br>","more":"<br>之前把玩的时候自己甚至连一本完整的javaEE资料都没有看完过，虽然现在也还是入门级新手，不过在其他项目中的工作也让我有了比之前更多的积累，应该可以看得更透一些。</p>\n<p>从哪里开始呢？我个人认为应该从dubbo的SPI理念开始，由于dubbo的项目Leader一开始就把其定义成一个方便扩展的服务框架，所以在dubbo的架构设计中始终保持了良好的依赖扩展机制：<strong>微内核+插件</strong>。简而言之就是让扩展者可以和项目开发者拥有一样的灵活度，这也是dubbo得以迅速流行的一个必要条件。</p>\n<p>要想实现这种自由度，除了在架构分层组件上要保持高内聚低耦合外，底层也需要一套强大的类管理工具。在javaEE世界里，把这份工作做到极致的也已经有成熟的标准规范：OSGi。不过OSGi并不完全适配dubbo的需求，而且这玩意儿也有些过于重了，所以在此基础上，dubbo结合JDK标准的SPI机制设计出来一个轻量级的实现：<a href=\"https://github.com/alibaba/cooma/wiki\">Cooma</a>。</p>\n<p>这篇文章，我就打算从Cooma说起，官方介绍的已经非常详细了，不过它在从dubbo独立出来发布之前是做过修改优化的，在dubbo项目中使用时可能会存在些许的不同，我们就从dubbo内部来研读这部分实现的代码，并结合dubbo中的上下文来了解一下dubbo是如何使用SPI的。</p>\n<p>我们把目标定位在dubbo的这个包上：</p>\n<blockquote>\n<p>com.alibaba.dubbo.common.extension</p>\n</blockquote>\n<p>看一下这个包的目录结构：</p>\n<pre><code>com.alibaba.dubbo.common.extension\n |\n |--factory\n |     |--AdaptiveExtensionFactory   #稍后解释\n |     |--SpiExtensionFactory        #稍后解释\n |\n |--support\n |     |--ActivateComparator\n |\n |--Activate  #自动激活加载扩展的注解\n |--Adaptive  #自适应扩展点的注解\n |--ExtensionFactory  #扩展点对象生成工厂接口\n |--ExtensionLoader   #扩展点加载器，扩展点的查找，校验，加载等核心逻辑的实现类\n |--SPI   #扩展点注解\n</code></pre><p>我们通过对照dubbo如何使用扩展点机制来完成扩展点工厂实例的选择与加载来了解一下扩展点实现的细节，这句话很拗口，有点递归的味道，我们不妨直接从代码中来理解：</p>\n<pre><code>public class ExtensionLoader&lt;T&gt; {\n    ...\n    private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;();\n    private final Class&lt;?&gt; type;        \n    ...\n    @SuppressWarnings(&quot;unchecked&quot;)\n    public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) {\n        if (type == null)\n            throw new IllegalArgumentException(&quot;Extension type == null&quot;);\n        if(!type.isInterface()) {\n            throw new IllegalArgumentException(&quot;Extension type(&quot; + type + &quot;) is not interface!&quot;);\n        }\n        if(!withExtensionAnnotation(type)) {\n            throw new IllegalArgumentException(&quot;Extension type(&quot; + type + \n                    &quot;) is not extension, because WITHOUT @&quot; + SPI.class.getSimpleName() + &quot; Annotation!&quot;);\n        }\n\n        ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type);\n        if (loader == null) {\n            EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type));\n            loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type);\n        }\n        return loader;\n    }\n\n    private ExtensionLoader(Class&lt;?&gt; type) {\n        this.type = type;\n        objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());\n    }        \n    ...\n}\n</code></pre><p>我们主要看<code>ExtensionLoader</code>构造方法，其中它初始化了<code>type</code>和<code>objectFactory</code>，前者为要作为扩展点的接口类型，后者表示要如何获取指定名称的扩展点实例（工厂类），目前dubbo提供了2个实现类，上面在包结构图上已经标注过了。</p>\n<pre><code>@SuppressWarnings(&quot;unchecked&quot;)\npublic T getAdaptiveExtension() {\n    Object instance = cachedAdaptiveInstance.get();\n    if (instance == null) {\n        if(createAdaptiveInstanceError == null) {\n            synchronized (cachedAdaptiveInstance) {\n                instance = cachedAdaptiveInstance.get();\n                if (instance == null) {\n                    try {\n                        instance = createAdaptiveExtension();\n                        cachedAdaptiveInstance.set(instance);\n                    } catch (Throwable t) {\n                        createAdaptiveInstanceError = t;\n                        throw new IllegalStateException(&quot;fail to create adaptive instance: &quot; + t.toString(), t);\n                    }\n                }\n            }\n        }\n        else {\n            throw new IllegalStateException(&quot;fail to create adaptive instance: &quot; + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError);\n        }\n    }\n\n    return (T) instance;\n}\n</code></pre><p>上面这个方法是用来获取自适应扩展类实例的，但其实它只是封装了一层缓存而已，真正完成创建实例的是<code>createAdaptiveExtension</code>方法。由于调用关系太深，请看下面的图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Elc1xnHk/7eCGH.png\" alt=\"\"></p>\n<p>上图中给出的路径，缺少了查找扩展点实现的细节，也就是并没有展开<code>getExtensionClasses</code>方法，该方法会根据指定位置的配置文件扫描并解析拿到所有可用的扩展点实现，代码如下：</p>\n<pre><code>private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() {\n    Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get();\n    if (classes == null) {\n        synchronized (cachedClasses) {\n            classes = cachedClasses.get();\n            if (classes == null) {\n                classes = loadExtensionClasses();\n                cachedClasses.set(classes);\n            }\n        }\n    }\n    return classes;\n}\n</code></pre><p>可见它也只是封装了一层缓存而已，我们继续深挖<code>loadExtensionClasses</code>方法：</p>\n<pre><code>// 此方法已经getExtensionClasses方法同步过。\nprivate Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() {\n    //检查并获取该接口类型声明的默认扩展点实现\n    final SPI defaultAnnotation = type.getAnnotation(SPI.class);\n    if(defaultAnnotation != null) {\n        String value = defaultAnnotation.value();\n        if(value != null &amp;&amp; (value = value.trim()).length() &gt; 0) {\n            String[] names = NAME_SEPARATOR.split(value);\n            if(names.length &gt; 1) {\n                throw new IllegalStateException(&quot;more than 1 default extension name on extension &quot; + type.getName()\n                        + &quot;: &quot; + Arrays.toString(names));\n            }\n            if(names.length == 1) cachedDefaultName = names[0];\n        }\n    }\n\n    //去三个指定的位置查找配置文件并解析拿到扩展点键值映射关系\n    Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;();\n    loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY);\n    loadFile(extensionClasses, DUBBO_DIRECTORY);\n    loadFile(extensionClasses, SERVICES_DIRECTORY);\n\n    return extensionClasses;\n}\n</code></pre><p>我们先来看一下配置文件的格式：</p>\n<pre><code>adaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactory\nspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactory\n</code></pre><p><code>loadFile</code>方法会从指定位置（<code>META-INF/dubbo/internal/</code>）根据指定接口类型（<code>type</code>）为文件名称查找目标配置文件，然后解析并校验，最终拿到匹配的扩展点类的所有<code>Class</code>实例。对应上面给出的配置文件，也就是<code>AdaptiveExtensionFactory</code>和<code>SpiExtensionFactory</code>，它们已经在包结构图上提到过了。</p>\n<p>现在我们来着重看一下这两个类，它们到底是做什么用的呢？首先，<code>AdaptiveExtensionFactory</code>定义上有<code>@Adaptive</code>注解标识，很明显，它就是自适应扩展点的实现，从<code>loadFile</code>方法中可以留意到：<strong>同一个接口类型只能存在一个自适应扩展点实现</strong>：</p>\n<pre><code>@Adaptive\npublic class AdaptiveExtensionFactory implements ExtensionFactory {\n\n    private final List&lt;ExtensionFactory&gt; factories;\n\n    public AdaptiveExtensionFactory() {\n        ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class);\n        List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;();\n        for (String name : loader.getSupportedExtensions()) {\n            list.add(loader.getExtension(name));\n        }\n        factories = Collections.unmodifiableList(list);\n    }\n\n    //从这个方法定义来看，这个自适应扩展点实现类并没有做任何事儿，唯一的工作就是把真正获取扩展点实例的逻辑依次交给\n    //框架中声明的所有ExtensionFactory扩展点实例，默认也就是SpiExtensionFactory\n    public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) {\n        for (ExtensionFactory factory : factories) {\n            T extension = factory.getExtension(type, name);\n            if (extension != null) {\n                return extension;\n            }\n        }\n        return null;\n    }\n}\n</code></pre><p>可以看到，<code>AdaptiveExtensionFactory</code>把逻辑委托给<code>SpiExtensionFactory</code>来做，而后者又是怎么做的呢：</p>\n<pre><code>public class SpiExtensionFactory implements ExtensionFactory {\n\n    public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) {\n        if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) {\n            ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type);\n            if (loader.getSupportedExtensions().size() &gt; 0) {\n                //获取自适应扩展点实例，这是dubbo默认的行为，\n                //也可以自己写一个ExtensionFactory来按照要求加载扩展点\n                return loader.getAdaptiveExtension();   \n            }\n        }\n        return null;\n    }\n}\n</code></pre><p>而<code>objectFactory</code>（真实工作的也就是<code>SpiExtensionFactory.getExtension</code>）只是用在ExtendLoader的注入方法（<code>injectExtension</code>）中，该方法用于为选定的扩展点实现注入相关的其他扩展点实例。</p>\n<p>目前为止，我们已经大概了解在dubbo内部，是以什么样的规则来使用扩展点机制，也为以后学习dubbo的其它方面提供了基础。</p>"},{"title":"dubbox新增的REST协议分析","date":"2015-03-12T07:54:30.000Z","_content":"\n我们今天来看一下dubbox多出来的那个“x”都包含什么，当然一定会存在遗落，毕竟我是从一个第三方使用者的角度来总结的。之前也写了几篇关于dubbo的文章，虽然都加了`dubbox`的tag，但这一篇才是真正的只与dubbox相关的哟~\n<!-- more -->\n先从业务应用的角度来看，其实dangdang给dubbo嫁接的rest协议是基于RESTEasy的，并且增加了序列化的方式，还有额外的servlet容器。前两个新增是开发者需要非常熟悉的，毕竟是要常打交道的。servlet容器更多的是和运维人员有交集。\n\nRESTEasy不熟悉的童鞋（和我一样），不妨先看一些相关的技术文档，我这里粗糙的翻译了一篇，[尽请笑纳](http://blog.kazaff.me/2015/03/10/%E7%9C%8B%E7%9C%8BRESTEasy/)。随着你对RESTEasy的熟悉，你会发现dubbox中很多的新增特性都是RESTEasy带来的，遵循JAX-RS规范。当然dangdang的大牛们也做了很多工作，后面我们一点一点分析。\n\n这里还要再次说一个关于RESTEasy的小[问题](https://github.com/dangdangdotcom/dubbox/issues/30)，这也是最终有这篇文章的原因。\n\n序列化部分，dangdang为dubbox新增了fst和kryo两种方式，使用方式和dubbo原有的保持一致，这一部分几乎是对业务透明的，之所以说是几乎，是因为不少大牛提到序列化这部分还是存在不少坑，这就需要我们在开发时进行比较全面的测试，由于我们目前还没正式投入使用，所以暂时就说这么多。\n\n关于新增的servlet容器，目前知道的就是tomcat-embed，另外如果使用REST协议，还可以使用Tjws容器，不过RESEasy官方推荐这个玩意儿还是建议在测试环境中使用。当然，我们也可以选择使用`server=\"servlet\"`来使用外部的servlet容器，例如和其他应用使用同一个tomcat。但是文档上也叮嘱，即便是打算使用外部tomcat，也**尽可能不要和其他应用混合部署，而应该用单独的实例**。\n\n其实上面说的这些，在dubbox提供的[指南](http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point)中都有详细的说明，多说只是重复。\n\n\n\n源码解析\n---\n\n我们接下来看一下新增的`RestProtocol`的具体实现。基于之前的分析结果，我们可以直接定位到核心的代码块（doExport）：\n\n\tprotected <T> Runnable doExport(T impl, Class<T> type, URL url) throws RpcException {\n        String addr = url.getIp() + \":\" + url.getPort();\n\n        //这么处理其实是为了配合dubbo的延迟暴露机制，延迟暴露的原理是创建新线程，所以ServiceImplHolder靠ThreadLocal来记录对应的类信息，而不是靠公共变量，避免竞争问题\n        Class implClass = ServiceImplHolder.getInstance().popServiceImpl().getClass();\n\n        //根据url中的地址创建server容器，相同地址的服务使用相同的容器\n        RestServer server = servers.get(addr);\n        if (server == null) {\n            server = serverFactory.createServer(url.getParameter(Constants.SERVER_KEY, \"jetty\"));   //默认使用jetty，当当推荐使用tomcat\n            server.start(url);\n            servers.put(addr, server);\n        }\n\n        //查看implClass是否包含jax-rs注解\n        final Class resourceDef = GetRestful.getRootResourceClass(implClass) != null ? implClass : type;\n        server.deploy(resourceDef, impl, getContextPath(url));  //在server中部署指定服务\n\n        final RestServer s = server;    //注意这样的写法，java要求线程中只能使用外部final变量\n        return new Runnable() {\n            public void run() {\n                // TODO due to dubbo's current architecture,\n                // it will be called from registry protocol in the shutdown process and won't appear in logs\n                s.undeploy(resourceDef);\n            }\n        };\n    }\n\n该方法是继承自dubbo原有的`AbstractProxyProtocol`类：\n\n![](http://pic.yupoo.com/kazaff/EvwMF0Rm/Br6Hp.png)\n\n按照dubbo的逻辑，注意该方法最终返回的是一个可异步执行的callback类，完成的逻辑也很简单，就是从对应的server中把指定资源服务给“卸载”掉。\n\n我们再来关注一下关于`server`的逻辑，这部分其实很简单，根据你的配置直接创建对应的server：\n\n\tpublic class RestServerFactory {\n\n\t    private HttpBinder httpBinder;  //提供http服务的容器\n\t\n\t\t//该方法为SPI注入时调用，会注入一个httpBinder自适应扩展实例\n\t    public void setHttpBinder(HttpBinder httpBinder) {\n\t        this.httpBinder = httpBinder;\n\t    }\n\t\n\t    public RestServer createServer(String name) {\n\t        // TODO move names to Constants\n\t        if (\"servlet\".equalsIgnoreCase(name) || \"jetty\".equalsIgnoreCase(name) || \"tomcat\".equalsIgnoreCase(name)) {\n\t            return new DubboHttpServer(httpBinder);\n\t\t//        } else if (\"tjws\".equalsIgnoreCase(name)) {\n\t\t//            return new TjwsServer();\n\t        } else if (\"netty\".equalsIgnoreCase(name)) {\n\t            return new NettyServer();\n\t        } else if (\"sunhttp\".equalsIgnoreCase(name)) {\n\t            return new SunHttpServer();\n\t        } else {\n\t            throw new IllegalArgumentException(\"Unrecognized server name: \" + name);\n\t        }\n    \t}\n\t}\n\n`DubboHttpServer`类主要贡酒是完成了RESTEasy和servlet容器的绑定，上面代码的`httpBinder`代表的就是你要使用的容器，例如tomcat。这部分逻辑你需要结合RESTEasy的初始化步骤来理解，我就不多说了。\n\ntomcat-embed的使用方式，也非常的直观，结合官方提供的例子即可，也不多说了。\n\n\n总之，这篇文章还是很水的，不管怎么说，这就是我这几天来的工作内容。更多内容，敬请期待~~\n\n\n","source":"_posts/dubbox新增的REST协议分析.md","raw":"title: dubbox新增的REST协议分析\ndate: 2015-03-12 15:54:30\ntags:\n- rest\n- dubbox\n- dubbo\n- 协议\n- RESTEasy\n- tomcat-embed\n\ncategories: j2ee\n---\n\n我们今天来看一下dubbox多出来的那个“x”都包含什么，当然一定会存在遗落，毕竟我是从一个第三方使用者的角度来总结的。之前也写了几篇关于dubbo的文章，虽然都加了`dubbox`的tag，但这一篇才是真正的只与dubbox相关的哟~\n<!-- more -->\n先从业务应用的角度来看，其实dangdang给dubbo嫁接的rest协议是基于RESTEasy的，并且增加了序列化的方式，还有额外的servlet容器。前两个新增是开发者需要非常熟悉的，毕竟是要常打交道的。servlet容器更多的是和运维人员有交集。\n\nRESTEasy不熟悉的童鞋（和我一样），不妨先看一些相关的技术文档，我这里粗糙的翻译了一篇，[尽请笑纳](http://blog.kazaff.me/2015/03/10/%E7%9C%8B%E7%9C%8BRESTEasy/)。随着你对RESTEasy的熟悉，你会发现dubbox中很多的新增特性都是RESTEasy带来的，遵循JAX-RS规范。当然dangdang的大牛们也做了很多工作，后面我们一点一点分析。\n\n这里还要再次说一个关于RESTEasy的小[问题](https://github.com/dangdangdotcom/dubbox/issues/30)，这也是最终有这篇文章的原因。\n\n序列化部分，dangdang为dubbox新增了fst和kryo两种方式，使用方式和dubbo原有的保持一致，这一部分几乎是对业务透明的，之所以说是几乎，是因为不少大牛提到序列化这部分还是存在不少坑，这就需要我们在开发时进行比较全面的测试，由于我们目前还没正式投入使用，所以暂时就说这么多。\n\n关于新增的servlet容器，目前知道的就是tomcat-embed，另外如果使用REST协议，还可以使用Tjws容器，不过RESEasy官方推荐这个玩意儿还是建议在测试环境中使用。当然，我们也可以选择使用`server=\"servlet\"`来使用外部的servlet容器，例如和其他应用使用同一个tomcat。但是文档上也叮嘱，即便是打算使用外部tomcat，也**尽可能不要和其他应用混合部署，而应该用单独的实例**。\n\n其实上面说的这些，在dubbox提供的[指南](http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point)中都有详细的说明，多说只是重复。\n\n\n\n源码解析\n---\n\n我们接下来看一下新增的`RestProtocol`的具体实现。基于之前的分析结果，我们可以直接定位到核心的代码块（doExport）：\n\n\tprotected <T> Runnable doExport(T impl, Class<T> type, URL url) throws RpcException {\n        String addr = url.getIp() + \":\" + url.getPort();\n\n        //这么处理其实是为了配合dubbo的延迟暴露机制，延迟暴露的原理是创建新线程，所以ServiceImplHolder靠ThreadLocal来记录对应的类信息，而不是靠公共变量，避免竞争问题\n        Class implClass = ServiceImplHolder.getInstance().popServiceImpl().getClass();\n\n        //根据url中的地址创建server容器，相同地址的服务使用相同的容器\n        RestServer server = servers.get(addr);\n        if (server == null) {\n            server = serverFactory.createServer(url.getParameter(Constants.SERVER_KEY, \"jetty\"));   //默认使用jetty，当当推荐使用tomcat\n            server.start(url);\n            servers.put(addr, server);\n        }\n\n        //查看implClass是否包含jax-rs注解\n        final Class resourceDef = GetRestful.getRootResourceClass(implClass) != null ? implClass : type;\n        server.deploy(resourceDef, impl, getContextPath(url));  //在server中部署指定服务\n\n        final RestServer s = server;    //注意这样的写法，java要求线程中只能使用外部final变量\n        return new Runnable() {\n            public void run() {\n                // TODO due to dubbo's current architecture,\n                // it will be called from registry protocol in the shutdown process and won't appear in logs\n                s.undeploy(resourceDef);\n            }\n        };\n    }\n\n该方法是继承自dubbo原有的`AbstractProxyProtocol`类：\n\n![](http://pic.yupoo.com/kazaff/EvwMF0Rm/Br6Hp.png)\n\n按照dubbo的逻辑，注意该方法最终返回的是一个可异步执行的callback类，完成的逻辑也很简单，就是从对应的server中把指定资源服务给“卸载”掉。\n\n我们再来关注一下关于`server`的逻辑，这部分其实很简单，根据你的配置直接创建对应的server：\n\n\tpublic class RestServerFactory {\n\n\t    private HttpBinder httpBinder;  //提供http服务的容器\n\t\n\t\t//该方法为SPI注入时调用，会注入一个httpBinder自适应扩展实例\n\t    public void setHttpBinder(HttpBinder httpBinder) {\n\t        this.httpBinder = httpBinder;\n\t    }\n\t\n\t    public RestServer createServer(String name) {\n\t        // TODO move names to Constants\n\t        if (\"servlet\".equalsIgnoreCase(name) || \"jetty\".equalsIgnoreCase(name) || \"tomcat\".equalsIgnoreCase(name)) {\n\t            return new DubboHttpServer(httpBinder);\n\t\t//        } else if (\"tjws\".equalsIgnoreCase(name)) {\n\t\t//            return new TjwsServer();\n\t        } else if (\"netty\".equalsIgnoreCase(name)) {\n\t            return new NettyServer();\n\t        } else if (\"sunhttp\".equalsIgnoreCase(name)) {\n\t            return new SunHttpServer();\n\t        } else {\n\t            throw new IllegalArgumentException(\"Unrecognized server name: \" + name);\n\t        }\n    \t}\n\t}\n\n`DubboHttpServer`类主要贡酒是完成了RESTEasy和servlet容器的绑定，上面代码的`httpBinder`代表的就是你要使用的容器，例如tomcat。这部分逻辑你需要结合RESTEasy的初始化步骤来理解，我就不多说了。\n\ntomcat-embed的使用方式，也非常的直观，结合官方提供的例子即可，也不多说了。\n\n\n总之，这篇文章还是很水的，不管怎么说，这就是我这几天来的工作内容。更多内容，敬请期待~~\n\n\n","slug":"dubbox新增的REST协议分析","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yrc00bigtfy47k1vik2","comments":1,"layout":"post","photos":[],"link":"","content":"<p>我们今天来看一下dubbox多出来的那个“x”都包含什么，当然一定会存在遗落，毕竟我是从一个第三方使用者的角度来总结的。之前也写了几篇关于dubbo的文章，虽然都加了<code>dubbox</code>的tag，但这一篇才是真正的只与dubbox相关的哟~<br><a id=\"more\"></a><br>先从业务应用的角度来看，其实dangdang给dubbo嫁接的rest协议是基于RESTEasy的，并且增加了序列化的方式，还有额外的servlet容器。前两个新增是开发者需要非常熟悉的，毕竟是要常打交道的。servlet容器更多的是和运维人员有交集。</p>\n<p>RESTEasy不熟悉的童鞋（和我一样），不妨先看一些相关的技术文档，我这里粗糙的翻译了一篇，<a href=\"http://blog.kazaff.me/2015/03/10/%E7%9C%8B%E7%9C%8BRESTEasy/\">尽请笑纳</a>。随着你对RESTEasy的熟悉，你会发现dubbox中很多的新增特性都是RESTEasy带来的，遵循JAX-RS规范。当然dangdang的大牛们也做了很多工作，后面我们一点一点分析。</p>\n<p>这里还要再次说一个关于RESTEasy的小<a href=\"https://github.com/dangdangdotcom/dubbox/issues/30\" target=\"_blank\" rel=\"external\">问题</a>，这也是最终有这篇文章的原因。</p>\n<p>序列化部分，dangdang为dubbox新增了fst和kryo两种方式，使用方式和dubbo原有的保持一致，这一部分几乎是对业务透明的，之所以说是几乎，是因为不少大牛提到序列化这部分还是存在不少坑，这就需要我们在开发时进行比较全面的测试，由于我们目前还没正式投入使用，所以暂时就说这么多。</p>\n<p>关于新增的servlet容器，目前知道的就是tomcat-embed，另外如果使用REST协议，还可以使用Tjws容器，不过RESEasy官方推荐这个玩意儿还是建议在测试环境中使用。当然，我们也可以选择使用<code>server=&quot;servlet&quot;</code>来使用外部的servlet容器，例如和其他应用使用同一个tomcat。但是文档上也叮嘱，即便是打算使用外部tomcat，也<strong>尽可能不要和其他应用混合部署，而应该用单独的实例</strong>。</p>\n<p>其实上面说的这些，在dubbox提供的<a href=\"http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point\" target=\"_blank\" rel=\"external\">指南</a>中都有详细的说明，多说只是重复。</p>\n<h2 id=\"源码解析\"><a href=\"#源码解析\" class=\"headerlink\" title=\"源码解析\"></a>源码解析</h2><p>我们接下来看一下新增的<code>RestProtocol</code>的具体实现。基于之前的分析结果，我们可以直接定位到核心的代码块（doExport）：</p>\n<pre><code>protected &lt;T&gt; Runnable doExport(T impl, Class&lt;T&gt; type, URL url) throws RpcException {\n    String addr = url.getIp() + &quot;:&quot; + url.getPort();\n\n    //这么处理其实是为了配合dubbo的延迟暴露机制，延迟暴露的原理是创建新线程，所以ServiceImplHolder靠ThreadLocal来记录对应的类信息，而不是靠公共变量，避免竞争问题\n    Class implClass = ServiceImplHolder.getInstance().popServiceImpl().getClass();\n\n    //根据url中的地址创建server容器，相同地址的服务使用相同的容器\n    RestServer server = servers.get(addr);\n    if (server == null) {\n        server = serverFactory.createServer(url.getParameter(Constants.SERVER_KEY, &quot;jetty&quot;));   //默认使用jetty，当当推荐使用tomcat\n        server.start(url);\n        servers.put(addr, server);\n    }\n\n    //查看implClass是否包含jax-rs注解\n    final Class resourceDef = GetRestful.getRootResourceClass(implClass) != null ? implClass : type;\n    server.deploy(resourceDef, impl, getContextPath(url));  //在server中部署指定服务\n\n    final RestServer s = server;    //注意这样的写法，java要求线程中只能使用外部final变量\n    return new Runnable() {\n        public void run() {\n            // TODO due to dubbo&apos;s current architecture,\n            // it will be called from registry protocol in the shutdown process and won&apos;t appear in logs\n            s.undeploy(resourceDef);\n        }\n    };\n}\n</code></pre><p>该方法是继承自dubbo原有的<code>AbstractProxyProtocol</code>类：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EvwMF0Rm/Br6Hp.png\" alt=\"\"></p>\n<p>按照dubbo的逻辑，注意该方法最终返回的是一个可异步执行的callback类，完成的逻辑也很简单，就是从对应的server中把指定资源服务给“卸载”掉。</p>\n<p>我们再来关注一下关于<code>server</code>的逻辑，这部分其实很简单，根据你的配置直接创建对应的server：</p>\n<pre><code>public class RestServerFactory {\n\n    private HttpBinder httpBinder;  //提供http服务的容器\n\n    //该方法为SPI注入时调用，会注入一个httpBinder自适应扩展实例\n    public void setHttpBinder(HttpBinder httpBinder) {\n        this.httpBinder = httpBinder;\n    }\n\n    public RestServer createServer(String name) {\n        // TODO move names to Constants\n        if (&quot;servlet&quot;.equalsIgnoreCase(name) || &quot;jetty&quot;.equalsIgnoreCase(name) || &quot;tomcat&quot;.equalsIgnoreCase(name)) {\n            return new DubboHttpServer(httpBinder);\n    //        } else if (&quot;tjws&quot;.equalsIgnoreCase(name)) {\n    //            return new TjwsServer();\n        } else if (&quot;netty&quot;.equalsIgnoreCase(name)) {\n            return new NettyServer();\n        } else if (&quot;sunhttp&quot;.equalsIgnoreCase(name)) {\n            return new SunHttpServer();\n        } else {\n            throw new IllegalArgumentException(&quot;Unrecognized server name: &quot; + name);\n        }\n    }\n}\n</code></pre><p><code>DubboHttpServer</code>类主要贡酒是完成了RESTEasy和servlet容器的绑定，上面代码的<code>httpBinder</code>代表的就是你要使用的容器，例如tomcat。这部分逻辑你需要结合RESTEasy的初始化步骤来理解，我就不多说了。</p>\n<p>tomcat-embed的使用方式，也非常的直观，结合官方提供的例子即可，也不多说了。</p>\n<p>总之，这篇文章还是很水的，不管怎么说，这就是我这几天来的工作内容。更多内容，敬请期待~~</p>\n","excerpt":"<p>我们今天来看一下dubbox多出来的那个“x”都包含什么，当然一定会存在遗落，毕竟我是从一个第三方使用者的角度来总结的。之前也写了几篇关于dubbo的文章，虽然都加了<code>dubbox</code>的tag，但这一篇才是真正的只与dubbox相关的哟~<br>","more":"<br>先从业务应用的角度来看，其实dangdang给dubbo嫁接的rest协议是基于RESTEasy的，并且增加了序列化的方式，还有额外的servlet容器。前两个新增是开发者需要非常熟悉的，毕竟是要常打交道的。servlet容器更多的是和运维人员有交集。</p>\n<p>RESTEasy不熟悉的童鞋（和我一样），不妨先看一些相关的技术文档，我这里粗糙的翻译了一篇，<a href=\"http://blog.kazaff.me/2015/03/10/%E7%9C%8B%E7%9C%8BRESTEasy/\">尽请笑纳</a>。随着你对RESTEasy的熟悉，你会发现dubbox中很多的新增特性都是RESTEasy带来的，遵循JAX-RS规范。当然dangdang的大牛们也做了很多工作，后面我们一点一点分析。</p>\n<p>这里还要再次说一个关于RESTEasy的小<a href=\"https://github.com/dangdangdotcom/dubbox/issues/30\">问题</a>，这也是最终有这篇文章的原因。</p>\n<p>序列化部分，dangdang为dubbox新增了fst和kryo两种方式，使用方式和dubbo原有的保持一致，这一部分几乎是对业务透明的，之所以说是几乎，是因为不少大牛提到序列化这部分还是存在不少坑，这就需要我们在开发时进行比较全面的测试，由于我们目前还没正式投入使用，所以暂时就说这么多。</p>\n<p>关于新增的servlet容器，目前知道的就是tomcat-embed，另外如果使用REST协议，还可以使用Tjws容器，不过RESEasy官方推荐这个玩意儿还是建议在测试环境中使用。当然，我们也可以选择使用<code>server=&quot;servlet&quot;</code>来使用外部的servlet容器，例如和其他应用使用同一个tomcat。但是文档上也叮嘱，即便是打算使用外部tomcat，也<strong>尽可能不要和其他应用混合部署，而应该用单独的实例</strong>。</p>\n<p>其实上面说的这些，在dubbox提供的<a href=\"http://dangdangdotcom.github.io/dubbox/rest.html#show-last-Point\">指南</a>中都有详细的说明，多说只是重复。</p>\n<h2 id=\"源码解析\"><a href=\"#源码解析\" class=\"headerlink\" title=\"源码解析\"></a>源码解析</h2><p>我们接下来看一下新增的<code>RestProtocol</code>的具体实现。基于之前的分析结果，我们可以直接定位到核心的代码块（doExport）：</p>\n<pre><code>protected &lt;T&gt; Runnable doExport(T impl, Class&lt;T&gt; type, URL url) throws RpcException {\n    String addr = url.getIp() + &quot;:&quot; + url.getPort();\n\n    //这么处理其实是为了配合dubbo的延迟暴露机制，延迟暴露的原理是创建新线程，所以ServiceImplHolder靠ThreadLocal来记录对应的类信息，而不是靠公共变量，避免竞争问题\n    Class implClass = ServiceImplHolder.getInstance().popServiceImpl().getClass();\n\n    //根据url中的地址创建server容器，相同地址的服务使用相同的容器\n    RestServer server = servers.get(addr);\n    if (server == null) {\n        server = serverFactory.createServer(url.getParameter(Constants.SERVER_KEY, &quot;jetty&quot;));   //默认使用jetty，当当推荐使用tomcat\n        server.start(url);\n        servers.put(addr, server);\n    }\n\n    //查看implClass是否包含jax-rs注解\n    final Class resourceDef = GetRestful.getRootResourceClass(implClass) != null ? implClass : type;\n    server.deploy(resourceDef, impl, getContextPath(url));  //在server中部署指定服务\n\n    final RestServer s = server;    //注意这样的写法，java要求线程中只能使用外部final变量\n    return new Runnable() {\n        public void run() {\n            // TODO due to dubbo&apos;s current architecture,\n            // it will be called from registry protocol in the shutdown process and won&apos;t appear in logs\n            s.undeploy(resourceDef);\n        }\n    };\n}\n</code></pre><p>该方法是继承自dubbo原有的<code>AbstractProxyProtocol</code>类：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EvwMF0Rm/Br6Hp.png\" alt=\"\"></p>\n<p>按照dubbo的逻辑，注意该方法最终返回的是一个可异步执行的callback类，完成的逻辑也很简单，就是从对应的server中把指定资源服务给“卸载”掉。</p>\n<p>我们再来关注一下关于<code>server</code>的逻辑，这部分其实很简单，根据你的配置直接创建对应的server：</p>\n<pre><code>public class RestServerFactory {\n\n    private HttpBinder httpBinder;  //提供http服务的容器\n\n    //该方法为SPI注入时调用，会注入一个httpBinder自适应扩展实例\n    public void setHttpBinder(HttpBinder httpBinder) {\n        this.httpBinder = httpBinder;\n    }\n\n    public RestServer createServer(String name) {\n        // TODO move names to Constants\n        if (&quot;servlet&quot;.equalsIgnoreCase(name) || &quot;jetty&quot;.equalsIgnoreCase(name) || &quot;tomcat&quot;.equalsIgnoreCase(name)) {\n            return new DubboHttpServer(httpBinder);\n    //        } else if (&quot;tjws&quot;.equalsIgnoreCase(name)) {\n    //            return new TjwsServer();\n        } else if (&quot;netty&quot;.equalsIgnoreCase(name)) {\n            return new NettyServer();\n        } else if (&quot;sunhttp&quot;.equalsIgnoreCase(name)) {\n            return new SunHttpServer();\n        } else {\n            throw new IllegalArgumentException(&quot;Unrecognized server name: &quot; + name);\n        }\n    }\n}\n</code></pre><p><code>DubboHttpServer</code>类主要贡酒是完成了RESTEasy和servlet容器的绑定，上面代码的<code>httpBinder</code>代表的就是你要使用的容器，例如tomcat。这部分逻辑你需要结合RESTEasy的初始化步骤来理解，我就不多说了。</p>\n<p>tomcat-embed的使用方式，也非常的直观，结合官方提供的例子即可，也不多说了。</p>\n<p>总之，这篇文章还是很水的，不管怎么说，这就是我这几天来的工作内容。更多内容，敬请期待~~</p>"},{"title":"dubbo-admin与多注册中心","date":"2015-04-05T07:54:30.000Z","_content":"\n\ndubbo-admin是否支持同时关联多个注册中心统一管理不同注册中心上注册的服务？\n\n答案是：**不支持**！\n\n<!--more-->\n\n这里指的多注册中心，并不是zookeeper集群，两者的差别看[这里](http://alibaba.github.io/dubbo-doc-static/Multi+Registry-zh.htm)和[这里](http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm)。\n\n[dubbo-admin](http://alibaba.github.io/dubbo-doc-static/Operation+Tutorial-zh.htm)提供了运维界面，辅助我们更好的管理和维护服务之间的依赖等信息。刚认识dubbo时确实被这么逆天的功能给震惊了（现在也是~）。\n\n那么该怎么办呢？目前想到的就只是为每一个注册中心部署一套admin管理后台。确实听起来有些土鳖，但应该是最省事儿的了吧~\n\n当然，也可以改造一下现有的dubbo-admin逻辑，只不过以现在我的道行还做不到啊~坐等高手！\n\n最后还要叮嘱的是，如果你的注册中心和服务之间的网络质量比较差，建议你配置一个较长的timeout时间，否则会出现：\n\n\t...\n\tnested exception is org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 5000\n\t...\n\n这么写：\n\n\t <dubbo:registry protocol=\"zookeeper\" address=\"192.168.76.138:2182,192.168.76.138:2181,192.168.76.138:2183\" timeout=\"100000\"/>\n","source":"_posts/dubbo-admin与多注册中心.md","raw":"title: dubbo-admin与多注册中心\ndate: 2015-04-05 15:54:30\ntags:\n- dubbo\n- zookeeper\n\ncategories: j2ee\n---\n\n\ndubbo-admin是否支持同时关联多个注册中心统一管理不同注册中心上注册的服务？\n\n答案是：**不支持**！\n\n<!--more-->\n\n这里指的多注册中心，并不是zookeeper集群，两者的差别看[这里](http://alibaba.github.io/dubbo-doc-static/Multi+Registry-zh.htm)和[这里](http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm)。\n\n[dubbo-admin](http://alibaba.github.io/dubbo-doc-static/Operation+Tutorial-zh.htm)提供了运维界面，辅助我们更好的管理和维护服务之间的依赖等信息。刚认识dubbo时确实被这么逆天的功能给震惊了（现在也是~）。\n\n那么该怎么办呢？目前想到的就只是为每一个注册中心部署一套admin管理后台。确实听起来有些土鳖，但应该是最省事儿的了吧~\n\n当然，也可以改造一下现有的dubbo-admin逻辑，只不过以现在我的道行还做不到啊~坐等高手！\n\n最后还要叮嘱的是，如果你的注册中心和服务之间的网络质量比较差，建议你配置一个较长的timeout时间，否则会出现：\n\n\t...\n\tnested exception is org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 5000\n\t...\n\n这么写：\n\n\t <dubbo:registry protocol=\"zookeeper\" address=\"192.168.76.138:2182,192.168.76.138:2181,192.168.76.138:2183\" timeout=\"100000\"/>\n","slug":"dubbo-admin与多注册中心","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yrj00bsgtfy8g1o6ehh","comments":1,"layout":"post","photos":[],"link":"","content":"<p>dubbo-admin是否支持同时关联多个注册中心统一管理不同注册中心上注册的服务？</p>\n<p>答案是：<strong>不支持</strong>！</p>\n<a id=\"more\"></a>\n<p>这里指的多注册中心，并不是zookeeper集群，两者的差别看<a href=\"http://alibaba.github.io/dubbo-doc-static/Multi+Registry-zh.htm\" target=\"_blank\" rel=\"external\">这里</a>和<a href=\"http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p><a href=\"http://alibaba.github.io/dubbo-doc-static/Operation+Tutorial-zh.htm\" target=\"_blank\" rel=\"external\">dubbo-admin</a>提供了运维界面，辅助我们更好的管理和维护服务之间的依赖等信息。刚认识dubbo时确实被这么逆天的功能给震惊了（现在也是~）。</p>\n<p>那么该怎么办呢？目前想到的就只是为每一个注册中心部署一套admin管理后台。确实听起来有些土鳖，但应该是最省事儿的了吧~</p>\n<p>当然，也可以改造一下现有的dubbo-admin逻辑，只不过以现在我的道行还做不到啊~坐等高手！</p>\n<p>最后还要叮嘱的是，如果你的注册中心和服务之间的网络质量比较差，建议你配置一个较长的timeout时间，否则会出现：</p>\n<pre><code>...\nnested exception is org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 5000\n...\n</code></pre><p>这么写：</p>\n<pre><code>&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;192.168.76.138:2182,192.168.76.138:2181,192.168.76.138:2183&quot; timeout=&quot;100000&quot;/&gt;\n</code></pre>","excerpt":"<p>dubbo-admin是否支持同时关联多个注册中心统一管理不同注册中心上注册的服务？</p>\n<p>答案是：<strong>不支持</strong>！</p>","more":"<p>这里指的多注册中心，并不是zookeeper集群，两者的差别看<a href=\"http://alibaba.github.io/dubbo-doc-static/Multi+Registry-zh.htm\">这里</a>和<a href=\"http://alibaba.github.io/dubbo-doc-static/Zookeeper+Registry-zh.htm\">这里</a>。</p>\n<p><a href=\"http://alibaba.github.io/dubbo-doc-static/Operation+Tutorial-zh.htm\">dubbo-admin</a>提供了运维界面，辅助我们更好的管理和维护服务之间的依赖等信息。刚认识dubbo时确实被这么逆天的功能给震惊了（现在也是~）。</p>\n<p>那么该怎么办呢？目前想到的就只是为每一个注册中心部署一套admin管理后台。确实听起来有些土鳖，但应该是最省事儿的了吧~</p>\n<p>当然，也可以改造一下现有的dubbo-admin逻辑，只不过以现在我的道行还做不到啊~坐等高手！</p>\n<p>最后还要叮嘱的是，如果你的注册中心和服务之间的网络质量比较差，建议你配置一个较长的timeout时间，否则会出现：</p>\n<pre><code>...\nnested exception is org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 5000\n...\n</code></pre><p>这么写：</p>\n<pre><code>&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;192.168.76.138:2182,192.168.76.138:2181,192.168.76.138:2183&quot; timeout=&quot;100000&quot;/&gt;\n</code></pre>"},{"title":"RequireJS导入cmd模块","date":"2015-05-23T01:37:12.000Z","_content":"\n搞了一段时间的JAVA，又要再一次回归前端技术了，其实这么说也不准确，因为现在的前端技术已经囊括了太多~\n\n这次回来，是为了征服**移动端**，也很可能最后一次为目前的公司征战沙场了（有种说不出道不明预感~）！我一直坚信，应用级别的APP开发套件迟早一定是H5的天下，跨平台永远是人类追求的目标，这个应该是毋庸置疑的！谁能做到真的“跨平台”，谁就能笼络更多的人心。\n<!--more-->\n目前我看到的发展史是：\n\n\tNative --> Hybrid --> H5\n\n虽然这路程并不平坦，反反复复坎坎坷坷，但大方向还是非常明确的~\n\n扯了那么多，今次的主题是AMD和CMD，之所以纠结这两个概念，是因为目前项目中计划开发一些用于封装逻辑的SDK，那么，就需要我们提供各种语言和平台下的SDK，当然这个范围一开始并不会太大，毕竟能力有限。\n\n前端，移动端，Node端我打算实现基于JS的SDK，这就要求在项目模块化组织时选择一个通用性更强的标准，一开始打算使用RequireJS，因为目前公司的项目中使用的就是它，不过，它是基于AMD概念的，也就是说更偏重于前端，不过，还好，RequireJS可以兼容基于CMD概念实现的模块，下面我看一个例子：\n\n\n\tProject\n\t\t|-index.html\n\t\t|-main.js\n\t\t|-scripts\n\t\t|\t|-require.js\n\t\t|-lib\n\t\t\t|-foo\n\t\t\t|\t|-main.js\n\t\t\t|-bar\n\t\t\t\t|-main.js\n\nindex.html\n\n\t<!DOCTYPE html>\n\t<html>\n\t<head><title></title></head>\n\t<body>\n\t<script data-main=\"./main\" src=\"scripts/require.js\"></script>\n\t</body>\n\t</html>\n\nmain.js\n\n\trequire.config({\n\t\tbaseUrl: \"./lib\", //所有模块的base URL,注意，以.js结尾的文件加载时不会使用该baseUrl\n\t\tpackages:[\"foo\",\"bar\"],\t//需要把所有CMD的模块都声明在这里\n\t\twaitSeconds: 10   //waitSeconds是指定最多花多长等待时间来加载一个JavaScript文件，用户不指定的情况下默认为7秒\n\t});\n\t\n\trequire([\"foo\"],function(foo){\n\t\tconsole.log(\"test\");\n\t\tfoo.log();\n\t});\n\nlib/foo/main.js\n\n\tdefine(function(require, exports, module){\n\t\texports.name = \"foo\";\n\t\texports.log = function(){\n\t\t\tconsole.log(this.name);\n\t\t}\n\t\n\t\tvar bar = require(\"bar\");\n\t\tbar.log();\n\t\n\t});\n\nlib/bar/main.js\n\n\tdefine(function(require, exports, module){\n\t\texports.name = \"bar\";\n\t\texports.log = function(){\n\t\t\tconsole.log(this.name);\n\t\t}\n\t});\n\n代码很简单，直接放在web目录下测试即可，运行看一下控制台的输出：\n\n\tbar\n\ttest\n\tfoo\n\n留意一下输出的顺序，“bar”甚至再“test”之前，这是为什么呢？理由很简单，因为`foo`模块被main.js依赖，所以requireJS会先加载并执行它，这个时候发现`foo`模块又依赖`bar`模块，所以会先去加载`bar`模块，加载完毕后执行`foo`模块中写的逻辑，这个时候会打印出“bar”，接下来，main.js的回调逻辑会执行，打印“test”，然后再调用“foo.log()”打印最后的“foo”。\n\n这样，我们就可以把SDK以CMD规范来编写，将来用于多种场景~\n\n参考：\n\n[RequireJS 中文网](http://www.requirejs.cn/#show-last-Point)\n\n[CMD 模块定义规范](https://github.com/seajs/seajs/issues/242)","source":"_posts/RequireJS导入CMD模块.md","raw":"title: RequireJS导入cmd模块\ndate: 2015-05-23 09:37:12\ntags: \n- amd\n- cmd\n- RequireJS\ncategories: 前端\n---\n\n搞了一段时间的JAVA，又要再一次回归前端技术了，其实这么说也不准确，因为现在的前端技术已经囊括了太多~\n\n这次回来，是为了征服**移动端**，也很可能最后一次为目前的公司征战沙场了（有种说不出道不明预感~）！我一直坚信，应用级别的APP开发套件迟早一定是H5的天下，跨平台永远是人类追求的目标，这个应该是毋庸置疑的！谁能做到真的“跨平台”，谁就能笼络更多的人心。\n<!--more-->\n目前我看到的发展史是：\n\n\tNative --> Hybrid --> H5\n\n虽然这路程并不平坦，反反复复坎坎坷坷，但大方向还是非常明确的~\n\n扯了那么多，今次的主题是AMD和CMD，之所以纠结这两个概念，是因为目前项目中计划开发一些用于封装逻辑的SDK，那么，就需要我们提供各种语言和平台下的SDK，当然这个范围一开始并不会太大，毕竟能力有限。\n\n前端，移动端，Node端我打算实现基于JS的SDK，这就要求在项目模块化组织时选择一个通用性更强的标准，一开始打算使用RequireJS，因为目前公司的项目中使用的就是它，不过，它是基于AMD概念的，也就是说更偏重于前端，不过，还好，RequireJS可以兼容基于CMD概念实现的模块，下面我看一个例子：\n\n\n\tProject\n\t\t|-index.html\n\t\t|-main.js\n\t\t|-scripts\n\t\t|\t|-require.js\n\t\t|-lib\n\t\t\t|-foo\n\t\t\t|\t|-main.js\n\t\t\t|-bar\n\t\t\t\t|-main.js\n\nindex.html\n\n\t<!DOCTYPE html>\n\t<html>\n\t<head><title></title></head>\n\t<body>\n\t<script data-main=\"./main\" src=\"scripts/require.js\"></script>\n\t</body>\n\t</html>\n\nmain.js\n\n\trequire.config({\n\t\tbaseUrl: \"./lib\", //所有模块的base URL,注意，以.js结尾的文件加载时不会使用该baseUrl\n\t\tpackages:[\"foo\",\"bar\"],\t//需要把所有CMD的模块都声明在这里\n\t\twaitSeconds: 10   //waitSeconds是指定最多花多长等待时间来加载一个JavaScript文件，用户不指定的情况下默认为7秒\n\t});\n\t\n\trequire([\"foo\"],function(foo){\n\t\tconsole.log(\"test\");\n\t\tfoo.log();\n\t});\n\nlib/foo/main.js\n\n\tdefine(function(require, exports, module){\n\t\texports.name = \"foo\";\n\t\texports.log = function(){\n\t\t\tconsole.log(this.name);\n\t\t}\n\t\n\t\tvar bar = require(\"bar\");\n\t\tbar.log();\n\t\n\t});\n\nlib/bar/main.js\n\n\tdefine(function(require, exports, module){\n\t\texports.name = \"bar\";\n\t\texports.log = function(){\n\t\t\tconsole.log(this.name);\n\t\t}\n\t});\n\n代码很简单，直接放在web目录下测试即可，运行看一下控制台的输出：\n\n\tbar\n\ttest\n\tfoo\n\n留意一下输出的顺序，“bar”甚至再“test”之前，这是为什么呢？理由很简单，因为`foo`模块被main.js依赖，所以requireJS会先加载并执行它，这个时候发现`foo`模块又依赖`bar`模块，所以会先去加载`bar`模块，加载完毕后执行`foo`模块中写的逻辑，这个时候会打印出“bar”，接下来，main.js的回调逻辑会执行，打印“test”，然后再调用“foo.log()”打印最后的“foo”。\n\n这样，我们就可以把SDK以CMD规范来编写，将来用于多种场景~\n\n参考：\n\n[RequireJS 中文网](http://www.requirejs.cn/#show-last-Point)\n\n[CMD 模块定义规范](https://github.com/seajs/seajs/issues/242)","slug":"RequireJS导入CMD模块","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yrn00bwgtfycdnbh19f","comments":1,"layout":"post","photos":[],"link":"","content":"<p>搞了一段时间的JAVA，又要再一次回归前端技术了，其实这么说也不准确，因为现在的前端技术已经囊括了太多~</p>\n<p>这次回来，是为了征服<strong>移动端</strong>，也很可能最后一次为目前的公司征战沙场了（有种说不出道不明预感~）！我一直坚信，应用级别的APP开发套件迟早一定是H5的天下，跨平台永远是人类追求的目标，这个应该是毋庸置疑的！谁能做到真的“跨平台”，谁就能笼络更多的人心。<br><a id=\"more\"></a><br>目前我看到的发展史是：</p>\n<pre><code>Native --&gt; Hybrid --&gt; H5\n</code></pre><p>虽然这路程并不平坦，反反复复坎坎坷坷，但大方向还是非常明确的~</p>\n<p>扯了那么多，今次的主题是AMD和CMD，之所以纠结这两个概念，是因为目前项目中计划开发一些用于封装逻辑的SDK，那么，就需要我们提供各种语言和平台下的SDK，当然这个范围一开始并不会太大，毕竟能力有限。</p>\n<p>前端，移动端，Node端我打算实现基于JS的SDK，这就要求在项目模块化组织时选择一个通用性更强的标准，一开始打算使用RequireJS，因为目前公司的项目中使用的就是它，不过，它是基于AMD概念的，也就是说更偏重于前端，不过，还好，RequireJS可以兼容基于CMD概念实现的模块，下面我看一个例子：</p>\n<pre><code>Project\n    |-index.html\n    |-main.js\n    |-scripts\n    |    |-require.js\n    |-lib\n        |-foo\n        |    |-main.js\n        |-bar\n            |-main.js\n</code></pre><p>index.html</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n&lt;script data-main=&quot;./main&quot; src=&quot;scripts/require.js&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>main.js</p>\n<pre><code>require.config({\n    baseUrl: &quot;./lib&quot;, //所有模块的base URL,注意，以.js结尾的文件加载时不会使用该baseUrl\n    packages:[&quot;foo&quot;,&quot;bar&quot;],    //需要把所有CMD的模块都声明在这里\n    waitSeconds: 10   //waitSeconds是指定最多花多长等待时间来加载一个JavaScript文件，用户不指定的情况下默认为7秒\n});\n\nrequire([&quot;foo&quot;],function(foo){\n    console.log(&quot;test&quot;);\n    foo.log();\n});\n</code></pre><p>lib/foo/main.js</p>\n<pre><code>define(function(require, exports, module){\n    exports.name = &quot;foo&quot;;\n    exports.log = function(){\n        console.log(this.name);\n    }\n\n    var bar = require(&quot;bar&quot;);\n    bar.log();\n\n});\n</code></pre><p>lib/bar/main.js</p>\n<pre><code>define(function(require, exports, module){\n    exports.name = &quot;bar&quot;;\n    exports.log = function(){\n        console.log(this.name);\n    }\n});\n</code></pre><p>代码很简单，直接放在web目录下测试即可，运行看一下控制台的输出：</p>\n<pre><code>bar\ntest\nfoo\n</code></pre><p>留意一下输出的顺序，“bar”甚至再“test”之前，这是为什么呢？理由很简单，因为<code>foo</code>模块被main.js依赖，所以requireJS会先加载并执行它，这个时候发现<code>foo</code>模块又依赖<code>bar</code>模块，所以会先去加载<code>bar</code>模块，加载完毕后执行<code>foo</code>模块中写的逻辑，这个时候会打印出“bar”，接下来，main.js的回调逻辑会执行，打印“test”，然后再调用“foo.log()”打印最后的“foo”。</p>\n<p>这样，我们就可以把SDK以CMD规范来编写，将来用于多种场景~</p>\n<p>参考：</p>\n<p><a href=\"http://www.requirejs.cn/#show-last-Point\" target=\"_blank\" rel=\"external\">RequireJS 中文网</a></p>\n<p><a href=\"https://github.com/seajs/seajs/issues/242\" target=\"_blank\" rel=\"external\">CMD 模块定义规范</a></p>\n","excerpt":"<p>搞了一段时间的JAVA，又要再一次回归前端技术了，其实这么说也不准确，因为现在的前端技术已经囊括了太多~</p>\n<p>这次回来，是为了征服<strong>移动端</strong>，也很可能最后一次为目前的公司征战沙场了（有种说不出道不明预感~）！我一直坚信，应用级别的APP开发套件迟早一定是H5的天下，跨平台永远是人类追求的目标，这个应该是毋庸置疑的！谁能做到真的“跨平台”，谁就能笼络更多的人心。<br>","more":"<br>目前我看到的发展史是：</p>\n<pre><code>Native --&gt; Hybrid --&gt; H5\n</code></pre><p>虽然这路程并不平坦，反反复复坎坎坷坷，但大方向还是非常明确的~</p>\n<p>扯了那么多，今次的主题是AMD和CMD，之所以纠结这两个概念，是因为目前项目中计划开发一些用于封装逻辑的SDK，那么，就需要我们提供各种语言和平台下的SDK，当然这个范围一开始并不会太大，毕竟能力有限。</p>\n<p>前端，移动端，Node端我打算实现基于JS的SDK，这就要求在项目模块化组织时选择一个通用性更强的标准，一开始打算使用RequireJS，因为目前公司的项目中使用的就是它，不过，它是基于AMD概念的，也就是说更偏重于前端，不过，还好，RequireJS可以兼容基于CMD概念实现的模块，下面我看一个例子：</p>\n<pre><code>Project\n    |-index.html\n    |-main.js\n    |-scripts\n    |    |-require.js\n    |-lib\n        |-foo\n        |    |-main.js\n        |-bar\n            |-main.js\n</code></pre><p>index.html</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n&lt;script data-main=&quot;./main&quot; src=&quot;scripts/require.js&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>main.js</p>\n<pre><code>require.config({\n    baseUrl: &quot;./lib&quot;, //所有模块的base URL,注意，以.js结尾的文件加载时不会使用该baseUrl\n    packages:[&quot;foo&quot;,&quot;bar&quot;],    //需要把所有CMD的模块都声明在这里\n    waitSeconds: 10   //waitSeconds是指定最多花多长等待时间来加载一个JavaScript文件，用户不指定的情况下默认为7秒\n});\n\nrequire([&quot;foo&quot;],function(foo){\n    console.log(&quot;test&quot;);\n    foo.log();\n});\n</code></pre><p>lib/foo/main.js</p>\n<pre><code>define(function(require, exports, module){\n    exports.name = &quot;foo&quot;;\n    exports.log = function(){\n        console.log(this.name);\n    }\n\n    var bar = require(&quot;bar&quot;);\n    bar.log();\n\n});\n</code></pre><p>lib/bar/main.js</p>\n<pre><code>define(function(require, exports, module){\n    exports.name = &quot;bar&quot;;\n    exports.log = function(){\n        console.log(this.name);\n    }\n});\n</code></pre><p>代码很简单，直接放在web目录下测试即可，运行看一下控制台的输出：</p>\n<pre><code>bar\ntest\nfoo\n</code></pre><p>留意一下输出的顺序，“bar”甚至再“test”之前，这是为什么呢？理由很简单，因为<code>foo</code>模块被main.js依赖，所以requireJS会先加载并执行它，这个时候发现<code>foo</code>模块又依赖<code>bar</code>模块，所以会先去加载<code>bar</code>模块，加载完毕后执行<code>foo</code>模块中写的逻辑，这个时候会打印出“bar”，接下来，main.js的回调逻辑会执行，打印“test”，然后再调用“foo.log()”打印最后的“foo”。</p>\n<p>这样，我们就可以把SDK以CMD规范来编写，将来用于多种场景~</p>\n<p>参考：</p>\n<p><a href=\"http://www.requirejs.cn/#show-last-Point\">RequireJS 中文网</a></p>\n<p><a href=\"https://github.com/seajs/seajs/issues/242\">CMD 模块定义规范</a></p>"},{"title":"React和flux初学","date":"2015-05-24T01:37:12.000Z","_content":"\n身为一个刚满三十岁的程序猿（还差2个月），我婶婶的体会到技术的无止境，这是一件多么有挑战的工作啊~\n\n这几天花时间看了一下ReactJS，感觉确实是个不错的思想，之前在公司内部推广AngularJS，虽然基本上已经在团队内部普及了MVVM的理念，但**组件化**还是做得一塌糊涂啊~\n<!--more-->\n初学ReactJS，最大的感触就是组件化的那叫一个彻底~以我目前的了解，尽管无法说出其AngularJS指令的功能差异，但至少在理念上，ReactJS更接近趋势一些~\n\n老实讲，原先认为可能要花很久来学习ReactJS，但没想到粗略的看了两天文档，就对其有了一个比较全面的了解，相比Angular确实有更好的学习曲线~\n\n其实原本的目的是为了`React-Native`，但现在对React本身就产生了非常大的兴趣，入门教程强烈推荐：[阮一峰的分享](http://www.ruanyifeng.com/blog/2015/03/react.html)。相信你看完以后，基本上就对React有了一个较为完整的了解，再花点时间啃一下[官方文档](http://reactjs.cn/react/docs/getting-started.html)，基本上就可以看懂简单的项目了……\n\n为什么说**简单的项目**呢？因为很少有实际项目是仅使用基础React就完成全部的，原因是因为：\n\n> React仅仅是UI\n\n其实这也是我一开始的疑惑，相比Angular提供整套的路由，控制器，作用域等概念，React简直太轻了，甚至可以说是缺乏必要的功能（当然，这都是个人观点~）。\n\n正因如此，Facebook又进一步推出了一个思想：[Flux](http://zhuanlan.zhihu.com/FrontendMagazine/19900243#show-last-Point)。其宣扬**单向数据流**，让我这个当时震撼于“双向绑定”的童鞋又一次被撼动（小人物就是这样，永远只能追赶大牛）~\n\n观望了一下社区，发现大家又各自选择自己中意的Flux具体实现（Flux更合适被当做一种思想，而非实现），这里有一个[项目](https://github.com/voronianski/flux-comparison)，用来对比各种具体实现的差异。简直太宏伟了，感觉一辈子也看不完的资料啊，最后我选择的是：[Refluxjs](https://github.com/spoike/refluxjs)。这个看起来还是非常亲切的，相比Facebook提供的原版Flux，要“简单”很多~\n\n现在，基本上可以看懂中大型项目了，但貌似还少了点啥，路由，没错，就是每个传统web项目非常重要的一环，不过不要怕，也已经有非常强大的扩展来帮我们完成：[React-router](http://rackt.github.io/react-router/)。\n\n总结下来，感觉要比angular轻量很多（至少在概念上），下一个小项目中我感觉自己会尝试一下它~\n\nPS：貌似Facebook在推一个新的React框架（应该算框架吧）：[Relay](http://segmentfault.com/a/1190000002570887)，强大的一笔~","source":"_posts/React和flux初尝心得.md","raw":"title: React和flux初学\ndate: 2015-05-24 09:37:12\ntags: \n- react\n- flux\n- mvvm\ncategories: 前端\n---\n\n身为一个刚满三十岁的程序猿（还差2个月），我婶婶的体会到技术的无止境，这是一件多么有挑战的工作啊~\n\n这几天花时间看了一下ReactJS，感觉确实是个不错的思想，之前在公司内部推广AngularJS，虽然基本上已经在团队内部普及了MVVM的理念，但**组件化**还是做得一塌糊涂啊~\n<!--more-->\n初学ReactJS，最大的感触就是组件化的那叫一个彻底~以我目前的了解，尽管无法说出其AngularJS指令的功能差异，但至少在理念上，ReactJS更接近趋势一些~\n\n老实讲，原先认为可能要花很久来学习ReactJS，但没想到粗略的看了两天文档，就对其有了一个比较全面的了解，相比Angular确实有更好的学习曲线~\n\n其实原本的目的是为了`React-Native`，但现在对React本身就产生了非常大的兴趣，入门教程强烈推荐：[阮一峰的分享](http://www.ruanyifeng.com/blog/2015/03/react.html)。相信你看完以后，基本上就对React有了一个较为完整的了解，再花点时间啃一下[官方文档](http://reactjs.cn/react/docs/getting-started.html)，基本上就可以看懂简单的项目了……\n\n为什么说**简单的项目**呢？因为很少有实际项目是仅使用基础React就完成全部的，原因是因为：\n\n> React仅仅是UI\n\n其实这也是我一开始的疑惑，相比Angular提供整套的路由，控制器，作用域等概念，React简直太轻了，甚至可以说是缺乏必要的功能（当然，这都是个人观点~）。\n\n正因如此，Facebook又进一步推出了一个思想：[Flux](http://zhuanlan.zhihu.com/FrontendMagazine/19900243#show-last-Point)。其宣扬**单向数据流**，让我这个当时震撼于“双向绑定”的童鞋又一次被撼动（小人物就是这样，永远只能追赶大牛）~\n\n观望了一下社区，发现大家又各自选择自己中意的Flux具体实现（Flux更合适被当做一种思想，而非实现），这里有一个[项目](https://github.com/voronianski/flux-comparison)，用来对比各种具体实现的差异。简直太宏伟了，感觉一辈子也看不完的资料啊，最后我选择的是：[Refluxjs](https://github.com/spoike/refluxjs)。这个看起来还是非常亲切的，相比Facebook提供的原版Flux，要“简单”很多~\n\n现在，基本上可以看懂中大型项目了，但貌似还少了点啥，路由，没错，就是每个传统web项目非常重要的一环，不过不要怕，也已经有非常强大的扩展来帮我们完成：[React-router](http://rackt.github.io/react-router/)。\n\n总结下来，感觉要比angular轻量很多（至少在概念上），下一个小项目中我感觉自己会尝试一下它~\n\nPS：貌似Facebook在推一个新的React框架（应该算框架吧）：[Relay](http://segmentfault.com/a/1190000002570887)，强大的一笔~","slug":"React和flux初尝心得","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yrr00c4gtfycwwzw3ch","comments":1,"layout":"post","photos":[],"link":"","content":"<p>身为一个刚满三十岁的程序猿（还差2个月），我婶婶的体会到技术的无止境，这是一件多么有挑战的工作啊~</p>\n<p>这几天花时间看了一下ReactJS，感觉确实是个不错的思想，之前在公司内部推广AngularJS，虽然基本上已经在团队内部普及了MVVM的理念，但<strong>组件化</strong>还是做得一塌糊涂啊~<br><a id=\"more\"></a><br>初学ReactJS，最大的感触就是组件化的那叫一个彻底~以我目前的了解，尽管无法说出其AngularJS指令的功能差异，但至少在理念上，ReactJS更接近趋势一些~</p>\n<p>老实讲，原先认为可能要花很久来学习ReactJS，但没想到粗略的看了两天文档，就对其有了一个比较全面的了解，相比Angular确实有更好的学习曲线~</p>\n<p>其实原本的目的是为了<code>React-Native</code>，但现在对React本身就产生了非常大的兴趣，入门教程强烈推荐：<a href=\"http://www.ruanyifeng.com/blog/2015/03/react.html\" target=\"_blank\" rel=\"external\">阮一峰的分享</a>。相信你看完以后，基本上就对React有了一个较为完整的了解，再花点时间啃一下<a href=\"http://reactjs.cn/react/docs/getting-started.html\" target=\"_blank\" rel=\"external\">官方文档</a>，基本上就可以看懂简单的项目了……</p>\n<p>为什么说<strong>简单的项目</strong>呢？因为很少有实际项目是仅使用基础React就完成全部的，原因是因为：</p>\n<blockquote>\n<p>React仅仅是UI</p>\n</blockquote>\n<p>其实这也是我一开始的疑惑，相比Angular提供整套的路由，控制器，作用域等概念，React简直太轻了，甚至可以说是缺乏必要的功能（当然，这都是个人观点~）。</p>\n<p>正因如此，Facebook又进一步推出了一个思想：<a href=\"http://zhuanlan.zhihu.com/FrontendMagazine/19900243#show-last-Point\" target=\"_blank\" rel=\"external\">Flux</a>。其宣扬<strong>单向数据流</strong>，让我这个当时震撼于“双向绑定”的童鞋又一次被撼动（小人物就是这样，永远只能追赶大牛）~</p>\n<p>观望了一下社区，发现大家又各自选择自己中意的Flux具体实现（Flux更合适被当做一种思想，而非实现），这里有一个<a href=\"https://github.com/voronianski/flux-comparison\" target=\"_blank\" rel=\"external\">项目</a>，用来对比各种具体实现的差异。简直太宏伟了，感觉一辈子也看不完的资料啊，最后我选择的是：<a href=\"https://github.com/spoike/refluxjs\" target=\"_blank\" rel=\"external\">Refluxjs</a>。这个看起来还是非常亲切的，相比Facebook提供的原版Flux，要“简单”很多~</p>\n<p>现在，基本上可以看懂中大型项目了，但貌似还少了点啥，路由，没错，就是每个传统web项目非常重要的一环，不过不要怕，也已经有非常强大的扩展来帮我们完成：<a href=\"http://rackt.github.io/react-router/\" target=\"_blank\" rel=\"external\">React-router</a>。</p>\n<p>总结下来，感觉要比angular轻量很多（至少在概念上），下一个小项目中我感觉自己会尝试一下它~</p>\n<p>PS：貌似Facebook在推一个新的React框架（应该算框架吧）：<a href=\"http://segmentfault.com/a/1190000002570887\" target=\"_blank\" rel=\"external\">Relay</a>，强大的一笔~</p>\n","excerpt":"<p>身为一个刚满三十岁的程序猿（还差2个月），我婶婶的体会到技术的无止境，这是一件多么有挑战的工作啊~</p>\n<p>这几天花时间看了一下ReactJS，感觉确实是个不错的思想，之前在公司内部推广AngularJS，虽然基本上已经在团队内部普及了MVVM的理念，但<strong>组件化</strong>还是做得一塌糊涂啊~<br>","more":"<br>初学ReactJS，最大的感触就是组件化的那叫一个彻底~以我目前的了解，尽管无法说出其AngularJS指令的功能差异，但至少在理念上，ReactJS更接近趋势一些~</p>\n<p>老实讲，原先认为可能要花很久来学习ReactJS，但没想到粗略的看了两天文档，就对其有了一个比较全面的了解，相比Angular确实有更好的学习曲线~</p>\n<p>其实原本的目的是为了<code>React-Native</code>，但现在对React本身就产生了非常大的兴趣，入门教程强烈推荐：<a href=\"http://www.ruanyifeng.com/blog/2015/03/react.html\">阮一峰的分享</a>。相信你看完以后，基本上就对React有了一个较为完整的了解，再花点时间啃一下<a href=\"http://reactjs.cn/react/docs/getting-started.html\">官方文档</a>，基本上就可以看懂简单的项目了……</p>\n<p>为什么说<strong>简单的项目</strong>呢？因为很少有实际项目是仅使用基础React就完成全部的，原因是因为：</p>\n<blockquote>\n<p>React仅仅是UI</p>\n</blockquote>\n<p>其实这也是我一开始的疑惑，相比Angular提供整套的路由，控制器，作用域等概念，React简直太轻了，甚至可以说是缺乏必要的功能（当然，这都是个人观点~）。</p>\n<p>正因如此，Facebook又进一步推出了一个思想：<a href=\"http://zhuanlan.zhihu.com/FrontendMagazine/19900243#show-last-Point\">Flux</a>。其宣扬<strong>单向数据流</strong>，让我这个当时震撼于“双向绑定”的童鞋又一次被撼动（小人物就是这样，永远只能追赶大牛）~</p>\n<p>观望了一下社区，发现大家又各自选择自己中意的Flux具体实现（Flux更合适被当做一种思想，而非实现），这里有一个<a href=\"https://github.com/voronianski/flux-comparison\">项目</a>，用来对比各种具体实现的差异。简直太宏伟了，感觉一辈子也看不完的资料啊，最后我选择的是：<a href=\"https://github.com/spoike/refluxjs\">Refluxjs</a>。这个看起来还是非常亲切的，相比Facebook提供的原版Flux，要“简单”很多~</p>\n<p>现在，基本上可以看懂中大型项目了，但貌似还少了点啥，路由，没错，就是每个传统web项目非常重要的一环，不过不要怕，也已经有非常强大的扩展来帮我们完成：<a href=\"http://rackt.github.io/react-router/\">React-router</a>。</p>\n<p>总结下来，感觉要比angular轻量很多（至少在概念上），下一个小项目中我感觉自己会尝试一下它~</p>\n<p>PS：貌似Facebook在推一个新的React框架（应该算框架吧）：<a href=\"http://segmentfault.com/a/1190000002570887\">Relay</a>，强大的一笔~</p>"},{"title":"ReactNative的Image","date":"2015-05-25T01:37:12.000Z","_content":"\n今天就聊一个问题，React Native的Image读取本地图片的方法。（甚少见我如此不罗嗦了吧？那是因为真的没时间啊……）\n\n按照官方[文档](http://facebook.github.io/react-native/docs/image.html#content)中的描述，RCT（React Native）中考虑到诸多原因，提供了一种快速获取本地图片资源的方法：`require('image!你的图片名称')`。\n<!--more-->\n看上去很简单，但对于我这种移动端开发小白来说，简单的有点简陋了，首先，我们要从如何把本地图片导入到项目说起，在xcode的文件导航栏，找到你的项目文件夹，点击其中的“Images.xcassets”，然后你就会看到右边工作区界面，然后直接把你想导入的本地图片直接拖入工作区即可，具体步骤可参见[这里](http://www.cocoachina.com/ios/20141210/10587.html)，虽然该帖子的xcode版本不是最新的，但步骤没啥问题。\n\n这里注意的是，我们只能导入**png**，这可能并不是xcode要求的，但是RCT只会去读取png图片～～此外，我在导入的时候，xcode总是提醒我**权限不够**，你只需要修改“Images.xcassets”文件的权限即可，如下图：\n\n![](http://pic.yupoo.com/kazaff/EFjwGAwJ/UVRDA.png)\n\n好了，接下来你就可以使用官方提供的代码实例测试了：\n\n\treturn (\n    \t<View>\n      \t\t<Image\n        \t\tstyle={styles.icon}\n        \t\tsource={require('image!myIcon')}\n      \t\t/>\n    \t</View>\n    );\n    \n你会发现，图片竟然还是没有显示，这是为什么呢？告诉你，你还需要重新编译项目哦，简单的依靠RCT提供的动态刷新是无法加载你刚新增的本地资源的～\n\nok，按照我的描述，你应该就不会遇到下面这个头疼的报错了：\n\n![](http://i.stack.imgur.com/SvCdg.png)","source":"_posts/ReactNative的Image.md","raw":"title: ReactNative的Image\ndate: 2015-05-25 09:37:12\ntags: \n- ReactNative\n- xcode\n- 权限\ncategories: 前端\n---\n\n今天就聊一个问题，React Native的Image读取本地图片的方法。（甚少见我如此不罗嗦了吧？那是因为真的没时间啊……）\n\n按照官方[文档](http://facebook.github.io/react-native/docs/image.html#content)中的描述，RCT（React Native）中考虑到诸多原因，提供了一种快速获取本地图片资源的方法：`require('image!你的图片名称')`。\n<!--more-->\n看上去很简单，但对于我这种移动端开发小白来说，简单的有点简陋了，首先，我们要从如何把本地图片导入到项目说起，在xcode的文件导航栏，找到你的项目文件夹，点击其中的“Images.xcassets”，然后你就会看到右边工作区界面，然后直接把你想导入的本地图片直接拖入工作区即可，具体步骤可参见[这里](http://www.cocoachina.com/ios/20141210/10587.html)，虽然该帖子的xcode版本不是最新的，但步骤没啥问题。\n\n这里注意的是，我们只能导入**png**，这可能并不是xcode要求的，但是RCT只会去读取png图片～～此外，我在导入的时候，xcode总是提醒我**权限不够**，你只需要修改“Images.xcassets”文件的权限即可，如下图：\n\n![](http://pic.yupoo.com/kazaff/EFjwGAwJ/UVRDA.png)\n\n好了，接下来你就可以使用官方提供的代码实例测试了：\n\n\treturn (\n    \t<View>\n      \t\t<Image\n        \t\tstyle={styles.icon}\n        \t\tsource={require('image!myIcon')}\n      \t\t/>\n    \t</View>\n    );\n    \n你会发现，图片竟然还是没有显示，这是为什么呢？告诉你，你还需要重新编译项目哦，简单的依靠RCT提供的动态刷新是无法加载你刚新增的本地资源的～\n\nok，按照我的描述，你应该就不会遇到下面这个头疼的报错了：\n\n![](http://i.stack.imgur.com/SvCdg.png)","slug":"ReactNative的Image","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ys000ccgtfywbspz2iw","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天就聊一个问题，React Native的Image读取本地图片的方法。（甚少见我如此不罗嗦了吧？那是因为真的没时间啊……）</p>\n<p>按照官方<a href=\"http://facebook.github.io/react-native/docs/image.html#content\" target=\"_blank\" rel=\"external\">文档</a>中的描述，RCT（React Native）中考虑到诸多原因，提供了一种快速获取本地图片资源的方法：<code>require(&#39;image!你的图片名称&#39;)</code>。<br><a id=\"more\"></a><br>看上去很简单，但对于我这种移动端开发小白来说，简单的有点简陋了，首先，我们要从如何把本地图片导入到项目说起，在xcode的文件导航栏，找到你的项目文件夹，点击其中的“Images.xcassets”，然后你就会看到右边工作区界面，然后直接把你想导入的本地图片直接拖入工作区即可，具体步骤可参见<a href=\"http://www.cocoachina.com/ios/20141210/10587.html\" target=\"_blank\" rel=\"external\">这里</a>，虽然该帖子的xcode版本不是最新的，但步骤没啥问题。</p>\n<p>这里注意的是，我们只能导入<strong>png</strong>，这可能并不是xcode要求的，但是RCT只会去读取png图片～～此外，我在导入的时候，xcode总是提醒我<strong>权限不够</strong>，你只需要修改“Images.xcassets”文件的权限即可，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EFjwGAwJ/UVRDA.png\" alt=\"\"></p>\n<p>好了，接下来你就可以使用官方提供的代码实例测试了：</p>\n<pre><code>return (\n    &lt;View&gt;\n          &lt;Image\n            style={styles.icon}\n            source={require(&apos;image!myIcon&apos;)}\n          /&gt;\n    &lt;/View&gt;\n);\n</code></pre><p>你会发现，图片竟然还是没有显示，这是为什么呢？告诉你，你还需要重新编译项目哦，简单的依靠RCT提供的动态刷新是无法加载你刚新增的本地资源的～</p>\n<p>ok，按照我的描述，你应该就不会遇到下面这个头疼的报错了：</p>\n<p><img src=\"http://i.stack.imgur.com/SvCdg.png\" alt=\"\"></p>\n","excerpt":"<p>今天就聊一个问题，React Native的Image读取本地图片的方法。（甚少见我如此不罗嗦了吧？那是因为真的没时间啊……）</p>\n<p>按照官方<a href=\"http://facebook.github.io/react-native/docs/image.html#content\">文档</a>中的描述，RCT（React Native）中考虑到诸多原因，提供了一种快速获取本地图片资源的方法：<code>require(&#39;image!你的图片名称&#39;)</code>。<br>","more":"<br>看上去很简单，但对于我这种移动端开发小白来说，简单的有点简陋了，首先，我们要从如何把本地图片导入到项目说起，在xcode的文件导航栏，找到你的项目文件夹，点击其中的“Images.xcassets”，然后你就会看到右边工作区界面，然后直接把你想导入的本地图片直接拖入工作区即可，具体步骤可参见<a href=\"http://www.cocoachina.com/ios/20141210/10587.html\">这里</a>，虽然该帖子的xcode版本不是最新的，但步骤没啥问题。</p>\n<p>这里注意的是，我们只能导入<strong>png</strong>，这可能并不是xcode要求的，但是RCT只会去读取png图片～～此外，我在导入的时候，xcode总是提醒我<strong>权限不够</strong>，你只需要修改“Images.xcassets”文件的权限即可，如下图：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/EFjwGAwJ/UVRDA.png\" alt=\"\"></p>\n<p>好了，接下来你就可以使用官方提供的代码实例测试了：</p>\n<pre><code>return (\n    &lt;View&gt;\n          &lt;Image\n            style={styles.icon}\n            source={require(&apos;image!myIcon&apos;)}\n          /&gt;\n    &lt;/View&gt;\n);\n</code></pre><p>你会发现，图片竟然还是没有显示，这是为什么呢？告诉你，你还需要重新编译项目哦，简单的依靠RCT提供的动态刷新是无法加载你刚新增的本地资源的～</p>\n<p>ok，按照我的描述，你应该就不会遇到下面这个头疼的报错了：</p>\n<p><img src=\"http://i.stack.imgur.com/SvCdg.png\" alt=\"\"></p>"},{"title":"No WebApplicationContext found","date":"2014-12-09T03:13:12.000Z","_content":"\n\n> No WebApplicationContext found: no ContextLoaderListener registered?\n\n上面个异常信息可把我给坑苦了，整整一下午啊，外加一晚上。其实吧，问题不在于人家这个报错，你瞅瞅，多体贴，甚至都加上了人性化的提醒，相对其他异常信息来说，这已经很友好了不是么？\n<!--more-->\n先来简单说一下问题场景吧：**我的目的很直白，就是想在Servlet的Filter中使用Spring的Ioc注入指定的Bean**。\n\n怎么样，直白的都要哭了！\n\n对于我这种新手，确实一开始是不知道Filter中是无法使用spring的依赖注入的，原因很简单，因为Filter并不受spring管理，自然无法使用Ioc了！不过，我又不能直接“new”想用的bean，因为最终我的bean会使用依赖注入相关的资源！\n\n要说这种需求一点儿都不偏门，gg上一搜一大把：[苦逼版](http://zy116494718.iteye.com/blog/1918131)，[二逼版](http://blog.csdn.net/geloin/article/details/7441937)。\n\n苦逼版其实也挺好的，简单明了，不过对我这种强迫症患者来说，总感觉难受，可能是由于手动调用`getBean()`的缘故吧～我也不清楚，反正难受！\n\n着重来说说这个二逼版，`DelegatingFilterProxy`这个类就是spring专门针对我们的问题场景量身定做的一个现成的实现版本，其实TA内部会帮我们调用苦逼版中的相关代码，有兴趣的同学强烈推荐看看[源码](http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/filter/DelegatingFilterProxy.java#DelegatingFilterProxy.doFilter%28%29)。\n\n我就是由于白天浮躁的环境让我一不小心上了鬼子的当！我其实是一个温文尔雅的人，真真儿的。但我现在杀人的心都有！如果你点开了我上面提供的二逼版链接，那你留意一下TA的这句话：\n\n>  (1) contextAttribute，使用委派Bean的范围，其值必须从org.springframework.context.ApplicationContext.WebApplicationContext中取得，默认值是session；\n\n卧槽，写的真尼玛专业啊，我都信了！原因是因为我的场景恰恰是需要设置注入进来的Bean的生命周期为request的，我就理所应当的认为TA说的木牛错，我还傻不拉唧的花了一下午的时间把\"singleton\"、“session”、“request”等使了个遍！\n\n片头那个错误信息折磨了我几个小时，作者你造么？你能别吓唬乱写么？\n\n哥这性子就是倔，回到家游戏都没玩，电影也没看，美剧缓冲着也不管了，心想劳资这么正儿八经的一个需求，怎么可能Spring就不能满足呢？\n\n我又写了个简单的测试专门来排查问题，然后又去看源码！可算让我知道原因了！就是上面的那句扯犊子的话给我坑的！\n\n`contextAttribute`属性是在调用`WebApplicationContextUtils.getWebApplicationContext(getServletContext(), attrName)`的时候当第二个参数用的，追到`WebApplicationContextUtils`类去查源码，你就知道世界满满的恶意了！\n\n哥为了真理，网吧包宿的钱都准备好了，作者你造么？\n\n那么这个属性到底做甚的？看[这里](http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/context/support/WebApplicationContextUtils.java#WebApplicationContextUtils.getWebApplicationContext%28javax.servlet.ServletContext%2Cjava.lang.String%29)：\n\n> attrName the name of the ServletContext attribute to look for\n\n就这吧，我还能说点啥，妈蛋，哥再也不相信你(http://my.csdn.net/geloin)了。\n\n\n","source":"_posts/No WebApplicationContext found no ContextLoaderListener registered.md","raw":"title: No WebApplicationContext found\ndate: 2014-12-9 11:13:12\ntags: \n- spring\n- ioc\n- filter\n- servlet\n- DelegatingFilterProxy\ncategories: j2ee\n---\n\n\n> No WebApplicationContext found: no ContextLoaderListener registered?\n\n上面个异常信息可把我给坑苦了，整整一下午啊，外加一晚上。其实吧，问题不在于人家这个报错，你瞅瞅，多体贴，甚至都加上了人性化的提醒，相对其他异常信息来说，这已经很友好了不是么？\n<!--more-->\n先来简单说一下问题场景吧：**我的目的很直白，就是想在Servlet的Filter中使用Spring的Ioc注入指定的Bean**。\n\n怎么样，直白的都要哭了！\n\n对于我这种新手，确实一开始是不知道Filter中是无法使用spring的依赖注入的，原因很简单，因为Filter并不受spring管理，自然无法使用Ioc了！不过，我又不能直接“new”想用的bean，因为最终我的bean会使用依赖注入相关的资源！\n\n要说这种需求一点儿都不偏门，gg上一搜一大把：[苦逼版](http://zy116494718.iteye.com/blog/1918131)，[二逼版](http://blog.csdn.net/geloin/article/details/7441937)。\n\n苦逼版其实也挺好的，简单明了，不过对我这种强迫症患者来说，总感觉难受，可能是由于手动调用`getBean()`的缘故吧～我也不清楚，反正难受！\n\n着重来说说这个二逼版，`DelegatingFilterProxy`这个类就是spring专门针对我们的问题场景量身定做的一个现成的实现版本，其实TA内部会帮我们调用苦逼版中的相关代码，有兴趣的同学强烈推荐看看[源码](http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/filter/DelegatingFilterProxy.java#DelegatingFilterProxy.doFilter%28%29)。\n\n我就是由于白天浮躁的环境让我一不小心上了鬼子的当！我其实是一个温文尔雅的人，真真儿的。但我现在杀人的心都有！如果你点开了我上面提供的二逼版链接，那你留意一下TA的这句话：\n\n>  (1) contextAttribute，使用委派Bean的范围，其值必须从org.springframework.context.ApplicationContext.WebApplicationContext中取得，默认值是session；\n\n卧槽，写的真尼玛专业啊，我都信了！原因是因为我的场景恰恰是需要设置注入进来的Bean的生命周期为request的，我就理所应当的认为TA说的木牛错，我还傻不拉唧的花了一下午的时间把\"singleton\"、“session”、“request”等使了个遍！\n\n片头那个错误信息折磨了我几个小时，作者你造么？你能别吓唬乱写么？\n\n哥这性子就是倔，回到家游戏都没玩，电影也没看，美剧缓冲着也不管了，心想劳资这么正儿八经的一个需求，怎么可能Spring就不能满足呢？\n\n我又写了个简单的测试专门来排查问题，然后又去看源码！可算让我知道原因了！就是上面的那句扯犊子的话给我坑的！\n\n`contextAttribute`属性是在调用`WebApplicationContextUtils.getWebApplicationContext(getServletContext(), attrName)`的时候当第二个参数用的，追到`WebApplicationContextUtils`类去查源码，你就知道世界满满的恶意了！\n\n哥为了真理，网吧包宿的钱都准备好了，作者你造么？\n\n那么这个属性到底做甚的？看[这里](http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/context/support/WebApplicationContextUtils.java#WebApplicationContextUtils.getWebApplicationContext%28javax.servlet.ServletContext%2Cjava.lang.String%29)：\n\n> attrName the name of the ServletContext attribute to look for\n\n就这吧，我还能说点啥，妈蛋，哥再也不相信你(http://my.csdn.net/geloin)了。\n\n\n","slug":"No WebApplicationContext found no ContextLoaderListener registered","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ys500ckgtfygod7zati","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>No WebApplicationContext found: no ContextLoaderListener registered?</p>\n</blockquote>\n<p>上面个异常信息可把我给坑苦了，整整一下午啊，外加一晚上。其实吧，问题不在于人家这个报错，你瞅瞅，多体贴，甚至都加上了人性化的提醒，相对其他异常信息来说，这已经很友好了不是么？<br><a id=\"more\"></a><br>先来简单说一下问题场景吧：<strong>我的目的很直白，就是想在Servlet的Filter中使用Spring的Ioc注入指定的Bean</strong>。</p>\n<p>怎么样，直白的都要哭了！</p>\n<p>对于我这种新手，确实一开始是不知道Filter中是无法使用spring的依赖注入的，原因很简单，因为Filter并不受spring管理，自然无法使用Ioc了！不过，我又不能直接“new”想用的bean，因为最终我的bean会使用依赖注入相关的资源！</p>\n<p>要说这种需求一点儿都不偏门，gg上一搜一大把：<a href=\"http://zy116494718.iteye.com/blog/1918131\" target=\"_blank\" rel=\"external\">苦逼版</a>，<a href=\"http://blog.csdn.net/geloin/article/details/7441937\" target=\"_blank\" rel=\"external\">二逼版</a>。</p>\n<p>苦逼版其实也挺好的，简单明了，不过对我这种强迫症患者来说，总感觉难受，可能是由于手动调用<code>getBean()</code>的缘故吧～我也不清楚，反正难受！</p>\n<p>着重来说说这个二逼版，<code>DelegatingFilterProxy</code>这个类就是spring专门针对我们的问题场景量身定做的一个现成的实现版本，其实TA内部会帮我们调用苦逼版中的相关代码，有兴趣的同学强烈推荐看看<a href=\"http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/filter/DelegatingFilterProxy.java#DelegatingFilterProxy.doFilter%28%29\" target=\"_blank\" rel=\"external\">源码</a>。</p>\n<p>我就是由于白天浮躁的环境让我一不小心上了鬼子的当！我其实是一个温文尔雅的人，真真儿的。但我现在杀人的心都有！如果你点开了我上面提供的二逼版链接，那你留意一下TA的这句话：</p>\n<blockquote>\n<p> (1) contextAttribute，使用委派Bean的范围，其值必须从org.springframework.context.ApplicationContext.WebApplicationContext中取得，默认值是session；</p>\n</blockquote>\n<p>卧槽，写的真尼玛专业啊，我都信了！原因是因为我的场景恰恰是需要设置注入进来的Bean的生命周期为request的，我就理所应当的认为TA说的木牛错，我还傻不拉唧的花了一下午的时间把”singleton”、“session”、“request”等使了个遍！</p>\n<p>片头那个错误信息折磨了我几个小时，作者你造么？你能别吓唬乱写么？</p>\n<p>哥这性子就是倔，回到家游戏都没玩，电影也没看，美剧缓冲着也不管了，心想劳资这么正儿八经的一个需求，怎么可能Spring就不能满足呢？</p>\n<p>我又写了个简单的测试专门来排查问题，然后又去看源码！可算让我知道原因了！就是上面的那句扯犊子的话给我坑的！</p>\n<p><code>contextAttribute</code>属性是在调用<code>WebApplicationContextUtils.getWebApplicationContext(getServletContext(), attrName)</code>的时候当第二个参数用的，追到<code>WebApplicationContextUtils</code>类去查源码，你就知道世界满满的恶意了！</p>\n<p>哥为了真理，网吧包宿的钱都准备好了，作者你造么？</p>\n<p>那么这个属性到底做甚的？看<a href=\"http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/context/support/WebApplicationContextUtils.java#WebApplicationContextUtils.getWebApplicationContext%28javax.servlet.ServletContext%2Cjava.lang.String%29\" target=\"_blank\" rel=\"external\">这里</a>：</p>\n<blockquote>\n<p>attrName the name of the ServletContext attribute to look for</p>\n</blockquote>\n<p>就这吧，我还能说点啥，妈蛋，哥再也不相信你(<a href=\"http://my.csdn.net/geloin)了。\" target=\"_blank\" rel=\"external\">http://my.csdn.net/geloin)了。</a></p>\n","excerpt":"<blockquote>\n<p>No WebApplicationContext found: no ContextLoaderListener registered?</p>\n</blockquote>\n<p>上面个异常信息可把我给坑苦了，整整一下午啊，外加一晚上。其实吧，问题不在于人家这个报错，你瞅瞅，多体贴，甚至都加上了人性化的提醒，相对其他异常信息来说，这已经很友好了不是么？<br>","more":"<br>先来简单说一下问题场景吧：<strong>我的目的很直白，就是想在Servlet的Filter中使用Spring的Ioc注入指定的Bean</strong>。</p>\n<p>怎么样，直白的都要哭了！</p>\n<p>对于我这种新手，确实一开始是不知道Filter中是无法使用spring的依赖注入的，原因很简单，因为Filter并不受spring管理，自然无法使用Ioc了！不过，我又不能直接“new”想用的bean，因为最终我的bean会使用依赖注入相关的资源！</p>\n<p>要说这种需求一点儿都不偏门，gg上一搜一大把：<a href=\"http://zy116494718.iteye.com/blog/1918131\">苦逼版</a>，<a href=\"http://blog.csdn.net/geloin/article/details/7441937\">二逼版</a>。</p>\n<p>苦逼版其实也挺好的，简单明了，不过对我这种强迫症患者来说，总感觉难受，可能是由于手动调用<code>getBean()</code>的缘故吧～我也不清楚，反正难受！</p>\n<p>着重来说说这个二逼版，<code>DelegatingFilterProxy</code>这个类就是spring专门针对我们的问题场景量身定做的一个现成的实现版本，其实TA内部会帮我们调用苦逼版中的相关代码，有兴趣的同学强烈推荐看看<a href=\"http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/filter/DelegatingFilterProxy.java#DelegatingFilterProxy.doFilter%28%29\">源码</a>。</p>\n<p>我就是由于白天浮躁的环境让我一不小心上了鬼子的当！我其实是一个温文尔雅的人，真真儿的。但我现在杀人的心都有！如果你点开了我上面提供的二逼版链接，那你留意一下TA的这句话：</p>\n<blockquote>\n<p> (1) contextAttribute，使用委派Bean的范围，其值必须从org.springframework.context.ApplicationContext.WebApplicationContext中取得，默认值是session；</p>\n</blockquote>\n<p>卧槽，写的真尼玛专业啊，我都信了！原因是因为我的场景恰恰是需要设置注入进来的Bean的生命周期为request的，我就理所应当的认为TA说的木牛错，我还傻不拉唧的花了一下午的时间把”singleton”、“session”、“request”等使了个遍！</p>\n<p>片头那个错误信息折磨了我几个小时，作者你造么？你能别吓唬乱写么？</p>\n<p>哥这性子就是倔，回到家游戏都没玩，电影也没看，美剧缓冲着也不管了，心想劳资这么正儿八经的一个需求，怎么可能Spring就不能满足呢？</p>\n<p>我又写了个简单的测试专门来排查问题，然后又去看源码！可算让我知道原因了！就是上面的那句扯犊子的话给我坑的！</p>\n<p><code>contextAttribute</code>属性是在调用<code>WebApplicationContextUtils.getWebApplicationContext(getServletContext(), attrName)</code>的时候当第二个参数用的，追到<code>WebApplicationContextUtils</code>类去查源码，你就知道世界满满的恶意了！</p>\n<p>哥为了真理，网吧包宿的钱都准备好了，作者你造么？</p>\n<p>那么这个属性到底做甚的？看<a href=\"http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.web/3.2.2/org/springframework/web/context/support/WebApplicationContextUtils.java#WebApplicationContextUtils.getWebApplicationContext%28javax.servlet.ServletContext%2Cjava.lang.String%29\">这里</a>：</p>\n<blockquote>\n<p>attrName the name of the ServletContext attribute to look for</p>\n</blockquote>\n<p>就这吧，我还能说点啥，妈蛋，哥再也不相信你(<a href=\"http://my.csdn.net/geloin)了。\">http://my.csdn.net/geloin)了。</a></p>"},{"title":"Mac配置Apache的权限问题","date":"2014-09-22T02:54:30.000Z","_content":"\n说来不怕你笑话，搞了好些年的php，可还是会在配置环境的时候出现各种个样的逗比情况。\n<!-- more -->\n今天用自己的笔记本调试一个php网站，需要搞一个vhost。配置好后发现提示我403错误：\n\n> You don’t have permission to access on this server.\n\t\n\n按照个人的条件反射，第一件事儿就是把指定的web目录设置为777权限。可是发现还是不行，查了一下网上的解决方案，竟然发现很多人都说是：\n\n\t<Directory />\n\t\tOptions Indexes FollowSymLinks MultiViews\n        AllowOverride None\n        Order deny,allow\n        Allow from all\t#这里是重点\n    </Directory>\n    \n但是对我来说，肯定没用～～这个时候我就有点抓瞎了，后来总算知道问题了，**原来不仅仅要对当前web目录设置正确的权限，还要把其父目录设置正确的权限**。\n\n参考：\n[Mac配置Apache的Vhosts权限问题](http://www.orzcc.com/2011/07/641629.html)","source":"_posts/Mac配置Apache的权限问题.md","raw":"title: Mac配置Apache的权限问题\ndate: 2014-09-22 10:54:30\ntags: \n- mac\n- apache\n- vhost\n- 权限\ncategories: mac\n---\n\n说来不怕你笑话，搞了好些年的php，可还是会在配置环境的时候出现各种个样的逗比情况。\n<!-- more -->\n今天用自己的笔记本调试一个php网站，需要搞一个vhost。配置好后发现提示我403错误：\n\n> You don’t have permission to access on this server.\n\t\n\n按照个人的条件反射，第一件事儿就是把指定的web目录设置为777权限。可是发现还是不行，查了一下网上的解决方案，竟然发现很多人都说是：\n\n\t<Directory />\n\t\tOptions Indexes FollowSymLinks MultiViews\n        AllowOverride None\n        Order deny,allow\n        Allow from all\t#这里是重点\n    </Directory>\n    \n但是对我来说，肯定没用～～这个时候我就有点抓瞎了，后来总算知道问题了，**原来不仅仅要对当前web目录设置正确的权限，还要把其父目录设置正确的权限**。\n\n参考：\n[Mac配置Apache的Vhosts权限问题](http://www.orzcc.com/2011/07/641629.html)","slug":"Mac配置Apache的权限问题","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ysj00cvgtfyvbnb56pk","comments":1,"layout":"post","photos":[],"link":"","content":"<p>说来不怕你笑话，搞了好些年的php，可还是会在配置环境的时候出现各种个样的逗比情况。<br><a id=\"more\"></a><br>今天用自己的笔记本调试一个php网站，需要搞一个vhost。配置好后发现提示我403错误：</p>\n<blockquote>\n<p>You don’t have permission to access on this server.</p>\n</blockquote>\n<p>按照个人的条件反射，第一件事儿就是把指定的web目录设置为777权限。可是发现还是不行，查了一下网上的解决方案，竟然发现很多人都说是：</p>\n<pre><code>&lt;Directory /&gt;\n    Options Indexes FollowSymLinks MultiViews\n    AllowOverride None\n    Order deny,allow\n    Allow from all    #这里是重点\n&lt;/Directory&gt;\n</code></pre><p>但是对我来说，肯定没用～～这个时候我就有点抓瞎了，后来总算知道问题了，<strong>原来不仅仅要对当前web目录设置正确的权限，还要把其父目录设置正确的权限</strong>。</p>\n<p>参考：<br><a href=\"http://www.orzcc.com/2011/07/641629.html\" target=\"_blank\" rel=\"external\">Mac配置Apache的Vhosts权限问题</a></p>\n","excerpt":"<p>说来不怕你笑话，搞了好些年的php，可还是会在配置环境的时候出现各种个样的逗比情况。<br>","more":"<br>今天用自己的笔记本调试一个php网站，需要搞一个vhost。配置好后发现提示我403错误：</p>\n<blockquote>\n<p>You don’t have permission to access on this server.</p>\n</blockquote>\n<p>按照个人的条件反射，第一件事儿就是把指定的web目录设置为777权限。可是发现还是不行，查了一下网上的解决方案，竟然发现很多人都说是：</p>\n<pre><code>&lt;Directory /&gt;\n    Options Indexes FollowSymLinks MultiViews\n    AllowOverride None\n    Order deny,allow\n    Allow from all    #这里是重点\n&lt;/Directory&gt;\n</code></pre><p>但是对我来说，肯定没用～～这个时候我就有点抓瞎了，后来总算知道问题了，<strong>原来不仅仅要对当前web目录设置正确的权限，还要把其父目录设置正确的权限</strong>。</p>\n<p>参考：<br><a href=\"http://www.orzcc.com/2011/07/641629.html\">Mac配置Apache的Vhosts权限问题</a></p>"},{"title":"Kafka+Avro的demo","date":"2015-04-27T07:54:30.000Z","_content":"\n最近在对消息中间件进行调研，原先项目里使用的是RabbitMQ，理由很简单：**对开发语言支持度是最好的**，没有之一。但是业界的反馈是，其高并发和分布式支持存在不足~\n<!--more-->\n我就打算再了解一下**kafka**，看看它是怎么个用法~~\n\n如RabbitMQ一样，kafka也提供了终端脚本来完成基本功能的测试，可以看一下[这里](http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point)。但光玩玩脚本或官方提供的例子，是不能满足我的~\n\n作为把消息队列，让其使用在项目中，除了解决和业务代码进行互动以外，还要考虑数据传输的格式问题，也就是说如何解决producer和consumer之间通信的协议问题。\n\n官方推荐的就是Avro，只可惜我找了半天，都没有一个现成的kafka+Avro的demo供我测试，那就只能自己试着写个了~~\n\n\tpackage me.kazaff.mq;\n\t\n\timport kafka.consumer.ConsumerConfig;\n\timport kafka.consumer.ConsumerIterator;\n\timport kafka.consumer.KafkaStream;\n\timport kafka.javaapi.consumer.ConsumerConnector;\n\timport kafka.javaapi.producer.Producer;\n\timport kafka.producer.KeyedMessage;\n\timport kafka.producer.ProducerConfig;\n\timport me.kazaff.mq.avro.Message;\n\timport org.apache.avro.io.*;\n\timport org.apache.avro.specific.SpecificDatumReader;\n\timport org.apache.avro.specific.SpecificDatumWriter;\n\t\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\timport java.util.*;\n\t\n\tpublic class Main {\n\t\n\t    public static void main(String[] args){\n\t        try {\n\t            //消息生产\n\t            produce();\n\t\n\t            //消息消费\n\t            consume();\n\t\n\t        }catch (Exception ex){\n\t            System.out.println(ex);\n\t        }\n\t\n\t    }\n\t\n\t    private static void produce() throws IOException{\n\t        Properties props = new Properties();\n\t        props.put(\"metadata.broker.list\", \"localhost:9092\");\n\t        props.put(\"serializer.class\", \"kafka.serializer.DefaultEncoder\");\n\t        props.put(\"key.serializer.class\", \"kafka.serializer.StringEncoder\");    //key的类型需要和serializer保持一致，如果key是String，则需要配置为kafka.serializer.StringEncoder，如果不配置，默认为kafka.serializer.DefaultEncoder，即二进制格式\n\t        props.put(\"partition.class\", \"me.kazaff.mq.MyPartitioner\");\n\t        props.put(\"request.required.acks\", \"1\");\n\t\n\t        ProducerConfig config = new ProducerConfig(props);\n\t        Producer<String, byte[]> producer = new Producer<String, byte[]>(config);\n\t\n\t        Random rnd = new Random();\n\t        for(int index = 0; index <= 10; index++){\n\t            Message msg = new Message();\n\t            msg.setUrl(\"blog.kazaff.me\");\n\t            msg.setIp(\"192.168.137.\" + rnd.nextInt(255));\n\t            msg.setDate(Long.toString(new Date().getTime()));\n\t\n\t            DatumWriter<Message> msgDatumWriter = new SpecificDatumWriter<Message>(Message.class);\n\t            ByteArrayOutputStream os = new ByteArrayOutputStream();\n\t            try {\n\t                Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n\t                msgDatumWriter.write(msg, e);\n\t                e.flush();\n\t                byte[] byteData = os.toByteArray();\n\t\n\t                KeyedMessage<String, byte[]> data = new KeyedMessage<String, byte[]>(\"demo\", \"0\", byteData);\n\t                producer.send(data);\n\t\n\t            }catch (IOException ex){\n\t                System.out.println(ex.getMessage());\n\t            }finally {\n\t                os.close();\n\t            }\n\t        }\n\t        producer.close();\n\t    }\n\t\n\t    private static void consume(){\n\t        Properties props = new Properties();\n\t        props.put(\"zookeeper.connect\", \"localhost:2181\");\n\t        props.put(\"group.id\", \"1\");\n\t        props.put(\"zookeeper.session.timeout.ms\", \"400\");\n\t        props.put(\"zookeeper.sync.time.ms\", \"200\");\n\t        props.put(\"auto.commit.interval.ms\", \"1000\");\n\t\n\t        ConsumerConnector consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(props));\n\t        Map<String, Integer> topicCountMap = new HashMap<String, Integer>();\n\t        topicCountMap.put(\"demo\", 1);\n\t        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.createMessageStreams(topicCountMap);\n\t        List<KafkaStream<byte[], byte[]>> streams = consumerMap.get(\"demo\");\n\t        KafkaStream steam = streams.get(0);\n\t\n\t        ConsumerIterator<byte[], byte[]> it = steam.iterator();\n\t        while (it.hasNext()){\n\t            try {\n\t                DatumReader<Message> reader = new SpecificDatumReader<Message>(Message.class);\n\t                Decoder decoder = DecoderFactory.get().binaryDecoder(it.next().message(), null);\n\t                Message msg = reader.read(null, decoder);\n\t\n\t                System.out.println(msg.getDate() + \",\" + msg.getUrl() + \",\" + msg.getIp());\n\t\n\t            }catch (Exception ex){\n\t                System.out.println(ex);\n\t            }\n\t        }\n\t\n\t        if(consumer != null)\n\t            consumer.shutdown();\n\t    }\n\t}\n\n**PS：这只是个测试的例子，存在各种问题，不建议直接使用在项目中。**\n\n为了方便大家直接测试，我把pom.xml也贴出来：\n\n\t<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n\t    <modelVersion>4.0.0</modelVersion>\n\t\n\t    <groupId>me.kazaff.mq</groupId>\n\t    <artifactId>kafkaProducer</artifactId>\n\t    <version>0.0.1</version>\n\t    <packaging>jar</packaging>\n\t    <name>kafkaProducer</name>\n\t    <description>The Producer of message, use Avro to encode data, and send to the kafka.</description>\n\t\n\t    <dependencies>\n\t        <dependency>\n\t            <groupId>org.apache.kafka</groupId>\n\t            <artifactId>kafka_2.11</artifactId>\n\t            <version>0.8.2.1</version>\n\t        </dependency>\n\t\n\t        <dependency>\n\t            <groupId>org.apache.avro</groupId>\n\t            <artifactId>avro</artifactId>\n\t            <version>1.7.6-cdh5.2.5</version>\n\t        </dependency>\n\t\n\t    </dependencies>\n\t    <build>\n\t        <plugins>\n\t            <plugin>\n\t                <groupId>org.apache.avro</groupId>\n\t                <artifactId>avro-maven-plugin</artifactId>\n\t                <version>1.7.6</version>\n\t                <executions>\n\t                    <execution>\n\t                        <phase>generate-sources</phase>\n\t                        <goals>\n\t                            <goal>schema</goal>\n\t                        </goals>\n\t                        <configuration>\n\t                            <sourceDirectory>${project.basedir}/src/avro/</sourceDirectory>\n\t                            <outputDirectory>${project.basedir}/src/</outputDirectory>\n\t                        </configuration>\n\t                    </execution>\n\t                </executions>\n\t            </plugin>\n\t            <plugin>\n\t                <groupId>org.apache.maven.plugins</groupId>\n\t                <artifactId>maven-compiler-plugin</artifactId>\n\t                <configuration>\n\t                    <source>1.7</source>\n\t                    <target>1.7</target>\n\t                </configuration>\n\t            </plugin>\n\t        </plugins>\n\t    </build>\n\t\n\t    <repositories>\n\t        <repository>\n\t            <id>cloudera-repo-releases</id>\n\t            <url>https://repository.cloudera.com/artifactory/repo/</url>\n\t        </repository>\n\t    </repositories>\n\t</project>\n\n下面是Avro使用的Schema：\n\n\t{\n\t    \"namespace\": \"me.kazaff.mq.avro\",\n\t    \"type\": \"record\",\n\t    \"name\": \"Message\",\n\t    \"fields\": [\n\t        {\n\t            \"name\": \"date\",\n\t            \"type\": \"string\"\n\t        },\n\t        {\n\t            \"name\": \"url\",\n\t            \"type\": \"string\"\n\t        },\n\t        {\n\t            \"name\": \"ip\",\n\t            \"type\": \"string\"\n\t        }\n\t    ]\n\t}\n\n代码中使用的`MyPartitioner`其实很sb：\n\n\tpackage me.kazaff.mq;\n\n\timport kafka.producer.Partitioner;\n\timport kafka.utils.VerifiableProperties;\n\t\n\t/**\n\t * Created by kazaff on 2015/4/21.\n\t */\n\tpublic class MyPartitioner implements Partitioner {\n\t    public MyPartitioner(VerifiableProperties props){}\n\t\n\t    public int partition(Object key, int numPartitions){\n\t        return 0;\n\t    }\n\t}\n\n需要注意的是，我是先使用Maven根据配置的plugin，把声明的Schema先处理生成对应的Class文件，然后再进行运行测试的~\n\n\n### 问题\n---\n#### 1.\n\n> java.lang.ClassCastException: [B cannot be cast to java.lang.String\n\n解决方法很简单：\n\n\tprops.put(\"serializer.class\", \"kafka.serializer.DefaultEncoder\");\n\n这样，kafka就默认使用二进制的序列化方案处理Avro的编码结果了。\n\n\n#### 2.\n\n> java.lang.ClassCastException: java.lang.String cannot be cast to [B\n\n这个问题是最恶心的，搜了半天都没有找到原因，原因是**问题1**中那么设置后，Kafka所有的数据序列化方式都成了二进制方式，包括我们后面要使用的“key”（用于kafka选择分区的线索）。\n\n所以你还需要再加一条配置：\n\n\tprops.put(\"key.serializer.class\", \"kafka.serializer.StringEncoder\");\n\n单独设置一下“key”的序列化方式，这样就可以编译运行了~~\n\n\n---\n\n初尝Kafka和Avro，就这么点儿要记录的，不要嫌少哟~~","source":"_posts/Kafka+Avro的demo.md","raw":"title: Kafka+Avro的demo\ndate: 2015-04-27 15:54:30\ntags:\n- Kafka\n- Avro\n- RabbitMQ\n- 序列化\n\ncategories: j2ee\n---\n\n最近在对消息中间件进行调研，原先项目里使用的是RabbitMQ，理由很简单：**对开发语言支持度是最好的**，没有之一。但是业界的反馈是，其高并发和分布式支持存在不足~\n<!--more-->\n我就打算再了解一下**kafka**，看看它是怎么个用法~~\n\n如RabbitMQ一样，kafka也提供了终端脚本来完成基本功能的测试，可以看一下[这里](http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point)。但光玩玩脚本或官方提供的例子，是不能满足我的~\n\n作为把消息队列，让其使用在项目中，除了解决和业务代码进行互动以外，还要考虑数据传输的格式问题，也就是说如何解决producer和consumer之间通信的协议问题。\n\n官方推荐的就是Avro，只可惜我找了半天，都没有一个现成的kafka+Avro的demo供我测试，那就只能自己试着写个了~~\n\n\tpackage me.kazaff.mq;\n\t\n\timport kafka.consumer.ConsumerConfig;\n\timport kafka.consumer.ConsumerIterator;\n\timport kafka.consumer.KafkaStream;\n\timport kafka.javaapi.consumer.ConsumerConnector;\n\timport kafka.javaapi.producer.Producer;\n\timport kafka.producer.KeyedMessage;\n\timport kafka.producer.ProducerConfig;\n\timport me.kazaff.mq.avro.Message;\n\timport org.apache.avro.io.*;\n\timport org.apache.avro.specific.SpecificDatumReader;\n\timport org.apache.avro.specific.SpecificDatumWriter;\n\t\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\timport java.util.*;\n\t\n\tpublic class Main {\n\t\n\t    public static void main(String[] args){\n\t        try {\n\t            //消息生产\n\t            produce();\n\t\n\t            //消息消费\n\t            consume();\n\t\n\t        }catch (Exception ex){\n\t            System.out.println(ex);\n\t        }\n\t\n\t    }\n\t\n\t    private static void produce() throws IOException{\n\t        Properties props = new Properties();\n\t        props.put(\"metadata.broker.list\", \"localhost:9092\");\n\t        props.put(\"serializer.class\", \"kafka.serializer.DefaultEncoder\");\n\t        props.put(\"key.serializer.class\", \"kafka.serializer.StringEncoder\");    //key的类型需要和serializer保持一致，如果key是String，则需要配置为kafka.serializer.StringEncoder，如果不配置，默认为kafka.serializer.DefaultEncoder，即二进制格式\n\t        props.put(\"partition.class\", \"me.kazaff.mq.MyPartitioner\");\n\t        props.put(\"request.required.acks\", \"1\");\n\t\n\t        ProducerConfig config = new ProducerConfig(props);\n\t        Producer<String, byte[]> producer = new Producer<String, byte[]>(config);\n\t\n\t        Random rnd = new Random();\n\t        for(int index = 0; index <= 10; index++){\n\t            Message msg = new Message();\n\t            msg.setUrl(\"blog.kazaff.me\");\n\t            msg.setIp(\"192.168.137.\" + rnd.nextInt(255));\n\t            msg.setDate(Long.toString(new Date().getTime()));\n\t\n\t            DatumWriter<Message> msgDatumWriter = new SpecificDatumWriter<Message>(Message.class);\n\t            ByteArrayOutputStream os = new ByteArrayOutputStream();\n\t            try {\n\t                Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n\t                msgDatumWriter.write(msg, e);\n\t                e.flush();\n\t                byte[] byteData = os.toByteArray();\n\t\n\t                KeyedMessage<String, byte[]> data = new KeyedMessage<String, byte[]>(\"demo\", \"0\", byteData);\n\t                producer.send(data);\n\t\n\t            }catch (IOException ex){\n\t                System.out.println(ex.getMessage());\n\t            }finally {\n\t                os.close();\n\t            }\n\t        }\n\t        producer.close();\n\t    }\n\t\n\t    private static void consume(){\n\t        Properties props = new Properties();\n\t        props.put(\"zookeeper.connect\", \"localhost:2181\");\n\t        props.put(\"group.id\", \"1\");\n\t        props.put(\"zookeeper.session.timeout.ms\", \"400\");\n\t        props.put(\"zookeeper.sync.time.ms\", \"200\");\n\t        props.put(\"auto.commit.interval.ms\", \"1000\");\n\t\n\t        ConsumerConnector consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(props));\n\t        Map<String, Integer> topicCountMap = new HashMap<String, Integer>();\n\t        topicCountMap.put(\"demo\", 1);\n\t        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.createMessageStreams(topicCountMap);\n\t        List<KafkaStream<byte[], byte[]>> streams = consumerMap.get(\"demo\");\n\t        KafkaStream steam = streams.get(0);\n\t\n\t        ConsumerIterator<byte[], byte[]> it = steam.iterator();\n\t        while (it.hasNext()){\n\t            try {\n\t                DatumReader<Message> reader = new SpecificDatumReader<Message>(Message.class);\n\t                Decoder decoder = DecoderFactory.get().binaryDecoder(it.next().message(), null);\n\t                Message msg = reader.read(null, decoder);\n\t\n\t                System.out.println(msg.getDate() + \",\" + msg.getUrl() + \",\" + msg.getIp());\n\t\n\t            }catch (Exception ex){\n\t                System.out.println(ex);\n\t            }\n\t        }\n\t\n\t        if(consumer != null)\n\t            consumer.shutdown();\n\t    }\n\t}\n\n**PS：这只是个测试的例子，存在各种问题，不建议直接使用在项目中。**\n\n为了方便大家直接测试，我把pom.xml也贴出来：\n\n\t<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n\t    <modelVersion>4.0.0</modelVersion>\n\t\n\t    <groupId>me.kazaff.mq</groupId>\n\t    <artifactId>kafkaProducer</artifactId>\n\t    <version>0.0.1</version>\n\t    <packaging>jar</packaging>\n\t    <name>kafkaProducer</name>\n\t    <description>The Producer of message, use Avro to encode data, and send to the kafka.</description>\n\t\n\t    <dependencies>\n\t        <dependency>\n\t            <groupId>org.apache.kafka</groupId>\n\t            <artifactId>kafka_2.11</artifactId>\n\t            <version>0.8.2.1</version>\n\t        </dependency>\n\t\n\t        <dependency>\n\t            <groupId>org.apache.avro</groupId>\n\t            <artifactId>avro</artifactId>\n\t            <version>1.7.6-cdh5.2.5</version>\n\t        </dependency>\n\t\n\t    </dependencies>\n\t    <build>\n\t        <plugins>\n\t            <plugin>\n\t                <groupId>org.apache.avro</groupId>\n\t                <artifactId>avro-maven-plugin</artifactId>\n\t                <version>1.7.6</version>\n\t                <executions>\n\t                    <execution>\n\t                        <phase>generate-sources</phase>\n\t                        <goals>\n\t                            <goal>schema</goal>\n\t                        </goals>\n\t                        <configuration>\n\t                            <sourceDirectory>${project.basedir}/src/avro/</sourceDirectory>\n\t                            <outputDirectory>${project.basedir}/src/</outputDirectory>\n\t                        </configuration>\n\t                    </execution>\n\t                </executions>\n\t            </plugin>\n\t            <plugin>\n\t                <groupId>org.apache.maven.plugins</groupId>\n\t                <artifactId>maven-compiler-plugin</artifactId>\n\t                <configuration>\n\t                    <source>1.7</source>\n\t                    <target>1.7</target>\n\t                </configuration>\n\t            </plugin>\n\t        </plugins>\n\t    </build>\n\t\n\t    <repositories>\n\t        <repository>\n\t            <id>cloudera-repo-releases</id>\n\t            <url>https://repository.cloudera.com/artifactory/repo/</url>\n\t        </repository>\n\t    </repositories>\n\t</project>\n\n下面是Avro使用的Schema：\n\n\t{\n\t    \"namespace\": \"me.kazaff.mq.avro\",\n\t    \"type\": \"record\",\n\t    \"name\": \"Message\",\n\t    \"fields\": [\n\t        {\n\t            \"name\": \"date\",\n\t            \"type\": \"string\"\n\t        },\n\t        {\n\t            \"name\": \"url\",\n\t            \"type\": \"string\"\n\t        },\n\t        {\n\t            \"name\": \"ip\",\n\t            \"type\": \"string\"\n\t        }\n\t    ]\n\t}\n\n代码中使用的`MyPartitioner`其实很sb：\n\n\tpackage me.kazaff.mq;\n\n\timport kafka.producer.Partitioner;\n\timport kafka.utils.VerifiableProperties;\n\t\n\t/**\n\t * Created by kazaff on 2015/4/21.\n\t */\n\tpublic class MyPartitioner implements Partitioner {\n\t    public MyPartitioner(VerifiableProperties props){}\n\t\n\t    public int partition(Object key, int numPartitions){\n\t        return 0;\n\t    }\n\t}\n\n需要注意的是，我是先使用Maven根据配置的plugin，把声明的Schema先处理生成对应的Class文件，然后再进行运行测试的~\n\n\n### 问题\n---\n#### 1.\n\n> java.lang.ClassCastException: [B cannot be cast to java.lang.String\n\n解决方法很简单：\n\n\tprops.put(\"serializer.class\", \"kafka.serializer.DefaultEncoder\");\n\n这样，kafka就默认使用二进制的序列化方案处理Avro的编码结果了。\n\n\n#### 2.\n\n> java.lang.ClassCastException: java.lang.String cannot be cast to [B\n\n这个问题是最恶心的，搜了半天都没有找到原因，原因是**问题1**中那么设置后，Kafka所有的数据序列化方式都成了二进制方式，包括我们后面要使用的“key”（用于kafka选择分区的线索）。\n\n所以你还需要再加一条配置：\n\n\tprops.put(\"key.serializer.class\", \"kafka.serializer.StringEncoder\");\n\n单独设置一下“key”的序列化方式，这样就可以编译运行了~~\n\n\n---\n\n初尝Kafka和Avro，就这么点儿要记录的，不要嫌少哟~~","slug":"Kafka+Avro的demo","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ysp00d5gtfyc0kcxx35","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近在对消息中间件进行调研，原先项目里使用的是RabbitMQ，理由很简单：<strong>对开发语言支持度是最好的</strong>，没有之一。但是业界的反馈是，其高并发和分布式支持存在不足~<br><a id=\"more\"></a><br>我就打算再了解一下<strong>kafka</strong>，看看它是怎么个用法~~</p>\n<p>如RabbitMQ一样，kafka也提供了终端脚本来完成基本功能的测试，可以看一下<a href=\"http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point\" target=\"_blank\" rel=\"external\">这里</a>。但光玩玩脚本或官方提供的例子，是不能满足我的~</p>\n<p>作为把消息队列，让其使用在项目中，除了解决和业务代码进行互动以外，还要考虑数据传输的格式问题，也就是说如何解决producer和consumer之间通信的协议问题。</p>\n<p>官方推荐的就是Avro，只可惜我找了半天，都没有一个现成的kafka+Avro的demo供我测试，那就只能自己试着写个了~~</p>\n<pre><code>package me.kazaff.mq;\n\nimport kafka.consumer.ConsumerConfig;\nimport kafka.consumer.ConsumerIterator;\nimport kafka.consumer.KafkaStream;\nimport kafka.javaapi.consumer.ConsumerConnector;\nimport kafka.javaapi.producer.Producer;\nimport kafka.producer.KeyedMessage;\nimport kafka.producer.ProducerConfig;\nimport me.kazaff.mq.avro.Message;\nimport org.apache.avro.io.*;\nimport org.apache.avro.specific.SpecificDatumReader;\nimport org.apache.avro.specific.SpecificDatumWriter;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.util.*;\n\npublic class Main {\n\n    public static void main(String[] args){\n        try {\n            //消息生产\n            produce();\n\n            //消息消费\n            consume();\n\n        }catch (Exception ex){\n            System.out.println(ex);\n        }\n\n    }\n\n    private static void produce() throws IOException{\n        Properties props = new Properties();\n        props.put(&quot;metadata.broker.list&quot;, &quot;localhost:9092&quot;);\n        props.put(&quot;serializer.class&quot;, &quot;kafka.serializer.DefaultEncoder&quot;);\n        props.put(&quot;key.serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;);    //key的类型需要和serializer保持一致，如果key是String，则需要配置为kafka.serializer.StringEncoder，如果不配置，默认为kafka.serializer.DefaultEncoder，即二进制格式\n        props.put(&quot;partition.class&quot;, &quot;me.kazaff.mq.MyPartitioner&quot;);\n        props.put(&quot;request.required.acks&quot;, &quot;1&quot;);\n\n        ProducerConfig config = new ProducerConfig(props);\n        Producer&lt;String, byte[]&gt; producer = new Producer&lt;String, byte[]&gt;(config);\n\n        Random rnd = new Random();\n        for(int index = 0; index &lt;= 10; index++){\n            Message msg = new Message();\n            msg.setUrl(&quot;blog.kazaff.me&quot;);\n            msg.setIp(&quot;192.168.137.&quot; + rnd.nextInt(255));\n            msg.setDate(Long.toString(new Date().getTime()));\n\n            DatumWriter&lt;Message&gt; msgDatumWriter = new SpecificDatumWriter&lt;Message&gt;(Message.class);\n            ByteArrayOutputStream os = new ByteArrayOutputStream();\n            try {\n                Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n                msgDatumWriter.write(msg, e);\n                e.flush();\n                byte[] byteData = os.toByteArray();\n\n                KeyedMessage&lt;String, byte[]&gt; data = new KeyedMessage&lt;String, byte[]&gt;(&quot;demo&quot;, &quot;0&quot;, byteData);\n                producer.send(data);\n\n            }catch (IOException ex){\n                System.out.println(ex.getMessage());\n            }finally {\n                os.close();\n            }\n        }\n        producer.close();\n    }\n\n    private static void consume(){\n        Properties props = new Properties();\n        props.put(&quot;zookeeper.connect&quot;, &quot;localhost:2181&quot;);\n        props.put(&quot;group.id&quot;, &quot;1&quot;);\n        props.put(&quot;zookeeper.session.timeout.ms&quot;, &quot;400&quot;);\n        props.put(&quot;zookeeper.sync.time.ms&quot;, &quot;200&quot;);\n        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);\n\n        ConsumerConnector consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(props));\n        Map&lt;String, Integer&gt; topicCountMap = new HashMap&lt;String, Integer&gt;();\n        topicCountMap.put(&quot;demo&quot;, 1);\n        Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; consumerMap = consumer.createMessageStreams(topicCountMap);\n        List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt; streams = consumerMap.get(&quot;demo&quot;);\n        KafkaStream steam = streams.get(0);\n\n        ConsumerIterator&lt;byte[], byte[]&gt; it = steam.iterator();\n        while (it.hasNext()){\n            try {\n                DatumReader&lt;Message&gt; reader = new SpecificDatumReader&lt;Message&gt;(Message.class);\n                Decoder decoder = DecoderFactory.get().binaryDecoder(it.next().message(), null);\n                Message msg = reader.read(null, decoder);\n\n                System.out.println(msg.getDate() + &quot;,&quot; + msg.getUrl() + &quot;,&quot; + msg.getIp());\n\n            }catch (Exception ex){\n                System.out.println(ex);\n            }\n        }\n\n        if(consumer != null)\n            consumer.shutdown();\n    }\n}\n</code></pre><p><strong>PS：这只是个测试的例子，存在各种问题，不建议直接使用在项目中。</strong></p>\n<p>为了方便大家直接测试，我把pom.xml也贴出来：</p>\n<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n     xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n    &lt;groupId&gt;me.kazaff.mq&lt;/groupId&gt;\n    &lt;artifactId&gt;kafkaProducer&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1&lt;/version&gt;\n    &lt;packaging&gt;jar&lt;/packaging&gt;\n    &lt;name&gt;kafkaProducer&lt;/name&gt;\n    &lt;description&gt;The Producer of message, use Avro to encode data, and send to the kafka.&lt;/description&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;\n            &lt;artifactId&gt;kafka_2.11&lt;/artifactId&gt;\n            &lt;version&gt;0.8.2.1&lt;/version&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n            &lt;artifactId&gt;avro&lt;/artifactId&gt;\n            &lt;version&gt;1.7.6-cdh5.2.5&lt;/version&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n                &lt;artifactId&gt;avro-maven-plugin&lt;/artifactId&gt;\n                &lt;version&gt;1.7.6&lt;/version&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;phase&gt;generate-sources&lt;/phase&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;schema&lt;/goal&gt;\n                        &lt;/goals&gt;\n                        &lt;configuration&gt;\n                            &lt;sourceDirectory&gt;${project.basedir}/src/avro/&lt;/sourceDirectory&gt;\n                            &lt;outputDirectory&gt;${project.basedir}/src/&lt;/outputDirectory&gt;\n                        &lt;/configuration&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;1.7&lt;/source&gt;\n                    &lt;target&gt;1.7&lt;/target&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n    &lt;repositories&gt;\n        &lt;repository&gt;\n            &lt;id&gt;cloudera-repo-releases&lt;/id&gt;\n            &lt;url&gt;https://repository.cloudera.com/artifactory/repo/&lt;/url&gt;\n        &lt;/repository&gt;\n    &lt;/repositories&gt;\n&lt;/project&gt;\n</code></pre><p>下面是Avro使用的Schema：</p>\n<pre><code>{\n    &quot;namespace&quot;: &quot;me.kazaff.mq.avro&quot;,\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;Message&quot;,\n    &quot;fields&quot;: [\n        {\n            &quot;name&quot;: &quot;date&quot;,\n            &quot;type&quot;: &quot;string&quot;\n        },\n        {\n            &quot;name&quot;: &quot;url&quot;,\n            &quot;type&quot;: &quot;string&quot;\n        },\n        {\n            &quot;name&quot;: &quot;ip&quot;,\n            &quot;type&quot;: &quot;string&quot;\n        }\n    ]\n}\n</code></pre><p>代码中使用的<code>MyPartitioner</code>其实很sb：</p>\n<pre><code>package me.kazaff.mq;\n\nimport kafka.producer.Partitioner;\nimport kafka.utils.VerifiableProperties;\n\n/**\n * Created by kazaff on 2015/4/21.\n */\npublic class MyPartitioner implements Partitioner {\n    public MyPartitioner(VerifiableProperties props){}\n\n    public int partition(Object key, int numPartitions){\n        return 0;\n    }\n}\n</code></pre><p>需要注意的是，我是先使用Maven根据配置的plugin，把声明的Schema先处理生成对应的Class文件，然后再进行运行测试的~</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><hr>\n<h4 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1.\"></a>1.</h4><blockquote>\n<p>java.lang.ClassCastException: [B cannot be cast to java.lang.String</p>\n</blockquote>\n<p>解决方法很简单：</p>\n<pre><code>props.put(&quot;serializer.class&quot;, &quot;kafka.serializer.DefaultEncoder&quot;);\n</code></pre><p>这样，kafka就默认使用二进制的序列化方案处理Avro的编码结果了。</p>\n<h4 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2.\"></a>2.</h4><blockquote>\n<p>java.lang.ClassCastException: java.lang.String cannot be cast to [B</p>\n</blockquote>\n<p>这个问题是最恶心的，搜了半天都没有找到原因，原因是<strong>问题1</strong>中那么设置后，Kafka所有的数据序列化方式都成了二进制方式，包括我们后面要使用的“key”（用于kafka选择分区的线索）。</p>\n<p>所以你还需要再加一条配置：</p>\n<pre><code>props.put(&quot;key.serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;);\n</code></pre><p>单独设置一下“key”的序列化方式，这样就可以编译运行了~~</p>\n<hr>\n<p>初尝Kafka和Avro，就这么点儿要记录的，不要嫌少哟~~</p>\n","excerpt":"<p>最近在对消息中间件进行调研，原先项目里使用的是RabbitMQ，理由很简单：<strong>对开发语言支持度是最好的</strong>，没有之一。但是业界的反馈是，其高并发和分布式支持存在不足~<br>","more":"<br>我就打算再了解一下<strong>kafka</strong>，看看它是怎么个用法~~</p>\n<p>如RabbitMQ一样，kafka也提供了终端脚本来完成基本功能的测试，可以看一下<a href=\"http://colobu.com/2014/08/06/kafka-quickstart/#show-last-Point\">这里</a>。但光玩玩脚本或官方提供的例子，是不能满足我的~</p>\n<p>作为把消息队列，让其使用在项目中，除了解决和业务代码进行互动以外，还要考虑数据传输的格式问题，也就是说如何解决producer和consumer之间通信的协议问题。</p>\n<p>官方推荐的就是Avro，只可惜我找了半天，都没有一个现成的kafka+Avro的demo供我测试，那就只能自己试着写个了~~</p>\n<pre><code>package me.kazaff.mq;\n\nimport kafka.consumer.ConsumerConfig;\nimport kafka.consumer.ConsumerIterator;\nimport kafka.consumer.KafkaStream;\nimport kafka.javaapi.consumer.ConsumerConnector;\nimport kafka.javaapi.producer.Producer;\nimport kafka.producer.KeyedMessage;\nimport kafka.producer.ProducerConfig;\nimport me.kazaff.mq.avro.Message;\nimport org.apache.avro.io.*;\nimport org.apache.avro.specific.SpecificDatumReader;\nimport org.apache.avro.specific.SpecificDatumWriter;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.util.*;\n\npublic class Main {\n\n    public static void main(String[] args){\n        try {\n            //消息生产\n            produce();\n\n            //消息消费\n            consume();\n\n        }catch (Exception ex){\n            System.out.println(ex);\n        }\n\n    }\n\n    private static void produce() throws IOException{\n        Properties props = new Properties();\n        props.put(&quot;metadata.broker.list&quot;, &quot;localhost:9092&quot;);\n        props.put(&quot;serializer.class&quot;, &quot;kafka.serializer.DefaultEncoder&quot;);\n        props.put(&quot;key.serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;);    //key的类型需要和serializer保持一致，如果key是String，则需要配置为kafka.serializer.StringEncoder，如果不配置，默认为kafka.serializer.DefaultEncoder，即二进制格式\n        props.put(&quot;partition.class&quot;, &quot;me.kazaff.mq.MyPartitioner&quot;);\n        props.put(&quot;request.required.acks&quot;, &quot;1&quot;);\n\n        ProducerConfig config = new ProducerConfig(props);\n        Producer&lt;String, byte[]&gt; producer = new Producer&lt;String, byte[]&gt;(config);\n\n        Random rnd = new Random();\n        for(int index = 0; index &lt;= 10; index++){\n            Message msg = new Message();\n            msg.setUrl(&quot;blog.kazaff.me&quot;);\n            msg.setIp(&quot;192.168.137.&quot; + rnd.nextInt(255));\n            msg.setDate(Long.toString(new Date().getTime()));\n\n            DatumWriter&lt;Message&gt; msgDatumWriter = new SpecificDatumWriter&lt;Message&gt;(Message.class);\n            ByteArrayOutputStream os = new ByteArrayOutputStream();\n            try {\n                Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n                msgDatumWriter.write(msg, e);\n                e.flush();\n                byte[] byteData = os.toByteArray();\n\n                KeyedMessage&lt;String, byte[]&gt; data = new KeyedMessage&lt;String, byte[]&gt;(&quot;demo&quot;, &quot;0&quot;, byteData);\n                producer.send(data);\n\n            }catch (IOException ex){\n                System.out.println(ex.getMessage());\n            }finally {\n                os.close();\n            }\n        }\n        producer.close();\n    }\n\n    private static void consume(){\n        Properties props = new Properties();\n        props.put(&quot;zookeeper.connect&quot;, &quot;localhost:2181&quot;);\n        props.put(&quot;group.id&quot;, &quot;1&quot;);\n        props.put(&quot;zookeeper.session.timeout.ms&quot;, &quot;400&quot;);\n        props.put(&quot;zookeeper.sync.time.ms&quot;, &quot;200&quot;);\n        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);\n\n        ConsumerConnector consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(props));\n        Map&lt;String, Integer&gt; topicCountMap = new HashMap&lt;String, Integer&gt;();\n        topicCountMap.put(&quot;demo&quot;, 1);\n        Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; consumerMap = consumer.createMessageStreams(topicCountMap);\n        List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt; streams = consumerMap.get(&quot;demo&quot;);\n        KafkaStream steam = streams.get(0);\n\n        ConsumerIterator&lt;byte[], byte[]&gt; it = steam.iterator();\n        while (it.hasNext()){\n            try {\n                DatumReader&lt;Message&gt; reader = new SpecificDatumReader&lt;Message&gt;(Message.class);\n                Decoder decoder = DecoderFactory.get().binaryDecoder(it.next().message(), null);\n                Message msg = reader.read(null, decoder);\n\n                System.out.println(msg.getDate() + &quot;,&quot; + msg.getUrl() + &quot;,&quot; + msg.getIp());\n\n            }catch (Exception ex){\n                System.out.println(ex);\n            }\n        }\n\n        if(consumer != null)\n            consumer.shutdown();\n    }\n}\n</code></pre><p><strong>PS：这只是个测试的例子，存在各种问题，不建议直接使用在项目中。</strong></p>\n<p>为了方便大家直接测试，我把pom.xml也贴出来：</p>\n<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n     xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n    &lt;groupId&gt;me.kazaff.mq&lt;/groupId&gt;\n    &lt;artifactId&gt;kafkaProducer&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1&lt;/version&gt;\n    &lt;packaging&gt;jar&lt;/packaging&gt;\n    &lt;name&gt;kafkaProducer&lt;/name&gt;\n    &lt;description&gt;The Producer of message, use Avro to encode data, and send to the kafka.&lt;/description&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;\n            &lt;artifactId&gt;kafka_2.11&lt;/artifactId&gt;\n            &lt;version&gt;0.8.2.1&lt;/version&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n            &lt;artifactId&gt;avro&lt;/artifactId&gt;\n            &lt;version&gt;1.7.6-cdh5.2.5&lt;/version&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n                &lt;artifactId&gt;avro-maven-plugin&lt;/artifactId&gt;\n                &lt;version&gt;1.7.6&lt;/version&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;phase&gt;generate-sources&lt;/phase&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;schema&lt;/goal&gt;\n                        &lt;/goals&gt;\n                        &lt;configuration&gt;\n                            &lt;sourceDirectory&gt;${project.basedir}/src/avro/&lt;/sourceDirectory&gt;\n                            &lt;outputDirectory&gt;${project.basedir}/src/&lt;/outputDirectory&gt;\n                        &lt;/configuration&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;1.7&lt;/source&gt;\n                    &lt;target&gt;1.7&lt;/target&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n    &lt;repositories&gt;\n        &lt;repository&gt;\n            &lt;id&gt;cloudera-repo-releases&lt;/id&gt;\n            &lt;url&gt;https://repository.cloudera.com/artifactory/repo/&lt;/url&gt;\n        &lt;/repository&gt;\n    &lt;/repositories&gt;\n&lt;/project&gt;\n</code></pre><p>下面是Avro使用的Schema：</p>\n<pre><code>{\n    &quot;namespace&quot;: &quot;me.kazaff.mq.avro&quot;,\n    &quot;type&quot;: &quot;record&quot;,\n    &quot;name&quot;: &quot;Message&quot;,\n    &quot;fields&quot;: [\n        {\n            &quot;name&quot;: &quot;date&quot;,\n            &quot;type&quot;: &quot;string&quot;\n        },\n        {\n            &quot;name&quot;: &quot;url&quot;,\n            &quot;type&quot;: &quot;string&quot;\n        },\n        {\n            &quot;name&quot;: &quot;ip&quot;,\n            &quot;type&quot;: &quot;string&quot;\n        }\n    ]\n}\n</code></pre><p>代码中使用的<code>MyPartitioner</code>其实很sb：</p>\n<pre><code>package me.kazaff.mq;\n\nimport kafka.producer.Partitioner;\nimport kafka.utils.VerifiableProperties;\n\n/**\n * Created by kazaff on 2015/4/21.\n */\npublic class MyPartitioner implements Partitioner {\n    public MyPartitioner(VerifiableProperties props){}\n\n    public int partition(Object key, int numPartitions){\n        return 0;\n    }\n}\n</code></pre><p>需要注意的是，我是先使用Maven根据配置的plugin，把声明的Schema先处理生成对应的Class文件，然后再进行运行测试的~</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><hr>\n<h4 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1.\"></a>1.</h4><blockquote>\n<p>java.lang.ClassCastException: [B cannot be cast to java.lang.String</p>\n</blockquote>\n<p>解决方法很简单：</p>\n<pre><code>props.put(&quot;serializer.class&quot;, &quot;kafka.serializer.DefaultEncoder&quot;);\n</code></pre><p>这样，kafka就默认使用二进制的序列化方案处理Avro的编码结果了。</p>\n<h4 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2.\"></a>2.</h4><blockquote>\n<p>java.lang.ClassCastException: java.lang.String cannot be cast to [B</p>\n</blockquote>\n<p>这个问题是最恶心的，搜了半天都没有找到原因，原因是<strong>问题1</strong>中那么设置后，Kafka所有的数据序列化方式都成了二进制方式，包括我们后面要使用的“key”（用于kafka选择分区的线索）。</p>\n<p>所以你还需要再加一条配置：</p>\n<pre><code>props.put(&quot;key.serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;);\n</code></pre><p>单独设置一下“key”的序列化方式，这样就可以编译运行了~~</p>\n<hr>\n<p>初尝Kafka和Avro，就这么点儿要记录的，不要嫌少哟~~</p>"},{"title":"Jedis异常Could not get a resource from the pool","date":"2015-01-04T08:42:58.000Z","_content":"\n今天用`jmeter`对项目中的相关接口进行压力测试，发现一个问题：\n\n> 严重: Servlet.service() for servlet [mvc-dispatcher] in context with path [] threw exception\njava.io.IOException: org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool\n\n<!--more-->\n\n字面意思来看，应该是redis连接池没有可申请的连接了。当然，在低并发测试时是不会看到这个报错的，大概在我把并发数调到200左右时会狂报这个错误！\n\n根据网上前辈们的总结，无非就是调整`Jedis`连接池的配置，redis本身的连接数的配置等等。这里我就不再复述了，我只想说，按照这些指示做了一边后问题并没任何好转。\n\n我用的是工作机，操作系统是WIN7 64位，redis用的是2.8.3 win64版，jedis的版本是2.6.1（网上说2.1.0之前的版本要手动归还连接），应用中操作redis的api是依赖spring-data封装的，配置如下：\n\n\t<!-- 会话持久层redis配置 -->\n    <bean id=\"poolConfig\" class=\"redis.clients.jedis.JedisPoolConfig\">\n        <property name=\"maxIdle\" value=\"${redis.maxIdle}\" />\n        <property name=\"maxTotal\" value=\"${redis.maxTotal}\" />\n        <property name=\"maxWaitMillis\" value=\"${redis.maxWaitMillis}\" />\n        <property name=\"testOnBorrow\" value=\"${redis.testOnBorrow}\" />\n        <property name=\"testOnReturn\" value=\"${redis.testOnReturn}\" />\n    </bean>\n\n    <bean id=\"jedisConnFactory\" class=\"org.springframework.data.redis.connection.jedis.JedisConnectionFactory\">\n        <property name=\"hostName\" value=\"${redis.host}\" />\n        <property name=\"port\" value=\"${redis.port}\" />\n        <property name=\"password\" value=\"${redis.password}\" />\n        <property name=\"usePool\" value=\"true\" />\n        <property name=\"poolConfig\" ref=\"poolConfig\" />\n        <property name=\"database\" value=\"${redis.db}\" />\n    </bean>\n\n    <bean id=\"redisTemplate\" class=\"org.springframework.data.redis.core.RedisTemplate\">\n        <property name=\"connectionFactory\" ref=\"jedisConnFactory\" />\n        <property name=\"keySerializer\">\n            <bean class=\"org.springframework.data.redis.serializer.StringRedisSerializer\" />\n        </property>\n        <property name=\"valueSerializer\">\n            <bean class=\"org.springframework.data.redis.serializer.JdkSerializationRedisSerializer\" />\n        </property>\n    </bean>\n\nredis连接池相关的参数如下：\n\n\t#redis配置\n\tredis.maxIdle=100\n\tredis.maxTotal=1000\n\tredis.maxWaitMillis=2000\n\tredis.testOnBorrow=true\n\tredis.testOnReturn=true\n\n中规中矩，而且按照我配置的相关参数，设置的并发500绝逼不应该报这个错误的！其中一个细节是，当应用狂报错时，redis-cli命令也无法连接到redis服务了，也就是说redis本身的配置根本就不匹配我在应用中连接池的配置，这应该是导致问题的根本原因，简单地说就是：\n\n> redis本身的连接数上限必须大于应用连接池中的最大连接数\n\n可本尊看了一下redis.conf文件，其中`maxClients`的值为0，也就是不限制。这尼玛如何是好？\n\n突然想到多年之前，小弟我刚接触redis的时候，就看到过一个大牛曾经说过：**redis的win版本基本上就是个玩具**。\n\n抱着试一试的心态（<s>我也购买了两盒...</s>），我试着让应用直连centos中的redis服务，尼玛直接就解决了，或者说出现的情况至少和配置相吻合，而且在linux下redis-server在启动之初就会提醒你关于连接数的配置，很贴心。\n\n好吧，最好再延伸一个老知识点，如果你想把redis的连接数设置的很大，很可能会超过目前配置的系统可使用文件句柄数上限，这时你的配置就会失效，那如何突破这个瓶颈呢，你需要了解一下这个命令： [ulimit](http://linuxguest.blog.51cto.com/195664/362366/)。\n\nPS：redis在linux上跑起来，就像吃了枪药，打了鸡血，磕了军粮丸一样，根本停不下来啊！","source":"_posts/Jedis异常Could not get a resource from the pool.md","raw":"title: Jedis异常Could not get a resource from the pool\ndate: 2015-01-04 16:42:58\ntags: \n- jedis\n- redis\n- 连接池\n- jmeter\n- ulimit\ncategories: j2ee\n---\n\n今天用`jmeter`对项目中的相关接口进行压力测试，发现一个问题：\n\n> 严重: Servlet.service() for servlet [mvc-dispatcher] in context with path [] threw exception\njava.io.IOException: org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool\n\n<!--more-->\n\n字面意思来看，应该是redis连接池没有可申请的连接了。当然，在低并发测试时是不会看到这个报错的，大概在我把并发数调到200左右时会狂报这个错误！\n\n根据网上前辈们的总结，无非就是调整`Jedis`连接池的配置，redis本身的连接数的配置等等。这里我就不再复述了，我只想说，按照这些指示做了一边后问题并没任何好转。\n\n我用的是工作机，操作系统是WIN7 64位，redis用的是2.8.3 win64版，jedis的版本是2.6.1（网上说2.1.0之前的版本要手动归还连接），应用中操作redis的api是依赖spring-data封装的，配置如下：\n\n\t<!-- 会话持久层redis配置 -->\n    <bean id=\"poolConfig\" class=\"redis.clients.jedis.JedisPoolConfig\">\n        <property name=\"maxIdle\" value=\"${redis.maxIdle}\" />\n        <property name=\"maxTotal\" value=\"${redis.maxTotal}\" />\n        <property name=\"maxWaitMillis\" value=\"${redis.maxWaitMillis}\" />\n        <property name=\"testOnBorrow\" value=\"${redis.testOnBorrow}\" />\n        <property name=\"testOnReturn\" value=\"${redis.testOnReturn}\" />\n    </bean>\n\n    <bean id=\"jedisConnFactory\" class=\"org.springframework.data.redis.connection.jedis.JedisConnectionFactory\">\n        <property name=\"hostName\" value=\"${redis.host}\" />\n        <property name=\"port\" value=\"${redis.port}\" />\n        <property name=\"password\" value=\"${redis.password}\" />\n        <property name=\"usePool\" value=\"true\" />\n        <property name=\"poolConfig\" ref=\"poolConfig\" />\n        <property name=\"database\" value=\"${redis.db}\" />\n    </bean>\n\n    <bean id=\"redisTemplate\" class=\"org.springframework.data.redis.core.RedisTemplate\">\n        <property name=\"connectionFactory\" ref=\"jedisConnFactory\" />\n        <property name=\"keySerializer\">\n            <bean class=\"org.springframework.data.redis.serializer.StringRedisSerializer\" />\n        </property>\n        <property name=\"valueSerializer\">\n            <bean class=\"org.springframework.data.redis.serializer.JdkSerializationRedisSerializer\" />\n        </property>\n    </bean>\n\nredis连接池相关的参数如下：\n\n\t#redis配置\n\tredis.maxIdle=100\n\tredis.maxTotal=1000\n\tredis.maxWaitMillis=2000\n\tredis.testOnBorrow=true\n\tredis.testOnReturn=true\n\n中规中矩，而且按照我配置的相关参数，设置的并发500绝逼不应该报这个错误的！其中一个细节是，当应用狂报错时，redis-cli命令也无法连接到redis服务了，也就是说redis本身的配置根本就不匹配我在应用中连接池的配置，这应该是导致问题的根本原因，简单地说就是：\n\n> redis本身的连接数上限必须大于应用连接池中的最大连接数\n\n可本尊看了一下redis.conf文件，其中`maxClients`的值为0，也就是不限制。这尼玛如何是好？\n\n突然想到多年之前，小弟我刚接触redis的时候，就看到过一个大牛曾经说过：**redis的win版本基本上就是个玩具**。\n\n抱着试一试的心态（<s>我也购买了两盒...</s>），我试着让应用直连centos中的redis服务，尼玛直接就解决了，或者说出现的情况至少和配置相吻合，而且在linux下redis-server在启动之初就会提醒你关于连接数的配置，很贴心。\n\n好吧，最好再延伸一个老知识点，如果你想把redis的连接数设置的很大，很可能会超过目前配置的系统可使用文件句柄数上限，这时你的配置就会失效，那如何突破这个瓶颈呢，你需要了解一下这个命令： [ulimit](http://linuxguest.blog.51cto.com/195664/362366/)。\n\nPS：redis在linux上跑起来，就像吃了枪药，打了鸡血，磕了军粮丸一样，根本停不下来啊！","slug":"Jedis异常Could not get a resource from the pool","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18ysv00degtfypzo7rlti","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天用<code>jmeter</code>对项目中的相关接口进行压力测试，发现一个问题：</p>\n<blockquote>\n<p>严重: Servlet.service() for servlet [mvc-dispatcher] in context with path [] threw exception<br>java.io.IOException: org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>字面意思来看，应该是redis连接池没有可申请的连接了。当然，在低并发测试时是不会看到这个报错的，大概在我把并发数调到200左右时会狂报这个错误！</p>\n<p>根据网上前辈们的总结，无非就是调整<code>Jedis</code>连接池的配置，redis本身的连接数的配置等等。这里我就不再复述了，我只想说，按照这些指示做了一边后问题并没任何好转。</p>\n<p>我用的是工作机，操作系统是WIN7 64位，redis用的是2.8.3 win64版，jedis的版本是2.6.1（网上说2.1.0之前的版本要手动归还连接），应用中操作redis的api是依赖spring-data封装的，配置如下：</p>\n<pre><code>&lt;!-- 会话持久层redis配置 --&gt;\n&lt;bean id=&quot;poolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;\n    &lt;property name=&quot;maxIdle&quot; value=&quot;${redis.maxIdle}&quot; /&gt;\n    &lt;property name=&quot;maxTotal&quot; value=&quot;${redis.maxTotal}&quot; /&gt;\n    &lt;property name=&quot;maxWaitMillis&quot; value=&quot;${redis.maxWaitMillis}&quot; /&gt;\n    &lt;property name=&quot;testOnBorrow&quot; value=&quot;${redis.testOnBorrow}&quot; /&gt;\n    &lt;property name=&quot;testOnReturn&quot; value=&quot;${redis.testOnReturn}&quot; /&gt;\n&lt;/bean&gt;\n\n&lt;bean id=&quot;jedisConnFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt;\n    &lt;property name=&quot;hostName&quot; value=&quot;${redis.host}&quot; /&gt;\n    &lt;property name=&quot;port&quot; value=&quot;${redis.port}&quot; /&gt;\n    &lt;property name=&quot;password&quot; value=&quot;${redis.password}&quot; /&gt;\n    &lt;property name=&quot;usePool&quot; value=&quot;true&quot; /&gt;\n    &lt;property name=&quot;poolConfig&quot; ref=&quot;poolConfig&quot; /&gt;\n    &lt;property name=&quot;database&quot; value=&quot;${redis.db}&quot; /&gt;\n&lt;/bean&gt;\n\n&lt;bean id=&quot;redisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt;\n    &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnFactory&quot; /&gt;\n    &lt;property name=&quot;keySerializer&quot;&gt;\n        &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot; /&gt;\n    &lt;/property&gt;\n    &lt;property name=&quot;valueSerializer&quot;&gt;\n        &lt;bean class=&quot;org.springframework.data.redis.serializer.JdkSerializationRedisSerializer&quot; /&gt;\n    &lt;/property&gt;\n&lt;/bean&gt;\n</code></pre><p>redis连接池相关的参数如下：</p>\n<pre><code>#redis配置\nredis.maxIdle=100\nredis.maxTotal=1000\nredis.maxWaitMillis=2000\nredis.testOnBorrow=true\nredis.testOnReturn=true\n</code></pre><p>中规中矩，而且按照我配置的相关参数，设置的并发500绝逼不应该报这个错误的！其中一个细节是，当应用狂报错时，redis-cli命令也无法连接到redis服务了，也就是说redis本身的配置根本就不匹配我在应用中连接池的配置，这应该是导致问题的根本原因，简单地说就是：</p>\n<blockquote>\n<p>redis本身的连接数上限必须大于应用连接池中的最大连接数</p>\n</blockquote>\n<p>可本尊看了一下redis.conf文件，其中<code>maxClients</code>的值为0，也就是不限制。这尼玛如何是好？</p>\n<p>突然想到多年之前，小弟我刚接触redis的时候，就看到过一个大牛曾经说过：<strong>redis的win版本基本上就是个玩具</strong>。</p>\n<p>抱着试一试的心态（<s>我也购买了两盒…</s>），我试着让应用直连centos中的redis服务，尼玛直接就解决了，或者说出现的情况至少和配置相吻合，而且在linux下redis-server在启动之初就会提醒你关于连接数的配置，很贴心。</p>\n<p>好吧，最好再延伸一个老知识点，如果你想把redis的连接数设置的很大，很可能会超过目前配置的系统可使用文件句柄数上限，这时你的配置就会失效，那如何突破这个瓶颈呢，你需要了解一下这个命令： <a href=\"http://linuxguest.blog.51cto.com/195664/362366/\" target=\"_blank\" rel=\"external\">ulimit</a>。</p>\n<p>PS：redis在linux上跑起来，就像吃了枪药，打了鸡血，磕了军粮丸一样，根本停不下来啊！</p>\n","excerpt":"<p>今天用<code>jmeter</code>对项目中的相关接口进行压力测试，发现一个问题：</p>\n<blockquote>\n<p>严重: Servlet.service() for servlet [mvc-dispatcher] in context with path [] threw exception<br>java.io.IOException: org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool</p>\n</blockquote>","more":"<p>字面意思来看，应该是redis连接池没有可申请的连接了。当然，在低并发测试时是不会看到这个报错的，大概在我把并发数调到200左右时会狂报这个错误！</p>\n<p>根据网上前辈们的总结，无非就是调整<code>Jedis</code>连接池的配置，redis本身的连接数的配置等等。这里我就不再复述了，我只想说，按照这些指示做了一边后问题并没任何好转。</p>\n<p>我用的是工作机，操作系统是WIN7 64位，redis用的是2.8.3 win64版，jedis的版本是2.6.1（网上说2.1.0之前的版本要手动归还连接），应用中操作redis的api是依赖spring-data封装的，配置如下：</p>\n<pre><code>&lt;!-- 会话持久层redis配置 --&gt;\n&lt;bean id=&quot;poolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;\n    &lt;property name=&quot;maxIdle&quot; value=&quot;${redis.maxIdle}&quot; /&gt;\n    &lt;property name=&quot;maxTotal&quot; value=&quot;${redis.maxTotal}&quot; /&gt;\n    &lt;property name=&quot;maxWaitMillis&quot; value=&quot;${redis.maxWaitMillis}&quot; /&gt;\n    &lt;property name=&quot;testOnBorrow&quot; value=&quot;${redis.testOnBorrow}&quot; /&gt;\n    &lt;property name=&quot;testOnReturn&quot; value=&quot;${redis.testOnReturn}&quot; /&gt;\n&lt;/bean&gt;\n\n&lt;bean id=&quot;jedisConnFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt;\n    &lt;property name=&quot;hostName&quot; value=&quot;${redis.host}&quot; /&gt;\n    &lt;property name=&quot;port&quot; value=&quot;${redis.port}&quot; /&gt;\n    &lt;property name=&quot;password&quot; value=&quot;${redis.password}&quot; /&gt;\n    &lt;property name=&quot;usePool&quot; value=&quot;true&quot; /&gt;\n    &lt;property name=&quot;poolConfig&quot; ref=&quot;poolConfig&quot; /&gt;\n    &lt;property name=&quot;database&quot; value=&quot;${redis.db}&quot; /&gt;\n&lt;/bean&gt;\n\n&lt;bean id=&quot;redisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt;\n    &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnFactory&quot; /&gt;\n    &lt;property name=&quot;keySerializer&quot;&gt;\n        &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot; /&gt;\n    &lt;/property&gt;\n    &lt;property name=&quot;valueSerializer&quot;&gt;\n        &lt;bean class=&quot;org.springframework.data.redis.serializer.JdkSerializationRedisSerializer&quot; /&gt;\n    &lt;/property&gt;\n&lt;/bean&gt;\n</code></pre><p>redis连接池相关的参数如下：</p>\n<pre><code>#redis配置\nredis.maxIdle=100\nredis.maxTotal=1000\nredis.maxWaitMillis=2000\nredis.testOnBorrow=true\nredis.testOnReturn=true\n</code></pre><p>中规中矩，而且按照我配置的相关参数，设置的并发500绝逼不应该报这个错误的！其中一个细节是，当应用狂报错时，redis-cli命令也无法连接到redis服务了，也就是说redis本身的配置根本就不匹配我在应用中连接池的配置，这应该是导致问题的根本原因，简单地说就是：</p>\n<blockquote>\n<p>redis本身的连接数上限必须大于应用连接池中的最大连接数</p>\n</blockquote>\n<p>可本尊看了一下redis.conf文件，其中<code>maxClients</code>的值为0，也就是不限制。这尼玛如何是好？</p>\n<p>突然想到多年之前，小弟我刚接触redis的时候，就看到过一个大牛曾经说过：<strong>redis的win版本基本上就是个玩具</strong>。</p>\n<p>抱着试一试的心态（<s>我也购买了两盒…</s>），我试着让应用直连centos中的redis服务，尼玛直接就解决了，或者说出现的情况至少和配置相吻合，而且在linux下redis-server在启动之初就会提醒你关于连接数的配置，很贴心。</p>\n<p>好吧，最好再延伸一个老知识点，如果你想把redis的连接数设置的很大，很可能会超过目前配置的系统可使用文件句柄数上限，这时你的配置就会失效，那如何突破这个瓶颈呢，你需要了解一下这个命令： <a href=\"http://linuxguest.blog.51cto.com/195664/362366/\">ulimit</a>。</p>\n<p>PS：redis在linux上跑起来，就像吃了枪药，打了鸡血，磕了军粮丸一样，根本停不下来啊！</p>"},{"title":"JDBC的超时问题","date":"2015-04-28T07:54:30.000Z","_content":"\njava新人，问题多多~今天来聊聊JDBC的连接超时问题。\n<!--more-->\n首先，我把mysql的两个相关参数设置为：\n\n\tinteractive_timeout=10\n\twait_timeout=10\n\n单位为秒，也就是说不管是交互还是非交互式的客户端在空闲十秒mysql就会自动断开对应连接。\n\n好，继续，使用`org.springframework.jdbc.datasource.DriverManagerDataSource `来进行数据库查询，是否会出现超时错误呢？\n\n\tApplicationContext context = new ClassPathXmlApplicationContext(\"spring-config.xml\");\n    JdbcTemplate jdbcTemplate = (JdbcTemplate)context.getBean(\"jdbcTemplate\");\n\n    String sql = \"SELECT * FROM diabloo LIMIT 1\";\n    User target = jdbcTemplate.queryForObject(sql, new RowMapper<User>() {\n        public User mapRow(ResultSet rs, int i) throws SQLException {\n            User one = new User();\n            one.setName(rs.getString(\"name\"));\n            return one;\n        }\n    });\n    System.out.println(target.getName());\n\n    //睡眠足够时间，导致mysql连接超时\n    Thread.sleep(11000);\n\n    sql = \"SELECT * FROM diabloo LIMIT 1\";\n    target = jdbcTemplate.queryForObject(sql, new RowMapper<User>() {\n        public User mapRow(ResultSet rs, int i) throws SQLException {\n            User one = new User();\n            one.setName(rs.getString(\"name\"));\n            return one;\n        }\n    });\n    System.out.println(target.getName());\n\n我以为会超时的，但却一切正常，后来gg搜索，才发现原因：\n\n> DriverManagerDataSource建立连接是只要有连接就新建一个connection，......\n\n这在我看来，有点吃惊，不过后来就明白了Spring提供这个类的目的，我想更多的理由是用它来充当数据池的**connectFactory角色**。\n\n再看来直接使用原始的JDBC情况下是否会出现超时：\n\n\tClass.forName(\"com.mysql.jdbc.Driver\");\n    // 建立连接\n    Connection con = DriverManager.getConnection(\n            \"jdbc:mysql://localhost:3306/test\", \"root\", \"\");\n    Statement stmt = con.createStatement();\n    ResultSet rs = stmt.executeQuery(\"SELECT * FROM diabloo LIMIT 1\");\n    while (rs.next()) {\n        String name = rs.getString(\"name\");\n        System.out.println(name);\n    }\n\n    //睡眠足够时间，导致mysql连接超时\n    Thread.sleep(11000);\n\n    stmt = con.createStatement();\n    rs = stmt.executeQuery(\"SELECT * FROM diabloo LIMIT 1\");\n    while (rs.next()) {\n        String name = rs.getString(\"name\");\n        System.out.println(name);\n    }\n\n这就和猜想一致了，报超时异常了~~\n\n另附一大神的[文章](http://www.importnew.com/2466.html#show-last-Point)，推荐阅读~","source":"_posts/JDBC的超时问题.md","raw":"title: JDBC的超时问题\ndate: 2015-04-28 15:54:30\ntags:\n- mysql\n- timeout\n- 超时\n- jdbc\n- DriverManagerDataSource\n\ncategories: j2ee\n---\n\njava新人，问题多多~今天来聊聊JDBC的连接超时问题。\n<!--more-->\n首先，我把mysql的两个相关参数设置为：\n\n\tinteractive_timeout=10\n\twait_timeout=10\n\n单位为秒，也就是说不管是交互还是非交互式的客户端在空闲十秒mysql就会自动断开对应连接。\n\n好，继续，使用`org.springframework.jdbc.datasource.DriverManagerDataSource `来进行数据库查询，是否会出现超时错误呢？\n\n\tApplicationContext context = new ClassPathXmlApplicationContext(\"spring-config.xml\");\n    JdbcTemplate jdbcTemplate = (JdbcTemplate)context.getBean(\"jdbcTemplate\");\n\n    String sql = \"SELECT * FROM diabloo LIMIT 1\";\n    User target = jdbcTemplate.queryForObject(sql, new RowMapper<User>() {\n        public User mapRow(ResultSet rs, int i) throws SQLException {\n            User one = new User();\n            one.setName(rs.getString(\"name\"));\n            return one;\n        }\n    });\n    System.out.println(target.getName());\n\n    //睡眠足够时间，导致mysql连接超时\n    Thread.sleep(11000);\n\n    sql = \"SELECT * FROM diabloo LIMIT 1\";\n    target = jdbcTemplate.queryForObject(sql, new RowMapper<User>() {\n        public User mapRow(ResultSet rs, int i) throws SQLException {\n            User one = new User();\n            one.setName(rs.getString(\"name\"));\n            return one;\n        }\n    });\n    System.out.println(target.getName());\n\n我以为会超时的，但却一切正常，后来gg搜索，才发现原因：\n\n> DriverManagerDataSource建立连接是只要有连接就新建一个connection，......\n\n这在我看来，有点吃惊，不过后来就明白了Spring提供这个类的目的，我想更多的理由是用它来充当数据池的**connectFactory角色**。\n\n再看来直接使用原始的JDBC情况下是否会出现超时：\n\n\tClass.forName(\"com.mysql.jdbc.Driver\");\n    // 建立连接\n    Connection con = DriverManager.getConnection(\n            \"jdbc:mysql://localhost:3306/test\", \"root\", \"\");\n    Statement stmt = con.createStatement();\n    ResultSet rs = stmt.executeQuery(\"SELECT * FROM diabloo LIMIT 1\");\n    while (rs.next()) {\n        String name = rs.getString(\"name\");\n        System.out.println(name);\n    }\n\n    //睡眠足够时间，导致mysql连接超时\n    Thread.sleep(11000);\n\n    stmt = con.createStatement();\n    rs = stmt.executeQuery(\"SELECT * FROM diabloo LIMIT 1\");\n    while (rs.next()) {\n        String name = rs.getString(\"name\");\n        System.out.println(name);\n    }\n\n这就和猜想一致了，报超时异常了~~\n\n另附一大神的[文章](http://www.importnew.com/2466.html#show-last-Point)，推荐阅读~","slug":"JDBC的超时问题","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yt000dpgtfyfweottii","comments":1,"layout":"post","photos":[],"link":"","content":"<p>java新人，问题多多~今天来聊聊JDBC的连接超时问题。<br><a id=\"more\"></a><br>首先，我把mysql的两个相关参数设置为：</p>\n<pre><code>interactive_timeout=10\nwait_timeout=10\n</code></pre><p>单位为秒，也就是说不管是交互还是非交互式的客户端在空闲十秒mysql就会自动断开对应连接。</p>\n<p>好，继续，使用<code>org.springframework.jdbc.datasource.DriverManagerDataSource</code>来进行数据库查询，是否会出现超时错误呢？</p>\n<pre><code>ApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-config.xml&quot;);\nJdbcTemplate jdbcTemplate = (JdbcTemplate)context.getBean(&quot;jdbcTemplate&quot;);\n\nString sql = &quot;SELECT * FROM diabloo LIMIT 1&quot;;\nUser target = jdbcTemplate.queryForObject(sql, new RowMapper&lt;User&gt;() {\n    public User mapRow(ResultSet rs, int i) throws SQLException {\n        User one = new User();\n        one.setName(rs.getString(&quot;name&quot;));\n        return one;\n    }\n});\nSystem.out.println(target.getName());\n\n//睡眠足够时间，导致mysql连接超时\nThread.sleep(11000);\n\nsql = &quot;SELECT * FROM diabloo LIMIT 1&quot;;\ntarget = jdbcTemplate.queryForObject(sql, new RowMapper&lt;User&gt;() {\n    public User mapRow(ResultSet rs, int i) throws SQLException {\n        User one = new User();\n        one.setName(rs.getString(&quot;name&quot;));\n        return one;\n    }\n});\nSystem.out.println(target.getName());\n</code></pre><p>我以为会超时的，但却一切正常，后来gg搜索，才发现原因：</p>\n<blockquote>\n<p>DriverManagerDataSource建立连接是只要有连接就新建一个connection，……</p>\n</blockquote>\n<p>这在我看来，有点吃惊，不过后来就明白了Spring提供这个类的目的，我想更多的理由是用它来充当数据池的<strong>connectFactory角色</strong>。</p>\n<p>再看来直接使用原始的JDBC情况下是否会出现超时：</p>\n<pre><code>Class.forName(&quot;com.mysql.jdbc.Driver&quot;);\n// 建立连接\nConnection con = DriverManager.getConnection(\n        &quot;jdbc:mysql://localhost:3306/test&quot;, &quot;root&quot;, &quot;&quot;);\nStatement stmt = con.createStatement();\nResultSet rs = stmt.executeQuery(&quot;SELECT * FROM diabloo LIMIT 1&quot;);\nwhile (rs.next()) {\n    String name = rs.getString(&quot;name&quot;);\n    System.out.println(name);\n}\n\n//睡眠足够时间，导致mysql连接超时\nThread.sleep(11000);\n\nstmt = con.createStatement();\nrs = stmt.executeQuery(&quot;SELECT * FROM diabloo LIMIT 1&quot;);\nwhile (rs.next()) {\n    String name = rs.getString(&quot;name&quot;);\n    System.out.println(name);\n}\n</code></pre><p>这就和猜想一致了，报超时异常了~~</p>\n<p>另附一大神的<a href=\"http://www.importnew.com/2466.html#show-last-Point\" target=\"_blank\" rel=\"external\">文章</a>，推荐阅读~</p>\n","excerpt":"<p>java新人，问题多多~今天来聊聊JDBC的连接超时问题。<br>","more":"<br>首先，我把mysql的两个相关参数设置为：</p>\n<pre><code>interactive_timeout=10\nwait_timeout=10\n</code></pre><p>单位为秒，也就是说不管是交互还是非交互式的客户端在空闲十秒mysql就会自动断开对应连接。</p>\n<p>好，继续，使用<code>org.springframework.jdbc.datasource.DriverManagerDataSource</code>来进行数据库查询，是否会出现超时错误呢？</p>\n<pre><code>ApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-config.xml&quot;);\nJdbcTemplate jdbcTemplate = (JdbcTemplate)context.getBean(&quot;jdbcTemplate&quot;);\n\nString sql = &quot;SELECT * FROM diabloo LIMIT 1&quot;;\nUser target = jdbcTemplate.queryForObject(sql, new RowMapper&lt;User&gt;() {\n    public User mapRow(ResultSet rs, int i) throws SQLException {\n        User one = new User();\n        one.setName(rs.getString(&quot;name&quot;));\n        return one;\n    }\n});\nSystem.out.println(target.getName());\n\n//睡眠足够时间，导致mysql连接超时\nThread.sleep(11000);\n\nsql = &quot;SELECT * FROM diabloo LIMIT 1&quot;;\ntarget = jdbcTemplate.queryForObject(sql, new RowMapper&lt;User&gt;() {\n    public User mapRow(ResultSet rs, int i) throws SQLException {\n        User one = new User();\n        one.setName(rs.getString(&quot;name&quot;));\n        return one;\n    }\n});\nSystem.out.println(target.getName());\n</code></pre><p>我以为会超时的，但却一切正常，后来gg搜索，才发现原因：</p>\n<blockquote>\n<p>DriverManagerDataSource建立连接是只要有连接就新建一个connection，……</p>\n</blockquote>\n<p>这在我看来，有点吃惊，不过后来就明白了Spring提供这个类的目的，我想更多的理由是用它来充当数据池的<strong>connectFactory角色</strong>。</p>\n<p>再看来直接使用原始的JDBC情况下是否会出现超时：</p>\n<pre><code>Class.forName(&quot;com.mysql.jdbc.Driver&quot;);\n// 建立连接\nConnection con = DriverManager.getConnection(\n        &quot;jdbc:mysql://localhost:3306/test&quot;, &quot;root&quot;, &quot;&quot;);\nStatement stmt = con.createStatement();\nResultSet rs = stmt.executeQuery(&quot;SELECT * FROM diabloo LIMIT 1&quot;);\nwhile (rs.next()) {\n    String name = rs.getString(&quot;name&quot;);\n    System.out.println(name);\n}\n\n//睡眠足够时间，导致mysql连接超时\nThread.sleep(11000);\n\nstmt = con.createStatement();\nrs = stmt.executeQuery(&quot;SELECT * FROM diabloo LIMIT 1&quot;);\nwhile (rs.next()) {\n    String name = rs.getString(&quot;name&quot;);\n    System.out.println(name);\n}\n</code></pre><p>这就和猜想一致了，报超时异常了~~</p>\n<p>另附一大神的<a href=\"http://www.importnew.com/2466.html#show-last-Point\">文章</a>，推荐阅读~</p>"},{"title":"Avro的三种序列化方法","date":"2015-04-30T07:54:30.000Z","_content":"\n知道Avro有一段时间了，但是并没有过多的动手测试其用法，今天花时间好好找了几个例子来练习Avro，特此记录，供以后查阅。\n<!--more-->\nAvro提供了自身的RPC实现，可以更完美的利用Avro的设计思想来完成高性能的跨进程通信，不过我们这里只注重使用Avro的序列化/反序列化的细节。\n\nAvro使用Json来声明Schema，这个预先定义的模式作为通信两端数据协议，在网络传输前后对目标数据进行二进制处理。太多的理论可以从Avro官网上了解到，我们下面就进入代码模式。\n\n测试代码是基于Maven的，你可能会使用下面的pom.xml：\n\n\t<dependencies>\n        <dependency>\n            <groupId>org.apache.avro</groupId>\n            <artifactId>avro</artifactId>\n            <version>1.7.6-cdh5.2.5</version>\n        </dependency>\n    </dependencies>\n\n\t<repositories>\n        <repository>\n            <id>cloudera-repo-releases</id>\n            <url>https://repository.cloudera.com/artifactory/repo/</url>\n        </repository>\n    </repositories>\n\n#### 方法1\n---\n该方法描述的场景是：用指定的json schema对数据进行编码，并用相同/近似的schema对数据进行解码。\n\t\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\t\n\timport org.apache.avro.Schema;\n\timport org.apache.avro.generic.GenericData;\n\timport org.apache.avro.generic.GenericDatumReader;\n\timport org.apache.avro.generic.GenericDatumWriter;\n\timport org.apache.avro.generic.GenericRecord;\n\timport org.apache.avro.io.DatumReader;\n\timport org.apache.avro.io.Decoder;\n\timport org.apache.avro.io.DecoderFactory;\n\timport org.apache.avro.io.Encoder;\n\timport org.apache.avro.io.EncoderFactory;\n\t\n\tpublic class AvroTest {\n\t    public static void main(String[] args) throws IOException {\n\t        // Schema\n\t        String schemaDescription = \" {    \\n\"\n\t                + \" \\\"name\\\": \\\"FacebookUser\\\", \\n\"\n\t                + \" \\\"type\\\": \\\"record\\\",\\n\" + \" \\\"fields\\\": [\\n\"\n\t                + \"   {\\\"name\\\": \\\"name\\\", \\\"type\\\": \\\"string\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_likes\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_photos\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_groups\\\", \\\"type\\\": \\\"int\\\"} ]\\n\" + \"}\";\n\t\n\t        Schema s = Schema.parse(schemaDescription);\t//parse方法在当前的Avro版本下已不推荐使用\n\t        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n\t        Encoder e = EncoderFactory.get().binaryEncoder(outputStream, null);\n\t        GenericDatumWriter w = new GenericDatumWriter(s);\n\t\n\t        // Populate data\n\t        GenericRecord r = new GenericData.Record(s);\n\t        r.put(\"name\", new org.apache.avro.util.Utf8(\"kazaff\"));\n\t        r.put(\"num_likes\", 1);\n\t        r.put(\"num_groups\", 423);\n\t        r.put(\"num_photos\", 0);\n\t\n\t        // Encode\n\t        w.write(r, e);\n\t        e.flush();\n\t       \n\t        byte[] encodedByteArray = outputStream.toByteArray();\n\t        String encodedString = outputStream.toString();\n\t       \n\t        System.out.println(\"encodedString: \"+encodedString);\n\t       \n\t        // Decode using same schema\n\t        DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>(s);\n\t        Decoder decoder = DecoderFactory.get().binaryDecoder(encodedByteArray, null);\n\t        GenericRecord result = reader.read(null, decoder);\n\t        System.out.println(result.get(\"name\").toString());\n\t        System.out.println(result.get(\"num_likes\").toString());\n\t        System.out.println(result.get(\"num_groups\").toString());\n\t        System.out.println(result.get(\"num_photos\").toString());\n\t       \n\t    }\n\t}\n\n可以看出，编码解码都需要指定schema，这相当于要求通信两端必须提前通过某种交互来完成schema的同步工作（貌似Avro自带的RPC就实现了这个细节），通过代码中的打印语句，我们可以留意到，这种方式下，编码后的数据是不包含schema的（**我不确定对，但相比第二种方式确实有这种差异性**）。\n\n\n#### 方法2\n---\n该方法采用的方式是通过指定的json schema把数据进行编码，并同时把schema作为metadata放在编码后的数据头部。解码则使用内嵌在数据中的schema来完成。\n\n\timport java.io.ByteArrayInputStream;\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\t\n\timport org.apache.avro.Schema;\n\timport org.apache.avro.file.DataFileStream;\n\timport org.apache.avro.file.DataFileWriter;\n\timport org.apache.avro.generic.GenericData;\n\timport org.apache.avro.generic.GenericDatumReader;\n\timport org.apache.avro.generic.GenericDatumWriter;\n\timport org.apache.avro.generic.GenericRecord;\n\timport org.apache.avro.io.DatumReader;\n\timport org.apache.avro.io.DatumWriter;\n\t\n\tpublic class AvroDataFile {\n\t\n\t    /**\n\t     * @param args\n\t     * @throws IOException\n\t     */\n\t    public static void main(String[] args) throws IOException {\n\t        // Schema\n\t        String schemaDescription = \" {    \\n\"\n\t                + \" \\\"name\\\": \\\"FacebookUser\\\", \\n\"\n\t                + \" \\\"type\\\": \\\"record\\\",\\n\" + \" \\\"fields\\\": [\\n\"\n\t                + \"   {\\\"name\\\": \\\"name\\\", \\\"type\\\": \\\"string\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_likes\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_photos\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_groups\\\", \\\"type\\\": \\\"int\\\"} ]\\n\" + \"}\";\n\t\n\t        Schema schema = Schema.parse(schemaDescription);\t//parse方法在当前的Avro版本下已不推荐使用\n\t        ByteArrayOutputStream os = new ByteArrayOutputStream();\n\t        DatumWriter<GenericRecord> writer = new GenericDatumWriter<GenericRecord>(schema);\n\t        DataFileWriter<GenericRecord> dataFileWriter = new DataFileWriter<GenericRecord>(writer);\n\t        dataFileWriter.create(schema, os);\n\t\n\t        // Populate data\n\t        GenericRecord datum = new GenericData.Record(schema);\n\t        datum.put(\"name\", new org.apache.avro.util.Utf8(\"kazaff\"));\n\t        datum.put(\"num_likes\", 1);\n\t        datum.put(\"num_groups\", 423);\n\t        datum.put(\"num_photos\", 0);\n\t\n\t        dataFileWriter.append(datum);\n\t        dataFileWriter.close();\n\t\n\t        System.out.println(\"encoded string: \" + os.toString());\t//可以看到，数据是头部携带了schema metadata\n\t\n\t        // Decode\n\t        DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>();\n\t        ByteArrayInputStream is = new ByteArrayInputStream(os.toByteArray());\n\t        DataFileStream<GenericRecord> dataFileReader = new DataFileStream<GenericRecord>(is, reader);\n\t\n\t        GenericRecord record = null;\n\t        while (dataFileReader.hasNext()) {\n\t            record = dataFileReader.next(record);\n\t\t\t\tSystem.out.println(record.getSchema());\t//可以直接获取该数据的json schema定义\n\t            System.out.println(record.get(\"name\").toString());\n\t            System.out.println(record.get(\"num_likes\").toString());\n\t            System.out.println(record.get(\"num_groups\").toString());\n\t            System.out.println(record.get(\"num_photos\").toString());\n\t        }\n\t    }\n\t}\n\n该方法最符合我的预期，这样若我们使用第三方RPC框架（like dubbo），就不需要为schema的数据同步问题花太多精力，但是能想到的问题就是通信成本，毕竟每次数据通信都要携带json schema metadata感觉总是不太好接受，尤其是针对单一长连接场景，似乎更应该去实现类似Avro提供的RPC那样的机制，可以获得更好的性能。\n\n\n#### 方法3\n---\n利用Avro提供的反射机制来完成数据的编码解码，**该方法我没有进行实测**。\n\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\t\n\timport org.apache.avro.Schema;\n\timport org.apache.avro.io.DatumWriter;\n\timport org.apache.avro.io.Decoder;\n\timport org.apache.avro.io.DecoderFactory;\n\timport org.apache.avro.io.Encoder;\n\timport org.apache.avro.io.EncoderFactory;\n\timport org.apache.avro.reflect.ReflectData;\n\timport org.apache.avro.reflect.ReflectDatumReader;\n\timport org.apache.avro.reflect.ReflectDatumWriter;\n\t\n\timport dto.AnotherEmployee;\n\timport dto.Employee;\n\t\n\tpublic class AvroReflect {\n\t    final static ReflectData reflectData = ReflectData.get();\n\t    final static Schema schema = reflectData.getSchema(Employee.class);\n\t\n\t    public static void main(String[] args) throws IOException {\n\t        ByteArrayOutputStream os = new ByteArrayOutputStream();\n\t        Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n\t\n\t        DatumWriter<Employee> writer = new ReflectDatumWriter<Employee>(schema);\n\t        Employee employee = new Employee();\n\t        employee.setName(\"Kamal\");\n\t        employee.setSsn(\"000-00-0000\");\n\t        employee.setAge(29);\n\t\n\t        writer.write(employee, e);\n\t        e.flush();\n\t       \n\t        System.out.println(os.toString());\n\t       \n\t        ReflectData reflectData = ReflectData.get();\n\t        Schema schm = reflectData.getSchema(AnotherEmployee.class);\n\t        ReflectDatumReader<AnotherEmployee> reader = new ReflectDatumReader<AnotherEmployee>(schm);\n\t        Decoder decoder = DecoderFactory.get().binaryDecoder(os.toByteArray(), null);\n\t        AnotherEmployee decodedEmployee = reader.read(null, decoder);\n\t       \n\t        System.out.println(\"Name: \"+decodedEmployee.getName());\n\t        System.out.println(\"Age: \"+decodedEmployee.getAge());\n\t        System.out.println(\"SSN: \"+decodedEmployee.getSsn());\n\t    }\n\t}\n\n\n以上代码，均参考自：[Apache Avro \"HelloWorld\" Examples](http://bigdatazone.blogspot.com/2012/04/apache-avro-helloworld-examples.html)","source":"_posts/Avro的三种序列化与反序列化方法.md","raw":"title: Avro的三种序列化方法\ndate: 2015-04-30 15:54:30\ntags:\n- Avro\n- 序列化\n- RPC\n- json\n- schema\n\ncategories: j2ee\n---\n\n知道Avro有一段时间了，但是并没有过多的动手测试其用法，今天花时间好好找了几个例子来练习Avro，特此记录，供以后查阅。\n<!--more-->\nAvro提供了自身的RPC实现，可以更完美的利用Avro的设计思想来完成高性能的跨进程通信，不过我们这里只注重使用Avro的序列化/反序列化的细节。\n\nAvro使用Json来声明Schema，这个预先定义的模式作为通信两端数据协议，在网络传输前后对目标数据进行二进制处理。太多的理论可以从Avro官网上了解到，我们下面就进入代码模式。\n\n测试代码是基于Maven的，你可能会使用下面的pom.xml：\n\n\t<dependencies>\n        <dependency>\n            <groupId>org.apache.avro</groupId>\n            <artifactId>avro</artifactId>\n            <version>1.7.6-cdh5.2.5</version>\n        </dependency>\n    </dependencies>\n\n\t<repositories>\n        <repository>\n            <id>cloudera-repo-releases</id>\n            <url>https://repository.cloudera.com/artifactory/repo/</url>\n        </repository>\n    </repositories>\n\n#### 方法1\n---\n该方法描述的场景是：用指定的json schema对数据进行编码，并用相同/近似的schema对数据进行解码。\n\t\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\t\n\timport org.apache.avro.Schema;\n\timport org.apache.avro.generic.GenericData;\n\timport org.apache.avro.generic.GenericDatumReader;\n\timport org.apache.avro.generic.GenericDatumWriter;\n\timport org.apache.avro.generic.GenericRecord;\n\timport org.apache.avro.io.DatumReader;\n\timport org.apache.avro.io.Decoder;\n\timport org.apache.avro.io.DecoderFactory;\n\timport org.apache.avro.io.Encoder;\n\timport org.apache.avro.io.EncoderFactory;\n\t\n\tpublic class AvroTest {\n\t    public static void main(String[] args) throws IOException {\n\t        // Schema\n\t        String schemaDescription = \" {    \\n\"\n\t                + \" \\\"name\\\": \\\"FacebookUser\\\", \\n\"\n\t                + \" \\\"type\\\": \\\"record\\\",\\n\" + \" \\\"fields\\\": [\\n\"\n\t                + \"   {\\\"name\\\": \\\"name\\\", \\\"type\\\": \\\"string\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_likes\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_photos\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_groups\\\", \\\"type\\\": \\\"int\\\"} ]\\n\" + \"}\";\n\t\n\t        Schema s = Schema.parse(schemaDescription);\t//parse方法在当前的Avro版本下已不推荐使用\n\t        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n\t        Encoder e = EncoderFactory.get().binaryEncoder(outputStream, null);\n\t        GenericDatumWriter w = new GenericDatumWriter(s);\n\t\n\t        // Populate data\n\t        GenericRecord r = new GenericData.Record(s);\n\t        r.put(\"name\", new org.apache.avro.util.Utf8(\"kazaff\"));\n\t        r.put(\"num_likes\", 1);\n\t        r.put(\"num_groups\", 423);\n\t        r.put(\"num_photos\", 0);\n\t\n\t        // Encode\n\t        w.write(r, e);\n\t        e.flush();\n\t       \n\t        byte[] encodedByteArray = outputStream.toByteArray();\n\t        String encodedString = outputStream.toString();\n\t       \n\t        System.out.println(\"encodedString: \"+encodedString);\n\t       \n\t        // Decode using same schema\n\t        DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>(s);\n\t        Decoder decoder = DecoderFactory.get().binaryDecoder(encodedByteArray, null);\n\t        GenericRecord result = reader.read(null, decoder);\n\t        System.out.println(result.get(\"name\").toString());\n\t        System.out.println(result.get(\"num_likes\").toString());\n\t        System.out.println(result.get(\"num_groups\").toString());\n\t        System.out.println(result.get(\"num_photos\").toString());\n\t       \n\t    }\n\t}\n\n可以看出，编码解码都需要指定schema，这相当于要求通信两端必须提前通过某种交互来完成schema的同步工作（貌似Avro自带的RPC就实现了这个细节），通过代码中的打印语句，我们可以留意到，这种方式下，编码后的数据是不包含schema的（**我不确定对，但相比第二种方式确实有这种差异性**）。\n\n\n#### 方法2\n---\n该方法采用的方式是通过指定的json schema把数据进行编码，并同时把schema作为metadata放在编码后的数据头部。解码则使用内嵌在数据中的schema来完成。\n\n\timport java.io.ByteArrayInputStream;\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\t\n\timport org.apache.avro.Schema;\n\timport org.apache.avro.file.DataFileStream;\n\timport org.apache.avro.file.DataFileWriter;\n\timport org.apache.avro.generic.GenericData;\n\timport org.apache.avro.generic.GenericDatumReader;\n\timport org.apache.avro.generic.GenericDatumWriter;\n\timport org.apache.avro.generic.GenericRecord;\n\timport org.apache.avro.io.DatumReader;\n\timport org.apache.avro.io.DatumWriter;\n\t\n\tpublic class AvroDataFile {\n\t\n\t    /**\n\t     * @param args\n\t     * @throws IOException\n\t     */\n\t    public static void main(String[] args) throws IOException {\n\t        // Schema\n\t        String schemaDescription = \" {    \\n\"\n\t                + \" \\\"name\\\": \\\"FacebookUser\\\", \\n\"\n\t                + \" \\\"type\\\": \\\"record\\\",\\n\" + \" \\\"fields\\\": [\\n\"\n\t                + \"   {\\\"name\\\": \\\"name\\\", \\\"type\\\": \\\"string\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_likes\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_photos\\\", \\\"type\\\": \\\"int\\\"},\\n\"\n\t                + \"   {\\\"name\\\": \\\"num_groups\\\", \\\"type\\\": \\\"int\\\"} ]\\n\" + \"}\";\n\t\n\t        Schema schema = Schema.parse(schemaDescription);\t//parse方法在当前的Avro版本下已不推荐使用\n\t        ByteArrayOutputStream os = new ByteArrayOutputStream();\n\t        DatumWriter<GenericRecord> writer = new GenericDatumWriter<GenericRecord>(schema);\n\t        DataFileWriter<GenericRecord> dataFileWriter = new DataFileWriter<GenericRecord>(writer);\n\t        dataFileWriter.create(schema, os);\n\t\n\t        // Populate data\n\t        GenericRecord datum = new GenericData.Record(schema);\n\t        datum.put(\"name\", new org.apache.avro.util.Utf8(\"kazaff\"));\n\t        datum.put(\"num_likes\", 1);\n\t        datum.put(\"num_groups\", 423);\n\t        datum.put(\"num_photos\", 0);\n\t\n\t        dataFileWriter.append(datum);\n\t        dataFileWriter.close();\n\t\n\t        System.out.println(\"encoded string: \" + os.toString());\t//可以看到，数据是头部携带了schema metadata\n\t\n\t        // Decode\n\t        DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>();\n\t        ByteArrayInputStream is = new ByteArrayInputStream(os.toByteArray());\n\t        DataFileStream<GenericRecord> dataFileReader = new DataFileStream<GenericRecord>(is, reader);\n\t\n\t        GenericRecord record = null;\n\t        while (dataFileReader.hasNext()) {\n\t            record = dataFileReader.next(record);\n\t\t\t\tSystem.out.println(record.getSchema());\t//可以直接获取该数据的json schema定义\n\t            System.out.println(record.get(\"name\").toString());\n\t            System.out.println(record.get(\"num_likes\").toString());\n\t            System.out.println(record.get(\"num_groups\").toString());\n\t            System.out.println(record.get(\"num_photos\").toString());\n\t        }\n\t    }\n\t}\n\n该方法最符合我的预期，这样若我们使用第三方RPC框架（like dubbo），就不需要为schema的数据同步问题花太多精力，但是能想到的问题就是通信成本，毕竟每次数据通信都要携带json schema metadata感觉总是不太好接受，尤其是针对单一长连接场景，似乎更应该去实现类似Avro提供的RPC那样的机制，可以获得更好的性能。\n\n\n#### 方法3\n---\n利用Avro提供的反射机制来完成数据的编码解码，**该方法我没有进行实测**。\n\n\timport java.io.ByteArrayOutputStream;\n\timport java.io.IOException;\n\t\n\timport org.apache.avro.Schema;\n\timport org.apache.avro.io.DatumWriter;\n\timport org.apache.avro.io.Decoder;\n\timport org.apache.avro.io.DecoderFactory;\n\timport org.apache.avro.io.Encoder;\n\timport org.apache.avro.io.EncoderFactory;\n\timport org.apache.avro.reflect.ReflectData;\n\timport org.apache.avro.reflect.ReflectDatumReader;\n\timport org.apache.avro.reflect.ReflectDatumWriter;\n\t\n\timport dto.AnotherEmployee;\n\timport dto.Employee;\n\t\n\tpublic class AvroReflect {\n\t    final static ReflectData reflectData = ReflectData.get();\n\t    final static Schema schema = reflectData.getSchema(Employee.class);\n\t\n\t    public static void main(String[] args) throws IOException {\n\t        ByteArrayOutputStream os = new ByteArrayOutputStream();\n\t        Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n\t\n\t        DatumWriter<Employee> writer = new ReflectDatumWriter<Employee>(schema);\n\t        Employee employee = new Employee();\n\t        employee.setName(\"Kamal\");\n\t        employee.setSsn(\"000-00-0000\");\n\t        employee.setAge(29);\n\t\n\t        writer.write(employee, e);\n\t        e.flush();\n\t       \n\t        System.out.println(os.toString());\n\t       \n\t        ReflectData reflectData = ReflectData.get();\n\t        Schema schm = reflectData.getSchema(AnotherEmployee.class);\n\t        ReflectDatumReader<AnotherEmployee> reader = new ReflectDatumReader<AnotherEmployee>(schm);\n\t        Decoder decoder = DecoderFactory.get().binaryDecoder(os.toByteArray(), null);\n\t        AnotherEmployee decodedEmployee = reader.read(null, decoder);\n\t       \n\t        System.out.println(\"Name: \"+decodedEmployee.getName());\n\t        System.out.println(\"Age: \"+decodedEmployee.getAge());\n\t        System.out.println(\"SSN: \"+decodedEmployee.getSsn());\n\t    }\n\t}\n\n\n以上代码，均参考自：[Apache Avro \"HelloWorld\" Examples](http://bigdatazone.blogspot.com/2012/04/apache-avro-helloworld-examples.html)","slug":"Avro的三种序列化与反序列化方法","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yt500e0gtfyx8chvbni","comments":1,"layout":"post","photos":[],"link":"","content":"<p>知道Avro有一段时间了，但是并没有过多的动手测试其用法，今天花时间好好找了几个例子来练习Avro，特此记录，供以后查阅。<br><a id=\"more\"></a><br>Avro提供了自身的RPC实现，可以更完美的利用Avro的设计思想来完成高性能的跨进程通信，不过我们这里只注重使用Avro的序列化/反序列化的细节。</p>\n<p>Avro使用Json来声明Schema，这个预先定义的模式作为通信两端数据协议，在网络传输前后对目标数据进行二进制处理。太多的理论可以从Avro官网上了解到，我们下面就进入代码模式。</p>\n<p>测试代码是基于Maven的，你可能会使用下面的pom.xml：</p>\n<pre><code>&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n        &lt;artifactId&gt;avro&lt;/artifactId&gt;\n        &lt;version&gt;1.7.6-cdh5.2.5&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n\n&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;cloudera-repo-releases&lt;/id&gt;\n        &lt;url&gt;https://repository.cloudera.com/artifactory/repo/&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre><h4 id=\"方法1\"><a href=\"#方法1\" class=\"headerlink\" title=\"方法1\"></a>方法1</h4><hr>\n<p>该方法描述的场景是：用指定的json schema对数据进行编码，并用相同/近似的schema对数据进行解码。</p>\n<pre><code>import java.io.ByteArrayOutputStream;\nimport java.io.IOException;\n\nimport org.apache.avro.Schema;\nimport org.apache.avro.generic.GenericData;\nimport org.apache.avro.generic.GenericDatumReader;\nimport org.apache.avro.generic.GenericDatumWriter;\nimport org.apache.avro.generic.GenericRecord;\nimport org.apache.avro.io.DatumReader;\nimport org.apache.avro.io.Decoder;\nimport org.apache.avro.io.DecoderFactory;\nimport org.apache.avro.io.Encoder;\nimport org.apache.avro.io.EncoderFactory;\n\npublic class AvroTest {\n    public static void main(String[] args) throws IOException {\n        // Schema\n        String schemaDescription = &quot; {    \\n&quot;\n                + &quot; \\&quot;name\\&quot;: \\&quot;FacebookUser\\&quot;, \\n&quot;\n                + &quot; \\&quot;type\\&quot;: \\&quot;record\\&quot;,\\n&quot; + &quot; \\&quot;fields\\&quot;: [\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;name\\&quot;, \\&quot;type\\&quot;: \\&quot;string\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_likes\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_photos\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_groups\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;} ]\\n&quot; + &quot;}&quot;;\n\n        Schema s = Schema.parse(schemaDescription);    //parse方法在当前的Avro版本下已不推荐使用\n        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n        Encoder e = EncoderFactory.get().binaryEncoder(outputStream, null);\n        GenericDatumWriter w = new GenericDatumWriter(s);\n\n        // Populate data\n        GenericRecord r = new GenericData.Record(s);\n        r.put(&quot;name&quot;, new org.apache.avro.util.Utf8(&quot;kazaff&quot;));\n        r.put(&quot;num_likes&quot;, 1);\n        r.put(&quot;num_groups&quot;, 423);\n        r.put(&quot;num_photos&quot;, 0);\n\n        // Encode\n        w.write(r, e);\n        e.flush();\n\n        byte[] encodedByteArray = outputStream.toByteArray();\n        String encodedString = outputStream.toString();\n\n        System.out.println(&quot;encodedString: &quot;+encodedString);\n\n        // Decode using same schema\n        DatumReader&lt;GenericRecord&gt; reader = new GenericDatumReader&lt;GenericRecord&gt;(s);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(encodedByteArray, null);\n        GenericRecord result = reader.read(null, decoder);\n        System.out.println(result.get(&quot;name&quot;).toString());\n        System.out.println(result.get(&quot;num_likes&quot;).toString());\n        System.out.println(result.get(&quot;num_groups&quot;).toString());\n        System.out.println(result.get(&quot;num_photos&quot;).toString());\n\n    }\n}\n</code></pre><p>可以看出，编码解码都需要指定schema，这相当于要求通信两端必须提前通过某种交互来完成schema的同步工作（貌似Avro自带的RPC就实现了这个细节），通过代码中的打印语句，我们可以留意到，这种方式下，编码后的数据是不包含schema的（<strong>我不确定对，但相比第二种方式确实有这种差异性</strong>）。</p>\n<h4 id=\"方法2\"><a href=\"#方法2\" class=\"headerlink\" title=\"方法2\"></a>方法2</h4><hr>\n<p>该方法采用的方式是通过指定的json schema把数据进行编码，并同时把schema作为metadata放在编码后的数据头部。解码则使用内嵌在数据中的schema来完成。</p>\n<pre><code>import java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\n\nimport org.apache.avro.Schema;\nimport org.apache.avro.file.DataFileStream;\nimport org.apache.avro.file.DataFileWriter;\nimport org.apache.avro.generic.GenericData;\nimport org.apache.avro.generic.GenericDatumReader;\nimport org.apache.avro.generic.GenericDatumWriter;\nimport org.apache.avro.generic.GenericRecord;\nimport org.apache.avro.io.DatumReader;\nimport org.apache.avro.io.DatumWriter;\n\npublic class AvroDataFile {\n\n    /**\n     * @param args\n     * @throws IOException\n     */\n    public static void main(String[] args) throws IOException {\n        // Schema\n        String schemaDescription = &quot; {    \\n&quot;\n                + &quot; \\&quot;name\\&quot;: \\&quot;FacebookUser\\&quot;, \\n&quot;\n                + &quot; \\&quot;type\\&quot;: \\&quot;record\\&quot;,\\n&quot; + &quot; \\&quot;fields\\&quot;: [\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;name\\&quot;, \\&quot;type\\&quot;: \\&quot;string\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_likes\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_photos\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_groups\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;} ]\\n&quot; + &quot;}&quot;;\n\n        Schema schema = Schema.parse(schemaDescription);    //parse方法在当前的Avro版本下已不推荐使用\n        ByteArrayOutputStream os = new ByteArrayOutputStream();\n        DatumWriter&lt;GenericRecord&gt; writer = new GenericDatumWriter&lt;GenericRecord&gt;(schema);\n        DataFileWriter&lt;GenericRecord&gt; dataFileWriter = new DataFileWriter&lt;GenericRecord&gt;(writer);\n        dataFileWriter.create(schema, os);\n\n        // Populate data\n        GenericRecord datum = new GenericData.Record(schema);\n        datum.put(&quot;name&quot;, new org.apache.avro.util.Utf8(&quot;kazaff&quot;));\n        datum.put(&quot;num_likes&quot;, 1);\n        datum.put(&quot;num_groups&quot;, 423);\n        datum.put(&quot;num_photos&quot;, 0);\n\n        dataFileWriter.append(datum);\n        dataFileWriter.close();\n\n        System.out.println(&quot;encoded string: &quot; + os.toString());    //可以看到，数据是头部携带了schema metadata\n\n        // Decode\n        DatumReader&lt;GenericRecord&gt; reader = new GenericDatumReader&lt;GenericRecord&gt;();\n        ByteArrayInputStream is = new ByteArrayInputStream(os.toByteArray());\n        DataFileStream&lt;GenericRecord&gt; dataFileReader = new DataFileStream&lt;GenericRecord&gt;(is, reader);\n\n        GenericRecord record = null;\n        while (dataFileReader.hasNext()) {\n            record = dataFileReader.next(record);\n            System.out.println(record.getSchema());    //可以直接获取该数据的json schema定义\n            System.out.println(record.get(&quot;name&quot;).toString());\n            System.out.println(record.get(&quot;num_likes&quot;).toString());\n            System.out.println(record.get(&quot;num_groups&quot;).toString());\n            System.out.println(record.get(&quot;num_photos&quot;).toString());\n        }\n    }\n}\n</code></pre><p>该方法最符合我的预期，这样若我们使用第三方RPC框架（like dubbo），就不需要为schema的数据同步问题花太多精力，但是能想到的问题就是通信成本，毕竟每次数据通信都要携带json schema metadata感觉总是不太好接受，尤其是针对单一长连接场景，似乎更应该去实现类似Avro提供的RPC那样的机制，可以获得更好的性能。</p>\n<h4 id=\"方法3\"><a href=\"#方法3\" class=\"headerlink\" title=\"方法3\"></a>方法3</h4><hr>\n<p>利用Avro提供的反射机制来完成数据的编码解码，<strong>该方法我没有进行实测</strong>。</p>\n<pre><code>import java.io.ByteArrayOutputStream;\nimport java.io.IOException;\n\nimport org.apache.avro.Schema;\nimport org.apache.avro.io.DatumWriter;\nimport org.apache.avro.io.Decoder;\nimport org.apache.avro.io.DecoderFactory;\nimport org.apache.avro.io.Encoder;\nimport org.apache.avro.io.EncoderFactory;\nimport org.apache.avro.reflect.ReflectData;\nimport org.apache.avro.reflect.ReflectDatumReader;\nimport org.apache.avro.reflect.ReflectDatumWriter;\n\nimport dto.AnotherEmployee;\nimport dto.Employee;\n\npublic class AvroReflect {\n    final static ReflectData reflectData = ReflectData.get();\n    final static Schema schema = reflectData.getSchema(Employee.class);\n\n    public static void main(String[] args) throws IOException {\n        ByteArrayOutputStream os = new ByteArrayOutputStream();\n        Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n\n        DatumWriter&lt;Employee&gt; writer = new ReflectDatumWriter&lt;Employee&gt;(schema);\n        Employee employee = new Employee();\n        employee.setName(&quot;Kamal&quot;);\n        employee.setSsn(&quot;000-00-0000&quot;);\n        employee.setAge(29);\n\n        writer.write(employee, e);\n        e.flush();\n\n        System.out.println(os.toString());\n\n        ReflectData reflectData = ReflectData.get();\n        Schema schm = reflectData.getSchema(AnotherEmployee.class);\n        ReflectDatumReader&lt;AnotherEmployee&gt; reader = new ReflectDatumReader&lt;AnotherEmployee&gt;(schm);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(os.toByteArray(), null);\n        AnotherEmployee decodedEmployee = reader.read(null, decoder);\n\n        System.out.println(&quot;Name: &quot;+decodedEmployee.getName());\n        System.out.println(&quot;Age: &quot;+decodedEmployee.getAge());\n        System.out.println(&quot;SSN: &quot;+decodedEmployee.getSsn());\n    }\n}\n</code></pre><p>以上代码，均参考自：<a href=\"http://bigdatazone.blogspot.com/2012/04/apache-avro-helloworld-examples.html\" target=\"_blank\" rel=\"external\">Apache Avro “HelloWorld” Examples</a></p>\n","excerpt":"<p>知道Avro有一段时间了，但是并没有过多的动手测试其用法，今天花时间好好找了几个例子来练习Avro，特此记录，供以后查阅。<br>","more":"<br>Avro提供了自身的RPC实现，可以更完美的利用Avro的设计思想来完成高性能的跨进程通信，不过我们这里只注重使用Avro的序列化/反序列化的细节。</p>\n<p>Avro使用Json来声明Schema，这个预先定义的模式作为通信两端数据协议，在网络传输前后对目标数据进行二进制处理。太多的理论可以从Avro官网上了解到，我们下面就进入代码模式。</p>\n<p>测试代码是基于Maven的，你可能会使用下面的pom.xml：</p>\n<pre><code>&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n        &lt;artifactId&gt;avro&lt;/artifactId&gt;\n        &lt;version&gt;1.7.6-cdh5.2.5&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n\n&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;cloudera-repo-releases&lt;/id&gt;\n        &lt;url&gt;https://repository.cloudera.com/artifactory/repo/&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre><h4 id=\"方法1\"><a href=\"#方法1\" class=\"headerlink\" title=\"方法1\"></a>方法1</h4><hr>\n<p>该方法描述的场景是：用指定的json schema对数据进行编码，并用相同/近似的schema对数据进行解码。</p>\n<pre><code>import java.io.ByteArrayOutputStream;\nimport java.io.IOException;\n\nimport org.apache.avro.Schema;\nimport org.apache.avro.generic.GenericData;\nimport org.apache.avro.generic.GenericDatumReader;\nimport org.apache.avro.generic.GenericDatumWriter;\nimport org.apache.avro.generic.GenericRecord;\nimport org.apache.avro.io.DatumReader;\nimport org.apache.avro.io.Decoder;\nimport org.apache.avro.io.DecoderFactory;\nimport org.apache.avro.io.Encoder;\nimport org.apache.avro.io.EncoderFactory;\n\npublic class AvroTest {\n    public static void main(String[] args) throws IOException {\n        // Schema\n        String schemaDescription = &quot; {    \\n&quot;\n                + &quot; \\&quot;name\\&quot;: \\&quot;FacebookUser\\&quot;, \\n&quot;\n                + &quot; \\&quot;type\\&quot;: \\&quot;record\\&quot;,\\n&quot; + &quot; \\&quot;fields\\&quot;: [\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;name\\&quot;, \\&quot;type\\&quot;: \\&quot;string\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_likes\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_photos\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_groups\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;} ]\\n&quot; + &quot;}&quot;;\n\n        Schema s = Schema.parse(schemaDescription);    //parse方法在当前的Avro版本下已不推荐使用\n        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n        Encoder e = EncoderFactory.get().binaryEncoder(outputStream, null);\n        GenericDatumWriter w = new GenericDatumWriter(s);\n\n        // Populate data\n        GenericRecord r = new GenericData.Record(s);\n        r.put(&quot;name&quot;, new org.apache.avro.util.Utf8(&quot;kazaff&quot;));\n        r.put(&quot;num_likes&quot;, 1);\n        r.put(&quot;num_groups&quot;, 423);\n        r.put(&quot;num_photos&quot;, 0);\n\n        // Encode\n        w.write(r, e);\n        e.flush();\n\n        byte[] encodedByteArray = outputStream.toByteArray();\n        String encodedString = outputStream.toString();\n\n        System.out.println(&quot;encodedString: &quot;+encodedString);\n\n        // Decode using same schema\n        DatumReader&lt;GenericRecord&gt; reader = new GenericDatumReader&lt;GenericRecord&gt;(s);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(encodedByteArray, null);\n        GenericRecord result = reader.read(null, decoder);\n        System.out.println(result.get(&quot;name&quot;).toString());\n        System.out.println(result.get(&quot;num_likes&quot;).toString());\n        System.out.println(result.get(&quot;num_groups&quot;).toString());\n        System.out.println(result.get(&quot;num_photos&quot;).toString());\n\n    }\n}\n</code></pre><p>可以看出，编码解码都需要指定schema，这相当于要求通信两端必须提前通过某种交互来完成schema的同步工作（貌似Avro自带的RPC就实现了这个细节），通过代码中的打印语句，我们可以留意到，这种方式下，编码后的数据是不包含schema的（<strong>我不确定对，但相比第二种方式确实有这种差异性</strong>）。</p>\n<h4 id=\"方法2\"><a href=\"#方法2\" class=\"headerlink\" title=\"方法2\"></a>方法2</h4><hr>\n<p>该方法采用的方式是通过指定的json schema把数据进行编码，并同时把schema作为metadata放在编码后的数据头部。解码则使用内嵌在数据中的schema来完成。</p>\n<pre><code>import java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\n\nimport org.apache.avro.Schema;\nimport org.apache.avro.file.DataFileStream;\nimport org.apache.avro.file.DataFileWriter;\nimport org.apache.avro.generic.GenericData;\nimport org.apache.avro.generic.GenericDatumReader;\nimport org.apache.avro.generic.GenericDatumWriter;\nimport org.apache.avro.generic.GenericRecord;\nimport org.apache.avro.io.DatumReader;\nimport org.apache.avro.io.DatumWriter;\n\npublic class AvroDataFile {\n\n    /**\n     * @param args\n     * @throws IOException\n     */\n    public static void main(String[] args) throws IOException {\n        // Schema\n        String schemaDescription = &quot; {    \\n&quot;\n                + &quot; \\&quot;name\\&quot;: \\&quot;FacebookUser\\&quot;, \\n&quot;\n                + &quot; \\&quot;type\\&quot;: \\&quot;record\\&quot;,\\n&quot; + &quot; \\&quot;fields\\&quot;: [\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;name\\&quot;, \\&quot;type\\&quot;: \\&quot;string\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_likes\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_photos\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;},\\n&quot;\n                + &quot;   {\\&quot;name\\&quot;: \\&quot;num_groups\\&quot;, \\&quot;type\\&quot;: \\&quot;int\\&quot;} ]\\n&quot; + &quot;}&quot;;\n\n        Schema schema = Schema.parse(schemaDescription);    //parse方法在当前的Avro版本下已不推荐使用\n        ByteArrayOutputStream os = new ByteArrayOutputStream();\n        DatumWriter&lt;GenericRecord&gt; writer = new GenericDatumWriter&lt;GenericRecord&gt;(schema);\n        DataFileWriter&lt;GenericRecord&gt; dataFileWriter = new DataFileWriter&lt;GenericRecord&gt;(writer);\n        dataFileWriter.create(schema, os);\n\n        // Populate data\n        GenericRecord datum = new GenericData.Record(schema);\n        datum.put(&quot;name&quot;, new org.apache.avro.util.Utf8(&quot;kazaff&quot;));\n        datum.put(&quot;num_likes&quot;, 1);\n        datum.put(&quot;num_groups&quot;, 423);\n        datum.put(&quot;num_photos&quot;, 0);\n\n        dataFileWriter.append(datum);\n        dataFileWriter.close();\n\n        System.out.println(&quot;encoded string: &quot; + os.toString());    //可以看到，数据是头部携带了schema metadata\n\n        // Decode\n        DatumReader&lt;GenericRecord&gt; reader = new GenericDatumReader&lt;GenericRecord&gt;();\n        ByteArrayInputStream is = new ByteArrayInputStream(os.toByteArray());\n        DataFileStream&lt;GenericRecord&gt; dataFileReader = new DataFileStream&lt;GenericRecord&gt;(is, reader);\n\n        GenericRecord record = null;\n        while (dataFileReader.hasNext()) {\n            record = dataFileReader.next(record);\n            System.out.println(record.getSchema());    //可以直接获取该数据的json schema定义\n            System.out.println(record.get(&quot;name&quot;).toString());\n            System.out.println(record.get(&quot;num_likes&quot;).toString());\n            System.out.println(record.get(&quot;num_groups&quot;).toString());\n            System.out.println(record.get(&quot;num_photos&quot;).toString());\n        }\n    }\n}\n</code></pre><p>该方法最符合我的预期，这样若我们使用第三方RPC框架（like dubbo），就不需要为schema的数据同步问题花太多精力，但是能想到的问题就是通信成本，毕竟每次数据通信都要携带json schema metadata感觉总是不太好接受，尤其是针对单一长连接场景，似乎更应该去实现类似Avro提供的RPC那样的机制，可以获得更好的性能。</p>\n<h4 id=\"方法3\"><a href=\"#方法3\" class=\"headerlink\" title=\"方法3\"></a>方法3</h4><hr>\n<p>利用Avro提供的反射机制来完成数据的编码解码，<strong>该方法我没有进行实测</strong>。</p>\n<pre><code>import java.io.ByteArrayOutputStream;\nimport java.io.IOException;\n\nimport org.apache.avro.Schema;\nimport org.apache.avro.io.DatumWriter;\nimport org.apache.avro.io.Decoder;\nimport org.apache.avro.io.DecoderFactory;\nimport org.apache.avro.io.Encoder;\nimport org.apache.avro.io.EncoderFactory;\nimport org.apache.avro.reflect.ReflectData;\nimport org.apache.avro.reflect.ReflectDatumReader;\nimport org.apache.avro.reflect.ReflectDatumWriter;\n\nimport dto.AnotherEmployee;\nimport dto.Employee;\n\npublic class AvroReflect {\n    final static ReflectData reflectData = ReflectData.get();\n    final static Schema schema = reflectData.getSchema(Employee.class);\n\n    public static void main(String[] args) throws IOException {\n        ByteArrayOutputStream os = new ByteArrayOutputStream();\n        Encoder e = EncoderFactory.get().binaryEncoder(os, null);\n\n        DatumWriter&lt;Employee&gt; writer = new ReflectDatumWriter&lt;Employee&gt;(schema);\n        Employee employee = new Employee();\n        employee.setName(&quot;Kamal&quot;);\n        employee.setSsn(&quot;000-00-0000&quot;);\n        employee.setAge(29);\n\n        writer.write(employee, e);\n        e.flush();\n\n        System.out.println(os.toString());\n\n        ReflectData reflectData = ReflectData.get();\n        Schema schm = reflectData.getSchema(AnotherEmployee.class);\n        ReflectDatumReader&lt;AnotherEmployee&gt; reader = new ReflectDatumReader&lt;AnotherEmployee&gt;(schm);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(os.toByteArray(), null);\n        AnotherEmployee decodedEmployee = reader.read(null, decoder);\n\n        System.out.println(&quot;Name: &quot;+decodedEmployee.getName());\n        System.out.println(&quot;Age: &quot;+decodedEmployee.getAge());\n        System.out.println(&quot;SSN: &quot;+decodedEmployee.getSsn());\n    }\n}\n</code></pre><p>以上代码，均参考自：<a href=\"http://bigdatazone.blogspot.com/2012/04/apache-avro-helloworld-examples.html\">Apache Avro “HelloWorld” Examples</a></p>"},{"title":"注解Scope(prototype)的正确用法","date":"2014-12-05T02:37:12.000Z","_content":"\n\n昨天加班在搞一个关于session的问题，有兴趣的童鞋可以去[这里](http://segmentfault.com/q/1010000002406950)观望一下。\n\n总之除了吃惊外就是感觉手脚束缚！现在只能彻底放弃使用默认的`session`机制了，不知道这算是好事儿还是坏事儿。\n<!-- more -->\n现在的思路是这样的：\n\n1. 在Servlet过滤器中把`ServletRequest`对象替换为自己的`Wrapper`实例，在其中实现`getSession()`方法，返回我们自定义的`HttpSession`对象\n2. 我们实现一个继承了`HttpSession`接口的自定义会话类，用于第一步的返回，该自定义会话类提供接受`sessionId`参数获取会话数据的方法\n3. 通过拿在`request`对象中获取的`sessionId`去`redis`中取得对应的登录用户的信息：`sessionUser`对象；\n4. 在每次请求处理完后（过滤器最后一行代码）让自定义会话类把会话数据回写入`redis`，由于要持久化对象到`redis`中，所以要选择一个高效能的序列化与反序列化实现。\n\n当然也可以再进一步优化，例如说最后一步，检查如果`MySession`对象没有被修改则不需要回写等。\n\n说到现在，貌似和这篇文章的主题没有半毛钱关系的说~~表着急嘛，这不是要开始说了嘛！\n\n上面的第三步提到，我们自定义的这个会话对象的生命周期应该为：**每次请求**。如果采用`spring`默认提供的`singleton`的话就乱套了，你懂的！\n\n在和同事讨论上面的自定义会话机制的实现时，他叮嘱我说：\n\n> `@Scope(\"request\")`作用域使用时要加上额外的参数（proxyMode）\n\n不过并没有给我说清楚到底为啥。本着打破砂锅问到底的神经，我在GG和百度上搜索了一下，不知道是不是因为关键字写的不合理，总之并没有找到有用的中文资料，大多都是相互转载，而且讲的都是理论，并且用的也配置文件方式而非注解。\n\n无奈只得翻墙查了一下，找到了一篇很好的[文章](http://whyjava.wordpress.com/2010/10/30/spring-scoped-proxy-beans-an-alternative-to-method-injection/)，而且早在2010年就已经总结出来了，为啥国内社区的就没有呢？真的是我搜的方式不对么？\n\n不扯淡了，文章中说：\n\n> Method Injection is useful in scenarios where you need to inject a smaller scope bean in a larger scope bean.  For example, you have to inject a prototype bean inside an singleton bean , on each method invocation of Singleton bean. Just defining your bean prototype, does not create new instance each time a singleton bean is called because container creates a singleton bean only once, and thus only sets a prototype bean once. \n\n大概意思是，当你把声明为相对范围小的作用域（例如：prototy）对象注入到相对范围大的作用域（例如：singleton）对象时，由于外层对象只会初始化一次，所以会导致内部注入的对象也只会被初始化一次。\n\n道理十分的简单，就是因为这个原因，所以你有意把作用域定义为`prototy`的类可能并不是按照你认为的方式运作。\n\n解决这个问题的方法有多种，比方说你可以使用**Method Injection**，而不是直接注入在类属性中，不过这就要求程序员在使用时需要特别对待这些类。\n\n现在就是***proxyMode**发挥作用的时候：\n\n\t@Scope(proxyMode = ScopedProxyMode.TARGET_CLASS, value = \"prototype\")\n\n这么写，就可以保证该类会按照你大脑中的方式使用了：**每次使用都会重新初始化一个对象**。\n\n源码就不去深究了。8~","source":"_posts/@Scope(prototype)的正确用法.md","raw":"title: 注解Scope(prototype)的正确用法\ndate: 2014-12-05 10:37:12\ntags: \n- 会话\n- session\n- spring\n- 依赖注入\n- 作用域\n- 生命周期\n- scope\n\ncategories: \n- java\n---\n\n\n昨天加班在搞一个关于session的问题，有兴趣的童鞋可以去[这里](http://segmentfault.com/q/1010000002406950)观望一下。\n\n总之除了吃惊外就是感觉手脚束缚！现在只能彻底放弃使用默认的`session`机制了，不知道这算是好事儿还是坏事儿。\n<!-- more -->\n现在的思路是这样的：\n\n1. 在Servlet过滤器中把`ServletRequest`对象替换为自己的`Wrapper`实例，在其中实现`getSession()`方法，返回我们自定义的`HttpSession`对象\n2. 我们实现一个继承了`HttpSession`接口的自定义会话类，用于第一步的返回，该自定义会话类提供接受`sessionId`参数获取会话数据的方法\n3. 通过拿在`request`对象中获取的`sessionId`去`redis`中取得对应的登录用户的信息：`sessionUser`对象；\n4. 在每次请求处理完后（过滤器最后一行代码）让自定义会话类把会话数据回写入`redis`，由于要持久化对象到`redis`中，所以要选择一个高效能的序列化与反序列化实现。\n\n当然也可以再进一步优化，例如说最后一步，检查如果`MySession`对象没有被修改则不需要回写等。\n\n说到现在，貌似和这篇文章的主题没有半毛钱关系的说~~表着急嘛，这不是要开始说了嘛！\n\n上面的第三步提到，我们自定义的这个会话对象的生命周期应该为：**每次请求**。如果采用`spring`默认提供的`singleton`的话就乱套了，你懂的！\n\n在和同事讨论上面的自定义会话机制的实现时，他叮嘱我说：\n\n> `@Scope(\"request\")`作用域使用时要加上额外的参数（proxyMode）\n\n不过并没有给我说清楚到底为啥。本着打破砂锅问到底的神经，我在GG和百度上搜索了一下，不知道是不是因为关键字写的不合理，总之并没有找到有用的中文资料，大多都是相互转载，而且讲的都是理论，并且用的也配置文件方式而非注解。\n\n无奈只得翻墙查了一下，找到了一篇很好的[文章](http://whyjava.wordpress.com/2010/10/30/spring-scoped-proxy-beans-an-alternative-to-method-injection/)，而且早在2010年就已经总结出来了，为啥国内社区的就没有呢？真的是我搜的方式不对么？\n\n不扯淡了，文章中说：\n\n> Method Injection is useful in scenarios where you need to inject a smaller scope bean in a larger scope bean.  For example, you have to inject a prototype bean inside an singleton bean , on each method invocation of Singleton bean. Just defining your bean prototype, does not create new instance each time a singleton bean is called because container creates a singleton bean only once, and thus only sets a prototype bean once. \n\n大概意思是，当你把声明为相对范围小的作用域（例如：prototy）对象注入到相对范围大的作用域（例如：singleton）对象时，由于外层对象只会初始化一次，所以会导致内部注入的对象也只会被初始化一次。\n\n道理十分的简单，就是因为这个原因，所以你有意把作用域定义为`prototy`的类可能并不是按照你认为的方式运作。\n\n解决这个问题的方法有多种，比方说你可以使用**Method Injection**，而不是直接注入在类属性中，不过这就要求程序员在使用时需要特别对待这些类。\n\n现在就是***proxyMode**发挥作用的时候：\n\n\t@Scope(proxyMode = ScopedProxyMode.TARGET_CLASS, value = \"prototype\")\n\n这么写，就可以保证该类会按照你大脑中的方式使用了：**每次使用都会重新初始化一个对象**。\n\n源码就不去深究了。8~","slug":"@Scope(prototype)的正确用法","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cica18yta00e8gtfy66x1yycu","comments":1,"layout":"post","photos":[],"link":"","content":"<p>昨天加班在搞一个关于session的问题，有兴趣的童鞋可以去<a href=\"http://segmentfault.com/q/1010000002406950\" target=\"_blank\" rel=\"external\">这里</a>观望一下。</p>\n<p>总之除了吃惊外就是感觉手脚束缚！现在只能彻底放弃使用默认的<code>session</code>机制了，不知道这算是好事儿还是坏事儿。<br><a id=\"more\"></a><br>现在的思路是这样的：</p>\n<ol>\n<li>在Servlet过滤器中把<code>ServletRequest</code>对象替换为自己的<code>Wrapper</code>实例，在其中实现<code>getSession()</code>方法，返回我们自定义的<code>HttpSession</code>对象</li>\n<li>我们实现一个继承了<code>HttpSession</code>接口的自定义会话类，用于第一步的返回，该自定义会话类提供接受<code>sessionId</code>参数获取会话数据的方法</li>\n<li>通过拿在<code>request</code>对象中获取的<code>sessionId</code>去<code>redis</code>中取得对应的登录用户的信息：<code>sessionUser</code>对象；</li>\n<li>在每次请求处理完后（过滤器最后一行代码）让自定义会话类把会话数据回写入<code>redis</code>，由于要持久化对象到<code>redis</code>中，所以要选择一个高效能的序列化与反序列化实现。</li>\n</ol>\n<p>当然也可以再进一步优化，例如说最后一步，检查如果<code>MySession</code>对象没有被修改则不需要回写等。</p>\n<p>说到现在，貌似和这篇文章的主题没有半毛钱关系的说~~表着急嘛，这不是要开始说了嘛！</p>\n<p>上面的第三步提到，我们自定义的这个会话对象的生命周期应该为：<strong>每次请求</strong>。如果采用<code>spring</code>默认提供的<code>singleton</code>的话就乱套了，你懂的！</p>\n<p>在和同事讨论上面的自定义会话机制的实现时，他叮嘱我说：</p>\n<blockquote>\n<p><code>@Scope(&quot;request&quot;)</code>作用域使用时要加上额外的参数（proxyMode）</p>\n</blockquote>\n<p>不过并没有给我说清楚到底为啥。本着打破砂锅问到底的神经，我在GG和百度上搜索了一下，不知道是不是因为关键字写的不合理，总之并没有找到有用的中文资料，大多都是相互转载，而且讲的都是理论，并且用的也配置文件方式而非注解。</p>\n<p>无奈只得翻墙查了一下，找到了一篇很好的<a href=\"http://whyjava.wordpress.com/2010/10/30/spring-scoped-proxy-beans-an-alternative-to-method-injection/\" target=\"_blank\" rel=\"external\">文章</a>，而且早在2010年就已经总结出来了，为啥国内社区的就没有呢？真的是我搜的方式不对么？</p>\n<p>不扯淡了，文章中说：</p>\n<blockquote>\n<p>Method Injection is useful in scenarios where you need to inject a smaller scope bean in a larger scope bean.  For example, you have to inject a prototype bean inside an singleton bean , on each method invocation of Singleton bean. Just defining your bean prototype, does not create new instance each time a singleton bean is called because container creates a singleton bean only once, and thus only sets a prototype bean once. </p>\n</blockquote>\n<p>大概意思是，当你把声明为相对范围小的作用域（例如：prototy）对象注入到相对范围大的作用域（例如：singleton）对象时，由于外层对象只会初始化一次，所以会导致内部注入的对象也只会被初始化一次。</p>\n<p>道理十分的简单，就是因为这个原因，所以你有意把作用域定义为<code>prototy</code>的类可能并不是按照你认为的方式运作。</p>\n<p>解决这个问题的方法有多种，比方说你可以使用<strong>Method Injection</strong>，而不是直接注入在类属性中，不过这就要求程序员在使用时需要特别对待这些类。</p>\n<p>现在就是<strong>*proxyMode</strong>发挥作用的时候：</p>\n<pre><code>@Scope(proxyMode = ScopedProxyMode.TARGET_CLASS, value = &quot;prototype&quot;)\n</code></pre><p>这么写，就可以保证该类会按照你大脑中的方式使用了：<strong>每次使用都会重新初始化一个对象</strong>。</p>\n<p>源码就不去深究了。8~</p>\n","excerpt":"<p>昨天加班在搞一个关于session的问题，有兴趣的童鞋可以去<a href=\"http://segmentfault.com/q/1010000002406950\">这里</a>观望一下。</p>\n<p>总之除了吃惊外就是感觉手脚束缚！现在只能彻底放弃使用默认的<code>session</code>机制了，不知道这算是好事儿还是坏事儿。<br>","more":"<br>现在的思路是这样的：</p>\n<ol>\n<li>在Servlet过滤器中把<code>ServletRequest</code>对象替换为自己的<code>Wrapper</code>实例，在其中实现<code>getSession()</code>方法，返回我们自定义的<code>HttpSession</code>对象</li>\n<li>我们实现一个继承了<code>HttpSession</code>接口的自定义会话类，用于第一步的返回，该自定义会话类提供接受<code>sessionId</code>参数获取会话数据的方法</li>\n<li>通过拿在<code>request</code>对象中获取的<code>sessionId</code>去<code>redis</code>中取得对应的登录用户的信息：<code>sessionUser</code>对象；</li>\n<li>在每次请求处理完后（过滤器最后一行代码）让自定义会话类把会话数据回写入<code>redis</code>，由于要持久化对象到<code>redis</code>中，所以要选择一个高效能的序列化与反序列化实现。</li>\n</ol>\n<p>当然也可以再进一步优化，例如说最后一步，检查如果<code>MySession</code>对象没有被修改则不需要回写等。</p>\n<p>说到现在，貌似和这篇文章的主题没有半毛钱关系的说~~表着急嘛，这不是要开始说了嘛！</p>\n<p>上面的第三步提到，我们自定义的这个会话对象的生命周期应该为：<strong>每次请求</strong>。如果采用<code>spring</code>默认提供的<code>singleton</code>的话就乱套了，你懂的！</p>\n<p>在和同事讨论上面的自定义会话机制的实现时，他叮嘱我说：</p>\n<blockquote>\n<p><code>@Scope(&quot;request&quot;)</code>作用域使用时要加上额外的参数（proxyMode）</p>\n</blockquote>\n<p>不过并没有给我说清楚到底为啥。本着打破砂锅问到底的神经，我在GG和百度上搜索了一下，不知道是不是因为关键字写的不合理，总之并没有找到有用的中文资料，大多都是相互转载，而且讲的都是理论，并且用的也配置文件方式而非注解。</p>\n<p>无奈只得翻墙查了一下，找到了一篇很好的<a href=\"http://whyjava.wordpress.com/2010/10/30/spring-scoped-proxy-beans-an-alternative-to-method-injection/\">文章</a>，而且早在2010年就已经总结出来了，为啥国内社区的就没有呢？真的是我搜的方式不对么？</p>\n<p>不扯淡了，文章中说：</p>\n<blockquote>\n<p>Method Injection is useful in scenarios where you need to inject a smaller scope bean in a larger scope bean.  For example, you have to inject a prototype bean inside an singleton bean , on each method invocation of Singleton bean. Just defining your bean prototype, does not create new instance each time a singleton bean is called because container creates a singleton bean only once, and thus only sets a prototype bean once. </p>\n</blockquote>\n<p>大概意思是，当你把声明为相对范围小的作用域（例如：prototy）对象注入到相对范围大的作用域（例如：singleton）对象时，由于外层对象只会初始化一次，所以会导致内部注入的对象也只会被初始化一次。</p>\n<p>道理十分的简单，就是因为这个原因，所以你有意把作用域定义为<code>prototy</code>的类可能并不是按照你认为的方式运作。</p>\n<p>解决这个问题的方法有多种，比方说你可以使用<strong>Method Injection</strong>，而不是直接注入在类属性中，不过这就要求程序员在使用时需要特别对待这些类。</p>\n<p>现在就是<strong>*proxyMode</strong>发挥作用的时候：</p>\n<pre><code>@Scope(proxyMode = ScopedProxyMode.TARGET_CLASS, value = &quot;prototype&quot;)\n</code></pre><p>这么写，就可以保证该类会按照你大脑中的方式使用了：<strong>每次使用都会重新初始化一个对象</strong>。</p>\n<p>源码就不去深究了。8~</p>"},{"title":"论uikit的重要性","date":"2015-08-08T01:37:12.000Z","_content":"\n这年头，最怕的就是上贼船，真的！我才从待了四年的公司离职，谁知刚出粪坑又入“火坑”，真是运气太差啊～\n<!--more-->\n我所说的这个火坑，其实是一套无意间发现的ui，好吧，其实是我特意搜的，只恨当时鬼迷心窍被忽悠了啊（当然，也可能是我等级不够，下不了这个副本啊～）。\n\n我所指的ui就是：[materialUI](http://material-ui.com/#/)。搞开发的，谁不佩服google的技术，之前玩的angular就是出自google，而我说的这套ui代码就是基于Material design设计理念打造而成，确实很容易看对眼啊～\n\n只可惜小哥我前端道行太浅驾驭不了啊，花了几天的时间硬是给我死扛着做了个demo，进度着实缓慢，哎～\n\n为什么说它不爽呢？在我看来，它封装的太厚实了，除了暴露出来的一些操作属性外，你很难去控制这些控件的位置，更别提样式了，当然可能作者就是为了避免整体的设计理念被打乱吧。\n\n除此之外，该uikit不支持多国语言，而且datepicker也不是自适应的，导致无法在手机上很好的操作，而且动效还有些许卡顿（可能是我设备档次太低～）。\n\n不过，它的leftNav控件着实不赖，不管是性能还是美观度都非常讨好。\n\n当然，它还缺少了很多我个人认为非常必备的控件，比方说页码，面包屑等，期待它的完善吧～反正小哥我是耗不起了。\n\n我在中文论坛上搜了搜，果不其然找到了一个国人发布的ui库，之前也听说过，不过这次发现竟然还有react版本的，真是大爱啊：[amazeui](http://amazeui.org/react/components)。哥可不是做广告啊，其实原先我是打算使用：[react-bootstrap](http://react-bootstrap.github.io/components.html)，可不知道是不是审美疲劳了，总之bs2.0已经无法满足我的欲望了。\n\n这几天就容我换个行头重新来过吧～","source":"_posts/论UIkit的重要性.md","raw":"title: 论uikit的重要性\ndate: 2015-08-08 09:37:12\ntags: \n- react\n- ui\ncategories: 前端\n---\n\n这年头，最怕的就是上贼船，真的！我才从待了四年的公司离职，谁知刚出粪坑又入“火坑”，真是运气太差啊～\n<!--more-->\n我所说的这个火坑，其实是一套无意间发现的ui，好吧，其实是我特意搜的，只恨当时鬼迷心窍被忽悠了啊（当然，也可能是我等级不够，下不了这个副本啊～）。\n\n我所指的ui就是：[materialUI](http://material-ui.com/#/)。搞开发的，谁不佩服google的技术，之前玩的angular就是出自google，而我说的这套ui代码就是基于Material design设计理念打造而成，确实很容易看对眼啊～\n\n只可惜小哥我前端道行太浅驾驭不了啊，花了几天的时间硬是给我死扛着做了个demo，进度着实缓慢，哎～\n\n为什么说它不爽呢？在我看来，它封装的太厚实了，除了暴露出来的一些操作属性外，你很难去控制这些控件的位置，更别提样式了，当然可能作者就是为了避免整体的设计理念被打乱吧。\n\n除此之外，该uikit不支持多国语言，而且datepicker也不是自适应的，导致无法在手机上很好的操作，而且动效还有些许卡顿（可能是我设备档次太低～）。\n\n不过，它的leftNav控件着实不赖，不管是性能还是美观度都非常讨好。\n\n当然，它还缺少了很多我个人认为非常必备的控件，比方说页码，面包屑等，期待它的完善吧～反正小哥我是耗不起了。\n\n我在中文论坛上搜了搜，果不其然找到了一个国人发布的ui库，之前也听说过，不过这次发现竟然还有react版本的，真是大爱啊：[amazeui](http://amazeui.org/react/components)。哥可不是做广告啊，其实原先我是打算使用：[react-bootstrap](http://react-bootstrap.github.io/components.html)，可不知道是不是审美疲劳了，总之bs2.0已经无法满足我的欲望了。\n\n这几天就容我换个行头重新来过吧～","slug":"论UIkit的重要性","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cid38pv5k00002hws2w7a57bd","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这年头，最怕的就是上贼船，真的！我才从待了四年的公司离职，谁知刚出粪坑又入“火坑”，真是运气太差啊～<br><a id=\"more\"></a><br>我所说的这个火坑，其实是一套无意间发现的ui，好吧，其实是我特意搜的，只恨当时鬼迷心窍被忽悠了啊（当然，也可能是我等级不够，下不了这个副本啊～）。</p>\n<p>我所指的ui就是：<a href=\"http://material-ui.com/#/\" target=\"_blank\" rel=\"external\">materialUI</a>。搞开发的，谁不佩服google的技术，之前玩的angular就是出自google，而我说的这套ui代码就是基于Material design设计理念打造而成，确实很容易看对眼啊～</p>\n<p>只可惜小哥我前端道行太浅驾驭不了啊，花了几天的时间硬是给我死扛着做了个demo，进度着实缓慢，哎～</p>\n<p>为什么说它不爽呢？在我看来，它封装的太厚实了，除了暴露出来的一些操作属性外，你很难去控制这些控件的位置，更别提样式了，当然可能作者就是为了避免整体的设计理念被打乱吧。</p>\n<p>除此之外，该uikit不支持多国语言，而且datepicker也不是自适应的，导致无法在手机上很好的操作，而且动效还有些许卡顿（可能是我设备档次太低～）。</p>\n<p>不过，它的leftNav控件着实不赖，不管是性能还是美观度都非常讨好。</p>\n<p>当然，它还缺少了很多我个人认为非常必备的控件，比方说页码，面包屑等，期待它的完善吧～反正小哥我是耗不起了。</p>\n<p>我在中文论坛上搜了搜，果不其然找到了一个国人发布的ui库，之前也听说过，不过这次发现竟然还有react版本的，真是大爱啊：<a href=\"http://amazeui.org/react/components\" target=\"_blank\" rel=\"external\">amazeui</a>。哥可不是做广告啊，其实原先我是打算使用：<a href=\"http://react-bootstrap.github.io/components.html\" target=\"_blank\" rel=\"external\">react-bootstrap</a>，可不知道是不是审美疲劳了，总之bs2.0已经无法满足我的欲望了。</p>\n<p>这几天就容我换个行头重新来过吧～</p>\n","excerpt":"<p>这年头，最怕的就是上贼船，真的！我才从待了四年的公司离职，谁知刚出粪坑又入“火坑”，真是运气太差啊～<br>","more":"<br>我所说的这个火坑，其实是一套无意间发现的ui，好吧，其实是我特意搜的，只恨当时鬼迷心窍被忽悠了啊（当然，也可能是我等级不够，下不了这个副本啊～）。</p>\n<p>我所指的ui就是：<a href=\"http://material-ui.com/#/\">materialUI</a>。搞开发的，谁不佩服google的技术，之前玩的angular就是出自google，而我说的这套ui代码就是基于Material design设计理念打造而成，确实很容易看对眼啊～</p>\n<p>只可惜小哥我前端道行太浅驾驭不了啊，花了几天的时间硬是给我死扛着做了个demo，进度着实缓慢，哎～</p>\n<p>为什么说它不爽呢？在我看来，它封装的太厚实了，除了暴露出来的一些操作属性外，你很难去控制这些控件的位置，更别提样式了，当然可能作者就是为了避免整体的设计理念被打乱吧。</p>\n<p>除此之外，该uikit不支持多国语言，而且datepicker也不是自适应的，导致无法在手机上很好的操作，而且动效还有些许卡顿（可能是我设备档次太低～）。</p>\n<p>不过，它的leftNav控件着实不赖，不管是性能还是美观度都非常讨好。</p>\n<p>当然，它还缺少了很多我个人认为非常必备的控件，比方说页码，面包屑等，期待它的完善吧～反正小哥我是耗不起了。</p>\n<p>我在中文论坛上搜了搜，果不其然找到了一个国人发布的ui库，之前也听说过，不过这次发现竟然还有react版本的，真是大爱啊：<a href=\"http://amazeui.org/react/components\">amazeui</a>。哥可不是做广告啊，其实原先我是打算使用：<a href=\"http://react-bootstrap.github.io/components.html\">react-bootstrap</a>，可不知道是不是审美疲劳了，总之bs2.0已经无法满足我的欲望了。</p>\n<p>这几天就容我换个行头重新来过吧～</p>"},{"title":"React开发web系统初体验","date":"2015-08-25T01:37:12.000Z","_content":"\n大热React的这段时间里，刚好碰到我找工作，所以画了一些时间学了一下react，用其开发了一个小web系统，下面主要是介绍一下其中的一些收获。\n<!--more-->\n\nReact ＋ ？ \n---\n这里我想说的是，只用react你是不足以搭建一个web系统的前端的，保守的说，你还需要：\n\n1. 路由：react-router\n2. ajax：我使用的是jQuery\n3. 项目文档结构：\n\n![](http://pic.yupoo.com/kazaff/EU3r7OaO/pa2RS.jpg)\n\n你会发现上图中存在两种带描述后缀的文件：XXXAction.js 和 XXXStore.js，之所以这么分，是因为项目里还是用了[reflux](http://blog.kazaff.me/2015/05/24/React%E5%92%8Cflux%E5%88%9D%E5%B0%9D%E5%BF%83%E5%BE%97/)，这个理念我们之前已经说过了。\n\n除此之外，所有页面文件的后缀名我使用`.jsx`，其他都是`.js`，我认为这样有助于快速的了解对应文件的作用。\n\n\n上述文件结构其实不算很灵活，实际开发中碰到有一些通用需求的页面，又不是太适合放在components里，就显得无法适配了，除此之外，components中的可复用web控件，理应不包含数据获取相关业务逻辑，但由于时间关系，我打破了这个规则，这样这些控件就无法直接用于其他项目了。。。以后开发需要注意～\n\n\n组件化思维\n---\n\n之前在使用angular的时候，指令其实是推荐使用的，但是你也完全可以不考虑组件模式，而react就不行了，你无时无刻不被强迫思考组件这个概念，因为react提供的语法本身就无时无刻体现了该模式，这一点我认为是极好的。\n\n可以说虽然react不像angular那样提供大量的内容需要开发者掌握，但想要用好react，必须建立起组件思维，官方提供的demo中就强调了如何把原先思考页面的布局改为思考页面的组件，听起来简单但实际做的时候还是会有些不适应。\n\n\n语法小贴士\n---\n\n1. 由于有babel这样的好东西，所以推荐从今天起就开始使用es6\n2. 好好学一下webpack的用法\n3. 那些不用来影响视图的变量就不要放在state中\n4. 组件嵌套时，props的值不要在组件内部做二次赋值，这样会导致react数据绑定“失效”，下面我给个例子：\n\n\t\tlet Inside = React.createClass({\n  \t\t\tcomponentWillMount(){\n    \t\t\tthis.setState({\n      \t\t\t\ta: this.props.params.a,\n    \t\t\t});\n  \t\t\t},\n  \n  \t\t\trender(){\n    \t\t\treturn (\n      \t\t\t\t<div>{this.state.a}</div>\n    \t\t\t);\n  \t\t\t},\n\t\t});\n\n\t\tlet Outside = React.createClass({\n  \t\t\tgetInitialState(){\n    \t\t\treturn {\n      \t\t\t\tdata: {\n        \t\t\t\ta: 1,\n      \t\t\t\t},\n    \t\t\t};\n  \t\t\t},\n  \n  \t\t\trender(){\n    \t\t\treturn (\n      \t\t\t\t<Inside params={this.state.data} />\n    \t\t\t);\n  \t\t\t},\n\t\t});\n\n看上去按说应该在外层每次修改`this.state.data.a`的时候内层都应该立刻显示最新的a值，但其实不然，原因其实很简单，内层`componentWillMount`方法只会在组件第一次加载时调用一次，然后就没有然后了。\n\n聪明的童鞋应该知道怎么改了，我就不多说了。\n\n\n\n\n最后\n---\n\n我给出我项目的依赖库：\n\n\t\"devDependencies\": {\n      \"babel-core\": \"^5.8.20\",\n      \"babel-loader\": \"^5.3.2\",\n      \"css-loader\": \"^0.15.6\",\n      \"file-loader\": \"^0.8.4\",\n      \"html-webpack-plugin\": \"^1.6.0\",\n      \"react-hot-loader\": \"^1.2.8\",\n      \"style-loader\": \"^0.12.3\",\n      \"url-loader\": \"^0.5.6\",\n      \"webpack\": \"^1.10.5\",\n      \"webpack-dev-server\": \"^1.10.1\",\n      \"amazeui\": \"^2.4.0\",\n      \"amazeui-react\": \"latest\"\n   \t},\n    \"dependencies\": {\n      \"react\": \"^0.13.3\",\n      \"react-notification-system\": \"^0.1.14\",\n      \"react-router\": \"^0.13.3\",\n      \"reflux\": \"^0.2.11\"\n    }\n    \n下面是项目的webpack配置文件：\n\n\tvar path = require('path');\n\tvar webpack = require('webpack');\n\tvar HtmlWebpackPlugin = require('html-webpack-plugin');\n\tvar node_modules = path.resolve(__dirname, 'node_modules');\n\t\n\tvar deps = [\n  \t\t//'react/dist/react.min.js',\n  \t\t'react-router/umd/ReactRouter.min.js',\n  \t\t//'amazeui-react/dist/amazeui.react.min.js',\n\t];\n\n\tvar config = {\n  \t\tentry: [\n    \t\tpath.resolve(__dirname, \"app/app.jsx\"),\n    \t\t\"webpack/hot/dev-server\",\n  \t\t],\n  \t\tresolve: {\n    \talias: {}\n  \t\t},\n  \t\toutput: {\n    \t\tpath: path.resolve(__dirname, \"build\"),\n    \t\tfilename: \"bundle.js\",\n  \t\t},\n  \t\tplugins: [\n    \t\t/*new webpack.optimize.UglifyJsPlugin({\n      \t\t\tcompress:{\n        \t\t\twarnings: false,\n      \t\t\t},\n    \t\t}),\n    \t\tnew webpack.optimize.CommonsChunkPlugin('common', 'common.js'),*/\n    \t\tnew HtmlWebpackPlugin({\n      \t\t\tinject: true,\n      \t\t\ttemplate: 'app/index.html',\n    \t\t}),\n    \t\tnew webpack.NoErrorsPlugin(),\n  \t\t],\n  \t\tmodule: {\n    \t\tloaders: [\n      \t\t{\n        \t\ttest: /\\.jsx?$/,\n        \t\t//loaders: ['react-hot','babel']\n        \t\tloader: 'babel'\n      \t\t},\n      \t\t{\n        \t\ttest: /\\.css$/,\n        \t\tloader: 'style!css',\n      \t\t},\n      \t\t{\n        \t\ttest: /\\.(png|jpg|eot|ttf|woff|woff2)$/,\n        \t\tloader: 'url',\n      \t\t}\n    \t\t],\n    \t\tnoParse: [],\n  \t\t},\n  \t\tdebug: true,\n  \t\tdevtool: 'eval-cheap-module-source-map',\n  \t\tdevServer: {\n    \t\tcontentBase: path.resolve(__dirname, \"build\"),\n    \t\thistoryApiFallback: true\n  \t\t}\n\t};\n\n\tdeps.forEach(function (dep) {\n  \t\tvar depPath = path.resolve(node_modules, dep);\n  \t\tconfig.resolve.alias[dep.split(path.sep)[0]] = depPath;\n  \t\tconfig.module.noParse.push(depPath);\n\t});\n\n\tmodule.exports = config;\n\n\n实际使用下来，感觉react要比ng强很多，同时也非常期待ng2的问世。\n","source":"_posts/React开发web系统初体验.md","raw":"title: React开发web系统初体验\ndate: 2015-08-25 09:37:12\ntags: \n- react\n- react-router\n- reflux\ncategories: 前端\n---\n\n大热React的这段时间里，刚好碰到我找工作，所以画了一些时间学了一下react，用其开发了一个小web系统，下面主要是介绍一下其中的一些收获。\n<!--more-->\n\nReact ＋ ？ \n---\n这里我想说的是，只用react你是不足以搭建一个web系统的前端的，保守的说，你还需要：\n\n1. 路由：react-router\n2. ajax：我使用的是jQuery\n3. 项目文档结构：\n\n![](http://pic.yupoo.com/kazaff/EU3r7OaO/pa2RS.jpg)\n\n你会发现上图中存在两种带描述后缀的文件：XXXAction.js 和 XXXStore.js，之所以这么分，是因为项目里还是用了[reflux](http://blog.kazaff.me/2015/05/24/React%E5%92%8Cflux%E5%88%9D%E5%B0%9D%E5%BF%83%E5%BE%97/)，这个理念我们之前已经说过了。\n\n除此之外，所有页面文件的后缀名我使用`.jsx`，其他都是`.js`，我认为这样有助于快速的了解对应文件的作用。\n\n\n上述文件结构其实不算很灵活，实际开发中碰到有一些通用需求的页面，又不是太适合放在components里，就显得无法适配了，除此之外，components中的可复用web控件，理应不包含数据获取相关业务逻辑，但由于时间关系，我打破了这个规则，这样这些控件就无法直接用于其他项目了。。。以后开发需要注意～\n\n\n组件化思维\n---\n\n之前在使用angular的时候，指令其实是推荐使用的，但是你也完全可以不考虑组件模式，而react就不行了，你无时无刻不被强迫思考组件这个概念，因为react提供的语法本身就无时无刻体现了该模式，这一点我认为是极好的。\n\n可以说虽然react不像angular那样提供大量的内容需要开发者掌握，但想要用好react，必须建立起组件思维，官方提供的demo中就强调了如何把原先思考页面的布局改为思考页面的组件，听起来简单但实际做的时候还是会有些不适应。\n\n\n语法小贴士\n---\n\n1. 由于有babel这样的好东西，所以推荐从今天起就开始使用es6\n2. 好好学一下webpack的用法\n3. 那些不用来影响视图的变量就不要放在state中\n4. 组件嵌套时，props的值不要在组件内部做二次赋值，这样会导致react数据绑定“失效”，下面我给个例子：\n\n\t\tlet Inside = React.createClass({\n  \t\t\tcomponentWillMount(){\n    \t\t\tthis.setState({\n      \t\t\t\ta: this.props.params.a,\n    \t\t\t});\n  \t\t\t},\n  \n  \t\t\trender(){\n    \t\t\treturn (\n      \t\t\t\t<div>{this.state.a}</div>\n    \t\t\t);\n  \t\t\t},\n\t\t});\n\n\t\tlet Outside = React.createClass({\n  \t\t\tgetInitialState(){\n    \t\t\treturn {\n      \t\t\t\tdata: {\n        \t\t\t\ta: 1,\n      \t\t\t\t},\n    \t\t\t};\n  \t\t\t},\n  \n  \t\t\trender(){\n    \t\t\treturn (\n      \t\t\t\t<Inside params={this.state.data} />\n    \t\t\t);\n  \t\t\t},\n\t\t});\n\n看上去按说应该在外层每次修改`this.state.data.a`的时候内层都应该立刻显示最新的a值，但其实不然，原因其实很简单，内层`componentWillMount`方法只会在组件第一次加载时调用一次，然后就没有然后了。\n\n聪明的童鞋应该知道怎么改了，我就不多说了。\n\n\n\n\n最后\n---\n\n我给出我项目的依赖库：\n\n\t\"devDependencies\": {\n      \"babel-core\": \"^5.8.20\",\n      \"babel-loader\": \"^5.3.2\",\n      \"css-loader\": \"^0.15.6\",\n      \"file-loader\": \"^0.8.4\",\n      \"html-webpack-plugin\": \"^1.6.0\",\n      \"react-hot-loader\": \"^1.2.8\",\n      \"style-loader\": \"^0.12.3\",\n      \"url-loader\": \"^0.5.6\",\n      \"webpack\": \"^1.10.5\",\n      \"webpack-dev-server\": \"^1.10.1\",\n      \"amazeui\": \"^2.4.0\",\n      \"amazeui-react\": \"latest\"\n   \t},\n    \"dependencies\": {\n      \"react\": \"^0.13.3\",\n      \"react-notification-system\": \"^0.1.14\",\n      \"react-router\": \"^0.13.3\",\n      \"reflux\": \"^0.2.11\"\n    }\n    \n下面是项目的webpack配置文件：\n\n\tvar path = require('path');\n\tvar webpack = require('webpack');\n\tvar HtmlWebpackPlugin = require('html-webpack-plugin');\n\tvar node_modules = path.resolve(__dirname, 'node_modules');\n\t\n\tvar deps = [\n  \t\t//'react/dist/react.min.js',\n  \t\t'react-router/umd/ReactRouter.min.js',\n  \t\t//'amazeui-react/dist/amazeui.react.min.js',\n\t];\n\n\tvar config = {\n  \t\tentry: [\n    \t\tpath.resolve(__dirname, \"app/app.jsx\"),\n    \t\t\"webpack/hot/dev-server\",\n  \t\t],\n  \t\tresolve: {\n    \talias: {}\n  \t\t},\n  \t\toutput: {\n    \t\tpath: path.resolve(__dirname, \"build\"),\n    \t\tfilename: \"bundle.js\",\n  \t\t},\n  \t\tplugins: [\n    \t\t/*new webpack.optimize.UglifyJsPlugin({\n      \t\t\tcompress:{\n        \t\t\twarnings: false,\n      \t\t\t},\n    \t\t}),\n    \t\tnew webpack.optimize.CommonsChunkPlugin('common', 'common.js'),*/\n    \t\tnew HtmlWebpackPlugin({\n      \t\t\tinject: true,\n      \t\t\ttemplate: 'app/index.html',\n    \t\t}),\n    \t\tnew webpack.NoErrorsPlugin(),\n  \t\t],\n  \t\tmodule: {\n    \t\tloaders: [\n      \t\t{\n        \t\ttest: /\\.jsx?$/,\n        \t\t//loaders: ['react-hot','babel']\n        \t\tloader: 'babel'\n      \t\t},\n      \t\t{\n        \t\ttest: /\\.css$/,\n        \t\tloader: 'style!css',\n      \t\t},\n      \t\t{\n        \t\ttest: /\\.(png|jpg|eot|ttf|woff|woff2)$/,\n        \t\tloader: 'url',\n      \t\t}\n    \t\t],\n    \t\tnoParse: [],\n  \t\t},\n  \t\tdebug: true,\n  \t\tdevtool: 'eval-cheap-module-source-map',\n  \t\tdevServer: {\n    \t\tcontentBase: path.resolve(__dirname, \"build\"),\n    \t\thistoryApiFallback: true\n  \t\t}\n\t};\n\n\tdeps.forEach(function (dep) {\n  \t\tvar depPath = path.resolve(node_modules, dep);\n  \t\tconfig.resolve.alias[dep.split(path.sep)[0]] = depPath;\n  \t\tconfig.module.noParse.push(depPath);\n\t});\n\n\tmodule.exports = config;\n\n\n实际使用下来，感觉react要比ng强很多，同时也非常期待ng2的问世。\n","slug":"React开发web系统初体验","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cidr1e0y5000010ws91jer8b0","comments":1,"layout":"post","photos":[],"link":"","content":"<p>大热React的这段时间里，刚好碰到我找工作，所以画了一些时间学了一下react，用其开发了一个小web系统，下面主要是介绍一下其中的一些收获。<br><a id=\"more\"></a></p>\n<h2 id=\"React-＋-？\"><a href=\"#React-＋-？\" class=\"headerlink\" title=\"React ＋ ？ \"></a>React ＋ ？ </h2><p>这里我想说的是，只用react你是不足以搭建一个web系统的前端的，保守的说，你还需要：</p>\n<ol>\n<li>路由：react-router</li>\n<li>ajax：我使用的是jQuery</li>\n<li>项目文档结构：</li>\n</ol>\n<p><img src=\"http://pic.yupoo.com/kazaff/EU3r7OaO/pa2RS.jpg\" alt=\"\"></p>\n<p>你会发现上图中存在两种带描述后缀的文件：XXXAction.js 和 XXXStore.js，之所以这么分，是因为项目里还是用了<a href=\"http://blog.kazaff.me/2015/05/24/React%E5%92%8Cflux%E5%88%9D%E5%B0%9D%E5%BF%83%E5%BE%97/\">reflux</a>，这个理念我们之前已经说过了。</p>\n<p>除此之外，所有页面文件的后缀名我使用<code>.jsx</code>，其他都是<code>.js</code>，我认为这样有助于快速的了解对应文件的作用。</p>\n<p>上述文件结构其实不算很灵活，实际开发中碰到有一些通用需求的页面，又不是太适合放在components里，就显得无法适配了，除此之外，components中的可复用web控件，理应不包含数据获取相关业务逻辑，但由于时间关系，我打破了这个规则，这样这些控件就无法直接用于其他项目了。。。以后开发需要注意～</p>\n<h2 id=\"组件化思维\"><a href=\"#组件化思维\" class=\"headerlink\" title=\"组件化思维\"></a>组件化思维</h2><p>之前在使用angular的时候，指令其实是推荐使用的，但是你也完全可以不考虑组件模式，而react就不行了，你无时无刻不被强迫思考组件这个概念，因为react提供的语法本身就无时无刻体现了该模式，这一点我认为是极好的。</p>\n<p>可以说虽然react不像angular那样提供大量的内容需要开发者掌握，但想要用好react，必须建立起组件思维，官方提供的demo中就强调了如何把原先思考页面的布局改为思考页面的组件，听起来简单但实际做的时候还是会有些不适应。</p>\n<h2 id=\"语法小贴士\"><a href=\"#语法小贴士\" class=\"headerlink\" title=\"语法小贴士\"></a>语法小贴士</h2><ol>\n<li>由于有babel这样的好东西，所以推荐从今天起就开始使用es6</li>\n<li>好好学一下webpack的用法</li>\n<li>那些不用来影响视图的变量就不要放在state中</li>\n<li><p>组件嵌套时，props的值不要在组件内部做二次赋值，这样会导致react数据绑定“失效”，下面我给个例子：</p>\n<pre><code>let Inside = React.createClass({\n      componentWillMount(){\n        this.setState({\n              a: this.props.params.a,\n        });\n      },\n\n      render(){\n        return (\n              &lt;div&gt;{this.state.a}&lt;/div&gt;\n        );\n      },\n});\n\nlet Outside = React.createClass({\n      getInitialState(){\n        return {\n              data: {\n                a: 1,\n              },\n        };\n      },\n\n      render(){\n        return (\n              &lt;Inside params={this.state.data} /&gt;\n        );\n      },\n});\n</code></pre></li>\n</ol>\n<p>看上去按说应该在外层每次修改<code>this.state.data.a</code>的时候内层都应该立刻显示最新的a值，但其实不然，原因其实很简单，内层<code>componentWillMount</code>方法只会在组件第一次加载时调用一次，然后就没有然后了。</p>\n<p>聪明的童鞋应该知道怎么改了，我就不多说了。</p>\n<h2 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h2><p>我给出我项目的依赖库：</p>\n<pre><code>&quot;devDependencies&quot;: {\n  &quot;babel-core&quot;: &quot;^5.8.20&quot;,\n  &quot;babel-loader&quot;: &quot;^5.3.2&quot;,\n  &quot;css-loader&quot;: &quot;^0.15.6&quot;,\n  &quot;file-loader&quot;: &quot;^0.8.4&quot;,\n  &quot;html-webpack-plugin&quot;: &quot;^1.6.0&quot;,\n  &quot;react-hot-loader&quot;: &quot;^1.2.8&quot;,\n  &quot;style-loader&quot;: &quot;^0.12.3&quot;,\n  &quot;url-loader&quot;: &quot;^0.5.6&quot;,\n  &quot;webpack&quot;: &quot;^1.10.5&quot;,\n  &quot;webpack-dev-server&quot;: &quot;^1.10.1&quot;,\n  &quot;amazeui&quot;: &quot;^2.4.0&quot;,\n  &quot;amazeui-react&quot;: &quot;latest&quot;\n   },\n&quot;dependencies&quot;: {\n  &quot;react&quot;: &quot;^0.13.3&quot;,\n  &quot;react-notification-system&quot;: &quot;^0.1.14&quot;,\n  &quot;react-router&quot;: &quot;^0.13.3&quot;,\n  &quot;reflux&quot;: &quot;^0.2.11&quot;\n}\n</code></pre><p>下面是项目的webpack配置文件：</p>\n<pre><code>var path = require(&apos;path&apos;);\nvar webpack = require(&apos;webpack&apos;);\nvar HtmlWebpackPlugin = require(&apos;html-webpack-plugin&apos;);\nvar node_modules = path.resolve(__dirname, &apos;node_modules&apos;);\n\nvar deps = [\n      //&apos;react/dist/react.min.js&apos;,\n      &apos;react-router/umd/ReactRouter.min.js&apos;,\n      //&apos;amazeui-react/dist/amazeui.react.min.js&apos;,\n];\n\nvar config = {\n      entry: [\n        path.resolve(__dirname, &quot;app/app.jsx&quot;),\n        &quot;webpack/hot/dev-server&quot;,\n      ],\n      resolve: {\n    alias: {}\n      },\n      output: {\n        path: path.resolve(__dirname, &quot;build&quot;),\n        filename: &quot;bundle.js&quot;,\n      },\n      plugins: [\n        /*new webpack.optimize.UglifyJsPlugin({\n              compress:{\n                warnings: false,\n              },\n        }),\n        new webpack.optimize.CommonsChunkPlugin(&apos;common&apos;, &apos;common.js&apos;),*/\n        new HtmlWebpackPlugin({\n              inject: true,\n              template: &apos;app/index.html&apos;,\n        }),\n        new webpack.NoErrorsPlugin(),\n      ],\n      module: {\n        loaders: [\n          {\n            test: /\\.jsx?$/,\n            //loaders: [&apos;react-hot&apos;,&apos;babel&apos;]\n            loader: &apos;babel&apos;\n          },\n          {\n            test: /\\.css$/,\n            loader: &apos;style!css&apos;,\n          },\n          {\n            test: /\\.(png|jpg|eot|ttf|woff|woff2)$/,\n            loader: &apos;url&apos;,\n          }\n        ],\n        noParse: [],\n      },\n      debug: true,\n      devtool: &apos;eval-cheap-module-source-map&apos;,\n      devServer: {\n        contentBase: path.resolve(__dirname, &quot;build&quot;),\n        historyApiFallback: true\n      }\n};\n\ndeps.forEach(function (dep) {\n      var depPath = path.resolve(node_modules, dep);\n      config.resolve.alias[dep.split(path.sep)[0]] = depPath;\n      config.module.noParse.push(depPath);\n});\n\nmodule.exports = config;\n</code></pre><p>实际使用下来，感觉react要比ng强很多，同时也非常期待ng2的问世。</p>\n","excerpt":"<p>大热React的这段时间里，刚好碰到我找工作，所以画了一些时间学了一下react，用其开发了一个小web系统，下面主要是介绍一下其中的一些收获。<br>","more":"</p>\n<h2 id=\"React-＋-？\"><a href=\"#React-＋-？\" class=\"headerlink\" title=\"React ＋ ？ \"></a>React ＋ ？ </h2><p>这里我想说的是，只用react你是不足以搭建一个web系统的前端的，保守的说，你还需要：</p>\n<ol>\n<li>路由：react-router</li>\n<li>ajax：我使用的是jQuery</li>\n<li>项目文档结构：</li>\n</ol>\n<p><img src=\"http://pic.yupoo.com/kazaff/EU3r7OaO/pa2RS.jpg\" alt=\"\"></p>\n<p>你会发现上图中存在两种带描述后缀的文件：XXXAction.js 和 XXXStore.js，之所以这么分，是因为项目里还是用了<a href=\"http://blog.kazaff.me/2015/05/24/React%E5%92%8Cflux%E5%88%9D%E5%B0%9D%E5%BF%83%E5%BE%97/\">reflux</a>，这个理念我们之前已经说过了。</p>\n<p>除此之外，所有页面文件的后缀名我使用<code>.jsx</code>，其他都是<code>.js</code>，我认为这样有助于快速的了解对应文件的作用。</p>\n<p>上述文件结构其实不算很灵活，实际开发中碰到有一些通用需求的页面，又不是太适合放在components里，就显得无法适配了，除此之外，components中的可复用web控件，理应不包含数据获取相关业务逻辑，但由于时间关系，我打破了这个规则，这样这些控件就无法直接用于其他项目了。。。以后开发需要注意～</p>\n<h2 id=\"组件化思维\"><a href=\"#组件化思维\" class=\"headerlink\" title=\"组件化思维\"></a>组件化思维</h2><p>之前在使用angular的时候，指令其实是推荐使用的，但是你也完全可以不考虑组件模式，而react就不行了，你无时无刻不被强迫思考组件这个概念，因为react提供的语法本身就无时无刻体现了该模式，这一点我认为是极好的。</p>\n<p>可以说虽然react不像angular那样提供大量的内容需要开发者掌握，但想要用好react，必须建立起组件思维，官方提供的demo中就强调了如何把原先思考页面的布局改为思考页面的组件，听起来简单但实际做的时候还是会有些不适应。</p>\n<h2 id=\"语法小贴士\"><a href=\"#语法小贴士\" class=\"headerlink\" title=\"语法小贴士\"></a>语法小贴士</h2><ol>\n<li>由于有babel这样的好东西，所以推荐从今天起就开始使用es6</li>\n<li>好好学一下webpack的用法</li>\n<li>那些不用来影响视图的变量就不要放在state中</li>\n<li><p>组件嵌套时，props的值不要在组件内部做二次赋值，这样会导致react数据绑定“失效”，下面我给个例子：</p>\n<pre><code>let Inside = React.createClass({\n      componentWillMount(){\n        this.setState({\n              a: this.props.params.a,\n        });\n      },\n\n      render(){\n        return (\n              &lt;div&gt;{this.state.a}&lt;/div&gt;\n        );\n      },\n});\n\nlet Outside = React.createClass({\n      getInitialState(){\n        return {\n              data: {\n                a: 1,\n              },\n        };\n      },\n\n      render(){\n        return (\n              &lt;Inside params={this.state.data} /&gt;\n        );\n      },\n});\n</code></pre></li>\n</ol>\n<p>看上去按说应该在外层每次修改<code>this.state.data.a</code>的时候内层都应该立刻显示最新的a值，但其实不然，原因其实很简单，内层<code>componentWillMount</code>方法只会在组件第一次加载时调用一次，然后就没有然后了。</p>\n<p>聪明的童鞋应该知道怎么改了，我就不多说了。</p>\n<h2 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h2><p>我给出我项目的依赖库：</p>\n<pre><code>&quot;devDependencies&quot;: {\n  &quot;babel-core&quot;: &quot;^5.8.20&quot;,\n  &quot;babel-loader&quot;: &quot;^5.3.2&quot;,\n  &quot;css-loader&quot;: &quot;^0.15.6&quot;,\n  &quot;file-loader&quot;: &quot;^0.8.4&quot;,\n  &quot;html-webpack-plugin&quot;: &quot;^1.6.0&quot;,\n  &quot;react-hot-loader&quot;: &quot;^1.2.8&quot;,\n  &quot;style-loader&quot;: &quot;^0.12.3&quot;,\n  &quot;url-loader&quot;: &quot;^0.5.6&quot;,\n  &quot;webpack&quot;: &quot;^1.10.5&quot;,\n  &quot;webpack-dev-server&quot;: &quot;^1.10.1&quot;,\n  &quot;amazeui&quot;: &quot;^2.4.0&quot;,\n  &quot;amazeui-react&quot;: &quot;latest&quot;\n   },\n&quot;dependencies&quot;: {\n  &quot;react&quot;: &quot;^0.13.3&quot;,\n  &quot;react-notification-system&quot;: &quot;^0.1.14&quot;,\n  &quot;react-router&quot;: &quot;^0.13.3&quot;,\n  &quot;reflux&quot;: &quot;^0.2.11&quot;\n}\n</code></pre><p>下面是项目的webpack配置文件：</p>\n<pre><code>var path = require(&apos;path&apos;);\nvar webpack = require(&apos;webpack&apos;);\nvar HtmlWebpackPlugin = require(&apos;html-webpack-plugin&apos;);\nvar node_modules = path.resolve(__dirname, &apos;node_modules&apos;);\n\nvar deps = [\n      //&apos;react/dist/react.min.js&apos;,\n      &apos;react-router/umd/ReactRouter.min.js&apos;,\n      //&apos;amazeui-react/dist/amazeui.react.min.js&apos;,\n];\n\nvar config = {\n      entry: [\n        path.resolve(__dirname, &quot;app/app.jsx&quot;),\n        &quot;webpack/hot/dev-server&quot;,\n      ],\n      resolve: {\n    alias: {}\n      },\n      output: {\n        path: path.resolve(__dirname, &quot;build&quot;),\n        filename: &quot;bundle.js&quot;,\n      },\n      plugins: [\n        /*new webpack.optimize.UglifyJsPlugin({\n              compress:{\n                warnings: false,\n              },\n        }),\n        new webpack.optimize.CommonsChunkPlugin(&apos;common&apos;, &apos;common.js&apos;),*/\n        new HtmlWebpackPlugin({\n              inject: true,\n              template: &apos;app/index.html&apos;,\n        }),\n        new webpack.NoErrorsPlugin(),\n      ],\n      module: {\n        loaders: [\n          {\n            test: /\\.jsx?$/,\n            //loaders: [&apos;react-hot&apos;,&apos;babel&apos;]\n            loader: &apos;babel&apos;\n          },\n          {\n            test: /\\.css$/,\n            loader: &apos;style!css&apos;,\n          },\n          {\n            test: /\\.(png|jpg|eot|ttf|woff|woff2)$/,\n            loader: &apos;url&apos;,\n          }\n        ],\n        noParse: [],\n      },\n      debug: true,\n      devtool: &apos;eval-cheap-module-source-map&apos;,\n      devServer: {\n        contentBase: path.resolve(__dirname, &quot;build&quot;),\n        historyApiFallback: true\n      }\n};\n\ndeps.forEach(function (dep) {\n      var depPath = path.resolve(node_modules, dep);\n      config.resolve.alias[dep.split(path.sep)[0]] = depPath;\n      config.module.noParse.push(depPath);\n});\n\nmodule.exports = config;\n</code></pre><p>实际使用下来，感觉react要比ng强很多，同时也非常期待ng2的问世。</p>"},{"title":"［译］reactjs性能篇","date":"2015-09-10T01:37:12.000Z","_content":"\n英文有限，技术一般，海涵海涵，由于不是翻译出身，所以存在大量的瞎胡乱翻译的情况，信不过我的，请看原文～～\n\n原文地址：[https://facebook.github.io/react/docs/advanced-performance.html](https://facebook.github.io/react/docs/advanced-performance.html)\n\n<!--more-->\n\n---\n\n###性能优化\n\n每当开发者选择将react用在真实项目中时都会先问一个问题：使用react是否会让项目速度更快，更灵活，更容易维护。此外每次状态数据发生改变时都会进行重新渲染界面的处理做法会不会造成性能瓶颈？而在react内部则是通过使用一些精妙的技巧来最小化每次造成ui更新的昂贵的dom操作从而保证性能的。\n\n\n####避免直接作用于DOM\nreact实现了一层虚拟dom，它用来映射浏览器的原生dom树。通过这一层虚拟的dom，可以让react避免直接操作dom，因为直接操作浏览器dom的速度要远低于操作javascript对象。每当组件的属性或者状态发生改变时，react会在内存中构造一个新的虚拟dom与原先老的进行对比，用来判断是否需要更新浏览器的dom树，这样就尽可能的优化了渲染dom的性能损耗。\n\n在此之上，react提供了组件生命周期函数，`shouldComponentUpdate`，组件在决定重新渲染（虚拟dom比对完毕生成最终的dom后）之前会调用该函数，该函数将是否重新渲染的权限交给了开发者，该函数默认直接返回`true`，表示默认直接出发dom更新：\n\t\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\treturn true;\n\t}\n\n值得注意的是，react会非常频繁的调用该函数，所以如果你打算自己实现该函数的逻辑，请尽可能保证性能。\n\n比方说，你有一个拥有多个帖子的聊天应用，如果此时只有一个发生了变化，如果你如下实现了`shouldComponentUpdate`，react会根据情况避免重新渲染那些没有发生变化的帖子：\n\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\t// TODO: return whether or not current chat thread is different to former one.\n  \t\t// 根据实际情况判断当前帖子的状态是否和之前不同\n\t}\n\t\n总之，react尽可能的避免了昂贵的dom操作，并且允许开发者干涉该行为。\n\n\n####shouldComponentUpdate实战\n这里举个包含子元素的组件例子，如下图：\n\n![](https://facebook.github.io/react/img/docs/should-component-update.png)\n\n图中每个圆点表示一个dom节点，当某个dom节点的`shouldComponentUpdate`返回`false`时（例如c2），react就无需为其更新dom，注意，react甚至根本不会去调用c4和c5节点的`shouldComponentUpdate`函数哦～\n\n图中c1和c3的`shouldComponentUpdate`返回了`true`，因此react会检查检查其它们包含的直接子节点。最有趣的是c8节点，虽然调用它的`shouldComponentUpdate`方法返回的是`true`，但react检查后发现其dom结构并未发生改变，所以react最终是不会重新渲染其浏览器dom的。\n\n上图的情况下，react最终只会重新渲染c6，原因你应该懂的。\n\n那么我们应该如何实现`shouldComponentUpdate`函数呢？假设你有一个只包含字符串的组件，如下：\n\n\tReact.createClass({\n  \t\tpropTypes: {\n    \t\tvalue: React.PropTypes.string.isRequired\n  \t\t},\n\n  \t\trender: function() {\n    \t\treturn <div>{this.props.value}</div>;\n  \t\t}\n\t});\n\t\n我们可以简单的直接实现`shouldComponentUpdate`如下：\n\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\treturn this.props.value !== nextProps.value;\n\t}\n\n目前为止一切都很顺利，处理基础类型的属性和状态是很简单的，我们可以直接使用js语言提供的`===`比对来实现一个mix并注入到所有组件中，事实上，react自身已经提供了一个类似的：[PureRenderMixin](https://facebook.github.io/react/docs/pure-render-mixin.html)。\n\n但是如果你的组件所拥有的属性或状态不是基础类型呢，而是复合类型呢？比方说是一个js对象，`{foo: 'bar'}`：\n\n\tReact.createClass({\n  \t\tpropTypes: {\n    \t\tvalue: React.PropTypes.object.isRequired\n  \t\t},\n\n  \t\trender: function() {\n    \t\treturn <div>{this.props.value.foo}</div>;\n  \t\t}\n\t});\n\t\n这种情况下我们刚才实现的那种`shouldComponentUpdate`就歇菜了：\n\n\t// 假设 this.props.value 是 { foo: 'bar' }\n\t// 假设 nextProps.value 是 { foo: 'bar' },\n\t// 但是nextProps和this.props对应的引用不相同\n\tthis.props.value !== nextProps.value; // true\n\t\n要想修复这个问题，简单粗暴的方法是我们直接比对`foo`的值，如下：\n\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\treturn this.props.value.foo !== nextProps.value.foo;\n\t}\n\t\n我们当然可以通过深比对来确定属性或状态是否确实发生了改变，但是这种深比对是非常昂贵的，还记得我们刚出说过`shouldComponentUpdate`函数的调用非常频繁么？更何况我们为每个model去单独实现一个匹配的深比对逻辑，对于开发人员来说也是非常痛苦的。最重要的是，如果我们不是很小心的处理对象引用关系的话，还会带来灾难。例如下面这个组件：\n\n\tReact.createClass({\n  \t\tgetInitialState: function() {\n    \t\treturn { value: { foo: 'bar' } };\n  \t\t},\n\n  \t\tonClick: function() {\n    \t\tvar value = this.state.value;\n    \t\tvalue.foo += 'bar'; // ANTI-PATTERN!\n    \t\tthis.setState({ value: value });\n  \t\t},\n\n  \t\trender: function() {\n    \t\treturn (\n      \t\t\t<div>\n        \t\t\t<InnerComponent value={this.state.value} />\n        \t\t\t<a onClick={this.onClick}>Click me</a>\n      \t\t\t</div>\n    \t\t);\n  \t\t}\n\t});\n\t\n起初，InnerComponent组件进行渲染，它得到的value属性为`{foo: 'bar'}`。当用户点击链接后，父组件的状态将会更新为`{ value: { foo: 'barbar' } }`，触发了InnerComponent组件的重新渲染，因为它得到了一个新的属性：`{ foo: 'barbar' }`。\n\n看上去一切都挺好的，其实问题在于，父组件和子组件供用了同一个对象的引用，当用户触发click事件时，InnerComponent的prop将会发生改变，因此它的`shouldComponentUpdate`函数将会被调用，而此时如果按照我们目前的`shouldComponentUpdate`比对逻辑的话，`this.props.value.foo`和`nextProps.value.foo`是相等的，因为事实上，它们同时引用同一个对象哦～所以，我们将会看到，InnerComponent的ui并没有更新。哎～，不信的话，我贴出完整代码：\n\n\t<!DOCTYPE html>\n\t<html>\n\t\t<head>\n\t\t\t<meta charset=\"utf-8\">\n\t\t\t<title>demo</title>\n\t\t\t<!--引入React库-->\n\t\t\t<script src=\"lib/react.min.js\"></script>\n\t\t\t<!--引入JSX转换库-->\n\t\t\t<script src=\"lib/JSXTransformer.js\"></script>\n\t\t\t<!--组件样式-->\n\t\t</head>\n\t\t<body>\n\t\t\t<!--定义容器-->\n\t\t\t<div id=\"content\"></div>\n\n\t\t\t<!--声明脚本类型为JSX-->\n\t\t\t<script type=\"text/jsx\">\n\n\t\t\t\tvar InnerComponent = React.createClass({\n        \t\t\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\t\t\t\t\treturn this.props.value.foo !== nextProps.value.foo;\n\t\t\t\t\t},\n  \t\t\t\t\trender: function() {\n    \t\t\t\t\treturn (\n      \t\t\t\t\t\t<div>\n        \t\t\t\t\t\t{this.props.value.foo}\n      \t\t\t\t\t\t</div>\n    \t\t\t\t\t);\n  \t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\tvar OutComponent = React.createClass({\n  \t\t\t\t\tgetInitialState: function() {\n    \t\t\t\t\treturn { value: { foo: 'bar' } };\n  \t\t\t\t\t},\n\n  \t\t\t\t\tonClick: function() {\n    \t\t\t\t\tvar value = this.state.value;\n    \t\t\t\t\tvalue.foo += 'bar'; // ANTI-PATTERN!\n    \t\t\t\t\tthis.setState({ value: value });\n  \t\t\t\t\t},\n\n  \t\t\t\t\trender: function() {\n    \t\t\t\t\treturn (\n      \t\t\t\t\t\t<div>\n        \t\t\t\t\t\t<InnerComponent value={this.state.value} />\n        \t\t\t\t\t\t<a onClick={this.onClick}>Click me</a>\n      \t\t\t\t\t\t</div>\n    \t\t\t\t\t);\n  \t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\tReact.render(<OutComponent />, document.querySelector(\"#content\"));\n\t\t\n\t\t\t</script>\n\t\t</body>\n\t</html>\n\n\n\n####Immutable-js的救赎\n[Immutable-js](https://github.com/facebook/immutable-js)是一个javascript集合库，作者是Lee Byron，该项目最近从fb开源。它提供了不可变集合类型：\n\n+ 不可变性：一旦创建，这个集合不允许再更改。\n+ 延续性：新集合可以衍生自一个已经创建过的集合，并作一些改动，此时源集合不会受到任何影响。\n+ 结构共享：如果新集合衍生自一个老集合，那么新集合中与老集合相同的部份将会共享同一块内存，这样做的好处是节省内存开销，并能在创建新集合对象时减少内存拷贝的性能损耗。\n\n不可变性使得监控状态变化变得可行，每次状态发生变化，将总是返回一个新的对象，我们只需要检查改变前后的对象引用是否相同即可。举个例子：\n\n\tvar x = { foo: \"bar\" };\n\tvar y = x;\n\ty.foo = \"baz\";\n\tx === y; // true\n\t\n尽管变量y被修改，但由于y和x的引用相同，最后的比对仍然返回true。如果上面的代码用immutable-js来实现：\n\n\tvar SomeRecord = Immutable.Record({ foo: null });\n\tvar x = new SomeRecord({ foo: 'bar'  });\n\tvar y = x.set('foo', 'baz');\n\tx === y; // false\n\t\n看到了么，是不是很爽？\n\n另外一种监控变量的方法是设置一个标识位，但这需要开发者编写额外的代码，哎，反正活着就是麻烦。\n\n总之，不可变集合结构提供了你一个廉价且简单的监控对象改变的方法，你可以放在`shouldComponentUpdate`中。因此，如果你的model属性和状态是基于immutable-js来实现的，那么你就可以直接使用官方提供的`PureRenderMixin`哟～\n\n####Immutable-js和Flux\n如果你恰巧使用[Flux](https://facebook.github.io/flux/)，并且你又基于immutable-js来实现你的store，那你先看一下相关的[api](https://facebook.github.io/immutable-js/docs/#/)吧。\n\n让我们来用个模拟应用演示一下使用一种可行的方案。首先，我们需要定义一下用到的model：\n\n\tvar User = Immutable.Record({\n  \t\tid: undefined,\n  \t\tname: undefined,\n  \t\temail: undefined\n\t});\n\n\tvar Message = Immutable.Record({\n  \t\ttimestamp: new Date(),\n  \t\tsender: undefined,\n  \t\ttext: ''\n\t});\n\t\n每个Record接受一个对象，分别定义了字段和默认值。我们的messages store需要使用的是list结构：\n\n\tthis.users = Immutable.List();\n\tthis.messages = Immutable.List();\n\t\n很简单吧，接着，每当store接受到一个新的message时，我们只需要创建一个新的record并把它加入到列表中即可：\n\n\tthis.messages = this.messages.push(new Message({\n  \t\ttimestamp: payload.timestamp,\n  \t\tsender: payload.sender,\n  \t\ttext: payload.text\n\t});\n\t\n对比我们刚刚讲过的immutable-js特性，在react的组件中我们只需要直接注入`PureRenderMixin`即可高枕无忧。\n\n","source":"_posts/[译]Reactjs性能篇.md","raw":"title: ［译］reactjs性能篇\ndate: 2015-09-10 09:37:12\ntags: \n- react\n- dom\n- shouldComponentUpdate\n- Immutable-js\ncategories: 前端\n---\n\n英文有限，技术一般，海涵海涵，由于不是翻译出身，所以存在大量的瞎胡乱翻译的情况，信不过我的，请看原文～～\n\n原文地址：[https://facebook.github.io/react/docs/advanced-performance.html](https://facebook.github.io/react/docs/advanced-performance.html)\n\n<!--more-->\n\n---\n\n###性能优化\n\n每当开发者选择将react用在真实项目中时都会先问一个问题：使用react是否会让项目速度更快，更灵活，更容易维护。此外每次状态数据发生改变时都会进行重新渲染界面的处理做法会不会造成性能瓶颈？而在react内部则是通过使用一些精妙的技巧来最小化每次造成ui更新的昂贵的dom操作从而保证性能的。\n\n\n####避免直接作用于DOM\nreact实现了一层虚拟dom，它用来映射浏览器的原生dom树。通过这一层虚拟的dom，可以让react避免直接操作dom，因为直接操作浏览器dom的速度要远低于操作javascript对象。每当组件的属性或者状态发生改变时，react会在内存中构造一个新的虚拟dom与原先老的进行对比，用来判断是否需要更新浏览器的dom树，这样就尽可能的优化了渲染dom的性能损耗。\n\n在此之上，react提供了组件生命周期函数，`shouldComponentUpdate`，组件在决定重新渲染（虚拟dom比对完毕生成最终的dom后）之前会调用该函数，该函数将是否重新渲染的权限交给了开发者，该函数默认直接返回`true`，表示默认直接出发dom更新：\n\t\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\treturn true;\n\t}\n\n值得注意的是，react会非常频繁的调用该函数，所以如果你打算自己实现该函数的逻辑，请尽可能保证性能。\n\n比方说，你有一个拥有多个帖子的聊天应用，如果此时只有一个发生了变化，如果你如下实现了`shouldComponentUpdate`，react会根据情况避免重新渲染那些没有发生变化的帖子：\n\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\t// TODO: return whether or not current chat thread is different to former one.\n  \t\t// 根据实际情况判断当前帖子的状态是否和之前不同\n\t}\n\t\n总之，react尽可能的避免了昂贵的dom操作，并且允许开发者干涉该行为。\n\n\n####shouldComponentUpdate实战\n这里举个包含子元素的组件例子，如下图：\n\n![](https://facebook.github.io/react/img/docs/should-component-update.png)\n\n图中每个圆点表示一个dom节点，当某个dom节点的`shouldComponentUpdate`返回`false`时（例如c2），react就无需为其更新dom，注意，react甚至根本不会去调用c4和c5节点的`shouldComponentUpdate`函数哦～\n\n图中c1和c3的`shouldComponentUpdate`返回了`true`，因此react会检查检查其它们包含的直接子节点。最有趣的是c8节点，虽然调用它的`shouldComponentUpdate`方法返回的是`true`，但react检查后发现其dom结构并未发生改变，所以react最终是不会重新渲染其浏览器dom的。\n\n上图的情况下，react最终只会重新渲染c6，原因你应该懂的。\n\n那么我们应该如何实现`shouldComponentUpdate`函数呢？假设你有一个只包含字符串的组件，如下：\n\n\tReact.createClass({\n  \t\tpropTypes: {\n    \t\tvalue: React.PropTypes.string.isRequired\n  \t\t},\n\n  \t\trender: function() {\n    \t\treturn <div>{this.props.value}</div>;\n  \t\t}\n\t});\n\t\n我们可以简单的直接实现`shouldComponentUpdate`如下：\n\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\treturn this.props.value !== nextProps.value;\n\t}\n\n目前为止一切都很顺利，处理基础类型的属性和状态是很简单的，我们可以直接使用js语言提供的`===`比对来实现一个mix并注入到所有组件中，事实上，react自身已经提供了一个类似的：[PureRenderMixin](https://facebook.github.io/react/docs/pure-render-mixin.html)。\n\n但是如果你的组件所拥有的属性或状态不是基础类型呢，而是复合类型呢？比方说是一个js对象，`{foo: 'bar'}`：\n\n\tReact.createClass({\n  \t\tpropTypes: {\n    \t\tvalue: React.PropTypes.object.isRequired\n  \t\t},\n\n  \t\trender: function() {\n    \t\treturn <div>{this.props.value.foo}</div>;\n  \t\t}\n\t});\n\t\n这种情况下我们刚才实现的那种`shouldComponentUpdate`就歇菜了：\n\n\t// 假设 this.props.value 是 { foo: 'bar' }\n\t// 假设 nextProps.value 是 { foo: 'bar' },\n\t// 但是nextProps和this.props对应的引用不相同\n\tthis.props.value !== nextProps.value; // true\n\t\n要想修复这个问题，简单粗暴的方法是我们直接比对`foo`的值，如下：\n\n\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\treturn this.props.value.foo !== nextProps.value.foo;\n\t}\n\t\n我们当然可以通过深比对来确定属性或状态是否确实发生了改变，但是这种深比对是非常昂贵的，还记得我们刚出说过`shouldComponentUpdate`函数的调用非常频繁么？更何况我们为每个model去单独实现一个匹配的深比对逻辑，对于开发人员来说也是非常痛苦的。最重要的是，如果我们不是很小心的处理对象引用关系的话，还会带来灾难。例如下面这个组件：\n\n\tReact.createClass({\n  \t\tgetInitialState: function() {\n    \t\treturn { value: { foo: 'bar' } };\n  \t\t},\n\n  \t\tonClick: function() {\n    \t\tvar value = this.state.value;\n    \t\tvalue.foo += 'bar'; // ANTI-PATTERN!\n    \t\tthis.setState({ value: value });\n  \t\t},\n\n  \t\trender: function() {\n    \t\treturn (\n      \t\t\t<div>\n        \t\t\t<InnerComponent value={this.state.value} />\n        \t\t\t<a onClick={this.onClick}>Click me</a>\n      \t\t\t</div>\n    \t\t);\n  \t\t}\n\t});\n\t\n起初，InnerComponent组件进行渲染，它得到的value属性为`{foo: 'bar'}`。当用户点击链接后，父组件的状态将会更新为`{ value: { foo: 'barbar' } }`，触发了InnerComponent组件的重新渲染，因为它得到了一个新的属性：`{ foo: 'barbar' }`。\n\n看上去一切都挺好的，其实问题在于，父组件和子组件供用了同一个对象的引用，当用户触发click事件时，InnerComponent的prop将会发生改变，因此它的`shouldComponentUpdate`函数将会被调用，而此时如果按照我们目前的`shouldComponentUpdate`比对逻辑的话，`this.props.value.foo`和`nextProps.value.foo`是相等的，因为事实上，它们同时引用同一个对象哦～所以，我们将会看到，InnerComponent的ui并没有更新。哎～，不信的话，我贴出完整代码：\n\n\t<!DOCTYPE html>\n\t<html>\n\t\t<head>\n\t\t\t<meta charset=\"utf-8\">\n\t\t\t<title>demo</title>\n\t\t\t<!--引入React库-->\n\t\t\t<script src=\"lib/react.min.js\"></script>\n\t\t\t<!--引入JSX转换库-->\n\t\t\t<script src=\"lib/JSXTransformer.js\"></script>\n\t\t\t<!--组件样式-->\n\t\t</head>\n\t\t<body>\n\t\t\t<!--定义容器-->\n\t\t\t<div id=\"content\"></div>\n\n\t\t\t<!--声明脚本类型为JSX-->\n\t\t\t<script type=\"text/jsx\">\n\n\t\t\t\tvar InnerComponent = React.createClass({\n        \t\t\tshouldComponentUpdate: function(nextProps, nextState) {\n  \t\t\t\t\t\treturn this.props.value.foo !== nextProps.value.foo;\n\t\t\t\t\t},\n  \t\t\t\t\trender: function() {\n    \t\t\t\t\treturn (\n      \t\t\t\t\t\t<div>\n        \t\t\t\t\t\t{this.props.value.foo}\n      \t\t\t\t\t\t</div>\n    \t\t\t\t\t);\n  \t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\tvar OutComponent = React.createClass({\n  \t\t\t\t\tgetInitialState: function() {\n    \t\t\t\t\treturn { value: { foo: 'bar' } };\n  \t\t\t\t\t},\n\n  \t\t\t\t\tonClick: function() {\n    \t\t\t\t\tvar value = this.state.value;\n    \t\t\t\t\tvalue.foo += 'bar'; // ANTI-PATTERN!\n    \t\t\t\t\tthis.setState({ value: value });\n  \t\t\t\t\t},\n\n  \t\t\t\t\trender: function() {\n    \t\t\t\t\treturn (\n      \t\t\t\t\t\t<div>\n        \t\t\t\t\t\t<InnerComponent value={this.state.value} />\n        \t\t\t\t\t\t<a onClick={this.onClick}>Click me</a>\n      \t\t\t\t\t\t</div>\n    \t\t\t\t\t);\n  \t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\tReact.render(<OutComponent />, document.querySelector(\"#content\"));\n\t\t\n\t\t\t</script>\n\t\t</body>\n\t</html>\n\n\n\n####Immutable-js的救赎\n[Immutable-js](https://github.com/facebook/immutable-js)是一个javascript集合库，作者是Lee Byron，该项目最近从fb开源。它提供了不可变集合类型：\n\n+ 不可变性：一旦创建，这个集合不允许再更改。\n+ 延续性：新集合可以衍生自一个已经创建过的集合，并作一些改动，此时源集合不会受到任何影响。\n+ 结构共享：如果新集合衍生自一个老集合，那么新集合中与老集合相同的部份将会共享同一块内存，这样做的好处是节省内存开销，并能在创建新集合对象时减少内存拷贝的性能损耗。\n\n不可变性使得监控状态变化变得可行，每次状态发生变化，将总是返回一个新的对象，我们只需要检查改变前后的对象引用是否相同即可。举个例子：\n\n\tvar x = { foo: \"bar\" };\n\tvar y = x;\n\ty.foo = \"baz\";\n\tx === y; // true\n\t\n尽管变量y被修改，但由于y和x的引用相同，最后的比对仍然返回true。如果上面的代码用immutable-js来实现：\n\n\tvar SomeRecord = Immutable.Record({ foo: null });\n\tvar x = new SomeRecord({ foo: 'bar'  });\n\tvar y = x.set('foo', 'baz');\n\tx === y; // false\n\t\n看到了么，是不是很爽？\n\n另外一种监控变量的方法是设置一个标识位，但这需要开发者编写额外的代码，哎，反正活着就是麻烦。\n\n总之，不可变集合结构提供了你一个廉价且简单的监控对象改变的方法，你可以放在`shouldComponentUpdate`中。因此，如果你的model属性和状态是基于immutable-js来实现的，那么你就可以直接使用官方提供的`PureRenderMixin`哟～\n\n####Immutable-js和Flux\n如果你恰巧使用[Flux](https://facebook.github.io/flux/)，并且你又基于immutable-js来实现你的store，那你先看一下相关的[api](https://facebook.github.io/immutable-js/docs/#/)吧。\n\n让我们来用个模拟应用演示一下使用一种可行的方案。首先，我们需要定义一下用到的model：\n\n\tvar User = Immutable.Record({\n  \t\tid: undefined,\n  \t\tname: undefined,\n  \t\temail: undefined\n\t});\n\n\tvar Message = Immutable.Record({\n  \t\ttimestamp: new Date(),\n  \t\tsender: undefined,\n  \t\ttext: ''\n\t});\n\t\n每个Record接受一个对象，分别定义了字段和默认值。我们的messages store需要使用的是list结构：\n\n\tthis.users = Immutable.List();\n\tthis.messages = Immutable.List();\n\t\n很简单吧，接着，每当store接受到一个新的message时，我们只需要创建一个新的record并把它加入到列表中即可：\n\n\tthis.messages = this.messages.push(new Message({\n  \t\ttimestamp: payload.timestamp,\n  \t\tsender: payload.sender,\n  \t\ttext: payload.text\n\t});\n\t\n对比我们刚刚讲过的immutable-js特性，在react的组件中我们只需要直接注入`PureRenderMixin`即可高枕无忧。\n\n","slug":"[译]Reactjs性能篇","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"ciee5jad80000tcwslvz63sl2","comments":1,"layout":"post","photos":[],"link":"","content":"<p>英文有限，技术一般，海涵海涵，由于不是翻译出身，所以存在大量的瞎胡乱翻译的情况，信不过我的，请看原文～～</p>\n<p>原文地址：<a href=\"https://facebook.github.io/react/docs/advanced-performance.html\" target=\"_blank\" rel=\"external\">https://facebook.github.io/react/docs/advanced-performance.html</a></p>\n<a id=\"more\"></a>\n<hr>\n<p>###性能优化</p>\n<p>每当开发者选择将react用在真实项目中时都会先问一个问题：使用react是否会让项目速度更快，更灵活，更容易维护。此外每次状态数据发生改变时都会进行重新渲染界面的处理做法会不会造成性能瓶颈？而在react内部则是通过使用一些精妙的技巧来最小化每次造成ui更新的昂贵的dom操作从而保证性能的。</p>\n<p>####避免直接作用于DOM<br>react实现了一层虚拟dom，它用来映射浏览器的原生dom树。通过这一层虚拟的dom，可以让react避免直接操作dom，因为直接操作浏览器dom的速度要远低于操作javascript对象。每当组件的属性或者状态发生改变时，react会在内存中构造一个新的虚拟dom与原先老的进行对比，用来判断是否需要更新浏览器的dom树，这样就尽可能的优化了渲染dom的性能损耗。</p>\n<p>在此之上，react提供了组件生命周期函数，<code>shouldComponentUpdate</code>，组件在决定重新渲染（虚拟dom比对完毕生成最终的dom后）之前会调用该函数，该函数将是否重新渲染的权限交给了开发者，该函数默认直接返回<code>true</code>，表示默认直接出发dom更新：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      return true;\n}\n</code></pre><p>值得注意的是，react会非常频繁的调用该函数，所以如果你打算自己实现该函数的逻辑，请尽可能保证性能。</p>\n<p>比方说，你有一个拥有多个帖子的聊天应用，如果此时只有一个发生了变化，如果你如下实现了<code>shouldComponentUpdate</code>，react会根据情况避免重新渲染那些没有发生变化的帖子：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      // TODO: return whether or not current chat thread is different to former one.\n      // 根据实际情况判断当前帖子的状态是否和之前不同\n}\n</code></pre><p>总之，react尽可能的避免了昂贵的dom操作，并且允许开发者干涉该行为。</p>\n<p>####shouldComponentUpdate实战<br>这里举个包含子元素的组件例子，如下图：</p>\n<p><img src=\"https://facebook.github.io/react/img/docs/should-component-update.png\" alt=\"\"></p>\n<p>图中每个圆点表示一个dom节点，当某个dom节点的<code>shouldComponentUpdate</code>返回<code>false</code>时（例如c2），react就无需为其更新dom，注意，react甚至根本不会去调用c4和c5节点的<code>shouldComponentUpdate</code>函数哦～</p>\n<p>图中c1和c3的<code>shouldComponentUpdate</code>返回了<code>true</code>，因此react会检查检查其它们包含的直接子节点。最有趣的是c8节点，虽然调用它的<code>shouldComponentUpdate</code>方法返回的是<code>true</code>，但react检查后发现其dom结构并未发生改变，所以react最终是不会重新渲染其浏览器dom的。</p>\n<p>上图的情况下，react最终只会重新渲染c6，原因你应该懂的。</p>\n<p>那么我们应该如何实现<code>shouldComponentUpdate</code>函数呢？假设你有一个只包含字符串的组件，如下：</p>\n<pre><code>React.createClass({\n      propTypes: {\n        value: React.PropTypes.string.isRequired\n      },\n\n      render: function() {\n        return &lt;div&gt;{this.props.value}&lt;/div&gt;;\n      }\n});\n</code></pre><p>我们可以简单的直接实现<code>shouldComponentUpdate</code>如下：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      return this.props.value !== nextProps.value;\n}\n</code></pre><p>目前为止一切都很顺利，处理基础类型的属性和状态是很简单的，我们可以直接使用js语言提供的<code>===</code>比对来实现一个mix并注入到所有组件中，事实上，react自身已经提供了一个类似的：<a href=\"https://facebook.github.io/react/docs/pure-render-mixin.html\" target=\"_blank\" rel=\"external\">PureRenderMixin</a>。</p>\n<p>但是如果你的组件所拥有的属性或状态不是基础类型呢，而是复合类型呢？比方说是一个js对象，<code>{foo: &#39;bar&#39;}</code>：</p>\n<pre><code>React.createClass({\n      propTypes: {\n        value: React.PropTypes.object.isRequired\n      },\n\n      render: function() {\n        return &lt;div&gt;{this.props.value.foo}&lt;/div&gt;;\n      }\n});\n</code></pre><p>这种情况下我们刚才实现的那种<code>shouldComponentUpdate</code>就歇菜了：</p>\n<pre><code>// 假设 this.props.value 是 { foo: &apos;bar&apos; }\n// 假设 nextProps.value 是 { foo: &apos;bar&apos; },\n// 但是nextProps和this.props对应的引用不相同\nthis.props.value !== nextProps.value; // true\n</code></pre><p>要想修复这个问题，简单粗暴的方法是我们直接比对<code>foo</code>的值，如下：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      return this.props.value.foo !== nextProps.value.foo;\n}\n</code></pre><p>我们当然可以通过深比对来确定属性或状态是否确实发生了改变，但是这种深比对是非常昂贵的，还记得我们刚出说过<code>shouldComponentUpdate</code>函数的调用非常频繁么？更何况我们为每个model去单独实现一个匹配的深比对逻辑，对于开发人员来说也是非常痛苦的。最重要的是，如果我们不是很小心的处理对象引用关系的话，还会带来灾难。例如下面这个组件：</p>\n<pre><code>React.createClass({\n      getInitialState: function() {\n        return { value: { foo: &apos;bar&apos; } };\n      },\n\n      onClick: function() {\n        var value = this.state.value;\n        value.foo += &apos;bar&apos;; // ANTI-PATTERN!\n        this.setState({ value: value });\n      },\n\n      render: function() {\n        return (\n              &lt;div&gt;\n                &lt;InnerComponent value={this.state.value} /&gt;\n                &lt;a onClick={this.onClick}&gt;Click me&lt;/a&gt;\n              &lt;/div&gt;\n        );\n      }\n});\n</code></pre><p>起初，InnerComponent组件进行渲染，它得到的value属性为<code>{foo: &#39;bar&#39;}</code>。当用户点击链接后，父组件的状态将会更新为<code>{ value: { foo: &#39;barbar&#39; } }</code>，触发了InnerComponent组件的重新渲染，因为它得到了一个新的属性：<code>{ foo: &#39;barbar&#39; }</code>。</p>\n<p>看上去一切都挺好的，其实问题在于，父组件和子组件供用了同一个对象的引用，当用户触发click事件时，InnerComponent的prop将会发生改变，因此它的<code>shouldComponentUpdate</code>函数将会被调用，而此时如果按照我们目前的<code>shouldComponentUpdate</code>比对逻辑的话，<code>this.props.value.foo</code>和<code>nextProps.value.foo</code>是相等的，因为事实上，它们同时引用同一个对象哦～所以，我们将会看到，InnerComponent的ui并没有更新。哎～，不信的话，我贴出完整代码：</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=&quot;utf-8&quot;&gt;\n        &lt;title&gt;demo&lt;/title&gt;\n        &lt;!--引入React库--&gt;\n        &lt;script src=&quot;lib/react.min.js&quot;&gt;&lt;/script&gt;\n        &lt;!--引入JSX转换库--&gt;\n        &lt;script src=&quot;lib/JSXTransformer.js&quot;&gt;&lt;/script&gt;\n        &lt;!--组件样式--&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;!--定义容器--&gt;\n        &lt;div id=&quot;content&quot;&gt;&lt;/div&gt;\n\n        &lt;!--声明脚本类型为JSX--&gt;\n        &lt;script type=&quot;text/jsx&quot;&gt;\n\n            var InnerComponent = React.createClass({\n                shouldComponentUpdate: function(nextProps, nextState) {\n                      return this.props.value.foo !== nextProps.value.foo;\n                },\n                  render: function() {\n                    return (\n                          &lt;div&gt;\n                            {this.props.value.foo}\n                          &lt;/div&gt;\n                    );\n                  }\n            });\n\n            var OutComponent = React.createClass({\n                  getInitialState: function() {\n                    return { value: { foo: &apos;bar&apos; } };\n                  },\n\n                  onClick: function() {\n                    var value = this.state.value;\n                    value.foo += &apos;bar&apos;; // ANTI-PATTERN!\n                    this.setState({ value: value });\n                  },\n\n                  render: function() {\n                    return (\n                          &lt;div&gt;\n                            &lt;InnerComponent value={this.state.value} /&gt;\n                            &lt;a onClick={this.onClick}&gt;Click me&lt;/a&gt;\n                          &lt;/div&gt;\n                    );\n                  }\n            });\n\n            React.render(&lt;OutComponent /&gt;, document.querySelector(&quot;#content&quot;));\n\n        &lt;/script&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>####Immutable-js的救赎<br><a href=\"https://github.com/facebook/immutable-js\" target=\"_blank\" rel=\"external\">Immutable-js</a>是一个javascript集合库，作者是Lee Byron，该项目最近从fb开源。它提供了不可变集合类型：</p>\n<ul>\n<li>不可变性：一旦创建，这个集合不允许再更改。</li>\n<li>延续性：新集合可以衍生自一个已经创建过的集合，并作一些改动，此时源集合不会受到任何影响。</li>\n<li>结构共享：如果新集合衍生自一个老集合，那么新集合中与老集合相同的部份将会共享同一块内存，这样做的好处是节省内存开销，并能在创建新集合对象时减少内存拷贝的性能损耗。</li>\n</ul>\n<p>不可变性使得监控状态变化变得可行，每次状态发生变化，将总是返回一个新的对象，我们只需要检查改变前后的对象引用是否相同即可。举个例子：</p>\n<pre><code>var x = { foo: &quot;bar&quot; };\nvar y = x;\ny.foo = &quot;baz&quot;;\nx === y; // true\n</code></pre><p>尽管变量y被修改，但由于y和x的引用相同，最后的比对仍然返回true。如果上面的代码用immutable-js来实现：</p>\n<pre><code>var SomeRecord = Immutable.Record({ foo: null });\nvar x = new SomeRecord({ foo: &apos;bar&apos;  });\nvar y = x.set(&apos;foo&apos;, &apos;baz&apos;);\nx === y; // false\n</code></pre><p>看到了么，是不是很爽？</p>\n<p>另外一种监控变量的方法是设置一个标识位，但这需要开发者编写额外的代码，哎，反正活着就是麻烦。</p>\n<p>总之，不可变集合结构提供了你一个廉价且简单的监控对象改变的方法，你可以放在<code>shouldComponentUpdate</code>中。因此，如果你的model属性和状态是基于immutable-js来实现的，那么你就可以直接使用官方提供的<code>PureRenderMixin</code>哟～</p>\n<p>####Immutable-js和Flux<br>如果你恰巧使用<a href=\"https://facebook.github.io/flux/\" target=\"_blank\" rel=\"external\">Flux</a>，并且你又基于immutable-js来实现你的store，那你先看一下相关的<a href=\"https://facebook.github.io/immutable-js/docs/#/\" target=\"_blank\" rel=\"external\">api</a>吧。</p>\n<p>让我们来用个模拟应用演示一下使用一种可行的方案。首先，我们需要定义一下用到的model：</p>\n<pre><code>var User = Immutable.Record({\n      id: undefined,\n      name: undefined,\n      email: undefined\n});\n\nvar Message = Immutable.Record({\n      timestamp: new Date(),\n      sender: undefined,\n      text: &apos;&apos;\n});\n</code></pre><p>每个Record接受一个对象，分别定义了字段和默认值。我们的messages store需要使用的是list结构：</p>\n<pre><code>this.users = Immutable.List();\nthis.messages = Immutable.List();\n</code></pre><p>很简单吧，接着，每当store接受到一个新的message时，我们只需要创建一个新的record并把它加入到列表中即可：</p>\n<pre><code>this.messages = this.messages.push(new Message({\n      timestamp: payload.timestamp,\n      sender: payload.sender,\n      text: payload.text\n});\n</code></pre><p>对比我们刚刚讲过的immutable-js特性，在react的组件中我们只需要直接注入<code>PureRenderMixin</code>即可高枕无忧。</p>\n","excerpt":"<p>英文有限，技术一般，海涵海涵，由于不是翻译出身，所以存在大量的瞎胡乱翻译的情况，信不过我的，请看原文～～</p>\n<p>原文地址：<a href=\"https://facebook.github.io/react/docs/advanced-performance.html\">https://facebook.github.io/react/docs/advanced-performance.html</a></p>","more":"<hr>\n<p>###性能优化</p>\n<p>每当开发者选择将react用在真实项目中时都会先问一个问题：使用react是否会让项目速度更快，更灵活，更容易维护。此外每次状态数据发生改变时都会进行重新渲染界面的处理做法会不会造成性能瓶颈？而在react内部则是通过使用一些精妙的技巧来最小化每次造成ui更新的昂贵的dom操作从而保证性能的。</p>\n<p>####避免直接作用于DOM<br>react实现了一层虚拟dom，它用来映射浏览器的原生dom树。通过这一层虚拟的dom，可以让react避免直接操作dom，因为直接操作浏览器dom的速度要远低于操作javascript对象。每当组件的属性或者状态发生改变时，react会在内存中构造一个新的虚拟dom与原先老的进行对比，用来判断是否需要更新浏览器的dom树，这样就尽可能的优化了渲染dom的性能损耗。</p>\n<p>在此之上，react提供了组件生命周期函数，<code>shouldComponentUpdate</code>，组件在决定重新渲染（虚拟dom比对完毕生成最终的dom后）之前会调用该函数，该函数将是否重新渲染的权限交给了开发者，该函数默认直接返回<code>true</code>，表示默认直接出发dom更新：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      return true;\n}\n</code></pre><p>值得注意的是，react会非常频繁的调用该函数，所以如果你打算自己实现该函数的逻辑，请尽可能保证性能。</p>\n<p>比方说，你有一个拥有多个帖子的聊天应用，如果此时只有一个发生了变化，如果你如下实现了<code>shouldComponentUpdate</code>，react会根据情况避免重新渲染那些没有发生变化的帖子：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      // TODO: return whether or not current chat thread is different to former one.\n      // 根据实际情况判断当前帖子的状态是否和之前不同\n}\n</code></pre><p>总之，react尽可能的避免了昂贵的dom操作，并且允许开发者干涉该行为。</p>\n<p>####shouldComponentUpdate实战<br>这里举个包含子元素的组件例子，如下图：</p>\n<p><img src=\"https://facebook.github.io/react/img/docs/should-component-update.png\" alt=\"\"></p>\n<p>图中每个圆点表示一个dom节点，当某个dom节点的<code>shouldComponentUpdate</code>返回<code>false</code>时（例如c2），react就无需为其更新dom，注意，react甚至根本不会去调用c4和c5节点的<code>shouldComponentUpdate</code>函数哦～</p>\n<p>图中c1和c3的<code>shouldComponentUpdate</code>返回了<code>true</code>，因此react会检查检查其它们包含的直接子节点。最有趣的是c8节点，虽然调用它的<code>shouldComponentUpdate</code>方法返回的是<code>true</code>，但react检查后发现其dom结构并未发生改变，所以react最终是不会重新渲染其浏览器dom的。</p>\n<p>上图的情况下，react最终只会重新渲染c6，原因你应该懂的。</p>\n<p>那么我们应该如何实现<code>shouldComponentUpdate</code>函数呢？假设你有一个只包含字符串的组件，如下：</p>\n<pre><code>React.createClass({\n      propTypes: {\n        value: React.PropTypes.string.isRequired\n      },\n\n      render: function() {\n        return &lt;div&gt;{this.props.value}&lt;/div&gt;;\n      }\n});\n</code></pre><p>我们可以简单的直接实现<code>shouldComponentUpdate</code>如下：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      return this.props.value !== nextProps.value;\n}\n</code></pre><p>目前为止一切都很顺利，处理基础类型的属性和状态是很简单的，我们可以直接使用js语言提供的<code>===</code>比对来实现一个mix并注入到所有组件中，事实上，react自身已经提供了一个类似的：<a href=\"https://facebook.github.io/react/docs/pure-render-mixin.html\">PureRenderMixin</a>。</p>\n<p>但是如果你的组件所拥有的属性或状态不是基础类型呢，而是复合类型呢？比方说是一个js对象，<code>{foo: &#39;bar&#39;}</code>：</p>\n<pre><code>React.createClass({\n      propTypes: {\n        value: React.PropTypes.object.isRequired\n      },\n\n      render: function() {\n        return &lt;div&gt;{this.props.value.foo}&lt;/div&gt;;\n      }\n});\n</code></pre><p>这种情况下我们刚才实现的那种<code>shouldComponentUpdate</code>就歇菜了：</p>\n<pre><code>// 假设 this.props.value 是 { foo: &apos;bar&apos; }\n// 假设 nextProps.value 是 { foo: &apos;bar&apos; },\n// 但是nextProps和this.props对应的引用不相同\nthis.props.value !== nextProps.value; // true\n</code></pre><p>要想修复这个问题，简单粗暴的方法是我们直接比对<code>foo</code>的值，如下：</p>\n<pre><code>shouldComponentUpdate: function(nextProps, nextState) {\n      return this.props.value.foo !== nextProps.value.foo;\n}\n</code></pre><p>我们当然可以通过深比对来确定属性或状态是否确实发生了改变，但是这种深比对是非常昂贵的，还记得我们刚出说过<code>shouldComponentUpdate</code>函数的调用非常频繁么？更何况我们为每个model去单独实现一个匹配的深比对逻辑，对于开发人员来说也是非常痛苦的。最重要的是，如果我们不是很小心的处理对象引用关系的话，还会带来灾难。例如下面这个组件：</p>\n<pre><code>React.createClass({\n      getInitialState: function() {\n        return { value: { foo: &apos;bar&apos; } };\n      },\n\n      onClick: function() {\n        var value = this.state.value;\n        value.foo += &apos;bar&apos;; // ANTI-PATTERN!\n        this.setState({ value: value });\n      },\n\n      render: function() {\n        return (\n              &lt;div&gt;\n                &lt;InnerComponent value={this.state.value} /&gt;\n                &lt;a onClick={this.onClick}&gt;Click me&lt;/a&gt;\n              &lt;/div&gt;\n        );\n      }\n});\n</code></pre><p>起初，InnerComponent组件进行渲染，它得到的value属性为<code>{foo: &#39;bar&#39;}</code>。当用户点击链接后，父组件的状态将会更新为<code>{ value: { foo: &#39;barbar&#39; } }</code>，触发了InnerComponent组件的重新渲染，因为它得到了一个新的属性：<code>{ foo: &#39;barbar&#39; }</code>。</p>\n<p>看上去一切都挺好的，其实问题在于，父组件和子组件供用了同一个对象的引用，当用户触发click事件时，InnerComponent的prop将会发生改变，因此它的<code>shouldComponentUpdate</code>函数将会被调用，而此时如果按照我们目前的<code>shouldComponentUpdate</code>比对逻辑的话，<code>this.props.value.foo</code>和<code>nextProps.value.foo</code>是相等的，因为事实上，它们同时引用同一个对象哦～所以，我们将会看到，InnerComponent的ui并没有更新。哎～，不信的话，我贴出完整代码：</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=&quot;utf-8&quot;&gt;\n        &lt;title&gt;demo&lt;/title&gt;\n        &lt;!--引入React库--&gt;\n        &lt;script src=&quot;lib/react.min.js&quot;&gt;&lt;/script&gt;\n        &lt;!--引入JSX转换库--&gt;\n        &lt;script src=&quot;lib/JSXTransformer.js&quot;&gt;&lt;/script&gt;\n        &lt;!--组件样式--&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;!--定义容器--&gt;\n        &lt;div id=&quot;content&quot;&gt;&lt;/div&gt;\n\n        &lt;!--声明脚本类型为JSX--&gt;\n        &lt;script type=&quot;text/jsx&quot;&gt;\n\n            var InnerComponent = React.createClass({\n                shouldComponentUpdate: function(nextProps, nextState) {\n                      return this.props.value.foo !== nextProps.value.foo;\n                },\n                  render: function() {\n                    return (\n                          &lt;div&gt;\n                            {this.props.value.foo}\n                          &lt;/div&gt;\n                    );\n                  }\n            });\n\n            var OutComponent = React.createClass({\n                  getInitialState: function() {\n                    return { value: { foo: &apos;bar&apos; } };\n                  },\n\n                  onClick: function() {\n                    var value = this.state.value;\n                    value.foo += &apos;bar&apos;; // ANTI-PATTERN!\n                    this.setState({ value: value });\n                  },\n\n                  render: function() {\n                    return (\n                          &lt;div&gt;\n                            &lt;InnerComponent value={this.state.value} /&gt;\n                            &lt;a onClick={this.onClick}&gt;Click me&lt;/a&gt;\n                          &lt;/div&gt;\n                    );\n                  }\n            });\n\n            React.render(&lt;OutComponent /&gt;, document.querySelector(&quot;#content&quot;));\n\n        &lt;/script&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>####Immutable-js的救赎<br><a href=\"https://github.com/facebook/immutable-js\">Immutable-js</a>是一个javascript集合库，作者是Lee Byron，该项目最近从fb开源。它提供了不可变集合类型：</p>\n<ul>\n<li>不可变性：一旦创建，这个集合不允许再更改。</li>\n<li>延续性：新集合可以衍生自一个已经创建过的集合，并作一些改动，此时源集合不会受到任何影响。</li>\n<li>结构共享：如果新集合衍生自一个老集合，那么新集合中与老集合相同的部份将会共享同一块内存，这样做的好处是节省内存开销，并能在创建新集合对象时减少内存拷贝的性能损耗。</li>\n</ul>\n<p>不可变性使得监控状态变化变得可行，每次状态发生变化，将总是返回一个新的对象，我们只需要检查改变前后的对象引用是否相同即可。举个例子：</p>\n<pre><code>var x = { foo: &quot;bar&quot; };\nvar y = x;\ny.foo = &quot;baz&quot;;\nx === y; // true\n</code></pre><p>尽管变量y被修改，但由于y和x的引用相同，最后的比对仍然返回true。如果上面的代码用immutable-js来实现：</p>\n<pre><code>var SomeRecord = Immutable.Record({ foo: null });\nvar x = new SomeRecord({ foo: &apos;bar&apos;  });\nvar y = x.set(&apos;foo&apos;, &apos;baz&apos;);\nx === y; // false\n</code></pre><p>看到了么，是不是很爽？</p>\n<p>另外一种监控变量的方法是设置一个标识位，但这需要开发者编写额外的代码，哎，反正活着就是麻烦。</p>\n<p>总之，不可变集合结构提供了你一个廉价且简单的监控对象改变的方法，你可以放在<code>shouldComponentUpdate</code>中。因此，如果你的model属性和状态是基于immutable-js来实现的，那么你就可以直接使用官方提供的<code>PureRenderMixin</code>哟～</p>\n<p>####Immutable-js和Flux<br>如果你恰巧使用<a href=\"https://facebook.github.io/flux/\">Flux</a>，并且你又基于immutable-js来实现你的store，那你先看一下相关的<a href=\"https://facebook.github.io/immutable-js/docs/#/\">api</a>吧。</p>\n<p>让我们来用个模拟应用演示一下使用一种可行的方案。首先，我们需要定义一下用到的model：</p>\n<pre><code>var User = Immutable.Record({\n      id: undefined,\n      name: undefined,\n      email: undefined\n});\n\nvar Message = Immutable.Record({\n      timestamp: new Date(),\n      sender: undefined,\n      text: &apos;&apos;\n});\n</code></pre><p>每个Record接受一个对象，分别定义了字段和默认值。我们的messages store需要使用的是list结构：</p>\n<pre><code>this.users = Immutable.List();\nthis.messages = Immutable.List();\n</code></pre><p>很简单吧，接着，每当store接受到一个新的message时，我们只需要创建一个新的record并把它加入到列表中即可：</p>\n<pre><code>this.messages = this.messages.push(new Message({\n      timestamp: payload.timestamp,\n      sender: payload.sender,\n      text: payload.text\n});\n</code></pre><p>对比我们刚刚讲过的immutable-js特性，在react的组件中我们只需要直接注入<code>PureRenderMixin</code>即可高枕无忧。</p>"},{"title":"［译]全栈Redux实战","date":"2015-10-08T01:37:12.000Z","_content":"\n本文乱译自一篇英文博文（[Full-Stack Redux Tutorial](http://teropa.info/blog/2015/09/10/full-stack-redux-tutorial.html)），本人英语能力不足，技术能力有限，如有错误，多多包涵。\n\n<!--more-->\n\n#关于Redux+React+Immutable的测试先行开发综合指南\n\nRedux是最近发生在js界令人兴奋的事儿。它把众多优秀的库和框架中非常正确的特性保留了下来：简单且可预测的模型，强调函数式编程和不可变数据，基于api的轻量级实现……你还有什么理由不喜欢呢？\n\nRedux是一个非常小的代码库，掌握它所有的api并不困难，但对很多同学来讲，它要求的：创建组件（blocks），自满足的纯函数和不可变数据会带来不少别扭，那到底应该怎么办呢？\n\n这篇文章将会带你创建一个全栈的Redux和Immutable-js应用。我们将详细讲解创建该应用的Node+Redu后端和React+Redux前端的所有步骤。本指南将使用ES6,Babel,Socket.io,Webpack和Mocha。这是一个非常令人着迷的技术栈选型，你肯定不及待的想要开始了。\n\n##目录\n（不翻译）\n\n## 你需要准备什么\n\n这篇文章需要读者具备开发js应用的能力，我们讲使用Node，ES6，React，Webpack，和Babel，所以你最好能了解这些工具，这样你才不会掉队。\n\n在上面提到的工具集中，你需要安装Node和NPM，和一款你喜欢的编辑器。\n\n##应用\n\n我们将要开发一款应用，它用来为聚会，会议，集会等用户群提供实时投票功能。\n\n这个点子来自于现实中我们经常需要为电影，音乐，编程语言等进行投票。该应用将所有选项两两分组，这样用户可以根据喜好进行二选一，最终拿到最佳结果。\n\n举个例子，这里拿Danny Boyle电影做例子来发起投票：\n\n![](http://teropa.info/images/vote_logic.png)\n\n这个应用有两类独立的界面：用于投票的移动端界面，用于其它功能的浏览器界面。投票结果界面设计成有利于幻灯片或其它更大尺寸的屏幕显示，它用来展示投票的实时结果。\n\n![](http://teropa.info/images/vote_system.png)\n\n##架构\n\n该系统应该有2部分组成：浏览器端我们使用React来提供用户界面，服务端我们使用Node来处理投票逻辑。两端通信我们选择使用WebSockets。\n\n我们将使用Redux来组织前后端的应用代码。我们将使用Immutable数据结构来处理应用的state。\n\n虽然我们的前后端存在许多相似性，例如都使用Redux。但是它们之间并没有什么可复用代码。这更像一个分布式系统，靠传递消息进行通信。\n\n##服务端应用\n\n我们先来实现Node应用，这有助于我们专注于核心业务逻辑，而不是过早的被界面干扰。\n\n实现服务端应用，我们需要先了解Redux和Immutable，并且明白它们如何协作。Redux常常被用在React开发中，但它并不限制于此。我们这里就要学习让Redux如何在其它场景下使用。\n\n我推荐大家跟着我们的指导一起写出一个应用，但你也可以直接从[github](https://github.com/teropa/redux-voting-server)上下载代码。\n\n###设计应用的状态树（State Tree）\n\n设计一个Redux应用往往从思考应用的状态树数据结构开始，它是用来描述你的应用在任何时间点下状态的数据结构。\n\n任何的框架和架构都包含状态。在Ember和Backbone框架里，状态就是模型（Models）。在Anglar中，状态常常用Factories和Services来管理。而在大多数Flux实现中，常常用Stores来负责状态。那Redux又和它们有哪些不同之处呢？\n\n最大的不同之处是，在Redux中，应用的状态是全部存在一个单一的树结构中的。换句话说，应用的所有状态信息都存储在这个包含map和array的数据结构中。\n\n这么做很有意义，我们马上就会感受到。最重要的一点是，这么做迫使你将应用的行为和状态隔离开来。状态就是纯数据，它不包含任何方法或函数。\n\n这么做听起来存在局限，特别是你刚刚从面向对象思想背景下转到Redux。但这确实是一种解放，因为这么做将使你专注于数据自身。如果你花一些时间来设计你的应用状态，其它环节将水到渠成。\n\n这并不是说你总应该一上来就设计你的实体状态树然后再做其它部分。通常你最终会同时考虑应用的所有方面。然而，我发现当你想到一个点子时，在写代码前先思考在不同解决方案下状态树的结构会非常有帮助。\n\n所以，让我们先看看我们的投票应用的状态树应该是什么样的。应用的目标是可以针对多个选项进行投票，那么符合直觉的一种初始化状态应该是包含要被投票的选项集合，我们称之为条目[entries]：\n\n![](http://teropa.info/images/vote_server_tree_entries.png)\n\n当投票开始，还必须定位哪些选项是当前项。所以我们可能还需要一个vote条目，它用来存储当前投票的数据对，投票项应该是来自entries中的：\n\n![](http://teropa.info/images/vote_server_tree_pair.png)\n\n除此之外，投票的计数也应该被保存起来：\n\n![](http://teropa.info/images/vote_server_tree_tally.png)\n\n每次用户进行二选一后，未被选择的那项直接丢弃，被选择的条目重新放回entries的末尾，然后从entries头部选择下一对投票项：\n\n![](http://teropa.info/images/vote_server_tree_next.png)\n\n我们可以想象一下，这么周而复始的投票，最终将会得到一个结果，投票也就结束了：\n\n![](http://teropa.info/images/vote_server_tree_winner.png)\n\n如此设计看起来是合情合理的。针对上面的场景存在很多不同的设计，我们当前的做法也可能不是最佳的，但我们暂时就先这么定吧，足够我们进行下一步了。最重要的是我们在没有写任何代码的前提下已经从最初的点子过渡到确定了应用的具体功能。\n\n###项目安排\n\n是时候开始脏活累活了。开始之前，我们先创建一个项目目录：\n\n\tmkdir voting-server\n\tcd voting-server\n\tnpm init         #所有提示问题直接敲回车即可\n\n初始化完毕后，我们的项目目录下将会只存在一个*package.json*文件。\n\n我们将采用ES6语法来写代码。Node是从4.0.0版本后开始支持大多数ES6语法的，并且目前并不支持modules，但我们需要用到。我们将加入Babel，这样我们就能将ES6直接转换成ES5了：\n\n\tnpm install --save-dev babel\n\n我们还需要些库来用于写单元测试：\n\n\tnpm install --save-dev mocha chai\n\n[Mocha](https://mochajs.org/)是一个我们将要使用的测试框架，[Chai](http://chaijs.com/)是一个我们用来测试的断言库。\n\n我们将使用下面的mocha命令来跑测试项：\n\n\t./node_modules/mocha/bin/mocha --compilers js:babel/register --recursive\n\n这条命令告诉Mocha递归的去项目中查找并执行所有测试项，但执行前先使用Babel进行语法转换。\n\n为了使用方便，可以在我们的*package.json*中添加下面这段代码：\n\n\t\"scripts\": {\n  \t\t\"test\": \"mocha --compilers js:babel/register --recursive\"\n\t},\n\n这样以后我们跑测试就只需要执行：\n\n\tnpm run test\n\n另外，我们还可以添加*test:watch*命令，它用来监控文件变化并自动跑测试项：\n\n\t\"scripts\": {\n  \t\t\"test\": \"mocha --compilers js:babel/register --recursive\",\n  \t\t\"test:watch\": \"npm run test -- --watch\"\n\t},\n\n我们还将用到一个库，来自于facebook：[Immutable](http://facebook.github.io/immutable-js/)，它提供了许多数据结构供我们使用。下一小节我们再来讨论Immutable，但我们在这里先将它加入到我们的项目中，附带[chai-immutable](https://github.com/astorije/chai-immutable)库，它用来向Chai库加入不可变数据结构比对功能：\n\n\tnpm install --save immutable\n\tnpm install --save-dev chai-immutable\n\n我们需要在所有测试代码前先加入chai-immutable插件，所以我们来先创建一个测试辅助文件：\n\n\t//test/test_helper.js\n\n\timport chai from 'chai';\n\timport chaiImmutable from 'chai-immutable';\n\n\tchai.use(chaiImmutable);\n\n然后我们需要让Mocha在开始跑测试之前先加载这个文件，修改package.json：\n\n\t\"scripts\": {\n  \t\t\"test\": \"mocha --compilers js:babel/register --\t\trequire ./test/test_helper.js  --recursive\",\n  \t\t\"test:watch\": \"npm run test -- --watch\"\n\t},\n\n好了，准备的差不多了。\n\n###酸爽的Immutable\n\n第二个值得重视的点是，Redux架构下状态并非只是一个普通的tree，而是一棵不可变的tree。\n\n回想一下前面我们设计的状态tree，你可能会觉得可以直接在应用的代码里直接更新tree：修改映射的值，或删除数组元素等。然而，这并不是Redux允许的。\n\n一个Redux应用的状态树是不可变的数据结构。这意味着，一旦你得到了一棵状态树，它就不会在改变了。任何用户行为改变应用状态，你都会获取一棵映射应用改变后新状态的完整状态树。\n\n这说明任何连续的状态（改变前后）都被分别存储在独立的两棵树。你通过调用一个函数来从一种状态转入下一个状态。\n\n![](http://teropa.info/images/vote_state_succession.png)\n\n这么做好在哪呢？第一，用户通常想一个undo功能，当你误操作导致破坏了应用状态后，你往往想退回到应用的历史状态，而单一的状态tree让该需求变得廉价，你只需要简单保存上一个状态tree的数据即可。你也可以序列化tree并存储起来以供将来重放，这对debug很有帮助的。\n\n抛开其它的特性不谈，不可变数据至少会让你的代码变得简单，这非常重要。你可以用纯函数来进行编程：接受参数数据，返回数据，其它啥都不做。这种函数拥有可预见性，你可以多次调用它，只要参数一致，它总返回相同的结果（冪等性）。测试将变的容易，你不需要在测试前创建太多的准备，仅仅是传入参数和返回值。\n\n不可变数据结构是我们创建应用状态的基础，让我们花点时间来写一些测试项来保证它的正常工作。\n\n为了更了解不可变性，我们来看一个十分简单的数据结构：假设我们有一个计数应用，它只包含一个计数器变量，该变量会从0增加到1，增加到2，增加到3，以此类推。\n\n如果用不可变数据来设计这个计数器变量，则每当计数器自增，我们不是去改变变量本身。你可以想象成该计数器变量没有“setters”方法，你不能执行`42.setValue(43)`。\n\n每当变化发生，我们将获得一个新的变量，它的值是之前的那个变量的值加1等到的。我们可以为此写一个纯函数，它接受一个参数代表当前的状态，并返回一个值表示新的状态。记住，调用它并会修改传入参数的值。这里看一下函数实现和测试代码：\n\n\t//test/immutable_spec.js\n\n\timport {expect} from 'chai';\n\n\tdescribe('immutability', () => {\n\n  \t\tdescribe('a number', () => {\n\n    \t\tfunction increment(currentState) {\n      \t\t\treturn currentState + 1;\n    \t\t}\n\n    \t\tit('is immutable', () => {\n      \t\t\tlet state = 42;\n      \t\t\tlet nextState = increment(state);\n\n      \t\t\texpect(nextState).to.equal(43);\n      \t\t\texpect(state).to.equal(42);\n    \t\t});\n\n  \t\t});\n\t});\n\n可以看到当`increment`调用后`state`并没有被修改，这是因为`Numbers`是不可变的。\n\n我们接下来要做的是让各种数据结构都不可变，而不仅仅是一个整数。\n\n利用Immutable提供的[Lists](https://facebook.github.io/immutable-js/docs/#/Listf)，我们可以假设我们的应用拥有一个电影列表的状态，并且有一个操作用来向当前列表中添加新电影，新列表数据是添加前的列表数据和新增的电影条目合并后的结果，注意，添加前的旧列表数据并没有被修改哦：\n\n\t//test/immutable_spec.json\n\n\timport {expect} from 'chai';\n\timport {List} from 'immutable';\n\n\tdescribe('immutability', () => {\n\n  \t\t// ...\n\n  \t\tdescribe('A List', () => {\n\n    \t\tfunction addMovie(currentState, movie) {\n      \t\t\treturn currentState.push(movie);\n    \t\t}\n\n    \t\tit('is immutable', () => {\n      \t\t\tlet state = List.of('Trainspotting', '28 Days Later');\n      \t\t\tlet nextState = addMovie(state, 'Sunshine');\n\n      \t\t\texpect(nextState).to.equal(List.of(\n        \t\t\t'Trainspotting',\n        \t\t\t'28 Days Later',\n        \t\t\t'Sunshine'\n      \t\t\t));\n      \t\t\texpect(state).to.equal(List.of(\n        \t\t\t'Trainspotting',\n        \t\t\t'28 Days Later'\n      \t\t\t));\n    \t\t});\n  \t\t});\n\t});\n\n如果我们使用的是原生态js数组，那么上面的`addMovie`函数并不会保证旧的状态不会被修改。这里我们使用的是Immutable List。\n\n真实软件中，一个状态树通常是嵌套了多种数据结构的：list，map以及其它类型的集合。假设状态树是一个包含了*movies*列表的hash map，添加一个电影意味着我们需要创建一个新的map，并且在新的map的*movies*元素中添加该新增数据：\n\n\t//test/immutable_spec.json\n\n\timport {expect} from 'chai';\n\timport {List, Map} from 'immutable';\n\n\tdescribe('immutability', () => {\n\n  \t\t// ...\n\n  \t\tdescribe('a tree', () => {\n\n    \t\tfunction addMovie(currentState, movie) {\n      \t\t\treturn currentState.set(\n        \t\t\t'movies',\n       \t\t\t\t currentState.get('movies').push(movie)\n      \t\t\t);\n    \t\t}\n\n    \t\tit('is immutable', () => {\n      \t\t\tlet state = Map({\n        \t\t\tmovies: List.of('Trainspotting', '28 Days Later')\n      \t\t\t});\n      \t\t\tlet nextState = addMovie(state, 'Sunshine');\n\n      \t\t\texpect(nextState).to.equal(Map({\n        \t\t\tmovies: List.of(\n          \t\t\t\t'Trainspotting',\n          \t\t\t\t'28 Days Later',\n          \t\t\t\t'Sunshine'\n        \t\t\t)\n      \t\t\t}));\n      \t\t\texpect(state).to.equal(Map({\n       \t \t\t\tmovies: List.of(\n          \t\t\t\t'Trainspotting',\n          \t\t\t\t'28 Days Later'\n        \t\t\t)\n      \t\t\t}));\n    \t\t});\n  \t\t});\n\t});\n\n该例子和前面的那个类似，主要用来展示在嵌套结构下Immutable的行为。\n\n针对类似上面这个例子的嵌套数据结构，Immutable提供了很多辅助函数，可以帮助我们更容易的定位嵌套数据的内部属性，以达到更新对应值的目的。我们可以使用一个叫`update`的方法来修改上面的代码：\n\n\t//test/immutable_spec.json\n\n\tfunction addMovie(currentState, movie) {\n  \t\treturn currentState.update('movies', movies => movies.push(movie));\n\t}\n\n现在我们很好的了解了不可变数据，这将被用于我们的应用状态。[Immutable API](https://facebook.github.io/immutable-js/docs/#/)提供了非常多的辅助函数，我们目前只是学了点皮毛。\n\n不可变数据是Redux的核心理念，但并不是必须使用Immutable库来实现这个特性。事实上，[官方Redux文档](http://rackt.github.io/redux/)使用的是原生js对象和数组，并通过简单的扩展它们来实现的。\n\n这个教程中，我们将使用Immutable库，原因如下：\n\n- 该库将使得实现不可变数据结构变得非常简单；\n- 我个人偏爱于将尽可能的使用不可变数据，如果你的数据允许直接修改，迟早会有人踩坑；\n- 不可变数据结构更新是持续的，意味着很容易产生性能平静，特别维护是非常庞大的状态树，使用原生js对象和数组意味着要频繁的进行拷贝，很容易导致性能问题。\n\n###基于纯函数实现应用逻辑\n\n根据目前我们掌握的不可变状态树和相关操作，我们可以尝试实现投票应用的逻辑。应用的核心逻辑我们拆分成：状态树结构和生成新状态树的函数集合。\n\n####加载条目\n\n首先，之前说到，应用允许“加载”一个用来投票的条目集。我们需要一个`setEntries`函数，它用来提供应用的初始化状态：\n\n\t//test/core_spec.js\n\n\timport {List, Map} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport {setEntries} from '../src/core';\n\n\tdescribe('application logic', () => {\n\n\t  describe('setEntries', () => {\n\n\t    it('adds the entries to the state', () => {\n\t      const state = Map();\n\t      const entries = List.of('Trainspotting', '28 Days Later');\n\t      const nextState = setEntries(state, entries);\n\t      expect(nextState).to.equal(Map({\n\t        entries: List.of('Trainspotting', '28 Days Later')\n\t      }));\n\t    });\n\t  });\n\t});\n\n我们目前`setEntries`函数的第一版非常简单：在状态map中创建一个`entries`键，并设置给定的条目List。\n\n\t//src/core.js\n\n\texport function setEntries(state, entries) {\n\t\treturn state.set('entries', entries);\n\t}\n\n为了方便起见，我们允许函数第二个参数接受一个原生js数组（或支持iterable的类型），但在状态树中它应该是一个Immutable List：\n\n\t//test/core_spec.js\n\n\tit('converts to immutable', () => {\n\t  const state = Map();\n\t  const entries = ['Trainspotting', '28 Days Later'];\n\t  const nextState = setEntries(state, entries);\n\t  expect(nextState).to.equal(Map({\n\t    entries: List.of('Trainspotting', '28 Days Later')\n\t  }));\n\t});\n\n为了达到要求，我们需要修改一下代码：\n\n\t//src/core.js\n\n\timport {List} from 'immutable';\n\n\texport function setEntries(state, entries) {\n\t  return state.set('entries', List(entries));\n\t}\n\n####开始投票\n\n当state加载了条目集合后，我们可以调用一个`next`函数来开始投票。这表示，我们到了之前设计的状态树的第二阶段。\n\n`next`函数需要在状态树创建中一个投票map，该map有拥有一个`pair`键，值为投票条目中的前两个元素。\n这两个元素一旦确定，就要从之前的条目列表中清除：\n\n\t//test/core_spec.js\n\n\timport {List, Map} from 'immutable';\n\timport {expect} from 'chai';\n\timport {setEntries, next} from '../src/core';\n\n\tdescribe('application logic', () => {\n\n\t  // ..\n\n\t  describe('next', () => {\n\n\t    it('takes the next two entries under vote', () => {\n\t      const state = Map({\n\t        entries: List.of('Trainspotting', '28 Days Later', 'Sunshine')\n\t      });\n\t      const nextState = next(state);\n\t      expect(nextState).to.equal(Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later')\n\t        }),\n\t        entries: List.of('Sunshine')\n\t      }));\n\t    });\n\t  });\n\t});\n\n`next`函数实现如下：\n\n\t//src/core.js\n\n\timport {List, Map} from 'immutable';\n\n\t// ...\n\n\texport function next(state) {\n\t  const entries = state.get('entries');\n\t  return state.merge({\n\t    vote: Map({pair: entries.take(2)}),\n\t    entries: entries.skip(2)\n\t  });\n\t}\n\n####投票\n\n当用户产生投票行为后，每当用户给某个条目投了一票后，`vote`将会为这个条目添加`tally`信息，如果对应的\n条目信息已存在，则需要则增：\n\n\t//test/core_spec.js\n\n\timport {List, Map} from 'immutable';\n\timport {expect} from 'chai';\n\timport {setEntries, next, vote} from '../src/core';\n\n\tdescribe('application logic', () => {\n\n\t  // ...\n\n\t  describe('vote', () => {\n\n\t    it('creates a tally for the voted entry', () => {\n\t      const state = Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later')\n\t        }),\n\t        entries: List()\n\t      });\n\t      const nextState = vote(state, 'Trainspotting');\n\t      expect(nextState).to.equal(Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({\n\t            'Trainspotting': 1\n\t          })\n\t        }),\n\t        entries: List()\n\t      }));\n\t    });\n\n\t    it('adds to existing tally for the voted entry', () => {\n\t      const state = Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({\n\t            'Trainspotting': 3,\n\t            '28 Days Later': 2\n\t          })\n\t        }),\n\t        entries: List()\n\t      });\n\t      const nextState = vote(state, 'Trainspotting');\n\t      expect(nextState).to.equal(Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({\n\t            'Trainspotting': 4,\n\t            '28 Days Later': 2\n\t          })\n\t        }),\n\t        entries: List()\n\t      }));\n\t    });\n\t  });\n\t});\n\n为了让上面的测试项通过，我们可以如下实现`vote`函数：\n\n\t//src/core.js\n\n\texport function vote(state, entry) {\n\t  return state.updateIn(\n\t    ['vote', 'tally', entry],\n\t    0,\n\t    tally => tally + 1\n\t  );\n\t}\n\n[updateIn](https://facebook.github.io/immutable-js/docs/#/Map/updateIn)让我们更容易完成目标。\n它接受的第一个参数是个表达式，含义是“定位到嵌套数据结构的指定位置，路径为：['vote', 'tally', 'Trainspotting']”，\n并且执行后面逻辑：如果路径指定的位置不存在，则创建新的映射对，并初始化为0，否则对应值加1。\n\n可能对你来说上面的语法太过于晦涩，但一旦你掌握了它，你将会发现用起来非常的酸爽，所以花一些时间学习并\n适应它是非常值得的。\n\n####继续投票\n\n每次完成一次二选一投票，用户将进入到第二轮投票，每次得票最高的选项将被保存并添加回条目集合。我们需要添加\n这个逻辑到`next`函数中：\n\n\t//test/core_spec.js\n\n\tdescribe('next', () => {\n\n\t  // ...\n\n\t  it('puts winner of current vote back to entries', () => {\n\t    const state = Map({\n\t      vote: Map({\n\t        pair: List.of('Trainspotting', '28 Days Later'),\n\t        tally: Map({\n\t          'Trainspotting': 4,\n\t          '28 Days Later': 2\n\t        })\n\t      }),\n\t      entries: List.of('Sunshine', 'Millions', '127 Hours')\n\t    });\n\t    const nextState = next(state);\n\t    expect(nextState).to.equal(Map({\n\t      vote: Map({\n\t        pair: List.of('Sunshine', 'Millions')\n\t      }),\n\t      entries: List.of('127 Hours', 'Trainspotting')\n\t    }));\n\t  });\n\n\t  it('puts both from tied vote back to entries', () => {\n\t    const state = Map({\n\t      vote: Map({\n\t        pair: List.of('Trainspotting', '28 Days Later'),\n\t        tally: Map({\n\t          'Trainspotting': 3,\n\t          '28 Days Later': 3\n\t        })\n\t      }),\n\t      entries: List.of('Sunshine', 'Millions', '127 Hours')\n\t    });\n\t    const nextState = next(state);\n\t    expect(nextState).to.equal(Map({\n\t      vote: Map({\n\t        pair: List.of('Sunshine', 'Millions')\n\t      }),\n\t      entries: List.of('127 Hours', 'Trainspotting', '28 Days Later')\n\t    }));\n\t  });\n\t});\n\n我们需要一个`getWinners`函数来帮我们选择谁是赢家：\n\n\t//src/core.js\n\n\tfunction getWinners(vote) {\n\t  if (!vote) return [];\n\t  const [a, b] = vote.get('pair');\n\t  const aVotes = vote.getIn(['tally', a], 0);\n\t  const bVotes = vote.getIn(['tally', b], 0);\n\t  if      (aVotes > bVotes)  return [a];\n\t  else if (aVotes < bVotes)  return [b];\n\t  else                       return [a, b];\n\t}\n\n\texport function next(state) {\n\t  const entries = state.get('entries')\n\t                       .concat(getWinners(state.get('vote')));\n\t  return state.merge({\n\t    vote: Map({pair: entries.take(2)}),\n\t    entries: entries.skip(2)\n\t  });\n\t}\n\n####投票结束\n\n当投票项只剩一个时，投票结束：\n\n\t//test/core_spec.js\n\n\tdescribe('next', () => {\n\n\t  // ...\n\n\t  it('marks winner when just one entry left', () => {\n\t    const state = Map({\n\t      vote: Map({\n\t        pair: List.of('Trainspotting', '28 Days Later'),\n\t        tally: Map({\n\t          'Trainspotting': 4,\n\t          '28 Days Later': 2\n\t        })\n\t      }),\n\t      entries: List()\n\t    });\n\t    const nextState = next(state);\n\t    expect(nextState).to.equal(Map({\n\t      winner: 'Trainspotting'\n\t    }));\n\t  });\n\t});\n\n我们需要在`next`函数中增加一个条件分支，用来匹配上面的逻辑：\n\n\t//src/core.js\n\n\texport function next(state) {\n\t  const entries = state.get('entries')\n\t                       .concat(getWinners(state.get('vote')));\n\t  if (entries.size === 1) {\n\t    return state.remove('vote')\n\t                .remove('entries')\n\t                .set('winner', entries.first());\n\t  } else {\n\t    return state.merge({\n\t      vote: Map({pair: entries.take(2)}),\n\t      entries: entries.skip(2)\n\t    });\n\t  }\n\t}\n\n我们可以直接返回`Map({winner: entries.first()})`，但我们还是基于旧的状态数据进行一步一步的\n操作最终得到结果，这么做是为将来做打算。因为应用将来可能还会有很多其它状态数据在Map中，这是一个写测试项的好习惯。\n所以我们以后要记住，不要重新创建一个状态数据，而是从旧的状态数据中生成新的状态实例。\n\n到此为止我们已经有了一套可以接受的应用核心逻辑实现，表现形式为几个独立的函数。我们也有针对这些函数的\n测试代码，这些测试项很容易写：No setup, no mocks, no stubs。这就是纯函数的魅力，我们只需要调用它们，\n并检查返回值就行了。\n\n提醒一下，我们目前还没有安装redux哦，我们就已经可以专注于应用自身的逻辑本身进行实现，而不被所谓的框架\n所干扰。这真的很不错，对吧？\n\n###初识Actions和Reducers\n\n我们有了应用的核心函数，但在Redux中我们不应该直接调用函数。在这些函数和应用之间还存在这一个中间层：Actions。\n\nAction是一个描述应用状态变化发生的简单数据结构。按照约定，每个action都包含一个`type`属性，\n该属性用于描述操作类型。action通常还包含其它属性，下面是一个简单的action例子，该action用来匹配\n前面我们写的业务操作：\n\n\t{type: 'SET_ENTRIES', entries: ['Trainspotting', '28 Days Later']}\n\n\t{type: 'NEXT'}\n\n\t{type: 'VOTE', entry: 'Trainspotting'}\n\nactions的描述就这些，但我们还需要一种方式用来把它绑定到我们实际的核心函数上。举个例子：\n\n\t// 定义一个action\n\tlet voteAction = {type: 'VOTE', entry: 'Trainspotting'}\n\t// 该action应该触发下面的逻辑\n\treturn vote(state, voteAction.entry);\n\n我们接下来要用到的是一个普通函数，它用来根据action和当前state来调用指定的核心函数，我们称这种函数叫：\nreducer：\n\n\t//src/reducer.js\n\n\texport default function reducer(state, action) {\n\t  // Figure out which function to call and call it\n\t}\n\n我们应该测试这个reducer是否可以正确匹配我们之前的三个actions：\n\n\t//test/reducer_spec.js\n\n\timport {Map, fromJS} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport reducer from '../src/reducer';\n\n\tdescribe('reducer', () => {\n\n\t  it('handles SET_ENTRIES', () => {\n\t    const initialState = Map();\n\t    const action = {type: 'SET_ENTRIES', entries: ['Trainspotting']};\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      entries: ['Trainspotting']\n\t    }));\n\t  });\n\n\t  it('handles NEXT', () => {\n\t    const initialState = fromJS({\n\t      entries: ['Trainspotting', '28 Days Later']\n\t    });\n\t    const action = {type: 'NEXT'};\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later']\n\t      },\n\t      entries: []\n\t    }));\n\t  });\n\n\t  it('handles VOTE', () => {\n\t    const initialState = fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later']\n\t      },\n\t      entries: []\n\t    });\n\t    const action = {type: 'VOTE', entry: 'Trainspotting'};\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      },\n\t      entries: []\n\t    }));\n\t  });\n\t});\n\n我们的reducer将根据action的type来选择对应的核心函数，它同时也应该知道如何使用action的额外属性：\n\n\t//src/reducer.js\n\n\timport {setEntries, next, vote} from './core';\n\n\texport default function reducer(state, action) {\n\t  switch (action.type) {\n\t  case 'SET_ENTRIES':\n\t    return setEntries(state, action.entries);\n\t  case 'NEXT':\n\t    return next(state);\n\t  case 'VOTE':\n\t    return vote(state, action.entry)\n\t  }\n\t  return state;\n\t}\n\n注意，如果reducer没有匹配到action，则应该返回当前的state。\n\nreducers还有一个需要特别注意的地方，那就是当传递一个未定义的state参数时，reducers应该知道如何\n初始化state为有意义的值。我们的场景中，初始值为Map，因此如果传给reducer一个`undefined`state的话，\nreducers将使用一个空的Map来代替：\n\n\t//test/reducer_spec.js\n\n\tdescribe('reducer', () => {\n\n\t  // ...\n\n\t  it('has an initial state', () => {\n\t    const action = {type: 'SET_ENTRIES', entries: ['Trainspotting']};\n\t    const nextState = reducer(undefined, action);\n\t    expect(nextState).to.equal(fromJS({\n\t      entries: ['Trainspotting']\n\t    }));\n\t  });\n\t});\n\n之前在我们的`cores.js`文件中，我们定义了初始值：\n\n\t//src/core.js\n\n\texport const INITIAL_STATE = Map();\n\n所以在reducer中我们可以直接导入它：\n\n\t//src/reducer.js\n\n\timport {setEntries, next, vote, INITIAL_STATE} from './core';\n\n\texport default function reducer(state = INITIAL_STATE, action) {\n\t  switch (action.type) {\n\t  case 'SET_ENTRIES':\n\t    return setEntries(state, action.entries);\n\t  case 'NEXT':\n\t    return next(state);\n\t  case 'VOTE':\n\t    return vote(state, action.entry)\n\t  }\n\t  return state;\n\t}\n\n事实上，提供一个action集合，你可以将它们分解并作用在当前状态上，这也是为什么称它们为reducer的原因：\n它完全适配reduce方法：\n\n\t//test/reducer_spec.js\n\n\tit('can be used with reduce', () => {\n\t  const actions = [\n\t    {type: 'SET_ENTRIES', entries: ['Trainspotting', '28 Days Later']},\n\t    {type: 'NEXT'},\n\t    {type: 'VOTE', entry: 'Trainspotting'},\n\t    {type: 'VOTE', entry: '28 Days Later'},\n\t    {type: 'VOTE', entry: 'Trainspotting'},\n\t    {type: 'NEXT'}\n\t  ];\n\t  const finalState = actions.reduce(reducer, Map());\n\n\t  expect(finalState).to.equal(fromJS({\n\t    winner: 'Trainspotting'\n\t  }));\n\t});\n\n相比直接调用核心业务函数，这种批处理或称之为重放一个action集合的能力主要依赖于状态转换的action/reducer模型。\n举个例子，你可以把actions序列化成json，并轻松的将它发送给Web Worker去执行你的reducer逻辑。或者\n直接通过网络发送到其它地方供日后执行！\n\n注意我们这里使用的是普通js对象作为actions，而并非不可变数据类型。这是Redux提倡我们的做法。\n\n###尝试Reducer协作\n\n目前我们的核心函数都是接受整个state并返回更新后的整个state。\n\n这么做在大型应用中可能并不太明智。如果你的应用所有操作都要求必须接受完整的state，那么这个项目维护起来就是灾难。\n日后如果你想进行state结构的调整，你将会付出惨痛的代价。\n\n其实有更好的做法，你只需要保证组件操作尽可能小的state片段即可。我们这里提到的就是模块化思想：\n提供给模块仅它需要的数据，不多不少。\n\n我们的应用很小，所以这并不是太大的问题，但我们还是选择改善这一点：没有必要给`vote`函数传递整个state，它只需要`vote`\n部分。让我们修改一下对应的测试代码：\n\n\t//test/core_spec.js\n\n\tdescribe('vote', () => {\n\n\t  it('creates a tally for the voted entry', () => {\n\t    const state = Map({\n\t      pair: List.of('Trainspotting', '28 Days Later')\n\t    });\n\t    const nextState = vote(state, 'Trainspotting')\n\t    expect(nextState).to.equal(Map({\n\t      pair: List.of('Trainspotting', '28 Days Later'),\n\t      tally: Map({\n\t        'Trainspotting': 1\n\t      })\n\t    }));\n\t  });\n\n\t  it('adds to existing tally for the voted entry', () => {\n\t    const state = Map({\n\t      pair: List.of('Trainspotting', '28 Days Later'),\n\t      tally: Map({\n\t        'Trainspotting': 3,\n\t        '28 Days Later': 2\n\t      })\n\t    });\n\t    const nextState = vote(state, 'Trainspotting');\n\t    expect(nextState).to.equal(Map({\n\t      pair: List.of('Trainspotting', '28 Days Later'),\n\t      tally: Map({\n\t        'Trainspotting': 4,\n\t        '28 Days Later': 2\n\t      })\n\t    }));\n\t  });\n\t});\n\n看，测试代码更加简单了。\n\n`vote`函数的实现也需要更新：\n\n\t//src/core.js\n\n\texport function vote(voteState, entry) {\n\t  return voteState.updateIn(\n\t    ['tally', entry],\n\t    0,\n\t    tally => tally + 1\n\t  );\n\t}\n\n最后我们还需要修改`reducer`，只传递需要的state给`vote`函数：\n\n\t//src/reducer.js\n\n\texport default function reducer(state = INITIAL_STATE, action) {\n\t  switch (action.type) {\n\t  case 'SET_ENTRIES':\n\t    return setEntries(state, action.entries);\n\t  case 'NEXT':\n\t    return next(state);\n\t  case 'VOTE':\n\t    return state.update('vote',\n\t                        voteState => vote(voteState, action.entry));\n\t  }\n\t  return state;\n\t}\n\n这个做法在大型项目中非常重要：根reducer只传递部分state给下一级reducer。我们将定位合适的state片段的工作\n从对应的更新操作中分离出来。\n\n[Redux的reducers文档](http://rackt.github.io/redux/docs/basics/Reducers.html)针对这一细节\n介绍了更多内容，并描述了一些辅助函数的用法，可以在更多长场景中有效的使用。\n\n###初识Redux Store\n\n现在我们可以开始了解如何将上面介绍的内容使用在Redux中了。\n\n如你所见，如果你有一个actions集合，你可以调用`reduce`，获得最终的应用状态。当然，通常情况下不会如此，actions\n将会在不同的时间发生：用户操作，远程调用，超时触发器等。\n\n针对这些情况，我们可以使用Redux Store。从名字可以看出它用来存储应用的状态。\n\nRedux Store通常会由一个reducer函数初始化，如我们之前实现的：\n\n\timport {createStore} from 'redux';\n\n\tconst store = createStore(reducer);\n\n接下来你就可以向这个Store指派actions了。Store内部将会使用你实现的reducer来处理action，并负责传递给\nreducer应用的state，最后负责存储reducer返回的新state：\n\n\tstore.dispatch({type: 'NEXT'});\n\n任何时刻你都可以通过下面的方法获取当前的state：\n\n\tstore.getState();\n\n我们将会创建一个`store.js`用来初始化和导出一个Redux Store对象。让我们先写测试代码吧：\n\n\t//test/store_spec.js\n\n\timport {Map, fromJS} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport makeStore from '../src/store';\n\n\tdescribe('store', () => {\n\n\t  it('is a Redux store configured with the correct reducer', () => {\n\t    const store = makeStore();\n\t    expect(store.getState()).to.equal(Map());\n\n\t    store.dispatch({\n\t      type: 'SET_ENTRIES',\n\t      entries: ['Trainspotting', '28 Days Later']\n\t    });\n\t    expect(store.getState()).to.equal(fromJS({\n\t      entries: ['Trainspotting', '28 Days Later']\n\t    }));\n\t  });\n\t});\n\n在创建Store之前，我们先在项目中加入Redux库：\n\n\tnpm install --save redux\n\n然后我们新建`store.js`文件，如下：\n\n\t//src/store.js\n\n\timport {createStore} from 'redux';\n\timport reducer from './reducer';\n\n\texport default function makeStore() {\n\t  return createStore(reducer);\n\t}\n\nRedux Store负责将应用的所有组件关联起来：它持有应用的当前状态，并负责指派actions，且负责调用包含了\n业务逻辑的reducer。\n\n应用的业务代码和Redux的整合方式非常引人注目，因为我们只有一个普通的reducer函数，这是唯一需要告诉Redux\n的事儿。其它部分全部都是我们自己的，没有框架入侵的，高便携的纯函数代码！\n\n现在我们创建一个应用的入口文件`index.js`：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\n\texport const store = makeStore();\n\n现在我们可以开启一个[Node REPL](http://segmentfault.com/a/1190000002673137)（例如babel-node）,\n载入`index.js`文件来测试执行了。\n\n###配置Socket.io服务\n\n我们的应用服务端用来为一个提供投票和显示结果浏览器端提供服务的，为了这个目的，我们需要考虑两端通信的方式。\n\n这个应用需要实时通信，这确保我们的投票者可以实时查看到所有人的投票信息。为此，我们选择使用WebSockets作为\n通信方式。因此，我们选择[Socket.io](http://socket.io/)库作为跨终端的websocket抽象实现层，它在客户端\n不支持websocket的情况下提供了多种备选方案。\n\n让我们在项目中加入Socket.io：\n\n\tnpm install --save socket.io\n\n现在，让我新建一个`server.js`文件：\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport default function startServer() {\n\tconst io = new Server().attach(8090);\n\t}\n\n这里我们创建了一个Socket.io 服务，绑定8090端口。端口号是我随意选的，你可以更改，但后面客户端连接时\n要注意匹配。\n\n现在我们可以在`index.js`中调用这个函数：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\timport startServer from './src/server';\n\n\texport const store = makeStore();\n\tstartServer();\n\n我们现在可以在`package.json`中添加`start`指令来方便启动应用：\n\n\t//package.json\n\t\"scripts\": {\n\t\t\"start\": \"babel-node index.js\",\n\t\t\"test\": \"mocha --compilers js:babel/register  --require ./test/test_helper.js  --recursive\",\n\t\t\"test:watch\": \"npm run test --watch\"\n\t},\n\n这样我们就可以直接执行下面命令来开启应用：\n\n\tnpm run start\n\n###用Redux监听器传播State\n\n我们现在拥有了一个Socket.io服务，也建立了Redux状态容器，但它们并没有整合在一起，这就是我们接下来要做的事儿。\n\n我们的服务端需要让客户端知道当前的应用状态（例如：“正在投票的项目是什么？”，“当前的票数是什么？”，\n“已经出来结果了吗？”）。这些都可以通过每当变化发生时[触发Socket.io事件](http://socket.io/docs/server-api/#server#emit)来实现。\n\n我们如何得知什么时候发生变化？Redux对此提供了方案：你可以订阅Redux Store。这样每当store指派了action之后，在可能发生变化前\n会调用你提供的指定回调函数。\n\n我们要修改一下`startServer`实现，我们先来调整一下index.js：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\timport {startServer} from './src/server';\n\n\texport const store = makeStore();\n\tstartServer(store);\n\n接下来我们只需监听store的状态，并把它序列化后用socket.io事件传播给所有处于连接状态的客户端。\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport function startServer(store) {\n\t  const io = new Server().attach(8090);\n\n\t  store.subscribe(\n\t    () => io.emit('state', store.getState().toJS())\n\t  );\n\t}\n\n目前我们的做法是一旦状态有改变，就发送整个state给所有客户端，很容易想到这非常不友好，产生大量流量\n损耗，更好的做法是只传递改变的state片段，但我们为了简单，在这个例子中就先这么实现吧。\n\n除了状态发生变化时发送状态数据外，每当新客户端连接服务器端时也应该直接发送当前的状态给该客户端。\n\n我们可以通过监听Socket.io的`connection`事件来实现上述需求：\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport function startServer(store) {\n\t  const io = new Server().attach(8090);\n\n\t  store.subscribe(\n\t    () => io.emit('state', store.getState().toJS())\n\t  );\n\n\t  io.on('connection', (socket) => {\n\t    socket.emit('state', store.getState().toJS());\n\t  });\n\t}\n\n###接受远程调用Redux Actions\n\n除了将应用状态同步给客户端外，我们还需要接受来自客户端的更新操作：投票者需要发起投票，投票组织者需要\n发起下一轮投票的请求。\n\n我们的解决方案非常简单。我们只需要让客户端发布“action”事件即可，然后我们直接将事件发送给Redux Store：\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport function startServer(store) {\n\t  const io = new Server().attach(8090);\n\n\t  store.subscribe(\n\t    () => io.emit('state', store.getState().toJS())\n\t  );\n\n\t  io.on('connection', (socket) => {\n\t    socket.emit('state', store.getState().toJS());\n\t    socket.on('action', store.dispatch.bind(store));\n\t  });\n\t}\n\n这样我们就完成了远程调用actions。Redux架构让我们的项目更加简单：actions仅仅是js对象，可以很容易用于\n网络传输，我们现在实现了一个支持多人投票的服务端系统，很有成就感吧。\n\n现在我们的服务端操作流程如下：\n\n1. 客户端发送一个action给服务端；\n2. 服务端交给Redux Store处理action；\n3. Store调用reducer，reducer执行对应的应用逻辑；\n4. Store根据reducer的返回结果来更新状态；\n5. Store触发服务端监听的回调函数；\n6. 服务端触发“state”事件；\n7. 所有连接的客户端接受到新的状态。\n\n在结束服务端开发之前，我们载入一些测试数据来感受一下。我们可以添加`entries.json`文件：\n\n\t//entries.json\n\n\t[\n\t  \"Shallow Grave\",\n\t  \"Trainspotting\",\n\t  \"A Life Less Ordinary\",\n\t  \"The Beach\",\n\t  \"28 Days Later\",\n\t  \"Millions\",\n\t  \"Sunshine\",\n\t  \"Slumdog Millionaire\",\n\t  \"127 Hours\",\n\t  \"Trance\",\n\t  \"Steve Jobs\"\n\t]\n\n我们在`index.json`中加载它然后发起`next`action来开启投票：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\timport {startServer} from './src/server';\n\n\texport const store = makeStore();\n\tstartServer(store);\n\n\tstore.dispatch({\n\t  type: 'SET_ENTRIES',\n\t  entries: require('./entries.json')\n\t});\n\tstore.dispatch({type: 'NEXT'});\n\n那么接下来我们就来看看如何实现客户端。\n\n##客户端应用\n\n本教程剩余的部分就是写一个React应用，用来连接服务端，并提供投票给使用者。\n\n在客户端我们依然使用Redux。这是更常见的搭配：用于React应用的底层引擎。我们已经了解到Redux如何使用。\n现在我们将学习它是如何结合并影响React应用的。\n\n我推荐大家跟随本教程的步骤完成应用，但你也可以从[github](https://github.com/teropa/redux-voting-client)上获取源码。\n\n###客户端项目创建\n\n第一件事儿我们当然是创建一个新的NPM项目，如下：\n\n\tmkdir voting-client\n\tcd voting-client\n\tnpm init            # Just hit enter for each question\n\n我们的应用需要一个html主页，我们放在`dist/index.html`：\n\n\t//dist/index.html\n\n\t<!DOCTYPE html>\n\t<html>\n\t<body>\n\t  <div id=\"app\"></div>\n\t  <script src=\"bundle.js\"></script>\n\t</body>\n\t</html>\n\n这个页面包含一个id为app的`<div>`，我们将在其中插入我们的应用。在同级目录下还需要一个`bundle.js`文件。\n\n我们为应用新建第一个js文件，它是系统的入口文件。目前我们先简单的添加一行日志代码：\n\n\t//src/index.js\n\tconsole.log('I am alive!');\n\n为了给我们客户端开发减负，我们将使用[Webpack](http://webpack.github.io/)，让我们加入到项目中：\n\n\tnpm install --save-dev webpack webpack-dev-server\n\n接下来，我们在项目根目录新建一个Webpack配置文件：\n\n\t//webpack.config.js\n\n\tmodule.exports = {\n\t  entry: [\n\t    './src/index.js'\n\t  ],\n\t  output: {\n\t    path: __dirname + '/dist',\n\t    publicPath: '/',\n\t    filename: 'bundle.js'\n\t  },\n\t  devServer: {\n\t    contentBase: './dist'\n\t  }\n\t};\n\n配置表明将找到我们的`index.js`入口，并编译到`dist/bundle.js`中。同时把`dist`目录当作开发服务器根目录。\n\n你现在可以执行Webpack来生成`bundle.js`：\n\n\twebpack\n\n你也可以开启一个开发服务器，访问localhost:8080来测试页面效果：\n\n\twebpack-dev-server\n\n由于我们将使用ES6语法和React的[JSX语法](https://facebook.github.io/jsx/)，我们需要一些工具。\nBabel是一个非常合适的选择，我们需要Babel库：\n\n\tnpm install --save-dev babel-core babel-loader\n\n我们可以在Webpack配置文件中添加一些配置，这样webpack将会对`.jsx`和`.js`文件使用Babel进行处理：\n\n\t//webpack.config.js\n\n\tmodule.exports = {\n\t\tentry: [\n\t\t\t'./src/index.js'\n\t\t],\n\t\tmodule: {\n\t\t\tloaders: [{\n\t\t\t\ttest: /\\.jsx?$/,\n\t\t\t\texclude: /node_modules/,\n\t\t\t\tloader: 'babel'\n\t\t\t}]\n\t\t},\n\t\tresolve: {\n\t\t\textensions: ['', '.js', '.jsx']\n\t\t},\n\t\toutput: {\n\t\t\tpath: __dirname + '/dist',\n\t\t\tpublicPath: '/',\n\t\t\tfilename: 'bundle.js'\n\t\t},\n\t\tdevServer: {\n\t\t\tcontentBase: './dist'\n\t\t}\n\t};\n\n\n###单元测试支持\n\n我们也将会为客户端代码编写一些单元测试。我们使用与服务端相同的测试套件：\n\n\tnpm install --save-dev mocha chai\n\n我们也将会测试我们的React组件，这就要求需要一个DOM库。我们可能需要像[Karma](http://karma-runner.github.io/0.13/index.html)\n库一样的功能来进行真实web浏览器测试。但我们这里准备使用一个node端纯js的dom库：\n\n\tnpm install --save-dev jsdom@3\n\n在用于react之前我们需要一些jsdom的预备代码。我们需要创建通常在浏览器端被提供的`document`和`window`对象。\n并且将它们声明为全局对象，这样才能被React使用。我们可以创建一个测试辅助文件做这些工作：\n\n\t//test/test_helper.js\n\n\timport jsdom from 'jsdom';\n\n\tconst doc = jsdom.jsdom('<!doctype html><html><body></body></html>');\n\tconst win = doc.defaultView;\n\n\tglobal.document = doc;\n\tglobal.window = win;\n\n此外，我们还需要将jsdom提供的`window`对象的所有属性导入到Node.js的全局变量中，这样使用这些属性时\n就不需要`window.`前缀，这才满足在浏览器环境下的用法：\n\n\t//test/test_helper.js\n\n\timport jsdom from 'jsdom';\n\n\tconst doc = jsdom.jsdom('<!doctype html><html><body></body></html>');\n\tconst win = doc.defaultView;\n\n\tglobal.document = doc;\n\tglobal.window = win;\n\n\tObject.keys(window).forEach((key) => {\n\t  if (!(key in global)) {\n\t    global[key] = window[key];\n\t  }\n\t});\n\n我们还需要使用Immutable集合，所以我们也需要参照后段配置添加相应的库：\n\n\tnpm install --save immutable\n\tnpm install --save-dev chai-immutable\n\n现在我们再次修改辅助文件：\n\n\t//test/test_helper.js\n\n\timport jsdom from 'jsdom';\n\timport chai from 'chai';\n\timport chaiImmutable from 'chai-immutable';\n\n\tconst doc = jsdom.jsdom('<!doctype html><html><body></body></html>');\n\tconst win = doc.defaultView;\n\n\tglobal.document = doc;\n\tglobal.window = win;\n\n\tObject.keys(window).forEach((key) => {\n\t  if (!(key in global)) {\n\t    global[key] = window[key];\n\t  }\n\t});\n\n\tchai.use(chaiImmutable);\n\n最后一步是在`package.json`中添加指令：\n\n\t//package.json\n\n\t\"scripts\": {\n\t  \"test\": \"mocha --compilers js:babel-core/register --require ./test/test_helper.js 'test/**/*.@(js|jsx)'\"\n\t},\n\n这几乎和我们在后端做的一样，只有两个地方不同：\n\n- Babel的编译器名称：在该项目中我们使用`babel-core`代替`babel`\n- 测试文件设置：服务端我们使用`--recursive`，但这么设置无法匹配`.jsx`文件，所以我们需要使用\n[glob](https://github.com/isaacs/node-glob)\n\n为了实现当代码发生修改后自动进行测试，我们依然添加`test:watch`指令：\n\n\t//package.json\n\n\t\"scripts\": {\n\t  \"test\": \"mocha --compilers js:babel-core/register --require ./test/test_helper.js 'test/**/*.@(js|jsx)'\",\n\t  \"test:watch\": \"npm run test -- --watch\"\n\t},\n\n###React和react-hot-loader\n\n最后我们来聊聊React！\n\n使用React+Redux+Immutable来开发应用真正酷毙的地方在于：我们可以用纯组件（有时候也称为蠢组件）思想实现\n任何东西。这个概念与纯函数很类似，有如下一些规则：\n\n1. 一个纯组件利用props接受所有它需要的数据，类似一个函数的入参，除此之外它不会被任何其它因素影响；\n2. 一个纯组件通常没有内部状态。它用来渲染的数据完全来自于输入props，使用相同的props来渲染相同的纯组件多次，\n将得到相同的UI。不存在隐藏的内部状态导致渲染不同。\n\n这就带来了[一个和使用纯函数一样的效果](https://www.youtube.com/watch?v=1uRC3hmKQnM&feature=youtu.be&t=13m10s)：\n我们可以根据输入来预测一个组件的渲染，我们不需要知道组件的其它信息。这也使得我们的界面测试变得很简单，\n与我们测试纯应用逻辑一样简单。\n\n如果组件不包含状态，那么状态放在哪？当然在不可变的Store中啊！我们已经见识过它是怎么运作的了，其\n最大的特点就是从界面代码中分离出状态。\n\n在此之前，我们还是先给项目添加React：\n\n\tnpm install --save react\n\n我们同样需要[react-hot-loader](https://github.com/gaearon/react-hot-loader)。它让我们的开发\n变得非常快，因为它提供了我们在不丢失当前状态的情况下重载代码的能力：\n\n\tnpm install --save-dev react-hot-loader\n\n我们需要更新一下`webpack.config.js`，使其能热加载：\n\n\t//webpack.config.js\n\n\tvar webpack = require('webpack');\n\n\tmodule.exports = {\n\t  entry: [\n\t    'webpack-dev-server/client?http://localhost:8080',\n\t    'webpack/hot/only-dev-server',\n\t    './src/index.js'\n\t  ],\n\t  module: {\n\t    loaders: [{\n\t      test: /\\.jsx?$/,\n\t      exclude: /node_modules/,\n\t      loader: 'react-hot!babel'\n\t    }],\n\t  }\n\t  resolve: {\n\t    extensions: ['', '.js', '.jsx']\n\t  },\n\t  output: {\n\t    path: __dirname + '/dist',\n\t    publicPath: '/',\n\t    filename: 'bundle.js'\n\t  },\n\t  devServer: {\n\t    contentBase: './dist',\n\t    hot: true\n\t  },\n\t  plugins: [\n\t    new webpack.HotModuleReplacementPlugin()\n\t  ]\n\t};\n\n在上述配置的`entry`里我们包含了2个新的应用入口点：webpack dev server和webpack hot module loader。\n它们提供了webpack模块热替换能力。该能力并不是默认加载的，所以上面我们才需要在`plugins`和`devServer`\n中手动加载。\n\n配置的`loaders`部分我们在原先的Babel前配置了`react-hot`用于`.js`和`.jsx`文件。\n\n如果你现在重启开发服务器，你将看到一个在终端看到Hot Module Replacement已开启的消息提醒。我们可以\n开始写我们的第一个组件了。\n\n###实现投票界面\n\n应用的投票界面非常简单：一旦投票启动，它将现实2个按钮，分别用来表示2个可选项，当投票结束，它显示最终结果。\n\n![](http://teropa.info/images/voting_shots.png)\n\n我们之前都是以测试先行的开发方式，但是在react组件开发中我们将先实现组件，再进行测试。这是因为\nwebpack和react-hot-loader提供了更加优良的[反馈机制](http://blog.iterate.no/2012/10/01/know-your-feedback-loop-why-and-how-to-optimize-it/)。\n而且，也没有比直接看到界面更加好的测试UI手段了。\n\n让我们假设有一个`Voting`组件，在之前的入口文件`index.html`的`#app`div中加载它。由于我们的代码中\n包含JSX语法，所以需要把`index.js`重命名为`index.jsx`：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tReact.render(\n\t  <Voting pair={pair} />,\n\t  document.getElementById('app')\n\t);\n\n`Voting`组件将使用`pair`属性来加载数据。我们目前可以先硬编码数据，稍后我们将会用真实数据来代替。\n组件本身是纯粹的，并且对数据来源并不敏感。\n\n注意，在`webpack.config.js`中的入口点文件名也要修改：\n\n\t//webpack.config.js\n\n\tentry: [\n\t  'webpack-dev-server/client?http://localhost:8080',\n\t  'webpack/hot/only-dev-server',\n\t  './src/index.jsx'\n\t],\n\n如果你此时重启webpack-dev-server，你将看到缺失Voting组件的报错。让我们修复它：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}>\n\t          <h1>{entry}</h1>\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n你将会在浏览器上看到组件创建的2个按钮。你可以试试修改代码感受一下浏览器自动更新的魅力，没有刷新，\n没有页面加载，一切都那么迅雷不及掩耳盗铃。\n\n现在我们来添加第一个单元测试：\n\n\t//test/components/Voting_spec.jsx\n\n\timport Voting from '../../src/components/Voting';\n\n\tdescribe('Voting', () => {\n\n\t});\n\n测试组件渲染的按钮，我们必须先看看它的输出是什么。要在单元测试中渲染一个组件，我们需要`react/addons`提供\n的辅助函数[renderIntoDocument](https://facebook.github.io/react/docs/test-utils.html#renderintodocument)：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport Voting from '../../src/components/Voting';\n\n\tconst {renderIntoDocument} = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  it('renders a pair of buttons', () => {\n\t    const component = renderIntoDocument(\n\t      <Voting pair={[\"Trainspotting\", \"28 Days Later\"]} />\n\t    );\n\t  });\n\t});\n\n一旦组件渲染完毕，我就可以通过react提供的另一个辅助函数[scryRenderedDOMComponentsWithTag](https://facebook.github.io/react/docs/test-utils.html#scryrendereddomcomponentswithtag)\n来拿到`button`元素。我们期望存在两个按钮，并且期望按钮的值是我们设置的：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport Voting from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithTag}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  it('renders a pair of buttons', () => {\n\t    const component = renderIntoDocument(\n\t      <Voting pair={[\"Trainspotting\", \"28 Days Later\"]} />\n\t    );\n\t    const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\n\t    expect(buttons.length).to.equal(2);\n\t    expect(buttons[0].getDOMNode().textContent).to.equal('Trainspotting');\n\t    expect(buttons[1].getDOMNode().textContent).to.equal('28 Days Later');\n\t  });\n\t});\n\n如果我们跑一下测试，将会看到测试通过的提示：\n\n\tnpm run test\n\n当用户点击某个按钮后，组件将会调用回调函数，该函数也由组件的prop传递给组件。\n\n让我们完成这一步，我们可以通过使用React提供的测试工具[Simulate](https://facebook.github.io/react/docs/test-utils.html#simulate)\n来模拟点击操作：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport Voting from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  // ...\n\n\t  it('invokes callback when a button is clicked', () => {\n\t    let votedWith;\n\t    const vote = (entry) => votedWith = entry;\n\n\t    const component = renderIntoDocument(\n\t      <Voting pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t              vote={vote}/>\n\t    );\n\t    const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\t    Simulate.click(buttons[0].getDOMNode());\n\n\t    expect(votedWith).to.equal('Trainspotting');\n\t  });\n\t});\n\n要想使上面的测试通过很简单，我们只需要让按钮的`onClick`事件调用`vote`并传递选中条目即可：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n这就是我们在纯组件中常用的方式：组件不需要做太多，只是回调传入的参数即可。\n\n注意，这里我们又是先写的测试代码，我发现业务代码的测试要比测试UI更容易写，所以后面我们会保持这种\n方式：UI测试后行，业务代码测试先行。\n\n一旦用户已经针对某对选项投过票了，我们就不应该允许他们再次投票，难道我们应该在组件内部维护某种状态么？\n不，我们需要保证我们的组件是纯粹的，所以我们需要分离这个逻辑，组件需要一个`hasVoted`属性，我们先硬编码\n传递给它：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tReact.render(\n\t  <Voting pair={pair} hasVoted=\"Trainspotting\" />,\n\t  document.getElementById('app')\n\t);\n\n我们可以简单的修改一下组件即可：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                disabled={this.isDisabled()}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n让我们再为按钮添加一个提示，当用户投票完毕后，在选中的项目上添加标识，这样用户就更容易理解：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  hasVotedFor: function(entry) {\n\t    return this.props.hasVoted === entry;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                disabled={this.isDisabled()}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t          {this.hasVotedFor(entry) ?\n\t            <div className=\"label\">Voted</div> :\n\t            null}\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n投票界面最后要添加的，就是获胜者样式。我们可能需要添加新的props：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tReact.render(\n\t  <Voting pair={pair} winner=\"Trainspotting\" />,\n\t  document.getElementById('app')\n\t);\n\n我们再次修改一下组件：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  hasVotedFor: function(entry) {\n\t    return this.props.hasVoted === entry;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.props.winner ?\n\t        <div ref=\"winner\">Winner is {this.props.winner}!</div> :\n\t        this.getPair().map(entry =>\n\t          <button key={entry}\n\t                  disabled={this.isDisabled()}\n\t                  onClick={() => this.props.vote(entry)}>\n\t            <h1>{entry}</h1>\n\t            {this.hasVotedFor(entry) ?\n\t              <div className=\"label\">Voted</div> :\n\t              null}\n\t          </button>\n\t        )}\n\t    </div>;\n\t  }\n\t});\n\n目前我们已经完成了所有要做的，但是`render`函数看着有点丑陋，如果我们可以把胜利界面独立成新的组件\n可能会好一些：\n\n\t//src/components/Winner.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <div className=\"winner\">\n\t      Winner is {this.props.winner}!\n\t    </div>;\n\t  }\n\t});\n\n这样投票组件就会变得很简单，它只需关注投票按钮逻辑即可：\n\n\t//src/components/Vote.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  hasVotedFor: function(entry) {\n\t    return this.props.hasVoted === entry;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                disabled={this.isDisabled()}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t          {this.hasVotedFor(entry) ?\n\t            <div className=\"label\">Voted</div> :\n\t            null}\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n最后我们只需要在`Voting`组件做一下判断即可：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n注意这里我们为胜利组件添加了[ref](https://facebook.github.io/react/docs/more-about-refs.html)，这是因为我们将在单元测试中利用它获取DOM节点。\n\n这就是我们的纯组件！注意目前我们还没有实现任何逻辑：我们并没有定义按钮的点击操作。组件只是用来渲染UI，其它\n什么都不需要做。后面当我们将UI与Redux Store结合时才会涉及到应用逻辑。\n\n继续下一步之前我们要为刚才新增的特性写更多的单元测试代码。首先，`hasVoted`属性将会使按钮改变状态：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('disables buttons when user has voted', () => {\n\t  const component = renderIntoDocument(\n\t    <Voting pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t            hasVoted=\"Trainspotting\" />\n\t  );\n\t  const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\n\t  expect(buttons.length).to.equal(2);\n\t  expect(buttons[0].getDOMNode().hasAttribute('disabled')).to.equal(true);\n\t  expect(buttons[1].getDOMNode().hasAttribute('disabled')).to.equal(true);\n\t});\n\n被`hasVoted`匹配的按钮将显示`Voted`标签：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('adds label to the voted entry', () => {\n\t  const component = renderIntoDocument(\n\t    <Voting pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t            hasVoted=\"Trainspotting\" />\n\t  );\n\t  const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\n\t  expect(buttons[0].getDOMNode().textContent).to.contain('Voted');\n\t});\n\n当获胜者产生，界面将不存在按钮，取而代替的是胜利者元素：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('renders just the winner when there is one', () => {\n\t  const component = renderIntoDocument(\n\t    <Voting winner=\"Trainspotting\" />\n\t  );\n\t  const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\t  expect(buttons.length).to.equal(0);\n\n\t  const winner = React.findDOMNode(component.refs.winner);\n\t  expect(winner).to.be.ok;\n\t  expect(winner.textContent).to.contain('Trainspotting');\n\t});\n\n###不可变数据和纯粹渲染\n\n我们之前已经讨论了许多关于不可变数据的红利，但是，当它和react结合时还会有一个非常屌的好处：\n如果我们创建纯react组件并传递给它不可变数据作为属性参数，我们将会让react在组件渲染检测中得到最大性能。\n\n这是靠react提供的[PureRenderMixin](https://facebook.github.io/react/docs/pure-render-mixin.html)实现的。\n当该mixin添加到组件中后，组件的更新检查逻辑将会被改变，由深比对改为高性能的浅比对。\n\n我们之所以可以使用浅比对，就是因为我们使用的是不可变数据。如果一个组件的所有参数都是不可变数据，\n那么将大大提高应用性能。\n\n我们可以在单元测试里更清楚的看见差别，如果我们向纯组件中传入可变数组，当数组内部元素产生改变后，组件并不会\n重新渲染：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('renders as a pure component', () => {\n\t  const pair = ['Trainspotting', '28 Days Later'];\n\t  const component = renderIntoDocument(\n\t    <Voting pair={pair} />\n\t  );\n\n\t  let firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t  expect(firstButton.getDOMNode().textContent).to.equal('Trainspotting');\n\n\t  pair[0] = 'Sunshine';\n\t  component.setProps({pair: pair});\n\t  firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t  expect(firstButton.getDOMNode().textContent).to.equal('Trainspotting');\n\t});\n\n如果我们使用不可变数据，则完全没有问题：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List} from 'immutable';\n\timport Voting from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  // ...\n\n\t  it('does update DOM when prop changes', () => {\n\t    const pair = List.of('Trainspotting', '28 Days Later');\n\t    const component = renderIntoDocument(\n\t      <Voting pair={pair} />\n\t    );\n\n\t    let firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t    expect(firstButton.getDOMNode().textContent).to.equal('Trainspotting');\n\n\t    const newPair = pair.set(0, 'Sunshine');\n\t    component.setProps({pair: newPair});\n\t    firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t    expect(firstButton.getDOMNode().textContent).to.equal('Sunshine');\n\t  });\n\t});\n\n如果你跑上面的两个测试，你将会看到非预期的结果：因为实际上UI在两种场景下都更新了。那是因为现在组件\n依然使用的是深比对，这正是我们使用不可变数据想极力避免的。\n\n下面我们在组件中引入mixin，你就会拿到期望的结果了：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  // ...\n\t});\n\n\n\n\t//src/components/Vote.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  // ...\n\t});\n\n\n\n\t//src/components/Winner.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  // ...\n\t});\n\n###投票结果页面和路由实现\n\n投票页面已经搞定了，让我们开始实现投票结果页面吧。\n\n投票结果页面依然会显示两个条目，并且显示它们各自的票数。此外屏幕下方还会有一个按钮，供用户切换到下一轮投票。\n\n现在我们根据什么来确定显示哪个界面呢？使用URL是个不错的主意：我们可以设置根路径`#/`去显示投票页面，\n使用`#/results`来显示投票结果页面。\n\n我们使用[react-router](http://rackt.github.io/react-router/)可以很容易实现这个需求。让我们加入项目：\n\n\tnpm install --save react-router\n\n我们这里使用的react-router的0.13版本，它的1.0版本官方还没有发布，如果你打算使用其1.0RC版，那么下面的代码\n你可能需要做一些修改，可以看[router文档](https://github.com/rackt/react-router)。\n\n我们现在可以来配置一下路由路径，Router提供了一个`Route`组件用来让我们定义路由信息，同时也提供了`DefaultRoute`\n组件来让我们定义默认路由：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport {Route, DefaultRoute} from 'react-router';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tconst routes = <Route handler={App}>\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tReact.render(\n\t  <Voting pair={pair} />,\n\t  document.getElementById('app')\n\t);\n\n我们定义了一个默认的路由指向我们的`Voting`组件。我们需要定义个`App`组件来用于Route使用。\n\n根路由的作用就是为应用指定一个根组件：通常该组件充当所有子页面的模板。让我们来看看`App`的细节：\n\n\t//src/components/App.jsx\n\n\timport React from 'react';\n\timport {RouteHandler} from 'react-router';\n\timport {List} from 'immutable';\n\n\tconst pair = List.of('Trainspotting', '28 Days Later');\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <RouteHandler pair={pair} />\n\t  }\n\t});\n\n这个组件除了渲染了一个`RouteHandler`组件并没有做别的，这个组件同样是react-router提供的，它的作用就是\n每当路由匹配了某个定义的页面后将对应的页面组件插入到这个位置。目前我们只定义了一个默认路由指向`Voting`，\n所以目前我们的组件总是会显示`Voting`界面。\n\n注意，我们将我们硬编码的投票数据从`index.jsx`移到了`App.jsx`，当你给`RouteHandler`传递了属性值时，\n这些参数将会传给当前路由对应的组件。\n\n现在我们可以更新`index.jsx`：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\n\tconst routes = <Route handler={App}>\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Root />,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n`run`方法会根据当前浏览器的路径去查找定义的router来决定渲染哪个组件。一旦确定了对应的组件，它将会被\n当作指定的`Root`传给`run`的回调函数，在回调中我们将使用`React.render`将其插入DOM中。\n\n目前为止我们已经基于React router实现了之前的内容，我们现在可以很容易添加更多新的路由到应用。让我们\n把投票结果页面添加进去吧：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Root />,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n这里我们用使用`<Route>`组件定义了一个名为`/results`的路径，并绑定`Results`组件。\n\n让我们简单的实现一下这个`Results`组件，这样我们就可以看一下路由是如何工作的了：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>Hello from results!</div>\n\t  }\n\t});\n\n如果你在浏览器中输入[http://localhost:8080/#/results](http://localhost:8080/#/results)，你将会看到该结果组件。\n而其它路径都对应这投票页面，你也可以使用浏览器的前后按钮来切换这两个界面。\n\n接下来我们来实际实现一下结果组件：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  render: function() {\n\t    return <div className=\"results\">\n\t      {this.getPair().map(entry =>\n\t        <div key={entry} className=\"entry\">\n\t          <h1>{entry}</h1>\n\t        </div>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n结果界面除了显示投票项外，还应该显示它们对应的得票数，让我们先硬编码一下：\n\n\t//src/components/App.jsx\n\n\timport React from 'react/addons';\n\timport {RouteHandler} from 'react-router';\n\timport {List, Map} from 'immutable';\n\n\tconst pair = List.of('Trainspotting', '28 Days Later');\n\tconst tally = Map({'Trainspotting': 5, '28 Days Later': 4});\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <RouteHandler pair={pair}\n\t                         tally={tally} />\n\t  }\n\t});\n\n现在，我们再来修改一下结果组件：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return <div className=\"results\">\n\t      {this.getPair().map(entry =>\n\t        <div key={entry} className=\"entry\">\n\t          <h1>{entry}</h1>\n\t          <div className=\"voteCount\">\n\t            {this.getVotes(entry)}\n\t          </div>\n\t        </div>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n现在我们来针对目前的界面功能编写测试代码，以防止未来我们破坏这些功能。\n\n我们期望组件为每个选项都渲染一个div，并在其中显示选项的名称和票数。如果对应的选项没有票数，则默认显示0：\n\n\t//test/components/Results_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List, Map} from 'immutable';\n\timport Results from '../../src/components/Results';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithClass}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Results', () => {\n\n\t  it('renders entries with vote counts or zero', () => {\n\t    const pair = List.of('Trainspotting', '28 Days Later');\n\t    const tally = Map({'Trainspotting': 5});\n\t    const component = renderIntoDocument(\n\t      <Results pair={pair} tally={tally} />\n\t    );\n\t    const entries = scryRenderedDOMComponentsWithClass(component, 'entry');\n\t    const [train, days] = entries.map(e => e.getDOMNode().textContent);\n\n\t    expect(entries.length).to.equal(2);\n\t    expect(train).to.contain('Trainspotting');\n\t    expect(train).to.contain('5');\n\t    expect(days).to.contain('28 Days Later');\n\t    expect(days).to.contain('0');\n\t  });\n\t});\n\n接下来，我们看一下\"Next\"按钮，它允许用户切换到下一轮投票。\n\n我们的组件应该包含一个回调函数属性参数，当组件中的\"Next\"按钮被点击后，该回调函数将会被调用。我们来写一下\n这个操作的测试代码：\n\n\t//test/components/Results_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List, Map} from 'immutable';\n\timport Results from '../../src/components/Results';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithClass, Simulate}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Results', () => {\n\n\t  // ...\n\n\t  it('invokes the next callback when next button is clicked', () => {\n\t    let nextInvoked = false;\n\t    const next = () => nextInvoked = true;\n\n\t    const pair = List.of('Trainspotting', '28 Days Later');\n\t    const component = renderIntoDocument(\n\t      <Results pair={pair}\n\t               tally={Map()}\n\t               next={next}/>\n\t    );\n\t    Simulate.click(React.findDOMNode(component.refs.next));\n\n\t    expect(nextInvoked).to.equal(true);\n\t  });\n\t});\n\n写法和之前的投票按钮很类似吧。接下来让我们更新一下结果组件：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return <div className=\"results\">\n\t      <div className=\"tally\">\n\t        {this.getPair().map(entry =>\n\t          <div key={entry} className=\"entry\">\n\t            <h1>{entry}</h1>\n\t            <div class=\"voteCount\">\n\t              {this.getVotes(entry)}\n\t            </div>\n\t          </div>\n\t        )}\n\t      </div>\n\t      <div className=\"management\">\n\t        <button ref=\"next\"\n\t                className=\"next\"\n\t                onClick={this.props.next}>\n\t          Next\n\t        </button>\n\t      </div>\n\t    </div>;\n\t  }\n\t});\n\n最终投票结束，结果页面和投票页面一样，都要显示胜利者：\n\n\t//test/components/Results_spec.jsx\n\n\tit('renders the winner when there is one', () => {\n\t  const component = renderIntoDocument(\n\t    <Results winner=\"Trainspotting\"\n\t             pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t             tally={Map()} />\n\t  );\n\t  const winner = React.findDOMNode(component.refs.winner);\n\t  expect(winner).to.be.ok;\n\t  expect(winner.textContent).to.contain('Trainspotting');\n\t});\n\n我们可以想在投票界面中那样简单的实现一下上面的逻辑：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\timport Winner from './Winner';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return this.props.winner ?\n\t      <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t      <div className=\"results\">\n\t        <div className=\"tally\">\n\t          {this.getPair().map(entry =>\n\t            <div key={entry} className=\"entry\">\n\t              <h1>{entry}</h1>\n\t              <div className=\"voteCount\">\n\t                {this.getVotes(entry)}\n\t              </div>\n\t            </div>\n\t          )}\n\t        </div>\n\t        <div className=\"management\">\n\t          <button ref=\"next\"\n\t                   className=\"next\"\n\t                   onClick={this.props.next}>\n\t            Next\n\t          </button>\n\t        </div>\n\t      </div>;\n\t  }\n\t});\n\n到目前为止，我们已经实现了应用的UI，虽然现在它们并没有和真实数据和操作整合起来。这很不错不是么？\n我们只需要一些占位符数据就可以完成界面的开发，这让我们在这个阶段更专注于UI。\n\n接下来我们将会使用Redux Store来将真实数据整合到我们的界面中。\n\n###初识客户端的Redux Store\n\nRedux将会充当我们UI界面的状态容器，我们已经在服务端用过Redux，之前说的很多内容在这里也受用。\n现在我们已经准备好要在React应用中使用Redux了，这也是Redux更常见的使用场景。\n\n和在服务端一样，我们先来思考一下应用的状态。客户端的状态和服务端会非常的类似。\n\n我们有两个界面，并在其中需要显示成对的用于投票的条目：\n\n![](http://teropa.info/images/vote_client_pair.png)\n\n此外，结果页面需要显示票数：\n\n![](http://teropa.info/images/vote_client_tally.png)\n\n投票组件还需要记录当前用户已经投票过的选项：\n\n![](http://teropa.info/images/vote_client_hasvoted.png)\n\n结果组件还需要记录胜利者：\n\n![](http://teropa.info/images/vote_server_tree_winner.png)\n\n注意这里除了`hasVoted`外，其它都映射着服务端状态的子集。\n\n接下来我们来思考一下应用的核心逻辑，actions和reducers应该是什么样的。\n\n我们先来想想能够导致应用状态改变的操作都有那些？状态改变的来源之一是用户行为。我们的UI中存在两种\n可能的用户操作行为：\n\n- 用户在投票页面点击某个投票按钮；\n- 用户点击下一步按钮。\n\n另外，我们知道我们的服务端会将应用当前状态发送给客户端，我们将编写代码来接受状态数据，这也是导致状态\n改变的来源之一。\n\n我们可以从服务端状态更新开始，之前我们在服务端设置发送了一个`state`事件。该事件将携带我们之前设计的客户端\n状态树的状态数据。我们的客户端reducer将通过一个action来将服务器端的状态数据合并到客户端状态树中，\n这个action如下：\n\n\t{\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {...}\n\t  }\n\t}\n\n让我们先写一下reducer测试代码，它应该接受上面定义的那种action，并合并数据到客户端的当前状态中：\n\n\t//test/reducer_spec.js\n\n\timport {List, Map, fromJS} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport reducer from '../src/reducer';\n\n\tdescribe('reducer', () => {\n\n\t  it('handles SET_STATE', () => {\n\t    const initialState = Map();\n\t    const action = {\n\t      type: 'SET_STATE',\n\t      state: Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({Trainspotting: 1})\n\t        })\n\t      })\n\t    };\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      }\n\t    }));\n\t  });\n\t});\n\n这个renducers接受一个来自socket发送的原始的js数据结构，这里注意不是不可变数据类型哦。我们需要在返回前将其\n转换成不可变数据类型：\n\n\t//test/reducer_spec.js\n\n\tit('handles SET_STATE with plain JS payload', () => {\n\t  const initialState = Map();\n\t  const action = {\n\t    type: 'SET_STATE',\n\t    state: {\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      }\n\t    }\n\t  };\n\t  const nextState = reducer(initialState, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  }));\n\t});\n\nreducer同样应该可以正确的处理`undefined`初始化状态：\n\n\t//test/reducer_spec.js\n\n\tit('handles SET_STATE without initial state', () => {\n\t  const action = {\n\t    type: 'SET_STATE',\n\t    state: {\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      }\n\t    }\n\t  };\n\t  const nextState = reducer(undefined, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  }));\n\t});\n\n现在我们来看一下如何实现满足上面测试条件的reducer：\n\n\t//src/reducer.js\n\n\timport {Map} from 'immutable';\n\n\texport default function(state = Map(), action) {\n\n\t  return state;\n\t}\n\nreducer需要处理`SET_STATE`动作。在这个动作的处理中，我们应该将传入的状态数据和现有的进行合并，\n使用Map提供的[merge](https://facebook.github.io/immutable-js/docs/#/Map/merge)将很容易来实现这个操作：\n\n\t//src/reducer.js\n\n\timport {Map} from 'immutable';\n\n\tfunction setState(state, newState) {\n\t  return state.merge(newState);\n\t}\n\n\texport default function(state = Map(), action) {\n\t  switch (action.type) {\n\t  case 'SET_STATE':\n\t    return setState(state, action.state);\n\t  }\n\t  return state;\n\t}\n\n注意这里我们并没有单独写一个核心模块，而是直接在reducer中添加了个简单的`setState`函数来做业务逻辑。\n这是因为现在这个逻辑还很简单～\n\n关于改变用户状态的那两个用户交互：投票和下一步，它们都需要和服务端进行通信，我们一会再说。我们现在先把\nredux添加到项目中：\n\n\tnpm install --save redux\n\n`index.jsx`入口文件是一个初始化Store的好地方，让我们暂时先使用硬编码的数据来做：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Root />,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n那么，我们如何在react组件中从Store中获取数据呢？\n\n###让React从Redux中获取数据\n\n我们已经创建了一个使用不可变数据类型保存应用状态的Redux Store。我们还拥有接受不可变数据为参数的\n无状态的纯React组件。如果我们能使这些组件从Store中获取最新的状态数据，那真是极好的。当状态变化时，\nReact会重新渲染组件，pure render mixin可以使得我们的UI避免不必要的重复渲染。\n\n相比我们自己手动实现同步代码，我们更推荐使用[react-redux][https://github.com/rackt/react-redux]包来做：\n\n\tnpm install --save react-redux\n\n这个库主要做的是：\n\n1. 映射Store的状态到组件的输入props中；\n2. 映射actions到组件的回调props中。\n\n为了让它可以正常工作，我们需要将顶层的应用组件嵌套在react-redux的[Provider](https://github.com/rackt/react-redux#provider-store)组件中。\n这将把Redux Store和我们的状态树连接起来。\n\n我们将让Provider包含路由的根组件，这样会使得Provider成为整个应用组件的根节点：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n接下来我们要考虑一下，我们的那些组件需要绑定到Store上。我们一共有5个组件，可以分成三类：\n\n- 根组件`App`不需要绑定任何数据；\n- `Vote`和`Winner`组件只使用父组件传递来的数据，所以它们也不需要绑定；\n- 剩下的组件（`Voting`和`Results`）目前都是使用的硬编码数据，我们现在需要将其绑定到Store上。\n\n让我们从`Voting`组件开始。使用react-redux我们得到一个叫[connect](https://github.com/rackt/react-redux#connectmapstatetoprops-mapdispatchtoprops-mergeprops-options)的函数：\n\n\tconnect(mapStateToProps)(SomeComponent);\n\n该函数的作用就是将Redux Store中的状态数据映射到props对象中。这个props对象将会用于连接到的组件中。\n在我们的`Voting`场景中，我们需要从状态中拿到`pair`和`winner`值：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\tconst Voting = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n\tconnect(mapStateToProps)(Voting);\n\n\texport default Voting;\n\n在上面的代码中，`connect`函数并没有修改`Voting`组件本身，`Voting`组件依然保持这纯粹性。而`connect`\n返回的是一个`Voting`组件的连接版，我们称之为`VotingContainer`：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\texport const Voting = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n\texport const VotingContainer = connect(mapStateToProps)(Voting);\n\n这样，这个模块现在导出两个组件：一个纯`Voting`组件，一个连接后的`VotingContainer`版本。\nreact-redux官方称前者为“蠢”组件，后者则称为\"智能\"组件。我更倾向于用“pure”和“connected”来描述它们。\n怎么称呼随你便，主要是明白它们之间的差别：\n\n- 纯组件完全靠给它传入的props来工作，这非常类似一个纯函数；\n- 连接组件则封装了纯组件和一些逻辑用来与Redux Store协同工作，这些特性是redux-react提供的。\n\n我们得更新一下路由表，改用`VotingContainer`。一旦修改完毕，我们的投票界面将会使用来自Redux Store的数据：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n而在对应的测试代码中，我们则需要使用纯`Voting`组件定义：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List} from 'immutable';\n\timport {Voting} from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n其它地方不需要修改了。\n\n现在我们来如法炮制投票结果页面：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\n\texport const Results = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return this.props.winner ?\n\t      <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t      <div className=\"results\">\n\t        <div className=\"tally\">\n\t          {this.getPair().map(entry =>\n\t            <div key={entry} className=\"entry\">\n\t              <h1>{entry}</h1>\n\t              <div className=\"voteCount\">\n\t                {this.getVotes(entry)}\n\t              </div>\n\t            </div>\n\t          )}\n\t        </div>\n\t        <div className=\"management\">\n\t          <button ref=\"next\"\n\t                   className=\"next\"\n\t                   onClick={this.props.next}>\n\t            Next\n\t          </button>\n\t      </div>\n\t      </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    tally: state.getIn(['vote', 'tally']),\n\t    winner: state.get('winner')\n\t  }\n\t}\n\n\texport const ResultsContainer = connect(mapStateToProps)(Results);\n\n同样我们需要修改`index.jsx`来使用新的`ResultsContainer`：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n不要忘记修改测试代码啊：\n\n\t//test/components/Results_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List, Map} from 'immutable';\n\timport {Results} from '../../src/components/Results';\n\timport {expect} from 'chai';\n\n现在你已经知道如何让纯react组件与Redux Store整合了。\n\n对于一些只有一个根组件且没有路由的小应用，直接连接根组件就足够了。根组件会将状态数据传递给它的子组件。\n而对于那些使用路由，就像我们的场景，连接每一个路由指向的处理函数是个好主意。但是分别为每个组件编写连接代码并\n不适合所有的软件场景。我觉得保持组件props尽可能清晰明了是个非常好的习惯，因为它可以让你很容易清楚组件需要哪些数据，\n你就可以更容易管理那些连接代码。\n\n现在让我们开始把Redux数据对接到UI里，我们再也不需要那些`App.jsx`中手写的硬编码数据了，这样我们的`App.jsx`将会变得简单：\n\n\t//src/components/App.jsx\n\n\timport React from 'react';\n\timport {RouteHandler} from 'react-router';\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <RouteHandler />\n\t  }\n\t});\n\n\n###设置socket.io客户端\n\n现在我们已经创建好了客户端的Redux应用，我们接下来将讨论如何让其与我们之前开发的服务端应用进行对接。\n\n服务端已经准备好接受socket连接，并为其进行投票数据的发送。而我们的客户端也已经可以使用Redux Store很方便的\n接受数据了。我们剩下的工作就是把它们连接起来。\n\n我们需要使用socket.io从浏览器向服务端创建一个连接，我们可以使用[socket.io-client库](http://socket.io/docs/client-api/)来完成\n这个目的：\n\n\tnpm install --save socket.io-client\n\n这个库赋予了我们连接Socket.io服务端的能力，让我们连接之前写好的服务端，端口号8090（注意使用和后端匹配的端口）：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n你必须先确保你的服务端已经开启了，然后在浏览器端访问客户端应用，并检查网络监控，你会发现创建了一个\nWebSockets连接，并且开始传输Socket.io的心跳包了。\n\n###接受来自服务器端的actions\n\n我们虽然已经创建了个socket.io连接，但我们并没有用它获取任何数据。每当我们连接到服务端或服务端发生\n状态数据改变时，服务端会发送`state`事件给客户端。我们只需要监听对应的事件即可，我们在接受到事件通知后\n只需要简单的对我们的Store指派`SET_STATE`action即可：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch({type: 'SET_STATE', state})\n\t);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n注意我们移除了`SET_STATE`的硬编码，我们现在已经不需要伪造数据了。\n\n审视我们的界面，不管是投票还是结果页面，它们都会显示服务端提供的第一对选项。服务端和客户端已经连接上了！\n\n###从react组件中指派actions\n\n我们已经知道如何从Redux Store获取数据到UI中，现在来看看如何从UI中提交数据用于actions。\n\n思考这个问题的最佳场景是投票界面上的投票按钮。之前在写相关界面时，我们假设`Voting`组件接受一个回调函数props。\n当用户点击某个按钮时组件将会调用这个回调函数。但我们目前并没有实现这个回调函数，除了在测试代码中。\n\n当用户投票后应该做什么？投票结果应该发送给服务端，这部分我们稍后再说，客户端也需要执行一些逻辑：\n组件的`hasVoted`值应该被设置，这样用户才不会反复对同一对选项投票。\n\n这是我们要创建的第二个客户端Redux Action，我们称之为`VOTE`：\n\n\t//test/reducer_spec.js\n\n\tit('handles VOTE by setting hasVoted', () => {\n\t  const state = fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  });\n\t  const action = {type: 'VOTE', entry: 'Trainspotting'};\n\t  const nextState = reducer(state, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    },\n\t    hasVoted: 'Trainspotting'\n\t  }));\n\t});\n\n为了更严谨，我们应该考虑一种情况：不管什么原因，当`VOTE`action传递了一个不存在的选项时我们的应用该怎么做：\n\n\t//test/reducer_spec.js\n\n\tit('does not set hasVoted for VOTE on invalid entry', () => {\n\t  const state = fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  });\n\t  const action = {type: 'VOTE', entry: 'Sunshine'};\n\t  const nextState = reducer(state, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  }));\n\t});\n\n下面来看看我们的reducer如何实现的：\n\n\t//src/reducer.js\n\n\timport {Map} from 'immutable';\n\n\tfunction setState(state, newState) {\n\t  return state.merge(newState);\n\t}\n\n\tfunction vote(state, entry) {\n\t  const currentPair = state.getIn(['vote', 'pair']);\n\t  if (currentPair && currentPair.includes(entry)) {\n\t    return state.set('hasVoted', entry);\n\t  } else {\n\t    return state;\n\t  }\n\t}\n\n\texport default function(state = Map(), action) {\n\t  switch (action.type) {\n\t  case 'SET_STATE':\n\t    return setState(state, action.state);\n\t  case 'VOTE':\n\t    return vote(state, action.entry);\n\t  }\n\t  return state;\n\t}\n\n`hasVoted`并不会一直保存在状态数据中，每当开始一轮新的投票时，我们应该在`SET_STATE`action的处理逻辑中\n检查是否用户是否已经投票，如果还没，我们应该删除掉`hasVoted`：\n\n\t//test/reducer_spec.js\n\n\tit('removes hasVoted on SET_STATE if pair changes', () => {\n\t  const initialState = fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    },\n\t    hasVoted: 'Trainspotting'\n\t  });\n\t  const action = {\n\t    type: 'SET_STATE',\n\t    state: {\n\t      vote: {\n\t        pair: ['Sunshine', 'Slumdog Millionaire']\n\t      }\n\t    }\n\t  };\n\t  const nextState = reducer(initialState, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Sunshine', 'Slumdog Millionaire']\n\t    }\n\t  }));\n\t});\n\n根据需要，我们新增一个`resetVote`函数来处理`SET_STATE`动作：\n\n\t//src/reducer.js\n\n\timport {List, Map} from 'immutable';\n\n\tfunction setState(state, newState) {\n\t  return state.merge(newState);\n\t}\n\n\tfunction vote(state, entry) {\n\t  const currentPair = state.getIn(['vote', 'pair']);\n\t  if (currentPair && currentPair.includes(entry)) {\n\t    return state.set('hasVoted', entry);\n\t  } else {\n\t    return state;\n\t  }\n\t}\n\n\tfunction resetVote(state) {\n\t  const hasVoted = state.get('hasVoted');\n\t  const currentPair = state.getIn(['vote', 'pair'], List());\n\t  if (hasVoted && !currentPair.includes(hasVoted)) {\n\t    return state.remove('hasVoted');\n\t  } else {\n\t    return state;\n\t  }\n\t}\n\n\texport default function(state = Map(), action) {\n\t  switch (action.type) {\n\t  case 'SET_STATE':\n\t    return resetVote(setState(state, action.state));\n\t  case 'VOTE':\n\t    return vote(state, action.entry);\n\t  }\n\t  return state;\n\t}\n\n我们还需要在修改一下连接逻辑：\n\n\t//src/components/Voting.jsx\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    hasVoted: state.get('hasVoted'),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n现在我们依然需要为`Voting`提供一个`vote`回调函数，用来为Sotre指派我们新增的action。我们依然要尽力保证\n`Voting`组件的纯粹性，不应该依赖任何actions或Redux。这些工作都应该在react-redux的`connect`中处理。\n\n除了连接输入参数属性，react-redux还可以用来连接output actions。开始之前，我们先来介绍一下另一个Redux的\n核心概念：Action creators。\n\n如我们之前看到的，Redux actions通常就是一个简单的对象，它包含一个固有的`type`属性和其它内容。我们之前都是直接\n利用js对象字面量来直接声明所需的actions。其实可以使用一个factory函数来更好的生成actions，如下：\n\n\tfunction vote(entry) {\n\t  return {type: 'VOTE', entry};\n\t}\n\n这类函数就被称为action creators。它们就是个纯函数，用来返回action对象，别的没啥好介绍得了。但是你也可以\n在其中实现一些内部逻辑，而避免将每次生成action都重复编写它们。使用action creators可以更好的表达所有需要分发\n的actions。\n\n让我们新建一个用来声明客户端所需action的action creators文件：\n\n\t//src/action_creators.js\n\n\texport function setState(state) {\n\t  return {\n\t    type: 'SET_STATE',\n\t    state\n\t  };\n\t}\n\n\texport function vote(entry) {\n\t  return {\n\t    type: 'VOTE',\n\t    entry\n\t  };\n\t}\n\n我们当然也可以为action creators编写测试代码，但由于我们的代码逻辑太简单了，我就不再写测试了。\n\n现在我们可以在`index.jsx`中使用我们刚新增的`setState`action creator了：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport {setState} from './action_creators';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch(setState(state))\n\t);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n使用action creators还有一个非常优雅的特点：在我们的场景里，我们有一个需要`vote`回调函数props的\n`Vote`组件，我们同时拥有一个`vote`的action creator。它们的名字和函数签名完全一致（都接受一个用来表示\n选中项的参数）。现在我们只需要将action creators作为react-redux的`connect`函数的第二个参数，即可完成\n自动关联：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\timport * as actionCreators from '../action_creators';\n\n\texport const Voting = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    hasVoted: state.get('hasVoted'),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n\texport const VotingContainer = connect(\n\t  mapStateToProps,\n\t  actionCreators\n\t)(Voting);\n\n这么配置后，我们的`Voting`组件的`vote`参数属性将会与`vote`aciton creator关联起来。这样当点击\n某个投票按钮后，会导致触发`VOTE`动作。\n\n###使用Redux Middleware发送actions到服务端\n\n最后我们要做的是把用户数据提交到服务端，这种操作一般发生在用户投票，或选择跳转下一轮投票时发生。\n\n让我们讨论一下投票操作，下面列出了投票的逻辑：\n\n- 当用户进行投票，`VOTE`action将产生并分派到客户端的Redux Store中；\n- `VOTE`actions将触发客户端reducer进行`hasVoted`状态设置；\n- 服务端监控客户端通过socket.io投递的`action`，它将接收到的actions分派到服务端的Redux Store;\n- `VOTE`action将触发服务端的reducer，其会创建vote数据并更新对应的票数。\n\n这样来说，我们似乎已经都搞定了。唯一缺少的就是让客户端发送`VOTE`action给服务端。这相当于两端的\nRedux Store相互分派action，这就是我们接下来要做的。\n\n那么该怎么做呢？Redux并没有内建这种功能。所以我们需要设计一下何时何地来做这个工作：从客户端发送\naction到服务端。\n\nRedux提供了一个通用的方法来封装action：[Middleware](http://rackt.github.io/redux/docs/advanced/Middleware.html)。\n\nRedux中间件是一个函数，每当action将要被指派，并在对应的reducer执行之前会被调用。它常用来做像日志收集，\n异常处理，修整action，缓存结果，控制何时以何种方式来让store接收actions等工作。这正是我们可以利用的。\n\n注意，一定要分清Redux中间件和Redux监听器的差别：中间件被用于action将要指派给store阶段，它可以修改action对\nstore将带来的影响。而监听器则是在action被指派后，它不能改变action的行为。\n\n我们需要创建一个“远程action中间件”，该中间件可以让我们的action不仅仅能指派给本地的store，也可以通过\nsocket.io连接派送给远程的store。\n\n让我们创建这个中间件，It is a function that takes a Redux store, and returns another function that takes a \"next\" callback. That function returns a third function that takes a Redux action. The innermost function is where the middleware implementation will actually go\n（译者注：这句套绕口，请看官自行参悟）：\n\n\t//src/remote_action_middleware.js\n\n\texport default store => next => action => {\n\n\t}\n\n上面这个写法看着可能有点渗人，下面调整一下让大家好理解：\n\n\texport default function(store) {\n\t\treturn function(next) {\n\t\t\treturn function(action) {\n\n\t\t\t}\n\t\t}\n\t}\n\n这种嵌套接受单一参数函数的写法成为[currying](https://en.wikipedia.org/wiki/Currying)。\n这种写法主要用来简化中间件的实现：如果我们使用一个一次性接受所有参数的函数（`function(store, next, action) { }`），\n那么我们就不得不保证我们的中间件具体实现每次都要包含所有这些参数。\n\n上面的`next`参数作用是在中间件中一旦完成了action的处理，就可以调用它来退出当前逻辑：\n\n\t//src/remote_action_middleware.js\n\n\texport default store => next => action => {\n\t  return next(action);\n\t}\n\n如果中间件没有调用`next`，则该action将丢弃，不再传到reducer或store中。\n\n让我们写一个简单的日志中间件：\n\n\t//src/remote_action_middleware.js\n\n\texport default store => next => action => {\n\t  console.log('in middleware', action);\n\t  return next(action);\n\t}\n\n我们将上面这个中间件注册到我们的Redux Store中，我们将会抓取到所有action的日志。中间件可以通过Redux\n提供的`applyMiddleware`函数绑定到我们的store中：\n\n\t//src/components/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore, applyMiddleware} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport {setState} from './action_creators';\n\timport remoteActionMiddleware from './remote_action_middleware';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst createStoreWithMiddleware = applyMiddleware(\n\t  remoteActionMiddleware\n\t)(createStore);\n\tconst store = createStoreWithMiddleware(reducer);\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch(setState(state))\n\t);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n如果你重启应用，你将会看到我们设置的中间件会抓到应用触发的action日志。\n\n那我们应该怎么利用中间件机制来完成从客户端通过socket.io连接发送action给服务端呢？在此之前我们肯定需要先\n有一个连接供中间件使用，不幸的是我们已经有了，就在`index.jsx`中，我们只需要中间件可以拿到它即可。\n使用currying风格来实现这个中间件很简单：\n\n\t//src/remote_action_middleware.js\n\n\texport default socket => store => next => action => {\n\t  console.log('in middleware', action);\n\t  return next(action);\n\t}\n\n这样我们就可以在`index.jsx`中传入需要的连接了：\n\n\t//src/index.jsx\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch(setState(state))\n\t);\n\n\tconst createStoreWithMiddleware = applyMiddleware(\n\t  remoteActionMiddleware(socket)\n\t)(createStore);\n\tconst store = createStoreWithMiddleware(reducer);\n\n注意跟之前的代码比，我们需要调整一下顺序，让socket连接先于store被创建。\n\n一切就绪了，现在就可以使用我们的中间件发送`action`了：\n\n\t//src/remote_action_middleware.js\n\n\texport default socket => store => next => action => {\n\t  socket.emit('action', action);\n\t  return next(action);\n\t}\n\n打完收工。现在如果你再点击投票按钮，你就会看到所有连接到服务端的客户端的票数都会被更新！\n\n还有个很严重的问题我们要处理：现在每当我们收到服务端发来的`SET_STATE`action后，这个action都将会直接回传给\n服务端，这样我们就造成了一个死循环，这是非常反人类的。\n\n我们的中间件不应该不加处理的转发所有的action给服务端。个别action，例如`SET_STATE`，应该只在客户端做\n处理。我们在action中添加一个标识位用于识别哪些应该转发给服务端：\n\n\t//src/remote_action_middleware.js\n\n\texport default socket => store => next => action => {\n\t  if (action.meta && action.meta.remote) {\n\t    socket.emit('action', action);\n\t  }\n\t  return next(action);\n\t}\n\n我们同样应该修改相关的action creators：\n\n\t//src/action_creators.js\n\n\texport function setState(state) {\n\t  return {\n\t    type: 'SET_STATE',\n\t    state\n\t  };\n\t}\n\n\texport function vote(entry) {\n\t  return {\n\t    meta: {remote: true},\n\t    type: 'VOTE',\n\t    entry\n\t  };\n\t}\n\n让我们重新审视一下我们都干了什么：\n\n1. 用户点击投票按钮，`VOTE`action被分派；\n2. 远程action中间件通过socket.io连接转发该action给服务端；\n3. 客户端Redux Store处理这个action，记录本地`hasVoted`属性；\n4. 当action到达服务端，服务端的Redux Store将处理该action，更新所有投票及其票数；\n5. 设置在服务端Redux Store上的监听器将改变后的状态数据发送给所有在线的客户端；\n6. 每个客户端将触发`SET_STATE`action的分派；\n7. 每个客户端将根据这个action更新自己的状态，这样就保持了与服务端的同步。\n\n为了完成我们的应用，我们需要实现下一步按钮的逻辑。和投票类似，我们需要将数据发送到服务端：\n\n\t//src/action_creator.js\n\n\texport function setState(state) {\n\t  return {\n\t    type: 'SET_STATE',\n\t    state\n\t  };\n\t}\n\n\texport function vote(entry) {\n\t  return {\n\t    meta: {remote: true},\n\t    type: 'VOTE',\n\t    entry\n\t  };\n\t}\n\n\texport function next() {\n\t  return {\n\t    meta: {remote: true},\n\t    type: 'NEXT'\n\t  };\n\t}\n\n`ResultsContainer`组件将会自动关联action creators中的next作为props：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport * as actionCreators from '../action_creators';\n\n\texport const Results = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return this.props.winner ?\n\t      <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t      <div className=\"results\">\n\t        <div className=\"tally\">\n\t          {this.getPair().map(entry =>\n\t            <div key={entry} className=\"entry\">\n\t              <h1>{entry}</h1>\n\t              <div className=\"voteCount\">\n\t                {this.getVotes(entry)}\n\t              </div>\n\t            </div>\n\t          )}\n\t        </div>\n\t        <div className=\"management\">\n\t          <button ref=\"next\"\n\t                   className=\"next\"\n\t                   onClick={this.props.next()}>\n\t            Next\n\t          </button>\n\t        </div>\n\t      </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    tally: state.getIn(['vote', 'tally']),\n\t    winner: state.get('winner')\n\t  }\n\t}\n\n\texport const ResultsContainer = connect(\n\t  mapStateToProps,\n\t  actionCreators\n\t)(Results);\n\n彻底完工了！我们实现了一个功能完备的应用。\n\n###课后练习\n（不翻译）\n","source":"_posts/[译]全栈Redux实战.md","raw":"title: ［译]全栈Redux实战\ndate: 2015-10-08 09:37:12\ntags: \n- react\n- Redux\n- 单元测试\n- Immutable-js\ncategories: 前端\n---\n\n本文乱译自一篇英文博文（[Full-Stack Redux Tutorial](http://teropa.info/blog/2015/09/10/full-stack-redux-tutorial.html)），本人英语能力不足，技术能力有限，如有错误，多多包涵。\n\n<!--more-->\n\n#关于Redux+React+Immutable的测试先行开发综合指南\n\nRedux是最近发生在js界令人兴奋的事儿。它把众多优秀的库和框架中非常正确的特性保留了下来：简单且可预测的模型，强调函数式编程和不可变数据，基于api的轻量级实现……你还有什么理由不喜欢呢？\n\nRedux是一个非常小的代码库，掌握它所有的api并不困难，但对很多同学来讲，它要求的：创建组件（blocks），自满足的纯函数和不可变数据会带来不少别扭，那到底应该怎么办呢？\n\n这篇文章将会带你创建一个全栈的Redux和Immutable-js应用。我们将详细讲解创建该应用的Node+Redu后端和React+Redux前端的所有步骤。本指南将使用ES6,Babel,Socket.io,Webpack和Mocha。这是一个非常令人着迷的技术栈选型，你肯定不及待的想要开始了。\n\n##目录\n（不翻译）\n\n## 你需要准备什么\n\n这篇文章需要读者具备开发js应用的能力，我们讲使用Node，ES6，React，Webpack，和Babel，所以你最好能了解这些工具，这样你才不会掉队。\n\n在上面提到的工具集中，你需要安装Node和NPM，和一款你喜欢的编辑器。\n\n##应用\n\n我们将要开发一款应用，它用来为聚会，会议，集会等用户群提供实时投票功能。\n\n这个点子来自于现实中我们经常需要为电影，音乐，编程语言等进行投票。该应用将所有选项两两分组，这样用户可以根据喜好进行二选一，最终拿到最佳结果。\n\n举个例子，这里拿Danny Boyle电影做例子来发起投票：\n\n![](http://teropa.info/images/vote_logic.png)\n\n这个应用有两类独立的界面：用于投票的移动端界面，用于其它功能的浏览器界面。投票结果界面设计成有利于幻灯片或其它更大尺寸的屏幕显示，它用来展示投票的实时结果。\n\n![](http://teropa.info/images/vote_system.png)\n\n##架构\n\n该系统应该有2部分组成：浏览器端我们使用React来提供用户界面，服务端我们使用Node来处理投票逻辑。两端通信我们选择使用WebSockets。\n\n我们将使用Redux来组织前后端的应用代码。我们将使用Immutable数据结构来处理应用的state。\n\n虽然我们的前后端存在许多相似性，例如都使用Redux。但是它们之间并没有什么可复用代码。这更像一个分布式系统，靠传递消息进行通信。\n\n##服务端应用\n\n我们先来实现Node应用，这有助于我们专注于核心业务逻辑，而不是过早的被界面干扰。\n\n实现服务端应用，我们需要先了解Redux和Immutable，并且明白它们如何协作。Redux常常被用在React开发中，但它并不限制于此。我们这里就要学习让Redux如何在其它场景下使用。\n\n我推荐大家跟着我们的指导一起写出一个应用，但你也可以直接从[github](https://github.com/teropa/redux-voting-server)上下载代码。\n\n###设计应用的状态树（State Tree）\n\n设计一个Redux应用往往从思考应用的状态树数据结构开始，它是用来描述你的应用在任何时间点下状态的数据结构。\n\n任何的框架和架构都包含状态。在Ember和Backbone框架里，状态就是模型（Models）。在Anglar中，状态常常用Factories和Services来管理。而在大多数Flux实现中，常常用Stores来负责状态。那Redux又和它们有哪些不同之处呢？\n\n最大的不同之处是，在Redux中，应用的状态是全部存在一个单一的树结构中的。换句话说，应用的所有状态信息都存储在这个包含map和array的数据结构中。\n\n这么做很有意义，我们马上就会感受到。最重要的一点是，这么做迫使你将应用的行为和状态隔离开来。状态就是纯数据，它不包含任何方法或函数。\n\n这么做听起来存在局限，特别是你刚刚从面向对象思想背景下转到Redux。但这确实是一种解放，因为这么做将使你专注于数据自身。如果你花一些时间来设计你的应用状态，其它环节将水到渠成。\n\n这并不是说你总应该一上来就设计你的实体状态树然后再做其它部分。通常你最终会同时考虑应用的所有方面。然而，我发现当你想到一个点子时，在写代码前先思考在不同解决方案下状态树的结构会非常有帮助。\n\n所以，让我们先看看我们的投票应用的状态树应该是什么样的。应用的目标是可以针对多个选项进行投票，那么符合直觉的一种初始化状态应该是包含要被投票的选项集合，我们称之为条目[entries]：\n\n![](http://teropa.info/images/vote_server_tree_entries.png)\n\n当投票开始，还必须定位哪些选项是当前项。所以我们可能还需要一个vote条目，它用来存储当前投票的数据对，投票项应该是来自entries中的：\n\n![](http://teropa.info/images/vote_server_tree_pair.png)\n\n除此之外，投票的计数也应该被保存起来：\n\n![](http://teropa.info/images/vote_server_tree_tally.png)\n\n每次用户进行二选一后，未被选择的那项直接丢弃，被选择的条目重新放回entries的末尾，然后从entries头部选择下一对投票项：\n\n![](http://teropa.info/images/vote_server_tree_next.png)\n\n我们可以想象一下，这么周而复始的投票，最终将会得到一个结果，投票也就结束了：\n\n![](http://teropa.info/images/vote_server_tree_winner.png)\n\n如此设计看起来是合情合理的。针对上面的场景存在很多不同的设计，我们当前的做法也可能不是最佳的，但我们暂时就先这么定吧，足够我们进行下一步了。最重要的是我们在没有写任何代码的前提下已经从最初的点子过渡到确定了应用的具体功能。\n\n###项目安排\n\n是时候开始脏活累活了。开始之前，我们先创建一个项目目录：\n\n\tmkdir voting-server\n\tcd voting-server\n\tnpm init         #所有提示问题直接敲回车即可\n\n初始化完毕后，我们的项目目录下将会只存在一个*package.json*文件。\n\n我们将采用ES6语法来写代码。Node是从4.0.0版本后开始支持大多数ES6语法的，并且目前并不支持modules，但我们需要用到。我们将加入Babel，这样我们就能将ES6直接转换成ES5了：\n\n\tnpm install --save-dev babel\n\n我们还需要些库来用于写单元测试：\n\n\tnpm install --save-dev mocha chai\n\n[Mocha](https://mochajs.org/)是一个我们将要使用的测试框架，[Chai](http://chaijs.com/)是一个我们用来测试的断言库。\n\n我们将使用下面的mocha命令来跑测试项：\n\n\t./node_modules/mocha/bin/mocha --compilers js:babel/register --recursive\n\n这条命令告诉Mocha递归的去项目中查找并执行所有测试项，但执行前先使用Babel进行语法转换。\n\n为了使用方便，可以在我们的*package.json*中添加下面这段代码：\n\n\t\"scripts\": {\n  \t\t\"test\": \"mocha --compilers js:babel/register --recursive\"\n\t},\n\n这样以后我们跑测试就只需要执行：\n\n\tnpm run test\n\n另外，我们还可以添加*test:watch*命令，它用来监控文件变化并自动跑测试项：\n\n\t\"scripts\": {\n  \t\t\"test\": \"mocha --compilers js:babel/register --recursive\",\n  \t\t\"test:watch\": \"npm run test -- --watch\"\n\t},\n\n我们还将用到一个库，来自于facebook：[Immutable](http://facebook.github.io/immutable-js/)，它提供了许多数据结构供我们使用。下一小节我们再来讨论Immutable，但我们在这里先将它加入到我们的项目中，附带[chai-immutable](https://github.com/astorije/chai-immutable)库，它用来向Chai库加入不可变数据结构比对功能：\n\n\tnpm install --save immutable\n\tnpm install --save-dev chai-immutable\n\n我们需要在所有测试代码前先加入chai-immutable插件，所以我们来先创建一个测试辅助文件：\n\n\t//test/test_helper.js\n\n\timport chai from 'chai';\n\timport chaiImmutable from 'chai-immutable';\n\n\tchai.use(chaiImmutable);\n\n然后我们需要让Mocha在开始跑测试之前先加载这个文件，修改package.json：\n\n\t\"scripts\": {\n  \t\t\"test\": \"mocha --compilers js:babel/register --\t\trequire ./test/test_helper.js  --recursive\",\n  \t\t\"test:watch\": \"npm run test -- --watch\"\n\t},\n\n好了，准备的差不多了。\n\n###酸爽的Immutable\n\n第二个值得重视的点是，Redux架构下状态并非只是一个普通的tree，而是一棵不可变的tree。\n\n回想一下前面我们设计的状态tree，你可能会觉得可以直接在应用的代码里直接更新tree：修改映射的值，或删除数组元素等。然而，这并不是Redux允许的。\n\n一个Redux应用的状态树是不可变的数据结构。这意味着，一旦你得到了一棵状态树，它就不会在改变了。任何用户行为改变应用状态，你都会获取一棵映射应用改变后新状态的完整状态树。\n\n这说明任何连续的状态（改变前后）都被分别存储在独立的两棵树。你通过调用一个函数来从一种状态转入下一个状态。\n\n![](http://teropa.info/images/vote_state_succession.png)\n\n这么做好在哪呢？第一，用户通常想一个undo功能，当你误操作导致破坏了应用状态后，你往往想退回到应用的历史状态，而单一的状态tree让该需求变得廉价，你只需要简单保存上一个状态tree的数据即可。你也可以序列化tree并存储起来以供将来重放，这对debug很有帮助的。\n\n抛开其它的特性不谈，不可变数据至少会让你的代码变得简单，这非常重要。你可以用纯函数来进行编程：接受参数数据，返回数据，其它啥都不做。这种函数拥有可预见性，你可以多次调用它，只要参数一致，它总返回相同的结果（冪等性）。测试将变的容易，你不需要在测试前创建太多的准备，仅仅是传入参数和返回值。\n\n不可变数据结构是我们创建应用状态的基础，让我们花点时间来写一些测试项来保证它的正常工作。\n\n为了更了解不可变性，我们来看一个十分简单的数据结构：假设我们有一个计数应用，它只包含一个计数器变量，该变量会从0增加到1，增加到2，增加到3，以此类推。\n\n如果用不可变数据来设计这个计数器变量，则每当计数器自增，我们不是去改变变量本身。你可以想象成该计数器变量没有“setters”方法，你不能执行`42.setValue(43)`。\n\n每当变化发生，我们将获得一个新的变量，它的值是之前的那个变量的值加1等到的。我们可以为此写一个纯函数，它接受一个参数代表当前的状态，并返回一个值表示新的状态。记住，调用它并会修改传入参数的值。这里看一下函数实现和测试代码：\n\n\t//test/immutable_spec.js\n\n\timport {expect} from 'chai';\n\n\tdescribe('immutability', () => {\n\n  \t\tdescribe('a number', () => {\n\n    \t\tfunction increment(currentState) {\n      \t\t\treturn currentState + 1;\n    \t\t}\n\n    \t\tit('is immutable', () => {\n      \t\t\tlet state = 42;\n      \t\t\tlet nextState = increment(state);\n\n      \t\t\texpect(nextState).to.equal(43);\n      \t\t\texpect(state).to.equal(42);\n    \t\t});\n\n  \t\t});\n\t});\n\n可以看到当`increment`调用后`state`并没有被修改，这是因为`Numbers`是不可变的。\n\n我们接下来要做的是让各种数据结构都不可变，而不仅仅是一个整数。\n\n利用Immutable提供的[Lists](https://facebook.github.io/immutable-js/docs/#/Listf)，我们可以假设我们的应用拥有一个电影列表的状态，并且有一个操作用来向当前列表中添加新电影，新列表数据是添加前的列表数据和新增的电影条目合并后的结果，注意，添加前的旧列表数据并没有被修改哦：\n\n\t//test/immutable_spec.json\n\n\timport {expect} from 'chai';\n\timport {List} from 'immutable';\n\n\tdescribe('immutability', () => {\n\n  \t\t// ...\n\n  \t\tdescribe('A List', () => {\n\n    \t\tfunction addMovie(currentState, movie) {\n      \t\t\treturn currentState.push(movie);\n    \t\t}\n\n    \t\tit('is immutable', () => {\n      \t\t\tlet state = List.of('Trainspotting', '28 Days Later');\n      \t\t\tlet nextState = addMovie(state, 'Sunshine');\n\n      \t\t\texpect(nextState).to.equal(List.of(\n        \t\t\t'Trainspotting',\n        \t\t\t'28 Days Later',\n        \t\t\t'Sunshine'\n      \t\t\t));\n      \t\t\texpect(state).to.equal(List.of(\n        \t\t\t'Trainspotting',\n        \t\t\t'28 Days Later'\n      \t\t\t));\n    \t\t});\n  \t\t});\n\t});\n\n如果我们使用的是原生态js数组，那么上面的`addMovie`函数并不会保证旧的状态不会被修改。这里我们使用的是Immutable List。\n\n真实软件中，一个状态树通常是嵌套了多种数据结构的：list，map以及其它类型的集合。假设状态树是一个包含了*movies*列表的hash map，添加一个电影意味着我们需要创建一个新的map，并且在新的map的*movies*元素中添加该新增数据：\n\n\t//test/immutable_spec.json\n\n\timport {expect} from 'chai';\n\timport {List, Map} from 'immutable';\n\n\tdescribe('immutability', () => {\n\n  \t\t// ...\n\n  \t\tdescribe('a tree', () => {\n\n    \t\tfunction addMovie(currentState, movie) {\n      \t\t\treturn currentState.set(\n        \t\t\t'movies',\n       \t\t\t\t currentState.get('movies').push(movie)\n      \t\t\t);\n    \t\t}\n\n    \t\tit('is immutable', () => {\n      \t\t\tlet state = Map({\n        \t\t\tmovies: List.of('Trainspotting', '28 Days Later')\n      \t\t\t});\n      \t\t\tlet nextState = addMovie(state, 'Sunshine');\n\n      \t\t\texpect(nextState).to.equal(Map({\n        \t\t\tmovies: List.of(\n          \t\t\t\t'Trainspotting',\n          \t\t\t\t'28 Days Later',\n          \t\t\t\t'Sunshine'\n        \t\t\t)\n      \t\t\t}));\n      \t\t\texpect(state).to.equal(Map({\n       \t \t\t\tmovies: List.of(\n          \t\t\t\t'Trainspotting',\n          \t\t\t\t'28 Days Later'\n        \t\t\t)\n      \t\t\t}));\n    \t\t});\n  \t\t});\n\t});\n\n该例子和前面的那个类似，主要用来展示在嵌套结构下Immutable的行为。\n\n针对类似上面这个例子的嵌套数据结构，Immutable提供了很多辅助函数，可以帮助我们更容易的定位嵌套数据的内部属性，以达到更新对应值的目的。我们可以使用一个叫`update`的方法来修改上面的代码：\n\n\t//test/immutable_spec.json\n\n\tfunction addMovie(currentState, movie) {\n  \t\treturn currentState.update('movies', movies => movies.push(movie));\n\t}\n\n现在我们很好的了解了不可变数据，这将被用于我们的应用状态。[Immutable API](https://facebook.github.io/immutable-js/docs/#/)提供了非常多的辅助函数，我们目前只是学了点皮毛。\n\n不可变数据是Redux的核心理念，但并不是必须使用Immutable库来实现这个特性。事实上，[官方Redux文档](http://rackt.github.io/redux/)使用的是原生js对象和数组，并通过简单的扩展它们来实现的。\n\n这个教程中，我们将使用Immutable库，原因如下：\n\n- 该库将使得实现不可变数据结构变得非常简单；\n- 我个人偏爱于将尽可能的使用不可变数据，如果你的数据允许直接修改，迟早会有人踩坑；\n- 不可变数据结构更新是持续的，意味着很容易产生性能平静，特别维护是非常庞大的状态树，使用原生js对象和数组意味着要频繁的进行拷贝，很容易导致性能问题。\n\n###基于纯函数实现应用逻辑\n\n根据目前我们掌握的不可变状态树和相关操作，我们可以尝试实现投票应用的逻辑。应用的核心逻辑我们拆分成：状态树结构和生成新状态树的函数集合。\n\n####加载条目\n\n首先，之前说到，应用允许“加载”一个用来投票的条目集。我们需要一个`setEntries`函数，它用来提供应用的初始化状态：\n\n\t//test/core_spec.js\n\n\timport {List, Map} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport {setEntries} from '../src/core';\n\n\tdescribe('application logic', () => {\n\n\t  describe('setEntries', () => {\n\n\t    it('adds the entries to the state', () => {\n\t      const state = Map();\n\t      const entries = List.of('Trainspotting', '28 Days Later');\n\t      const nextState = setEntries(state, entries);\n\t      expect(nextState).to.equal(Map({\n\t        entries: List.of('Trainspotting', '28 Days Later')\n\t      }));\n\t    });\n\t  });\n\t});\n\n我们目前`setEntries`函数的第一版非常简单：在状态map中创建一个`entries`键，并设置给定的条目List。\n\n\t//src/core.js\n\n\texport function setEntries(state, entries) {\n\t\treturn state.set('entries', entries);\n\t}\n\n为了方便起见，我们允许函数第二个参数接受一个原生js数组（或支持iterable的类型），但在状态树中它应该是一个Immutable List：\n\n\t//test/core_spec.js\n\n\tit('converts to immutable', () => {\n\t  const state = Map();\n\t  const entries = ['Trainspotting', '28 Days Later'];\n\t  const nextState = setEntries(state, entries);\n\t  expect(nextState).to.equal(Map({\n\t    entries: List.of('Trainspotting', '28 Days Later')\n\t  }));\n\t});\n\n为了达到要求，我们需要修改一下代码：\n\n\t//src/core.js\n\n\timport {List} from 'immutable';\n\n\texport function setEntries(state, entries) {\n\t  return state.set('entries', List(entries));\n\t}\n\n####开始投票\n\n当state加载了条目集合后，我们可以调用一个`next`函数来开始投票。这表示，我们到了之前设计的状态树的第二阶段。\n\n`next`函数需要在状态树创建中一个投票map，该map有拥有一个`pair`键，值为投票条目中的前两个元素。\n这两个元素一旦确定，就要从之前的条目列表中清除：\n\n\t//test/core_spec.js\n\n\timport {List, Map} from 'immutable';\n\timport {expect} from 'chai';\n\timport {setEntries, next} from '../src/core';\n\n\tdescribe('application logic', () => {\n\n\t  // ..\n\n\t  describe('next', () => {\n\n\t    it('takes the next two entries under vote', () => {\n\t      const state = Map({\n\t        entries: List.of('Trainspotting', '28 Days Later', 'Sunshine')\n\t      });\n\t      const nextState = next(state);\n\t      expect(nextState).to.equal(Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later')\n\t        }),\n\t        entries: List.of('Sunshine')\n\t      }));\n\t    });\n\t  });\n\t});\n\n`next`函数实现如下：\n\n\t//src/core.js\n\n\timport {List, Map} from 'immutable';\n\n\t// ...\n\n\texport function next(state) {\n\t  const entries = state.get('entries');\n\t  return state.merge({\n\t    vote: Map({pair: entries.take(2)}),\n\t    entries: entries.skip(2)\n\t  });\n\t}\n\n####投票\n\n当用户产生投票行为后，每当用户给某个条目投了一票后，`vote`将会为这个条目添加`tally`信息，如果对应的\n条目信息已存在，则需要则增：\n\n\t//test/core_spec.js\n\n\timport {List, Map} from 'immutable';\n\timport {expect} from 'chai';\n\timport {setEntries, next, vote} from '../src/core';\n\n\tdescribe('application logic', () => {\n\n\t  // ...\n\n\t  describe('vote', () => {\n\n\t    it('creates a tally for the voted entry', () => {\n\t      const state = Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later')\n\t        }),\n\t        entries: List()\n\t      });\n\t      const nextState = vote(state, 'Trainspotting');\n\t      expect(nextState).to.equal(Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({\n\t            'Trainspotting': 1\n\t          })\n\t        }),\n\t        entries: List()\n\t      }));\n\t    });\n\n\t    it('adds to existing tally for the voted entry', () => {\n\t      const state = Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({\n\t            'Trainspotting': 3,\n\t            '28 Days Later': 2\n\t          })\n\t        }),\n\t        entries: List()\n\t      });\n\t      const nextState = vote(state, 'Trainspotting');\n\t      expect(nextState).to.equal(Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({\n\t            'Trainspotting': 4,\n\t            '28 Days Later': 2\n\t          })\n\t        }),\n\t        entries: List()\n\t      }));\n\t    });\n\t  });\n\t});\n\n为了让上面的测试项通过，我们可以如下实现`vote`函数：\n\n\t//src/core.js\n\n\texport function vote(state, entry) {\n\t  return state.updateIn(\n\t    ['vote', 'tally', entry],\n\t    0,\n\t    tally => tally + 1\n\t  );\n\t}\n\n[updateIn](https://facebook.github.io/immutable-js/docs/#/Map/updateIn)让我们更容易完成目标。\n它接受的第一个参数是个表达式，含义是“定位到嵌套数据结构的指定位置，路径为：['vote', 'tally', 'Trainspotting']”，\n并且执行后面逻辑：如果路径指定的位置不存在，则创建新的映射对，并初始化为0，否则对应值加1。\n\n可能对你来说上面的语法太过于晦涩，但一旦你掌握了它，你将会发现用起来非常的酸爽，所以花一些时间学习并\n适应它是非常值得的。\n\n####继续投票\n\n每次完成一次二选一投票，用户将进入到第二轮投票，每次得票最高的选项将被保存并添加回条目集合。我们需要添加\n这个逻辑到`next`函数中：\n\n\t//test/core_spec.js\n\n\tdescribe('next', () => {\n\n\t  // ...\n\n\t  it('puts winner of current vote back to entries', () => {\n\t    const state = Map({\n\t      vote: Map({\n\t        pair: List.of('Trainspotting', '28 Days Later'),\n\t        tally: Map({\n\t          'Trainspotting': 4,\n\t          '28 Days Later': 2\n\t        })\n\t      }),\n\t      entries: List.of('Sunshine', 'Millions', '127 Hours')\n\t    });\n\t    const nextState = next(state);\n\t    expect(nextState).to.equal(Map({\n\t      vote: Map({\n\t        pair: List.of('Sunshine', 'Millions')\n\t      }),\n\t      entries: List.of('127 Hours', 'Trainspotting')\n\t    }));\n\t  });\n\n\t  it('puts both from tied vote back to entries', () => {\n\t    const state = Map({\n\t      vote: Map({\n\t        pair: List.of('Trainspotting', '28 Days Later'),\n\t        tally: Map({\n\t          'Trainspotting': 3,\n\t          '28 Days Later': 3\n\t        })\n\t      }),\n\t      entries: List.of('Sunshine', 'Millions', '127 Hours')\n\t    });\n\t    const nextState = next(state);\n\t    expect(nextState).to.equal(Map({\n\t      vote: Map({\n\t        pair: List.of('Sunshine', 'Millions')\n\t      }),\n\t      entries: List.of('127 Hours', 'Trainspotting', '28 Days Later')\n\t    }));\n\t  });\n\t});\n\n我们需要一个`getWinners`函数来帮我们选择谁是赢家：\n\n\t//src/core.js\n\n\tfunction getWinners(vote) {\n\t  if (!vote) return [];\n\t  const [a, b] = vote.get('pair');\n\t  const aVotes = vote.getIn(['tally', a], 0);\n\t  const bVotes = vote.getIn(['tally', b], 0);\n\t  if      (aVotes > bVotes)  return [a];\n\t  else if (aVotes < bVotes)  return [b];\n\t  else                       return [a, b];\n\t}\n\n\texport function next(state) {\n\t  const entries = state.get('entries')\n\t                       .concat(getWinners(state.get('vote')));\n\t  return state.merge({\n\t    vote: Map({pair: entries.take(2)}),\n\t    entries: entries.skip(2)\n\t  });\n\t}\n\n####投票结束\n\n当投票项只剩一个时，投票结束：\n\n\t//test/core_spec.js\n\n\tdescribe('next', () => {\n\n\t  // ...\n\n\t  it('marks winner when just one entry left', () => {\n\t    const state = Map({\n\t      vote: Map({\n\t        pair: List.of('Trainspotting', '28 Days Later'),\n\t        tally: Map({\n\t          'Trainspotting': 4,\n\t          '28 Days Later': 2\n\t        })\n\t      }),\n\t      entries: List()\n\t    });\n\t    const nextState = next(state);\n\t    expect(nextState).to.equal(Map({\n\t      winner: 'Trainspotting'\n\t    }));\n\t  });\n\t});\n\n我们需要在`next`函数中增加一个条件分支，用来匹配上面的逻辑：\n\n\t//src/core.js\n\n\texport function next(state) {\n\t  const entries = state.get('entries')\n\t                       .concat(getWinners(state.get('vote')));\n\t  if (entries.size === 1) {\n\t    return state.remove('vote')\n\t                .remove('entries')\n\t                .set('winner', entries.first());\n\t  } else {\n\t    return state.merge({\n\t      vote: Map({pair: entries.take(2)}),\n\t      entries: entries.skip(2)\n\t    });\n\t  }\n\t}\n\n我们可以直接返回`Map({winner: entries.first()})`，但我们还是基于旧的状态数据进行一步一步的\n操作最终得到结果，这么做是为将来做打算。因为应用将来可能还会有很多其它状态数据在Map中，这是一个写测试项的好习惯。\n所以我们以后要记住，不要重新创建一个状态数据，而是从旧的状态数据中生成新的状态实例。\n\n到此为止我们已经有了一套可以接受的应用核心逻辑实现，表现形式为几个独立的函数。我们也有针对这些函数的\n测试代码，这些测试项很容易写：No setup, no mocks, no stubs。这就是纯函数的魅力，我们只需要调用它们，\n并检查返回值就行了。\n\n提醒一下，我们目前还没有安装redux哦，我们就已经可以专注于应用自身的逻辑本身进行实现，而不被所谓的框架\n所干扰。这真的很不错，对吧？\n\n###初识Actions和Reducers\n\n我们有了应用的核心函数，但在Redux中我们不应该直接调用函数。在这些函数和应用之间还存在这一个中间层：Actions。\n\nAction是一个描述应用状态变化发生的简单数据结构。按照约定，每个action都包含一个`type`属性，\n该属性用于描述操作类型。action通常还包含其它属性，下面是一个简单的action例子，该action用来匹配\n前面我们写的业务操作：\n\n\t{type: 'SET_ENTRIES', entries: ['Trainspotting', '28 Days Later']}\n\n\t{type: 'NEXT'}\n\n\t{type: 'VOTE', entry: 'Trainspotting'}\n\nactions的描述就这些，但我们还需要一种方式用来把它绑定到我们实际的核心函数上。举个例子：\n\n\t// 定义一个action\n\tlet voteAction = {type: 'VOTE', entry: 'Trainspotting'}\n\t// 该action应该触发下面的逻辑\n\treturn vote(state, voteAction.entry);\n\n我们接下来要用到的是一个普通函数，它用来根据action和当前state来调用指定的核心函数，我们称这种函数叫：\nreducer：\n\n\t//src/reducer.js\n\n\texport default function reducer(state, action) {\n\t  // Figure out which function to call and call it\n\t}\n\n我们应该测试这个reducer是否可以正确匹配我们之前的三个actions：\n\n\t//test/reducer_spec.js\n\n\timport {Map, fromJS} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport reducer from '../src/reducer';\n\n\tdescribe('reducer', () => {\n\n\t  it('handles SET_ENTRIES', () => {\n\t    const initialState = Map();\n\t    const action = {type: 'SET_ENTRIES', entries: ['Trainspotting']};\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      entries: ['Trainspotting']\n\t    }));\n\t  });\n\n\t  it('handles NEXT', () => {\n\t    const initialState = fromJS({\n\t      entries: ['Trainspotting', '28 Days Later']\n\t    });\n\t    const action = {type: 'NEXT'};\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later']\n\t      },\n\t      entries: []\n\t    }));\n\t  });\n\n\t  it('handles VOTE', () => {\n\t    const initialState = fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later']\n\t      },\n\t      entries: []\n\t    });\n\t    const action = {type: 'VOTE', entry: 'Trainspotting'};\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      },\n\t      entries: []\n\t    }));\n\t  });\n\t});\n\n我们的reducer将根据action的type来选择对应的核心函数，它同时也应该知道如何使用action的额外属性：\n\n\t//src/reducer.js\n\n\timport {setEntries, next, vote} from './core';\n\n\texport default function reducer(state, action) {\n\t  switch (action.type) {\n\t  case 'SET_ENTRIES':\n\t    return setEntries(state, action.entries);\n\t  case 'NEXT':\n\t    return next(state);\n\t  case 'VOTE':\n\t    return vote(state, action.entry)\n\t  }\n\t  return state;\n\t}\n\n注意，如果reducer没有匹配到action，则应该返回当前的state。\n\nreducers还有一个需要特别注意的地方，那就是当传递一个未定义的state参数时，reducers应该知道如何\n初始化state为有意义的值。我们的场景中，初始值为Map，因此如果传给reducer一个`undefined`state的话，\nreducers将使用一个空的Map来代替：\n\n\t//test/reducer_spec.js\n\n\tdescribe('reducer', () => {\n\n\t  // ...\n\n\t  it('has an initial state', () => {\n\t    const action = {type: 'SET_ENTRIES', entries: ['Trainspotting']};\n\t    const nextState = reducer(undefined, action);\n\t    expect(nextState).to.equal(fromJS({\n\t      entries: ['Trainspotting']\n\t    }));\n\t  });\n\t});\n\n之前在我们的`cores.js`文件中，我们定义了初始值：\n\n\t//src/core.js\n\n\texport const INITIAL_STATE = Map();\n\n所以在reducer中我们可以直接导入它：\n\n\t//src/reducer.js\n\n\timport {setEntries, next, vote, INITIAL_STATE} from './core';\n\n\texport default function reducer(state = INITIAL_STATE, action) {\n\t  switch (action.type) {\n\t  case 'SET_ENTRIES':\n\t    return setEntries(state, action.entries);\n\t  case 'NEXT':\n\t    return next(state);\n\t  case 'VOTE':\n\t    return vote(state, action.entry)\n\t  }\n\t  return state;\n\t}\n\n事实上，提供一个action集合，你可以将它们分解并作用在当前状态上，这也是为什么称它们为reducer的原因：\n它完全适配reduce方法：\n\n\t//test/reducer_spec.js\n\n\tit('can be used with reduce', () => {\n\t  const actions = [\n\t    {type: 'SET_ENTRIES', entries: ['Trainspotting', '28 Days Later']},\n\t    {type: 'NEXT'},\n\t    {type: 'VOTE', entry: 'Trainspotting'},\n\t    {type: 'VOTE', entry: '28 Days Later'},\n\t    {type: 'VOTE', entry: 'Trainspotting'},\n\t    {type: 'NEXT'}\n\t  ];\n\t  const finalState = actions.reduce(reducer, Map());\n\n\t  expect(finalState).to.equal(fromJS({\n\t    winner: 'Trainspotting'\n\t  }));\n\t});\n\n相比直接调用核心业务函数，这种批处理或称之为重放一个action集合的能力主要依赖于状态转换的action/reducer模型。\n举个例子，你可以把actions序列化成json，并轻松的将它发送给Web Worker去执行你的reducer逻辑。或者\n直接通过网络发送到其它地方供日后执行！\n\n注意我们这里使用的是普通js对象作为actions，而并非不可变数据类型。这是Redux提倡我们的做法。\n\n###尝试Reducer协作\n\n目前我们的核心函数都是接受整个state并返回更新后的整个state。\n\n这么做在大型应用中可能并不太明智。如果你的应用所有操作都要求必须接受完整的state，那么这个项目维护起来就是灾难。\n日后如果你想进行state结构的调整，你将会付出惨痛的代价。\n\n其实有更好的做法，你只需要保证组件操作尽可能小的state片段即可。我们这里提到的就是模块化思想：\n提供给模块仅它需要的数据，不多不少。\n\n我们的应用很小，所以这并不是太大的问题，但我们还是选择改善这一点：没有必要给`vote`函数传递整个state，它只需要`vote`\n部分。让我们修改一下对应的测试代码：\n\n\t//test/core_spec.js\n\n\tdescribe('vote', () => {\n\n\t  it('creates a tally for the voted entry', () => {\n\t    const state = Map({\n\t      pair: List.of('Trainspotting', '28 Days Later')\n\t    });\n\t    const nextState = vote(state, 'Trainspotting')\n\t    expect(nextState).to.equal(Map({\n\t      pair: List.of('Trainspotting', '28 Days Later'),\n\t      tally: Map({\n\t        'Trainspotting': 1\n\t      })\n\t    }));\n\t  });\n\n\t  it('adds to existing tally for the voted entry', () => {\n\t    const state = Map({\n\t      pair: List.of('Trainspotting', '28 Days Later'),\n\t      tally: Map({\n\t        'Trainspotting': 3,\n\t        '28 Days Later': 2\n\t      })\n\t    });\n\t    const nextState = vote(state, 'Trainspotting');\n\t    expect(nextState).to.equal(Map({\n\t      pair: List.of('Trainspotting', '28 Days Later'),\n\t      tally: Map({\n\t        'Trainspotting': 4,\n\t        '28 Days Later': 2\n\t      })\n\t    }));\n\t  });\n\t});\n\n看，测试代码更加简单了。\n\n`vote`函数的实现也需要更新：\n\n\t//src/core.js\n\n\texport function vote(voteState, entry) {\n\t  return voteState.updateIn(\n\t    ['tally', entry],\n\t    0,\n\t    tally => tally + 1\n\t  );\n\t}\n\n最后我们还需要修改`reducer`，只传递需要的state给`vote`函数：\n\n\t//src/reducer.js\n\n\texport default function reducer(state = INITIAL_STATE, action) {\n\t  switch (action.type) {\n\t  case 'SET_ENTRIES':\n\t    return setEntries(state, action.entries);\n\t  case 'NEXT':\n\t    return next(state);\n\t  case 'VOTE':\n\t    return state.update('vote',\n\t                        voteState => vote(voteState, action.entry));\n\t  }\n\t  return state;\n\t}\n\n这个做法在大型项目中非常重要：根reducer只传递部分state给下一级reducer。我们将定位合适的state片段的工作\n从对应的更新操作中分离出来。\n\n[Redux的reducers文档](http://rackt.github.io/redux/docs/basics/Reducers.html)针对这一细节\n介绍了更多内容，并描述了一些辅助函数的用法，可以在更多长场景中有效的使用。\n\n###初识Redux Store\n\n现在我们可以开始了解如何将上面介绍的内容使用在Redux中了。\n\n如你所见，如果你有一个actions集合，你可以调用`reduce`，获得最终的应用状态。当然，通常情况下不会如此，actions\n将会在不同的时间发生：用户操作，远程调用，超时触发器等。\n\n针对这些情况，我们可以使用Redux Store。从名字可以看出它用来存储应用的状态。\n\nRedux Store通常会由一个reducer函数初始化，如我们之前实现的：\n\n\timport {createStore} from 'redux';\n\n\tconst store = createStore(reducer);\n\n接下来你就可以向这个Store指派actions了。Store内部将会使用你实现的reducer来处理action，并负责传递给\nreducer应用的state，最后负责存储reducer返回的新state：\n\n\tstore.dispatch({type: 'NEXT'});\n\n任何时刻你都可以通过下面的方法获取当前的state：\n\n\tstore.getState();\n\n我们将会创建一个`store.js`用来初始化和导出一个Redux Store对象。让我们先写测试代码吧：\n\n\t//test/store_spec.js\n\n\timport {Map, fromJS} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport makeStore from '../src/store';\n\n\tdescribe('store', () => {\n\n\t  it('is a Redux store configured with the correct reducer', () => {\n\t    const store = makeStore();\n\t    expect(store.getState()).to.equal(Map());\n\n\t    store.dispatch({\n\t      type: 'SET_ENTRIES',\n\t      entries: ['Trainspotting', '28 Days Later']\n\t    });\n\t    expect(store.getState()).to.equal(fromJS({\n\t      entries: ['Trainspotting', '28 Days Later']\n\t    }));\n\t  });\n\t});\n\n在创建Store之前，我们先在项目中加入Redux库：\n\n\tnpm install --save redux\n\n然后我们新建`store.js`文件，如下：\n\n\t//src/store.js\n\n\timport {createStore} from 'redux';\n\timport reducer from './reducer';\n\n\texport default function makeStore() {\n\t  return createStore(reducer);\n\t}\n\nRedux Store负责将应用的所有组件关联起来：它持有应用的当前状态，并负责指派actions，且负责调用包含了\n业务逻辑的reducer。\n\n应用的业务代码和Redux的整合方式非常引人注目，因为我们只有一个普通的reducer函数，这是唯一需要告诉Redux\n的事儿。其它部分全部都是我们自己的，没有框架入侵的，高便携的纯函数代码！\n\n现在我们创建一个应用的入口文件`index.js`：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\n\texport const store = makeStore();\n\n现在我们可以开启一个[Node REPL](http://segmentfault.com/a/1190000002673137)（例如babel-node）,\n载入`index.js`文件来测试执行了。\n\n###配置Socket.io服务\n\n我们的应用服务端用来为一个提供投票和显示结果浏览器端提供服务的，为了这个目的，我们需要考虑两端通信的方式。\n\n这个应用需要实时通信，这确保我们的投票者可以实时查看到所有人的投票信息。为此，我们选择使用WebSockets作为\n通信方式。因此，我们选择[Socket.io](http://socket.io/)库作为跨终端的websocket抽象实现层，它在客户端\n不支持websocket的情况下提供了多种备选方案。\n\n让我们在项目中加入Socket.io：\n\n\tnpm install --save socket.io\n\n现在，让我新建一个`server.js`文件：\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport default function startServer() {\n\tconst io = new Server().attach(8090);\n\t}\n\n这里我们创建了一个Socket.io 服务，绑定8090端口。端口号是我随意选的，你可以更改，但后面客户端连接时\n要注意匹配。\n\n现在我们可以在`index.js`中调用这个函数：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\timport startServer from './src/server';\n\n\texport const store = makeStore();\n\tstartServer();\n\n我们现在可以在`package.json`中添加`start`指令来方便启动应用：\n\n\t//package.json\n\t\"scripts\": {\n\t\t\"start\": \"babel-node index.js\",\n\t\t\"test\": \"mocha --compilers js:babel/register  --require ./test/test_helper.js  --recursive\",\n\t\t\"test:watch\": \"npm run test --watch\"\n\t},\n\n这样我们就可以直接执行下面命令来开启应用：\n\n\tnpm run start\n\n###用Redux监听器传播State\n\n我们现在拥有了一个Socket.io服务，也建立了Redux状态容器，但它们并没有整合在一起，这就是我们接下来要做的事儿。\n\n我们的服务端需要让客户端知道当前的应用状态（例如：“正在投票的项目是什么？”，“当前的票数是什么？”，\n“已经出来结果了吗？”）。这些都可以通过每当变化发生时[触发Socket.io事件](http://socket.io/docs/server-api/#server#emit)来实现。\n\n我们如何得知什么时候发生变化？Redux对此提供了方案：你可以订阅Redux Store。这样每当store指派了action之后，在可能发生变化前\n会调用你提供的指定回调函数。\n\n我们要修改一下`startServer`实现，我们先来调整一下index.js：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\timport {startServer} from './src/server';\n\n\texport const store = makeStore();\n\tstartServer(store);\n\n接下来我们只需监听store的状态，并把它序列化后用socket.io事件传播给所有处于连接状态的客户端。\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport function startServer(store) {\n\t  const io = new Server().attach(8090);\n\n\t  store.subscribe(\n\t    () => io.emit('state', store.getState().toJS())\n\t  );\n\t}\n\n目前我们的做法是一旦状态有改变，就发送整个state给所有客户端，很容易想到这非常不友好，产生大量流量\n损耗，更好的做法是只传递改变的state片段，但我们为了简单，在这个例子中就先这么实现吧。\n\n除了状态发生变化时发送状态数据外，每当新客户端连接服务器端时也应该直接发送当前的状态给该客户端。\n\n我们可以通过监听Socket.io的`connection`事件来实现上述需求：\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport function startServer(store) {\n\t  const io = new Server().attach(8090);\n\n\t  store.subscribe(\n\t    () => io.emit('state', store.getState().toJS())\n\t  );\n\n\t  io.on('connection', (socket) => {\n\t    socket.emit('state', store.getState().toJS());\n\t  });\n\t}\n\n###接受远程调用Redux Actions\n\n除了将应用状态同步给客户端外，我们还需要接受来自客户端的更新操作：投票者需要发起投票，投票组织者需要\n发起下一轮投票的请求。\n\n我们的解决方案非常简单。我们只需要让客户端发布“action”事件即可，然后我们直接将事件发送给Redux Store：\n\n\t//src/server.js\n\n\timport Server from 'socket.io';\n\n\texport function startServer(store) {\n\t  const io = new Server().attach(8090);\n\n\t  store.subscribe(\n\t    () => io.emit('state', store.getState().toJS())\n\t  );\n\n\t  io.on('connection', (socket) => {\n\t    socket.emit('state', store.getState().toJS());\n\t    socket.on('action', store.dispatch.bind(store));\n\t  });\n\t}\n\n这样我们就完成了远程调用actions。Redux架构让我们的项目更加简单：actions仅仅是js对象，可以很容易用于\n网络传输，我们现在实现了一个支持多人投票的服务端系统，很有成就感吧。\n\n现在我们的服务端操作流程如下：\n\n1. 客户端发送一个action给服务端；\n2. 服务端交给Redux Store处理action；\n3. Store调用reducer，reducer执行对应的应用逻辑；\n4. Store根据reducer的返回结果来更新状态；\n5. Store触发服务端监听的回调函数；\n6. 服务端触发“state”事件；\n7. 所有连接的客户端接受到新的状态。\n\n在结束服务端开发之前，我们载入一些测试数据来感受一下。我们可以添加`entries.json`文件：\n\n\t//entries.json\n\n\t[\n\t  \"Shallow Grave\",\n\t  \"Trainspotting\",\n\t  \"A Life Less Ordinary\",\n\t  \"The Beach\",\n\t  \"28 Days Later\",\n\t  \"Millions\",\n\t  \"Sunshine\",\n\t  \"Slumdog Millionaire\",\n\t  \"127 Hours\",\n\t  \"Trance\",\n\t  \"Steve Jobs\"\n\t]\n\n我们在`index.json`中加载它然后发起`next`action来开启投票：\n\n\t//index.js\n\n\timport makeStore from './src/store';\n\timport {startServer} from './src/server';\n\n\texport const store = makeStore();\n\tstartServer(store);\n\n\tstore.dispatch({\n\t  type: 'SET_ENTRIES',\n\t  entries: require('./entries.json')\n\t});\n\tstore.dispatch({type: 'NEXT'});\n\n那么接下来我们就来看看如何实现客户端。\n\n##客户端应用\n\n本教程剩余的部分就是写一个React应用，用来连接服务端，并提供投票给使用者。\n\n在客户端我们依然使用Redux。这是更常见的搭配：用于React应用的底层引擎。我们已经了解到Redux如何使用。\n现在我们将学习它是如何结合并影响React应用的。\n\n我推荐大家跟随本教程的步骤完成应用，但你也可以从[github](https://github.com/teropa/redux-voting-client)上获取源码。\n\n###客户端项目创建\n\n第一件事儿我们当然是创建一个新的NPM项目，如下：\n\n\tmkdir voting-client\n\tcd voting-client\n\tnpm init            # Just hit enter for each question\n\n我们的应用需要一个html主页，我们放在`dist/index.html`：\n\n\t//dist/index.html\n\n\t<!DOCTYPE html>\n\t<html>\n\t<body>\n\t  <div id=\"app\"></div>\n\t  <script src=\"bundle.js\"></script>\n\t</body>\n\t</html>\n\n这个页面包含一个id为app的`<div>`，我们将在其中插入我们的应用。在同级目录下还需要一个`bundle.js`文件。\n\n我们为应用新建第一个js文件，它是系统的入口文件。目前我们先简单的添加一行日志代码：\n\n\t//src/index.js\n\tconsole.log('I am alive!');\n\n为了给我们客户端开发减负，我们将使用[Webpack](http://webpack.github.io/)，让我们加入到项目中：\n\n\tnpm install --save-dev webpack webpack-dev-server\n\n接下来，我们在项目根目录新建一个Webpack配置文件：\n\n\t//webpack.config.js\n\n\tmodule.exports = {\n\t  entry: [\n\t    './src/index.js'\n\t  ],\n\t  output: {\n\t    path: __dirname + '/dist',\n\t    publicPath: '/',\n\t    filename: 'bundle.js'\n\t  },\n\t  devServer: {\n\t    contentBase: './dist'\n\t  }\n\t};\n\n配置表明将找到我们的`index.js`入口，并编译到`dist/bundle.js`中。同时把`dist`目录当作开发服务器根目录。\n\n你现在可以执行Webpack来生成`bundle.js`：\n\n\twebpack\n\n你也可以开启一个开发服务器，访问localhost:8080来测试页面效果：\n\n\twebpack-dev-server\n\n由于我们将使用ES6语法和React的[JSX语法](https://facebook.github.io/jsx/)，我们需要一些工具。\nBabel是一个非常合适的选择，我们需要Babel库：\n\n\tnpm install --save-dev babel-core babel-loader\n\n我们可以在Webpack配置文件中添加一些配置，这样webpack将会对`.jsx`和`.js`文件使用Babel进行处理：\n\n\t//webpack.config.js\n\n\tmodule.exports = {\n\t\tentry: [\n\t\t\t'./src/index.js'\n\t\t],\n\t\tmodule: {\n\t\t\tloaders: [{\n\t\t\t\ttest: /\\.jsx?$/,\n\t\t\t\texclude: /node_modules/,\n\t\t\t\tloader: 'babel'\n\t\t\t}]\n\t\t},\n\t\tresolve: {\n\t\t\textensions: ['', '.js', '.jsx']\n\t\t},\n\t\toutput: {\n\t\t\tpath: __dirname + '/dist',\n\t\t\tpublicPath: '/',\n\t\t\tfilename: 'bundle.js'\n\t\t},\n\t\tdevServer: {\n\t\t\tcontentBase: './dist'\n\t\t}\n\t};\n\n\n###单元测试支持\n\n我们也将会为客户端代码编写一些单元测试。我们使用与服务端相同的测试套件：\n\n\tnpm install --save-dev mocha chai\n\n我们也将会测试我们的React组件，这就要求需要一个DOM库。我们可能需要像[Karma](http://karma-runner.github.io/0.13/index.html)\n库一样的功能来进行真实web浏览器测试。但我们这里准备使用一个node端纯js的dom库：\n\n\tnpm install --save-dev jsdom@3\n\n在用于react之前我们需要一些jsdom的预备代码。我们需要创建通常在浏览器端被提供的`document`和`window`对象。\n并且将它们声明为全局对象，这样才能被React使用。我们可以创建一个测试辅助文件做这些工作：\n\n\t//test/test_helper.js\n\n\timport jsdom from 'jsdom';\n\n\tconst doc = jsdom.jsdom('<!doctype html><html><body></body></html>');\n\tconst win = doc.defaultView;\n\n\tglobal.document = doc;\n\tglobal.window = win;\n\n此外，我们还需要将jsdom提供的`window`对象的所有属性导入到Node.js的全局变量中，这样使用这些属性时\n就不需要`window.`前缀，这才满足在浏览器环境下的用法：\n\n\t//test/test_helper.js\n\n\timport jsdom from 'jsdom';\n\n\tconst doc = jsdom.jsdom('<!doctype html><html><body></body></html>');\n\tconst win = doc.defaultView;\n\n\tglobal.document = doc;\n\tglobal.window = win;\n\n\tObject.keys(window).forEach((key) => {\n\t  if (!(key in global)) {\n\t    global[key] = window[key];\n\t  }\n\t});\n\n我们还需要使用Immutable集合，所以我们也需要参照后段配置添加相应的库：\n\n\tnpm install --save immutable\n\tnpm install --save-dev chai-immutable\n\n现在我们再次修改辅助文件：\n\n\t//test/test_helper.js\n\n\timport jsdom from 'jsdom';\n\timport chai from 'chai';\n\timport chaiImmutable from 'chai-immutable';\n\n\tconst doc = jsdom.jsdom('<!doctype html><html><body></body></html>');\n\tconst win = doc.defaultView;\n\n\tglobal.document = doc;\n\tglobal.window = win;\n\n\tObject.keys(window).forEach((key) => {\n\t  if (!(key in global)) {\n\t    global[key] = window[key];\n\t  }\n\t});\n\n\tchai.use(chaiImmutable);\n\n最后一步是在`package.json`中添加指令：\n\n\t//package.json\n\n\t\"scripts\": {\n\t  \"test\": \"mocha --compilers js:babel-core/register --require ./test/test_helper.js 'test/**/*.@(js|jsx)'\"\n\t},\n\n这几乎和我们在后端做的一样，只有两个地方不同：\n\n- Babel的编译器名称：在该项目中我们使用`babel-core`代替`babel`\n- 测试文件设置：服务端我们使用`--recursive`，但这么设置无法匹配`.jsx`文件，所以我们需要使用\n[glob](https://github.com/isaacs/node-glob)\n\n为了实现当代码发生修改后自动进行测试，我们依然添加`test:watch`指令：\n\n\t//package.json\n\n\t\"scripts\": {\n\t  \"test\": \"mocha --compilers js:babel-core/register --require ./test/test_helper.js 'test/**/*.@(js|jsx)'\",\n\t  \"test:watch\": \"npm run test -- --watch\"\n\t},\n\n###React和react-hot-loader\n\n最后我们来聊聊React！\n\n使用React+Redux+Immutable来开发应用真正酷毙的地方在于：我们可以用纯组件（有时候也称为蠢组件）思想实现\n任何东西。这个概念与纯函数很类似，有如下一些规则：\n\n1. 一个纯组件利用props接受所有它需要的数据，类似一个函数的入参，除此之外它不会被任何其它因素影响；\n2. 一个纯组件通常没有内部状态。它用来渲染的数据完全来自于输入props，使用相同的props来渲染相同的纯组件多次，\n将得到相同的UI。不存在隐藏的内部状态导致渲染不同。\n\n这就带来了[一个和使用纯函数一样的效果](https://www.youtube.com/watch?v=1uRC3hmKQnM&feature=youtu.be&t=13m10s)：\n我们可以根据输入来预测一个组件的渲染，我们不需要知道组件的其它信息。这也使得我们的界面测试变得很简单，\n与我们测试纯应用逻辑一样简单。\n\n如果组件不包含状态，那么状态放在哪？当然在不可变的Store中啊！我们已经见识过它是怎么运作的了，其\n最大的特点就是从界面代码中分离出状态。\n\n在此之前，我们还是先给项目添加React：\n\n\tnpm install --save react\n\n我们同样需要[react-hot-loader](https://github.com/gaearon/react-hot-loader)。它让我们的开发\n变得非常快，因为它提供了我们在不丢失当前状态的情况下重载代码的能力：\n\n\tnpm install --save-dev react-hot-loader\n\n我们需要更新一下`webpack.config.js`，使其能热加载：\n\n\t//webpack.config.js\n\n\tvar webpack = require('webpack');\n\n\tmodule.exports = {\n\t  entry: [\n\t    'webpack-dev-server/client?http://localhost:8080',\n\t    'webpack/hot/only-dev-server',\n\t    './src/index.js'\n\t  ],\n\t  module: {\n\t    loaders: [{\n\t      test: /\\.jsx?$/,\n\t      exclude: /node_modules/,\n\t      loader: 'react-hot!babel'\n\t    }],\n\t  }\n\t  resolve: {\n\t    extensions: ['', '.js', '.jsx']\n\t  },\n\t  output: {\n\t    path: __dirname + '/dist',\n\t    publicPath: '/',\n\t    filename: 'bundle.js'\n\t  },\n\t  devServer: {\n\t    contentBase: './dist',\n\t    hot: true\n\t  },\n\t  plugins: [\n\t    new webpack.HotModuleReplacementPlugin()\n\t  ]\n\t};\n\n在上述配置的`entry`里我们包含了2个新的应用入口点：webpack dev server和webpack hot module loader。\n它们提供了webpack模块热替换能力。该能力并不是默认加载的，所以上面我们才需要在`plugins`和`devServer`\n中手动加载。\n\n配置的`loaders`部分我们在原先的Babel前配置了`react-hot`用于`.js`和`.jsx`文件。\n\n如果你现在重启开发服务器，你将看到一个在终端看到Hot Module Replacement已开启的消息提醒。我们可以\n开始写我们的第一个组件了。\n\n###实现投票界面\n\n应用的投票界面非常简单：一旦投票启动，它将现实2个按钮，分别用来表示2个可选项，当投票结束，它显示最终结果。\n\n![](http://teropa.info/images/voting_shots.png)\n\n我们之前都是以测试先行的开发方式，但是在react组件开发中我们将先实现组件，再进行测试。这是因为\nwebpack和react-hot-loader提供了更加优良的[反馈机制](http://blog.iterate.no/2012/10/01/know-your-feedback-loop-why-and-how-to-optimize-it/)。\n而且，也没有比直接看到界面更加好的测试UI手段了。\n\n让我们假设有一个`Voting`组件，在之前的入口文件`index.html`的`#app`div中加载它。由于我们的代码中\n包含JSX语法，所以需要把`index.js`重命名为`index.jsx`：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tReact.render(\n\t  <Voting pair={pair} />,\n\t  document.getElementById('app')\n\t);\n\n`Voting`组件将使用`pair`属性来加载数据。我们目前可以先硬编码数据，稍后我们将会用真实数据来代替。\n组件本身是纯粹的，并且对数据来源并不敏感。\n\n注意，在`webpack.config.js`中的入口点文件名也要修改：\n\n\t//webpack.config.js\n\n\tentry: [\n\t  'webpack-dev-server/client?http://localhost:8080',\n\t  'webpack/hot/only-dev-server',\n\t  './src/index.jsx'\n\t],\n\n如果你此时重启webpack-dev-server，你将看到缺失Voting组件的报错。让我们修复它：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}>\n\t          <h1>{entry}</h1>\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n你将会在浏览器上看到组件创建的2个按钮。你可以试试修改代码感受一下浏览器自动更新的魅力，没有刷新，\n没有页面加载，一切都那么迅雷不及掩耳盗铃。\n\n现在我们来添加第一个单元测试：\n\n\t//test/components/Voting_spec.jsx\n\n\timport Voting from '../../src/components/Voting';\n\n\tdescribe('Voting', () => {\n\n\t});\n\n测试组件渲染的按钮，我们必须先看看它的输出是什么。要在单元测试中渲染一个组件，我们需要`react/addons`提供\n的辅助函数[renderIntoDocument](https://facebook.github.io/react/docs/test-utils.html#renderintodocument)：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport Voting from '../../src/components/Voting';\n\n\tconst {renderIntoDocument} = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  it('renders a pair of buttons', () => {\n\t    const component = renderIntoDocument(\n\t      <Voting pair={[\"Trainspotting\", \"28 Days Later\"]} />\n\t    );\n\t  });\n\t});\n\n一旦组件渲染完毕，我就可以通过react提供的另一个辅助函数[scryRenderedDOMComponentsWithTag](https://facebook.github.io/react/docs/test-utils.html#scryrendereddomcomponentswithtag)\n来拿到`button`元素。我们期望存在两个按钮，并且期望按钮的值是我们设置的：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport Voting from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithTag}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  it('renders a pair of buttons', () => {\n\t    const component = renderIntoDocument(\n\t      <Voting pair={[\"Trainspotting\", \"28 Days Later\"]} />\n\t    );\n\t    const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\n\t    expect(buttons.length).to.equal(2);\n\t    expect(buttons[0].getDOMNode().textContent).to.equal('Trainspotting');\n\t    expect(buttons[1].getDOMNode().textContent).to.equal('28 Days Later');\n\t  });\n\t});\n\n如果我们跑一下测试，将会看到测试通过的提示：\n\n\tnpm run test\n\n当用户点击某个按钮后，组件将会调用回调函数，该函数也由组件的prop传递给组件。\n\n让我们完成这一步，我们可以通过使用React提供的测试工具[Simulate](https://facebook.github.io/react/docs/test-utils.html#simulate)\n来模拟点击操作：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport Voting from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  // ...\n\n\t  it('invokes callback when a button is clicked', () => {\n\t    let votedWith;\n\t    const vote = (entry) => votedWith = entry;\n\n\t    const component = renderIntoDocument(\n\t      <Voting pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t              vote={vote}/>\n\t    );\n\t    const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\t    Simulate.click(buttons[0].getDOMNode());\n\n\t    expect(votedWith).to.equal('Trainspotting');\n\t  });\n\t});\n\n要想使上面的测试通过很简单，我们只需要让按钮的`onClick`事件调用`vote`并传递选中条目即可：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n这就是我们在纯组件中常用的方式：组件不需要做太多，只是回调传入的参数即可。\n\n注意，这里我们又是先写的测试代码，我发现业务代码的测试要比测试UI更容易写，所以后面我们会保持这种\n方式：UI测试后行，业务代码测试先行。\n\n一旦用户已经针对某对选项投过票了，我们就不应该允许他们再次投票，难道我们应该在组件内部维护某种状态么？\n不，我们需要保证我们的组件是纯粹的，所以我们需要分离这个逻辑，组件需要一个`hasVoted`属性，我们先硬编码\n传递给它：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tReact.render(\n\t  <Voting pair={pair} hasVoted=\"Trainspotting\" />,\n\t  document.getElementById('app')\n\t);\n\n我们可以简单的修改一下组件即可：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                disabled={this.isDisabled()}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n让我们再为按钮添加一个提示，当用户投票完毕后，在选中的项目上添加标识，这样用户就更容易理解：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  hasVotedFor: function(entry) {\n\t    return this.props.hasVoted === entry;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                disabled={this.isDisabled()}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t          {this.hasVotedFor(entry) ?\n\t            <div className=\"label\">Voted</div> :\n\t            null}\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n投票界面最后要添加的，就是获胜者样式。我们可能需要添加新的props：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tReact.render(\n\t  <Voting pair={pair} winner=\"Trainspotting\" />,\n\t  document.getElementById('app')\n\t);\n\n我们再次修改一下组件：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  hasVotedFor: function(entry) {\n\t    return this.props.hasVoted === entry;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.props.winner ?\n\t        <div ref=\"winner\">Winner is {this.props.winner}!</div> :\n\t        this.getPair().map(entry =>\n\t          <button key={entry}\n\t                  disabled={this.isDisabled()}\n\t                  onClick={() => this.props.vote(entry)}>\n\t            <h1>{entry}</h1>\n\t            {this.hasVotedFor(entry) ?\n\t              <div className=\"label\">Voted</div> :\n\t              null}\n\t          </button>\n\t        )}\n\t    </div>;\n\t  }\n\t});\n\n目前我们已经完成了所有要做的，但是`render`函数看着有点丑陋，如果我们可以把胜利界面独立成新的组件\n可能会好一些：\n\n\t//src/components/Winner.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <div className=\"winner\">\n\t      Winner is {this.props.winner}!\n\t    </div>;\n\t  }\n\t});\n\n这样投票组件就会变得很简单，它只需关注投票按钮逻辑即可：\n\n\t//src/components/Vote.jsx\n\n\timport React from 'react';\n\n\texport default React.createClass({\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  isDisabled: function() {\n\t    return !!this.props.hasVoted;\n\t  },\n\t  hasVotedFor: function(entry) {\n\t    return this.props.hasVoted === entry;\n\t  },\n\t  render: function() {\n\t    return <div className=\"voting\">\n\t      {this.getPair().map(entry =>\n\t        <button key={entry}\n\t                disabled={this.isDisabled()}\n\t                onClick={() => this.props.vote(entry)}>\n\t          <h1>{entry}</h1>\n\t          {this.hasVotedFor(entry) ?\n\t            <div className=\"label\">Voted</div> :\n\t            null}\n\t        </button>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n最后我们只需要在`Voting`组件做一下判断即可：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n注意这里我们为胜利组件添加了[ref](https://facebook.github.io/react/docs/more-about-refs.html)，这是因为我们将在单元测试中利用它获取DOM节点。\n\n这就是我们的纯组件！注意目前我们还没有实现任何逻辑：我们并没有定义按钮的点击操作。组件只是用来渲染UI，其它\n什么都不需要做。后面当我们将UI与Redux Store结合时才会涉及到应用逻辑。\n\n继续下一步之前我们要为刚才新增的特性写更多的单元测试代码。首先，`hasVoted`属性将会使按钮改变状态：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('disables buttons when user has voted', () => {\n\t  const component = renderIntoDocument(\n\t    <Voting pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t            hasVoted=\"Trainspotting\" />\n\t  );\n\t  const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\n\t  expect(buttons.length).to.equal(2);\n\t  expect(buttons[0].getDOMNode().hasAttribute('disabled')).to.equal(true);\n\t  expect(buttons[1].getDOMNode().hasAttribute('disabled')).to.equal(true);\n\t});\n\n被`hasVoted`匹配的按钮将显示`Voted`标签：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('adds label to the voted entry', () => {\n\t  const component = renderIntoDocument(\n\t    <Voting pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t            hasVoted=\"Trainspotting\" />\n\t  );\n\t  const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\n\t  expect(buttons[0].getDOMNode().textContent).to.contain('Voted');\n\t});\n\n当获胜者产生，界面将不存在按钮，取而代替的是胜利者元素：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('renders just the winner when there is one', () => {\n\t  const component = renderIntoDocument(\n\t    <Voting winner=\"Trainspotting\" />\n\t  );\n\t  const buttons = scryRenderedDOMComponentsWithTag(component, 'button');\n\t  expect(buttons.length).to.equal(0);\n\n\t  const winner = React.findDOMNode(component.refs.winner);\n\t  expect(winner).to.be.ok;\n\t  expect(winner.textContent).to.contain('Trainspotting');\n\t});\n\n###不可变数据和纯粹渲染\n\n我们之前已经讨论了许多关于不可变数据的红利，但是，当它和react结合时还会有一个非常屌的好处：\n如果我们创建纯react组件并传递给它不可变数据作为属性参数，我们将会让react在组件渲染检测中得到最大性能。\n\n这是靠react提供的[PureRenderMixin](https://facebook.github.io/react/docs/pure-render-mixin.html)实现的。\n当该mixin添加到组件中后，组件的更新检查逻辑将会被改变，由深比对改为高性能的浅比对。\n\n我们之所以可以使用浅比对，就是因为我们使用的是不可变数据。如果一个组件的所有参数都是不可变数据，\n那么将大大提高应用性能。\n\n我们可以在单元测试里更清楚的看见差别，如果我们向纯组件中传入可变数组，当数组内部元素产生改变后，组件并不会\n重新渲染：\n\n\t//test/components/Voting_spec.jsx\n\n\tit('renders as a pure component', () => {\n\t  const pair = ['Trainspotting', '28 Days Later'];\n\t  const component = renderIntoDocument(\n\t    <Voting pair={pair} />\n\t  );\n\n\t  let firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t  expect(firstButton.getDOMNode().textContent).to.equal('Trainspotting');\n\n\t  pair[0] = 'Sunshine';\n\t  component.setProps({pair: pair});\n\t  firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t  expect(firstButton.getDOMNode().textContent).to.equal('Trainspotting');\n\t});\n\n如果我们使用不可变数据，则完全没有问题：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List} from 'immutable';\n\timport Voting from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Voting', () => {\n\n\t  // ...\n\n\t  it('does update DOM when prop changes', () => {\n\t    const pair = List.of('Trainspotting', '28 Days Later');\n\t    const component = renderIntoDocument(\n\t      <Voting pair={pair} />\n\t    );\n\n\t    let firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t    expect(firstButton.getDOMNode().textContent).to.equal('Trainspotting');\n\n\t    const newPair = pair.set(0, 'Sunshine');\n\t    component.setProps({pair: newPair});\n\t    firstButton = scryRenderedDOMComponentsWithTag(component, 'button')[0];\n\t    expect(firstButton.getDOMNode().textContent).to.equal('Sunshine');\n\t  });\n\t});\n\n如果你跑上面的两个测试，你将会看到非预期的结果：因为实际上UI在两种场景下都更新了。那是因为现在组件\n依然使用的是深比对，这正是我们使用不可变数据想极力避免的。\n\n下面我们在组件中引入mixin，你就会拿到期望的结果了：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  // ...\n\t});\n\n\n\n\t//src/components/Vote.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  // ...\n\t});\n\n\n\n\t//src/components/Winner.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  // ...\n\t});\n\n###投票结果页面和路由实现\n\n投票页面已经搞定了，让我们开始实现投票结果页面吧。\n\n投票结果页面依然会显示两个条目，并且显示它们各自的票数。此外屏幕下方还会有一个按钮，供用户切换到下一轮投票。\n\n现在我们根据什么来确定显示哪个界面呢？使用URL是个不错的主意：我们可以设置根路径`#/`去显示投票页面，\n使用`#/results`来显示投票结果页面。\n\n我们使用[react-router](http://rackt.github.io/react-router/)可以很容易实现这个需求。让我们加入项目：\n\n\tnpm install --save react-router\n\n我们这里使用的react-router的0.13版本，它的1.0版本官方还没有发布，如果你打算使用其1.0RC版，那么下面的代码\n你可能需要做一些修改，可以看[router文档](https://github.com/rackt/react-router)。\n\n我们现在可以来配置一下路由路径，Router提供了一个`Route`组件用来让我们定义路由信息，同时也提供了`DefaultRoute`\n组件来让我们定义默认路由：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport {Route, DefaultRoute} from 'react-router';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\n\tconst pair = ['Trainspotting', '28 Days Later'];\n\n\tconst routes = <Route handler={App}>\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tReact.render(\n\t  <Voting pair={pair} />,\n\t  document.getElementById('app')\n\t);\n\n我们定义了一个默认的路由指向我们的`Voting`组件。我们需要定义个`App`组件来用于Route使用。\n\n根路由的作用就是为应用指定一个根组件：通常该组件充当所有子页面的模板。让我们来看看`App`的细节：\n\n\t//src/components/App.jsx\n\n\timport React from 'react';\n\timport {RouteHandler} from 'react-router';\n\timport {List} from 'immutable';\n\n\tconst pair = List.of('Trainspotting', '28 Days Later');\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <RouteHandler pair={pair} />\n\t  }\n\t});\n\n这个组件除了渲染了一个`RouteHandler`组件并没有做别的，这个组件同样是react-router提供的，它的作用就是\n每当路由匹配了某个定义的页面后将对应的页面组件插入到这个位置。目前我们只定义了一个默认路由指向`Voting`，\n所以目前我们的组件总是会显示`Voting`界面。\n\n注意，我们将我们硬编码的投票数据从`index.jsx`移到了`App.jsx`，当你给`RouteHandler`传递了属性值时，\n这些参数将会传给当前路由对应的组件。\n\n现在我们可以更新`index.jsx`：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\n\tconst routes = <Route handler={App}>\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Root />,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n`run`方法会根据当前浏览器的路径去查找定义的router来决定渲染哪个组件。一旦确定了对应的组件，它将会被\n当作指定的`Root`传给`run`的回调函数，在回调中我们将使用`React.render`将其插入DOM中。\n\n目前为止我们已经基于React router实现了之前的内容，我们现在可以很容易添加更多新的路由到应用。让我们\n把投票结果页面添加进去吧：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Root />,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n这里我们用使用`<Route>`组件定义了一个名为`/results`的路径，并绑定`Results`组件。\n\n让我们简单的实现一下这个`Results`组件，这样我们就可以看一下路由是如何工作的了：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>Hello from results!</div>\n\t  }\n\t});\n\n如果你在浏览器中输入[http://localhost:8080/#/results](http://localhost:8080/#/results)，你将会看到该结果组件。\n而其它路径都对应这投票页面，你也可以使用浏览器的前后按钮来切换这两个界面。\n\n接下来我们来实际实现一下结果组件：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  render: function() {\n\t    return <div className=\"results\">\n\t      {this.getPair().map(entry =>\n\t        <div key={entry} className=\"entry\">\n\t          <h1>{entry}</h1>\n\t        </div>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n结果界面除了显示投票项外，还应该显示它们对应的得票数，让我们先硬编码一下：\n\n\t//src/components/App.jsx\n\n\timport React from 'react/addons';\n\timport {RouteHandler} from 'react-router';\n\timport {List, Map} from 'immutable';\n\n\tconst pair = List.of('Trainspotting', '28 Days Later');\n\tconst tally = Map({'Trainspotting': 5, '28 Days Later': 4});\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <RouteHandler pair={pair}\n\t                         tally={tally} />\n\t  }\n\t});\n\n现在，我们再来修改一下结果组件：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return <div className=\"results\">\n\t      {this.getPair().map(entry =>\n\t        <div key={entry} className=\"entry\">\n\t          <h1>{entry}</h1>\n\t          <div className=\"voteCount\">\n\t            {this.getVotes(entry)}\n\t          </div>\n\t        </div>\n\t      )}\n\t    </div>;\n\t  }\n\t});\n\n现在我们来针对目前的界面功能编写测试代码，以防止未来我们破坏这些功能。\n\n我们期望组件为每个选项都渲染一个div，并在其中显示选项的名称和票数。如果对应的选项没有票数，则默认显示0：\n\n\t//test/components/Results_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List, Map} from 'immutable';\n\timport Results from '../../src/components/Results';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithClass}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Results', () => {\n\n\t  it('renders entries with vote counts or zero', () => {\n\t    const pair = List.of('Trainspotting', '28 Days Later');\n\t    const tally = Map({'Trainspotting': 5});\n\t    const component = renderIntoDocument(\n\t      <Results pair={pair} tally={tally} />\n\t    );\n\t    const entries = scryRenderedDOMComponentsWithClass(component, 'entry');\n\t    const [train, days] = entries.map(e => e.getDOMNode().textContent);\n\n\t    expect(entries.length).to.equal(2);\n\t    expect(train).to.contain('Trainspotting');\n\t    expect(train).to.contain('5');\n\t    expect(days).to.contain('28 Days Later');\n\t    expect(days).to.contain('0');\n\t  });\n\t});\n\n接下来，我们看一下\"Next\"按钮，它允许用户切换到下一轮投票。\n\n我们的组件应该包含一个回调函数属性参数，当组件中的\"Next\"按钮被点击后，该回调函数将会被调用。我们来写一下\n这个操作的测试代码：\n\n\t//test/components/Results_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List, Map} from 'immutable';\n\timport Results from '../../src/components/Results';\n\timport {expect} from 'chai';\n\n\tconst {renderIntoDocument, scryRenderedDOMComponentsWithClass, Simulate}\n\t  = React.addons.TestUtils;\n\n\tdescribe('Results', () => {\n\n\t  // ...\n\n\t  it('invokes the next callback when next button is clicked', () => {\n\t    let nextInvoked = false;\n\t    const next = () => nextInvoked = true;\n\n\t    const pair = List.of('Trainspotting', '28 Days Later');\n\t    const component = renderIntoDocument(\n\t      <Results pair={pair}\n\t               tally={Map()}\n\t               next={next}/>\n\t    );\n\t    Simulate.click(React.findDOMNode(component.refs.next));\n\n\t    expect(nextInvoked).to.equal(true);\n\t  });\n\t});\n\n写法和之前的投票按钮很类似吧。接下来让我们更新一下结果组件：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return <div className=\"results\">\n\t      <div className=\"tally\">\n\t        {this.getPair().map(entry =>\n\t          <div key={entry} className=\"entry\">\n\t            <h1>{entry}</h1>\n\t            <div class=\"voteCount\">\n\t              {this.getVotes(entry)}\n\t            </div>\n\t          </div>\n\t        )}\n\t      </div>\n\t      <div className=\"management\">\n\t        <button ref=\"next\"\n\t                className=\"next\"\n\t                onClick={this.props.next}>\n\t          Next\n\t        </button>\n\t      </div>\n\t    </div>;\n\t  }\n\t});\n\n最终投票结束，结果页面和投票页面一样，都要显示胜利者：\n\n\t//test/components/Results_spec.jsx\n\n\tit('renders the winner when there is one', () => {\n\t  const component = renderIntoDocument(\n\t    <Results winner=\"Trainspotting\"\n\t             pair={[\"Trainspotting\", \"28 Days Later\"]}\n\t             tally={Map()} />\n\t  );\n\t  const winner = React.findDOMNode(component.refs.winner);\n\t  expect(winner).to.be.ok;\n\t  expect(winner.textContent).to.contain('Trainspotting');\n\t});\n\n我们可以想在投票界面中那样简单的实现一下上面的逻辑：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\timport Winner from './Winner';\n\n\texport default React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return this.props.winner ?\n\t      <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t      <div className=\"results\">\n\t        <div className=\"tally\">\n\t          {this.getPair().map(entry =>\n\t            <div key={entry} className=\"entry\">\n\t              <h1>{entry}</h1>\n\t              <div className=\"voteCount\">\n\t                {this.getVotes(entry)}\n\t              </div>\n\t            </div>\n\t          )}\n\t        </div>\n\t        <div className=\"management\">\n\t          <button ref=\"next\"\n\t                   className=\"next\"\n\t                   onClick={this.props.next}>\n\t            Next\n\t          </button>\n\t        </div>\n\t      </div>;\n\t  }\n\t});\n\n到目前为止，我们已经实现了应用的UI，虽然现在它们并没有和真实数据和操作整合起来。这很不错不是么？\n我们只需要一些占位符数据就可以完成界面的开发，这让我们在这个阶段更专注于UI。\n\n接下来我们将会使用Redux Store来将真实数据整合到我们的界面中。\n\n###初识客户端的Redux Store\n\nRedux将会充当我们UI界面的状态容器，我们已经在服务端用过Redux，之前说的很多内容在这里也受用。\n现在我们已经准备好要在React应用中使用Redux了，这也是Redux更常见的使用场景。\n\n和在服务端一样，我们先来思考一下应用的状态。客户端的状态和服务端会非常的类似。\n\n我们有两个界面，并在其中需要显示成对的用于投票的条目：\n\n![](http://teropa.info/images/vote_client_pair.png)\n\n此外，结果页面需要显示票数：\n\n![](http://teropa.info/images/vote_client_tally.png)\n\n投票组件还需要记录当前用户已经投票过的选项：\n\n![](http://teropa.info/images/vote_client_hasvoted.png)\n\n结果组件还需要记录胜利者：\n\n![](http://teropa.info/images/vote_server_tree_winner.png)\n\n注意这里除了`hasVoted`外，其它都映射着服务端状态的子集。\n\n接下来我们来思考一下应用的核心逻辑，actions和reducers应该是什么样的。\n\n我们先来想想能够导致应用状态改变的操作都有那些？状态改变的来源之一是用户行为。我们的UI中存在两种\n可能的用户操作行为：\n\n- 用户在投票页面点击某个投票按钮；\n- 用户点击下一步按钮。\n\n另外，我们知道我们的服务端会将应用当前状态发送给客户端，我们将编写代码来接受状态数据，这也是导致状态\n改变的来源之一。\n\n我们可以从服务端状态更新开始，之前我们在服务端设置发送了一个`state`事件。该事件将携带我们之前设计的客户端\n状态树的状态数据。我们的客户端reducer将通过一个action来将服务器端的状态数据合并到客户端状态树中，\n这个action如下：\n\n\t{\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {...}\n\t  }\n\t}\n\n让我们先写一下reducer测试代码，它应该接受上面定义的那种action，并合并数据到客户端的当前状态中：\n\n\t//test/reducer_spec.js\n\n\timport {List, Map, fromJS} from 'immutable';\n\timport {expect} from 'chai';\n\n\timport reducer from '../src/reducer';\n\n\tdescribe('reducer', () => {\n\n\t  it('handles SET_STATE', () => {\n\t    const initialState = Map();\n\t    const action = {\n\t      type: 'SET_STATE',\n\t      state: Map({\n\t        vote: Map({\n\t          pair: List.of('Trainspotting', '28 Days Later'),\n\t          tally: Map({Trainspotting: 1})\n\t        })\n\t      })\n\t    };\n\t    const nextState = reducer(initialState, action);\n\n\t    expect(nextState).to.equal(fromJS({\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      }\n\t    }));\n\t  });\n\t});\n\n这个renducers接受一个来自socket发送的原始的js数据结构，这里注意不是不可变数据类型哦。我们需要在返回前将其\n转换成不可变数据类型：\n\n\t//test/reducer_spec.js\n\n\tit('handles SET_STATE with plain JS payload', () => {\n\t  const initialState = Map();\n\t  const action = {\n\t    type: 'SET_STATE',\n\t    state: {\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      }\n\t    }\n\t  };\n\t  const nextState = reducer(initialState, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  }));\n\t});\n\nreducer同样应该可以正确的处理`undefined`初始化状态：\n\n\t//test/reducer_spec.js\n\n\tit('handles SET_STATE without initial state', () => {\n\t  const action = {\n\t    type: 'SET_STATE',\n\t    state: {\n\t      vote: {\n\t        pair: ['Trainspotting', '28 Days Later'],\n\t        tally: {Trainspotting: 1}\n\t      }\n\t    }\n\t  };\n\t  const nextState = reducer(undefined, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  }));\n\t});\n\n现在我们来看一下如何实现满足上面测试条件的reducer：\n\n\t//src/reducer.js\n\n\timport {Map} from 'immutable';\n\n\texport default function(state = Map(), action) {\n\n\t  return state;\n\t}\n\nreducer需要处理`SET_STATE`动作。在这个动作的处理中，我们应该将传入的状态数据和现有的进行合并，\n使用Map提供的[merge](https://facebook.github.io/immutable-js/docs/#/Map/merge)将很容易来实现这个操作：\n\n\t//src/reducer.js\n\n\timport {Map} from 'immutable';\n\n\tfunction setState(state, newState) {\n\t  return state.merge(newState);\n\t}\n\n\texport default function(state = Map(), action) {\n\t  switch (action.type) {\n\t  case 'SET_STATE':\n\t    return setState(state, action.state);\n\t  }\n\t  return state;\n\t}\n\n注意这里我们并没有单独写一个核心模块，而是直接在reducer中添加了个简单的`setState`函数来做业务逻辑。\n这是因为现在这个逻辑还很简单～\n\n关于改变用户状态的那两个用户交互：投票和下一步，它们都需要和服务端进行通信，我们一会再说。我们现在先把\nredux添加到项目中：\n\n\tnpm install --save redux\n\n`index.jsx`入口文件是一个初始化Store的好地方，让我们暂时先使用硬编码的数据来做：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport Voting from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={Voting} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Root />,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n那么，我们如何在react组件中从Store中获取数据呢？\n\n###让React从Redux中获取数据\n\n我们已经创建了一个使用不可变数据类型保存应用状态的Redux Store。我们还拥有接受不可变数据为参数的\n无状态的纯React组件。如果我们能使这些组件从Store中获取最新的状态数据，那真是极好的。当状态变化时，\nReact会重新渲染组件，pure render mixin可以使得我们的UI避免不必要的重复渲染。\n\n相比我们自己手动实现同步代码，我们更推荐使用[react-redux][https://github.com/rackt/react-redux]包来做：\n\n\tnpm install --save react-redux\n\n这个库主要做的是：\n\n1. 映射Store的状态到组件的输入props中；\n2. 映射actions到组件的回调props中。\n\n为了让它可以正常工作，我们需要将顶层的应用组件嵌套在react-redux的[Provider](https://github.com/rackt/react-redux#provider-store)组件中。\n这将把Redux Store和我们的状态树连接起来。\n\n我们将让Provider包含路由的根组件，这样会使得Provider成为整个应用组件的根节点：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n接下来我们要考虑一下，我们的那些组件需要绑定到Store上。我们一共有5个组件，可以分成三类：\n\n- 根组件`App`不需要绑定任何数据；\n- `Vote`和`Winner`组件只使用父组件传递来的数据，所以它们也不需要绑定；\n- 剩下的组件（`Voting`和`Results`）目前都是使用的硬编码数据，我们现在需要将其绑定到Store上。\n\n让我们从`Voting`组件开始。使用react-redux我们得到一个叫[connect](https://github.com/rackt/react-redux#connectmapstatetoprops-mapdispatchtoprops-mergeprops-options)的函数：\n\n\tconnect(mapStateToProps)(SomeComponent);\n\n该函数的作用就是将Redux Store中的状态数据映射到props对象中。这个props对象将会用于连接到的组件中。\n在我们的`Voting`场景中，我们需要从状态中拿到`pair`和`winner`值：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\tconst Voting = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n\tconnect(mapStateToProps)(Voting);\n\n\texport default Voting;\n\n在上面的代码中，`connect`函数并没有修改`Voting`组件本身，`Voting`组件依然保持这纯粹性。而`connect`\n返回的是一个`Voting`组件的连接版，我们称之为`VotingContainer`：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\n\texport const Voting = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n\texport const VotingContainer = connect(mapStateToProps)(Voting);\n\n这样，这个模块现在导出两个组件：一个纯`Voting`组件，一个连接后的`VotingContainer`版本。\nreact-redux官方称前者为“蠢”组件，后者则称为\"智能\"组件。我更倾向于用“pure”和“connected”来描述它们。\n怎么称呼随你便，主要是明白它们之间的差别：\n\n- 纯组件完全靠给它传入的props来工作，这非常类似一个纯函数；\n- 连接组件则封装了纯组件和一些逻辑用来与Redux Store协同工作，这些特性是redux-react提供的。\n\n我们得更新一下路由表，改用`VotingContainer`。一旦修改完毕，我们的投票界面将会使用来自Redux Store的数据：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport Results from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={Results} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n而在对应的测试代码中，我们则需要使用纯`Voting`组件定义：\n\n\t//test/components/Voting_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List} from 'immutable';\n\timport {Voting} from '../../src/components/Voting';\n\timport {expect} from 'chai';\n\n其它地方不需要修改了。\n\n现在我们来如法炮制投票结果页面：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\n\texport const Results = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return this.props.winner ?\n\t      <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t      <div className=\"results\">\n\t        <div className=\"tally\">\n\t          {this.getPair().map(entry =>\n\t            <div key={entry} className=\"entry\">\n\t              <h1>{entry}</h1>\n\t              <div className=\"voteCount\">\n\t                {this.getVotes(entry)}\n\t              </div>\n\t            </div>\n\t          )}\n\t        </div>\n\t        <div className=\"management\">\n\t          <button ref=\"next\"\n\t                   className=\"next\"\n\t                   onClick={this.props.next}>\n\t            Next\n\t          </button>\n\t      </div>\n\t      </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    tally: state.getIn(['vote', 'tally']),\n\t    winner: state.get('winner')\n\t  }\n\t}\n\n\texport const ResultsContainer = connect(mapStateToProps)(Results);\n\n同样我们需要修改`index.jsx`来使用新的`ResultsContainer`：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n不要忘记修改测试代码啊：\n\n\t//test/components/Results_spec.jsx\n\n\timport React from 'react/addons';\n\timport {List, Map} from 'immutable';\n\timport {Results} from '../../src/components/Results';\n\timport {expect} from 'chai';\n\n现在你已经知道如何让纯react组件与Redux Store整合了。\n\n对于一些只有一个根组件且没有路由的小应用，直接连接根组件就足够了。根组件会将状态数据传递给它的子组件。\n而对于那些使用路由，就像我们的场景，连接每一个路由指向的处理函数是个好主意。但是分别为每个组件编写连接代码并\n不适合所有的软件场景。我觉得保持组件props尽可能清晰明了是个非常好的习惯，因为它可以让你很容易清楚组件需要哪些数据，\n你就可以更容易管理那些连接代码。\n\n现在让我们开始把Redux数据对接到UI里，我们再也不需要那些`App.jsx`中手写的硬编码数据了，这样我们的`App.jsx`将会变得简单：\n\n\t//src/components/App.jsx\n\n\timport React from 'react';\n\timport {RouteHandler} from 'react-router';\n\n\texport default React.createClass({\n\t  render: function() {\n\t    return <RouteHandler />\n\t  }\n\t});\n\n\n###设置socket.io客户端\n\n现在我们已经创建好了客户端的Redux应用，我们接下来将讨论如何让其与我们之前开发的服务端应用进行对接。\n\n服务端已经准备好接受socket连接，并为其进行投票数据的发送。而我们的客户端也已经可以使用Redux Store很方便的\n接受数据了。我们剩下的工作就是把它们连接起来。\n\n我们需要使用socket.io从浏览器向服务端创建一个连接，我们可以使用[socket.io-client库](http://socket.io/docs/client-api/)来完成\n这个目的：\n\n\tnpm install --save socket.io-client\n\n这个库赋予了我们连接Socket.io服务端的能力，让我们连接之前写好的服务端，端口号8090（注意使用和后端匹配的端口）：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\tstore.dispatch({\n\t  type: 'SET_STATE',\n\t  state: {\n\t    vote: {\n\t      pair: ['Sunshine', '28 Days Later'],\n\t      tally: {Sunshine: 2}\n\t    }\n\t  }\n\t});\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n你必须先确保你的服务端已经开启了，然后在浏览器端访问客户端应用，并检查网络监控，你会发现创建了一个\nWebSockets连接，并且开始传输Socket.io的心跳包了。\n\n###接受来自服务器端的actions\n\n我们虽然已经创建了个socket.io连接，但我们并没有用它获取任何数据。每当我们连接到服务端或服务端发生\n状态数据改变时，服务端会发送`state`事件给客户端。我们只需要监听对应的事件即可，我们在接受到事件通知后\n只需要简单的对我们的Store指派`SET_STATE`action即可：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch({type: 'SET_STATE', state})\n\t);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n注意我们移除了`SET_STATE`的硬编码，我们现在已经不需要伪造数据了。\n\n审视我们的界面，不管是投票还是结果页面，它们都会显示服务端提供的第一对选项。服务端和客户端已经连接上了！\n\n###从react组件中指派actions\n\n我们已经知道如何从Redux Store获取数据到UI中，现在来看看如何从UI中提交数据用于actions。\n\n思考这个问题的最佳场景是投票界面上的投票按钮。之前在写相关界面时，我们假设`Voting`组件接受一个回调函数props。\n当用户点击某个按钮时组件将会调用这个回调函数。但我们目前并没有实现这个回调函数，除了在测试代码中。\n\n当用户投票后应该做什么？投票结果应该发送给服务端，这部分我们稍后再说，客户端也需要执行一些逻辑：\n组件的`hasVoted`值应该被设置，这样用户才不会反复对同一对选项投票。\n\n这是我们要创建的第二个客户端Redux Action，我们称之为`VOTE`：\n\n\t//test/reducer_spec.js\n\n\tit('handles VOTE by setting hasVoted', () => {\n\t  const state = fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  });\n\t  const action = {type: 'VOTE', entry: 'Trainspotting'};\n\t  const nextState = reducer(state, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    },\n\t    hasVoted: 'Trainspotting'\n\t  }));\n\t});\n\n为了更严谨，我们应该考虑一种情况：不管什么原因，当`VOTE`action传递了一个不存在的选项时我们的应用该怎么做：\n\n\t//test/reducer_spec.js\n\n\tit('does not set hasVoted for VOTE on invalid entry', () => {\n\t  const state = fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  });\n\t  const action = {type: 'VOTE', entry: 'Sunshine'};\n\t  const nextState = reducer(state, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    }\n\t  }));\n\t});\n\n下面来看看我们的reducer如何实现的：\n\n\t//src/reducer.js\n\n\timport {Map} from 'immutable';\n\n\tfunction setState(state, newState) {\n\t  return state.merge(newState);\n\t}\n\n\tfunction vote(state, entry) {\n\t  const currentPair = state.getIn(['vote', 'pair']);\n\t  if (currentPair && currentPair.includes(entry)) {\n\t    return state.set('hasVoted', entry);\n\t  } else {\n\t    return state;\n\t  }\n\t}\n\n\texport default function(state = Map(), action) {\n\t  switch (action.type) {\n\t  case 'SET_STATE':\n\t    return setState(state, action.state);\n\t  case 'VOTE':\n\t    return vote(state, action.entry);\n\t  }\n\t  return state;\n\t}\n\n`hasVoted`并不会一直保存在状态数据中，每当开始一轮新的投票时，我们应该在`SET_STATE`action的处理逻辑中\n检查是否用户是否已经投票，如果还没，我们应该删除掉`hasVoted`：\n\n\t//test/reducer_spec.js\n\n\tit('removes hasVoted on SET_STATE if pair changes', () => {\n\t  const initialState = fromJS({\n\t    vote: {\n\t      pair: ['Trainspotting', '28 Days Later'],\n\t      tally: {Trainspotting: 1}\n\t    },\n\t    hasVoted: 'Trainspotting'\n\t  });\n\t  const action = {\n\t    type: 'SET_STATE',\n\t    state: {\n\t      vote: {\n\t        pair: ['Sunshine', 'Slumdog Millionaire']\n\t      }\n\t    }\n\t  };\n\t  const nextState = reducer(initialState, action);\n\n\t  expect(nextState).to.equal(fromJS({\n\t    vote: {\n\t      pair: ['Sunshine', 'Slumdog Millionaire']\n\t    }\n\t  }));\n\t});\n\n根据需要，我们新增一个`resetVote`函数来处理`SET_STATE`动作：\n\n\t//src/reducer.js\n\n\timport {List, Map} from 'immutable';\n\n\tfunction setState(state, newState) {\n\t  return state.merge(newState);\n\t}\n\n\tfunction vote(state, entry) {\n\t  const currentPair = state.getIn(['vote', 'pair']);\n\t  if (currentPair && currentPair.includes(entry)) {\n\t    return state.set('hasVoted', entry);\n\t  } else {\n\t    return state;\n\t  }\n\t}\n\n\tfunction resetVote(state) {\n\t  const hasVoted = state.get('hasVoted');\n\t  const currentPair = state.getIn(['vote', 'pair'], List());\n\t  if (hasVoted && !currentPair.includes(hasVoted)) {\n\t    return state.remove('hasVoted');\n\t  } else {\n\t    return state;\n\t  }\n\t}\n\n\texport default function(state = Map(), action) {\n\t  switch (action.type) {\n\t  case 'SET_STATE':\n\t    return resetVote(setState(state, action.state));\n\t  case 'VOTE':\n\t    return vote(state, action.entry);\n\t  }\n\t  return state;\n\t}\n\n我们还需要在修改一下连接逻辑：\n\n\t//src/components/Voting.jsx\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    hasVoted: state.get('hasVoted'),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n现在我们依然需要为`Voting`提供一个`vote`回调函数，用来为Sotre指派我们新增的action。我们依然要尽力保证\n`Voting`组件的纯粹性，不应该依赖任何actions或Redux。这些工作都应该在react-redux的`connect`中处理。\n\n除了连接输入参数属性，react-redux还可以用来连接output actions。开始之前，我们先来介绍一下另一个Redux的\n核心概念：Action creators。\n\n如我们之前看到的，Redux actions通常就是一个简单的对象，它包含一个固有的`type`属性和其它内容。我们之前都是直接\n利用js对象字面量来直接声明所需的actions。其实可以使用一个factory函数来更好的生成actions，如下：\n\n\tfunction vote(entry) {\n\t  return {type: 'VOTE', entry};\n\t}\n\n这类函数就被称为action creators。它们就是个纯函数，用来返回action对象，别的没啥好介绍得了。但是你也可以\n在其中实现一些内部逻辑，而避免将每次生成action都重复编写它们。使用action creators可以更好的表达所有需要分发\n的actions。\n\n让我们新建一个用来声明客户端所需action的action creators文件：\n\n\t//src/action_creators.js\n\n\texport function setState(state) {\n\t  return {\n\t    type: 'SET_STATE',\n\t    state\n\t  };\n\t}\n\n\texport function vote(entry) {\n\t  return {\n\t    type: 'VOTE',\n\t    entry\n\t  };\n\t}\n\n我们当然也可以为action creators编写测试代码，但由于我们的代码逻辑太简单了，我就不再写测试了。\n\n现在我们可以在`index.jsx`中使用我们刚新增的`setState`action creator了：\n\n\t//src/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport {setState} from './action_creators';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst store = createStore(reducer);\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch(setState(state))\n\t);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n使用action creators还有一个非常优雅的特点：在我们的场景里，我们有一个需要`vote`回调函数props的\n`Vote`组件，我们同时拥有一个`vote`的action creator。它们的名字和函数签名完全一致（都接受一个用来表示\n选中项的参数）。现在我们只需要将action creators作为react-redux的`connect`函数的第二个参数，即可完成\n自动关联：\n\n\t//src/components/Voting.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport Vote from './Vote';\n\timport * as actionCreators from '../action_creators';\n\n\texport const Voting = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  render: function() {\n\t    return <div>\n\t      {this.props.winner ?\n\t        <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t        <Vote {...this.props} />}\n\t    </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    hasVoted: state.get('hasVoted'),\n\t    winner: state.get('winner')\n\t  };\n\t}\n\n\texport const VotingContainer = connect(\n\t  mapStateToProps,\n\t  actionCreators\n\t)(Voting);\n\n这么配置后，我们的`Voting`组件的`vote`参数属性将会与`vote`aciton creator关联起来。这样当点击\n某个投票按钮后，会导致触发`VOTE`动作。\n\n###使用Redux Middleware发送actions到服务端\n\n最后我们要做的是把用户数据提交到服务端，这种操作一般发生在用户投票，或选择跳转下一轮投票时发生。\n\n让我们讨论一下投票操作，下面列出了投票的逻辑：\n\n- 当用户进行投票，`VOTE`action将产生并分派到客户端的Redux Store中；\n- `VOTE`actions将触发客户端reducer进行`hasVoted`状态设置；\n- 服务端监控客户端通过socket.io投递的`action`，它将接收到的actions分派到服务端的Redux Store;\n- `VOTE`action将触发服务端的reducer，其会创建vote数据并更新对应的票数。\n\n这样来说，我们似乎已经都搞定了。唯一缺少的就是让客户端发送`VOTE`action给服务端。这相当于两端的\nRedux Store相互分派action，这就是我们接下来要做的。\n\n那么该怎么做呢？Redux并没有内建这种功能。所以我们需要设计一下何时何地来做这个工作：从客户端发送\naction到服务端。\n\nRedux提供了一个通用的方法来封装action：[Middleware](http://rackt.github.io/redux/docs/advanced/Middleware.html)。\n\nRedux中间件是一个函数，每当action将要被指派，并在对应的reducer执行之前会被调用。它常用来做像日志收集，\n异常处理，修整action，缓存结果，控制何时以何种方式来让store接收actions等工作。这正是我们可以利用的。\n\n注意，一定要分清Redux中间件和Redux监听器的差别：中间件被用于action将要指派给store阶段，它可以修改action对\nstore将带来的影响。而监听器则是在action被指派后，它不能改变action的行为。\n\n我们需要创建一个“远程action中间件”，该中间件可以让我们的action不仅仅能指派给本地的store，也可以通过\nsocket.io连接派送给远程的store。\n\n让我们创建这个中间件，It is a function that takes a Redux store, and returns another function that takes a \"next\" callback. That function returns a third function that takes a Redux action. The innermost function is where the middleware implementation will actually go\n（译者注：这句套绕口，请看官自行参悟）：\n\n\t//src/remote_action_middleware.js\n\n\texport default store => next => action => {\n\n\t}\n\n上面这个写法看着可能有点渗人，下面调整一下让大家好理解：\n\n\texport default function(store) {\n\t\treturn function(next) {\n\t\t\treturn function(action) {\n\n\t\t\t}\n\t\t}\n\t}\n\n这种嵌套接受单一参数函数的写法成为[currying](https://en.wikipedia.org/wiki/Currying)。\n这种写法主要用来简化中间件的实现：如果我们使用一个一次性接受所有参数的函数（`function(store, next, action) { }`），\n那么我们就不得不保证我们的中间件具体实现每次都要包含所有这些参数。\n\n上面的`next`参数作用是在中间件中一旦完成了action的处理，就可以调用它来退出当前逻辑：\n\n\t//src/remote_action_middleware.js\n\n\texport default store => next => action => {\n\t  return next(action);\n\t}\n\n如果中间件没有调用`next`，则该action将丢弃，不再传到reducer或store中。\n\n让我们写一个简单的日志中间件：\n\n\t//src/remote_action_middleware.js\n\n\texport default store => next => action => {\n\t  console.log('in middleware', action);\n\t  return next(action);\n\t}\n\n我们将上面这个中间件注册到我们的Redux Store中，我们将会抓取到所有action的日志。中间件可以通过Redux\n提供的`applyMiddleware`函数绑定到我们的store中：\n\n\t//src/components/index.jsx\n\n\timport React from 'react';\n\timport Router, {Route, DefaultRoute} from 'react-router';\n\timport {createStore, applyMiddleware} from 'redux';\n\timport {Provider} from 'react-redux';\n\timport io from 'socket.io-client';\n\timport reducer from './reducer';\n\timport {setState} from './action_creators';\n\timport remoteActionMiddleware from './remote_action_middleware';\n\timport App from './components/App';\n\timport {VotingContainer} from './components/Voting';\n\timport {ResultsContainer} from './components/Results';\n\n\tconst createStoreWithMiddleware = applyMiddleware(\n\t  remoteActionMiddleware\n\t)(createStore);\n\tconst store = createStoreWithMiddleware(reducer);\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch(setState(state))\n\t);\n\n\tconst routes = <Route handler={App}>\n\t  <Route path=\"/results\" handler={ResultsContainer} />\n\t  <DefaultRoute handler={VotingContainer} />\n\t</Route>;\n\n\tRouter.run(routes, (Root) => {\n\t  React.render(\n\t    <Provider store={store}>\n\t      {() => <Root />}\n\t    </Provider>,\n\t    document.getElementById('app')\n\t  );\n\t});\n\n如果你重启应用，你将会看到我们设置的中间件会抓到应用触发的action日志。\n\n那我们应该怎么利用中间件机制来完成从客户端通过socket.io连接发送action给服务端呢？在此之前我们肯定需要先\n有一个连接供中间件使用，不幸的是我们已经有了，就在`index.jsx`中，我们只需要中间件可以拿到它即可。\n使用currying风格来实现这个中间件很简单：\n\n\t//src/remote_action_middleware.js\n\n\texport default socket => store => next => action => {\n\t  console.log('in middleware', action);\n\t  return next(action);\n\t}\n\n这样我们就可以在`index.jsx`中传入需要的连接了：\n\n\t//src/index.jsx\n\n\tconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\tsocket.on('state', state =>\n\t  store.dispatch(setState(state))\n\t);\n\n\tconst createStoreWithMiddleware = applyMiddleware(\n\t  remoteActionMiddleware(socket)\n\t)(createStore);\n\tconst store = createStoreWithMiddleware(reducer);\n\n注意跟之前的代码比，我们需要调整一下顺序，让socket连接先于store被创建。\n\n一切就绪了，现在就可以使用我们的中间件发送`action`了：\n\n\t//src/remote_action_middleware.js\n\n\texport default socket => store => next => action => {\n\t  socket.emit('action', action);\n\t  return next(action);\n\t}\n\n打完收工。现在如果你再点击投票按钮，你就会看到所有连接到服务端的客户端的票数都会被更新！\n\n还有个很严重的问题我们要处理：现在每当我们收到服务端发来的`SET_STATE`action后，这个action都将会直接回传给\n服务端，这样我们就造成了一个死循环，这是非常反人类的。\n\n我们的中间件不应该不加处理的转发所有的action给服务端。个别action，例如`SET_STATE`，应该只在客户端做\n处理。我们在action中添加一个标识位用于识别哪些应该转发给服务端：\n\n\t//src/remote_action_middleware.js\n\n\texport default socket => store => next => action => {\n\t  if (action.meta && action.meta.remote) {\n\t    socket.emit('action', action);\n\t  }\n\t  return next(action);\n\t}\n\n我们同样应该修改相关的action creators：\n\n\t//src/action_creators.js\n\n\texport function setState(state) {\n\t  return {\n\t    type: 'SET_STATE',\n\t    state\n\t  };\n\t}\n\n\texport function vote(entry) {\n\t  return {\n\t    meta: {remote: true},\n\t    type: 'VOTE',\n\t    entry\n\t  };\n\t}\n\n让我们重新审视一下我们都干了什么：\n\n1. 用户点击投票按钮，`VOTE`action被分派；\n2. 远程action中间件通过socket.io连接转发该action给服务端；\n3. 客户端Redux Store处理这个action，记录本地`hasVoted`属性；\n4. 当action到达服务端，服务端的Redux Store将处理该action，更新所有投票及其票数；\n5. 设置在服务端Redux Store上的监听器将改变后的状态数据发送给所有在线的客户端；\n6. 每个客户端将触发`SET_STATE`action的分派；\n7. 每个客户端将根据这个action更新自己的状态，这样就保持了与服务端的同步。\n\n为了完成我们的应用，我们需要实现下一步按钮的逻辑。和投票类似，我们需要将数据发送到服务端：\n\n\t//src/action_creator.js\n\n\texport function setState(state) {\n\t  return {\n\t    type: 'SET_STATE',\n\t    state\n\t  };\n\t}\n\n\texport function vote(entry) {\n\t  return {\n\t    meta: {remote: true},\n\t    type: 'VOTE',\n\t    entry\n\t  };\n\t}\n\n\texport function next() {\n\t  return {\n\t    meta: {remote: true},\n\t    type: 'NEXT'\n\t  };\n\t}\n\n`ResultsContainer`组件将会自动关联action creators中的next作为props：\n\n\t//src/components/Results.jsx\n\n\timport React from 'react/addons';\n\timport {connect} from 'react-redux';\n\timport Winner from './Winner';\n\timport * as actionCreators from '../action_creators';\n\n\texport const Results = React.createClass({\n\t  mixins: [React.addons.PureRenderMixin],\n\t  getPair: function() {\n\t    return this.props.pair || [];\n\t  },\n\t  getVotes: function(entry) {\n\t    if (this.props.tally && this.props.tally.has(entry)) {\n\t      return this.props.tally.get(entry);\n\t    }\n\t    return 0;\n\t  },\n\t  render: function() {\n\t    return this.props.winner ?\n\t      <Winner ref=\"winner\" winner={this.props.winner} /> :\n\t      <div className=\"results\">\n\t        <div className=\"tally\">\n\t          {this.getPair().map(entry =>\n\t            <div key={entry} className=\"entry\">\n\t              <h1>{entry}</h1>\n\t              <div className=\"voteCount\">\n\t                {this.getVotes(entry)}\n\t              </div>\n\t            </div>\n\t          )}\n\t        </div>\n\t        <div className=\"management\">\n\t          <button ref=\"next\"\n\t                   className=\"next\"\n\t                   onClick={this.props.next()}>\n\t            Next\n\t          </button>\n\t        </div>\n\t      </div>;\n\t  }\n\t});\n\n\tfunction mapStateToProps(state) {\n\t  return {\n\t    pair: state.getIn(['vote', 'pair']),\n\t    tally: state.getIn(['vote', 'tally']),\n\t    winner: state.get('winner')\n\t  }\n\t}\n\n\texport const ResultsContainer = connect(\n\t  mapStateToProps,\n\t  actionCreators\n\t)(Results);\n\n彻底完工了！我们实现了一个功能完备的应用。\n\n###课后练习\n（不翻译）\n","slug":"[译]全栈Redux实战","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cifi95baw0000rjws930lqbed","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本文乱译自一篇英文博文（<a href=\"http://teropa.info/blog/2015/09/10/full-stack-redux-tutorial.html\" target=\"_blank\" rel=\"external\">Full-Stack Redux Tutorial</a>），本人英语能力不足，技术能力有限，如有错误，多多包涵。</p>\n<a id=\"more\"></a>\n<p>#关于Redux+React+Immutable的测试先行开发综合指南</p>\n<p>Redux是最近发生在js界令人兴奋的事儿。它把众多优秀的库和框架中非常正确的特性保留了下来：简单且可预测的模型，强调函数式编程和不可变数据，基于api的轻量级实现……你还有什么理由不喜欢呢？</p>\n<p>Redux是一个非常小的代码库，掌握它所有的api并不困难，但对很多同学来讲，它要求的：创建组件（blocks），自满足的纯函数和不可变数据会带来不少别扭，那到底应该怎么办呢？</p>\n<p>这篇文章将会带你创建一个全栈的Redux和Immutable-js应用。我们将详细讲解创建该应用的Node+Redu后端和React+Redux前端的所有步骤。本指南将使用ES6,Babel,Socket.io,Webpack和Mocha。这是一个非常令人着迷的技术栈选型，你肯定不及待的想要开始了。</p>\n<p>##目录<br>（不翻译）</p>\n<h2 id=\"你需要准备什么\"><a href=\"#你需要准备什么\" class=\"headerlink\" title=\"你需要准备什么\"></a>你需要准备什么</h2><p>这篇文章需要读者具备开发js应用的能力，我们讲使用Node，ES6，React，Webpack，和Babel，所以你最好能了解这些工具，这样你才不会掉队。</p>\n<p>在上面提到的工具集中，你需要安装Node和NPM，和一款你喜欢的编辑器。</p>\n<p>##应用</p>\n<p>我们将要开发一款应用，它用来为聚会，会议，集会等用户群提供实时投票功能。</p>\n<p>这个点子来自于现实中我们经常需要为电影，音乐，编程语言等进行投票。该应用将所有选项两两分组，这样用户可以根据喜好进行二选一，最终拿到最佳结果。</p>\n<p>举个例子，这里拿Danny Boyle电影做例子来发起投票：</p>\n<p><img src=\"http://teropa.info/images/vote_logic.png\" alt=\"\"></p>\n<p>这个应用有两类独立的界面：用于投票的移动端界面，用于其它功能的浏览器界面。投票结果界面设计成有利于幻灯片或其它更大尺寸的屏幕显示，它用来展示投票的实时结果。</p>\n<p><img src=\"http://teropa.info/images/vote_system.png\" alt=\"\"></p>\n<p>##架构</p>\n<p>该系统应该有2部分组成：浏览器端我们使用React来提供用户界面，服务端我们使用Node来处理投票逻辑。两端通信我们选择使用WebSockets。</p>\n<p>我们将使用Redux来组织前后端的应用代码。我们将使用Immutable数据结构来处理应用的state。</p>\n<p>虽然我们的前后端存在许多相似性，例如都使用Redux。但是它们之间并没有什么可复用代码。这更像一个分布式系统，靠传递消息进行通信。</p>\n<p>##服务端应用</p>\n<p>我们先来实现Node应用，这有助于我们专注于核心业务逻辑，而不是过早的被界面干扰。</p>\n<p>实现服务端应用，我们需要先了解Redux和Immutable，并且明白它们如何协作。Redux常常被用在React开发中，但它并不限制于此。我们这里就要学习让Redux如何在其它场景下使用。</p>\n<p>我推荐大家跟着我们的指导一起写出一个应用，但你也可以直接从<a href=\"https://github.com/teropa/redux-voting-server\" target=\"_blank\" rel=\"external\">github</a>上下载代码。</p>\n<p>###设计应用的状态树（State Tree）</p>\n<p>设计一个Redux应用往往从思考应用的状态树数据结构开始，它是用来描述你的应用在任何时间点下状态的数据结构。</p>\n<p>任何的框架和架构都包含状态。在Ember和Backbone框架里，状态就是模型（Models）。在Anglar中，状态常常用Factories和Services来管理。而在大多数Flux实现中，常常用Stores来负责状态。那Redux又和它们有哪些不同之处呢？</p>\n<p>最大的不同之处是，在Redux中，应用的状态是全部存在一个单一的树结构中的。换句话说，应用的所有状态信息都存储在这个包含map和array的数据结构中。</p>\n<p>这么做很有意义，我们马上就会感受到。最重要的一点是，这么做迫使你将应用的行为和状态隔离开来。状态就是纯数据，它不包含任何方法或函数。</p>\n<p>这么做听起来存在局限，特别是你刚刚从面向对象思想背景下转到Redux。但这确实是一种解放，因为这么做将使你专注于数据自身。如果你花一些时间来设计你的应用状态，其它环节将水到渠成。</p>\n<p>这并不是说你总应该一上来就设计你的实体状态树然后再做其它部分。通常你最终会同时考虑应用的所有方面。然而，我发现当你想到一个点子时，在写代码前先思考在不同解决方案下状态树的结构会非常有帮助。</p>\n<p>所以，让我们先看看我们的投票应用的状态树应该是什么样的。应用的目标是可以针对多个选项进行投票，那么符合直觉的一种初始化状态应该是包含要被投票的选项集合，我们称之为条目[entries]：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_entries.png\" alt=\"\"></p>\n<p>当投票开始，还必须定位哪些选项是当前项。所以我们可能还需要一个vote条目，它用来存储当前投票的数据对，投票项应该是来自entries中的：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_pair.png\" alt=\"\"></p>\n<p>除此之外，投票的计数也应该被保存起来：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_tally.png\" alt=\"\"></p>\n<p>每次用户进行二选一后，未被选择的那项直接丢弃，被选择的条目重新放回entries的末尾，然后从entries头部选择下一对投票项：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_next.png\" alt=\"\"></p>\n<p>我们可以想象一下，这么周而复始的投票，最终将会得到一个结果，投票也就结束了：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_winner.png\" alt=\"\"></p>\n<p>如此设计看起来是合情合理的。针对上面的场景存在很多不同的设计，我们当前的做法也可能不是最佳的，但我们暂时就先这么定吧，足够我们进行下一步了。最重要的是我们在没有写任何代码的前提下已经从最初的点子过渡到确定了应用的具体功能。</p>\n<p>###项目安排</p>\n<p>是时候开始脏活累活了。开始之前，我们先创建一个项目目录：</p>\n<pre><code>mkdir voting-server\ncd voting-server\nnpm init         #所有提示问题直接敲回车即可\n</code></pre><p>初始化完毕后，我们的项目目录下将会只存在一个<em>package.json</em>文件。</p>\n<p>我们将采用ES6语法来写代码。Node是从4.0.0版本后开始支持大多数ES6语法的，并且目前并不支持modules，但我们需要用到。我们将加入Babel，这样我们就能将ES6直接转换成ES5了：</p>\n<pre><code>npm install --save-dev babel\n</code></pre><p>我们还需要些库来用于写单元测试：</p>\n<pre><code>npm install --save-dev mocha chai\n</code></pre><p><a href=\"https://mochajs.org/\" target=\"_blank\" rel=\"external\">Mocha</a>是一个我们将要使用的测试框架，<a href=\"http://chaijs.com/\" target=\"_blank\" rel=\"external\">Chai</a>是一个我们用来测试的断言库。</p>\n<p>我们将使用下面的mocha命令来跑测试项：</p>\n<pre><code>./node_modules/mocha/bin/mocha --compilers js:babel/register --recursive\n</code></pre><p>这条命令告诉Mocha递归的去项目中查找并执行所有测试项，但执行前先使用Babel进行语法转换。</p>\n<p>为了使用方便，可以在我们的<em>package.json</em>中添加下面这段代码：</p>\n<pre><code>&quot;scripts&quot;: {\n      &quot;test&quot;: &quot;mocha --compilers js:babel/register --recursive&quot;\n},\n</code></pre><p>这样以后我们跑测试就只需要执行：</p>\n<pre><code>npm run test\n</code></pre><p>另外，我们还可以添加<em>test:watch</em>命令，它用来监控文件变化并自动跑测试项：</p>\n<pre><code>&quot;scripts&quot;: {\n      &quot;test&quot;: &quot;mocha --compilers js:babel/register --recursive&quot;,\n      &quot;test:watch&quot;: &quot;npm run test -- --watch&quot;\n},\n</code></pre><p>我们还将用到一个库，来自于facebook：<a href=\"http://facebook.github.io/immutable-js/\" target=\"_blank\" rel=\"external\">Immutable</a>，它提供了许多数据结构供我们使用。下一小节我们再来讨论Immutable，但我们在这里先将它加入到我们的项目中，附带<a href=\"https://github.com/astorije/chai-immutable\" target=\"_blank\" rel=\"external\">chai-immutable</a>库，它用来向Chai库加入不可变数据结构比对功能：</p>\n<pre><code>npm install --save immutable\nnpm install --save-dev chai-immutable\n</code></pre><p>我们需要在所有测试代码前先加入chai-immutable插件，所以我们来先创建一个测试辅助文件：</p>\n<pre><code>//test/test_helper.js\n\nimport chai from &apos;chai&apos;;\nimport chaiImmutable from &apos;chai-immutable&apos;;\n\nchai.use(chaiImmutable);\n</code></pre><p>然后我们需要让Mocha在开始跑测试之前先加载这个文件，修改package.json：</p>\n<pre><code>&quot;scripts&quot;: {\n      &quot;test&quot;: &quot;mocha --compilers js:babel/register --        require ./test/test_helper.js  --recursive&quot;,\n      &quot;test:watch&quot;: &quot;npm run test -- --watch&quot;\n},\n</code></pre><p>好了，准备的差不多了。</p>\n<p>###酸爽的Immutable</p>\n<p>第二个值得重视的点是，Redux架构下状态并非只是一个普通的tree，而是一棵不可变的tree。</p>\n<p>回想一下前面我们设计的状态tree，你可能会觉得可以直接在应用的代码里直接更新tree：修改映射的值，或删除数组元素等。然而，这并不是Redux允许的。</p>\n<p>一个Redux应用的状态树是不可变的数据结构。这意味着，一旦你得到了一棵状态树，它就不会在改变了。任何用户行为改变应用状态，你都会获取一棵映射应用改变后新状态的完整状态树。</p>\n<p>这说明任何连续的状态（改变前后）都被分别存储在独立的两棵树。你通过调用一个函数来从一种状态转入下一个状态。</p>\n<p><img src=\"http://teropa.info/images/vote_state_succession.png\" alt=\"\"></p>\n<p>这么做好在哪呢？第一，用户通常想一个undo功能，当你误操作导致破坏了应用状态后，你往往想退回到应用的历史状态，而单一的状态tree让该需求变得廉价，你只需要简单保存上一个状态tree的数据即可。你也可以序列化tree并存储起来以供将来重放，这对debug很有帮助的。</p>\n<p>抛开其它的特性不谈，不可变数据至少会让你的代码变得简单，这非常重要。你可以用纯函数来进行编程：接受参数数据，返回数据，其它啥都不做。这种函数拥有可预见性，你可以多次调用它，只要参数一致，它总返回相同的结果（冪等性）。测试将变的容易，你不需要在测试前创建太多的准备，仅仅是传入参数和返回值。</p>\n<p>不可变数据结构是我们创建应用状态的基础，让我们花点时间来写一些测试项来保证它的正常工作。</p>\n<p>为了更了解不可变性，我们来看一个十分简单的数据结构：假设我们有一个计数应用，它只包含一个计数器变量，该变量会从0增加到1，增加到2，增加到3，以此类推。</p>\n<p>如果用不可变数据来设计这个计数器变量，则每当计数器自增，我们不是去改变变量本身。你可以想象成该计数器变量没有“setters”方法，你不能执行<code>42.setValue(43)</code>。</p>\n<p>每当变化发生，我们将获得一个新的变量，它的值是之前的那个变量的值加1等到的。我们可以为此写一个纯函数，它接受一个参数代表当前的状态，并返回一个值表示新的状态。记住，调用它并会修改传入参数的值。这里看一下函数实现和测试代码：</p>\n<pre><code>//test/immutable_spec.js\n\nimport {expect} from &apos;chai&apos;;\n\ndescribe(&apos;immutability&apos;, () =&gt; {\n\n      describe(&apos;a number&apos;, () =&gt; {\n\n        function increment(currentState) {\n              return currentState + 1;\n        }\n\n        it(&apos;is immutable&apos;, () =&gt; {\n              let state = 42;\n              let nextState = increment(state);\n\n              expect(nextState).to.equal(43);\n              expect(state).to.equal(42);\n        });\n\n      });\n});\n</code></pre><p>可以看到当<code>increment</code>调用后<code>state</code>并没有被修改，这是因为<code>Numbers</code>是不可变的。</p>\n<p>我们接下来要做的是让各种数据结构都不可变，而不仅仅是一个整数。</p>\n<p>利用Immutable提供的<a href=\"https://facebook.github.io/immutable-js/docs/#/Listf\" target=\"_blank\" rel=\"external\">Lists</a>，我们可以假设我们的应用拥有一个电影列表的状态，并且有一个操作用来向当前列表中添加新电影，新列表数据是添加前的列表数据和新增的电影条目合并后的结果，注意，添加前的旧列表数据并没有被修改哦：</p>\n<pre><code>//test/immutable_spec.json\n\nimport {expect} from &apos;chai&apos;;\nimport {List} from &apos;immutable&apos;;\n\ndescribe(&apos;immutability&apos;, () =&gt; {\n\n      // ...\n\n      describe(&apos;A List&apos;, () =&gt; {\n\n        function addMovie(currentState, movie) {\n              return currentState.push(movie);\n        }\n\n        it(&apos;is immutable&apos;, () =&gt; {\n              let state = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n              let nextState = addMovie(state, &apos;Sunshine&apos;);\n\n              expect(nextState).to.equal(List.of(\n                &apos;Trainspotting&apos;,\n                &apos;28 Days Later&apos;,\n                &apos;Sunshine&apos;\n              ));\n              expect(state).to.equal(List.of(\n                &apos;Trainspotting&apos;,\n                &apos;28 Days Later&apos;\n              ));\n        });\n      });\n});\n</code></pre><p>如果我们使用的是原生态js数组，那么上面的<code>addMovie</code>函数并不会保证旧的状态不会被修改。这里我们使用的是Immutable List。</p>\n<p>真实软件中，一个状态树通常是嵌套了多种数据结构的：list，map以及其它类型的集合。假设状态树是一个包含了<em>movies</em>列表的hash map，添加一个电影意味着我们需要创建一个新的map，并且在新的map的<em>movies</em>元素中添加该新增数据：</p>\n<pre><code>//test/immutable_spec.json\n\nimport {expect} from &apos;chai&apos;;\nimport {List, Map} from &apos;immutable&apos;;\n\ndescribe(&apos;immutability&apos;, () =&gt; {\n\n      // ...\n\n      describe(&apos;a tree&apos;, () =&gt; {\n\n        function addMovie(currentState, movie) {\n              return currentState.set(\n                &apos;movies&apos;,\n                    currentState.get(&apos;movies&apos;).push(movie)\n              );\n        }\n\n        it(&apos;is immutable&apos;, () =&gt; {\n              let state = Map({\n                movies: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n              });\n              let nextState = addMovie(state, &apos;Sunshine&apos;);\n\n              expect(nextState).to.equal(Map({\n                movies: List.of(\n                      &apos;Trainspotting&apos;,\n                      &apos;28 Days Later&apos;,\n                      &apos;Sunshine&apos;\n                )\n              }));\n              expect(state).to.equal(Map({\n                    movies: List.of(\n                      &apos;Trainspotting&apos;,\n                      &apos;28 Days Later&apos;\n                )\n              }));\n        });\n      });\n});\n</code></pre><p>该例子和前面的那个类似，主要用来展示在嵌套结构下Immutable的行为。</p>\n<p>针对类似上面这个例子的嵌套数据结构，Immutable提供了很多辅助函数，可以帮助我们更容易的定位嵌套数据的内部属性，以达到更新对应值的目的。我们可以使用一个叫<code>update</code>的方法来修改上面的代码：</p>\n<pre><code>//test/immutable_spec.json\n\nfunction addMovie(currentState, movie) {\n      return currentState.update(&apos;movies&apos;, movies =&gt; movies.push(movie));\n}\n</code></pre><p>现在我们很好的了解了不可变数据，这将被用于我们的应用状态。<a href=\"https://facebook.github.io/immutable-js/docs/#/\" target=\"_blank\" rel=\"external\">Immutable API</a>提供了非常多的辅助函数，我们目前只是学了点皮毛。</p>\n<p>不可变数据是Redux的核心理念，但并不是必须使用Immutable库来实现这个特性。事实上，<a href=\"http://rackt.github.io/redux/\" target=\"_blank\" rel=\"external\">官方Redux文档</a>使用的是原生js对象和数组，并通过简单的扩展它们来实现的。</p>\n<p>这个教程中，我们将使用Immutable库，原因如下：</p>\n<ul>\n<li>该库将使得实现不可变数据结构变得非常简单；</li>\n<li>我个人偏爱于将尽可能的使用不可变数据，如果你的数据允许直接修改，迟早会有人踩坑；</li>\n<li>不可变数据结构更新是持续的，意味着很容易产生性能平静，特别维护是非常庞大的状态树，使用原生js对象和数组意味着要频繁的进行拷贝，很容易导致性能问题。</li>\n</ul>\n<p>###基于纯函数实现应用逻辑</p>\n<p>根据目前我们掌握的不可变状态树和相关操作，我们可以尝试实现投票应用的逻辑。应用的核心逻辑我们拆分成：状态树结构和生成新状态树的函数集合。</p>\n<p>####加载条目</p>\n<p>首先，之前说到，应用允许“加载”一个用来投票的条目集。我们需要一个<code>setEntries</code>函数，它用来提供应用的初始化状态：</p>\n<pre><code>//test/core_spec.js\n\nimport {List, Map} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport {setEntries} from &apos;../src/core&apos;;\n\ndescribe(&apos;application logic&apos;, () =&gt; {\n\n  describe(&apos;setEntries&apos;, () =&gt; {\n\n    it(&apos;adds the entries to the state&apos;, () =&gt; {\n      const state = Map();\n      const entries = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n      const nextState = setEntries(state, entries);\n      expect(nextState).to.equal(Map({\n        entries: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n      }));\n    });\n  });\n});\n</code></pre><p>我们目前<code>setEntries</code>函数的第一版非常简单：在状态map中创建一个<code>entries</code>键，并设置给定的条目List。</p>\n<pre><code>//src/core.js\n\nexport function setEntries(state, entries) {\n    return state.set(&apos;entries&apos;, entries);\n}\n</code></pre><p>为了方便起见，我们允许函数第二个参数接受一个原生js数组（或支持iterable的类型），但在状态树中它应该是一个Immutable List：</p>\n<pre><code>//test/core_spec.js\n\nit(&apos;converts to immutable&apos;, () =&gt; {\n  const state = Map();\n  const entries = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n  const nextState = setEntries(state, entries);\n  expect(nextState).to.equal(Map({\n    entries: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n  }));\n});\n</code></pre><p>为了达到要求，我们需要修改一下代码：</p>\n<pre><code>//src/core.js\n\nimport {List} from &apos;immutable&apos;;\n\nexport function setEntries(state, entries) {\n  return state.set(&apos;entries&apos;, List(entries));\n}\n</code></pre><p>####开始投票</p>\n<p>当state加载了条目集合后，我们可以调用一个<code>next</code>函数来开始投票。这表示，我们到了之前设计的状态树的第二阶段。</p>\n<p><code>next</code>函数需要在状态树创建中一个投票map，该map有拥有一个<code>pair</code>键，值为投票条目中的前两个元素。<br>这两个元素一旦确定，就要从之前的条目列表中清除：</p>\n<pre><code>//test/core_spec.js\n\nimport {List, Map} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\nimport {setEntries, next} from &apos;../src/core&apos;;\n\ndescribe(&apos;application logic&apos;, () =&gt; {\n\n  // ..\n\n  describe(&apos;next&apos;, () =&gt; {\n\n    it(&apos;takes the next two entries under vote&apos;, () =&gt; {\n      const state = Map({\n        entries: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;, &apos;Sunshine&apos;)\n      });\n      const nextState = next(state);\n      expect(nextState).to.equal(Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n        }),\n        entries: List.of(&apos;Sunshine&apos;)\n      }));\n    });\n  });\n});\n</code></pre><p><code>next</code>函数实现如下：</p>\n<pre><code>//src/core.js\n\nimport {List, Map} from &apos;immutable&apos;;\n\n// ...\n\nexport function next(state) {\n  const entries = state.get(&apos;entries&apos;);\n  return state.merge({\n    vote: Map({pair: entries.take(2)}),\n    entries: entries.skip(2)\n  });\n}\n</code></pre><p>####投票</p>\n<p>当用户产生投票行为后，每当用户给某个条目投了一票后，<code>vote</code>将会为这个条目添加<code>tally</code>信息，如果对应的<br>条目信息已存在，则需要则增：</p>\n<pre><code>//test/core_spec.js\n\nimport {List, Map} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\nimport {setEntries, next, vote} from &apos;../src/core&apos;;\n\ndescribe(&apos;application logic&apos;, () =&gt; {\n\n  // ...\n\n  describe(&apos;vote&apos;, () =&gt; {\n\n    it(&apos;creates a tally for the voted entry&apos;, () =&gt; {\n      const state = Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n        }),\n        entries: List()\n      });\n      const nextState = vote(state, &apos;Trainspotting&apos;);\n      expect(nextState).to.equal(Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({\n            &apos;Trainspotting&apos;: 1\n          })\n        }),\n        entries: List()\n      }));\n    });\n\n    it(&apos;adds to existing tally for the voted entry&apos;, () =&gt; {\n      const state = Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({\n            &apos;Trainspotting&apos;: 3,\n            &apos;28 Days Later&apos;: 2\n          })\n        }),\n        entries: List()\n      });\n      const nextState = vote(state, &apos;Trainspotting&apos;);\n      expect(nextState).to.equal(Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({\n            &apos;Trainspotting&apos;: 4,\n            &apos;28 Days Later&apos;: 2\n          })\n        }),\n        entries: List()\n      }));\n    });\n  });\n});\n</code></pre><p>为了让上面的测试项通过，我们可以如下实现<code>vote</code>函数：</p>\n<pre><code>//src/core.js\n\nexport function vote(state, entry) {\n  return state.updateIn(\n    [&apos;vote&apos;, &apos;tally&apos;, entry],\n    0,\n    tally =&gt; tally + 1\n  );\n}\n</code></pre><p><a href=\"https://facebook.github.io/immutable-js/docs/#/Map/updateIn\" target=\"_blank\" rel=\"external\">updateIn</a>让我们更容易完成目标。<br>它接受的第一个参数是个表达式，含义是“定位到嵌套数据结构的指定位置，路径为：[‘vote’, ‘tally’, ‘Trainspotting’]”，<br>并且执行后面逻辑：如果路径指定的位置不存在，则创建新的映射对，并初始化为0，否则对应值加1。</p>\n<p>可能对你来说上面的语法太过于晦涩，但一旦你掌握了它，你将会发现用起来非常的酸爽，所以花一些时间学习并<br>适应它是非常值得的。</p>\n<p>####继续投票</p>\n<p>每次完成一次二选一投票，用户将进入到第二轮投票，每次得票最高的选项将被保存并添加回条目集合。我们需要添加<br>这个逻辑到<code>next</code>函数中：</p>\n<pre><code>//test/core_spec.js\n\ndescribe(&apos;next&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;puts winner of current vote back to entries&apos;, () =&gt; {\n    const state = Map({\n      vote: Map({\n        pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n        tally: Map({\n          &apos;Trainspotting&apos;: 4,\n          &apos;28 Days Later&apos;: 2\n        })\n      }),\n      entries: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;, &apos;127 Hours&apos;)\n    });\n    const nextState = next(state);\n    expect(nextState).to.equal(Map({\n      vote: Map({\n        pair: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;)\n      }),\n      entries: List.of(&apos;127 Hours&apos;, &apos;Trainspotting&apos;)\n    }));\n  });\n\n  it(&apos;puts both from tied vote back to entries&apos;, () =&gt; {\n    const state = Map({\n      vote: Map({\n        pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n        tally: Map({\n          &apos;Trainspotting&apos;: 3,\n          &apos;28 Days Later&apos;: 3\n        })\n      }),\n      entries: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;, &apos;127 Hours&apos;)\n    });\n    const nextState = next(state);\n    expect(nextState).to.equal(Map({\n      vote: Map({\n        pair: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;)\n      }),\n      entries: List.of(&apos;127 Hours&apos;, &apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n    }));\n  });\n});\n</code></pre><p>我们需要一个<code>getWinners</code>函数来帮我们选择谁是赢家：</p>\n<pre><code>//src/core.js\n\nfunction getWinners(vote) {\n  if (!vote) return [];\n  const [a, b] = vote.get(&apos;pair&apos;);\n  const aVotes = vote.getIn([&apos;tally&apos;, a], 0);\n  const bVotes = vote.getIn([&apos;tally&apos;, b], 0);\n  if      (aVotes &gt; bVotes)  return [a];\n  else if (aVotes &lt; bVotes)  return [b];\n  else                       return [a, b];\n}\n\nexport function next(state) {\n  const entries = state.get(&apos;entries&apos;)\n                       .concat(getWinners(state.get(&apos;vote&apos;)));\n  return state.merge({\n    vote: Map({pair: entries.take(2)}),\n    entries: entries.skip(2)\n  });\n}\n</code></pre><p>####投票结束</p>\n<p>当投票项只剩一个时，投票结束：</p>\n<pre><code>//test/core_spec.js\n\ndescribe(&apos;next&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;marks winner when just one entry left&apos;, () =&gt; {\n    const state = Map({\n      vote: Map({\n        pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n        tally: Map({\n          &apos;Trainspotting&apos;: 4,\n          &apos;28 Days Later&apos;: 2\n        })\n      }),\n      entries: List()\n    });\n    const nextState = next(state);\n    expect(nextState).to.equal(Map({\n      winner: &apos;Trainspotting&apos;\n    }));\n  });\n});\n</code></pre><p>我们需要在<code>next</code>函数中增加一个条件分支，用来匹配上面的逻辑：</p>\n<pre><code>//src/core.js\n\nexport function next(state) {\n  const entries = state.get(&apos;entries&apos;)\n                       .concat(getWinners(state.get(&apos;vote&apos;)));\n  if (entries.size === 1) {\n    return state.remove(&apos;vote&apos;)\n                .remove(&apos;entries&apos;)\n                .set(&apos;winner&apos;, entries.first());\n  } else {\n    return state.merge({\n      vote: Map({pair: entries.take(2)}),\n      entries: entries.skip(2)\n    });\n  }\n}\n</code></pre><p>我们可以直接返回<code>Map({winner: entries.first()})</code>，但我们还是基于旧的状态数据进行一步一步的<br>操作最终得到结果，这么做是为将来做打算。因为应用将来可能还会有很多其它状态数据在Map中，这是一个写测试项的好习惯。<br>所以我们以后要记住，不要重新创建一个状态数据，而是从旧的状态数据中生成新的状态实例。</p>\n<p>到此为止我们已经有了一套可以接受的应用核心逻辑实现，表现形式为几个独立的函数。我们也有针对这些函数的<br>测试代码，这些测试项很容易写：No setup, no mocks, no stubs。这就是纯函数的魅力，我们只需要调用它们，<br>并检查返回值就行了。</p>\n<p>提醒一下，我们目前还没有安装redux哦，我们就已经可以专注于应用自身的逻辑本身进行实现，而不被所谓的框架<br>所干扰。这真的很不错，对吧？</p>\n<p>###初识Actions和Reducers</p>\n<p>我们有了应用的核心函数，但在Redux中我们不应该直接调用函数。在这些函数和应用之间还存在这一个中间层：Actions。</p>\n<p>Action是一个描述应用状态变化发生的简单数据结构。按照约定，每个action都包含一个<code>type</code>属性，<br>该属性用于描述操作类型。action通常还包含其它属性，下面是一个简单的action例子，该action用来匹配<br>前面我们写的业务操作：</p>\n<pre><code>{type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]}\n\n{type: &apos;NEXT&apos;}\n\n{type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;}\n</code></pre><p>actions的描述就这些，但我们还需要一种方式用来把它绑定到我们实际的核心函数上。举个例子：</p>\n<pre><code>// 定义一个action\nlet voteAction = {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;}\n// 该action应该触发下面的逻辑\nreturn vote(state, voteAction.entry);\n</code></pre><p>我们接下来要用到的是一个普通函数，它用来根据action和当前state来调用指定的核心函数，我们称这种函数叫：<br>reducer：</p>\n<pre><code>//src/reducer.js\n\nexport default function reducer(state, action) {\n  // Figure out which function to call and call it\n}\n</code></pre><p>我们应该测试这个reducer是否可以正确匹配我们之前的三个actions：</p>\n<pre><code>//test/reducer_spec.js\n\nimport {Map, fromJS} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport reducer from &apos;../src/reducer&apos;;\n\ndescribe(&apos;reducer&apos;, () =&gt; {\n\n  it(&apos;handles SET_ENTRIES&apos;, () =&gt; {\n    const initialState = Map();\n    const action = {type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;]};\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      entries: [&apos;Trainspotting&apos;]\n    }));\n  });\n\n  it(&apos;handles NEXT&apos;, () =&gt; {\n    const initialState = fromJS({\n      entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n    });\n    const action = {type: &apos;NEXT&apos;};\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n      },\n      entries: []\n    }));\n  });\n\n  it(&apos;handles VOTE&apos;, () =&gt; {\n    const initialState = fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n      },\n      entries: []\n    });\n    const action = {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;};\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      },\n      entries: []\n    }));\n  });\n});\n</code></pre><p>我们的reducer将根据action的type来选择对应的核心函数，它同时也应该知道如何使用action的额外属性：</p>\n<pre><code>//src/reducer.js\n\nimport {setEntries, next, vote} from &apos;./core&apos;;\n\nexport default function reducer(state, action) {\n  switch (action.type) {\n  case &apos;SET_ENTRIES&apos;:\n    return setEntries(state, action.entries);\n  case &apos;NEXT&apos;:\n    return next(state);\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry)\n  }\n  return state;\n}\n</code></pre><p>注意，如果reducer没有匹配到action，则应该返回当前的state。</p>\n<p>reducers还有一个需要特别注意的地方，那就是当传递一个未定义的state参数时，reducers应该知道如何<br>初始化state为有意义的值。我们的场景中，初始值为Map，因此如果传给reducer一个<code>undefined</code>state的话，<br>reducers将使用一个空的Map来代替：</p>\n<pre><code>//test/reducer_spec.js\n\ndescribe(&apos;reducer&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;has an initial state&apos;, () =&gt; {\n    const action = {type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;]};\n    const nextState = reducer(undefined, action);\n    expect(nextState).to.equal(fromJS({\n      entries: [&apos;Trainspotting&apos;]\n    }));\n  });\n});\n</code></pre><p>之前在我们的<code>cores.js</code>文件中，我们定义了初始值：</p>\n<pre><code>//src/core.js\n\nexport const INITIAL_STATE = Map();\n</code></pre><p>所以在reducer中我们可以直接导入它：</p>\n<pre><code>//src/reducer.js\n\nimport {setEntries, next, vote, INITIAL_STATE} from &apos;./core&apos;;\n\nexport default function reducer(state = INITIAL_STATE, action) {\n  switch (action.type) {\n  case &apos;SET_ENTRIES&apos;:\n    return setEntries(state, action.entries);\n  case &apos;NEXT&apos;:\n    return next(state);\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry)\n  }\n  return state;\n}\n</code></pre><p>事实上，提供一个action集合，你可以将它们分解并作用在当前状态上，这也是为什么称它们为reducer的原因：<br>它完全适配reduce方法：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;can be used with reduce&apos;, () =&gt; {\n  const actions = [\n    {type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]},\n    {type: &apos;NEXT&apos;},\n    {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;},\n    {type: &apos;VOTE&apos;, entry: &apos;28 Days Later&apos;},\n    {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;},\n    {type: &apos;NEXT&apos;}\n  ];\n  const finalState = actions.reduce(reducer, Map());\n\n  expect(finalState).to.equal(fromJS({\n    winner: &apos;Trainspotting&apos;\n  }));\n});\n</code></pre><p>相比直接调用核心业务函数，这种批处理或称之为重放一个action集合的能力主要依赖于状态转换的action/reducer模型。<br>举个例子，你可以把actions序列化成json，并轻松的将它发送给Web Worker去执行你的reducer逻辑。或者<br>直接通过网络发送到其它地方供日后执行！</p>\n<p>注意我们这里使用的是普通js对象作为actions，而并非不可变数据类型。这是Redux提倡我们的做法。</p>\n<p>###尝试Reducer协作</p>\n<p>目前我们的核心函数都是接受整个state并返回更新后的整个state。</p>\n<p>这么做在大型应用中可能并不太明智。如果你的应用所有操作都要求必须接受完整的state，那么这个项目维护起来就是灾难。<br>日后如果你想进行state结构的调整，你将会付出惨痛的代价。</p>\n<p>其实有更好的做法，你只需要保证组件操作尽可能小的state片段即可。我们这里提到的就是模块化思想：<br>提供给模块仅它需要的数据，不多不少。</p>\n<p>我们的应用很小，所以这并不是太大的问题，但我们还是选择改善这一点：没有必要给<code>vote</code>函数传递整个state，它只需要<code>vote</code><br>部分。让我们修改一下对应的测试代码：</p>\n<pre><code>//test/core_spec.js\n\ndescribe(&apos;vote&apos;, () =&gt; {\n\n  it(&apos;creates a tally for the voted entry&apos;, () =&gt; {\n    const state = Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n    });\n    const nextState = vote(state, &apos;Trainspotting&apos;)\n    expect(nextState).to.equal(Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n      tally: Map({\n        &apos;Trainspotting&apos;: 1\n      })\n    }));\n  });\n\n  it(&apos;adds to existing tally for the voted entry&apos;, () =&gt; {\n    const state = Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n      tally: Map({\n        &apos;Trainspotting&apos;: 3,\n        &apos;28 Days Later&apos;: 2\n      })\n    });\n    const nextState = vote(state, &apos;Trainspotting&apos;);\n    expect(nextState).to.equal(Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n      tally: Map({\n        &apos;Trainspotting&apos;: 4,\n        &apos;28 Days Later&apos;: 2\n      })\n    }));\n  });\n});\n</code></pre><p>看，测试代码更加简单了。</p>\n<p><code>vote</code>函数的实现也需要更新：</p>\n<pre><code>//src/core.js\n\nexport function vote(voteState, entry) {\n  return voteState.updateIn(\n    [&apos;tally&apos;, entry],\n    0,\n    tally =&gt; tally + 1\n  );\n}\n</code></pre><p>最后我们还需要修改<code>reducer</code>，只传递需要的state给<code>vote</code>函数：</p>\n<pre><code>//src/reducer.js\n\nexport default function reducer(state = INITIAL_STATE, action) {\n  switch (action.type) {\n  case &apos;SET_ENTRIES&apos;:\n    return setEntries(state, action.entries);\n  case &apos;NEXT&apos;:\n    return next(state);\n  case &apos;VOTE&apos;:\n    return state.update(&apos;vote&apos;,\n                        voteState =&gt; vote(voteState, action.entry));\n  }\n  return state;\n}\n</code></pre><p>这个做法在大型项目中非常重要：根reducer只传递部分state给下一级reducer。我们将定位合适的state片段的工作<br>从对应的更新操作中分离出来。</p>\n<p><a href=\"http://rackt.github.io/redux/docs/basics/Reducers.html\" target=\"_blank\" rel=\"external\">Redux的reducers文档</a>针对这一细节<br>介绍了更多内容，并描述了一些辅助函数的用法，可以在更多长场景中有效的使用。</p>\n<p>###初识Redux Store</p>\n<p>现在我们可以开始了解如何将上面介绍的内容使用在Redux中了。</p>\n<p>如你所见，如果你有一个actions集合，你可以调用<code>reduce</code>，获得最终的应用状态。当然，通常情况下不会如此，actions<br>将会在不同的时间发生：用户操作，远程调用，超时触发器等。</p>\n<p>针对这些情况，我们可以使用Redux Store。从名字可以看出它用来存储应用的状态。</p>\n<p>Redux Store通常会由一个reducer函数初始化，如我们之前实现的：</p>\n<pre><code>import {createStore} from &apos;redux&apos;;\n\nconst store = createStore(reducer);\n</code></pre><p>接下来你就可以向这个Store指派actions了。Store内部将会使用你实现的reducer来处理action，并负责传递给<br>reducer应用的state，最后负责存储reducer返回的新state：</p>\n<pre><code>store.dispatch({type: &apos;NEXT&apos;});\n</code></pre><p>任何时刻你都可以通过下面的方法获取当前的state：</p>\n<pre><code>store.getState();\n</code></pre><p>我们将会创建一个<code>store.js</code>用来初始化和导出一个Redux Store对象。让我们先写测试代码吧：</p>\n<pre><code>//test/store_spec.js\n\nimport {Map, fromJS} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport makeStore from &apos;../src/store&apos;;\n\ndescribe(&apos;store&apos;, () =&gt; {\n\n  it(&apos;is a Redux store configured with the correct reducer&apos;, () =&gt; {\n    const store = makeStore();\n    expect(store.getState()).to.equal(Map());\n\n    store.dispatch({\n      type: &apos;SET_ENTRIES&apos;,\n      entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n    });\n    expect(store.getState()).to.equal(fromJS({\n      entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n    }));\n  });\n});\n</code></pre><p>在创建Store之前，我们先在项目中加入Redux库：</p>\n<pre><code>npm install --save redux\n</code></pre><p>然后我们新建<code>store.js</code>文件，如下：</p>\n<pre><code>//src/store.js\n\nimport {createStore} from &apos;redux&apos;;\nimport reducer from &apos;./reducer&apos;;\n\nexport default function makeStore() {\n  return createStore(reducer);\n}\n</code></pre><p>Redux Store负责将应用的所有组件关联起来：它持有应用的当前状态，并负责指派actions，且负责调用包含了<br>业务逻辑的reducer。</p>\n<p>应用的业务代码和Redux的整合方式非常引人注目，因为我们只有一个普通的reducer函数，这是唯一需要告诉Redux<br>的事儿。其它部分全部都是我们自己的，没有框架入侵的，高便携的纯函数代码！</p>\n<p>现在我们创建一个应用的入口文件<code>index.js</code>：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\n\nexport const store = makeStore();\n</code></pre><p>现在我们可以开启一个<a href=\"http://segmentfault.com/a/1190000002673137\" target=\"_blank\" rel=\"external\">Node REPL</a>（例如babel-node）,<br>载入<code>index.js</code>文件来测试执行了。</p>\n<p>###配置Socket.io服务</p>\n<p>我们的应用服务端用来为一个提供投票和显示结果浏览器端提供服务的，为了这个目的，我们需要考虑两端通信的方式。</p>\n<p>这个应用需要实时通信，这确保我们的投票者可以实时查看到所有人的投票信息。为此，我们选择使用WebSockets作为<br>通信方式。因此，我们选择<a href=\"http://socket.io/\" target=\"_blank\" rel=\"external\">Socket.io</a>库作为跨终端的websocket抽象实现层，它在客户端<br>不支持websocket的情况下提供了多种备选方案。</p>\n<p>让我们在项目中加入Socket.io：</p>\n<pre><code>npm install --save socket.io\n</code></pre><p>现在，让我新建一个<code>server.js</code>文件：</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport default function startServer() {\nconst io = new Server().attach(8090);\n}\n</code></pre><p>这里我们创建了一个Socket.io 服务，绑定8090端口。端口号是我随意选的，你可以更改，但后面客户端连接时<br>要注意匹配。</p>\n<p>现在我们可以在<code>index.js</code>中调用这个函数：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\nimport startServer from &apos;./src/server&apos;;\n\nexport const store = makeStore();\nstartServer();\n</code></pre><p>我们现在可以在<code>package.json</code>中添加<code>start</code>指令来方便启动应用：</p>\n<pre><code>//package.json\n&quot;scripts&quot;: {\n    &quot;start&quot;: &quot;babel-node index.js&quot;,\n    &quot;test&quot;: &quot;mocha --compilers js:babel/register  --require ./test/test_helper.js  --recursive&quot;,\n    &quot;test:watch&quot;: &quot;npm run test --watch&quot;\n},\n</code></pre><p>这样我们就可以直接执行下面命令来开启应用：</p>\n<pre><code>npm run start\n</code></pre><p>###用Redux监听器传播State</p>\n<p>我们现在拥有了一个Socket.io服务，也建立了Redux状态容器，但它们并没有整合在一起，这就是我们接下来要做的事儿。</p>\n<p>我们的服务端需要让客户端知道当前的应用状态（例如：“正在投票的项目是什么？”，“当前的票数是什么？”，<br>“已经出来结果了吗？”）。这些都可以通过每当变化发生时<a href=\"http://socket.io/docs/server-api/#server#emit\" target=\"_blank\" rel=\"external\">触发Socket.io事件</a>来实现。</p>\n<p>我们如何得知什么时候发生变化？Redux对此提供了方案：你可以订阅Redux Store。这样每当store指派了action之后，在可能发生变化前<br>会调用你提供的指定回调函数。</p>\n<p>我们要修改一下<code>startServer</code>实现，我们先来调整一下index.js：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\nimport {startServer} from &apos;./src/server&apos;;\n\nexport const store = makeStore();\nstartServer(store);\n</code></pre><p>接下来我们只需监听store的状态，并把它序列化后用socket.io事件传播给所有处于连接状态的客户端。</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport function startServer(store) {\n  const io = new Server().attach(8090);\n\n  store.subscribe(\n    () =&gt; io.emit(&apos;state&apos;, store.getState().toJS())\n  );\n}\n</code></pre><p>目前我们的做法是一旦状态有改变，就发送整个state给所有客户端，很容易想到这非常不友好，产生大量流量<br>损耗，更好的做法是只传递改变的state片段，但我们为了简单，在这个例子中就先这么实现吧。</p>\n<p>除了状态发生变化时发送状态数据外，每当新客户端连接服务器端时也应该直接发送当前的状态给该客户端。</p>\n<p>我们可以通过监听Socket.io的<code>connection</code>事件来实现上述需求：</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport function startServer(store) {\n  const io = new Server().attach(8090);\n\n  store.subscribe(\n    () =&gt; io.emit(&apos;state&apos;, store.getState().toJS())\n  );\n\n  io.on(&apos;connection&apos;, (socket) =&gt; {\n    socket.emit(&apos;state&apos;, store.getState().toJS());\n  });\n}\n</code></pre><p>###接受远程调用Redux Actions</p>\n<p>除了将应用状态同步给客户端外，我们还需要接受来自客户端的更新操作：投票者需要发起投票，投票组织者需要<br>发起下一轮投票的请求。</p>\n<p>我们的解决方案非常简单。我们只需要让客户端发布“action”事件即可，然后我们直接将事件发送给Redux Store：</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport function startServer(store) {\n  const io = new Server().attach(8090);\n\n  store.subscribe(\n    () =&gt; io.emit(&apos;state&apos;, store.getState().toJS())\n  );\n\n  io.on(&apos;connection&apos;, (socket) =&gt; {\n    socket.emit(&apos;state&apos;, store.getState().toJS());\n    socket.on(&apos;action&apos;, store.dispatch.bind(store));\n  });\n}\n</code></pre><p>这样我们就完成了远程调用actions。Redux架构让我们的项目更加简单：actions仅仅是js对象，可以很容易用于<br>网络传输，我们现在实现了一个支持多人投票的服务端系统，很有成就感吧。</p>\n<p>现在我们的服务端操作流程如下：</p>\n<ol>\n<li>客户端发送一个action给服务端；</li>\n<li>服务端交给Redux Store处理action；</li>\n<li>Store调用reducer，reducer执行对应的应用逻辑；</li>\n<li>Store根据reducer的返回结果来更新状态；</li>\n<li>Store触发服务端监听的回调函数；</li>\n<li>服务端触发“state”事件；</li>\n<li>所有连接的客户端接受到新的状态。</li>\n</ol>\n<p>在结束服务端开发之前，我们载入一些测试数据来感受一下。我们可以添加<code>entries.json</code>文件：</p>\n<pre><code>//entries.json\n\n[\n  &quot;Shallow Grave&quot;,\n  &quot;Trainspotting&quot;,\n  &quot;A Life Less Ordinary&quot;,\n  &quot;The Beach&quot;,\n  &quot;28 Days Later&quot;,\n  &quot;Millions&quot;,\n  &quot;Sunshine&quot;,\n  &quot;Slumdog Millionaire&quot;,\n  &quot;127 Hours&quot;,\n  &quot;Trance&quot;,\n  &quot;Steve Jobs&quot;\n]\n</code></pre><p>我们在<code>index.json</code>中加载它然后发起<code>next</code>action来开启投票：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\nimport {startServer} from &apos;./src/server&apos;;\n\nexport const store = makeStore();\nstartServer(store);\n\nstore.dispatch({\n  type: &apos;SET_ENTRIES&apos;,\n  entries: require(&apos;./entries.json&apos;)\n});\nstore.dispatch({type: &apos;NEXT&apos;});\n</code></pre><p>那么接下来我们就来看看如何实现客户端。</p>\n<p>##客户端应用</p>\n<p>本教程剩余的部分就是写一个React应用，用来连接服务端，并提供投票给使用者。</p>\n<p>在客户端我们依然使用Redux。这是更常见的搭配：用于React应用的底层引擎。我们已经了解到Redux如何使用。<br>现在我们将学习它是如何结合并影响React应用的。</p>\n<p>我推荐大家跟随本教程的步骤完成应用，但你也可以从<a href=\"https://github.com/teropa/redux-voting-client\" target=\"_blank\" rel=\"external\">github</a>上获取源码。</p>\n<p>###客户端项目创建</p>\n<p>第一件事儿我们当然是创建一个新的NPM项目，如下：</p>\n<pre><code>mkdir voting-client\ncd voting-client\nnpm init            # Just hit enter for each question\n</code></pre><p>我们的应用需要一个html主页，我们放在<code>dist/index.html</code>：</p>\n<pre><code>//dist/index.html\n\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n  &lt;div id=&quot;app&quot;&gt;&lt;/div&gt;\n  &lt;script src=&quot;bundle.js&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>这个页面包含一个id为app的<code>&lt;div&gt;</code>，我们将在其中插入我们的应用。在同级目录下还需要一个<code>bundle.js</code>文件。</p>\n<p>我们为应用新建第一个js文件，它是系统的入口文件。目前我们先简单的添加一行日志代码：</p>\n<pre><code>//src/index.js\nconsole.log(&apos;I am alive!&apos;);\n</code></pre><p>为了给我们客户端开发减负，我们将使用<a href=\"http://webpack.github.io/\" target=\"_blank\" rel=\"external\">Webpack</a>，让我们加入到项目中：</p>\n<pre><code>npm install --save-dev webpack webpack-dev-server\n</code></pre><p>接下来，我们在项目根目录新建一个Webpack配置文件：</p>\n<pre><code>//webpack.config.js\n\nmodule.exports = {\n  entry: [\n    &apos;./src/index.js&apos;\n  ],\n  output: {\n    path: __dirname + &apos;/dist&apos;,\n    publicPath: &apos;/&apos;,\n    filename: &apos;bundle.js&apos;\n  },\n  devServer: {\n    contentBase: &apos;./dist&apos;\n  }\n};\n</code></pre><p>配置表明将找到我们的<code>index.js</code>入口，并编译到<code>dist/bundle.js</code>中。同时把<code>dist</code>目录当作开发服务器根目录。</p>\n<p>你现在可以执行Webpack来生成<code>bundle.js</code>：</p>\n<pre><code>webpack\n</code></pre><p>你也可以开启一个开发服务器，访问localhost:8080来测试页面效果：</p>\n<pre><code>webpack-dev-server\n</code></pre><p>由于我们将使用ES6语法和React的<a href=\"https://facebook.github.io/jsx/\" target=\"_blank\" rel=\"external\">JSX语法</a>，我们需要一些工具。<br>Babel是一个非常合适的选择，我们需要Babel库：</p>\n<pre><code>npm install --save-dev babel-core babel-loader\n</code></pre><p>我们可以在Webpack配置文件中添加一些配置，这样webpack将会对<code>.jsx</code>和<code>.js</code>文件使用Babel进行处理：</p>\n<pre><code>//webpack.config.js\n\nmodule.exports = {\n    entry: [\n        &apos;./src/index.js&apos;\n    ],\n    module: {\n        loaders: [{\n            test: /\\.jsx?$/,\n            exclude: /node_modules/,\n            loader: &apos;babel&apos;\n        }]\n    },\n    resolve: {\n        extensions: [&apos;&apos;, &apos;.js&apos;, &apos;.jsx&apos;]\n    },\n    output: {\n        path: __dirname + &apos;/dist&apos;,\n        publicPath: &apos;/&apos;,\n        filename: &apos;bundle.js&apos;\n    },\n    devServer: {\n        contentBase: &apos;./dist&apos;\n    }\n};\n</code></pre><p>###单元测试支持</p>\n<p>我们也将会为客户端代码编写一些单元测试。我们使用与服务端相同的测试套件：</p>\n<pre><code>npm install --save-dev mocha chai\n</code></pre><p>我们也将会测试我们的React组件，这就要求需要一个DOM库。我们可能需要像<a href=\"http://karma-runner.github.io/0.13/index.html\" target=\"_blank\" rel=\"external\">Karma</a><br>库一样的功能来进行真实web浏览器测试。但我们这里准备使用一个node端纯js的dom库：</p>\n<pre><code>npm install --save-dev jsdom@3\n</code></pre><p>在用于react之前我们需要一些jsdom的预备代码。我们需要创建通常在浏览器端被提供的<code>document</code>和<code>window</code>对象。<br>并且将它们声明为全局对象，这样才能被React使用。我们可以创建一个测试辅助文件做这些工作：</p>\n<pre><code>//test/test_helper.js\n\nimport jsdom from &apos;jsdom&apos;;\n\nconst doc = jsdom.jsdom(&apos;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&apos;);\nconst win = doc.defaultView;\n\nglobal.document = doc;\nglobal.window = win;\n</code></pre><p>此外，我们还需要将jsdom提供的<code>window</code>对象的所有属性导入到Node.js的全局变量中，这样使用这些属性时<br>就不需要<code>window.</code>前缀，这才满足在浏览器环境下的用法：</p>\n<pre><code>//test/test_helper.js\n\nimport jsdom from &apos;jsdom&apos;;\n\nconst doc = jsdom.jsdom(&apos;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&apos;);\nconst win = doc.defaultView;\n\nglobal.document = doc;\nglobal.window = win;\n\nObject.keys(window).forEach((key) =&gt; {\n  if (!(key in global)) {\n    global[key] = window[key];\n  }\n});\n</code></pre><p>我们还需要使用Immutable集合，所以我们也需要参照后段配置添加相应的库：</p>\n<pre><code>npm install --save immutable\nnpm install --save-dev chai-immutable\n</code></pre><p>现在我们再次修改辅助文件：</p>\n<pre><code>//test/test_helper.js\n\nimport jsdom from &apos;jsdom&apos;;\nimport chai from &apos;chai&apos;;\nimport chaiImmutable from &apos;chai-immutable&apos;;\n\nconst doc = jsdom.jsdom(&apos;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&apos;);\nconst win = doc.defaultView;\n\nglobal.document = doc;\nglobal.window = win;\n\nObject.keys(window).forEach((key) =&gt; {\n  if (!(key in global)) {\n    global[key] = window[key];\n  }\n});\n\nchai.use(chaiImmutable);\n</code></pre><p>最后一步是在<code>package.json</code>中添加指令：</p>\n<pre><code>//package.json\n\n&quot;scripts&quot;: {\n  &quot;test&quot;: &quot;mocha --compilers js:babel-core/register --require ./test/test_helper.js &apos;test/**/*.@(js|jsx)&apos;&quot;\n},\n</code></pre><p>这几乎和我们在后端做的一样，只有两个地方不同：</p>\n<ul>\n<li>Babel的编译器名称：在该项目中我们使用<code>babel-core</code>代替<code>babel</code></li>\n<li>测试文件设置：服务端我们使用<code>--recursive</code>，但这么设置无法匹配<code>.jsx</code>文件，所以我们需要使用<br><a href=\"https://github.com/isaacs/node-glob\" target=\"_blank\" rel=\"external\">glob</a></li>\n</ul>\n<p>为了实现当代码发生修改后自动进行测试，我们依然添加<code>test:watch</code>指令：</p>\n<pre><code>//package.json\n\n&quot;scripts&quot;: {\n  &quot;test&quot;: &quot;mocha --compilers js:babel-core/register --require ./test/test_helper.js &apos;test/**/*.@(js|jsx)&apos;&quot;,\n  &quot;test:watch&quot;: &quot;npm run test -- --watch&quot;\n},\n</code></pre><p>###React和react-hot-loader</p>\n<p>最后我们来聊聊React！</p>\n<p>使用React+Redux+Immutable来开发应用真正酷毙的地方在于：我们可以用纯组件（有时候也称为蠢组件）思想实现<br>任何东西。这个概念与纯函数很类似，有如下一些规则：</p>\n<ol>\n<li>一个纯组件利用props接受所有它需要的数据，类似一个函数的入参，除此之外它不会被任何其它因素影响；</li>\n<li>一个纯组件通常没有内部状态。它用来渲染的数据完全来自于输入props，使用相同的props来渲染相同的纯组件多次，<br>将得到相同的UI。不存在隐藏的内部状态导致渲染不同。</li>\n</ol>\n<p>这就带来了<a href=\"https://www.youtube.com/watch?v=1uRC3hmKQnM&amp;feature=youtu.be&amp;t=13m10s\" target=\"_blank\" rel=\"external\">一个和使用纯函数一样的效果</a>：<br>我们可以根据输入来预测一个组件的渲染，我们不需要知道组件的其它信息。这也使得我们的界面测试变得很简单，<br>与我们测试纯应用逻辑一样简单。</p>\n<p>如果组件不包含状态，那么状态放在哪？当然在不可变的Store中啊！我们已经见识过它是怎么运作的了，其<br>最大的特点就是从界面代码中分离出状态。</p>\n<p>在此之前，我们还是先给项目添加React：</p>\n<pre><code>npm install --save react\n</code></pre><p>我们同样需要<a href=\"https://github.com/gaearon/react-hot-loader\" target=\"_blank\" rel=\"external\">react-hot-loader</a>。它让我们的开发<br>变得非常快，因为它提供了我们在不丢失当前状态的情况下重载代码的能力：</p>\n<pre><code>npm install --save-dev react-hot-loader\n</code></pre><p>我们需要更新一下<code>webpack.config.js</code>，使其能热加载：</p>\n<pre><code>//webpack.config.js\n\nvar webpack = require(&apos;webpack&apos;);\n\nmodule.exports = {\n  entry: [\n    &apos;webpack-dev-server/client?http://localhost:8080&apos;,\n    &apos;webpack/hot/only-dev-server&apos;,\n    &apos;./src/index.js&apos;\n  ],\n  module: {\n    loaders: [{\n      test: /\\.jsx?$/,\n      exclude: /node_modules/,\n      loader: &apos;react-hot!babel&apos;\n    }],\n  }\n  resolve: {\n    extensions: [&apos;&apos;, &apos;.js&apos;, &apos;.jsx&apos;]\n  },\n  output: {\n    path: __dirname + &apos;/dist&apos;,\n    publicPath: &apos;/&apos;,\n    filename: &apos;bundle.js&apos;\n  },\n  devServer: {\n    contentBase: &apos;./dist&apos;,\n    hot: true\n  },\n  plugins: [\n    new webpack.HotModuleReplacementPlugin()\n  ]\n};\n</code></pre><p>在上述配置的<code>entry</code>里我们包含了2个新的应用入口点：webpack dev server和webpack hot module loader。<br>它们提供了webpack模块热替换能力。该能力并不是默认加载的，所以上面我们才需要在<code>plugins</code>和<code>devServer</code><br>中手动加载。</p>\n<p>配置的<code>loaders</code>部分我们在原先的Babel前配置了<code>react-hot</code>用于<code>.js</code>和<code>.jsx</code>文件。</p>\n<p>如果你现在重启开发服务器，你将看到一个在终端看到Hot Module Replacement已开启的消息提醒。我们可以<br>开始写我们的第一个组件了。</p>\n<p>###实现投票界面</p>\n<p>应用的投票界面非常简单：一旦投票启动，它将现实2个按钮，分别用来表示2个可选项，当投票结束，它显示最终结果。</p>\n<p><img src=\"http://teropa.info/images/voting_shots.png\" alt=\"\"></p>\n<p>我们之前都是以测试先行的开发方式，但是在react组件开发中我们将先实现组件，再进行测试。这是因为<br>webpack和react-hot-loader提供了更加优良的<a href=\"http://blog.iterate.no/2012/10/01/know-your-feedback-loop-why-and-how-to-optimize-it/\" target=\"_blank\" rel=\"external\">反馈机制</a>。<br>而且，也没有比直接看到界面更加好的测试UI手段了。</p>\n<p>让我们假设有一个<code>Voting</code>组件，在之前的入口文件<code>index.html</code>的<code>#app</code>div中加载它。由于我们的代码中<br>包含JSX语法，所以需要把<code>index.js</code>重命名为<code>index.jsx</code>：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nReact.render(\n  &lt;Voting pair={pair} /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p><code>Voting</code>组件将使用<code>pair</code>属性来加载数据。我们目前可以先硬编码数据，稍后我们将会用真实数据来代替。<br>组件本身是纯粹的，并且对数据来源并不敏感。</p>\n<p>注意，在<code>webpack.config.js</code>中的入口点文件名也要修改：</p>\n<pre><code>//webpack.config.js\n\nentry: [\n  &apos;webpack-dev-server/client?http://localhost:8080&apos;,\n  &apos;webpack/hot/only-dev-server&apos;,\n  &apos;./src/index.jsx&apos;\n],\n</code></pre><p>如果你此时重启webpack-dev-server，你将看到缺失Voting组件的报错。让我们修复它：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>你将会在浏览器上看到组件创建的2个按钮。你可以试试修改代码感受一下浏览器自动更新的魅力，没有刷新，<br>没有页面加载，一切都那么迅雷不及掩耳盗铃。</p>\n<p>现在我们来添加第一个单元测试：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport Voting from &apos;../../src/components/Voting&apos;;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n});\n</code></pre><p>测试组件渲染的按钮，我们必须先看看它的输出是什么。要在单元测试中渲染一个组件，我们需要<code>react/addons</code>提供<br>的辅助函数<a href=\"https://facebook.github.io/react/docs/test-utils.html#renderintodocument\" target=\"_blank\" rel=\"external\">renderIntoDocument</a>：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\n\nconst {renderIntoDocument} = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  it(&apos;renders a pair of buttons&apos;, () =&gt; {\n    const component = renderIntoDocument(\n      &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]} /&gt;\n    );\n  });\n});\n</code></pre><p>一旦组件渲染完毕，我就可以通过react提供的另一个辅助函数<a href=\"https://facebook.github.io/react/docs/test-utils.html#scryrendereddomcomponentswithtag\" target=\"_blank\" rel=\"external\">scryRenderedDOMComponentsWithTag</a><br>来拿到<code>button</code>元素。我们期望存在两个按钮，并且期望按钮的值是我们设置的：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithTag}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  it(&apos;renders a pair of buttons&apos;, () =&gt; {\n    const component = renderIntoDocument(\n      &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]} /&gt;\n    );\n    const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n\n    expect(buttons.length).to.equal(2);\n    expect(buttons[0].getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n    expect(buttons[1].getDOMNode().textContent).to.equal(&apos;28 Days Later&apos;);\n  });\n});\n</code></pre><p>如果我们跑一下测试，将会看到测试通过的提示：</p>\n<pre><code>npm run test\n</code></pre><p>当用户点击某个按钮后，组件将会调用回调函数，该函数也由组件的prop传递给组件。</p>\n<p>让我们完成这一步，我们可以通过使用React提供的测试工具<a href=\"https://facebook.github.io/react/docs/test-utils.html#simulate\" target=\"_blank\" rel=\"external\">Simulate</a><br>来模拟点击操作：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;invokes callback when a button is clicked&apos;, () =&gt; {\n    let votedWith;\n    const vote = (entry) =&gt; votedWith = entry;\n\n    const component = renderIntoDocument(\n      &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n              vote={vote}/&gt;\n    );\n    const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n    Simulate.click(buttons[0].getDOMNode());\n\n    expect(votedWith).to.equal(&apos;Trainspotting&apos;);\n  });\n});\n</code></pre><p>要想使上面的测试通过很简单，我们只需要让按钮的<code>onClick</code>事件调用<code>vote</code>并传递选中条目即可：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>这就是我们在纯组件中常用的方式：组件不需要做太多，只是回调传入的参数即可。</p>\n<p>注意，这里我们又是先写的测试代码，我发现业务代码的测试要比测试UI更容易写，所以后面我们会保持这种<br>方式：UI测试后行，业务代码测试先行。</p>\n<p>一旦用户已经针对某对选项投过票了，我们就不应该允许他们再次投票，难道我们应该在组件内部维护某种状态么？<br>不，我们需要保证我们的组件是纯粹的，所以我们需要分离这个逻辑，组件需要一个<code>hasVoted</code>属性，我们先硬编码<br>传递给它：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nReact.render(\n  &lt;Voting pair={pair} hasVoted=&quot;Trainspotting&quot; /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p>我们可以简单的修改一下组件即可：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                disabled={this.isDisabled()}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>让我们再为按钮添加一个提示，当用户投票完毕后，在选中的项目上添加标识，这样用户就更容易理解：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  hasVotedFor: function(entry) {\n    return this.props.hasVoted === entry;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                disabled={this.isDisabled()}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n          {this.hasVotedFor(entry) ?\n            &lt;div className=&quot;label&quot;&gt;Voted&lt;/div&gt; :\n            null}\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>投票界面最后要添加的，就是获胜者样式。我们可能需要添加新的props：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nReact.render(\n  &lt;Voting pair={pair} winner=&quot;Trainspotting&quot; /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p>我们再次修改一下组件：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  hasVotedFor: function(entry) {\n    return this.props.hasVoted === entry;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.props.winner ?\n        &lt;div ref=&quot;winner&quot;&gt;Winner is {this.props.winner}!&lt;/div&gt; :\n        this.getPair().map(entry =&gt;\n          &lt;button key={entry}\n                  disabled={this.isDisabled()}\n                  onClick={() =&gt; this.props.vote(entry)}&gt;\n            &lt;h1&gt;{entry}&lt;/h1&gt;\n            {this.hasVotedFor(entry) ?\n              &lt;div className=&quot;label&quot;&gt;Voted&lt;/div&gt; :\n              null}\n          &lt;/button&gt;\n        )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>目前我们已经完成了所有要做的，但是<code>render</code>函数看着有点丑陋，如果我们可以把胜利界面独立成新的组件<br>可能会好一些：</p>\n<pre><code>//src/components/Winner.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  render: function() {\n    return &lt;div className=&quot;winner&quot;&gt;\n      Winner is {this.props.winner}!\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>这样投票组件就会变得很简单，它只需关注投票按钮逻辑即可：</p>\n<pre><code>//src/components/Vote.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  hasVotedFor: function(entry) {\n    return this.props.hasVoted === entry;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                disabled={this.isDisabled()}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n          {this.hasVotedFor(entry) ?\n            &lt;div className=&quot;label&quot;&gt;Voted&lt;/div&gt; :\n            null}\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>最后我们只需要在<code>Voting</code>组件做一下判断即可：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nexport default React.createClass({\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>注意这里我们为胜利组件添加了<a href=\"https://facebook.github.io/react/docs/more-about-refs.html\" target=\"_blank\" rel=\"external\">ref</a>，这是因为我们将在单元测试中利用它获取DOM节点。</p>\n<p>这就是我们的纯组件！注意目前我们还没有实现任何逻辑：我们并没有定义按钮的点击操作。组件只是用来渲染UI，其它<br>什么都不需要做。后面当我们将UI与Redux Store结合时才会涉及到应用逻辑。</p>\n<p>继续下一步之前我们要为刚才新增的特性写更多的单元测试代码。首先，<code>hasVoted</code>属性将会使按钮改变状态：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;disables buttons when user has voted&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n            hasVoted=&quot;Trainspotting&quot; /&gt;\n  );\n  const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n\n  expect(buttons.length).to.equal(2);\n  expect(buttons[0].getDOMNode().hasAttribute(&apos;disabled&apos;)).to.equal(true);\n  expect(buttons[1].getDOMNode().hasAttribute(&apos;disabled&apos;)).to.equal(true);\n});\n</code></pre><p>被<code>hasVoted</code>匹配的按钮将显示<code>Voted</code>标签：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;adds label to the voted entry&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n            hasVoted=&quot;Trainspotting&quot; /&gt;\n  );\n  const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n\n  expect(buttons[0].getDOMNode().textContent).to.contain(&apos;Voted&apos;);\n});\n</code></pre><p>当获胜者产生，界面将不存在按钮，取而代替的是胜利者元素：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;renders just the winner when there is one&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Voting winner=&quot;Trainspotting&quot; /&gt;\n  );\n  const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n  expect(buttons.length).to.equal(0);\n\n  const winner = React.findDOMNode(component.refs.winner);\n  expect(winner).to.be.ok;\n  expect(winner.textContent).to.contain(&apos;Trainspotting&apos;);\n});\n</code></pre><p>###不可变数据和纯粹渲染</p>\n<p>我们之前已经讨论了许多关于不可变数据的红利，但是，当它和react结合时还会有一个非常屌的好处：<br>如果我们创建纯react组件并传递给它不可变数据作为属性参数，我们将会让react在组件渲染检测中得到最大性能。</p>\n<p>这是靠react提供的<a href=\"https://facebook.github.io/react/docs/pure-render-mixin.html\" target=\"_blank\" rel=\"external\">PureRenderMixin</a>实现的。<br>当该mixin添加到组件中后，组件的更新检查逻辑将会被改变，由深比对改为高性能的浅比对。</p>\n<p>我们之所以可以使用浅比对，就是因为我们使用的是不可变数据。如果一个组件的所有参数都是不可变数据，<br>那么将大大提高应用性能。</p>\n<p>我们可以在单元测试里更清楚的看见差别，如果我们向纯组件中传入可变数组，当数组内部元素产生改变后，组件并不会<br>重新渲染：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;renders as a pure component&apos;, () =&gt; {\n  const pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n  const component = renderIntoDocument(\n    &lt;Voting pair={pair} /&gt;\n  );\n\n  let firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n  expect(firstButton.getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n\n  pair[0] = &apos;Sunshine&apos;;\n  component.setProps({pair: pair});\n  firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n  expect(firstButton.getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n});\n</code></pre><p>如果我们使用不可变数据，则完全没有问题：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List} from &apos;immutable&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;does update DOM when prop changes&apos;, () =&gt; {\n    const pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n    const component = renderIntoDocument(\n      &lt;Voting pair={pair} /&gt;\n    );\n\n    let firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n    expect(firstButton.getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n\n    const newPair = pair.set(0, &apos;Sunshine&apos;);\n    component.setProps({pair: newPair});\n    firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n    expect(firstButton.getDOMNode().textContent).to.equal(&apos;Sunshine&apos;);\n  });\n});\n</code></pre><p>如果你跑上面的两个测试，你将会看到非预期的结果：因为实际上UI在两种场景下都更新了。那是因为现在组件<br>依然使用的是深比对，这正是我们使用不可变数据想极力避免的。</p>\n<p>下面我们在组件中引入mixin，你就会拿到期望的结果了：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  // ...\n});\n\n\n\n//src/components/Vote.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  // ...\n});\n\n\n\n//src/components/Winner.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  // ...\n});\n</code></pre><p>###投票结果页面和路由实现</p>\n<p>投票页面已经搞定了，让我们开始实现投票结果页面吧。</p>\n<p>投票结果页面依然会显示两个条目，并且显示它们各自的票数。此外屏幕下方还会有一个按钮，供用户切换到下一轮投票。</p>\n<p>现在我们根据什么来确定显示哪个界面呢？使用URL是个不错的主意：我们可以设置根路径<code>#/</code>去显示投票页面，<br>使用<code>#/results</code>来显示投票结果页面。</p>\n<p>我们使用<a href=\"http://rackt.github.io/react-router/\" target=\"_blank\" rel=\"external\">react-router</a>可以很容易实现这个需求。让我们加入项目：</p>\n<pre><code>npm install --save react-router\n</code></pre><p>我们这里使用的react-router的0.13版本，它的1.0版本官方还没有发布，如果你打算使用其1.0RC版，那么下面的代码<br>你可能需要做一些修改，可以看<a href=\"https://github.com/rackt/react-router\" target=\"_blank\" rel=\"external\">router文档</a>。</p>\n<p>我们现在可以来配置一下路由路径，Router提供了一个<code>Route</code>组件用来让我们定义路由信息，同时也提供了<code>DefaultRoute</code><br>组件来让我们定义默认路由：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport {Route, DefaultRoute} from &apos;react-router&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nReact.render(\n  &lt;Voting pair={pair} /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p>我们定义了一个默认的路由指向我们的<code>Voting</code>组件。我们需要定义个<code>App</code>组件来用于Route使用。</p>\n<p>根路由的作用就是为应用指定一个根组件：通常该组件充当所有子页面的模板。让我们来看看<code>App</code>的细节：</p>\n<pre><code>//src/components/App.jsx\n\nimport React from &apos;react&apos;;\nimport {RouteHandler} from &apos;react-router&apos;;\nimport {List} from &apos;immutable&apos;;\n\nconst pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n\nexport default React.createClass({\n  render: function() {\n    return &lt;RouteHandler pair={pair} /&gt;\n  }\n});\n</code></pre><p>这个组件除了渲染了一个<code>RouteHandler</code>组件并没有做别的，这个组件同样是react-router提供的，它的作用就是<br>每当路由匹配了某个定义的页面后将对应的页面组件插入到这个位置。目前我们只定义了一个默认路由指向<code>Voting</code>，<br>所以目前我们的组件总是会显示<code>Voting</code>界面。</p>\n<p>注意，我们将我们硬编码的投票数据从<code>index.jsx</code>移到了<code>App.jsx</code>，当你给<code>RouteHandler</code>传递了属性值时，<br>这些参数将会传给当前路由对应的组件。</p>\n<p>现在我们可以更新<code>index.jsx</code>：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Root /&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p><code>run</code>方法会根据当前浏览器的路径去查找定义的router来决定渲染哪个组件。一旦确定了对应的组件，它将会被<br>当作指定的<code>Root</code>传给<code>run</code>的回调函数，在回调中我们将使用<code>React.render</code>将其插入DOM中。</p>\n<p>目前为止我们已经基于React router实现了之前的内容，我们现在可以很容易添加更多新的路由到应用。让我们<br>把投票结果页面添加进去吧：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Root /&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>这里我们用使用<code>&lt;Route&gt;</code>组件定义了一个名为<code>/results</code>的路径，并绑定<code>Results</code>组件。</p>\n<p>让我们简单的实现一下这个<code>Results</code>组件，这样我们就可以看一下路由是如何工作的了：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;Hello from results!&lt;/div&gt;\n  }\n});\n</code></pre><p>如果你在浏览器中输入<a href=\"http://localhost:8080/#/results\" target=\"_blank\" rel=\"external\">http://localhost:8080/#/results</a>，你将会看到该结果组件。<br>而其它路径都对应这投票页面，你也可以使用浏览器的前后按钮来切换这两个界面。</p>\n<p>接下来我们来实际实现一下结果组件：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  render: function() {\n    return &lt;div className=&quot;results&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;div key={entry} className=&quot;entry&quot;&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/div&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>结果界面除了显示投票项外，还应该显示它们对应的得票数，让我们先硬编码一下：</p>\n<pre><code>//src/components/App.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {RouteHandler} from &apos;react-router&apos;;\nimport {List, Map} from &apos;immutable&apos;;\n\nconst pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\nconst tally = Map({&apos;Trainspotting&apos;: 5, &apos;28 Days Later&apos;: 4});\n\nexport default React.createClass({\n  render: function() {\n    return &lt;RouteHandler pair={pair}\n                         tally={tally} /&gt;\n  }\n});\n</code></pre><p>现在，我们再来修改一下结果组件：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return &lt;div className=&quot;results&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;div key={entry} className=&quot;entry&quot;&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n          &lt;div className=&quot;voteCount&quot;&gt;\n            {this.getVotes(entry)}\n          &lt;/div&gt;\n        &lt;/div&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>现在我们来针对目前的界面功能编写测试代码，以防止未来我们破坏这些功能。</p>\n<p>我们期望组件为每个选项都渲染一个div，并在其中显示选项的名称和票数。如果对应的选项没有票数，则默认显示0：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List, Map} from &apos;immutable&apos;;\nimport Results from &apos;../../src/components/Results&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithClass}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Results&apos;, () =&gt; {\n\n  it(&apos;renders entries with vote counts or zero&apos;, () =&gt; {\n    const pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n    const tally = Map({&apos;Trainspotting&apos;: 5});\n    const component = renderIntoDocument(\n      &lt;Results pair={pair} tally={tally} /&gt;\n    );\n    const entries = scryRenderedDOMComponentsWithClass(component, &apos;entry&apos;);\n    const [train, days] = entries.map(e =&gt; e.getDOMNode().textContent);\n\n    expect(entries.length).to.equal(2);\n    expect(train).to.contain(&apos;Trainspotting&apos;);\n    expect(train).to.contain(&apos;5&apos;);\n    expect(days).to.contain(&apos;28 Days Later&apos;);\n    expect(days).to.contain(&apos;0&apos;);\n  });\n});\n</code></pre><p>接下来，我们看一下”Next”按钮，它允许用户切换到下一轮投票。</p>\n<p>我们的组件应该包含一个回调函数属性参数，当组件中的”Next”按钮被点击后，该回调函数将会被调用。我们来写一下<br>这个操作的测试代码：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List, Map} from &apos;immutable&apos;;\nimport Results from &apos;../../src/components/Results&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithClass, Simulate}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Results&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;invokes the next callback when next button is clicked&apos;, () =&gt; {\n    let nextInvoked = false;\n    const next = () =&gt; nextInvoked = true;\n\n    const pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n    const component = renderIntoDocument(\n      &lt;Results pair={pair}\n               tally={Map()}\n               next={next}/&gt;\n    );\n    Simulate.click(React.findDOMNode(component.refs.next));\n\n    expect(nextInvoked).to.equal(true);\n  });\n});\n</code></pre><p>写法和之前的投票按钮很类似吧。接下来让我们更新一下结果组件：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return &lt;div className=&quot;results&quot;&gt;\n      &lt;div className=&quot;tally&quot;&gt;\n        {this.getPair().map(entry =&gt;\n          &lt;div key={entry} className=&quot;entry&quot;&gt;\n            &lt;h1&gt;{entry}&lt;/h1&gt;\n            &lt;div class=&quot;voteCount&quot;&gt;\n              {this.getVotes(entry)}\n            &lt;/div&gt;\n          &lt;/div&gt;\n        )}\n      &lt;/div&gt;\n      &lt;div className=&quot;management&quot;&gt;\n        &lt;button ref=&quot;next&quot;\n                className=&quot;next&quot;\n                onClick={this.props.next}&gt;\n          Next\n        &lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>最终投票结束，结果页面和投票页面一样，都要显示胜利者：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nit(&apos;renders the winner when there is one&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Results winner=&quot;Trainspotting&quot;\n             pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n             tally={Map()} /&gt;\n  );\n  const winner = React.findDOMNode(component.refs.winner);\n  expect(winner).to.be.ok;\n  expect(winner.textContent).to.contain(&apos;Trainspotting&apos;);\n});\n</code></pre><p>我们可以想在投票界面中那样简单的实现一下上面的逻辑：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Winner from &apos;./Winner&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return this.props.winner ?\n      &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n      &lt;div className=&quot;results&quot;&gt;\n        &lt;div className=&quot;tally&quot;&gt;\n          {this.getPair().map(entry =&gt;\n            &lt;div key={entry} className=&quot;entry&quot;&gt;\n              &lt;h1&gt;{entry}&lt;/h1&gt;\n              &lt;div className=&quot;voteCount&quot;&gt;\n                {this.getVotes(entry)}\n              &lt;/div&gt;\n            &lt;/div&gt;\n          )}\n        &lt;/div&gt;\n        &lt;div className=&quot;management&quot;&gt;\n          &lt;button ref=&quot;next&quot;\n                   className=&quot;next&quot;\n                   onClick={this.props.next}&gt;\n            Next\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;;\n  }\n});\n</code></pre><p>到目前为止，我们已经实现了应用的UI，虽然现在它们并没有和真实数据和操作整合起来。这很不错不是么？<br>我们只需要一些占位符数据就可以完成界面的开发，这让我们在这个阶段更专注于UI。</p>\n<p>接下来我们将会使用Redux Store来将真实数据整合到我们的界面中。</p>\n<p>###初识客户端的Redux Store</p>\n<p>Redux将会充当我们UI界面的状态容器，我们已经在服务端用过Redux，之前说的很多内容在这里也受用。<br>现在我们已经准备好要在React应用中使用Redux了，这也是Redux更常见的使用场景。</p>\n<p>和在服务端一样，我们先来思考一下应用的状态。客户端的状态和服务端会非常的类似。</p>\n<p>我们有两个界面，并在其中需要显示成对的用于投票的条目：</p>\n<p><img src=\"http://teropa.info/images/vote_client_pair.png\" alt=\"\"></p>\n<p>此外，结果页面需要显示票数：</p>\n<p><img src=\"http://teropa.info/images/vote_client_tally.png\" alt=\"\"></p>\n<p>投票组件还需要记录当前用户已经投票过的选项：</p>\n<p><img src=\"http://teropa.info/images/vote_client_hasvoted.png\" alt=\"\"></p>\n<p>结果组件还需要记录胜利者：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_winner.png\" alt=\"\"></p>\n<p>注意这里除了<code>hasVoted</code>外，其它都映射着服务端状态的子集。</p>\n<p>接下来我们来思考一下应用的核心逻辑，actions和reducers应该是什么样的。</p>\n<p>我们先来想想能够导致应用状态改变的操作都有那些？状态改变的来源之一是用户行为。我们的UI中存在两种<br>可能的用户操作行为：</p>\n<ul>\n<li>用户在投票页面点击某个投票按钮；</li>\n<li>用户点击下一步按钮。</li>\n</ul>\n<p>另外，我们知道我们的服务端会将应用当前状态发送给客户端，我们将编写代码来接受状态数据，这也是导致状态<br>改变的来源之一。</p>\n<p>我们可以从服务端状态更新开始，之前我们在服务端设置发送了一个<code>state</code>事件。该事件将携带我们之前设计的客户端<br>状态树的状态数据。我们的客户端reducer将通过一个action来将服务器端的状态数据合并到客户端状态树中，<br>这个action如下：</p>\n<pre><code>{\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {...}\n  }\n}\n</code></pre><p>让我们先写一下reducer测试代码，它应该接受上面定义的那种action，并合并数据到客户端的当前状态中：</p>\n<pre><code>//test/reducer_spec.js\n\nimport {List, Map, fromJS} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport reducer from &apos;../src/reducer&apos;;\n\ndescribe(&apos;reducer&apos;, () =&gt; {\n\n  it(&apos;handles SET_STATE&apos;, () =&gt; {\n    const initialState = Map();\n    const action = {\n      type: &apos;SET_STATE&apos;,\n      state: Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({Trainspotting: 1})\n        })\n      })\n    };\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      }\n    }));\n  });\n});\n</code></pre><p>这个renducers接受一个来自socket发送的原始的js数据结构，这里注意不是不可变数据类型哦。我们需要在返回前将其<br>转换成不可变数据类型：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;handles SET_STATE with plain JS payload&apos;, () =&gt; {\n  const initialState = Map();\n  const action = {\n    type: &apos;SET_STATE&apos;,\n    state: {\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      }\n    }\n  };\n  const nextState = reducer(initialState, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  }));\n});\n</code></pre><p>reducer同样应该可以正确的处理<code>undefined</code>初始化状态：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;handles SET_STATE without initial state&apos;, () =&gt; {\n  const action = {\n    type: &apos;SET_STATE&apos;,\n    state: {\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      }\n    }\n  };\n  const nextState = reducer(undefined, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  }));\n});\n</code></pre><p>现在我们来看一下如何实现满足上面测试条件的reducer：</p>\n<pre><code>//src/reducer.js\n\nimport {Map} from &apos;immutable&apos;;\n\nexport default function(state = Map(), action) {\n\n  return state;\n}\n</code></pre><p>reducer需要处理<code>SET_STATE</code>动作。在这个动作的处理中，我们应该将传入的状态数据和现有的进行合并，<br>使用Map提供的<a href=\"https://facebook.github.io/immutable-js/docs/#/Map/merge\" target=\"_blank\" rel=\"external\">merge</a>将很容易来实现这个操作：</p>\n<pre><code>//src/reducer.js\n\nimport {Map} from &apos;immutable&apos;;\n\nfunction setState(state, newState) {\n  return state.merge(newState);\n}\n\nexport default function(state = Map(), action) {\n  switch (action.type) {\n  case &apos;SET_STATE&apos;:\n    return setState(state, action.state);\n  }\n  return state;\n}\n</code></pre><p>注意这里我们并没有单独写一个核心模块，而是直接在reducer中添加了个简单的<code>setState</code>函数来做业务逻辑。<br>这是因为现在这个逻辑还很简单～</p>\n<p>关于改变用户状态的那两个用户交互：投票和下一步，它们都需要和服务端进行通信，我们一会再说。我们现在先把<br>redux添加到项目中：</p>\n<pre><code>npm install --save redux\n</code></pre><p><code>index.jsx</code>入口文件是一个初始化Store的好地方，让我们暂时先使用硬编码的数据来做：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Root /&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>那么，我们如何在react组件中从Store中获取数据呢？</p>\n<p>###让React从Redux中获取数据</p>\n<p>我们已经创建了一个使用不可变数据类型保存应用状态的Redux Store。我们还拥有接受不可变数据为参数的<br>无状态的纯React组件。如果我们能使这些组件从Store中获取最新的状态数据，那真是极好的。当状态变化时，<br>React会重新渲染组件，pure render mixin可以使得我们的UI避免不必要的重复渲染。</p>\n<p>相比我们自己手动实现同步代码，我们更推荐使用[react-redux][<a href=\"https://github.com/rackt/react-redux]包来做：\" target=\"_blank\" rel=\"external\">https://github.com/rackt/react-redux]包来做：</a></p>\n<pre><code>npm install --save react-redux\n</code></pre><p>这个库主要做的是：</p>\n<ol>\n<li>映射Store的状态到组件的输入props中；</li>\n<li>映射actions到组件的回调props中。</li>\n</ol>\n<p>为了让它可以正常工作，我们需要将顶层的应用组件嵌套在react-redux的<a href=\"https://github.com/rackt/react-redux#provider-store\" target=\"_blank\" rel=\"external\">Provider</a>组件中。<br>这将把Redux Store和我们的状态树连接起来。</p>\n<p>我们将让Provider包含路由的根组件，这样会使得Provider成为整个应用组件的根节点：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>接下来我们要考虑一下，我们的那些组件需要绑定到Store上。我们一共有5个组件，可以分成三类：</p>\n<ul>\n<li>根组件<code>App</code>不需要绑定任何数据；</li>\n<li><code>Vote</code>和<code>Winner</code>组件只使用父组件传递来的数据，所以它们也不需要绑定；</li>\n<li>剩下的组件（<code>Voting</code>和<code>Results</code>）目前都是使用的硬编码数据，我们现在需要将其绑定到Store上。</li>\n</ul>\n<p>让我们从<code>Voting</code>组件开始。使用react-redux我们得到一个叫<a href=\"https://github.com/rackt/react-redux#connectmapstatetoprops-mapdispatchtoprops-mergeprops-options\" target=\"_blank\" rel=\"external\">connect</a>的函数：</p>\n<pre><code>connect(mapStateToProps)(SomeComponent);\n</code></pre><p>该函数的作用就是将Redux Store中的状态数据映射到props对象中。这个props对象将会用于连接到的组件中。<br>在我们的<code>Voting</code>场景中，我们需要从状态中拿到<code>pair</code>和<code>winner</code>值：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nconst Voting = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n\nconnect(mapStateToProps)(Voting);\n\nexport default Voting;\n</code></pre><p>在上面的代码中，<code>connect</code>函数并没有修改<code>Voting</code>组件本身，<code>Voting</code>组件依然保持这纯粹性。而<code>connect</code><br>返回的是一个<code>Voting</code>组件的连接版，我们称之为<code>VotingContainer</code>：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nexport const Voting = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n\nexport const VotingContainer = connect(mapStateToProps)(Voting);\n</code></pre><p>这样，这个模块现在导出两个组件：一个纯<code>Voting</code>组件，一个连接后的<code>VotingContainer</code>版本。<br>react-redux官方称前者为“蠢”组件，后者则称为”智能”组件。我更倾向于用“pure”和“connected”来描述它们。<br>怎么称呼随你便，主要是明白它们之间的差别：</p>\n<ul>\n<li>纯组件完全靠给它传入的props来工作，这非常类似一个纯函数；</li>\n<li>连接组件则封装了纯组件和一些逻辑用来与Redux Store协同工作，这些特性是redux-react提供的。</li>\n</ul>\n<p>我们得更新一下路由表，改用<code>VotingContainer</code>。一旦修改完毕，我们的投票界面将会使用来自Redux Store的数据：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>而在对应的测试代码中，我们则需要使用纯<code>Voting</code>组件定义：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List} from &apos;immutable&apos;;\nimport {Voting} from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n</code></pre><p>其它地方不需要修改了。</p>\n<p>现在我们来如法炮制投票结果页面：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\n\nexport const Results = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return this.props.winner ?\n      &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n      &lt;div className=&quot;results&quot;&gt;\n        &lt;div className=&quot;tally&quot;&gt;\n          {this.getPair().map(entry =&gt;\n            &lt;div key={entry} className=&quot;entry&quot;&gt;\n              &lt;h1&gt;{entry}&lt;/h1&gt;\n              &lt;div className=&quot;voteCount&quot;&gt;\n                {this.getVotes(entry)}\n              &lt;/div&gt;\n            &lt;/div&gt;\n          )}\n        &lt;/div&gt;\n        &lt;div className=&quot;management&quot;&gt;\n          &lt;button ref=&quot;next&quot;\n                   className=&quot;next&quot;\n                   onClick={this.props.next}&gt;\n            Next\n          &lt;/button&gt;\n      &lt;/div&gt;\n      &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    tally: state.getIn([&apos;vote&apos;, &apos;tally&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  }\n}\n\nexport const ResultsContainer = connect(mapStateToProps)(Results);\n</code></pre><p>同样我们需要修改<code>index.jsx</code>来使用新的<code>ResultsContainer</code>：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>不要忘记修改测试代码啊：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List, Map} from &apos;immutable&apos;;\nimport {Results} from &apos;../../src/components/Results&apos;;\nimport {expect} from &apos;chai&apos;;\n</code></pre><p>现在你已经知道如何让纯react组件与Redux Store整合了。</p>\n<p>对于一些只有一个根组件且没有路由的小应用，直接连接根组件就足够了。根组件会将状态数据传递给它的子组件。<br>而对于那些使用路由，就像我们的场景，连接每一个路由指向的处理函数是个好主意。但是分别为每个组件编写连接代码并<br>不适合所有的软件场景。我觉得保持组件props尽可能清晰明了是个非常好的习惯，因为它可以让你很容易清楚组件需要哪些数据，<br>你就可以更容易管理那些连接代码。</p>\n<p>现在让我们开始把Redux数据对接到UI里，我们再也不需要那些<code>App.jsx</code>中手写的硬编码数据了，这样我们的<code>App.jsx</code>将会变得简单：</p>\n<pre><code>//src/components/App.jsx\n\nimport React from &apos;react&apos;;\nimport {RouteHandler} from &apos;react-router&apos;;\n\nexport default React.createClass({\n  render: function() {\n    return &lt;RouteHandler /&gt;\n  }\n});\n</code></pre><p>###设置socket.io客户端</p>\n<p>现在我们已经创建好了客户端的Redux应用，我们接下来将讨论如何让其与我们之前开发的服务端应用进行对接。</p>\n<p>服务端已经准备好接受socket连接，并为其进行投票数据的发送。而我们的客户端也已经可以使用Redux Store很方便的<br>接受数据了。我们剩下的工作就是把它们连接起来。</p>\n<p>我们需要使用socket.io从浏览器向服务端创建一个连接，我们可以使用<a href=\"http://socket.io/docs/client-api/\" target=\"_blank\" rel=\"external\">socket.io-client库</a>来完成<br>这个目的：</p>\n<pre><code>npm install --save socket.io-client\n</code></pre><p>这个库赋予了我们连接Socket.io服务端的能力，让我们连接之前写好的服务端，端口号8090（注意使用和后端匹配的端口）：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>你必须先确保你的服务端已经开启了，然后在浏览器端访问客户端应用，并检查网络监控，你会发现创建了一个<br>WebSockets连接，并且开始传输Socket.io的心跳包了。</p>\n<p>###接受来自服务器端的actions</p>\n<p>我们虽然已经创建了个socket.io连接，但我们并没有用它获取任何数据。每当我们连接到服务端或服务端发生<br>状态数据改变时，服务端会发送<code>state</code>事件给客户端。我们只需要监听对应的事件即可，我们在接受到事件通知后<br>只需要简单的对我们的Store指派<code>SET_STATE</code>action即可：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch({type: &apos;SET_STATE&apos;, state})\n);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>注意我们移除了<code>SET_STATE</code>的硬编码，我们现在已经不需要伪造数据了。</p>\n<p>审视我们的界面，不管是投票还是结果页面，它们都会显示服务端提供的第一对选项。服务端和客户端已经连接上了！</p>\n<p>###从react组件中指派actions</p>\n<p>我们已经知道如何从Redux Store获取数据到UI中，现在来看看如何从UI中提交数据用于actions。</p>\n<p>思考这个问题的最佳场景是投票界面上的投票按钮。之前在写相关界面时，我们假设<code>Voting</code>组件接受一个回调函数props。<br>当用户点击某个按钮时组件将会调用这个回调函数。但我们目前并没有实现这个回调函数，除了在测试代码中。</p>\n<p>当用户投票后应该做什么？投票结果应该发送给服务端，这部分我们稍后再说，客户端也需要执行一些逻辑：<br>组件的<code>hasVoted</code>值应该被设置，这样用户才不会反复对同一对选项投票。</p>\n<p>这是我们要创建的第二个客户端Redux Action，我们称之为<code>VOTE</code>：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;handles VOTE by setting hasVoted&apos;, () =&gt; {\n  const state = fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  });\n  const action = {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;};\n  const nextState = reducer(state, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    },\n    hasVoted: &apos;Trainspotting&apos;\n  }));\n});\n</code></pre><p>为了更严谨，我们应该考虑一种情况：不管什么原因，当<code>VOTE</code>action传递了一个不存在的选项时我们的应用该怎么做：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;does not set hasVoted for VOTE on invalid entry&apos;, () =&gt; {\n  const state = fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  });\n  const action = {type: &apos;VOTE&apos;, entry: &apos;Sunshine&apos;};\n  const nextState = reducer(state, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  }));\n});\n</code></pre><p>下面来看看我们的reducer如何实现的：</p>\n<pre><code>//src/reducer.js\n\nimport {Map} from &apos;immutable&apos;;\n\nfunction setState(state, newState) {\n  return state.merge(newState);\n}\n\nfunction vote(state, entry) {\n  const currentPair = state.getIn([&apos;vote&apos;, &apos;pair&apos;]);\n  if (currentPair &amp;&amp; currentPair.includes(entry)) {\n    return state.set(&apos;hasVoted&apos;, entry);\n  } else {\n    return state;\n  }\n}\n\nexport default function(state = Map(), action) {\n  switch (action.type) {\n  case &apos;SET_STATE&apos;:\n    return setState(state, action.state);\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry);\n  }\n  return state;\n}\n</code></pre><p><code>hasVoted</code>并不会一直保存在状态数据中，每当开始一轮新的投票时，我们应该在<code>SET_STATE</code>action的处理逻辑中<br>检查是否用户是否已经投票，如果还没，我们应该删除掉<code>hasVoted</code>：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;removes hasVoted on SET_STATE if pair changes&apos;, () =&gt; {\n  const initialState = fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    },\n    hasVoted: &apos;Trainspotting&apos;\n  });\n  const action = {\n    type: &apos;SET_STATE&apos;,\n    state: {\n      vote: {\n        pair: [&apos;Sunshine&apos;, &apos;Slumdog Millionaire&apos;]\n      }\n    }\n  };\n  const nextState = reducer(initialState, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;Slumdog Millionaire&apos;]\n    }\n  }));\n});\n</code></pre><p>根据需要，我们新增一个<code>resetVote</code>函数来处理<code>SET_STATE</code>动作：</p>\n<pre><code>//src/reducer.js\n\nimport {List, Map} from &apos;immutable&apos;;\n\nfunction setState(state, newState) {\n  return state.merge(newState);\n}\n\nfunction vote(state, entry) {\n  const currentPair = state.getIn([&apos;vote&apos;, &apos;pair&apos;]);\n  if (currentPair &amp;&amp; currentPair.includes(entry)) {\n    return state.set(&apos;hasVoted&apos;, entry);\n  } else {\n    return state;\n  }\n}\n\nfunction resetVote(state) {\n  const hasVoted = state.get(&apos;hasVoted&apos;);\n  const currentPair = state.getIn([&apos;vote&apos;, &apos;pair&apos;], List());\n  if (hasVoted &amp;&amp; !currentPair.includes(hasVoted)) {\n    return state.remove(&apos;hasVoted&apos;);\n  } else {\n    return state;\n  }\n}\n\nexport default function(state = Map(), action) {\n  switch (action.type) {\n  case &apos;SET_STATE&apos;:\n    return resetVote(setState(state, action.state));\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry);\n  }\n  return state;\n}\n</code></pre><p>我们还需要在修改一下连接逻辑：</p>\n<pre><code>//src/components/Voting.jsx\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    hasVoted: state.get(&apos;hasVoted&apos;),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n</code></pre><p>现在我们依然需要为<code>Voting</code>提供一个<code>vote</code>回调函数，用来为Sotre指派我们新增的action。我们依然要尽力保证<br><code>Voting</code>组件的纯粹性，不应该依赖任何actions或Redux。这些工作都应该在react-redux的<code>connect</code>中处理。</p>\n<p>除了连接输入参数属性，react-redux还可以用来连接output actions。开始之前，我们先来介绍一下另一个Redux的<br>核心概念：Action creators。</p>\n<p>如我们之前看到的，Redux actions通常就是一个简单的对象，它包含一个固有的<code>type</code>属性和其它内容。我们之前都是直接<br>利用js对象字面量来直接声明所需的actions。其实可以使用一个factory函数来更好的生成actions，如下：</p>\n<pre><code>function vote(entry) {\n  return {type: &apos;VOTE&apos;, entry};\n}\n</code></pre><p>这类函数就被称为action creators。它们就是个纯函数，用来返回action对象，别的没啥好介绍得了。但是你也可以<br>在其中实现一些内部逻辑，而避免将每次生成action都重复编写它们。使用action creators可以更好的表达所有需要分发<br>的actions。</p>\n<p>让我们新建一个用来声明客户端所需action的action creators文件：</p>\n<pre><code>//src/action_creators.js\n\nexport function setState(state) {\n  return {\n    type: &apos;SET_STATE&apos;,\n    state\n  };\n}\n\nexport function vote(entry) {\n  return {\n    type: &apos;VOTE&apos;,\n    entry\n  };\n}\n</code></pre><p>我们当然也可以为action creators编写测试代码，但由于我们的代码逻辑太简单了，我就不再写测试了。</p>\n<p>现在我们可以在<code>index.jsx</code>中使用我们刚新增的<code>setState</code>action creator了：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport {setState} from &apos;./action_creators&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch(setState(state))\n);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>使用action creators还有一个非常优雅的特点：在我们的场景里，我们有一个需要<code>vote</code>回调函数props的<br><code>Vote</code>组件，我们同时拥有一个<code>vote</code>的action creator。它们的名字和函数签名完全一致（都接受一个用来表示<br>选中项的参数）。现在我们只需要将action creators作为react-redux的<code>connect</code>函数的第二个参数，即可完成<br>自动关联：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\nimport * as actionCreators from &apos;../action_creators&apos;;\n\nexport const Voting = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    hasVoted: state.get(&apos;hasVoted&apos;),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n\nexport const VotingContainer = connect(\n  mapStateToProps,\n  actionCreators\n)(Voting);\n</code></pre><p>这么配置后，我们的<code>Voting</code>组件的<code>vote</code>参数属性将会与<code>vote</code>aciton creator关联起来。这样当点击<br>某个投票按钮后，会导致触发<code>VOTE</code>动作。</p>\n<p>###使用Redux Middleware发送actions到服务端</p>\n<p>最后我们要做的是把用户数据提交到服务端，这种操作一般发生在用户投票，或选择跳转下一轮投票时发生。</p>\n<p>让我们讨论一下投票操作，下面列出了投票的逻辑：</p>\n<ul>\n<li>当用户进行投票，<code>VOTE</code>action将产生并分派到客户端的Redux Store中；</li>\n<li><code>VOTE</code>actions将触发客户端reducer进行<code>hasVoted</code>状态设置；</li>\n<li>服务端监控客户端通过socket.io投递的<code>action</code>，它将接收到的actions分派到服务端的Redux Store;</li>\n<li><code>VOTE</code>action将触发服务端的reducer，其会创建vote数据并更新对应的票数。</li>\n</ul>\n<p>这样来说，我们似乎已经都搞定了。唯一缺少的就是让客户端发送<code>VOTE</code>action给服务端。这相当于两端的<br>Redux Store相互分派action，这就是我们接下来要做的。</p>\n<p>那么该怎么做呢？Redux并没有内建这种功能。所以我们需要设计一下何时何地来做这个工作：从客户端发送<br>action到服务端。</p>\n<p>Redux提供了一个通用的方法来封装action：<a href=\"http://rackt.github.io/redux/docs/advanced/Middleware.html\" target=\"_blank\" rel=\"external\">Middleware</a>。</p>\n<p>Redux中间件是一个函数，每当action将要被指派，并在对应的reducer执行之前会被调用。它常用来做像日志收集，<br>异常处理，修整action，缓存结果，控制何时以何种方式来让store接收actions等工作。这正是我们可以利用的。</p>\n<p>注意，一定要分清Redux中间件和Redux监听器的差别：中间件被用于action将要指派给store阶段，它可以修改action对<br>store将带来的影响。而监听器则是在action被指派后，它不能改变action的行为。</p>\n<p>我们需要创建一个“远程action中间件”，该中间件可以让我们的action不仅仅能指派给本地的store，也可以通过<br>socket.io连接派送给远程的store。</p>\n<p>让我们创建这个中间件，It is a function that takes a Redux store, and returns another function that takes a “next” callback. That function returns a third function that takes a Redux action. The innermost function is where the middleware implementation will actually go<br>（译者注：这句套绕口，请看官自行参悟）：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default store =&gt; next =&gt; action =&gt; {\n\n}\n</code></pre><p>上面这个写法看着可能有点渗人，下面调整一下让大家好理解：</p>\n<pre><code>export default function(store) {\n    return function(next) {\n        return function(action) {\n\n        }\n    }\n}\n</code></pre><p>这种嵌套接受单一参数函数的写法成为<a href=\"https://en.wikipedia.org/wiki/Currying\" target=\"_blank\" rel=\"external\">currying</a>。<br>这种写法主要用来简化中间件的实现：如果我们使用一个一次性接受所有参数的函数（<code>function(store, next, action) { }</code>），<br>那么我们就不得不保证我们的中间件具体实现每次都要包含所有这些参数。</p>\n<p>上面的<code>next</code>参数作用是在中间件中一旦完成了action的处理，就可以调用它来退出当前逻辑：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default store =&gt; next =&gt; action =&gt; {\n  return next(action);\n}\n</code></pre><p>如果中间件没有调用<code>next</code>，则该action将丢弃，不再传到reducer或store中。</p>\n<p>让我们写一个简单的日志中间件：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default store =&gt; next =&gt; action =&gt; {\n  console.log(&apos;in middleware&apos;, action);\n  return next(action);\n}\n</code></pre><p>我们将上面这个中间件注册到我们的Redux Store中，我们将会抓取到所有action的日志。中间件可以通过Redux<br>提供的<code>applyMiddleware</code>函数绑定到我们的store中：</p>\n<pre><code>//src/components/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore, applyMiddleware} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport {setState} from &apos;./action_creators&apos;;\nimport remoteActionMiddleware from &apos;./remote_action_middleware&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst createStoreWithMiddleware = applyMiddleware(\n  remoteActionMiddleware\n)(createStore);\nconst store = createStoreWithMiddleware(reducer);\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch(setState(state))\n);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>如果你重启应用，你将会看到我们设置的中间件会抓到应用触发的action日志。</p>\n<p>那我们应该怎么利用中间件机制来完成从客户端通过socket.io连接发送action给服务端呢？在此之前我们肯定需要先<br>有一个连接供中间件使用，不幸的是我们已经有了，就在<code>index.jsx</code>中，我们只需要中间件可以拿到它即可。<br>使用currying风格来实现这个中间件很简单：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default socket =&gt; store =&gt; next =&gt; action =&gt; {\n  console.log(&apos;in middleware&apos;, action);\n  return next(action);\n}\n</code></pre><p>这样我们就可以在<code>index.jsx</code>中传入需要的连接了：</p>\n<pre><code>//src/index.jsx\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch(setState(state))\n);\n\nconst createStoreWithMiddleware = applyMiddleware(\n  remoteActionMiddleware(socket)\n)(createStore);\nconst store = createStoreWithMiddleware(reducer);\n</code></pre><p>注意跟之前的代码比，我们需要调整一下顺序，让socket连接先于store被创建。</p>\n<p>一切就绪了，现在就可以使用我们的中间件发送<code>action</code>了：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default socket =&gt; store =&gt; next =&gt; action =&gt; {\n  socket.emit(&apos;action&apos;, action);\n  return next(action);\n}\n</code></pre><p>打完收工。现在如果你再点击投票按钮，你就会看到所有连接到服务端的客户端的票数都会被更新！</p>\n<p>还有个很严重的问题我们要处理：现在每当我们收到服务端发来的<code>SET_STATE</code>action后，这个action都将会直接回传给<br>服务端，这样我们就造成了一个死循环，这是非常反人类的。</p>\n<p>我们的中间件不应该不加处理的转发所有的action给服务端。个别action，例如<code>SET_STATE</code>，应该只在客户端做<br>处理。我们在action中添加一个标识位用于识别哪些应该转发给服务端：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default socket =&gt; store =&gt; next =&gt; action =&gt; {\n  if (action.meta &amp;&amp; action.meta.remote) {\n    socket.emit(&apos;action&apos;, action);\n  }\n  return next(action);\n}\n</code></pre><p>我们同样应该修改相关的action creators：</p>\n<pre><code>//src/action_creators.js\n\nexport function setState(state) {\n  return {\n    type: &apos;SET_STATE&apos;,\n    state\n  };\n}\n\nexport function vote(entry) {\n  return {\n    meta: {remote: true},\n    type: &apos;VOTE&apos;,\n    entry\n  };\n}\n</code></pre><p>让我们重新审视一下我们都干了什么：</p>\n<ol>\n<li>用户点击投票按钮，<code>VOTE</code>action被分派；</li>\n<li>远程action中间件通过socket.io连接转发该action给服务端；</li>\n<li>客户端Redux Store处理这个action，记录本地<code>hasVoted</code>属性；</li>\n<li>当action到达服务端，服务端的Redux Store将处理该action，更新所有投票及其票数；</li>\n<li>设置在服务端Redux Store上的监听器将改变后的状态数据发送给所有在线的客户端；</li>\n<li>每个客户端将触发<code>SET_STATE</code>action的分派；</li>\n<li>每个客户端将根据这个action更新自己的状态，这样就保持了与服务端的同步。</li>\n</ol>\n<p>为了完成我们的应用，我们需要实现下一步按钮的逻辑。和投票类似，我们需要将数据发送到服务端：</p>\n<pre><code>//src/action_creator.js\n\nexport function setState(state) {\n  return {\n    type: &apos;SET_STATE&apos;,\n    state\n  };\n}\n\nexport function vote(entry) {\n  return {\n    meta: {remote: true},\n    type: &apos;VOTE&apos;,\n    entry\n  };\n}\n\nexport function next() {\n  return {\n    meta: {remote: true},\n    type: &apos;NEXT&apos;\n  };\n}\n</code></pre><p><code>ResultsContainer</code>组件将会自动关联action creators中的next作为props：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport * as actionCreators from &apos;../action_creators&apos;;\n\nexport const Results = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return this.props.winner ?\n      &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n      &lt;div className=&quot;results&quot;&gt;\n        &lt;div className=&quot;tally&quot;&gt;\n          {this.getPair().map(entry =&gt;\n            &lt;div key={entry} className=&quot;entry&quot;&gt;\n              &lt;h1&gt;{entry}&lt;/h1&gt;\n              &lt;div className=&quot;voteCount&quot;&gt;\n                {this.getVotes(entry)}\n              &lt;/div&gt;\n            &lt;/div&gt;\n          )}\n        &lt;/div&gt;\n        &lt;div className=&quot;management&quot;&gt;\n          &lt;button ref=&quot;next&quot;\n                   className=&quot;next&quot;\n                   onClick={this.props.next()}&gt;\n            Next\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    tally: state.getIn([&apos;vote&apos;, &apos;tally&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  }\n}\n\nexport const ResultsContainer = connect(\n  mapStateToProps,\n  actionCreators\n)(Results);\n</code></pre><p>彻底完工了！我们实现了一个功能完备的应用。</p>\n<p>###课后练习<br>（不翻译）</p>\n","excerpt":"<p>本文乱译自一篇英文博文（<a href=\"http://teropa.info/blog/2015/09/10/full-stack-redux-tutorial.html\">Full-Stack Redux Tutorial</a>），本人英语能力不足，技术能力有限，如有错误，多多包涵。</p>","more":"<p>#关于Redux+React+Immutable的测试先行开发综合指南</p>\n<p>Redux是最近发生在js界令人兴奋的事儿。它把众多优秀的库和框架中非常正确的特性保留了下来：简单且可预测的模型，强调函数式编程和不可变数据，基于api的轻量级实现……你还有什么理由不喜欢呢？</p>\n<p>Redux是一个非常小的代码库，掌握它所有的api并不困难，但对很多同学来讲，它要求的：创建组件（blocks），自满足的纯函数和不可变数据会带来不少别扭，那到底应该怎么办呢？</p>\n<p>这篇文章将会带你创建一个全栈的Redux和Immutable-js应用。我们将详细讲解创建该应用的Node+Redu后端和React+Redux前端的所有步骤。本指南将使用ES6,Babel,Socket.io,Webpack和Mocha。这是一个非常令人着迷的技术栈选型，你肯定不及待的想要开始了。</p>\n<p>##目录<br>（不翻译）</p>\n<h2 id=\"你需要准备什么\"><a href=\"#你需要准备什么\" class=\"headerlink\" title=\"你需要准备什么\"></a>你需要准备什么</h2><p>这篇文章需要读者具备开发js应用的能力，我们讲使用Node，ES6，React，Webpack，和Babel，所以你最好能了解这些工具，这样你才不会掉队。</p>\n<p>在上面提到的工具集中，你需要安装Node和NPM，和一款你喜欢的编辑器。</p>\n<p>##应用</p>\n<p>我们将要开发一款应用，它用来为聚会，会议，集会等用户群提供实时投票功能。</p>\n<p>这个点子来自于现实中我们经常需要为电影，音乐，编程语言等进行投票。该应用将所有选项两两分组，这样用户可以根据喜好进行二选一，最终拿到最佳结果。</p>\n<p>举个例子，这里拿Danny Boyle电影做例子来发起投票：</p>\n<p><img src=\"http://teropa.info/images/vote_logic.png\" alt=\"\"></p>\n<p>这个应用有两类独立的界面：用于投票的移动端界面，用于其它功能的浏览器界面。投票结果界面设计成有利于幻灯片或其它更大尺寸的屏幕显示，它用来展示投票的实时结果。</p>\n<p><img src=\"http://teropa.info/images/vote_system.png\" alt=\"\"></p>\n<p>##架构</p>\n<p>该系统应该有2部分组成：浏览器端我们使用React来提供用户界面，服务端我们使用Node来处理投票逻辑。两端通信我们选择使用WebSockets。</p>\n<p>我们将使用Redux来组织前后端的应用代码。我们将使用Immutable数据结构来处理应用的state。</p>\n<p>虽然我们的前后端存在许多相似性，例如都使用Redux。但是它们之间并没有什么可复用代码。这更像一个分布式系统，靠传递消息进行通信。</p>\n<p>##服务端应用</p>\n<p>我们先来实现Node应用，这有助于我们专注于核心业务逻辑，而不是过早的被界面干扰。</p>\n<p>实现服务端应用，我们需要先了解Redux和Immutable，并且明白它们如何协作。Redux常常被用在React开发中，但它并不限制于此。我们这里就要学习让Redux如何在其它场景下使用。</p>\n<p>我推荐大家跟着我们的指导一起写出一个应用，但你也可以直接从<a href=\"https://github.com/teropa/redux-voting-server\">github</a>上下载代码。</p>\n<p>###设计应用的状态树（State Tree）</p>\n<p>设计一个Redux应用往往从思考应用的状态树数据结构开始，它是用来描述你的应用在任何时间点下状态的数据结构。</p>\n<p>任何的框架和架构都包含状态。在Ember和Backbone框架里，状态就是模型（Models）。在Anglar中，状态常常用Factories和Services来管理。而在大多数Flux实现中，常常用Stores来负责状态。那Redux又和它们有哪些不同之处呢？</p>\n<p>最大的不同之处是，在Redux中，应用的状态是全部存在一个单一的树结构中的。换句话说，应用的所有状态信息都存储在这个包含map和array的数据结构中。</p>\n<p>这么做很有意义，我们马上就会感受到。最重要的一点是，这么做迫使你将应用的行为和状态隔离开来。状态就是纯数据，它不包含任何方法或函数。</p>\n<p>这么做听起来存在局限，特别是你刚刚从面向对象思想背景下转到Redux。但这确实是一种解放，因为这么做将使你专注于数据自身。如果你花一些时间来设计你的应用状态，其它环节将水到渠成。</p>\n<p>这并不是说你总应该一上来就设计你的实体状态树然后再做其它部分。通常你最终会同时考虑应用的所有方面。然而，我发现当你想到一个点子时，在写代码前先思考在不同解决方案下状态树的结构会非常有帮助。</p>\n<p>所以，让我们先看看我们的投票应用的状态树应该是什么样的。应用的目标是可以针对多个选项进行投票，那么符合直觉的一种初始化状态应该是包含要被投票的选项集合，我们称之为条目[entries]：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_entries.png\" alt=\"\"></p>\n<p>当投票开始，还必须定位哪些选项是当前项。所以我们可能还需要一个vote条目，它用来存储当前投票的数据对，投票项应该是来自entries中的：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_pair.png\" alt=\"\"></p>\n<p>除此之外，投票的计数也应该被保存起来：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_tally.png\" alt=\"\"></p>\n<p>每次用户进行二选一后，未被选择的那项直接丢弃，被选择的条目重新放回entries的末尾，然后从entries头部选择下一对投票项：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_next.png\" alt=\"\"></p>\n<p>我们可以想象一下，这么周而复始的投票，最终将会得到一个结果，投票也就结束了：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_winner.png\" alt=\"\"></p>\n<p>如此设计看起来是合情合理的。针对上面的场景存在很多不同的设计，我们当前的做法也可能不是最佳的，但我们暂时就先这么定吧，足够我们进行下一步了。最重要的是我们在没有写任何代码的前提下已经从最初的点子过渡到确定了应用的具体功能。</p>\n<p>###项目安排</p>\n<p>是时候开始脏活累活了。开始之前，我们先创建一个项目目录：</p>\n<pre><code>mkdir voting-server\ncd voting-server\nnpm init         #所有提示问题直接敲回车即可\n</code></pre><p>初始化完毕后，我们的项目目录下将会只存在一个<em>package.json</em>文件。</p>\n<p>我们将采用ES6语法来写代码。Node是从4.0.0版本后开始支持大多数ES6语法的，并且目前并不支持modules，但我们需要用到。我们将加入Babel，这样我们就能将ES6直接转换成ES5了：</p>\n<pre><code>npm install --save-dev babel\n</code></pre><p>我们还需要些库来用于写单元测试：</p>\n<pre><code>npm install --save-dev mocha chai\n</code></pre><p><a href=\"https://mochajs.org/\">Mocha</a>是一个我们将要使用的测试框架，<a href=\"http://chaijs.com/\">Chai</a>是一个我们用来测试的断言库。</p>\n<p>我们将使用下面的mocha命令来跑测试项：</p>\n<pre><code>./node_modules/mocha/bin/mocha --compilers js:babel/register --recursive\n</code></pre><p>这条命令告诉Mocha递归的去项目中查找并执行所有测试项，但执行前先使用Babel进行语法转换。</p>\n<p>为了使用方便，可以在我们的<em>package.json</em>中添加下面这段代码：</p>\n<pre><code>&quot;scripts&quot;: {\n      &quot;test&quot;: &quot;mocha --compilers js:babel/register --recursive&quot;\n},\n</code></pre><p>这样以后我们跑测试就只需要执行：</p>\n<pre><code>npm run test\n</code></pre><p>另外，我们还可以添加<em>test:watch</em>命令，它用来监控文件变化并自动跑测试项：</p>\n<pre><code>&quot;scripts&quot;: {\n      &quot;test&quot;: &quot;mocha --compilers js:babel/register --recursive&quot;,\n      &quot;test:watch&quot;: &quot;npm run test -- --watch&quot;\n},\n</code></pre><p>我们还将用到一个库，来自于facebook：<a href=\"http://facebook.github.io/immutable-js/\">Immutable</a>，它提供了许多数据结构供我们使用。下一小节我们再来讨论Immutable，但我们在这里先将它加入到我们的项目中，附带<a href=\"https://github.com/astorije/chai-immutable\">chai-immutable</a>库，它用来向Chai库加入不可变数据结构比对功能：</p>\n<pre><code>npm install --save immutable\nnpm install --save-dev chai-immutable\n</code></pre><p>我们需要在所有测试代码前先加入chai-immutable插件，所以我们来先创建一个测试辅助文件：</p>\n<pre><code>//test/test_helper.js\n\nimport chai from &apos;chai&apos;;\nimport chaiImmutable from &apos;chai-immutable&apos;;\n\nchai.use(chaiImmutable);\n</code></pre><p>然后我们需要让Mocha在开始跑测试之前先加载这个文件，修改package.json：</p>\n<pre><code>&quot;scripts&quot;: {\n      &quot;test&quot;: &quot;mocha --compilers js:babel/register --        require ./test/test_helper.js  --recursive&quot;,\n      &quot;test:watch&quot;: &quot;npm run test -- --watch&quot;\n},\n</code></pre><p>好了，准备的差不多了。</p>\n<p>###酸爽的Immutable</p>\n<p>第二个值得重视的点是，Redux架构下状态并非只是一个普通的tree，而是一棵不可变的tree。</p>\n<p>回想一下前面我们设计的状态tree，你可能会觉得可以直接在应用的代码里直接更新tree：修改映射的值，或删除数组元素等。然而，这并不是Redux允许的。</p>\n<p>一个Redux应用的状态树是不可变的数据结构。这意味着，一旦你得到了一棵状态树，它就不会在改变了。任何用户行为改变应用状态，你都会获取一棵映射应用改变后新状态的完整状态树。</p>\n<p>这说明任何连续的状态（改变前后）都被分别存储在独立的两棵树。你通过调用一个函数来从一种状态转入下一个状态。</p>\n<p><img src=\"http://teropa.info/images/vote_state_succession.png\" alt=\"\"></p>\n<p>这么做好在哪呢？第一，用户通常想一个undo功能，当你误操作导致破坏了应用状态后，你往往想退回到应用的历史状态，而单一的状态tree让该需求变得廉价，你只需要简单保存上一个状态tree的数据即可。你也可以序列化tree并存储起来以供将来重放，这对debug很有帮助的。</p>\n<p>抛开其它的特性不谈，不可变数据至少会让你的代码变得简单，这非常重要。你可以用纯函数来进行编程：接受参数数据，返回数据，其它啥都不做。这种函数拥有可预见性，你可以多次调用它，只要参数一致，它总返回相同的结果（冪等性）。测试将变的容易，你不需要在测试前创建太多的准备，仅仅是传入参数和返回值。</p>\n<p>不可变数据结构是我们创建应用状态的基础，让我们花点时间来写一些测试项来保证它的正常工作。</p>\n<p>为了更了解不可变性，我们来看一个十分简单的数据结构：假设我们有一个计数应用，它只包含一个计数器变量，该变量会从0增加到1，增加到2，增加到3，以此类推。</p>\n<p>如果用不可变数据来设计这个计数器变量，则每当计数器自增，我们不是去改变变量本身。你可以想象成该计数器变量没有“setters”方法，你不能执行<code>42.setValue(43)</code>。</p>\n<p>每当变化发生，我们将获得一个新的变量，它的值是之前的那个变量的值加1等到的。我们可以为此写一个纯函数，它接受一个参数代表当前的状态，并返回一个值表示新的状态。记住，调用它并会修改传入参数的值。这里看一下函数实现和测试代码：</p>\n<pre><code>//test/immutable_spec.js\n\nimport {expect} from &apos;chai&apos;;\n\ndescribe(&apos;immutability&apos;, () =&gt; {\n\n      describe(&apos;a number&apos;, () =&gt; {\n\n        function increment(currentState) {\n              return currentState + 1;\n        }\n\n        it(&apos;is immutable&apos;, () =&gt; {\n              let state = 42;\n              let nextState = increment(state);\n\n              expect(nextState).to.equal(43);\n              expect(state).to.equal(42);\n        });\n\n      });\n});\n</code></pre><p>可以看到当<code>increment</code>调用后<code>state</code>并没有被修改，这是因为<code>Numbers</code>是不可变的。</p>\n<p>我们接下来要做的是让各种数据结构都不可变，而不仅仅是一个整数。</p>\n<p>利用Immutable提供的<a href=\"https://facebook.github.io/immutable-js/docs/#/Listf\">Lists</a>，我们可以假设我们的应用拥有一个电影列表的状态，并且有一个操作用来向当前列表中添加新电影，新列表数据是添加前的列表数据和新增的电影条目合并后的结果，注意，添加前的旧列表数据并没有被修改哦：</p>\n<pre><code>//test/immutable_spec.json\n\nimport {expect} from &apos;chai&apos;;\nimport {List} from &apos;immutable&apos;;\n\ndescribe(&apos;immutability&apos;, () =&gt; {\n\n      // ...\n\n      describe(&apos;A List&apos;, () =&gt; {\n\n        function addMovie(currentState, movie) {\n              return currentState.push(movie);\n        }\n\n        it(&apos;is immutable&apos;, () =&gt; {\n              let state = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n              let nextState = addMovie(state, &apos;Sunshine&apos;);\n\n              expect(nextState).to.equal(List.of(\n                &apos;Trainspotting&apos;,\n                &apos;28 Days Later&apos;,\n                &apos;Sunshine&apos;\n              ));\n              expect(state).to.equal(List.of(\n                &apos;Trainspotting&apos;,\n                &apos;28 Days Later&apos;\n              ));\n        });\n      });\n});\n</code></pre><p>如果我们使用的是原生态js数组，那么上面的<code>addMovie</code>函数并不会保证旧的状态不会被修改。这里我们使用的是Immutable List。</p>\n<p>真实软件中，一个状态树通常是嵌套了多种数据结构的：list，map以及其它类型的集合。假设状态树是一个包含了<em>movies</em>列表的hash map，添加一个电影意味着我们需要创建一个新的map，并且在新的map的<em>movies</em>元素中添加该新增数据：</p>\n<pre><code>//test/immutable_spec.json\n\nimport {expect} from &apos;chai&apos;;\nimport {List, Map} from &apos;immutable&apos;;\n\ndescribe(&apos;immutability&apos;, () =&gt; {\n\n      // ...\n\n      describe(&apos;a tree&apos;, () =&gt; {\n\n        function addMovie(currentState, movie) {\n              return currentState.set(\n                &apos;movies&apos;,\n                    currentState.get(&apos;movies&apos;).push(movie)\n              );\n        }\n\n        it(&apos;is immutable&apos;, () =&gt; {\n              let state = Map({\n                movies: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n              });\n              let nextState = addMovie(state, &apos;Sunshine&apos;);\n\n              expect(nextState).to.equal(Map({\n                movies: List.of(\n                      &apos;Trainspotting&apos;,\n                      &apos;28 Days Later&apos;,\n                      &apos;Sunshine&apos;\n                )\n              }));\n              expect(state).to.equal(Map({\n                    movies: List.of(\n                      &apos;Trainspotting&apos;,\n                      &apos;28 Days Later&apos;\n                )\n              }));\n        });\n      });\n});\n</code></pre><p>该例子和前面的那个类似，主要用来展示在嵌套结构下Immutable的行为。</p>\n<p>针对类似上面这个例子的嵌套数据结构，Immutable提供了很多辅助函数，可以帮助我们更容易的定位嵌套数据的内部属性，以达到更新对应值的目的。我们可以使用一个叫<code>update</code>的方法来修改上面的代码：</p>\n<pre><code>//test/immutable_spec.json\n\nfunction addMovie(currentState, movie) {\n      return currentState.update(&apos;movies&apos;, movies =&gt; movies.push(movie));\n}\n</code></pre><p>现在我们很好的了解了不可变数据，这将被用于我们的应用状态。<a href=\"https://facebook.github.io/immutable-js/docs/#/\">Immutable API</a>提供了非常多的辅助函数，我们目前只是学了点皮毛。</p>\n<p>不可变数据是Redux的核心理念，但并不是必须使用Immutable库来实现这个特性。事实上，<a href=\"http://rackt.github.io/redux/\">官方Redux文档</a>使用的是原生js对象和数组，并通过简单的扩展它们来实现的。</p>\n<p>这个教程中，我们将使用Immutable库，原因如下：</p>\n<ul>\n<li>该库将使得实现不可变数据结构变得非常简单；</li>\n<li>我个人偏爱于将尽可能的使用不可变数据，如果你的数据允许直接修改，迟早会有人踩坑；</li>\n<li>不可变数据结构更新是持续的，意味着很容易产生性能平静，特别维护是非常庞大的状态树，使用原生js对象和数组意味着要频繁的进行拷贝，很容易导致性能问题。</li>\n</ul>\n<p>###基于纯函数实现应用逻辑</p>\n<p>根据目前我们掌握的不可变状态树和相关操作，我们可以尝试实现投票应用的逻辑。应用的核心逻辑我们拆分成：状态树结构和生成新状态树的函数集合。</p>\n<p>####加载条目</p>\n<p>首先，之前说到，应用允许“加载”一个用来投票的条目集。我们需要一个<code>setEntries</code>函数，它用来提供应用的初始化状态：</p>\n<pre><code>//test/core_spec.js\n\nimport {List, Map} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport {setEntries} from &apos;../src/core&apos;;\n\ndescribe(&apos;application logic&apos;, () =&gt; {\n\n  describe(&apos;setEntries&apos;, () =&gt; {\n\n    it(&apos;adds the entries to the state&apos;, () =&gt; {\n      const state = Map();\n      const entries = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n      const nextState = setEntries(state, entries);\n      expect(nextState).to.equal(Map({\n        entries: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n      }));\n    });\n  });\n});\n</code></pre><p>我们目前<code>setEntries</code>函数的第一版非常简单：在状态map中创建一个<code>entries</code>键，并设置给定的条目List。</p>\n<pre><code>//src/core.js\n\nexport function setEntries(state, entries) {\n    return state.set(&apos;entries&apos;, entries);\n}\n</code></pre><p>为了方便起见，我们允许函数第二个参数接受一个原生js数组（或支持iterable的类型），但在状态树中它应该是一个Immutable List：</p>\n<pre><code>//test/core_spec.js\n\nit(&apos;converts to immutable&apos;, () =&gt; {\n  const state = Map();\n  const entries = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n  const nextState = setEntries(state, entries);\n  expect(nextState).to.equal(Map({\n    entries: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n  }));\n});\n</code></pre><p>为了达到要求，我们需要修改一下代码：</p>\n<pre><code>//src/core.js\n\nimport {List} from &apos;immutable&apos;;\n\nexport function setEntries(state, entries) {\n  return state.set(&apos;entries&apos;, List(entries));\n}\n</code></pre><p>####开始投票</p>\n<p>当state加载了条目集合后，我们可以调用一个<code>next</code>函数来开始投票。这表示，我们到了之前设计的状态树的第二阶段。</p>\n<p><code>next</code>函数需要在状态树创建中一个投票map，该map有拥有一个<code>pair</code>键，值为投票条目中的前两个元素。<br>这两个元素一旦确定，就要从之前的条目列表中清除：</p>\n<pre><code>//test/core_spec.js\n\nimport {List, Map} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\nimport {setEntries, next} from &apos;../src/core&apos;;\n\ndescribe(&apos;application logic&apos;, () =&gt; {\n\n  // ..\n\n  describe(&apos;next&apos;, () =&gt; {\n\n    it(&apos;takes the next two entries under vote&apos;, () =&gt; {\n      const state = Map({\n        entries: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;, &apos;Sunshine&apos;)\n      });\n      const nextState = next(state);\n      expect(nextState).to.equal(Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n        }),\n        entries: List.of(&apos;Sunshine&apos;)\n      }));\n    });\n  });\n});\n</code></pre><p><code>next</code>函数实现如下：</p>\n<pre><code>//src/core.js\n\nimport {List, Map} from &apos;immutable&apos;;\n\n// ...\n\nexport function next(state) {\n  const entries = state.get(&apos;entries&apos;);\n  return state.merge({\n    vote: Map({pair: entries.take(2)}),\n    entries: entries.skip(2)\n  });\n}\n</code></pre><p>####投票</p>\n<p>当用户产生投票行为后，每当用户给某个条目投了一票后，<code>vote</code>将会为这个条目添加<code>tally</code>信息，如果对应的<br>条目信息已存在，则需要则增：</p>\n<pre><code>//test/core_spec.js\n\nimport {List, Map} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\nimport {setEntries, next, vote} from &apos;../src/core&apos;;\n\ndescribe(&apos;application logic&apos;, () =&gt; {\n\n  // ...\n\n  describe(&apos;vote&apos;, () =&gt; {\n\n    it(&apos;creates a tally for the voted entry&apos;, () =&gt; {\n      const state = Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n        }),\n        entries: List()\n      });\n      const nextState = vote(state, &apos;Trainspotting&apos;);\n      expect(nextState).to.equal(Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({\n            &apos;Trainspotting&apos;: 1\n          })\n        }),\n        entries: List()\n      }));\n    });\n\n    it(&apos;adds to existing tally for the voted entry&apos;, () =&gt; {\n      const state = Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({\n            &apos;Trainspotting&apos;: 3,\n            &apos;28 Days Later&apos;: 2\n          })\n        }),\n        entries: List()\n      });\n      const nextState = vote(state, &apos;Trainspotting&apos;);\n      expect(nextState).to.equal(Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({\n            &apos;Trainspotting&apos;: 4,\n            &apos;28 Days Later&apos;: 2\n          })\n        }),\n        entries: List()\n      }));\n    });\n  });\n});\n</code></pre><p>为了让上面的测试项通过，我们可以如下实现<code>vote</code>函数：</p>\n<pre><code>//src/core.js\n\nexport function vote(state, entry) {\n  return state.updateIn(\n    [&apos;vote&apos;, &apos;tally&apos;, entry],\n    0,\n    tally =&gt; tally + 1\n  );\n}\n</code></pre><p><a href=\"https://facebook.github.io/immutable-js/docs/#/Map/updateIn\">updateIn</a>让我们更容易完成目标。<br>它接受的第一个参数是个表达式，含义是“定位到嵌套数据结构的指定位置，路径为：[‘vote’, ‘tally’, ‘Trainspotting’]”，<br>并且执行后面逻辑：如果路径指定的位置不存在，则创建新的映射对，并初始化为0，否则对应值加1。</p>\n<p>可能对你来说上面的语法太过于晦涩，但一旦你掌握了它，你将会发现用起来非常的酸爽，所以花一些时间学习并<br>适应它是非常值得的。</p>\n<p>####继续投票</p>\n<p>每次完成一次二选一投票，用户将进入到第二轮投票，每次得票最高的选项将被保存并添加回条目集合。我们需要添加<br>这个逻辑到<code>next</code>函数中：</p>\n<pre><code>//test/core_spec.js\n\ndescribe(&apos;next&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;puts winner of current vote back to entries&apos;, () =&gt; {\n    const state = Map({\n      vote: Map({\n        pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n        tally: Map({\n          &apos;Trainspotting&apos;: 4,\n          &apos;28 Days Later&apos;: 2\n        })\n      }),\n      entries: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;, &apos;127 Hours&apos;)\n    });\n    const nextState = next(state);\n    expect(nextState).to.equal(Map({\n      vote: Map({\n        pair: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;)\n      }),\n      entries: List.of(&apos;127 Hours&apos;, &apos;Trainspotting&apos;)\n    }));\n  });\n\n  it(&apos;puts both from tied vote back to entries&apos;, () =&gt; {\n    const state = Map({\n      vote: Map({\n        pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n        tally: Map({\n          &apos;Trainspotting&apos;: 3,\n          &apos;28 Days Later&apos;: 3\n        })\n      }),\n      entries: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;, &apos;127 Hours&apos;)\n    });\n    const nextState = next(state);\n    expect(nextState).to.equal(Map({\n      vote: Map({\n        pair: List.of(&apos;Sunshine&apos;, &apos;Millions&apos;)\n      }),\n      entries: List.of(&apos;127 Hours&apos;, &apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n    }));\n  });\n});\n</code></pre><p>我们需要一个<code>getWinners</code>函数来帮我们选择谁是赢家：</p>\n<pre><code>//src/core.js\n\nfunction getWinners(vote) {\n  if (!vote) return [];\n  const [a, b] = vote.get(&apos;pair&apos;);\n  const aVotes = vote.getIn([&apos;tally&apos;, a], 0);\n  const bVotes = vote.getIn([&apos;tally&apos;, b], 0);\n  if      (aVotes &gt; bVotes)  return [a];\n  else if (aVotes &lt; bVotes)  return [b];\n  else                       return [a, b];\n}\n\nexport function next(state) {\n  const entries = state.get(&apos;entries&apos;)\n                       .concat(getWinners(state.get(&apos;vote&apos;)));\n  return state.merge({\n    vote: Map({pair: entries.take(2)}),\n    entries: entries.skip(2)\n  });\n}\n</code></pre><p>####投票结束</p>\n<p>当投票项只剩一个时，投票结束：</p>\n<pre><code>//test/core_spec.js\n\ndescribe(&apos;next&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;marks winner when just one entry left&apos;, () =&gt; {\n    const state = Map({\n      vote: Map({\n        pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n        tally: Map({\n          &apos;Trainspotting&apos;: 4,\n          &apos;28 Days Later&apos;: 2\n        })\n      }),\n      entries: List()\n    });\n    const nextState = next(state);\n    expect(nextState).to.equal(Map({\n      winner: &apos;Trainspotting&apos;\n    }));\n  });\n});\n</code></pre><p>我们需要在<code>next</code>函数中增加一个条件分支，用来匹配上面的逻辑：</p>\n<pre><code>//src/core.js\n\nexport function next(state) {\n  const entries = state.get(&apos;entries&apos;)\n                       .concat(getWinners(state.get(&apos;vote&apos;)));\n  if (entries.size === 1) {\n    return state.remove(&apos;vote&apos;)\n                .remove(&apos;entries&apos;)\n                .set(&apos;winner&apos;, entries.first());\n  } else {\n    return state.merge({\n      vote: Map({pair: entries.take(2)}),\n      entries: entries.skip(2)\n    });\n  }\n}\n</code></pre><p>我们可以直接返回<code>Map({winner: entries.first()})</code>，但我们还是基于旧的状态数据进行一步一步的<br>操作最终得到结果，这么做是为将来做打算。因为应用将来可能还会有很多其它状态数据在Map中，这是一个写测试项的好习惯。<br>所以我们以后要记住，不要重新创建一个状态数据，而是从旧的状态数据中生成新的状态实例。</p>\n<p>到此为止我们已经有了一套可以接受的应用核心逻辑实现，表现形式为几个独立的函数。我们也有针对这些函数的<br>测试代码，这些测试项很容易写：No setup, no mocks, no stubs。这就是纯函数的魅力，我们只需要调用它们，<br>并检查返回值就行了。</p>\n<p>提醒一下，我们目前还没有安装redux哦，我们就已经可以专注于应用自身的逻辑本身进行实现，而不被所谓的框架<br>所干扰。这真的很不错，对吧？</p>\n<p>###初识Actions和Reducers</p>\n<p>我们有了应用的核心函数，但在Redux中我们不应该直接调用函数。在这些函数和应用之间还存在这一个中间层：Actions。</p>\n<p>Action是一个描述应用状态变化发生的简单数据结构。按照约定，每个action都包含一个<code>type</code>属性，<br>该属性用于描述操作类型。action通常还包含其它属性，下面是一个简单的action例子，该action用来匹配<br>前面我们写的业务操作：</p>\n<pre><code>{type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]}\n\n{type: &apos;NEXT&apos;}\n\n{type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;}\n</code></pre><p>actions的描述就这些，但我们还需要一种方式用来把它绑定到我们实际的核心函数上。举个例子：</p>\n<pre><code>// 定义一个action\nlet voteAction = {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;}\n// 该action应该触发下面的逻辑\nreturn vote(state, voteAction.entry);\n</code></pre><p>我们接下来要用到的是一个普通函数，它用来根据action和当前state来调用指定的核心函数，我们称这种函数叫：<br>reducer：</p>\n<pre><code>//src/reducer.js\n\nexport default function reducer(state, action) {\n  // Figure out which function to call and call it\n}\n</code></pre><p>我们应该测试这个reducer是否可以正确匹配我们之前的三个actions：</p>\n<pre><code>//test/reducer_spec.js\n\nimport {Map, fromJS} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport reducer from &apos;../src/reducer&apos;;\n\ndescribe(&apos;reducer&apos;, () =&gt; {\n\n  it(&apos;handles SET_ENTRIES&apos;, () =&gt; {\n    const initialState = Map();\n    const action = {type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;]};\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      entries: [&apos;Trainspotting&apos;]\n    }));\n  });\n\n  it(&apos;handles NEXT&apos;, () =&gt; {\n    const initialState = fromJS({\n      entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n    });\n    const action = {type: &apos;NEXT&apos;};\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n      },\n      entries: []\n    }));\n  });\n\n  it(&apos;handles VOTE&apos;, () =&gt; {\n    const initialState = fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n      },\n      entries: []\n    });\n    const action = {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;};\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      },\n      entries: []\n    }));\n  });\n});\n</code></pre><p>我们的reducer将根据action的type来选择对应的核心函数，它同时也应该知道如何使用action的额外属性：</p>\n<pre><code>//src/reducer.js\n\nimport {setEntries, next, vote} from &apos;./core&apos;;\n\nexport default function reducer(state, action) {\n  switch (action.type) {\n  case &apos;SET_ENTRIES&apos;:\n    return setEntries(state, action.entries);\n  case &apos;NEXT&apos;:\n    return next(state);\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry)\n  }\n  return state;\n}\n</code></pre><p>注意，如果reducer没有匹配到action，则应该返回当前的state。</p>\n<p>reducers还有一个需要特别注意的地方，那就是当传递一个未定义的state参数时，reducers应该知道如何<br>初始化state为有意义的值。我们的场景中，初始值为Map，因此如果传给reducer一个<code>undefined</code>state的话，<br>reducers将使用一个空的Map来代替：</p>\n<pre><code>//test/reducer_spec.js\n\ndescribe(&apos;reducer&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;has an initial state&apos;, () =&gt; {\n    const action = {type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;]};\n    const nextState = reducer(undefined, action);\n    expect(nextState).to.equal(fromJS({\n      entries: [&apos;Trainspotting&apos;]\n    }));\n  });\n});\n</code></pre><p>之前在我们的<code>cores.js</code>文件中，我们定义了初始值：</p>\n<pre><code>//src/core.js\n\nexport const INITIAL_STATE = Map();\n</code></pre><p>所以在reducer中我们可以直接导入它：</p>\n<pre><code>//src/reducer.js\n\nimport {setEntries, next, vote, INITIAL_STATE} from &apos;./core&apos;;\n\nexport default function reducer(state = INITIAL_STATE, action) {\n  switch (action.type) {\n  case &apos;SET_ENTRIES&apos;:\n    return setEntries(state, action.entries);\n  case &apos;NEXT&apos;:\n    return next(state);\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry)\n  }\n  return state;\n}\n</code></pre><p>事实上，提供一个action集合，你可以将它们分解并作用在当前状态上，这也是为什么称它们为reducer的原因：<br>它完全适配reduce方法：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;can be used with reduce&apos;, () =&gt; {\n  const actions = [\n    {type: &apos;SET_ENTRIES&apos;, entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]},\n    {type: &apos;NEXT&apos;},\n    {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;},\n    {type: &apos;VOTE&apos;, entry: &apos;28 Days Later&apos;},\n    {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;},\n    {type: &apos;NEXT&apos;}\n  ];\n  const finalState = actions.reduce(reducer, Map());\n\n  expect(finalState).to.equal(fromJS({\n    winner: &apos;Trainspotting&apos;\n  }));\n});\n</code></pre><p>相比直接调用核心业务函数，这种批处理或称之为重放一个action集合的能力主要依赖于状态转换的action/reducer模型。<br>举个例子，你可以把actions序列化成json，并轻松的将它发送给Web Worker去执行你的reducer逻辑。或者<br>直接通过网络发送到其它地方供日后执行！</p>\n<p>注意我们这里使用的是普通js对象作为actions，而并非不可变数据类型。这是Redux提倡我们的做法。</p>\n<p>###尝试Reducer协作</p>\n<p>目前我们的核心函数都是接受整个state并返回更新后的整个state。</p>\n<p>这么做在大型应用中可能并不太明智。如果你的应用所有操作都要求必须接受完整的state，那么这个项目维护起来就是灾难。<br>日后如果你想进行state结构的调整，你将会付出惨痛的代价。</p>\n<p>其实有更好的做法，你只需要保证组件操作尽可能小的state片段即可。我们这里提到的就是模块化思想：<br>提供给模块仅它需要的数据，不多不少。</p>\n<p>我们的应用很小，所以这并不是太大的问题，但我们还是选择改善这一点：没有必要给<code>vote</code>函数传递整个state，它只需要<code>vote</code><br>部分。让我们修改一下对应的测试代码：</p>\n<pre><code>//test/core_spec.js\n\ndescribe(&apos;vote&apos;, () =&gt; {\n\n  it(&apos;creates a tally for the voted entry&apos;, () =&gt; {\n    const state = Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;)\n    });\n    const nextState = vote(state, &apos;Trainspotting&apos;)\n    expect(nextState).to.equal(Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n      tally: Map({\n        &apos;Trainspotting&apos;: 1\n      })\n    }));\n  });\n\n  it(&apos;adds to existing tally for the voted entry&apos;, () =&gt; {\n    const state = Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n      tally: Map({\n        &apos;Trainspotting&apos;: 3,\n        &apos;28 Days Later&apos;: 2\n      })\n    });\n    const nextState = vote(state, &apos;Trainspotting&apos;);\n    expect(nextState).to.equal(Map({\n      pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n      tally: Map({\n        &apos;Trainspotting&apos;: 4,\n        &apos;28 Days Later&apos;: 2\n      })\n    }));\n  });\n});\n</code></pre><p>看，测试代码更加简单了。</p>\n<p><code>vote</code>函数的实现也需要更新：</p>\n<pre><code>//src/core.js\n\nexport function vote(voteState, entry) {\n  return voteState.updateIn(\n    [&apos;tally&apos;, entry],\n    0,\n    tally =&gt; tally + 1\n  );\n}\n</code></pre><p>最后我们还需要修改<code>reducer</code>，只传递需要的state给<code>vote</code>函数：</p>\n<pre><code>//src/reducer.js\n\nexport default function reducer(state = INITIAL_STATE, action) {\n  switch (action.type) {\n  case &apos;SET_ENTRIES&apos;:\n    return setEntries(state, action.entries);\n  case &apos;NEXT&apos;:\n    return next(state);\n  case &apos;VOTE&apos;:\n    return state.update(&apos;vote&apos;,\n                        voteState =&gt; vote(voteState, action.entry));\n  }\n  return state;\n}\n</code></pre><p>这个做法在大型项目中非常重要：根reducer只传递部分state给下一级reducer。我们将定位合适的state片段的工作<br>从对应的更新操作中分离出来。</p>\n<p><a href=\"http://rackt.github.io/redux/docs/basics/Reducers.html\">Redux的reducers文档</a>针对这一细节<br>介绍了更多内容，并描述了一些辅助函数的用法，可以在更多长场景中有效的使用。</p>\n<p>###初识Redux Store</p>\n<p>现在我们可以开始了解如何将上面介绍的内容使用在Redux中了。</p>\n<p>如你所见，如果你有一个actions集合，你可以调用<code>reduce</code>，获得最终的应用状态。当然，通常情况下不会如此，actions<br>将会在不同的时间发生：用户操作，远程调用，超时触发器等。</p>\n<p>针对这些情况，我们可以使用Redux Store。从名字可以看出它用来存储应用的状态。</p>\n<p>Redux Store通常会由一个reducer函数初始化，如我们之前实现的：</p>\n<pre><code>import {createStore} from &apos;redux&apos;;\n\nconst store = createStore(reducer);\n</code></pre><p>接下来你就可以向这个Store指派actions了。Store内部将会使用你实现的reducer来处理action，并负责传递给<br>reducer应用的state，最后负责存储reducer返回的新state：</p>\n<pre><code>store.dispatch({type: &apos;NEXT&apos;});\n</code></pre><p>任何时刻你都可以通过下面的方法获取当前的state：</p>\n<pre><code>store.getState();\n</code></pre><p>我们将会创建一个<code>store.js</code>用来初始化和导出一个Redux Store对象。让我们先写测试代码吧：</p>\n<pre><code>//test/store_spec.js\n\nimport {Map, fromJS} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport makeStore from &apos;../src/store&apos;;\n\ndescribe(&apos;store&apos;, () =&gt; {\n\n  it(&apos;is a Redux store configured with the correct reducer&apos;, () =&gt; {\n    const store = makeStore();\n    expect(store.getState()).to.equal(Map());\n\n    store.dispatch({\n      type: &apos;SET_ENTRIES&apos;,\n      entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n    });\n    expect(store.getState()).to.equal(fromJS({\n      entries: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;]\n    }));\n  });\n});\n</code></pre><p>在创建Store之前，我们先在项目中加入Redux库：</p>\n<pre><code>npm install --save redux\n</code></pre><p>然后我们新建<code>store.js</code>文件，如下：</p>\n<pre><code>//src/store.js\n\nimport {createStore} from &apos;redux&apos;;\nimport reducer from &apos;./reducer&apos;;\n\nexport default function makeStore() {\n  return createStore(reducer);\n}\n</code></pre><p>Redux Store负责将应用的所有组件关联起来：它持有应用的当前状态，并负责指派actions，且负责调用包含了<br>业务逻辑的reducer。</p>\n<p>应用的业务代码和Redux的整合方式非常引人注目，因为我们只有一个普通的reducer函数，这是唯一需要告诉Redux<br>的事儿。其它部分全部都是我们自己的，没有框架入侵的，高便携的纯函数代码！</p>\n<p>现在我们创建一个应用的入口文件<code>index.js</code>：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\n\nexport const store = makeStore();\n</code></pre><p>现在我们可以开启一个<a href=\"http://segmentfault.com/a/1190000002673137\">Node REPL</a>（例如babel-node）,<br>载入<code>index.js</code>文件来测试执行了。</p>\n<p>###配置Socket.io服务</p>\n<p>我们的应用服务端用来为一个提供投票和显示结果浏览器端提供服务的，为了这个目的，我们需要考虑两端通信的方式。</p>\n<p>这个应用需要实时通信，这确保我们的投票者可以实时查看到所有人的投票信息。为此，我们选择使用WebSockets作为<br>通信方式。因此，我们选择<a href=\"http://socket.io/\">Socket.io</a>库作为跨终端的websocket抽象实现层，它在客户端<br>不支持websocket的情况下提供了多种备选方案。</p>\n<p>让我们在项目中加入Socket.io：</p>\n<pre><code>npm install --save socket.io\n</code></pre><p>现在，让我新建一个<code>server.js</code>文件：</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport default function startServer() {\nconst io = new Server().attach(8090);\n}\n</code></pre><p>这里我们创建了一个Socket.io 服务，绑定8090端口。端口号是我随意选的，你可以更改，但后面客户端连接时<br>要注意匹配。</p>\n<p>现在我们可以在<code>index.js</code>中调用这个函数：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\nimport startServer from &apos;./src/server&apos;;\n\nexport const store = makeStore();\nstartServer();\n</code></pre><p>我们现在可以在<code>package.json</code>中添加<code>start</code>指令来方便启动应用：</p>\n<pre><code>//package.json\n&quot;scripts&quot;: {\n    &quot;start&quot;: &quot;babel-node index.js&quot;,\n    &quot;test&quot;: &quot;mocha --compilers js:babel/register  --require ./test/test_helper.js  --recursive&quot;,\n    &quot;test:watch&quot;: &quot;npm run test --watch&quot;\n},\n</code></pre><p>这样我们就可以直接执行下面命令来开启应用：</p>\n<pre><code>npm run start\n</code></pre><p>###用Redux监听器传播State</p>\n<p>我们现在拥有了一个Socket.io服务，也建立了Redux状态容器，但它们并没有整合在一起，这就是我们接下来要做的事儿。</p>\n<p>我们的服务端需要让客户端知道当前的应用状态（例如：“正在投票的项目是什么？”，“当前的票数是什么？”，<br>“已经出来结果了吗？”）。这些都可以通过每当变化发生时<a href=\"http://socket.io/docs/server-api/#server#emit\">触发Socket.io事件</a>来实现。</p>\n<p>我们如何得知什么时候发生变化？Redux对此提供了方案：你可以订阅Redux Store。这样每当store指派了action之后，在可能发生变化前<br>会调用你提供的指定回调函数。</p>\n<p>我们要修改一下<code>startServer</code>实现，我们先来调整一下index.js：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\nimport {startServer} from &apos;./src/server&apos;;\n\nexport const store = makeStore();\nstartServer(store);\n</code></pre><p>接下来我们只需监听store的状态，并把它序列化后用socket.io事件传播给所有处于连接状态的客户端。</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport function startServer(store) {\n  const io = new Server().attach(8090);\n\n  store.subscribe(\n    () =&gt; io.emit(&apos;state&apos;, store.getState().toJS())\n  );\n}\n</code></pre><p>目前我们的做法是一旦状态有改变，就发送整个state给所有客户端，很容易想到这非常不友好，产生大量流量<br>损耗，更好的做法是只传递改变的state片段，但我们为了简单，在这个例子中就先这么实现吧。</p>\n<p>除了状态发生变化时发送状态数据外，每当新客户端连接服务器端时也应该直接发送当前的状态给该客户端。</p>\n<p>我们可以通过监听Socket.io的<code>connection</code>事件来实现上述需求：</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport function startServer(store) {\n  const io = new Server().attach(8090);\n\n  store.subscribe(\n    () =&gt; io.emit(&apos;state&apos;, store.getState().toJS())\n  );\n\n  io.on(&apos;connection&apos;, (socket) =&gt; {\n    socket.emit(&apos;state&apos;, store.getState().toJS());\n  });\n}\n</code></pre><p>###接受远程调用Redux Actions</p>\n<p>除了将应用状态同步给客户端外，我们还需要接受来自客户端的更新操作：投票者需要发起投票，投票组织者需要<br>发起下一轮投票的请求。</p>\n<p>我们的解决方案非常简单。我们只需要让客户端发布“action”事件即可，然后我们直接将事件发送给Redux Store：</p>\n<pre><code>//src/server.js\n\nimport Server from &apos;socket.io&apos;;\n\nexport function startServer(store) {\n  const io = new Server().attach(8090);\n\n  store.subscribe(\n    () =&gt; io.emit(&apos;state&apos;, store.getState().toJS())\n  );\n\n  io.on(&apos;connection&apos;, (socket) =&gt; {\n    socket.emit(&apos;state&apos;, store.getState().toJS());\n    socket.on(&apos;action&apos;, store.dispatch.bind(store));\n  });\n}\n</code></pre><p>这样我们就完成了远程调用actions。Redux架构让我们的项目更加简单：actions仅仅是js对象，可以很容易用于<br>网络传输，我们现在实现了一个支持多人投票的服务端系统，很有成就感吧。</p>\n<p>现在我们的服务端操作流程如下：</p>\n<ol>\n<li>客户端发送一个action给服务端；</li>\n<li>服务端交给Redux Store处理action；</li>\n<li>Store调用reducer，reducer执行对应的应用逻辑；</li>\n<li>Store根据reducer的返回结果来更新状态；</li>\n<li>Store触发服务端监听的回调函数；</li>\n<li>服务端触发“state”事件；</li>\n<li>所有连接的客户端接受到新的状态。</li>\n</ol>\n<p>在结束服务端开发之前，我们载入一些测试数据来感受一下。我们可以添加<code>entries.json</code>文件：</p>\n<pre><code>//entries.json\n\n[\n  &quot;Shallow Grave&quot;,\n  &quot;Trainspotting&quot;,\n  &quot;A Life Less Ordinary&quot;,\n  &quot;The Beach&quot;,\n  &quot;28 Days Later&quot;,\n  &quot;Millions&quot;,\n  &quot;Sunshine&quot;,\n  &quot;Slumdog Millionaire&quot;,\n  &quot;127 Hours&quot;,\n  &quot;Trance&quot;,\n  &quot;Steve Jobs&quot;\n]\n</code></pre><p>我们在<code>index.json</code>中加载它然后发起<code>next</code>action来开启投票：</p>\n<pre><code>//index.js\n\nimport makeStore from &apos;./src/store&apos;;\nimport {startServer} from &apos;./src/server&apos;;\n\nexport const store = makeStore();\nstartServer(store);\n\nstore.dispatch({\n  type: &apos;SET_ENTRIES&apos;,\n  entries: require(&apos;./entries.json&apos;)\n});\nstore.dispatch({type: &apos;NEXT&apos;});\n</code></pre><p>那么接下来我们就来看看如何实现客户端。</p>\n<p>##客户端应用</p>\n<p>本教程剩余的部分就是写一个React应用，用来连接服务端，并提供投票给使用者。</p>\n<p>在客户端我们依然使用Redux。这是更常见的搭配：用于React应用的底层引擎。我们已经了解到Redux如何使用。<br>现在我们将学习它是如何结合并影响React应用的。</p>\n<p>我推荐大家跟随本教程的步骤完成应用，但你也可以从<a href=\"https://github.com/teropa/redux-voting-client\">github</a>上获取源码。</p>\n<p>###客户端项目创建</p>\n<p>第一件事儿我们当然是创建一个新的NPM项目，如下：</p>\n<pre><code>mkdir voting-client\ncd voting-client\nnpm init            # Just hit enter for each question\n</code></pre><p>我们的应用需要一个html主页，我们放在<code>dist/index.html</code>：</p>\n<pre><code>//dist/index.html\n\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n  &lt;div id=&quot;app&quot;&gt;&lt;/div&gt;\n  &lt;script src=&quot;bundle.js&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>这个页面包含一个id为app的<code>&lt;div&gt;</code>，我们将在其中插入我们的应用。在同级目录下还需要一个<code>bundle.js</code>文件。</p>\n<p>我们为应用新建第一个js文件，它是系统的入口文件。目前我们先简单的添加一行日志代码：</p>\n<pre><code>//src/index.js\nconsole.log(&apos;I am alive!&apos;);\n</code></pre><p>为了给我们客户端开发减负，我们将使用<a href=\"http://webpack.github.io/\">Webpack</a>，让我们加入到项目中：</p>\n<pre><code>npm install --save-dev webpack webpack-dev-server\n</code></pre><p>接下来，我们在项目根目录新建一个Webpack配置文件：</p>\n<pre><code>//webpack.config.js\n\nmodule.exports = {\n  entry: [\n    &apos;./src/index.js&apos;\n  ],\n  output: {\n    path: __dirname + &apos;/dist&apos;,\n    publicPath: &apos;/&apos;,\n    filename: &apos;bundle.js&apos;\n  },\n  devServer: {\n    contentBase: &apos;./dist&apos;\n  }\n};\n</code></pre><p>配置表明将找到我们的<code>index.js</code>入口，并编译到<code>dist/bundle.js</code>中。同时把<code>dist</code>目录当作开发服务器根目录。</p>\n<p>你现在可以执行Webpack来生成<code>bundle.js</code>：</p>\n<pre><code>webpack\n</code></pre><p>你也可以开启一个开发服务器，访问localhost:8080来测试页面效果：</p>\n<pre><code>webpack-dev-server\n</code></pre><p>由于我们将使用ES6语法和React的<a href=\"https://facebook.github.io/jsx/\">JSX语法</a>，我们需要一些工具。<br>Babel是一个非常合适的选择，我们需要Babel库：</p>\n<pre><code>npm install --save-dev babel-core babel-loader\n</code></pre><p>我们可以在Webpack配置文件中添加一些配置，这样webpack将会对<code>.jsx</code>和<code>.js</code>文件使用Babel进行处理：</p>\n<pre><code>//webpack.config.js\n\nmodule.exports = {\n    entry: [\n        &apos;./src/index.js&apos;\n    ],\n    module: {\n        loaders: [{\n            test: /\\.jsx?$/,\n            exclude: /node_modules/,\n            loader: &apos;babel&apos;\n        }]\n    },\n    resolve: {\n        extensions: [&apos;&apos;, &apos;.js&apos;, &apos;.jsx&apos;]\n    },\n    output: {\n        path: __dirname + &apos;/dist&apos;,\n        publicPath: &apos;/&apos;,\n        filename: &apos;bundle.js&apos;\n    },\n    devServer: {\n        contentBase: &apos;./dist&apos;\n    }\n};\n</code></pre><p>###单元测试支持</p>\n<p>我们也将会为客户端代码编写一些单元测试。我们使用与服务端相同的测试套件：</p>\n<pre><code>npm install --save-dev mocha chai\n</code></pre><p>我们也将会测试我们的React组件，这就要求需要一个DOM库。我们可能需要像<a href=\"http://karma-runner.github.io/0.13/index.html\">Karma</a><br>库一样的功能来进行真实web浏览器测试。但我们这里准备使用一个node端纯js的dom库：</p>\n<pre><code>npm install --save-dev jsdom@3\n</code></pre><p>在用于react之前我们需要一些jsdom的预备代码。我们需要创建通常在浏览器端被提供的<code>document</code>和<code>window</code>对象。<br>并且将它们声明为全局对象，这样才能被React使用。我们可以创建一个测试辅助文件做这些工作：</p>\n<pre><code>//test/test_helper.js\n\nimport jsdom from &apos;jsdom&apos;;\n\nconst doc = jsdom.jsdom(&apos;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&apos;);\nconst win = doc.defaultView;\n\nglobal.document = doc;\nglobal.window = win;\n</code></pre><p>此外，我们还需要将jsdom提供的<code>window</code>对象的所有属性导入到Node.js的全局变量中，这样使用这些属性时<br>就不需要<code>window.</code>前缀，这才满足在浏览器环境下的用法：</p>\n<pre><code>//test/test_helper.js\n\nimport jsdom from &apos;jsdom&apos;;\n\nconst doc = jsdom.jsdom(&apos;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&apos;);\nconst win = doc.defaultView;\n\nglobal.document = doc;\nglobal.window = win;\n\nObject.keys(window).forEach((key) =&gt; {\n  if (!(key in global)) {\n    global[key] = window[key];\n  }\n});\n</code></pre><p>我们还需要使用Immutable集合，所以我们也需要参照后段配置添加相应的库：</p>\n<pre><code>npm install --save immutable\nnpm install --save-dev chai-immutable\n</code></pre><p>现在我们再次修改辅助文件：</p>\n<pre><code>//test/test_helper.js\n\nimport jsdom from &apos;jsdom&apos;;\nimport chai from &apos;chai&apos;;\nimport chaiImmutable from &apos;chai-immutable&apos;;\n\nconst doc = jsdom.jsdom(&apos;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&apos;);\nconst win = doc.defaultView;\n\nglobal.document = doc;\nglobal.window = win;\n\nObject.keys(window).forEach((key) =&gt; {\n  if (!(key in global)) {\n    global[key] = window[key];\n  }\n});\n\nchai.use(chaiImmutable);\n</code></pre><p>最后一步是在<code>package.json</code>中添加指令：</p>\n<pre><code>//package.json\n\n&quot;scripts&quot;: {\n  &quot;test&quot;: &quot;mocha --compilers js:babel-core/register --require ./test/test_helper.js &apos;test/**/*.@(js|jsx)&apos;&quot;\n},\n</code></pre><p>这几乎和我们在后端做的一样，只有两个地方不同：</p>\n<ul>\n<li>Babel的编译器名称：在该项目中我们使用<code>babel-core</code>代替<code>babel</code></li>\n<li>测试文件设置：服务端我们使用<code>--recursive</code>，但这么设置无法匹配<code>.jsx</code>文件，所以我们需要使用<br><a href=\"https://github.com/isaacs/node-glob\">glob</a></li>\n</ul>\n<p>为了实现当代码发生修改后自动进行测试，我们依然添加<code>test:watch</code>指令：</p>\n<pre><code>//package.json\n\n&quot;scripts&quot;: {\n  &quot;test&quot;: &quot;mocha --compilers js:babel-core/register --require ./test/test_helper.js &apos;test/**/*.@(js|jsx)&apos;&quot;,\n  &quot;test:watch&quot;: &quot;npm run test -- --watch&quot;\n},\n</code></pre><p>###React和react-hot-loader</p>\n<p>最后我们来聊聊React！</p>\n<p>使用React+Redux+Immutable来开发应用真正酷毙的地方在于：我们可以用纯组件（有时候也称为蠢组件）思想实现<br>任何东西。这个概念与纯函数很类似，有如下一些规则：</p>\n<ol>\n<li>一个纯组件利用props接受所有它需要的数据，类似一个函数的入参，除此之外它不会被任何其它因素影响；</li>\n<li>一个纯组件通常没有内部状态。它用来渲染的数据完全来自于输入props，使用相同的props来渲染相同的纯组件多次，<br>将得到相同的UI。不存在隐藏的内部状态导致渲染不同。</li>\n</ol>\n<p>这就带来了<a href=\"https://www.youtube.com/watch?v=1uRC3hmKQnM&amp;feature=youtu.be&amp;t=13m10s\">一个和使用纯函数一样的效果</a>：<br>我们可以根据输入来预测一个组件的渲染，我们不需要知道组件的其它信息。这也使得我们的界面测试变得很简单，<br>与我们测试纯应用逻辑一样简单。</p>\n<p>如果组件不包含状态，那么状态放在哪？当然在不可变的Store中啊！我们已经见识过它是怎么运作的了，其<br>最大的特点就是从界面代码中分离出状态。</p>\n<p>在此之前，我们还是先给项目添加React：</p>\n<pre><code>npm install --save react\n</code></pre><p>我们同样需要<a href=\"https://github.com/gaearon/react-hot-loader\">react-hot-loader</a>。它让我们的开发<br>变得非常快，因为它提供了我们在不丢失当前状态的情况下重载代码的能力：</p>\n<pre><code>npm install --save-dev react-hot-loader\n</code></pre><p>我们需要更新一下<code>webpack.config.js</code>，使其能热加载：</p>\n<pre><code>//webpack.config.js\n\nvar webpack = require(&apos;webpack&apos;);\n\nmodule.exports = {\n  entry: [\n    &apos;webpack-dev-server/client?http://localhost:8080&apos;,\n    &apos;webpack/hot/only-dev-server&apos;,\n    &apos;./src/index.js&apos;\n  ],\n  module: {\n    loaders: [{\n      test: /\\.jsx?$/,\n      exclude: /node_modules/,\n      loader: &apos;react-hot!babel&apos;\n    }],\n  }\n  resolve: {\n    extensions: [&apos;&apos;, &apos;.js&apos;, &apos;.jsx&apos;]\n  },\n  output: {\n    path: __dirname + &apos;/dist&apos;,\n    publicPath: &apos;/&apos;,\n    filename: &apos;bundle.js&apos;\n  },\n  devServer: {\n    contentBase: &apos;./dist&apos;,\n    hot: true\n  },\n  plugins: [\n    new webpack.HotModuleReplacementPlugin()\n  ]\n};\n</code></pre><p>在上述配置的<code>entry</code>里我们包含了2个新的应用入口点：webpack dev server和webpack hot module loader。<br>它们提供了webpack模块热替换能力。该能力并不是默认加载的，所以上面我们才需要在<code>plugins</code>和<code>devServer</code><br>中手动加载。</p>\n<p>配置的<code>loaders</code>部分我们在原先的Babel前配置了<code>react-hot</code>用于<code>.js</code>和<code>.jsx</code>文件。</p>\n<p>如果你现在重启开发服务器，你将看到一个在终端看到Hot Module Replacement已开启的消息提醒。我们可以<br>开始写我们的第一个组件了。</p>\n<p>###实现投票界面</p>\n<p>应用的投票界面非常简单：一旦投票启动，它将现实2个按钮，分别用来表示2个可选项，当投票结束，它显示最终结果。</p>\n<p><img src=\"http://teropa.info/images/voting_shots.png\" alt=\"\"></p>\n<p>我们之前都是以测试先行的开发方式，但是在react组件开发中我们将先实现组件，再进行测试。这是因为<br>webpack和react-hot-loader提供了更加优良的<a href=\"http://blog.iterate.no/2012/10/01/know-your-feedback-loop-why-and-how-to-optimize-it/\">反馈机制</a>。<br>而且，也没有比直接看到界面更加好的测试UI手段了。</p>\n<p>让我们假设有一个<code>Voting</code>组件，在之前的入口文件<code>index.html</code>的<code>#app</code>div中加载它。由于我们的代码中<br>包含JSX语法，所以需要把<code>index.js</code>重命名为<code>index.jsx</code>：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nReact.render(\n  &lt;Voting pair={pair} /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p><code>Voting</code>组件将使用<code>pair</code>属性来加载数据。我们目前可以先硬编码数据，稍后我们将会用真实数据来代替。<br>组件本身是纯粹的，并且对数据来源并不敏感。</p>\n<p>注意，在<code>webpack.config.js</code>中的入口点文件名也要修改：</p>\n<pre><code>//webpack.config.js\n\nentry: [\n  &apos;webpack-dev-server/client?http://localhost:8080&apos;,\n  &apos;webpack/hot/only-dev-server&apos;,\n  &apos;./src/index.jsx&apos;\n],\n</code></pre><p>如果你此时重启webpack-dev-server，你将看到缺失Voting组件的报错。让我们修复它：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>你将会在浏览器上看到组件创建的2个按钮。你可以试试修改代码感受一下浏览器自动更新的魅力，没有刷新，<br>没有页面加载，一切都那么迅雷不及掩耳盗铃。</p>\n<p>现在我们来添加第一个单元测试：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport Voting from &apos;../../src/components/Voting&apos;;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n});\n</code></pre><p>测试组件渲染的按钮，我们必须先看看它的输出是什么。要在单元测试中渲染一个组件，我们需要<code>react/addons</code>提供<br>的辅助函数<a href=\"https://facebook.github.io/react/docs/test-utils.html#renderintodocument\">renderIntoDocument</a>：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\n\nconst {renderIntoDocument} = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  it(&apos;renders a pair of buttons&apos;, () =&gt; {\n    const component = renderIntoDocument(\n      &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]} /&gt;\n    );\n  });\n});\n</code></pre><p>一旦组件渲染完毕，我就可以通过react提供的另一个辅助函数<a href=\"https://facebook.github.io/react/docs/test-utils.html#scryrendereddomcomponentswithtag\">scryRenderedDOMComponentsWithTag</a><br>来拿到<code>button</code>元素。我们期望存在两个按钮，并且期望按钮的值是我们设置的：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithTag}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  it(&apos;renders a pair of buttons&apos;, () =&gt; {\n    const component = renderIntoDocument(\n      &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]} /&gt;\n    );\n    const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n\n    expect(buttons.length).to.equal(2);\n    expect(buttons[0].getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n    expect(buttons[1].getDOMNode().textContent).to.equal(&apos;28 Days Later&apos;);\n  });\n});\n</code></pre><p>如果我们跑一下测试，将会看到测试通过的提示：</p>\n<pre><code>npm run test\n</code></pre><p>当用户点击某个按钮后，组件将会调用回调函数，该函数也由组件的prop传递给组件。</p>\n<p>让我们完成这一步，我们可以通过使用React提供的测试工具<a href=\"https://facebook.github.io/react/docs/test-utils.html#simulate\">Simulate</a><br>来模拟点击操作：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;invokes callback when a button is clicked&apos;, () =&gt; {\n    let votedWith;\n    const vote = (entry) =&gt; votedWith = entry;\n\n    const component = renderIntoDocument(\n      &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n              vote={vote}/&gt;\n    );\n    const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n    Simulate.click(buttons[0].getDOMNode());\n\n    expect(votedWith).to.equal(&apos;Trainspotting&apos;);\n  });\n});\n</code></pre><p>要想使上面的测试通过很简单，我们只需要让按钮的<code>onClick</code>事件调用<code>vote</code>并传递选中条目即可：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>这就是我们在纯组件中常用的方式：组件不需要做太多，只是回调传入的参数即可。</p>\n<p>注意，这里我们又是先写的测试代码，我发现业务代码的测试要比测试UI更容易写，所以后面我们会保持这种<br>方式：UI测试后行，业务代码测试先行。</p>\n<p>一旦用户已经针对某对选项投过票了，我们就不应该允许他们再次投票，难道我们应该在组件内部维护某种状态么？<br>不，我们需要保证我们的组件是纯粹的，所以我们需要分离这个逻辑，组件需要一个<code>hasVoted</code>属性，我们先硬编码<br>传递给它：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nReact.render(\n  &lt;Voting pair={pair} hasVoted=&quot;Trainspotting&quot; /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p>我们可以简单的修改一下组件即可：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                disabled={this.isDisabled()}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>让我们再为按钮添加一个提示，当用户投票完毕后，在选中的项目上添加标识，这样用户就更容易理解：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  hasVotedFor: function(entry) {\n    return this.props.hasVoted === entry;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                disabled={this.isDisabled()}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n          {this.hasVotedFor(entry) ?\n            &lt;div className=&quot;label&quot;&gt;Voted&lt;/div&gt; :\n            null}\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>投票界面最后要添加的，就是获胜者样式。我们可能需要添加新的props：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nReact.render(\n  &lt;Voting pair={pair} winner=&quot;Trainspotting&quot; /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p>我们再次修改一下组件：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  hasVotedFor: function(entry) {\n    return this.props.hasVoted === entry;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.props.winner ?\n        &lt;div ref=&quot;winner&quot;&gt;Winner is {this.props.winner}!&lt;/div&gt; :\n        this.getPair().map(entry =&gt;\n          &lt;button key={entry}\n                  disabled={this.isDisabled()}\n                  onClick={() =&gt; this.props.vote(entry)}&gt;\n            &lt;h1&gt;{entry}&lt;/h1&gt;\n            {this.hasVotedFor(entry) ?\n              &lt;div className=&quot;label&quot;&gt;Voted&lt;/div&gt; :\n              null}\n          &lt;/button&gt;\n        )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>目前我们已经完成了所有要做的，但是<code>render</code>函数看着有点丑陋，如果我们可以把胜利界面独立成新的组件<br>可能会好一些：</p>\n<pre><code>//src/components/Winner.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  render: function() {\n    return &lt;div className=&quot;winner&quot;&gt;\n      Winner is {this.props.winner}!\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>这样投票组件就会变得很简单，它只需关注投票按钮逻辑即可：</p>\n<pre><code>//src/components/Vote.jsx\n\nimport React from &apos;react&apos;;\n\nexport default React.createClass({\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  isDisabled: function() {\n    return !!this.props.hasVoted;\n  },\n  hasVotedFor: function(entry) {\n    return this.props.hasVoted === entry;\n  },\n  render: function() {\n    return &lt;div className=&quot;voting&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;button key={entry}\n                disabled={this.isDisabled()}\n                onClick={() =&gt; this.props.vote(entry)}&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n          {this.hasVotedFor(entry) ?\n            &lt;div className=&quot;label&quot;&gt;Voted&lt;/div&gt; :\n            null}\n        &lt;/button&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>最后我们只需要在<code>Voting</code>组件做一下判断即可：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nexport default React.createClass({\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>注意这里我们为胜利组件添加了<a href=\"https://facebook.github.io/react/docs/more-about-refs.html\">ref</a>，这是因为我们将在单元测试中利用它获取DOM节点。</p>\n<p>这就是我们的纯组件！注意目前我们还没有实现任何逻辑：我们并没有定义按钮的点击操作。组件只是用来渲染UI，其它<br>什么都不需要做。后面当我们将UI与Redux Store结合时才会涉及到应用逻辑。</p>\n<p>继续下一步之前我们要为刚才新增的特性写更多的单元测试代码。首先，<code>hasVoted</code>属性将会使按钮改变状态：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;disables buttons when user has voted&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n            hasVoted=&quot;Trainspotting&quot; /&gt;\n  );\n  const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n\n  expect(buttons.length).to.equal(2);\n  expect(buttons[0].getDOMNode().hasAttribute(&apos;disabled&apos;)).to.equal(true);\n  expect(buttons[1].getDOMNode().hasAttribute(&apos;disabled&apos;)).to.equal(true);\n});\n</code></pre><p>被<code>hasVoted</code>匹配的按钮将显示<code>Voted</code>标签：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;adds label to the voted entry&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Voting pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n            hasVoted=&quot;Trainspotting&quot; /&gt;\n  );\n  const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n\n  expect(buttons[0].getDOMNode().textContent).to.contain(&apos;Voted&apos;);\n});\n</code></pre><p>当获胜者产生，界面将不存在按钮，取而代替的是胜利者元素：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;renders just the winner when there is one&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Voting winner=&quot;Trainspotting&quot; /&gt;\n  );\n  const buttons = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;);\n  expect(buttons.length).to.equal(0);\n\n  const winner = React.findDOMNode(component.refs.winner);\n  expect(winner).to.be.ok;\n  expect(winner.textContent).to.contain(&apos;Trainspotting&apos;);\n});\n</code></pre><p>###不可变数据和纯粹渲染</p>\n<p>我们之前已经讨论了许多关于不可变数据的红利，但是，当它和react结合时还会有一个非常屌的好处：<br>如果我们创建纯react组件并传递给它不可变数据作为属性参数，我们将会让react在组件渲染检测中得到最大性能。</p>\n<p>这是靠react提供的<a href=\"https://facebook.github.io/react/docs/pure-render-mixin.html\">PureRenderMixin</a>实现的。<br>当该mixin添加到组件中后，组件的更新检查逻辑将会被改变，由深比对改为高性能的浅比对。</p>\n<p>我们之所以可以使用浅比对，就是因为我们使用的是不可变数据。如果一个组件的所有参数都是不可变数据，<br>那么将大大提高应用性能。</p>\n<p>我们可以在单元测试里更清楚的看见差别，如果我们向纯组件中传入可变数组，当数组内部元素产生改变后，组件并不会<br>重新渲染：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nit(&apos;renders as a pure component&apos;, () =&gt; {\n  const pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n  const component = renderIntoDocument(\n    &lt;Voting pair={pair} /&gt;\n  );\n\n  let firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n  expect(firstButton.getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n\n  pair[0] = &apos;Sunshine&apos;;\n  component.setProps({pair: pair});\n  firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n  expect(firstButton.getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n});\n</code></pre><p>如果我们使用不可变数据，则完全没有问题：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List} from &apos;immutable&apos;;\nimport Voting from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithTag, Simulate}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Voting&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;does update DOM when prop changes&apos;, () =&gt; {\n    const pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n    const component = renderIntoDocument(\n      &lt;Voting pair={pair} /&gt;\n    );\n\n    let firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n    expect(firstButton.getDOMNode().textContent).to.equal(&apos;Trainspotting&apos;);\n\n    const newPair = pair.set(0, &apos;Sunshine&apos;);\n    component.setProps({pair: newPair});\n    firstButton = scryRenderedDOMComponentsWithTag(component, &apos;button&apos;)[0];\n    expect(firstButton.getDOMNode().textContent).to.equal(&apos;Sunshine&apos;);\n  });\n});\n</code></pre><p>如果你跑上面的两个测试，你将会看到非预期的结果：因为实际上UI在两种场景下都更新了。那是因为现在组件<br>依然使用的是深比对，这正是我们使用不可变数据想极力避免的。</p>\n<p>下面我们在组件中引入mixin，你就会拿到期望的结果了：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  // ...\n});\n\n\n\n//src/components/Vote.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  // ...\n});\n\n\n\n//src/components/Winner.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  // ...\n});\n</code></pre><p>###投票结果页面和路由实现</p>\n<p>投票页面已经搞定了，让我们开始实现投票结果页面吧。</p>\n<p>投票结果页面依然会显示两个条目，并且显示它们各自的票数。此外屏幕下方还会有一个按钮，供用户切换到下一轮投票。</p>\n<p>现在我们根据什么来确定显示哪个界面呢？使用URL是个不错的主意：我们可以设置根路径<code>#/</code>去显示投票页面，<br>使用<code>#/results</code>来显示投票结果页面。</p>\n<p>我们使用<a href=\"http://rackt.github.io/react-router/\">react-router</a>可以很容易实现这个需求。让我们加入项目：</p>\n<pre><code>npm install --save react-router\n</code></pre><p>我们这里使用的react-router的0.13版本，它的1.0版本官方还没有发布，如果你打算使用其1.0RC版，那么下面的代码<br>你可能需要做一些修改，可以看<a href=\"https://github.com/rackt/react-router\">router文档</a>。</p>\n<p>我们现在可以来配置一下路由路径，Router提供了一个<code>Route</code>组件用来让我们定义路由信息，同时也提供了<code>DefaultRoute</code><br>组件来让我们定义默认路由：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport {Route, DefaultRoute} from &apos;react-router&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst pair = [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;];\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nReact.render(\n  &lt;Voting pair={pair} /&gt;,\n  document.getElementById(&apos;app&apos;)\n);\n</code></pre><p>我们定义了一个默认的路由指向我们的<code>Voting</code>组件。我们需要定义个<code>App</code>组件来用于Route使用。</p>\n<p>根路由的作用就是为应用指定一个根组件：通常该组件充当所有子页面的模板。让我们来看看<code>App</code>的细节：</p>\n<pre><code>//src/components/App.jsx\n\nimport React from &apos;react&apos;;\nimport {RouteHandler} from &apos;react-router&apos;;\nimport {List} from &apos;immutable&apos;;\n\nconst pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n\nexport default React.createClass({\n  render: function() {\n    return &lt;RouteHandler pair={pair} /&gt;\n  }\n});\n</code></pre><p>这个组件除了渲染了一个<code>RouteHandler</code>组件并没有做别的，这个组件同样是react-router提供的，它的作用就是<br>每当路由匹配了某个定义的页面后将对应的页面组件插入到这个位置。目前我们只定义了一个默认路由指向<code>Voting</code>，<br>所以目前我们的组件总是会显示<code>Voting</code>界面。</p>\n<p>注意，我们将我们硬编码的投票数据从<code>index.jsx</code>移到了<code>App.jsx</code>，当你给<code>RouteHandler</code>传递了属性值时，<br>这些参数将会传给当前路由对应的组件。</p>\n<p>现在我们可以更新<code>index.jsx</code>：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Root /&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p><code>run</code>方法会根据当前浏览器的路径去查找定义的router来决定渲染哪个组件。一旦确定了对应的组件，它将会被<br>当作指定的<code>Root</code>传给<code>run</code>的回调函数，在回调中我们将使用<code>React.render</code>将其插入DOM中。</p>\n<p>目前为止我们已经基于React router实现了之前的内容，我们现在可以很容易添加更多新的路由到应用。让我们<br>把投票结果页面添加进去吧：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Root /&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>这里我们用使用<code>&lt;Route&gt;</code>组件定义了一个名为<code>/results</code>的路径，并绑定<code>Results</code>组件。</p>\n<p>让我们简单的实现一下这个<code>Results</code>组件，这样我们就可以看一下路由是如何工作的了：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;Hello from results!&lt;/div&gt;\n  }\n});\n</code></pre><p>如果你在浏览器中输入<a href=\"http://localhost:8080/#/results\">http://localhost:8080/#/results</a>，你将会看到该结果组件。<br>而其它路径都对应这投票页面，你也可以使用浏览器的前后按钮来切换这两个界面。</p>\n<p>接下来我们来实际实现一下结果组件：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  render: function() {\n    return &lt;div className=&quot;results&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;div key={entry} className=&quot;entry&quot;&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n        &lt;/div&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>结果界面除了显示投票项外，还应该显示它们对应的得票数，让我们先硬编码一下：</p>\n<pre><code>//src/components/App.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {RouteHandler} from &apos;react-router&apos;;\nimport {List, Map} from &apos;immutable&apos;;\n\nconst pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\nconst tally = Map({&apos;Trainspotting&apos;: 5, &apos;28 Days Later&apos;: 4});\n\nexport default React.createClass({\n  render: function() {\n    return &lt;RouteHandler pair={pair}\n                         tally={tally} /&gt;\n  }\n});\n</code></pre><p>现在，我们再来修改一下结果组件：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return &lt;div className=&quot;results&quot;&gt;\n      {this.getPair().map(entry =&gt;\n        &lt;div key={entry} className=&quot;entry&quot;&gt;\n          &lt;h1&gt;{entry}&lt;/h1&gt;\n          &lt;div className=&quot;voteCount&quot;&gt;\n            {this.getVotes(entry)}\n          &lt;/div&gt;\n        &lt;/div&gt;\n      )}\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>现在我们来针对目前的界面功能编写测试代码，以防止未来我们破坏这些功能。</p>\n<p>我们期望组件为每个选项都渲染一个div，并在其中显示选项的名称和票数。如果对应的选项没有票数，则默认显示0：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List, Map} from &apos;immutable&apos;;\nimport Results from &apos;../../src/components/Results&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithClass}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Results&apos;, () =&gt; {\n\n  it(&apos;renders entries with vote counts or zero&apos;, () =&gt; {\n    const pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n    const tally = Map({&apos;Trainspotting&apos;: 5});\n    const component = renderIntoDocument(\n      &lt;Results pair={pair} tally={tally} /&gt;\n    );\n    const entries = scryRenderedDOMComponentsWithClass(component, &apos;entry&apos;);\n    const [train, days] = entries.map(e =&gt; e.getDOMNode().textContent);\n\n    expect(entries.length).to.equal(2);\n    expect(train).to.contain(&apos;Trainspotting&apos;);\n    expect(train).to.contain(&apos;5&apos;);\n    expect(days).to.contain(&apos;28 Days Later&apos;);\n    expect(days).to.contain(&apos;0&apos;);\n  });\n});\n</code></pre><p>接下来，我们看一下”Next”按钮，它允许用户切换到下一轮投票。</p>\n<p>我们的组件应该包含一个回调函数属性参数，当组件中的”Next”按钮被点击后，该回调函数将会被调用。我们来写一下<br>这个操作的测试代码：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List, Map} from &apos;immutable&apos;;\nimport Results from &apos;../../src/components/Results&apos;;\nimport {expect} from &apos;chai&apos;;\n\nconst {renderIntoDocument, scryRenderedDOMComponentsWithClass, Simulate}\n  = React.addons.TestUtils;\n\ndescribe(&apos;Results&apos;, () =&gt; {\n\n  // ...\n\n  it(&apos;invokes the next callback when next button is clicked&apos;, () =&gt; {\n    let nextInvoked = false;\n    const next = () =&gt; nextInvoked = true;\n\n    const pair = List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;);\n    const component = renderIntoDocument(\n      &lt;Results pair={pair}\n               tally={Map()}\n               next={next}/&gt;\n    );\n    Simulate.click(React.findDOMNode(component.refs.next));\n\n    expect(nextInvoked).to.equal(true);\n  });\n});\n</code></pre><p>写法和之前的投票按钮很类似吧。接下来让我们更新一下结果组件：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return &lt;div className=&quot;results&quot;&gt;\n      &lt;div className=&quot;tally&quot;&gt;\n        {this.getPair().map(entry =&gt;\n          &lt;div key={entry} className=&quot;entry&quot;&gt;\n            &lt;h1&gt;{entry}&lt;/h1&gt;\n            &lt;div class=&quot;voteCount&quot;&gt;\n              {this.getVotes(entry)}\n            &lt;/div&gt;\n          &lt;/div&gt;\n        )}\n      &lt;/div&gt;\n      &lt;div className=&quot;management&quot;&gt;\n        &lt;button ref=&quot;next&quot;\n                className=&quot;next&quot;\n                onClick={this.props.next}&gt;\n          Next\n        &lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;;\n  }\n});\n</code></pre><p>最终投票结束，结果页面和投票页面一样，都要显示胜利者：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nit(&apos;renders the winner when there is one&apos;, () =&gt; {\n  const component = renderIntoDocument(\n    &lt;Results winner=&quot;Trainspotting&quot;\n             pair={[&quot;Trainspotting&quot;, &quot;28 Days Later&quot;]}\n             tally={Map()} /&gt;\n  );\n  const winner = React.findDOMNode(component.refs.winner);\n  expect(winner).to.be.ok;\n  expect(winner.textContent).to.contain(&apos;Trainspotting&apos;);\n});\n</code></pre><p>我们可以想在投票界面中那样简单的实现一下上面的逻辑：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\nimport Winner from &apos;./Winner&apos;;\n\nexport default React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return this.props.winner ?\n      &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n      &lt;div className=&quot;results&quot;&gt;\n        &lt;div className=&quot;tally&quot;&gt;\n          {this.getPair().map(entry =&gt;\n            &lt;div key={entry} className=&quot;entry&quot;&gt;\n              &lt;h1&gt;{entry}&lt;/h1&gt;\n              &lt;div className=&quot;voteCount&quot;&gt;\n                {this.getVotes(entry)}\n              &lt;/div&gt;\n            &lt;/div&gt;\n          )}\n        &lt;/div&gt;\n        &lt;div className=&quot;management&quot;&gt;\n          &lt;button ref=&quot;next&quot;\n                   className=&quot;next&quot;\n                   onClick={this.props.next}&gt;\n            Next\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;;\n  }\n});\n</code></pre><p>到目前为止，我们已经实现了应用的UI，虽然现在它们并没有和真实数据和操作整合起来。这很不错不是么？<br>我们只需要一些占位符数据就可以完成界面的开发，这让我们在这个阶段更专注于UI。</p>\n<p>接下来我们将会使用Redux Store来将真实数据整合到我们的界面中。</p>\n<p>###初识客户端的Redux Store</p>\n<p>Redux将会充当我们UI界面的状态容器，我们已经在服务端用过Redux，之前说的很多内容在这里也受用。<br>现在我们已经准备好要在React应用中使用Redux了，这也是Redux更常见的使用场景。</p>\n<p>和在服务端一样，我们先来思考一下应用的状态。客户端的状态和服务端会非常的类似。</p>\n<p>我们有两个界面，并在其中需要显示成对的用于投票的条目：</p>\n<p><img src=\"http://teropa.info/images/vote_client_pair.png\" alt=\"\"></p>\n<p>此外，结果页面需要显示票数：</p>\n<p><img src=\"http://teropa.info/images/vote_client_tally.png\" alt=\"\"></p>\n<p>投票组件还需要记录当前用户已经投票过的选项：</p>\n<p><img src=\"http://teropa.info/images/vote_client_hasvoted.png\" alt=\"\"></p>\n<p>结果组件还需要记录胜利者：</p>\n<p><img src=\"http://teropa.info/images/vote_server_tree_winner.png\" alt=\"\"></p>\n<p>注意这里除了<code>hasVoted</code>外，其它都映射着服务端状态的子集。</p>\n<p>接下来我们来思考一下应用的核心逻辑，actions和reducers应该是什么样的。</p>\n<p>我们先来想想能够导致应用状态改变的操作都有那些？状态改变的来源之一是用户行为。我们的UI中存在两种<br>可能的用户操作行为：</p>\n<ul>\n<li>用户在投票页面点击某个投票按钮；</li>\n<li>用户点击下一步按钮。</li>\n</ul>\n<p>另外，我们知道我们的服务端会将应用当前状态发送给客户端，我们将编写代码来接受状态数据，这也是导致状态<br>改变的来源之一。</p>\n<p>我们可以从服务端状态更新开始，之前我们在服务端设置发送了一个<code>state</code>事件。该事件将携带我们之前设计的客户端<br>状态树的状态数据。我们的客户端reducer将通过一个action来将服务器端的状态数据合并到客户端状态树中，<br>这个action如下：</p>\n<pre><code>{\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {...}\n  }\n}\n</code></pre><p>让我们先写一下reducer测试代码，它应该接受上面定义的那种action，并合并数据到客户端的当前状态中：</p>\n<pre><code>//test/reducer_spec.js\n\nimport {List, Map, fromJS} from &apos;immutable&apos;;\nimport {expect} from &apos;chai&apos;;\n\nimport reducer from &apos;../src/reducer&apos;;\n\ndescribe(&apos;reducer&apos;, () =&gt; {\n\n  it(&apos;handles SET_STATE&apos;, () =&gt; {\n    const initialState = Map();\n    const action = {\n      type: &apos;SET_STATE&apos;,\n      state: Map({\n        vote: Map({\n          pair: List.of(&apos;Trainspotting&apos;, &apos;28 Days Later&apos;),\n          tally: Map({Trainspotting: 1})\n        })\n      })\n    };\n    const nextState = reducer(initialState, action);\n\n    expect(nextState).to.equal(fromJS({\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      }\n    }));\n  });\n});\n</code></pre><p>这个renducers接受一个来自socket发送的原始的js数据结构，这里注意不是不可变数据类型哦。我们需要在返回前将其<br>转换成不可变数据类型：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;handles SET_STATE with plain JS payload&apos;, () =&gt; {\n  const initialState = Map();\n  const action = {\n    type: &apos;SET_STATE&apos;,\n    state: {\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      }\n    }\n  };\n  const nextState = reducer(initialState, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  }));\n});\n</code></pre><p>reducer同样应该可以正确的处理<code>undefined</code>初始化状态：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;handles SET_STATE without initial state&apos;, () =&gt; {\n  const action = {\n    type: &apos;SET_STATE&apos;,\n    state: {\n      vote: {\n        pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n        tally: {Trainspotting: 1}\n      }\n    }\n  };\n  const nextState = reducer(undefined, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  }));\n});\n</code></pre><p>现在我们来看一下如何实现满足上面测试条件的reducer：</p>\n<pre><code>//src/reducer.js\n\nimport {Map} from &apos;immutable&apos;;\n\nexport default function(state = Map(), action) {\n\n  return state;\n}\n</code></pre><p>reducer需要处理<code>SET_STATE</code>动作。在这个动作的处理中，我们应该将传入的状态数据和现有的进行合并，<br>使用Map提供的<a href=\"https://facebook.github.io/immutable-js/docs/#/Map/merge\">merge</a>将很容易来实现这个操作：</p>\n<pre><code>//src/reducer.js\n\nimport {Map} from &apos;immutable&apos;;\n\nfunction setState(state, newState) {\n  return state.merge(newState);\n}\n\nexport default function(state = Map(), action) {\n  switch (action.type) {\n  case &apos;SET_STATE&apos;:\n    return setState(state, action.state);\n  }\n  return state;\n}\n</code></pre><p>注意这里我们并没有单独写一个核心模块，而是直接在reducer中添加了个简单的<code>setState</code>函数来做业务逻辑。<br>这是因为现在这个逻辑还很简单～</p>\n<p>关于改变用户状态的那两个用户交互：投票和下一步，它们都需要和服务端进行通信，我们一会再说。我们现在先把<br>redux添加到项目中：</p>\n<pre><code>npm install --save redux\n</code></pre><p><code>index.jsx</code>入口文件是一个初始化Store的好地方，让我们暂时先使用硬编码的数据来做：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport Voting from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={Voting} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Root /&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>那么，我们如何在react组件中从Store中获取数据呢？</p>\n<p>###让React从Redux中获取数据</p>\n<p>我们已经创建了一个使用不可变数据类型保存应用状态的Redux Store。我们还拥有接受不可变数据为参数的<br>无状态的纯React组件。如果我们能使这些组件从Store中获取最新的状态数据，那真是极好的。当状态变化时，<br>React会重新渲染组件，pure render mixin可以使得我们的UI避免不必要的重复渲染。</p>\n<p>相比我们自己手动实现同步代码，我们更推荐使用[react-redux][<a href=\"https://github.com/rackt/react-redux]包来做：\">https://github.com/rackt/react-redux]包来做：</a></p>\n<pre><code>npm install --save react-redux\n</code></pre><p>这个库主要做的是：</p>\n<ol>\n<li>映射Store的状态到组件的输入props中；</li>\n<li>映射actions到组件的回调props中。</li>\n</ol>\n<p>为了让它可以正常工作，我们需要将顶层的应用组件嵌套在react-redux的<a href=\"https://github.com/rackt/react-redux#provider-store\">Provider</a>组件中。<br>这将把Redux Store和我们的状态树连接起来。</p>\n<p>我们将让Provider包含路由的根组件，这样会使得Provider成为整个应用组件的根节点：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>接下来我们要考虑一下，我们的那些组件需要绑定到Store上。我们一共有5个组件，可以分成三类：</p>\n<ul>\n<li>根组件<code>App</code>不需要绑定任何数据；</li>\n<li><code>Vote</code>和<code>Winner</code>组件只使用父组件传递来的数据，所以它们也不需要绑定；</li>\n<li>剩下的组件（<code>Voting</code>和<code>Results</code>）目前都是使用的硬编码数据，我们现在需要将其绑定到Store上。</li>\n</ul>\n<p>让我们从<code>Voting</code>组件开始。使用react-redux我们得到一个叫<a href=\"https://github.com/rackt/react-redux#connectmapstatetoprops-mapdispatchtoprops-mergeprops-options\">connect</a>的函数：</p>\n<pre><code>connect(mapStateToProps)(SomeComponent);\n</code></pre><p>该函数的作用就是将Redux Store中的状态数据映射到props对象中。这个props对象将会用于连接到的组件中。<br>在我们的<code>Voting</code>场景中，我们需要从状态中拿到<code>pair</code>和<code>winner</code>值：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nconst Voting = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n\nconnect(mapStateToProps)(Voting);\n\nexport default Voting;\n</code></pre><p>在上面的代码中，<code>connect</code>函数并没有修改<code>Voting</code>组件本身，<code>Voting</code>组件依然保持这纯粹性。而<code>connect</code><br>返回的是一个<code>Voting</code>组件的连接版，我们称之为<code>VotingContainer</code>：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\n\nexport const Voting = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n\nexport const VotingContainer = connect(mapStateToProps)(Voting);\n</code></pre><p>这样，这个模块现在导出两个组件：一个纯<code>Voting</code>组件，一个连接后的<code>VotingContainer</code>版本。<br>react-redux官方称前者为“蠢”组件，后者则称为”智能”组件。我更倾向于用“pure”和“connected”来描述它们。<br>怎么称呼随你便，主要是明白它们之间的差别：</p>\n<ul>\n<li>纯组件完全靠给它传入的props来工作，这非常类似一个纯函数；</li>\n<li>连接组件则封装了纯组件和一些逻辑用来与Redux Store协同工作，这些特性是redux-react提供的。</li>\n</ul>\n<p>我们得更新一下路由表，改用<code>VotingContainer</code>。一旦修改完毕，我们的投票界面将会使用来自Redux Store的数据：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport Results from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={Results} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>而在对应的测试代码中，我们则需要使用纯<code>Voting</code>组件定义：</p>\n<pre><code>//test/components/Voting_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List} from &apos;immutable&apos;;\nimport {Voting} from &apos;../../src/components/Voting&apos;;\nimport {expect} from &apos;chai&apos;;\n</code></pre><p>其它地方不需要修改了。</p>\n<p>现在我们来如法炮制投票结果页面：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\n\nexport const Results = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return this.props.winner ?\n      &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n      &lt;div className=&quot;results&quot;&gt;\n        &lt;div className=&quot;tally&quot;&gt;\n          {this.getPair().map(entry =&gt;\n            &lt;div key={entry} className=&quot;entry&quot;&gt;\n              &lt;h1&gt;{entry}&lt;/h1&gt;\n              &lt;div className=&quot;voteCount&quot;&gt;\n                {this.getVotes(entry)}\n              &lt;/div&gt;\n            &lt;/div&gt;\n          )}\n        &lt;/div&gt;\n        &lt;div className=&quot;management&quot;&gt;\n          &lt;button ref=&quot;next&quot;\n                   className=&quot;next&quot;\n                   onClick={this.props.next}&gt;\n            Next\n          &lt;/button&gt;\n      &lt;/div&gt;\n      &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    tally: state.getIn([&apos;vote&apos;, &apos;tally&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  }\n}\n\nexport const ResultsContainer = connect(mapStateToProps)(Results);\n</code></pre><p>同样我们需要修改<code>index.jsx</code>来使用新的<code>ResultsContainer</code>：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>不要忘记修改测试代码啊：</p>\n<pre><code>//test/components/Results_spec.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {List, Map} from &apos;immutable&apos;;\nimport {Results} from &apos;../../src/components/Results&apos;;\nimport {expect} from &apos;chai&apos;;\n</code></pre><p>现在你已经知道如何让纯react组件与Redux Store整合了。</p>\n<p>对于一些只有一个根组件且没有路由的小应用，直接连接根组件就足够了。根组件会将状态数据传递给它的子组件。<br>而对于那些使用路由，就像我们的场景，连接每一个路由指向的处理函数是个好主意。但是分别为每个组件编写连接代码并<br>不适合所有的软件场景。我觉得保持组件props尽可能清晰明了是个非常好的习惯，因为它可以让你很容易清楚组件需要哪些数据，<br>你就可以更容易管理那些连接代码。</p>\n<p>现在让我们开始把Redux数据对接到UI里，我们再也不需要那些<code>App.jsx</code>中手写的硬编码数据了，这样我们的<code>App.jsx</code>将会变得简单：</p>\n<pre><code>//src/components/App.jsx\n\nimport React from &apos;react&apos;;\nimport {RouteHandler} from &apos;react-router&apos;;\n\nexport default React.createClass({\n  render: function() {\n    return &lt;RouteHandler /&gt;\n  }\n});\n</code></pre><p>###设置socket.io客户端</p>\n<p>现在我们已经创建好了客户端的Redux应用，我们接下来将讨论如何让其与我们之前开发的服务端应用进行对接。</p>\n<p>服务端已经准备好接受socket连接，并为其进行投票数据的发送。而我们的客户端也已经可以使用Redux Store很方便的<br>接受数据了。我们剩下的工作就是把它们连接起来。</p>\n<p>我们需要使用socket.io从浏览器向服务端创建一个连接，我们可以使用<a href=\"http://socket.io/docs/client-api/\">socket.io-client库</a>来完成<br>这个目的：</p>\n<pre><code>npm install --save socket.io-client\n</code></pre><p>这个库赋予了我们连接Socket.io服务端的能力，让我们连接之前写好的服务端，端口号8090（注意使用和后端匹配的端口）：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\nstore.dispatch({\n  type: &apos;SET_STATE&apos;,\n  state: {\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;28 Days Later&apos;],\n      tally: {Sunshine: 2}\n    }\n  }\n});\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>你必须先确保你的服务端已经开启了，然后在浏览器端访问客户端应用，并检查网络监控，你会发现创建了一个<br>WebSockets连接，并且开始传输Socket.io的心跳包了。</p>\n<p>###接受来自服务器端的actions</p>\n<p>我们虽然已经创建了个socket.io连接，但我们并没有用它获取任何数据。每当我们连接到服务端或服务端发生<br>状态数据改变时，服务端会发送<code>state</code>事件给客户端。我们只需要监听对应的事件即可，我们在接受到事件通知后<br>只需要简单的对我们的Store指派<code>SET_STATE</code>action即可：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch({type: &apos;SET_STATE&apos;, state})\n);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>注意我们移除了<code>SET_STATE</code>的硬编码，我们现在已经不需要伪造数据了。</p>\n<p>审视我们的界面，不管是投票还是结果页面，它们都会显示服务端提供的第一对选项。服务端和客户端已经连接上了！</p>\n<p>###从react组件中指派actions</p>\n<p>我们已经知道如何从Redux Store获取数据到UI中，现在来看看如何从UI中提交数据用于actions。</p>\n<p>思考这个问题的最佳场景是投票界面上的投票按钮。之前在写相关界面时，我们假设<code>Voting</code>组件接受一个回调函数props。<br>当用户点击某个按钮时组件将会调用这个回调函数。但我们目前并没有实现这个回调函数，除了在测试代码中。</p>\n<p>当用户投票后应该做什么？投票结果应该发送给服务端，这部分我们稍后再说，客户端也需要执行一些逻辑：<br>组件的<code>hasVoted</code>值应该被设置，这样用户才不会反复对同一对选项投票。</p>\n<p>这是我们要创建的第二个客户端Redux Action，我们称之为<code>VOTE</code>：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;handles VOTE by setting hasVoted&apos;, () =&gt; {\n  const state = fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  });\n  const action = {type: &apos;VOTE&apos;, entry: &apos;Trainspotting&apos;};\n  const nextState = reducer(state, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    },\n    hasVoted: &apos;Trainspotting&apos;\n  }));\n});\n</code></pre><p>为了更严谨，我们应该考虑一种情况：不管什么原因，当<code>VOTE</code>action传递了一个不存在的选项时我们的应用该怎么做：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;does not set hasVoted for VOTE on invalid entry&apos;, () =&gt; {\n  const state = fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  });\n  const action = {type: &apos;VOTE&apos;, entry: &apos;Sunshine&apos;};\n  const nextState = reducer(state, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    }\n  }));\n});\n</code></pre><p>下面来看看我们的reducer如何实现的：</p>\n<pre><code>//src/reducer.js\n\nimport {Map} from &apos;immutable&apos;;\n\nfunction setState(state, newState) {\n  return state.merge(newState);\n}\n\nfunction vote(state, entry) {\n  const currentPair = state.getIn([&apos;vote&apos;, &apos;pair&apos;]);\n  if (currentPair &amp;&amp; currentPair.includes(entry)) {\n    return state.set(&apos;hasVoted&apos;, entry);\n  } else {\n    return state;\n  }\n}\n\nexport default function(state = Map(), action) {\n  switch (action.type) {\n  case &apos;SET_STATE&apos;:\n    return setState(state, action.state);\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry);\n  }\n  return state;\n}\n</code></pre><p><code>hasVoted</code>并不会一直保存在状态数据中，每当开始一轮新的投票时，我们应该在<code>SET_STATE</code>action的处理逻辑中<br>检查是否用户是否已经投票，如果还没，我们应该删除掉<code>hasVoted</code>：</p>\n<pre><code>//test/reducer_spec.js\n\nit(&apos;removes hasVoted on SET_STATE if pair changes&apos;, () =&gt; {\n  const initialState = fromJS({\n    vote: {\n      pair: [&apos;Trainspotting&apos;, &apos;28 Days Later&apos;],\n      tally: {Trainspotting: 1}\n    },\n    hasVoted: &apos;Trainspotting&apos;\n  });\n  const action = {\n    type: &apos;SET_STATE&apos;,\n    state: {\n      vote: {\n        pair: [&apos;Sunshine&apos;, &apos;Slumdog Millionaire&apos;]\n      }\n    }\n  };\n  const nextState = reducer(initialState, action);\n\n  expect(nextState).to.equal(fromJS({\n    vote: {\n      pair: [&apos;Sunshine&apos;, &apos;Slumdog Millionaire&apos;]\n    }\n  }));\n});\n</code></pre><p>根据需要，我们新增一个<code>resetVote</code>函数来处理<code>SET_STATE</code>动作：</p>\n<pre><code>//src/reducer.js\n\nimport {List, Map} from &apos;immutable&apos;;\n\nfunction setState(state, newState) {\n  return state.merge(newState);\n}\n\nfunction vote(state, entry) {\n  const currentPair = state.getIn([&apos;vote&apos;, &apos;pair&apos;]);\n  if (currentPair &amp;&amp; currentPair.includes(entry)) {\n    return state.set(&apos;hasVoted&apos;, entry);\n  } else {\n    return state;\n  }\n}\n\nfunction resetVote(state) {\n  const hasVoted = state.get(&apos;hasVoted&apos;);\n  const currentPair = state.getIn([&apos;vote&apos;, &apos;pair&apos;], List());\n  if (hasVoted &amp;&amp; !currentPair.includes(hasVoted)) {\n    return state.remove(&apos;hasVoted&apos;);\n  } else {\n    return state;\n  }\n}\n\nexport default function(state = Map(), action) {\n  switch (action.type) {\n  case &apos;SET_STATE&apos;:\n    return resetVote(setState(state, action.state));\n  case &apos;VOTE&apos;:\n    return vote(state, action.entry);\n  }\n  return state;\n}\n</code></pre><p>我们还需要在修改一下连接逻辑：</p>\n<pre><code>//src/components/Voting.jsx\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    hasVoted: state.get(&apos;hasVoted&apos;),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n</code></pre><p>现在我们依然需要为<code>Voting</code>提供一个<code>vote</code>回调函数，用来为Sotre指派我们新增的action。我们依然要尽力保证<br><code>Voting</code>组件的纯粹性，不应该依赖任何actions或Redux。这些工作都应该在react-redux的<code>connect</code>中处理。</p>\n<p>除了连接输入参数属性，react-redux还可以用来连接output actions。开始之前，我们先来介绍一下另一个Redux的<br>核心概念：Action creators。</p>\n<p>如我们之前看到的，Redux actions通常就是一个简单的对象，它包含一个固有的<code>type</code>属性和其它内容。我们之前都是直接<br>利用js对象字面量来直接声明所需的actions。其实可以使用一个factory函数来更好的生成actions，如下：</p>\n<pre><code>function vote(entry) {\n  return {type: &apos;VOTE&apos;, entry};\n}\n</code></pre><p>这类函数就被称为action creators。它们就是个纯函数，用来返回action对象，别的没啥好介绍得了。但是你也可以<br>在其中实现一些内部逻辑，而避免将每次生成action都重复编写它们。使用action creators可以更好的表达所有需要分发<br>的actions。</p>\n<p>让我们新建一个用来声明客户端所需action的action creators文件：</p>\n<pre><code>//src/action_creators.js\n\nexport function setState(state) {\n  return {\n    type: &apos;SET_STATE&apos;,\n    state\n  };\n}\n\nexport function vote(entry) {\n  return {\n    type: &apos;VOTE&apos;,\n    entry\n  };\n}\n</code></pre><p>我们当然也可以为action creators编写测试代码，但由于我们的代码逻辑太简单了，我就不再写测试了。</p>\n<p>现在我们可以在<code>index.jsx</code>中使用我们刚新增的<code>setState</code>action creator了：</p>\n<pre><code>//src/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport {setState} from &apos;./action_creators&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst store = createStore(reducer);\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch(setState(state))\n);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>使用action creators还有一个非常优雅的特点：在我们的场景里，我们有一个需要<code>vote</code>回调函数props的<br><code>Vote</code>组件，我们同时拥有一个<code>vote</code>的action creator。它们的名字和函数签名完全一致（都接受一个用来表示<br>选中项的参数）。现在我们只需要将action creators作为react-redux的<code>connect</code>函数的第二个参数，即可完成<br>自动关联：</p>\n<pre><code>//src/components/Voting.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport Vote from &apos;./Vote&apos;;\nimport * as actionCreators from &apos;../action_creators&apos;;\n\nexport const Voting = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  render: function() {\n    return &lt;div&gt;\n      {this.props.winner ?\n        &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n        &lt;Vote {...this.props} /&gt;}\n    &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    hasVoted: state.get(&apos;hasVoted&apos;),\n    winner: state.get(&apos;winner&apos;)\n  };\n}\n\nexport const VotingContainer = connect(\n  mapStateToProps,\n  actionCreators\n)(Voting);\n</code></pre><p>这么配置后，我们的<code>Voting</code>组件的<code>vote</code>参数属性将会与<code>vote</code>aciton creator关联起来。这样当点击<br>某个投票按钮后，会导致触发<code>VOTE</code>动作。</p>\n<p>###使用Redux Middleware发送actions到服务端</p>\n<p>最后我们要做的是把用户数据提交到服务端，这种操作一般发生在用户投票，或选择跳转下一轮投票时发生。</p>\n<p>让我们讨论一下投票操作，下面列出了投票的逻辑：</p>\n<ul>\n<li>当用户进行投票，<code>VOTE</code>action将产生并分派到客户端的Redux Store中；</li>\n<li><code>VOTE</code>actions将触发客户端reducer进行<code>hasVoted</code>状态设置；</li>\n<li>服务端监控客户端通过socket.io投递的<code>action</code>，它将接收到的actions分派到服务端的Redux Store;</li>\n<li><code>VOTE</code>action将触发服务端的reducer，其会创建vote数据并更新对应的票数。</li>\n</ul>\n<p>这样来说，我们似乎已经都搞定了。唯一缺少的就是让客户端发送<code>VOTE</code>action给服务端。这相当于两端的<br>Redux Store相互分派action，这就是我们接下来要做的。</p>\n<p>那么该怎么做呢？Redux并没有内建这种功能。所以我们需要设计一下何时何地来做这个工作：从客户端发送<br>action到服务端。</p>\n<p>Redux提供了一个通用的方法来封装action：<a href=\"http://rackt.github.io/redux/docs/advanced/Middleware.html\">Middleware</a>。</p>\n<p>Redux中间件是一个函数，每当action将要被指派，并在对应的reducer执行之前会被调用。它常用来做像日志收集，<br>异常处理，修整action，缓存结果，控制何时以何种方式来让store接收actions等工作。这正是我们可以利用的。</p>\n<p>注意，一定要分清Redux中间件和Redux监听器的差别：中间件被用于action将要指派给store阶段，它可以修改action对<br>store将带来的影响。而监听器则是在action被指派后，它不能改变action的行为。</p>\n<p>我们需要创建一个“远程action中间件”，该中间件可以让我们的action不仅仅能指派给本地的store，也可以通过<br>socket.io连接派送给远程的store。</p>\n<p>让我们创建这个中间件，It is a function that takes a Redux store, and returns another function that takes a “next” callback. That function returns a third function that takes a Redux action. The innermost function is where the middleware implementation will actually go<br>（译者注：这句套绕口，请看官自行参悟）：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default store =&gt; next =&gt; action =&gt; {\n\n}\n</code></pre><p>上面这个写法看着可能有点渗人，下面调整一下让大家好理解：</p>\n<pre><code>export default function(store) {\n    return function(next) {\n        return function(action) {\n\n        }\n    }\n}\n</code></pre><p>这种嵌套接受单一参数函数的写法成为<a href=\"https://en.wikipedia.org/wiki/Currying\">currying</a>。<br>这种写法主要用来简化中间件的实现：如果我们使用一个一次性接受所有参数的函数（<code>function(store, next, action) { }</code>），<br>那么我们就不得不保证我们的中间件具体实现每次都要包含所有这些参数。</p>\n<p>上面的<code>next</code>参数作用是在中间件中一旦完成了action的处理，就可以调用它来退出当前逻辑：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default store =&gt; next =&gt; action =&gt; {\n  return next(action);\n}\n</code></pre><p>如果中间件没有调用<code>next</code>，则该action将丢弃，不再传到reducer或store中。</p>\n<p>让我们写一个简单的日志中间件：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default store =&gt; next =&gt; action =&gt; {\n  console.log(&apos;in middleware&apos;, action);\n  return next(action);\n}\n</code></pre><p>我们将上面这个中间件注册到我们的Redux Store中，我们将会抓取到所有action的日志。中间件可以通过Redux<br>提供的<code>applyMiddleware</code>函数绑定到我们的store中：</p>\n<pre><code>//src/components/index.jsx\n\nimport React from &apos;react&apos;;\nimport Router, {Route, DefaultRoute} from &apos;react-router&apos;;\nimport {createStore, applyMiddleware} from &apos;redux&apos;;\nimport {Provider} from &apos;react-redux&apos;;\nimport io from &apos;socket.io-client&apos;;\nimport reducer from &apos;./reducer&apos;;\nimport {setState} from &apos;./action_creators&apos;;\nimport remoteActionMiddleware from &apos;./remote_action_middleware&apos;;\nimport App from &apos;./components/App&apos;;\nimport {VotingContainer} from &apos;./components/Voting&apos;;\nimport {ResultsContainer} from &apos;./components/Results&apos;;\n\nconst createStoreWithMiddleware = applyMiddleware(\n  remoteActionMiddleware\n)(createStore);\nconst store = createStoreWithMiddleware(reducer);\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch(setState(state))\n);\n\nconst routes = &lt;Route handler={App}&gt;\n  &lt;Route path=&quot;/results&quot; handler={ResultsContainer} /&gt;\n  &lt;DefaultRoute handler={VotingContainer} /&gt;\n&lt;/Route&gt;;\n\nRouter.run(routes, (Root) =&gt; {\n  React.render(\n    &lt;Provider store={store}&gt;\n      {() =&gt; &lt;Root /&gt;}\n    &lt;/Provider&gt;,\n    document.getElementById(&apos;app&apos;)\n  );\n});\n</code></pre><p>如果你重启应用，你将会看到我们设置的中间件会抓到应用触发的action日志。</p>\n<p>那我们应该怎么利用中间件机制来完成从客户端通过socket.io连接发送action给服务端呢？在此之前我们肯定需要先<br>有一个连接供中间件使用，不幸的是我们已经有了，就在<code>index.jsx</code>中，我们只需要中间件可以拿到它即可。<br>使用currying风格来实现这个中间件很简单：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default socket =&gt; store =&gt; next =&gt; action =&gt; {\n  console.log(&apos;in middleware&apos;, action);\n  return next(action);\n}\n</code></pre><p>这样我们就可以在<code>index.jsx</code>中传入需要的连接了：</p>\n<pre><code>//src/index.jsx\n\nconst socket = io(`${location.protocol}//${location.hostname}:8090`);\nsocket.on(&apos;state&apos;, state =&gt;\n  store.dispatch(setState(state))\n);\n\nconst createStoreWithMiddleware = applyMiddleware(\n  remoteActionMiddleware(socket)\n)(createStore);\nconst store = createStoreWithMiddleware(reducer);\n</code></pre><p>注意跟之前的代码比，我们需要调整一下顺序，让socket连接先于store被创建。</p>\n<p>一切就绪了，现在就可以使用我们的中间件发送<code>action</code>了：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default socket =&gt; store =&gt; next =&gt; action =&gt; {\n  socket.emit(&apos;action&apos;, action);\n  return next(action);\n}\n</code></pre><p>打完收工。现在如果你再点击投票按钮，你就会看到所有连接到服务端的客户端的票数都会被更新！</p>\n<p>还有个很严重的问题我们要处理：现在每当我们收到服务端发来的<code>SET_STATE</code>action后，这个action都将会直接回传给<br>服务端，这样我们就造成了一个死循环，这是非常反人类的。</p>\n<p>我们的中间件不应该不加处理的转发所有的action给服务端。个别action，例如<code>SET_STATE</code>，应该只在客户端做<br>处理。我们在action中添加一个标识位用于识别哪些应该转发给服务端：</p>\n<pre><code>//src/remote_action_middleware.js\n\nexport default socket =&gt; store =&gt; next =&gt; action =&gt; {\n  if (action.meta &amp;&amp; action.meta.remote) {\n    socket.emit(&apos;action&apos;, action);\n  }\n  return next(action);\n}\n</code></pre><p>我们同样应该修改相关的action creators：</p>\n<pre><code>//src/action_creators.js\n\nexport function setState(state) {\n  return {\n    type: &apos;SET_STATE&apos;,\n    state\n  };\n}\n\nexport function vote(entry) {\n  return {\n    meta: {remote: true},\n    type: &apos;VOTE&apos;,\n    entry\n  };\n}\n</code></pre><p>让我们重新审视一下我们都干了什么：</p>\n<ol>\n<li>用户点击投票按钮，<code>VOTE</code>action被分派；</li>\n<li>远程action中间件通过socket.io连接转发该action给服务端；</li>\n<li>客户端Redux Store处理这个action，记录本地<code>hasVoted</code>属性；</li>\n<li>当action到达服务端，服务端的Redux Store将处理该action，更新所有投票及其票数；</li>\n<li>设置在服务端Redux Store上的监听器将改变后的状态数据发送给所有在线的客户端；</li>\n<li>每个客户端将触发<code>SET_STATE</code>action的分派；</li>\n<li>每个客户端将根据这个action更新自己的状态，这样就保持了与服务端的同步。</li>\n</ol>\n<p>为了完成我们的应用，我们需要实现下一步按钮的逻辑。和投票类似，我们需要将数据发送到服务端：</p>\n<pre><code>//src/action_creator.js\n\nexport function setState(state) {\n  return {\n    type: &apos;SET_STATE&apos;,\n    state\n  };\n}\n\nexport function vote(entry) {\n  return {\n    meta: {remote: true},\n    type: &apos;VOTE&apos;,\n    entry\n  };\n}\n\nexport function next() {\n  return {\n    meta: {remote: true},\n    type: &apos;NEXT&apos;\n  };\n}\n</code></pre><p><code>ResultsContainer</code>组件将会自动关联action creators中的next作为props：</p>\n<pre><code>//src/components/Results.jsx\n\nimport React from &apos;react/addons&apos;;\nimport {connect} from &apos;react-redux&apos;;\nimport Winner from &apos;./Winner&apos;;\nimport * as actionCreators from &apos;../action_creators&apos;;\n\nexport const Results = React.createClass({\n  mixins: [React.addons.PureRenderMixin],\n  getPair: function() {\n    return this.props.pair || [];\n  },\n  getVotes: function(entry) {\n    if (this.props.tally &amp;&amp; this.props.tally.has(entry)) {\n      return this.props.tally.get(entry);\n    }\n    return 0;\n  },\n  render: function() {\n    return this.props.winner ?\n      &lt;Winner ref=&quot;winner&quot; winner={this.props.winner} /&gt; :\n      &lt;div className=&quot;results&quot;&gt;\n        &lt;div className=&quot;tally&quot;&gt;\n          {this.getPair().map(entry =&gt;\n            &lt;div key={entry} className=&quot;entry&quot;&gt;\n              &lt;h1&gt;{entry}&lt;/h1&gt;\n              &lt;div className=&quot;voteCount&quot;&gt;\n                {this.getVotes(entry)}\n              &lt;/div&gt;\n            &lt;/div&gt;\n          )}\n        &lt;/div&gt;\n        &lt;div className=&quot;management&quot;&gt;\n          &lt;button ref=&quot;next&quot;\n                   className=&quot;next&quot;\n                   onClick={this.props.next()}&gt;\n            Next\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;;\n  }\n});\n\nfunction mapStateToProps(state) {\n  return {\n    pair: state.getIn([&apos;vote&apos;, &apos;pair&apos;]),\n    tally: state.getIn([&apos;vote&apos;, &apos;tally&apos;]),\n    winner: state.get(&apos;winner&apos;)\n  }\n}\n\nexport const ResultsContainer = connect(\n  mapStateToProps,\n  actionCreators\n)(Results);\n</code></pre><p>彻底完工了！我们实现了一个功能完备的应用。</p>\n<p>###课后练习<br>（不翻译）</p>"},{"title":"［译]深入浅出Redux中间件","date":"2015-10-09T01:37:12.000Z","_content":"\n原文地址：[https://medium.com/@meagle/understanding-87566abcfb7a](https://medium.com/@meagle/understanding-87566abcfb7a)\n\n---\n\n从2014年二月开始我就在使用facebook的React了，那时候它的版本才v0.9.x。我是从Backbone.js转过来的，当哥了解到Flux的好处和它提倡的单数据流架构时，我就已经决定不在使用Backbone.js提供的models和集合。这里我假设你已经大概了解了Flux，Redux，React和函数式编程的基本知识，在这篇文章中我将尽可能的涵盖所有内容。\n<!--more-->\nDan的Redux库真的非常简单和出彩儿，我相信每个人都可以借助它开发炫酷屌炸天的前端web应用。但我更想了解一下它的内部实现。我开始了Redux源码的探索，要想能更好的理解源码，你必须非常熟悉函数式编程理念。它的代码写的非常简练，没有扎实的基本功你会觉得非常难看懂。我将尝试带领你了解一些需要用到的函数式编程概念，包括：复合函数，柯里化，和高阶函数等。\n\n---\n\n我鼓励你去阅读源码来搞明白reducer函数是如何创建和组合的，action creator函数是如何作用于dispatch方法的，还有如何增加中间件来影响默认的dispatch方法的。这篇文章将会帮你理解一些Redux框架的源码，提升你的函数式编程能力，同时也让你尝试一下部分ES6语法。\n\n###中间件\n\nRedux最有趣的一个概念是它允许你通过自定义的中间件来影响你store的dispatch逻辑。然而，当我第一次试图查看[applyMiddleware.js](http://rackt.github.io/redux/docs/api/applyMiddleware.html)源码时，可把本宝宝吓坏了。所以我只能尝试参照Redux中间件的[文档](http://rackt.github.io/redux/docs/api/applyMiddleware.html)从功能层面来分析代码。看了下面[这段话](http://rackt.github.io/redux/docs/api/applyMiddleware.html)，让我找回了面子：\n\n> “中间件”这个词听起来很恐怖，但它实际一点都不难。想更好的了解中间件的方法就是看一下那些已经实现了的中间件是怎么工作的，然后尝试自己写一个。函数嵌套写法看起来很恐怖，但是大多数你能找到的中间件，代码都不超过十行，但是它们的强大来自于它们的可嵌套组合性。\n\n区区10行的中间件很容易写，但是你要想明白它们是如何放入中间件调用链，又是如何影响store的diapatch方法的，还真需要一些经验。首先让我们来简单定义一下中间件到底是个啥，并且找一些简单的中间件看一下它们的具体实现方式。关于中间件的定义我能找到的最简单的描述是：\n\n> 中间件主要被用于分离那些不属于你应用的核心业务逻辑的可被组合起来使用的代码。\n\n听起来不算太复杂，对吧;)\n\n如果你之前用过[Koa.js](http://koajs.com/)n，那你可能早就接触过中间件这个概念了。我最早使用中间件是在我用Java Servlet写Filters和用Ruby写类似认证授权，日志，性能监控或一些需要在业务逻辑执行前处理的模块。\n\nRedux的中间件主要用在store的dispatch函数上。dispatch函数的作用是发送actions给一个或多个reducer来影响应用状态的。中间件可以增强默认的dispatch函数，我们来看一下Redux1.0.1版本的applyMiddleware源码：\n\n\texport default function applyMiddleware(...middlewares) {    \t\treturn (next)  => \n   \t\t\n    \t\t(reducer, initialState) => {\n      \t\t\t\n      \t\t\tvar store = next(reducer, initialState);\n      \t\t\tvar dispatch = store.dispatch;\n      \t\t\tvar chain = [];\n      \t\t\t\n      \t\t\tvar middlewareAPI = {\n        \t\t\tgetState: store.getState,\n        \t\t\tdispatch: (action) => dispatch(action)\n      \t\t\t};\n      \t\t\t\n      \t\t\tchain = middlewares.map(middleware =>\n                    \t\t\tmiddleware(middlewareAPI));\n      \t\t\t\n      \t\t\tdispatch = compose(...chain, store.dispatch);\n      \t\t\treturn {\n        \t\t\t...store,\n        \t\t\tdispatch\n      \t\t\t};\n   \t\t\t};\n\t}\n\n就这么点儿代码，就使用了非常多的函数式编程的思想，包括：高阶函数，复合函数，柯里化和ES6语法。一开始我反复读了十遍，然后我疯了:)。让我们先来分别看一些函数式编程的知识，回头再理会上面这段让人不爽的代码。\n\n###函数式编程概念\n\n在开始阅读Redux中间件源码之前，你需要先掌握一些函数式编程知识，如果你已经自学成才了请跳过本节。\n\n####复合函数\n\n函数式编程是非常理论和非常数学化的。用数学的视角来解释复合函数，如下：\n\n\tgiven:\n\t\tf(x) = x^2 + 3x + 1\n\t\tg(x) = 2x\n\t\n\tthen:\n\t\t(f ∘ g)(x) = f(g(x)) = f(2x) = 4x^2 + 6x + 1 \n\t\t\n你可以将上面的方式扩展到组合两个或更多个函数这都是可以的。我们再来看个例子，演示组合两个函数并返回一个新的函数：\n\n\tvar greet = function(x) { return `Hello, ${ x }` };\n\tvar emote = function(x) { return `${x} :)` };\n\t\n\tvar compose = function(f, g) {\n  \t\treturn function(x) {\n    \t\treturn f(g(x));\n  \t\t}\n\t}\n\t\n\tvar happyGreeting = compose(greet, emote);\n\t// happyGreeting(“Mark”) -> Hello, Mark :)\n\t\n我们当然可以组合更多的函数，这里只是给大家简单阐述一下基础概念。更多的常用技巧我们我们可以在Redux的源码中看到。\n\n####柯里化\n\n另一个屌炸天的函数式编程概念被称之为：柯里化。（译者注：这段翻译起来太难了，我放弃了，推荐你看[这里](http://www.zhangxinxu.com/wordpress/2013/02/js-currying/)来了解这个概念）\n\n\tvar curriedAdd = function(a) {\n    \treturn function(b) {\n        \treturn a + b;\n    \t};\n\t};\n\t\n\tvar addTen = curriedAdd(10);\n\taddTen(10); //20\n\t\n\n通过柯里化来组合你的函数，你可以创建一个强大的数据处理管道。\n\n###Redux的Dispatch函数\n\nRedux的Store有一个dispatch函数，它关注你的应用实现的业务逻辑。你可以用它指派actions到你定义的reducer函数，用以更新你的应用状态。Redux的reducer函数接受一个当前状态参数和一个action参数，并返回一个新的状态对象：\n\n\treducer:: state -> action -> state\n\t\n指派action很像发送消息，如果我们假设要从一个列表中删除某个元素，action结构一般如下：\n\n\t{type: types.DELETE_ITEM, id: 1}\n\t\nstore会指派这个action对象到它所拥有的所有reducer函数来影响应用的状态，然而只有关注删除逻辑的reducer会真的修改状态。在此期间没人会关注到底是谁修改了状态，花了多长时间，或者记录一下变更前后的状态数据镜像。这些非核心关注点都可以交给中间件来完成。\n\n###Redux Middleware\n\nRedux中间件被设计成可组合的，会在dispatch方法之前调用的函数。让我们来创建一个简单的日志中间件，它会简单的输出dispatch前后的应用状态。Redux中间件的签名如下：\n\n\tmiddleware:: next -> action -> retVal\n\t\n我们的logger中间件实现如下：\n\n\texport default function createLogger({ getState }) {\n  \t\treturn (next) => \n    \t\t(action) => {\n      \t\t\tconst console = window.console;\n      \t\t\tconst prevState = getState();\n      \t\t\tconst returnValue = next(action);\n      \t\t\tconst nextState = getState();\n      \t\t\tconst actionType = String(action.type);\n      \t\t\tconst message = `action ${actionType}`;\n      \n      \t\t\tconsole.log(`%c prev state`, `color: #9E9E9E`, prevState);\n      \t\t\tconsole.log(`%c action`, `color: #03A9F4`, action);\n      \t\t\tconsole.log(`%c next state`, `color: #4CAF50`, nextState);\n      \t\t\treturn returnValue;\n    \t};\n\t}\n\t\n注意，我们的`createLogger`接受的`getState`方法是由`applyMiddleware.js`注入进来的。使用它可以在内部的闭包中得到应用的当前状态。最后我们返回调用`next`创建的函数作为结果。`next`方法用于维护中间件调用链和dispatch，它返回一个接受`action`对象的柯里化函数，接受的`action`对象可以在中间件中被修改，再传递给下一个被调用的中间件，最终dispatch会使用中间件修改后的action来执行。\n\n更健壮的logger中间件实现可以看[这里](https://www.npmjs.com/package/redux-logger)，为了节省时间，我们的logger中间件实现非常的简陋。\n\n我们来看看上面的logger中间件的业务流程：\n\n1. 得到当前的应用状态；\n2. 将action指派给下一个中间件；\n3. 调用链下游的中间件全部被执行；\n4. store中的匹配reducer被执行；\n5. 此时得到新的应用状态。\n\n我们这里来看一个拥有2个中间件组件的例子：\n\n![](https://cdn-images-1.medium.com/max/800/1*jNHs4JtDn9r00bs4iNSwjA.png)\n\n###剖析applyMiddleware.js\n\n现在咱们已经知道Redux中间件是个啥，并且也掌握了足够的函数式编程知识，那就让我们再次尝试阅读`applyMiddleware.js`的源码来探个究竟吧。这次感觉比较好理解了吧：\n\n\texport default function applyMiddleware(...middlewares) {    \t\treturn (next)  => \n   \t\t\n    \t\t(reducer, initialState) => {\n      \t\t\t\n      \t\t\tvar store = next(reducer, initialState);\n      \t\t\tvar dispatch = store.dispatch;\n      \t\t\tvar chain = [];\n      \t\t\t\n      \t\t\tvar middlewareAPI = {\n        \t\t\tgetState: store.getState,\n        \t\t\tdispatch: (action) => dispatch(action)\n      \t\t\t};\n      \t\t\t\n      \t\t\tchain = middlewares.map(middleware =>\n                    \t\t\tmiddleware(middlewareAPI));\n      \t\t\t\n      \t\t\tdispatch = compose(...chain, store.dispatch);\n      \t\t\treturn {\n        \t\t\t...store,\n        \t\t\tdispatch\n      \t\t\t};\n   \t\t\t};\n\t}\n\n`applyMiddleware`可能应该起一个更好一点的名字，谁能告诉我这是为谁来“申请中间件”？我觉得可以这么叫：`applyMiddlewareToStore`，这样是不是更加明确一些？\n\n我们来一行一行分析代码，首先我们看方法签名：\n\n\texport default function applyMiddleware(...middlewares)\n\t\n注意这里有个很有趣的写法，参数：`...middlewares`，这么定义允许我们调用时传入任意个数的中间件函数作为参数。接下来函数将返回一个接受`next`作为参数的函数：\n\n\treturn (next) => (reducer, initialState) => {...}\n\t\n`next`参数是一个被用来创建store的函数，你可以看一下[createStore.js](https://github.com/rackt/redux/blob/master/src/createStore.js)源码的实现细节。最后这个函数返回一个类似`createStore`的函数，不同的是它包含一个由中间件加工过的dispatch实现。\n\n接下来我们通过调用`next`拿到store对象（译者注：\"Next we assign the store implementation to the function responsible for creating the new store (again see createStore.js). \"这句实在翻译不来～）。我们用一个变量保存原始的dispatch函数，最后我们声明一个数组来存储我们创建的中间件链：\n\n\tvar store = next(reducer, initialState);\n\tvar dispatch = store.dispatch;\n\tvar chain = [];\n\t\n接下来的代码将`getState`和调用原始的`dispatch`函数注入给所有的中间件：\n\n\tvar middlewareAPI = {\n  \t\tgetState: store.getState,\n  \t\tdispatch: (action) => dispatch(action)\n\t};\n\n\tchain = middlewares.map(middleware =>\n                    middleware(middlewareAPI));\n\n然后我们根据中间件链创建一个加工过的dispatch实现：\n\n\tdispatch = compose(...chain, store.dispatch);\n\t\n最tm精妙的地方就是上面这行，Redux提供的`compose`工具函数组合了我们的中间件链，`compose`实现如下：\n\n\texport default function compose(...funcs) {\n \t\treturn funcs.reduceRight((composed, f) => f(composed));\n\t}\n\t\n碉堡了！上面的代码展示了中间件调用链是如何创建出来的。中间件调用链的顺序很重要，调用链类似下面这样：\n\n\tmiddlewareI(middlewareJ(middlewareK(store.dispatch)))(action)\n\t\n现在知道为啥我们要掌握复合函数和柯里化概念了吧？最后我们只需要将新的store和调整过的dispatch函数返回即可：\n\n\treturn {\n \t\t...store,\n \t\tdispatch\n\t};\n\t\n上面这种写法意思是返回一个对象，该对象拥有store的所有属性，并增加一个dispatch函数属性，store里自带的那个原始dispatch函数会被覆盖。这种写法会被[Babel](https://babeljs.io/repl/)转化成：\n\n\treturn _extends({}, store, { dispatch: _dispatch });\n\t\n现在让我们将我们的logger中间件注入到dispatch中：\n\n\timport { createStore, applyMiddleware } from ‘redux’;\n\timport loggerMiddleware from ‘logger’;\n\timport rootReducer from ‘../reducers’;\n\n\tconst createStoreWithMiddleware = \n  \t\tapplyMiddleware(loggerMiddleware)(createStore);\n\n\texport default function configureStore(initialState) {\n  \t\treturn createStoreWithMiddleware(rootReducer, initialState);\n\t}\n\t\n\tconst store = configureStore();\n\t\n###异步中间件\n\n我们已经会写基础的中间件了，我们就要玩儿点高深得了，整个能处理异步action的中间件咋样？让我们来看一下[redux-thunk](https://github.com/gaearon/redux-thunk)的更多细节。我们假设有一个包含异步请求的action，如下：\n\n\tfunction fetchQuote(symbol) {\n   \t\trequestQuote(symbol);\n   \t\treturn fetch(`http://www.google.com/finance/info?q=${symbol}`)\n      \t\t\t.then(req => req.json())\n      \t\t\t.then(json => showCurrentQuote(symbol, json));\n\t}\n\n上面代码并没有明显的调用dispatch来分派一个返回promise的action，我们需要使用redux-thunk中间件来延迟dipatch的执行：\n\n\tfunction fetchQuote(symbol) {\n  \t\treturn dispatch => {\n    \t\tdispatch(requestQuote(symbol));\n    \t\treturn fetch(`http://www.google.com/finance/info?q=${symbol}`)\n      \t\t\t\t.then(req => req.json())\n      \t\t\t\t.then(json => dispatch(showCurrentQuote(symbol, json)));\n  \t\t}\n\t}\n\t\n注意这里的`dipatch`\n和`getState`是由`applyMiddleware`函数注入进来的。现在我们就可以分派最终得到的action对象到store的reducers了。下面是类似redux-thunk的实现：\n\n\texport default function thunkMiddleware({ dispatch, getState }) {\n  \t\treturn next => \n     \t\t\taction => \n       \t\t\t\ttypeof action === ‘function’ ? \n         \t\t\t\taction(dispatch, getState) : \n         \t\t\t\tnext(action);\n\t}\n\t\n这个和你之前看到的中间件没什么太大不同。如果得到的action是个函数，就用`dispatch`和`getState`当作参数来调用它，否则就直接分派给store。你可以看一下Redux提供的更详细的[异步示例](https://github.com/rackt/redux/tree/master/examples)。另外还有一个支持promises的中间件是[redux-promise](https://github.com/acdlite/redux-promise)。我觉得选择使用哪个中间件可以根据性能来考量。\n\n###接下来干啥\n\n你现在已经知道Redux的核心代码，你现在可以尝试使用[react-redux](https://github.com/rackt/react-redux)来把Redux整合到你的react项目中了。\n\n如果你还是对函数式编程不太习惯，我鼓励你看一下来自[Brian Lonsdorf](https://twitter.com/drboolean)的优秀文献：\n\n- [Hey Underscore, You are Doing it Wrong! ](http://www.youtube.com/watch?v=m3svKOdZijA)：它介绍了很多函数式编程知识和少量的Underscore内容；\n- [Professor Frisby’s Mostly Adequate Guide to Functional Programming](http://drboolean.gitbooks.io/mostly-adequate-guide/content/index.html)\n\n###总结\n\n希望你已经了解了关于Redux中间件的足够信息，我也希望你掌握了更多的关于函数式编程的知识。我不断的尝试更多更好的函数式编程方法，尽管一开始并不容易，你需要不断的学习和尝试来参悟它的精髓。如果你完全掌握了这篇文章交给你的，那么你已经拥有了足够的信心去投入更多的学习当中。\n\n最后，千万别使用那些你还没有搞明白的第三方类库，你必须确定它会给你的项目带来好处。掌握它的一个好方法就是去阅读它的源码，你将会学到新的编程技术，淘汰那些老的解决方案。将一个工具引入你的项目前，你有责任搞清楚它的细节。\n\n\n\n\n","source":"_posts/[译]Redux中间件深入浅出.md","raw":"title: ［译]深入浅出Redux中间件\ndate: 2015-10-09 09:37:12\ntags: \n- react\n- Redux middleware\n- 函数式编程\n- 柯里化\n- 复合函数\n- currying\n- redux-thunk\ncategories: 前端\n---\n\n原文地址：[https://medium.com/@meagle/understanding-87566abcfb7a](https://medium.com/@meagle/understanding-87566abcfb7a)\n\n---\n\n从2014年二月开始我就在使用facebook的React了，那时候它的版本才v0.9.x。我是从Backbone.js转过来的，当哥了解到Flux的好处和它提倡的单数据流架构时，我就已经决定不在使用Backbone.js提供的models和集合。这里我假设你已经大概了解了Flux，Redux，React和函数式编程的基本知识，在这篇文章中我将尽可能的涵盖所有内容。\n<!--more-->\nDan的Redux库真的非常简单和出彩儿，我相信每个人都可以借助它开发炫酷屌炸天的前端web应用。但我更想了解一下它的内部实现。我开始了Redux源码的探索，要想能更好的理解源码，你必须非常熟悉函数式编程理念。它的代码写的非常简练，没有扎实的基本功你会觉得非常难看懂。我将尝试带领你了解一些需要用到的函数式编程概念，包括：复合函数，柯里化，和高阶函数等。\n\n---\n\n我鼓励你去阅读源码来搞明白reducer函数是如何创建和组合的，action creator函数是如何作用于dispatch方法的，还有如何增加中间件来影响默认的dispatch方法的。这篇文章将会帮你理解一些Redux框架的源码，提升你的函数式编程能力，同时也让你尝试一下部分ES6语法。\n\n###中间件\n\nRedux最有趣的一个概念是它允许你通过自定义的中间件来影响你store的dispatch逻辑。然而，当我第一次试图查看[applyMiddleware.js](http://rackt.github.io/redux/docs/api/applyMiddleware.html)源码时，可把本宝宝吓坏了。所以我只能尝试参照Redux中间件的[文档](http://rackt.github.io/redux/docs/api/applyMiddleware.html)从功能层面来分析代码。看了下面[这段话](http://rackt.github.io/redux/docs/api/applyMiddleware.html)，让我找回了面子：\n\n> “中间件”这个词听起来很恐怖，但它实际一点都不难。想更好的了解中间件的方法就是看一下那些已经实现了的中间件是怎么工作的，然后尝试自己写一个。函数嵌套写法看起来很恐怖，但是大多数你能找到的中间件，代码都不超过十行，但是它们的强大来自于它们的可嵌套组合性。\n\n区区10行的中间件很容易写，但是你要想明白它们是如何放入中间件调用链，又是如何影响store的diapatch方法的，还真需要一些经验。首先让我们来简单定义一下中间件到底是个啥，并且找一些简单的中间件看一下它们的具体实现方式。关于中间件的定义我能找到的最简单的描述是：\n\n> 中间件主要被用于分离那些不属于你应用的核心业务逻辑的可被组合起来使用的代码。\n\n听起来不算太复杂，对吧;)\n\n如果你之前用过[Koa.js](http://koajs.com/)n，那你可能早就接触过中间件这个概念了。我最早使用中间件是在我用Java Servlet写Filters和用Ruby写类似认证授权，日志，性能监控或一些需要在业务逻辑执行前处理的模块。\n\nRedux的中间件主要用在store的dispatch函数上。dispatch函数的作用是发送actions给一个或多个reducer来影响应用状态的。中间件可以增强默认的dispatch函数，我们来看一下Redux1.0.1版本的applyMiddleware源码：\n\n\texport default function applyMiddleware(...middlewares) {    \t\treturn (next)  => \n   \t\t\n    \t\t(reducer, initialState) => {\n      \t\t\t\n      \t\t\tvar store = next(reducer, initialState);\n      \t\t\tvar dispatch = store.dispatch;\n      \t\t\tvar chain = [];\n      \t\t\t\n      \t\t\tvar middlewareAPI = {\n        \t\t\tgetState: store.getState,\n        \t\t\tdispatch: (action) => dispatch(action)\n      \t\t\t};\n      \t\t\t\n      \t\t\tchain = middlewares.map(middleware =>\n                    \t\t\tmiddleware(middlewareAPI));\n      \t\t\t\n      \t\t\tdispatch = compose(...chain, store.dispatch);\n      \t\t\treturn {\n        \t\t\t...store,\n        \t\t\tdispatch\n      \t\t\t};\n   \t\t\t};\n\t}\n\n就这么点儿代码，就使用了非常多的函数式编程的思想，包括：高阶函数，复合函数，柯里化和ES6语法。一开始我反复读了十遍，然后我疯了:)。让我们先来分别看一些函数式编程的知识，回头再理会上面这段让人不爽的代码。\n\n###函数式编程概念\n\n在开始阅读Redux中间件源码之前，你需要先掌握一些函数式编程知识，如果你已经自学成才了请跳过本节。\n\n####复合函数\n\n函数式编程是非常理论和非常数学化的。用数学的视角来解释复合函数，如下：\n\n\tgiven:\n\t\tf(x) = x^2 + 3x + 1\n\t\tg(x) = 2x\n\t\n\tthen:\n\t\t(f ∘ g)(x) = f(g(x)) = f(2x) = 4x^2 + 6x + 1 \n\t\t\n你可以将上面的方式扩展到组合两个或更多个函数这都是可以的。我们再来看个例子，演示组合两个函数并返回一个新的函数：\n\n\tvar greet = function(x) { return `Hello, ${ x }` };\n\tvar emote = function(x) { return `${x} :)` };\n\t\n\tvar compose = function(f, g) {\n  \t\treturn function(x) {\n    \t\treturn f(g(x));\n  \t\t}\n\t}\n\t\n\tvar happyGreeting = compose(greet, emote);\n\t// happyGreeting(“Mark”) -> Hello, Mark :)\n\t\n我们当然可以组合更多的函数，这里只是给大家简单阐述一下基础概念。更多的常用技巧我们我们可以在Redux的源码中看到。\n\n####柯里化\n\n另一个屌炸天的函数式编程概念被称之为：柯里化。（译者注：这段翻译起来太难了，我放弃了，推荐你看[这里](http://www.zhangxinxu.com/wordpress/2013/02/js-currying/)来了解这个概念）\n\n\tvar curriedAdd = function(a) {\n    \treturn function(b) {\n        \treturn a + b;\n    \t};\n\t};\n\t\n\tvar addTen = curriedAdd(10);\n\taddTen(10); //20\n\t\n\n通过柯里化来组合你的函数，你可以创建一个强大的数据处理管道。\n\n###Redux的Dispatch函数\n\nRedux的Store有一个dispatch函数，它关注你的应用实现的业务逻辑。你可以用它指派actions到你定义的reducer函数，用以更新你的应用状态。Redux的reducer函数接受一个当前状态参数和一个action参数，并返回一个新的状态对象：\n\n\treducer:: state -> action -> state\n\t\n指派action很像发送消息，如果我们假设要从一个列表中删除某个元素，action结构一般如下：\n\n\t{type: types.DELETE_ITEM, id: 1}\n\t\nstore会指派这个action对象到它所拥有的所有reducer函数来影响应用的状态，然而只有关注删除逻辑的reducer会真的修改状态。在此期间没人会关注到底是谁修改了状态，花了多长时间，或者记录一下变更前后的状态数据镜像。这些非核心关注点都可以交给中间件来完成。\n\n###Redux Middleware\n\nRedux中间件被设计成可组合的，会在dispatch方法之前调用的函数。让我们来创建一个简单的日志中间件，它会简单的输出dispatch前后的应用状态。Redux中间件的签名如下：\n\n\tmiddleware:: next -> action -> retVal\n\t\n我们的logger中间件实现如下：\n\n\texport default function createLogger({ getState }) {\n  \t\treturn (next) => \n    \t\t(action) => {\n      \t\t\tconst console = window.console;\n      \t\t\tconst prevState = getState();\n      \t\t\tconst returnValue = next(action);\n      \t\t\tconst nextState = getState();\n      \t\t\tconst actionType = String(action.type);\n      \t\t\tconst message = `action ${actionType}`;\n      \n      \t\t\tconsole.log(`%c prev state`, `color: #9E9E9E`, prevState);\n      \t\t\tconsole.log(`%c action`, `color: #03A9F4`, action);\n      \t\t\tconsole.log(`%c next state`, `color: #4CAF50`, nextState);\n      \t\t\treturn returnValue;\n    \t};\n\t}\n\t\n注意，我们的`createLogger`接受的`getState`方法是由`applyMiddleware.js`注入进来的。使用它可以在内部的闭包中得到应用的当前状态。最后我们返回调用`next`创建的函数作为结果。`next`方法用于维护中间件调用链和dispatch，它返回一个接受`action`对象的柯里化函数，接受的`action`对象可以在中间件中被修改，再传递给下一个被调用的中间件，最终dispatch会使用中间件修改后的action来执行。\n\n更健壮的logger中间件实现可以看[这里](https://www.npmjs.com/package/redux-logger)，为了节省时间，我们的logger中间件实现非常的简陋。\n\n我们来看看上面的logger中间件的业务流程：\n\n1. 得到当前的应用状态；\n2. 将action指派给下一个中间件；\n3. 调用链下游的中间件全部被执行；\n4. store中的匹配reducer被执行；\n5. 此时得到新的应用状态。\n\n我们这里来看一个拥有2个中间件组件的例子：\n\n![](https://cdn-images-1.medium.com/max/800/1*jNHs4JtDn9r00bs4iNSwjA.png)\n\n###剖析applyMiddleware.js\n\n现在咱们已经知道Redux中间件是个啥，并且也掌握了足够的函数式编程知识，那就让我们再次尝试阅读`applyMiddleware.js`的源码来探个究竟吧。这次感觉比较好理解了吧：\n\n\texport default function applyMiddleware(...middlewares) {    \t\treturn (next)  => \n   \t\t\n    \t\t(reducer, initialState) => {\n      \t\t\t\n      \t\t\tvar store = next(reducer, initialState);\n      \t\t\tvar dispatch = store.dispatch;\n      \t\t\tvar chain = [];\n      \t\t\t\n      \t\t\tvar middlewareAPI = {\n        \t\t\tgetState: store.getState,\n        \t\t\tdispatch: (action) => dispatch(action)\n      \t\t\t};\n      \t\t\t\n      \t\t\tchain = middlewares.map(middleware =>\n                    \t\t\tmiddleware(middlewareAPI));\n      \t\t\t\n      \t\t\tdispatch = compose(...chain, store.dispatch);\n      \t\t\treturn {\n        \t\t\t...store,\n        \t\t\tdispatch\n      \t\t\t};\n   \t\t\t};\n\t}\n\n`applyMiddleware`可能应该起一个更好一点的名字，谁能告诉我这是为谁来“申请中间件”？我觉得可以这么叫：`applyMiddlewareToStore`，这样是不是更加明确一些？\n\n我们来一行一行分析代码，首先我们看方法签名：\n\n\texport default function applyMiddleware(...middlewares)\n\t\n注意这里有个很有趣的写法，参数：`...middlewares`，这么定义允许我们调用时传入任意个数的中间件函数作为参数。接下来函数将返回一个接受`next`作为参数的函数：\n\n\treturn (next) => (reducer, initialState) => {...}\n\t\n`next`参数是一个被用来创建store的函数，你可以看一下[createStore.js](https://github.com/rackt/redux/blob/master/src/createStore.js)源码的实现细节。最后这个函数返回一个类似`createStore`的函数，不同的是它包含一个由中间件加工过的dispatch实现。\n\n接下来我们通过调用`next`拿到store对象（译者注：\"Next we assign the store implementation to the function responsible for creating the new store (again see createStore.js). \"这句实在翻译不来～）。我们用一个变量保存原始的dispatch函数，最后我们声明一个数组来存储我们创建的中间件链：\n\n\tvar store = next(reducer, initialState);\n\tvar dispatch = store.dispatch;\n\tvar chain = [];\n\t\n接下来的代码将`getState`和调用原始的`dispatch`函数注入给所有的中间件：\n\n\tvar middlewareAPI = {\n  \t\tgetState: store.getState,\n  \t\tdispatch: (action) => dispatch(action)\n\t};\n\n\tchain = middlewares.map(middleware =>\n                    middleware(middlewareAPI));\n\n然后我们根据中间件链创建一个加工过的dispatch实现：\n\n\tdispatch = compose(...chain, store.dispatch);\n\t\n最tm精妙的地方就是上面这行，Redux提供的`compose`工具函数组合了我们的中间件链，`compose`实现如下：\n\n\texport default function compose(...funcs) {\n \t\treturn funcs.reduceRight((composed, f) => f(composed));\n\t}\n\t\n碉堡了！上面的代码展示了中间件调用链是如何创建出来的。中间件调用链的顺序很重要，调用链类似下面这样：\n\n\tmiddlewareI(middlewareJ(middlewareK(store.dispatch)))(action)\n\t\n现在知道为啥我们要掌握复合函数和柯里化概念了吧？最后我们只需要将新的store和调整过的dispatch函数返回即可：\n\n\treturn {\n \t\t...store,\n \t\tdispatch\n\t};\n\t\n上面这种写法意思是返回一个对象，该对象拥有store的所有属性，并增加一个dispatch函数属性，store里自带的那个原始dispatch函数会被覆盖。这种写法会被[Babel](https://babeljs.io/repl/)转化成：\n\n\treturn _extends({}, store, { dispatch: _dispatch });\n\t\n现在让我们将我们的logger中间件注入到dispatch中：\n\n\timport { createStore, applyMiddleware } from ‘redux’;\n\timport loggerMiddleware from ‘logger’;\n\timport rootReducer from ‘../reducers’;\n\n\tconst createStoreWithMiddleware = \n  \t\tapplyMiddleware(loggerMiddleware)(createStore);\n\n\texport default function configureStore(initialState) {\n  \t\treturn createStoreWithMiddleware(rootReducer, initialState);\n\t}\n\t\n\tconst store = configureStore();\n\t\n###异步中间件\n\n我们已经会写基础的中间件了，我们就要玩儿点高深得了，整个能处理异步action的中间件咋样？让我们来看一下[redux-thunk](https://github.com/gaearon/redux-thunk)的更多细节。我们假设有一个包含异步请求的action，如下：\n\n\tfunction fetchQuote(symbol) {\n   \t\trequestQuote(symbol);\n   \t\treturn fetch(`http://www.google.com/finance/info?q=${symbol}`)\n      \t\t\t.then(req => req.json())\n      \t\t\t.then(json => showCurrentQuote(symbol, json));\n\t}\n\n上面代码并没有明显的调用dispatch来分派一个返回promise的action，我们需要使用redux-thunk中间件来延迟dipatch的执行：\n\n\tfunction fetchQuote(symbol) {\n  \t\treturn dispatch => {\n    \t\tdispatch(requestQuote(symbol));\n    \t\treturn fetch(`http://www.google.com/finance/info?q=${symbol}`)\n      \t\t\t\t.then(req => req.json())\n      \t\t\t\t.then(json => dispatch(showCurrentQuote(symbol, json)));\n  \t\t}\n\t}\n\t\n注意这里的`dipatch`\n和`getState`是由`applyMiddleware`函数注入进来的。现在我们就可以分派最终得到的action对象到store的reducers了。下面是类似redux-thunk的实现：\n\n\texport default function thunkMiddleware({ dispatch, getState }) {\n  \t\treturn next => \n     \t\t\taction => \n       \t\t\t\ttypeof action === ‘function’ ? \n         \t\t\t\taction(dispatch, getState) : \n         \t\t\t\tnext(action);\n\t}\n\t\n这个和你之前看到的中间件没什么太大不同。如果得到的action是个函数，就用`dispatch`和`getState`当作参数来调用它，否则就直接分派给store。你可以看一下Redux提供的更详细的[异步示例](https://github.com/rackt/redux/tree/master/examples)。另外还有一个支持promises的中间件是[redux-promise](https://github.com/acdlite/redux-promise)。我觉得选择使用哪个中间件可以根据性能来考量。\n\n###接下来干啥\n\n你现在已经知道Redux的核心代码，你现在可以尝试使用[react-redux](https://github.com/rackt/react-redux)来把Redux整合到你的react项目中了。\n\n如果你还是对函数式编程不太习惯，我鼓励你看一下来自[Brian Lonsdorf](https://twitter.com/drboolean)的优秀文献：\n\n- [Hey Underscore, You are Doing it Wrong! ](http://www.youtube.com/watch?v=m3svKOdZijA)：它介绍了很多函数式编程知识和少量的Underscore内容；\n- [Professor Frisby’s Mostly Adequate Guide to Functional Programming](http://drboolean.gitbooks.io/mostly-adequate-guide/content/index.html)\n\n###总结\n\n希望你已经了解了关于Redux中间件的足够信息，我也希望你掌握了更多的关于函数式编程的知识。我不断的尝试更多更好的函数式编程方法，尽管一开始并不容易，你需要不断的学习和尝试来参悟它的精髓。如果你完全掌握了这篇文章交给你的，那么你已经拥有了足够的信心去投入更多的学习当中。\n\n最后，千万别使用那些你还没有搞明白的第三方类库，你必须确定它会给你的项目带来好处。掌握它的一个好方法就是去阅读它的源码，你将会学到新的编程技术，淘汰那些老的解决方案。将一个工具引入你的项目前，你有责任搞清楚它的细节。\n\n\n\n\n","slug":"[译]Redux中间件深入浅出","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cifjtuyg20000oews2deyibih","comments":1,"layout":"post","photos":[],"link":"","content":"<p>原文地址：<a href=\"https://medium.com/@meagle/understanding-87566abcfb7a\" target=\"_blank\" rel=\"external\">https://medium.com/@meagle/understanding-87566abcfb7a</a></p>\n<hr>\n<p>从2014年二月开始我就在使用facebook的React了，那时候它的版本才v0.9.x。我是从Backbone.js转过来的，当哥了解到Flux的好处和它提倡的单数据流架构时，我就已经决定不在使用Backbone.js提供的models和集合。这里我假设你已经大概了解了Flux，Redux，React和函数式编程的基本知识，在这篇文章中我将尽可能的涵盖所有内容。<br><a id=\"more\"></a><br>Dan的Redux库真的非常简单和出彩儿，我相信每个人都可以借助它开发炫酷屌炸天的前端web应用。但我更想了解一下它的内部实现。我开始了Redux源码的探索，要想能更好的理解源码，你必须非常熟悉函数式编程理念。它的代码写的非常简练，没有扎实的基本功你会觉得非常难看懂。我将尝试带领你了解一些需要用到的函数式编程概念，包括：复合函数，柯里化，和高阶函数等。</p>\n<hr>\n<p>我鼓励你去阅读源码来搞明白reducer函数是如何创建和组合的，action creator函数是如何作用于dispatch方法的，还有如何增加中间件来影响默认的dispatch方法的。这篇文章将会帮你理解一些Redux框架的源码，提升你的函数式编程能力，同时也让你尝试一下部分ES6语法。</p>\n<p>###中间件</p>\n<p>Redux最有趣的一个概念是它允许你通过自定义的中间件来影响你store的dispatch逻辑。然而，当我第一次试图查看<a href=\"http://rackt.github.io/redux/docs/api/applyMiddleware.html\" target=\"_blank\" rel=\"external\">applyMiddleware.js</a>源码时，可把本宝宝吓坏了。所以我只能尝试参照Redux中间件的<a href=\"http://rackt.github.io/redux/docs/api/applyMiddleware.html\" target=\"_blank\" rel=\"external\">文档</a>从功能层面来分析代码。看了下面<a href=\"http://rackt.github.io/redux/docs/api/applyMiddleware.html\" target=\"_blank\" rel=\"external\">这段话</a>，让我找回了面子：</p>\n<blockquote>\n<p>“中间件”这个词听起来很恐怖，但它实际一点都不难。想更好的了解中间件的方法就是看一下那些已经实现了的中间件是怎么工作的，然后尝试自己写一个。函数嵌套写法看起来很恐怖，但是大多数你能找到的中间件，代码都不超过十行，但是它们的强大来自于它们的可嵌套组合性。</p>\n</blockquote>\n<p>区区10行的中间件很容易写，但是你要想明白它们是如何放入中间件调用链，又是如何影响store的diapatch方法的，还真需要一些经验。首先让我们来简单定义一下中间件到底是个啥，并且找一些简单的中间件看一下它们的具体实现方式。关于中间件的定义我能找到的最简单的描述是：</p>\n<blockquote>\n<p>中间件主要被用于分离那些不属于你应用的核心业务逻辑的可被组合起来使用的代码。</p>\n</blockquote>\n<p>听起来不算太复杂，对吧;)</p>\n<p>如果你之前用过<a href=\"http://koajs.com/\" target=\"_blank\" rel=\"external\">Koa.js</a>n，那你可能早就接触过中间件这个概念了。我最早使用中间件是在我用Java Servlet写Filters和用Ruby写类似认证授权，日志，性能监控或一些需要在业务逻辑执行前处理的模块。</p>\n<p>Redux的中间件主要用在store的dispatch函数上。dispatch函数的作用是发送actions给一个或多个reducer来影响应用状态的。中间件可以增强默认的dispatch函数，我们来看一下Redux1.0.1版本的applyMiddleware源码：</p>\n<pre><code>export default function applyMiddleware(...middlewares) {            return (next)  =&gt; \n\n        (reducer, initialState) =&gt; {\n\n              var store = next(reducer, initialState);\n              var dispatch = store.dispatch;\n              var chain = [];\n\n              var middlewareAPI = {\n                getState: store.getState,\n                dispatch: (action) =&gt; dispatch(action)\n              };\n\n              chain = middlewares.map(middleware =&gt;\n                            middleware(middlewareAPI));\n\n              dispatch = compose(...chain, store.dispatch);\n              return {\n                ...store,\n                dispatch\n              };\n           };\n}\n</code></pre><p>就这么点儿代码，就使用了非常多的函数式编程的思想，包括：高阶函数，复合函数，柯里化和ES6语法。一开始我反复读了十遍，然后我疯了:)。让我们先来分别看一些函数式编程的知识，回头再理会上面这段让人不爽的代码。</p>\n<p>###函数式编程概念</p>\n<p>在开始阅读Redux中间件源码之前，你需要先掌握一些函数式编程知识，如果你已经自学成才了请跳过本节。</p>\n<p>####复合函数</p>\n<p>函数式编程是非常理论和非常数学化的。用数学的视角来解释复合函数，如下：</p>\n<pre><code>given:\n    f(x) = x^2 + 3x + 1\n    g(x) = 2x\n\nthen:\n    (f ∘ g)(x) = f(g(x)) = f(2x) = 4x^2 + 6x + 1 \n</code></pre><p>你可以将上面的方式扩展到组合两个或更多个函数这都是可以的。我们再来看个例子，演示组合两个函数并返回一个新的函数：</p>\n<pre><code>var greet = function(x) { return `Hello, ${ x }` };\nvar emote = function(x) { return `${x} :)` };\n\nvar compose = function(f, g) {\n      return function(x) {\n        return f(g(x));\n      }\n}\n\nvar happyGreeting = compose(greet, emote);\n// happyGreeting(“Mark”) -&gt; Hello, Mark :)\n</code></pre><p>我们当然可以组合更多的函数，这里只是给大家简单阐述一下基础概念。更多的常用技巧我们我们可以在Redux的源码中看到。</p>\n<p>####柯里化</p>\n<p>另一个屌炸天的函数式编程概念被称之为：柯里化。（译者注：这段翻译起来太难了，我放弃了，推荐你看<a href=\"http://www.zhangxinxu.com/wordpress/2013/02/js-currying/\" target=\"_blank\" rel=\"external\">这里</a>来了解这个概念）</p>\n<pre><code>var curriedAdd = function(a) {\n    return function(b) {\n        return a + b;\n    };\n};\n\nvar addTen = curriedAdd(10);\naddTen(10); //20\n</code></pre><p>通过柯里化来组合你的函数，你可以创建一个强大的数据处理管道。</p>\n<p>###Redux的Dispatch函数</p>\n<p>Redux的Store有一个dispatch函数，它关注你的应用实现的业务逻辑。你可以用它指派actions到你定义的reducer函数，用以更新你的应用状态。Redux的reducer函数接受一个当前状态参数和一个action参数，并返回一个新的状态对象：</p>\n<pre><code>reducer:: state -&gt; action -&gt; state\n</code></pre><p>指派action很像发送消息，如果我们假设要从一个列表中删除某个元素，action结构一般如下：</p>\n<pre><code>{type: types.DELETE_ITEM, id: 1}\n</code></pre><p>store会指派这个action对象到它所拥有的所有reducer函数来影响应用的状态，然而只有关注删除逻辑的reducer会真的修改状态。在此期间没人会关注到底是谁修改了状态，花了多长时间，或者记录一下变更前后的状态数据镜像。这些非核心关注点都可以交给中间件来完成。</p>\n<p>###Redux Middleware</p>\n<p>Redux中间件被设计成可组合的，会在dispatch方法之前调用的函数。让我们来创建一个简单的日志中间件，它会简单的输出dispatch前后的应用状态。Redux中间件的签名如下：</p>\n<pre><code>middleware:: next -&gt; action -&gt; retVal\n</code></pre><p>我们的logger中间件实现如下：</p>\n<pre><code>export default function createLogger({ getState }) {\n      return (next) =&gt; \n        (action) =&gt; {\n              const console = window.console;\n              const prevState = getState();\n              const returnValue = next(action);\n              const nextState = getState();\n              const actionType = String(action.type);\n              const message = `action ${actionType}`;\n\n              console.log(`%c prev state`, `color: #9E9E9E`, prevState);\n              console.log(`%c action`, `color: #03A9F4`, action);\n              console.log(`%c next state`, `color: #4CAF50`, nextState);\n              return returnValue;\n    };\n}\n</code></pre><p>注意，我们的<code>createLogger</code>接受的<code>getState</code>方法是由<code>applyMiddleware.js</code>注入进来的。使用它可以在内部的闭包中得到应用的当前状态。最后我们返回调用<code>next</code>创建的函数作为结果。<code>next</code>方法用于维护中间件调用链和dispatch，它返回一个接受<code>action</code>对象的柯里化函数，接受的<code>action</code>对象可以在中间件中被修改，再传递给下一个被调用的中间件，最终dispatch会使用中间件修改后的action来执行。</p>\n<p>更健壮的logger中间件实现可以看<a href=\"https://www.npmjs.com/package/redux-logger\" target=\"_blank\" rel=\"external\">这里</a>，为了节省时间，我们的logger中间件实现非常的简陋。</p>\n<p>我们来看看上面的logger中间件的业务流程：</p>\n<ol>\n<li>得到当前的应用状态；</li>\n<li>将action指派给下一个中间件；</li>\n<li>调用链下游的中间件全部被执行；</li>\n<li>store中的匹配reducer被执行；</li>\n<li>此时得到新的应用状态。</li>\n</ol>\n<p>我们这里来看一个拥有2个中间件组件的例子：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*jNHs4JtDn9r00bs4iNSwjA.png\" alt=\"\"></p>\n<p>###剖析applyMiddleware.js</p>\n<p>现在咱们已经知道Redux中间件是个啥，并且也掌握了足够的函数式编程知识，那就让我们再次尝试阅读<code>applyMiddleware.js</code>的源码来探个究竟吧。这次感觉比较好理解了吧：</p>\n<pre><code>export default function applyMiddleware(...middlewares) {            return (next)  =&gt; \n\n        (reducer, initialState) =&gt; {\n\n              var store = next(reducer, initialState);\n              var dispatch = store.dispatch;\n              var chain = [];\n\n              var middlewareAPI = {\n                getState: store.getState,\n                dispatch: (action) =&gt; dispatch(action)\n              };\n\n              chain = middlewares.map(middleware =&gt;\n                            middleware(middlewareAPI));\n\n              dispatch = compose(...chain, store.dispatch);\n              return {\n                ...store,\n                dispatch\n              };\n           };\n}\n</code></pre><p><code>applyMiddleware</code>可能应该起一个更好一点的名字，谁能告诉我这是为谁来“申请中间件”？我觉得可以这么叫：<code>applyMiddlewareToStore</code>，这样是不是更加明确一些？</p>\n<p>我们来一行一行分析代码，首先我们看方法签名：</p>\n<pre><code>export default function applyMiddleware(...middlewares)\n</code></pre><p>注意这里有个很有趣的写法，参数：<code>...middlewares</code>，这么定义允许我们调用时传入任意个数的中间件函数作为参数。接下来函数将返回一个接受<code>next</code>作为参数的函数：</p>\n<pre><code>return (next) =&gt; (reducer, initialState) =&gt; {...}\n</code></pre><p><code>next</code>参数是一个被用来创建store的函数，你可以看一下<a href=\"https://github.com/rackt/redux/blob/master/src/createStore.js\" target=\"_blank\" rel=\"external\">createStore.js</a>源码的实现细节。最后这个函数返回一个类似<code>createStore</code>的函数，不同的是它包含一个由中间件加工过的dispatch实现。</p>\n<p>接下来我们通过调用<code>next</code>拿到store对象（译者注：”Next we assign the store implementation to the function responsible for creating the new store (again see createStore.js). “这句实在翻译不来～）。我们用一个变量保存原始的dispatch函数，最后我们声明一个数组来存储我们创建的中间件链：</p>\n<pre><code>var store = next(reducer, initialState);\nvar dispatch = store.dispatch;\nvar chain = [];\n</code></pre><p>接下来的代码将<code>getState</code>和调用原始的<code>dispatch</code>函数注入给所有的中间件：</p>\n<pre><code>var middlewareAPI = {\n      getState: store.getState,\n      dispatch: (action) =&gt; dispatch(action)\n};\n\nchain = middlewares.map(middleware =&gt;\n                middleware(middlewareAPI));\n</code></pre><p>然后我们根据中间件链创建一个加工过的dispatch实现：</p>\n<pre><code>dispatch = compose(...chain, store.dispatch);\n</code></pre><p>最tm精妙的地方就是上面这行，Redux提供的<code>compose</code>工具函数组合了我们的中间件链，<code>compose</code>实现如下：</p>\n<pre><code>export default function compose(...funcs) {\n     return funcs.reduceRight((composed, f) =&gt; f(composed));\n}\n</code></pre><p>碉堡了！上面的代码展示了中间件调用链是如何创建出来的。中间件调用链的顺序很重要，调用链类似下面这样：</p>\n<pre><code>middlewareI(middlewareJ(middlewareK(store.dispatch)))(action)\n</code></pre><p>现在知道为啥我们要掌握复合函数和柯里化概念了吧？最后我们只需要将新的store和调整过的dispatch函数返回即可：</p>\n<pre><code>return {\n     ...store,\n     dispatch\n};\n</code></pre><p>上面这种写法意思是返回一个对象，该对象拥有store的所有属性，并增加一个dispatch函数属性，store里自带的那个原始dispatch函数会被覆盖。这种写法会被<a href=\"https://babeljs.io/repl/\" target=\"_blank\" rel=\"external\">Babel</a>转化成：</p>\n<pre><code>return _extends({}, store, { dispatch: _dispatch });\n</code></pre><p>现在让我们将我们的logger中间件注入到dispatch中：</p>\n<pre><code>import { createStore, applyMiddleware } from ‘redux’;\nimport loggerMiddleware from ‘logger’;\nimport rootReducer from ‘../reducers’;\n\nconst createStoreWithMiddleware = \n      applyMiddleware(loggerMiddleware)(createStore);\n\nexport default function configureStore(initialState) {\n      return createStoreWithMiddleware(rootReducer, initialState);\n}\n\nconst store = configureStore();\n</code></pre><p>###异步中间件</p>\n<p>我们已经会写基础的中间件了，我们就要玩儿点高深得了，整个能处理异步action的中间件咋样？让我们来看一下<a href=\"https://github.com/gaearon/redux-thunk\" target=\"_blank\" rel=\"external\">redux-thunk</a>的更多细节。我们假设有一个包含异步请求的action，如下：</p>\n<pre><code>function fetchQuote(symbol) {\n       requestQuote(symbol);\n       return fetch(`http://www.google.com/finance/info?q=${symbol}`)\n              .then(req =&gt; req.json())\n              .then(json =&gt; showCurrentQuote(symbol, json));\n}\n</code></pre><p>上面代码并没有明显的调用dispatch来分派一个返回promise的action，我们需要使用redux-thunk中间件来延迟dipatch的执行：</p>\n<pre><code>function fetchQuote(symbol) {\n      return dispatch =&gt; {\n        dispatch(requestQuote(symbol));\n        return fetch(`http://www.google.com/finance/info?q=${symbol}`)\n                  .then(req =&gt; req.json())\n                  .then(json =&gt; dispatch(showCurrentQuote(symbol, json)));\n      }\n}\n</code></pre><p>注意这里的<code>dipatch</code><br>和<code>getState</code>是由<code>applyMiddleware</code>函数注入进来的。现在我们就可以分派最终得到的action对象到store的reducers了。下面是类似redux-thunk的实现：</p>\n<pre><code>export default function thunkMiddleware({ dispatch, getState }) {\n      return next =&gt; \n             action =&gt; \n                   typeof action === ‘function’ ? \n                     action(dispatch, getState) : \n                     next(action);\n}\n</code></pre><p>这个和你之前看到的中间件没什么太大不同。如果得到的action是个函数，就用<code>dispatch</code>和<code>getState</code>当作参数来调用它，否则就直接分派给store。你可以看一下Redux提供的更详细的<a href=\"https://github.com/rackt/redux/tree/master/examples\" target=\"_blank\" rel=\"external\">异步示例</a>。另外还有一个支持promises的中间件是<a href=\"https://github.com/acdlite/redux-promise\" target=\"_blank\" rel=\"external\">redux-promise</a>。我觉得选择使用哪个中间件可以根据性能来考量。</p>\n<p>###接下来干啥</p>\n<p>你现在已经知道Redux的核心代码，你现在可以尝试使用<a href=\"https://github.com/rackt/react-redux\" target=\"_blank\" rel=\"external\">react-redux</a>来把Redux整合到你的react项目中了。</p>\n<p>如果你还是对函数式编程不太习惯，我鼓励你看一下来自<a href=\"https://twitter.com/drboolean\" target=\"_blank\" rel=\"external\">Brian Lonsdorf</a>的优秀文献：</p>\n<ul>\n<li><a href=\"http://www.youtube.com/watch?v=m3svKOdZijA\" target=\"_blank\" rel=\"external\">Hey Underscore, You are Doing it Wrong! </a>：它介绍了很多函数式编程知识和少量的Underscore内容；</li>\n<li><a href=\"http://drboolean.gitbooks.io/mostly-adequate-guide/content/index.html\" target=\"_blank\" rel=\"external\">Professor Frisby’s Mostly Adequate Guide to Functional Programming</a></li>\n</ul>\n<p>###总结</p>\n<p>希望你已经了解了关于Redux中间件的足够信息，我也希望你掌握了更多的关于函数式编程的知识。我不断的尝试更多更好的函数式编程方法，尽管一开始并不容易，你需要不断的学习和尝试来参悟它的精髓。如果你完全掌握了这篇文章交给你的，那么你已经拥有了足够的信心去投入更多的学习当中。</p>\n<p>最后，千万别使用那些你还没有搞明白的第三方类库，你必须确定它会给你的项目带来好处。掌握它的一个好方法就是去阅读它的源码，你将会学到新的编程技术，淘汰那些老的解决方案。将一个工具引入你的项目前，你有责任搞清楚它的细节。</p>\n","excerpt":"<p>原文地址：<a href=\"https://medium.com/@meagle/understanding-87566abcfb7a\">https://medium.com/@meagle/understanding-87566abcfb7a</a></p>\n<hr>\n<p>从2014年二月开始我就在使用facebook的React了，那时候它的版本才v0.9.x。我是从Backbone.js转过来的，当哥了解到Flux的好处和它提倡的单数据流架构时，我就已经决定不在使用Backbone.js提供的models和集合。这里我假设你已经大概了解了Flux，Redux，React和函数式编程的基本知识，在这篇文章中我将尽可能的涵盖所有内容。<br>","more":"<br>Dan的Redux库真的非常简单和出彩儿，我相信每个人都可以借助它开发炫酷屌炸天的前端web应用。但我更想了解一下它的内部实现。我开始了Redux源码的探索，要想能更好的理解源码，你必须非常熟悉函数式编程理念。它的代码写的非常简练，没有扎实的基本功你会觉得非常难看懂。我将尝试带领你了解一些需要用到的函数式编程概念，包括：复合函数，柯里化，和高阶函数等。</p>\n<hr>\n<p>我鼓励你去阅读源码来搞明白reducer函数是如何创建和组合的，action creator函数是如何作用于dispatch方法的，还有如何增加中间件来影响默认的dispatch方法的。这篇文章将会帮你理解一些Redux框架的源码，提升你的函数式编程能力，同时也让你尝试一下部分ES6语法。</p>\n<p>###中间件</p>\n<p>Redux最有趣的一个概念是它允许你通过自定义的中间件来影响你store的dispatch逻辑。然而，当我第一次试图查看<a href=\"http://rackt.github.io/redux/docs/api/applyMiddleware.html\">applyMiddleware.js</a>源码时，可把本宝宝吓坏了。所以我只能尝试参照Redux中间件的<a href=\"http://rackt.github.io/redux/docs/api/applyMiddleware.html\">文档</a>从功能层面来分析代码。看了下面<a href=\"http://rackt.github.io/redux/docs/api/applyMiddleware.html\">这段话</a>，让我找回了面子：</p>\n<blockquote>\n<p>“中间件”这个词听起来很恐怖，但它实际一点都不难。想更好的了解中间件的方法就是看一下那些已经实现了的中间件是怎么工作的，然后尝试自己写一个。函数嵌套写法看起来很恐怖，但是大多数你能找到的中间件，代码都不超过十行，但是它们的强大来自于它们的可嵌套组合性。</p>\n</blockquote>\n<p>区区10行的中间件很容易写，但是你要想明白它们是如何放入中间件调用链，又是如何影响store的diapatch方法的，还真需要一些经验。首先让我们来简单定义一下中间件到底是个啥，并且找一些简单的中间件看一下它们的具体实现方式。关于中间件的定义我能找到的最简单的描述是：</p>\n<blockquote>\n<p>中间件主要被用于分离那些不属于你应用的核心业务逻辑的可被组合起来使用的代码。</p>\n</blockquote>\n<p>听起来不算太复杂，对吧;)</p>\n<p>如果你之前用过<a href=\"http://koajs.com/\">Koa.js</a>n，那你可能早就接触过中间件这个概念了。我最早使用中间件是在我用Java Servlet写Filters和用Ruby写类似认证授权，日志，性能监控或一些需要在业务逻辑执行前处理的模块。</p>\n<p>Redux的中间件主要用在store的dispatch函数上。dispatch函数的作用是发送actions给一个或多个reducer来影响应用状态的。中间件可以增强默认的dispatch函数，我们来看一下Redux1.0.1版本的applyMiddleware源码：</p>\n<pre><code>export default function applyMiddleware(...middlewares) {            return (next)  =&gt; \n\n        (reducer, initialState) =&gt; {\n\n              var store = next(reducer, initialState);\n              var dispatch = store.dispatch;\n              var chain = [];\n\n              var middlewareAPI = {\n                getState: store.getState,\n                dispatch: (action) =&gt; dispatch(action)\n              };\n\n              chain = middlewares.map(middleware =&gt;\n                            middleware(middlewareAPI));\n\n              dispatch = compose(...chain, store.dispatch);\n              return {\n                ...store,\n                dispatch\n              };\n           };\n}\n</code></pre><p>就这么点儿代码，就使用了非常多的函数式编程的思想，包括：高阶函数，复合函数，柯里化和ES6语法。一开始我反复读了十遍，然后我疯了:)。让我们先来分别看一些函数式编程的知识，回头再理会上面这段让人不爽的代码。</p>\n<p>###函数式编程概念</p>\n<p>在开始阅读Redux中间件源码之前，你需要先掌握一些函数式编程知识，如果你已经自学成才了请跳过本节。</p>\n<p>####复合函数</p>\n<p>函数式编程是非常理论和非常数学化的。用数学的视角来解释复合函数，如下：</p>\n<pre><code>given:\n    f(x) = x^2 + 3x + 1\n    g(x) = 2x\n\nthen:\n    (f ∘ g)(x) = f(g(x)) = f(2x) = 4x^2 + 6x + 1 \n</code></pre><p>你可以将上面的方式扩展到组合两个或更多个函数这都是可以的。我们再来看个例子，演示组合两个函数并返回一个新的函数：</p>\n<pre><code>var greet = function(x) { return `Hello, ${ x }` };\nvar emote = function(x) { return `${x} :)` };\n\nvar compose = function(f, g) {\n      return function(x) {\n        return f(g(x));\n      }\n}\n\nvar happyGreeting = compose(greet, emote);\n// happyGreeting(“Mark”) -&gt; Hello, Mark :)\n</code></pre><p>我们当然可以组合更多的函数，这里只是给大家简单阐述一下基础概念。更多的常用技巧我们我们可以在Redux的源码中看到。</p>\n<p>####柯里化</p>\n<p>另一个屌炸天的函数式编程概念被称之为：柯里化。（译者注：这段翻译起来太难了，我放弃了，推荐你看<a href=\"http://www.zhangxinxu.com/wordpress/2013/02/js-currying/\">这里</a>来了解这个概念）</p>\n<pre><code>var curriedAdd = function(a) {\n    return function(b) {\n        return a + b;\n    };\n};\n\nvar addTen = curriedAdd(10);\naddTen(10); //20\n</code></pre><p>通过柯里化来组合你的函数，你可以创建一个强大的数据处理管道。</p>\n<p>###Redux的Dispatch函数</p>\n<p>Redux的Store有一个dispatch函数，它关注你的应用实现的业务逻辑。你可以用它指派actions到你定义的reducer函数，用以更新你的应用状态。Redux的reducer函数接受一个当前状态参数和一个action参数，并返回一个新的状态对象：</p>\n<pre><code>reducer:: state -&gt; action -&gt; state\n</code></pre><p>指派action很像发送消息，如果我们假设要从一个列表中删除某个元素，action结构一般如下：</p>\n<pre><code>{type: types.DELETE_ITEM, id: 1}\n</code></pre><p>store会指派这个action对象到它所拥有的所有reducer函数来影响应用的状态，然而只有关注删除逻辑的reducer会真的修改状态。在此期间没人会关注到底是谁修改了状态，花了多长时间，或者记录一下变更前后的状态数据镜像。这些非核心关注点都可以交给中间件来完成。</p>\n<p>###Redux Middleware</p>\n<p>Redux中间件被设计成可组合的，会在dispatch方法之前调用的函数。让我们来创建一个简单的日志中间件，它会简单的输出dispatch前后的应用状态。Redux中间件的签名如下：</p>\n<pre><code>middleware:: next -&gt; action -&gt; retVal\n</code></pre><p>我们的logger中间件实现如下：</p>\n<pre><code>export default function createLogger({ getState }) {\n      return (next) =&gt; \n        (action) =&gt; {\n              const console = window.console;\n              const prevState = getState();\n              const returnValue = next(action);\n              const nextState = getState();\n              const actionType = String(action.type);\n              const message = `action ${actionType}`;\n\n              console.log(`%c prev state`, `color: #9E9E9E`, prevState);\n              console.log(`%c action`, `color: #03A9F4`, action);\n              console.log(`%c next state`, `color: #4CAF50`, nextState);\n              return returnValue;\n    };\n}\n</code></pre><p>注意，我们的<code>createLogger</code>接受的<code>getState</code>方法是由<code>applyMiddleware.js</code>注入进来的。使用它可以在内部的闭包中得到应用的当前状态。最后我们返回调用<code>next</code>创建的函数作为结果。<code>next</code>方法用于维护中间件调用链和dispatch，它返回一个接受<code>action</code>对象的柯里化函数，接受的<code>action</code>对象可以在中间件中被修改，再传递给下一个被调用的中间件，最终dispatch会使用中间件修改后的action来执行。</p>\n<p>更健壮的logger中间件实现可以看<a href=\"https://www.npmjs.com/package/redux-logger\">这里</a>，为了节省时间，我们的logger中间件实现非常的简陋。</p>\n<p>我们来看看上面的logger中间件的业务流程：</p>\n<ol>\n<li>得到当前的应用状态；</li>\n<li>将action指派给下一个中间件；</li>\n<li>调用链下游的中间件全部被执行；</li>\n<li>store中的匹配reducer被执行；</li>\n<li>此时得到新的应用状态。</li>\n</ol>\n<p>我们这里来看一个拥有2个中间件组件的例子：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*jNHs4JtDn9r00bs4iNSwjA.png\" alt=\"\"></p>\n<p>###剖析applyMiddleware.js</p>\n<p>现在咱们已经知道Redux中间件是个啥，并且也掌握了足够的函数式编程知识，那就让我们再次尝试阅读<code>applyMiddleware.js</code>的源码来探个究竟吧。这次感觉比较好理解了吧：</p>\n<pre><code>export default function applyMiddleware(...middlewares) {            return (next)  =&gt; \n\n        (reducer, initialState) =&gt; {\n\n              var store = next(reducer, initialState);\n              var dispatch = store.dispatch;\n              var chain = [];\n\n              var middlewareAPI = {\n                getState: store.getState,\n                dispatch: (action) =&gt; dispatch(action)\n              };\n\n              chain = middlewares.map(middleware =&gt;\n                            middleware(middlewareAPI));\n\n              dispatch = compose(...chain, store.dispatch);\n              return {\n                ...store,\n                dispatch\n              };\n           };\n}\n</code></pre><p><code>applyMiddleware</code>可能应该起一个更好一点的名字，谁能告诉我这是为谁来“申请中间件”？我觉得可以这么叫：<code>applyMiddlewareToStore</code>，这样是不是更加明确一些？</p>\n<p>我们来一行一行分析代码，首先我们看方法签名：</p>\n<pre><code>export default function applyMiddleware(...middlewares)\n</code></pre><p>注意这里有个很有趣的写法，参数：<code>...middlewares</code>，这么定义允许我们调用时传入任意个数的中间件函数作为参数。接下来函数将返回一个接受<code>next</code>作为参数的函数：</p>\n<pre><code>return (next) =&gt; (reducer, initialState) =&gt; {...}\n</code></pre><p><code>next</code>参数是一个被用来创建store的函数，你可以看一下<a href=\"https://github.com/rackt/redux/blob/master/src/createStore.js\">createStore.js</a>源码的实现细节。最后这个函数返回一个类似<code>createStore</code>的函数，不同的是它包含一个由中间件加工过的dispatch实现。</p>\n<p>接下来我们通过调用<code>next</code>拿到store对象（译者注：”Next we assign the store implementation to the function responsible for creating the new store (again see createStore.js). “这句实在翻译不来～）。我们用一个变量保存原始的dispatch函数，最后我们声明一个数组来存储我们创建的中间件链：</p>\n<pre><code>var store = next(reducer, initialState);\nvar dispatch = store.dispatch;\nvar chain = [];\n</code></pre><p>接下来的代码将<code>getState</code>和调用原始的<code>dispatch</code>函数注入给所有的中间件：</p>\n<pre><code>var middlewareAPI = {\n      getState: store.getState,\n      dispatch: (action) =&gt; dispatch(action)\n};\n\nchain = middlewares.map(middleware =&gt;\n                middleware(middlewareAPI));\n</code></pre><p>然后我们根据中间件链创建一个加工过的dispatch实现：</p>\n<pre><code>dispatch = compose(...chain, store.dispatch);\n</code></pre><p>最tm精妙的地方就是上面这行，Redux提供的<code>compose</code>工具函数组合了我们的中间件链，<code>compose</code>实现如下：</p>\n<pre><code>export default function compose(...funcs) {\n     return funcs.reduceRight((composed, f) =&gt; f(composed));\n}\n</code></pre><p>碉堡了！上面的代码展示了中间件调用链是如何创建出来的。中间件调用链的顺序很重要，调用链类似下面这样：</p>\n<pre><code>middlewareI(middlewareJ(middlewareK(store.dispatch)))(action)\n</code></pre><p>现在知道为啥我们要掌握复合函数和柯里化概念了吧？最后我们只需要将新的store和调整过的dispatch函数返回即可：</p>\n<pre><code>return {\n     ...store,\n     dispatch\n};\n</code></pre><p>上面这种写法意思是返回一个对象，该对象拥有store的所有属性，并增加一个dispatch函数属性，store里自带的那个原始dispatch函数会被覆盖。这种写法会被<a href=\"https://babeljs.io/repl/\">Babel</a>转化成：</p>\n<pre><code>return _extends({}, store, { dispatch: _dispatch });\n</code></pre><p>现在让我们将我们的logger中间件注入到dispatch中：</p>\n<pre><code>import { createStore, applyMiddleware } from ‘redux’;\nimport loggerMiddleware from ‘logger’;\nimport rootReducer from ‘../reducers’;\n\nconst createStoreWithMiddleware = \n      applyMiddleware(loggerMiddleware)(createStore);\n\nexport default function configureStore(initialState) {\n      return createStoreWithMiddleware(rootReducer, initialState);\n}\n\nconst store = configureStore();\n</code></pre><p>###异步中间件</p>\n<p>我们已经会写基础的中间件了，我们就要玩儿点高深得了，整个能处理异步action的中间件咋样？让我们来看一下<a href=\"https://github.com/gaearon/redux-thunk\">redux-thunk</a>的更多细节。我们假设有一个包含异步请求的action，如下：</p>\n<pre><code>function fetchQuote(symbol) {\n       requestQuote(symbol);\n       return fetch(`http://www.google.com/finance/info?q=${symbol}`)\n              .then(req =&gt; req.json())\n              .then(json =&gt; showCurrentQuote(symbol, json));\n}\n</code></pre><p>上面代码并没有明显的调用dispatch来分派一个返回promise的action，我们需要使用redux-thunk中间件来延迟dipatch的执行：</p>\n<pre><code>function fetchQuote(symbol) {\n      return dispatch =&gt; {\n        dispatch(requestQuote(symbol));\n        return fetch(`http://www.google.com/finance/info?q=${symbol}`)\n                  .then(req =&gt; req.json())\n                  .then(json =&gt; dispatch(showCurrentQuote(symbol, json)));\n      }\n}\n</code></pre><p>注意这里的<code>dipatch</code><br>和<code>getState</code>是由<code>applyMiddleware</code>函数注入进来的。现在我们就可以分派最终得到的action对象到store的reducers了。下面是类似redux-thunk的实现：</p>\n<pre><code>export default function thunkMiddleware({ dispatch, getState }) {\n      return next =&gt; \n             action =&gt; \n                   typeof action === ‘function’ ? \n                     action(dispatch, getState) : \n                     next(action);\n}\n</code></pre><p>这个和你之前看到的中间件没什么太大不同。如果得到的action是个函数，就用<code>dispatch</code>和<code>getState</code>当作参数来调用它，否则就直接分派给store。你可以看一下Redux提供的更详细的<a href=\"https://github.com/rackt/redux/tree/master/examples\">异步示例</a>。另外还有一个支持promises的中间件是<a href=\"https://github.com/acdlite/redux-promise\">redux-promise</a>。我觉得选择使用哪个中间件可以根据性能来考量。</p>\n<p>###接下来干啥</p>\n<p>你现在已经知道Redux的核心代码，你现在可以尝试使用<a href=\"https://github.com/rackt/react-redux\">react-redux</a>来把Redux整合到你的react项目中了。</p>\n<p>如果你还是对函数式编程不太习惯，我鼓励你看一下来自<a href=\"https://twitter.com/drboolean\">Brian Lonsdorf</a>的优秀文献：</p>\n<ul>\n<li><a href=\"http://www.youtube.com/watch?v=m3svKOdZijA\">Hey Underscore, You are Doing it Wrong! </a>：它介绍了很多函数式编程知识和少量的Underscore内容；</li>\n<li><a href=\"http://drboolean.gitbooks.io/mostly-adequate-guide/content/index.html\">Professor Frisby’s Mostly Adequate Guide to Functional Programming</a></li>\n</ul>\n<p>###总结</p>\n<p>希望你已经了解了关于Redux中间件的足够信息，我也希望你掌握了更多的关于函数式编程的知识。我不断的尝试更多更好的函数式编程方法，尽管一开始并不容易，你需要不断的学习和尝试来参悟它的精髓。如果你完全掌握了这篇文章交给你的，那么你已经拥有了足够的信心去投入更多的学习当中。</p>\n<p>最后，千万别使用那些你还没有搞明白的第三方类库，你必须确定它会给你的项目带来好处。掌握它的一个好方法就是去阅读它的源码，你将会学到新的编程技术，淘汰那些老的解决方案。将一个工具引入你的项目前，你有责任搞清楚它的细节。</p>"},{"title":"Webpack科普","date":"2015-10-14T01:37:12.000Z","_content":"\n到底什么是[webpack](http://webpack.github.io)。\n<!--more-->\n![webpack](http://webpack.github.io/assets/what-is-webpack.png)\n\n一图蔽之，这就是它。我贴一些找到的感觉还不错的文章来加速大家的了解：\n\n[深入浅出React（二）：React开发神器Webpack](http://www.infoq.com/cn/articles/react-and-webpack#show-last-Point)\n\n[Webpack 怎么用](http://segmentfault.com/a/1190000002552008)\n\n[webpack和react小书](https://fakefish.github.io/react-webpack-cookbook/Introduction-to-Webpack.html)\n\n[Webpack 性能优化 （一）](http://code.oneapm.com/javascript/2015/07/07/webpack_performance_1/)\n\n[webpack文档中文版](https://github.com/liunian/webpack-doc/blob/master/SUMMARY.md)","source":"_posts/Webpack科普.md","raw":"title: Webpack科普\ndate: 2015-10-14 09:37:12\ntags: \n- webpack\ncategories: 前端\n---\n\n到底什么是[webpack](http://webpack.github.io)。\n<!--more-->\n![webpack](http://webpack.github.io/assets/what-is-webpack.png)\n\n一图蔽之，这就是它。我贴一些找到的感觉还不错的文章来加速大家的了解：\n\n[深入浅出React（二）：React开发神器Webpack](http://www.infoq.com/cn/articles/react-and-webpack#show-last-Point)\n\n[Webpack 怎么用](http://segmentfault.com/a/1190000002552008)\n\n[webpack和react小书](https://fakefish.github.io/react-webpack-cookbook/Introduction-to-Webpack.html)\n\n[Webpack 性能优化 （一）](http://code.oneapm.com/javascript/2015/07/07/webpack_performance_1/)\n\n[webpack文档中文版](https://github.com/liunian/webpack-doc/blob/master/SUMMARY.md)","slug":"Webpack科普","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cifqxchx70000hkws8msk5nxp","comments":1,"layout":"post","photos":[],"link":"","content":"<p>到底什么是<a href=\"http://webpack.github.io\" target=\"_blank\" rel=\"external\">webpack</a>。<br><a id=\"more\"></a><br><img src=\"http://webpack.github.io/assets/what-is-webpack.png\" alt=\"webpack\"></p>\n<p>一图蔽之，这就是它。我贴一些找到的感觉还不错的文章来加速大家的了解：</p>\n<p><a href=\"http://www.infoq.com/cn/articles/react-and-webpack#show-last-Point\" target=\"_blank\" rel=\"external\">深入浅出React（二）：React开发神器Webpack</a></p>\n<p><a href=\"http://segmentfault.com/a/1190000002552008\" target=\"_blank\" rel=\"external\">Webpack 怎么用</a></p>\n<p><a href=\"https://fakefish.github.io/react-webpack-cookbook/Introduction-to-Webpack.html\" target=\"_blank\" rel=\"external\">webpack和react小书</a></p>\n<p><a href=\"http://code.oneapm.com/javascript/2015/07/07/webpack_performance_1/\" target=\"_blank\" rel=\"external\">Webpack 性能优化 （一）</a></p>\n<p><a href=\"https://github.com/liunian/webpack-doc/blob/master/SUMMARY.md\" target=\"_blank\" rel=\"external\">webpack文档中文版</a></p>\n","excerpt":"<p>到底什么是<a href=\"http://webpack.github.io\">webpack</a>。<br>","more":"<br><img src=\"http://webpack.github.io/assets/what-is-webpack.png\" alt=\"webpack\"></p>\n<p>一图蔽之，这就是它。我贴一些找到的感觉还不错的文章来加速大家的了解：</p>\n<p><a href=\"http://www.infoq.com/cn/articles/react-and-webpack#show-last-Point\">深入浅出React（二）：React开发神器Webpack</a></p>\n<p><a href=\"http://segmentfault.com/a/1190000002552008\">Webpack 怎么用</a></p>\n<p><a href=\"https://fakefish.github.io/react-webpack-cookbook/Introduction-to-Webpack.html\">webpack和react小书</a></p>\n<p><a href=\"http://code.oneapm.com/javascript/2015/07/07/webpack_performance_1/\">Webpack 性能优化 （一）</a></p>\n<p><a href=\"https://github.com/liunian/webpack-doc/blob/master/SUMMARY.md\">webpack文档中文版</a></p>"},{"title":"react-router的组件生命周期","date":"2015-10-24T01:37:12.000Z","_content":"\n昨天碰到个[问题](http://segmentfault.com/q/1010000003899542)，GG了半天也没有发现一篇对应主题的文章，最后还是在react-router的github官方求助，才被热心的大牛给上了一课，其实这也都怪自己没有耐心仔细阅读react-router的官方资料，下面就来简单汉化一下官方针对这个问题的相关解释。\n\n以下内容翻译自官方文档，原文链接：[https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md](https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md)\n\n<!--more-->\n\n---\n\n##Component Lifecycle\n\n理解router在其生命周中会触发哪些hooks调用对于实现你的应用场景非常重要，常见的场景是何时抓取数据。\n\n在router中组件的生命周期和react中定义的并没有什么不同，让我们来假设一个场景，其route配置如下：\n\n\t<Route path=\"/\" component={App}>\n  \t\t<IndexRoute component={Home}/>\n  \t\t<Route path=\"invoices/:invoiceId\" component={Invoice}/>\n  \t\t<Route path=\"accounts/:accountId\" component={Account}/>\n\t</Route>\n\t\n###Lifecycle hooks when routing\n\n1. 我们假设用户访问应用的\"/\"页面。\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | `componentDidMount` |\n    | Home | `componentDidMount` |\n    | Invoice | N/A |\n    | Account | N/A |\n    \n2. 然后，用户从\"/\"页面跳转到\"/invoice/123\"\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | `componentWillReceiveProps`, `componentDidUpdate` |\n    | Home | `componentWillUnmount` |\n    | Invoice | `componentDidMount` |\n    | Account | N/A | \n\n\t- `App`组件由于之前已经被渲染过，但是由于将会从router中接受到新的props（`children`，`params`，`location`等），所以会调用其`componentWillReceiveProps`和`componentDidUpdate`方法\n\t- `Home`组件此时已经不再需要了，所以它会被卸载\n\t- `Invoice`组件此时将会被首次渲染\n\t\n3. 再然后，用户从\"/invoice/123\"页面跳转到\"/invoice/789\"\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | componentWillReceiveProps, componentDidUpdate |\n    | Home | N/A |\n    | Invoice | componentWillReceiveProps, componentDidUpdate |\n    | Account | N/A |\n\t\n\t这次所有需要的组件之前都已经被加载了，此时它们都会接收到来自router传递的新props。\n\t\n4. 最后，用户从\"/invoice/789\"页面跳转访问\"/accounts/123\"\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | componentWillReceiveProps, componentDidUpdate |\n    | Home | N/A |\n    | Invoice | componentWillUnmount |\n    | Account | componentDidMount |\n\n###Fetching Data\n\n在使用router时有很多种方法来获取数据，其中最简单的一种方式就是利用组件的生命周期hooks，并保存数据在组件的state中（译者：这一点在Redux设计理念中被强烈反对，事实证明即便是不依赖state，这种方式照样可行，我们后面会给出例子）。我们已经知道了当router切换时组件的生命周期hooks调用过程，我们来为之前的`Invoice`组件来实现一个简单的获取数据逻辑。\n\n\tlet Invoice = React.createClass({\n\n  \t\tgetInitialState () {\n    \t\treturn {\n      \t\t\tinvoice: null\n    \t\t}\n  \t\t},\n\n  \t\tcomponentDidMount () {\n    \t\t// fetch data initially in scenario 2 from above\n    \t\tthis.fetchInvoice()\n  \t\t},\n\n  \t\tcomponentDidUpdate (prevProps) {\n    \t\t// respond to parameter change in scenario 3\n    \t\tlet oldId = prevProps.params.invoiceId\n    \t\tlet newId = this.props.params.invoiceId\n    \t\tif (newId !== oldId)\n      \t\t\tthis.fetchInvoice()\n  \t\t},\n\n  \t\tcomponentWillUnmount () {\n    \t\t// allows us to ignore an inflight request in scenario 4\n    \t\tthis.ignoreLastFetch = true\n  \t\t},\n\n  \t\tfetchInvoice () {\n    \t\tlet url = `/api/invoices/${this.props.params.invoiceId}`\n    \t\tthis.request = fetch(url, (err, data) => {\n      \t\tif (!this.ignoreLastFetch)\n        \t\tthis.setState({ invoice: data.invoice })\n    \t\t})\n  \t\t},\n\n  \t\trender () {\n    \t\treturn <InvoiceView invoice={this.state.invoice}/>\n  \t\t}\n\t})\n\t\n---\n\n##译者总结\n\n在本篇开头我的那篇问题贴中已描述场景，由于我一直以来对react的生命周期hooks错误的理解，导致死活无法优雅的实现兼容浏览器前进后退操作的组件。经过上面内容的学习，一切都不在话下。\n\n首先，我之前总是习惯使用`componentWillMount`方法来初始化组件的状态，事实证明这种写法并非适用于所有场景（尽管使用它也可以，但至少不是更多人推荐的）。其次，尽可能避免让组件包含太多会话状态，保证组件的纯净。\n\n在我的代码中，更改后的完美版本如下：\n\n（算了，想了想这部分代码的附加逻辑太多，不适合用来阐述上述观点，还是不贴了～）","source":"_posts/react-router的组件生命周期.md","raw":"title: react-router的组件生命周期\ndate: 2015-10-24 09:37:12\ntags: \n- react\n- react-router\n- lifecycle\n- 组件生命周期\n- componentDidUpdate\ncategories: 前端\n---\n\n昨天碰到个[问题](http://segmentfault.com/q/1010000003899542)，GG了半天也没有发现一篇对应主题的文章，最后还是在react-router的github官方求助，才被热心的大牛给上了一课，其实这也都怪自己没有耐心仔细阅读react-router的官方资料，下面就来简单汉化一下官方针对这个问题的相关解释。\n\n以下内容翻译自官方文档，原文链接：[https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md](https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md)\n\n<!--more-->\n\n---\n\n##Component Lifecycle\n\n理解router在其生命周中会触发哪些hooks调用对于实现你的应用场景非常重要，常见的场景是何时抓取数据。\n\n在router中组件的生命周期和react中定义的并没有什么不同，让我们来假设一个场景，其route配置如下：\n\n\t<Route path=\"/\" component={App}>\n  \t\t<IndexRoute component={Home}/>\n  \t\t<Route path=\"invoices/:invoiceId\" component={Invoice}/>\n  \t\t<Route path=\"accounts/:accountId\" component={Account}/>\n\t</Route>\n\t\n###Lifecycle hooks when routing\n\n1. 我们假设用户访问应用的\"/\"页面。\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | `componentDidMount` |\n    | Home | `componentDidMount` |\n    | Invoice | N/A |\n    | Account | N/A |\n    \n2. 然后，用户从\"/\"页面跳转到\"/invoice/123\"\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | `componentWillReceiveProps`, `componentDidUpdate` |\n    | Home | `componentWillUnmount` |\n    | Invoice | `componentDidMount` |\n    | Account | N/A | \n\n\t- `App`组件由于之前已经被渲染过，但是由于将会从router中接受到新的props（`children`，`params`，`location`等），所以会调用其`componentWillReceiveProps`和`componentDidUpdate`方法\n\t- `Home`组件此时已经不再需要了，所以它会被卸载\n\t- `Invoice`组件此时将会被首次渲染\n\t\n3. 再然后，用户从\"/invoice/123\"页面跳转到\"/invoice/789\"\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | componentWillReceiveProps, componentDidUpdate |\n    | Home | N/A |\n    | Invoice | componentWillReceiveProps, componentDidUpdate |\n    | Account | N/A |\n\t\n\t这次所有需要的组件之前都已经被加载了，此时它们都会接收到来自router传递的新props。\n\t\n4. 最后，用户从\"/invoice/789\"页面跳转访问\"/accounts/123\"\n\n\t| 组件 | 生命周期内的hooks调用 |\n    |-----------|------------------------|\n    | App | componentWillReceiveProps, componentDidUpdate |\n    | Home | N/A |\n    | Invoice | componentWillUnmount |\n    | Account | componentDidMount |\n\n###Fetching Data\n\n在使用router时有很多种方法来获取数据，其中最简单的一种方式就是利用组件的生命周期hooks，并保存数据在组件的state中（译者：这一点在Redux设计理念中被强烈反对，事实证明即便是不依赖state，这种方式照样可行，我们后面会给出例子）。我们已经知道了当router切换时组件的生命周期hooks调用过程，我们来为之前的`Invoice`组件来实现一个简单的获取数据逻辑。\n\n\tlet Invoice = React.createClass({\n\n  \t\tgetInitialState () {\n    \t\treturn {\n      \t\t\tinvoice: null\n    \t\t}\n  \t\t},\n\n  \t\tcomponentDidMount () {\n    \t\t// fetch data initially in scenario 2 from above\n    \t\tthis.fetchInvoice()\n  \t\t},\n\n  \t\tcomponentDidUpdate (prevProps) {\n    \t\t// respond to parameter change in scenario 3\n    \t\tlet oldId = prevProps.params.invoiceId\n    \t\tlet newId = this.props.params.invoiceId\n    \t\tif (newId !== oldId)\n      \t\t\tthis.fetchInvoice()\n  \t\t},\n\n  \t\tcomponentWillUnmount () {\n    \t\t// allows us to ignore an inflight request in scenario 4\n    \t\tthis.ignoreLastFetch = true\n  \t\t},\n\n  \t\tfetchInvoice () {\n    \t\tlet url = `/api/invoices/${this.props.params.invoiceId}`\n    \t\tthis.request = fetch(url, (err, data) => {\n      \t\tif (!this.ignoreLastFetch)\n        \t\tthis.setState({ invoice: data.invoice })\n    \t\t})\n  \t\t},\n\n  \t\trender () {\n    \t\treturn <InvoiceView invoice={this.state.invoice}/>\n  \t\t}\n\t})\n\t\n---\n\n##译者总结\n\n在本篇开头我的那篇问题贴中已描述场景，由于我一直以来对react的生命周期hooks错误的理解，导致死活无法优雅的实现兼容浏览器前进后退操作的组件。经过上面内容的学习，一切都不在话下。\n\n首先，我之前总是习惯使用`componentWillMount`方法来初始化组件的状态，事实证明这种写法并非适用于所有场景（尽管使用它也可以，但至少不是更多人推荐的）。其次，尽可能避免让组件包含太多会话状态，保证组件的纯净。\n\n在我的代码中，更改后的完美版本如下：\n\n（算了，想了想这部分代码的附加逻辑太多，不适合用来阐述上述观点，还是不贴了～）","slug":"react-router的组件生命周期","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cig4tt4vc0000suws6k37qbcu","comments":1,"layout":"post","photos":[],"link":"","content":"<p>昨天碰到个<a href=\"http://segmentfault.com/q/1010000003899542\" target=\"_blank\" rel=\"external\">问题</a>，GG了半天也没有发现一篇对应主题的文章，最后还是在react-router的github官方求助，才被热心的大牛给上了一课，其实这也都怪自己没有耐心仔细阅读react-router的官方资料，下面就来简单汉化一下官方针对这个问题的相关解释。</p>\n<p>以下内容翻译自官方文档，原文链接：<a href=\"https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md\" target=\"_blank\" rel=\"external\">https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md</a></p>\n<a id=\"more\"></a>\n<hr>\n<p>##Component Lifecycle</p>\n<p>理解router在其生命周中会触发哪些hooks调用对于实现你的应用场景非常重要，常见的场景是何时抓取数据。</p>\n<p>在router中组件的生命周期和react中定义的并没有什么不同，让我们来假设一个场景，其route配置如下：</p>\n<pre><code>&lt;Route path=&quot;/&quot; component={App}&gt;\n      &lt;IndexRoute component={Home}/&gt;\n      &lt;Route path=&quot;invoices/:invoiceId&quot; component={Invoice}/&gt;\n      &lt;Route path=&quot;accounts/:accountId&quot; component={Account}/&gt;\n&lt;/Route&gt;\n</code></pre><p>###Lifecycle hooks when routing</p>\n<ol>\n<li><p>我们假设用户访问应用的”/“页面。</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | <code>componentDidMount</code> |<br> | Home | <code>componentDidMount</code> |<br> | Invoice | N/A |<br> | Account | N/A |</p>\n</li>\n<li><p>然后，用户从”/“页面跳转到”/invoice/123”</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | <code>componentWillReceiveProps</code>, <code>componentDidUpdate</code> |<br> | Home | <code>componentWillUnmount</code> |<br> | Invoice | <code>componentDidMount</code> |<br> | Account | N/A | </p>\n<ul>\n<li><code>App</code>组件由于之前已经被渲染过，但是由于将会从router中接受到新的props（<code>children</code>，<code>params</code>，<code>location</code>等），所以会调用其<code>componentWillReceiveProps</code>和<code>componentDidUpdate</code>方法</li>\n<li><code>Home</code>组件此时已经不再需要了，所以它会被卸载</li>\n<li><code>Invoice</code>组件此时将会被首次渲染</li>\n</ul>\n</li>\n<li><p>再然后，用户从”/invoice/123”页面跳转到”/invoice/789”</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | componentWillReceiveProps, componentDidUpdate |<br> | Home | N/A |<br> | Invoice | componentWillReceiveProps, componentDidUpdate |<br> | Account | N/A |</p>\n<p> 这次所有需要的组件之前都已经被加载了，此时它们都会接收到来自router传递的新props。</p>\n</li>\n<li><p>最后，用户从”/invoice/789”页面跳转访问”/accounts/123”</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | componentWillReceiveProps, componentDidUpdate |<br> | Home | N/A |<br> | Invoice | componentWillUnmount |<br> | Account | componentDidMount |</p>\n</li>\n</ol>\n<p>###Fetching Data</p>\n<p>在使用router时有很多种方法来获取数据，其中最简单的一种方式就是利用组件的生命周期hooks，并保存数据在组件的state中（译者：这一点在Redux设计理念中被强烈反对，事实证明即便是不依赖state，这种方式照样可行，我们后面会给出例子）。我们已经知道了当router切换时组件的生命周期hooks调用过程，我们来为之前的<code>Invoice</code>组件来实现一个简单的获取数据逻辑。</p>\n<pre><code>let Invoice = React.createClass({\n\n      getInitialState () {\n        return {\n              invoice: null\n        }\n      },\n\n      componentDidMount () {\n        // fetch data initially in scenario 2 from above\n        this.fetchInvoice()\n      },\n\n      componentDidUpdate (prevProps) {\n        // respond to parameter change in scenario 3\n        let oldId = prevProps.params.invoiceId\n        let newId = this.props.params.invoiceId\n        if (newId !== oldId)\n              this.fetchInvoice()\n      },\n\n      componentWillUnmount () {\n        // allows us to ignore an inflight request in scenario 4\n        this.ignoreLastFetch = true\n      },\n\n      fetchInvoice () {\n        let url = `/api/invoices/${this.props.params.invoiceId}`\n        this.request = fetch(url, (err, data) =&gt; {\n          if (!this.ignoreLastFetch)\n            this.setState({ invoice: data.invoice })\n        })\n      },\n\n      render () {\n        return &lt;InvoiceView invoice={this.state.invoice}/&gt;\n      }\n})\n</code></pre><hr>\n<p>##译者总结</p>\n<p>在本篇开头我的那篇问题贴中已描述场景，由于我一直以来对react的生命周期hooks错误的理解，导致死活无法优雅的实现兼容浏览器前进后退操作的组件。经过上面内容的学习，一切都不在话下。</p>\n<p>首先，我之前总是习惯使用<code>componentWillMount</code>方法来初始化组件的状态，事实证明这种写法并非适用于所有场景（尽管使用它也可以，但至少不是更多人推荐的）。其次，尽可能避免让组件包含太多会话状态，保证组件的纯净。</p>\n<p>在我的代码中，更改后的完美版本如下：</p>\n<p>（算了，想了想这部分代码的附加逻辑太多，不适合用来阐述上述观点，还是不贴了～）</p>\n","excerpt":"<p>昨天碰到个<a href=\"http://segmentfault.com/q/1010000003899542\">问题</a>，GG了半天也没有发现一篇对应主题的文章，最后还是在react-router的github官方求助，才被热心的大牛给上了一课，其实这也都怪自己没有耐心仔细阅读react-router的官方资料，下面就来简单汉化一下官方针对这个问题的相关解释。</p>\n<p>以下内容翻译自官方文档，原文链接：<a href=\"https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md\">https://github.com/rackt/react-router/blob/master/docs/guides/advanced/ComponentLifecycle.md</a></p>","more":"<hr>\n<p>##Component Lifecycle</p>\n<p>理解router在其生命周中会触发哪些hooks调用对于实现你的应用场景非常重要，常见的场景是何时抓取数据。</p>\n<p>在router中组件的生命周期和react中定义的并没有什么不同，让我们来假设一个场景，其route配置如下：</p>\n<pre><code>&lt;Route path=&quot;/&quot; component={App}&gt;\n      &lt;IndexRoute component={Home}/&gt;\n      &lt;Route path=&quot;invoices/:invoiceId&quot; component={Invoice}/&gt;\n      &lt;Route path=&quot;accounts/:accountId&quot; component={Account}/&gt;\n&lt;/Route&gt;\n</code></pre><p>###Lifecycle hooks when routing</p>\n<ol>\n<li><p>我们假设用户访问应用的”/“页面。</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | <code>componentDidMount</code> |<br> | Home | <code>componentDidMount</code> |<br> | Invoice | N/A |<br> | Account | N/A |</p>\n</li>\n<li><p>然后，用户从”/“页面跳转到”/invoice/123”</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | <code>componentWillReceiveProps</code>, <code>componentDidUpdate</code> |<br> | Home | <code>componentWillUnmount</code> |<br> | Invoice | <code>componentDidMount</code> |<br> | Account | N/A | </p>\n<ul>\n<li><code>App</code>组件由于之前已经被渲染过，但是由于将会从router中接受到新的props（<code>children</code>，<code>params</code>，<code>location</code>等），所以会调用其<code>componentWillReceiveProps</code>和<code>componentDidUpdate</code>方法</li>\n<li><code>Home</code>组件此时已经不再需要了，所以它会被卸载</li>\n<li><code>Invoice</code>组件此时将会被首次渲染</li>\n</ul>\n</li>\n<li><p>再然后，用户从”/invoice/123”页面跳转到”/invoice/789”</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | componentWillReceiveProps, componentDidUpdate |<br> | Home | N/A |<br> | Invoice | componentWillReceiveProps, componentDidUpdate |<br> | Account | N/A |</p>\n<p> 这次所有需要的组件之前都已经被加载了，此时它们都会接收到来自router传递的新props。</p>\n</li>\n<li><p>最后，用户从”/invoice/789”页面跳转访问”/accounts/123”</p>\n<p> | 组件 | 生命周期内的hooks调用 |<br> |———–|————————|<br> | App | componentWillReceiveProps, componentDidUpdate |<br> | Home | N/A |<br> | Invoice | componentWillUnmount |<br> | Account | componentDidMount |</p>\n</li>\n</ol>\n<p>###Fetching Data</p>\n<p>在使用router时有很多种方法来获取数据，其中最简单的一种方式就是利用组件的生命周期hooks，并保存数据在组件的state中（译者：这一点在Redux设计理念中被强烈反对，事实证明即便是不依赖state，这种方式照样可行，我们后面会给出例子）。我们已经知道了当router切换时组件的生命周期hooks调用过程，我们来为之前的<code>Invoice</code>组件来实现一个简单的获取数据逻辑。</p>\n<pre><code>let Invoice = React.createClass({\n\n      getInitialState () {\n        return {\n              invoice: null\n        }\n      },\n\n      componentDidMount () {\n        // fetch data initially in scenario 2 from above\n        this.fetchInvoice()\n      },\n\n      componentDidUpdate (prevProps) {\n        // respond to parameter change in scenario 3\n        let oldId = prevProps.params.invoiceId\n        let newId = this.props.params.invoiceId\n        if (newId !== oldId)\n              this.fetchInvoice()\n      },\n\n      componentWillUnmount () {\n        // allows us to ignore an inflight request in scenario 4\n        this.ignoreLastFetch = true\n      },\n\n      fetchInvoice () {\n        let url = `/api/invoices/${this.props.params.invoiceId}`\n        this.request = fetch(url, (err, data) =&gt; {\n          if (!this.ignoreLastFetch)\n            this.setState({ invoice: data.invoice })\n        })\n      },\n\n      render () {\n        return &lt;InvoiceView invoice={this.state.invoice}/&gt;\n      }\n})\n</code></pre><hr>\n<p>##译者总结</p>\n<p>在本篇开头我的那篇问题贴中已描述场景，由于我一直以来对react的生命周期hooks错误的理解，导致死活无法优雅的实现兼容浏览器前进后退操作的组件。经过上面内容的学习，一切都不在话下。</p>\n<p>首先，我之前总是习惯使用<code>componentWillMount</code>方法来初始化组件的状态，事实证明这种写法并非适用于所有场景（尽管使用它也可以，但至少不是更多人推荐的）。其次，尽可能避免让组件包含太多会话状态，保证组件的纯净。</p>\n<p>在我的代码中，更改后的完美版本如下：</p>\n<p>（算了，想了想这部分代码的附加逻辑太多，不适合用来阐述上述观点，还是不贴了～）</p>"},{"title":"react写小项目后感","date":"2015-11-16T01:37:12.000Z","_content":"\n用react差不多三个月了吧，断断续续的写了几个小项目，感觉美美哒。作为自我总结，也为其他新人指南，特此发一篇。\n<!--more-->\n\n####首先\n\n你得搞清楚，你处在的时代。别给我说你没听过JS，也别说jQuery不熟，对了，还有ajax。这些已经算是这个时代前端开发人员的基本功了。\n\n当然，仅仅会了这些，还差得远。各种css库，JS库和框架，ajax库，你多少也得略知一二吧，搞清楚什么叫浏览器兼容性，什么叫事件，什么是回调，还有响应布局啊乱七八糟的。\n\n哎哟不错，掌握了这些小九九，你体内的查克拉就差不多了。接下来要面对的，就是前端工程化问题。说白点，就是你可能不光要能做出来，还得做的高效。\n\n\n####新概念\n\n前端技术这些年真心不让人省心，几乎每时每刻都可能会发生点改变世界的事儿。你可以看一下github上的js项目，当然还有npm里。说到npm，自然又会扯出nodejs。唉，心塞啊。好像自己这几年积累的开发经验，都是围绕着js打转转。\n\n那这些就是新概念么？其实也不算，css3，html5，es6，es7，这些概念有的已经快好几年了，至今仍未彻底落地。但身为前端，你却不能不去掌握它们，因为你会从中感受到优雅，感受到强大。\n\n####react\n\n各大技术社区，充斥着react的身影，这也让facebook开源套件获得了越来越高的曝光率，react生态系统以迅雷不及掩耳盗铃之势，超越了神圣的angularJS，这让我这个老ng粉儿感叹世事无常啊。\n\n不过react却真如它所说，确实以新的理念为开发者带来了大道至简的哲学。至少对我来讲，曾经头疼于如何给团队讲解ioc，讲指令，现在这些复杂概念不需要了（对于新手来讲）。开发人员只需要对组件，模块有些许的认知，就可以动手干了！\n\n*react组件的生命周期，是每一个使用者无论如何都一定要花时间提前掌握的，不然别说你懂react，最好都别说你听说过它！*\n\n####工程化\n\n前端工程化的概念，随着一大堆构建工具，也慢慢的被大家所认可，BAE的前端研发团队各自有响应的一套解决方案。当然，开源界在这一方面一点也不含糊，前端构建工具多的你都来不及用，可能它就已经消失了。\n\nreact的世界里，有webpack，有babel，这些林林总总的强大猛兽，让开发者战无不胜。你还在等什么？\n\n####移动\n\n我并不会开发移动端app，这一点也已经给我带来了感受得到的机会流逝，但我骨子里却无法磨灭一个想法，我一直非常的看好web，十几年前，软件都是安装在pc上的，就好像今天安装在手机中的app一样。但，这不是常态，web才是互联网的常态，我相信不出几年，app的概念也会不见，web大统！\n\n这也是像google这样的科技巨头一直在努力的方向。\n\n####落地\n\n扯蛋时间结束了，说点干货。\n\nreact只是一个近乎完美的view，它自己也这么说。你肯定还需要点儿别的，我之前的文章也反复强调过这一点了。相信你很容易就能找到各种缺少的组件，当然你也可以尝试一下我找到的一个脚手架：[react_scaffolding](https://github.com/kazaff/react_scaffolding)。\n\n它已经把react，react-router，redux，immutable，superagent等组装好了，开箱即用。当然，并不能说这就是最佳组合了，我相信还有更好的。\n\n支持react的ui也越来越多，像之前推荐的妹子ui，还有阿里蚂蚁开发的ant，都非常优秀。但这里需要叮嘱的是，随着react0.14+的发布，独立了dom相关的操作，这让部分ui库不再可用，选择的时候一定要注意啊。\n\n另外，es6的class语法，并不支持react曾经推从的mixins哲学，当然，你依然可以用es5的语法来使用mixins，这一点也不难。\n\n组件之前的通信方式也有一大堆，但有时候你还是不得不跳出react，不过没关系，CustomEvent应该可以帮到你。\n\n我还想说，一直都挺希望路由配置可以去中心化，这一点[react-router](https://github.com/rackt/react-router/blob/master/docs/guides/advanced/DynamicRouting.md)也可以很好的帮你搞定。\n\n其实，上面推荐的那个脚手架，在实际项目开发时，还是无法避免大量的样板代码，比方说你写reducer和api的地方，如果能利用代理或工厂模式动态创建相关逻辑，那也是极好的。\n\n最后，思考了十分钟，确实想不到还要说点啥了，那就到此为止吧。","source":"_posts/react写小项目后感.md","raw":"title: react写小项目后感\ndate: 2015-11-16 09:37:12\ntags: \n- react\ncategories: 前端\n---\n\n用react差不多三个月了吧，断断续续的写了几个小项目，感觉美美哒。作为自我总结，也为其他新人指南，特此发一篇。\n<!--more-->\n\n####首先\n\n你得搞清楚，你处在的时代。别给我说你没听过JS，也别说jQuery不熟，对了，还有ajax。这些已经算是这个时代前端开发人员的基本功了。\n\n当然，仅仅会了这些，还差得远。各种css库，JS库和框架，ajax库，你多少也得略知一二吧，搞清楚什么叫浏览器兼容性，什么叫事件，什么是回调，还有响应布局啊乱七八糟的。\n\n哎哟不错，掌握了这些小九九，你体内的查克拉就差不多了。接下来要面对的，就是前端工程化问题。说白点，就是你可能不光要能做出来，还得做的高效。\n\n\n####新概念\n\n前端技术这些年真心不让人省心，几乎每时每刻都可能会发生点改变世界的事儿。你可以看一下github上的js项目，当然还有npm里。说到npm，自然又会扯出nodejs。唉，心塞啊。好像自己这几年积累的开发经验，都是围绕着js打转转。\n\n那这些就是新概念么？其实也不算，css3，html5，es6，es7，这些概念有的已经快好几年了，至今仍未彻底落地。但身为前端，你却不能不去掌握它们，因为你会从中感受到优雅，感受到强大。\n\n####react\n\n各大技术社区，充斥着react的身影，这也让facebook开源套件获得了越来越高的曝光率，react生态系统以迅雷不及掩耳盗铃之势，超越了神圣的angularJS，这让我这个老ng粉儿感叹世事无常啊。\n\n不过react却真如它所说，确实以新的理念为开发者带来了大道至简的哲学。至少对我来讲，曾经头疼于如何给团队讲解ioc，讲指令，现在这些复杂概念不需要了（对于新手来讲）。开发人员只需要对组件，模块有些许的认知，就可以动手干了！\n\n*react组件的生命周期，是每一个使用者无论如何都一定要花时间提前掌握的，不然别说你懂react，最好都别说你听说过它！*\n\n####工程化\n\n前端工程化的概念，随着一大堆构建工具，也慢慢的被大家所认可，BAE的前端研发团队各自有响应的一套解决方案。当然，开源界在这一方面一点也不含糊，前端构建工具多的你都来不及用，可能它就已经消失了。\n\nreact的世界里，有webpack，有babel，这些林林总总的强大猛兽，让开发者战无不胜。你还在等什么？\n\n####移动\n\n我并不会开发移动端app，这一点也已经给我带来了感受得到的机会流逝，但我骨子里却无法磨灭一个想法，我一直非常的看好web，十几年前，软件都是安装在pc上的，就好像今天安装在手机中的app一样。但，这不是常态，web才是互联网的常态，我相信不出几年，app的概念也会不见，web大统！\n\n这也是像google这样的科技巨头一直在努力的方向。\n\n####落地\n\n扯蛋时间结束了，说点干货。\n\nreact只是一个近乎完美的view，它自己也这么说。你肯定还需要点儿别的，我之前的文章也反复强调过这一点了。相信你很容易就能找到各种缺少的组件，当然你也可以尝试一下我找到的一个脚手架：[react_scaffolding](https://github.com/kazaff/react_scaffolding)。\n\n它已经把react，react-router，redux，immutable，superagent等组装好了，开箱即用。当然，并不能说这就是最佳组合了，我相信还有更好的。\n\n支持react的ui也越来越多，像之前推荐的妹子ui，还有阿里蚂蚁开发的ant，都非常优秀。但这里需要叮嘱的是，随着react0.14+的发布，独立了dom相关的操作，这让部分ui库不再可用，选择的时候一定要注意啊。\n\n另外，es6的class语法，并不支持react曾经推从的mixins哲学，当然，你依然可以用es5的语法来使用mixins，这一点也不难。\n\n组件之前的通信方式也有一大堆，但有时候你还是不得不跳出react，不过没关系，CustomEvent应该可以帮到你。\n\n我还想说，一直都挺希望路由配置可以去中心化，这一点[react-router](https://github.com/rackt/react-router/blob/master/docs/guides/advanced/DynamicRouting.md)也可以很好的帮你搞定。\n\n其实，上面推荐的那个脚手架，在实际项目开发时，还是无法避免大量的样板代码，比方说你写reducer和api的地方，如果能利用代理或工厂模式动态创建相关逻辑，那也是极好的。\n\n最后，思考了十分钟，确实想不到还要说点啥了，那就到此为止吧。","slug":"react写小项目后感","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cih0be1hd0000ikws2w1avnip","comments":1,"layout":"post","photos":[],"link":"","content":"<p>用react差不多三个月了吧，断断续续的写了几个小项目，感觉美美哒。作为自我总结，也为其他新人指南，特此发一篇。<br><a id=\"more\"></a></p>\n<p>####首先</p>\n<p>你得搞清楚，你处在的时代。别给我说你没听过JS，也别说jQuery不熟，对了，还有ajax。这些已经算是这个时代前端开发人员的基本功了。</p>\n<p>当然，仅仅会了这些，还差得远。各种css库，JS库和框架，ajax库，你多少也得略知一二吧，搞清楚什么叫浏览器兼容性，什么叫事件，什么是回调，还有响应布局啊乱七八糟的。</p>\n<p>哎哟不错，掌握了这些小九九，你体内的查克拉就差不多了。接下来要面对的，就是前端工程化问题。说白点，就是你可能不光要能做出来，还得做的高效。</p>\n<p>####新概念</p>\n<p>前端技术这些年真心不让人省心，几乎每时每刻都可能会发生点改变世界的事儿。你可以看一下github上的js项目，当然还有npm里。说到npm，自然又会扯出nodejs。唉，心塞啊。好像自己这几年积累的开发经验，都是围绕着js打转转。</p>\n<p>那这些就是新概念么？其实也不算，css3，html5，es6，es7，这些概念有的已经快好几年了，至今仍未彻底落地。但身为前端，你却不能不去掌握它们，因为你会从中感受到优雅，感受到强大。</p>\n<p>####react</p>\n<p>各大技术社区，充斥着react的身影，这也让facebook开源套件获得了越来越高的曝光率，react生态系统以迅雷不及掩耳盗铃之势，超越了神圣的angularJS，这让我这个老ng粉儿感叹世事无常啊。</p>\n<p>不过react却真如它所说，确实以新的理念为开发者带来了大道至简的哲学。至少对我来讲，曾经头疼于如何给团队讲解ioc，讲指令，现在这些复杂概念不需要了（对于新手来讲）。开发人员只需要对组件，模块有些许的认知，就可以动手干了！</p>\n<p><em>react组件的生命周期，是每一个使用者无论如何都一定要花时间提前掌握的，不然别说你懂react，最好都别说你听说过它！</em></p>\n<p>####工程化</p>\n<p>前端工程化的概念，随着一大堆构建工具，也慢慢的被大家所认可，BAE的前端研发团队各自有响应的一套解决方案。当然，开源界在这一方面一点也不含糊，前端构建工具多的你都来不及用，可能它就已经消失了。</p>\n<p>react的世界里，有webpack，有babel，这些林林总总的强大猛兽，让开发者战无不胜。你还在等什么？</p>\n<p>####移动</p>\n<p>我并不会开发移动端app，这一点也已经给我带来了感受得到的机会流逝，但我骨子里却无法磨灭一个想法，我一直非常的看好web，十几年前，软件都是安装在pc上的，就好像今天安装在手机中的app一样。但，这不是常态，web才是互联网的常态，我相信不出几年，app的概念也会不见，web大统！</p>\n<p>这也是像google这样的科技巨头一直在努力的方向。</p>\n<p>####落地</p>\n<p>扯蛋时间结束了，说点干货。</p>\n<p>react只是一个近乎完美的view，它自己也这么说。你肯定还需要点儿别的，我之前的文章也反复强调过这一点了。相信你很容易就能找到各种缺少的组件，当然你也可以尝试一下我找到的一个脚手架：<a href=\"https://github.com/kazaff/react_scaffolding\" target=\"_blank\" rel=\"external\">react_scaffolding</a>。</p>\n<p>它已经把react，react-router，redux，immutable，superagent等组装好了，开箱即用。当然，并不能说这就是最佳组合了，我相信还有更好的。</p>\n<p>支持react的ui也越来越多，像之前推荐的妹子ui，还有阿里蚂蚁开发的ant，都非常优秀。但这里需要叮嘱的是，随着react0.14+的发布，独立了dom相关的操作，这让部分ui库不再可用，选择的时候一定要注意啊。</p>\n<p>另外，es6的class语法，并不支持react曾经推从的mixins哲学，当然，你依然可以用es5的语法来使用mixins，这一点也不难。</p>\n<p>组件之前的通信方式也有一大堆，但有时候你还是不得不跳出react，不过没关系，CustomEvent应该可以帮到你。</p>\n<p>我还想说，一直都挺希望路由配置可以去中心化，这一点<a href=\"https://github.com/rackt/react-router/blob/master/docs/guides/advanced/DynamicRouting.md\" target=\"_blank\" rel=\"external\">react-router</a>也可以很好的帮你搞定。</p>\n<p>其实，上面推荐的那个脚手架，在实际项目开发时，还是无法避免大量的样板代码，比方说你写reducer和api的地方，如果能利用代理或工厂模式动态创建相关逻辑，那也是极好的。</p>\n<p>最后，思考了十分钟，确实想不到还要说点啥了，那就到此为止吧。</p>\n","excerpt":"<p>用react差不多三个月了吧，断断续续的写了几个小项目，感觉美美哒。作为自我总结，也为其他新人指南，特此发一篇。<br>","more":"</p>\n<p>####首先</p>\n<p>你得搞清楚，你处在的时代。别给我说你没听过JS，也别说jQuery不熟，对了，还有ajax。这些已经算是这个时代前端开发人员的基本功了。</p>\n<p>当然，仅仅会了这些，还差得远。各种css库，JS库和框架，ajax库，你多少也得略知一二吧，搞清楚什么叫浏览器兼容性，什么叫事件，什么是回调，还有响应布局啊乱七八糟的。</p>\n<p>哎哟不错，掌握了这些小九九，你体内的查克拉就差不多了。接下来要面对的，就是前端工程化问题。说白点，就是你可能不光要能做出来，还得做的高效。</p>\n<p>####新概念</p>\n<p>前端技术这些年真心不让人省心，几乎每时每刻都可能会发生点改变世界的事儿。你可以看一下github上的js项目，当然还有npm里。说到npm，自然又会扯出nodejs。唉，心塞啊。好像自己这几年积累的开发经验，都是围绕着js打转转。</p>\n<p>那这些就是新概念么？其实也不算，css3，html5，es6，es7，这些概念有的已经快好几年了，至今仍未彻底落地。但身为前端，你却不能不去掌握它们，因为你会从中感受到优雅，感受到强大。</p>\n<p>####react</p>\n<p>各大技术社区，充斥着react的身影，这也让facebook开源套件获得了越来越高的曝光率，react生态系统以迅雷不及掩耳盗铃之势，超越了神圣的angularJS，这让我这个老ng粉儿感叹世事无常啊。</p>\n<p>不过react却真如它所说，确实以新的理念为开发者带来了大道至简的哲学。至少对我来讲，曾经头疼于如何给团队讲解ioc，讲指令，现在这些复杂概念不需要了（对于新手来讲）。开发人员只需要对组件，模块有些许的认知，就可以动手干了！</p>\n<p><em>react组件的生命周期，是每一个使用者无论如何都一定要花时间提前掌握的，不然别说你懂react，最好都别说你听说过它！</em></p>\n<p>####工程化</p>\n<p>前端工程化的概念，随着一大堆构建工具，也慢慢的被大家所认可，BAE的前端研发团队各自有响应的一套解决方案。当然，开源界在这一方面一点也不含糊，前端构建工具多的你都来不及用，可能它就已经消失了。</p>\n<p>react的世界里，有webpack，有babel，这些林林总总的强大猛兽，让开发者战无不胜。你还在等什么？</p>\n<p>####移动</p>\n<p>我并不会开发移动端app，这一点也已经给我带来了感受得到的机会流逝，但我骨子里却无法磨灭一个想法，我一直非常的看好web，十几年前，软件都是安装在pc上的，就好像今天安装在手机中的app一样。但，这不是常态，web才是互联网的常态，我相信不出几年，app的概念也会不见，web大统！</p>\n<p>这也是像google这样的科技巨头一直在努力的方向。</p>\n<p>####落地</p>\n<p>扯蛋时间结束了，说点干货。</p>\n<p>react只是一个近乎完美的view，它自己也这么说。你肯定还需要点儿别的，我之前的文章也反复强调过这一点了。相信你很容易就能找到各种缺少的组件，当然你也可以尝试一下我找到的一个脚手架：<a href=\"https://github.com/kazaff/react_scaffolding\">react_scaffolding</a>。</p>\n<p>它已经把react，react-router，redux，immutable，superagent等组装好了，开箱即用。当然，并不能说这就是最佳组合了，我相信还有更好的。</p>\n<p>支持react的ui也越来越多，像之前推荐的妹子ui，还有阿里蚂蚁开发的ant，都非常优秀。但这里需要叮嘱的是，随着react0.14+的发布，独立了dom相关的操作，这让部分ui库不再可用，选择的时候一定要注意啊。</p>\n<p>另外，es6的class语法，并不支持react曾经推从的mixins哲学，当然，你依然可以用es5的语法来使用mixins，这一点也不难。</p>\n<p>组件之前的通信方式也有一大堆，但有时候你还是不得不跳出react，不过没关系，CustomEvent应该可以帮到你。</p>\n<p>我还想说，一直都挺希望路由配置可以去中心化，这一点<a href=\"https://github.com/rackt/react-router/blob/master/docs/guides/advanced/DynamicRouting.md\">react-router</a>也可以很好的帮你搞定。</p>\n<p>其实，上面推荐的那个脚手架，在实际项目开发时，还是无法避免大量的样板代码，比方说你写reducer和api的地方，如果能利用代理或工厂模式动态创建相关逻辑，那也是极好的。</p>\n<p>最后，思考了十分钟，确实想不到还要说点啥了，那就到此为止吧。</p>"},{"title":"微信第三方登录","date":"2015-11-24T01:37:12.000Z","_content":"\n最近工作需要，运营想实现一个功能，让网站用户可以通过微信进行登录。这在社交媒体如火如荼的今天，再常见不过了。\n\n<!--more-->\n\n提到第三方登录的技术范畴，就不得不提OAuth，要说这个OAuth，我就不啰嗦了，还是推荐大家直接看阮老师的[理解OAuth 2.0](http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html)，没错，这个协议已经是2.0版本了！\n\n不是太复杂，对吧？了解了理论姿势，我们再来结合实际场景完成功能，首先要知道，我们的场景不是要自己实现这个OAuth协议，而是根据第三方平台（这里特指微信）来完成我们的需求。\n\n一直没写网站类型的系统，所以一直也没怎么去和常用的第三方系统对接，懒嘛，时间多花在打电动上了……不过其实知道并不复杂，我们来先梳理一下要用到的技术：\n\n- ajax（看具体场景了，我所处理的系统需要）\n- json\n- OAuth2.0\n\n大概就这些吧，前两个基本上是web2.0以后的必备知识，而第三个我们刚才也介绍过了，那么就开始动手吧！\n\n哦～稍等一下，在写代码之前，我们还没看微信接口的规则呢，说到这个，我这个小白就得叮嘱一下大家了，微信平台分2个：**公众号平台**和**开放平台**。前者多用来结合公众号后台来完成更加复杂的业务逻辑的，当然也能解决我们今天讨论的这个登录问题，但后者更适合我们！\n\n顺便说一下，要使用微信的接口是要申请的，申请是要审核的，审核是要收费的！目前应该是申请一次300块，申请所需要的手续和申请支付宝差不多，就是一些备案号啊，公司执照啊等等吧，可以访问[这里](https://open.weixin.qq.com/)。\n\n目前微信开放平台针对网页提供的就只有用于第三方登录的接口（其实也就是获取用户信息的接口），相关接口文档可以访问[这里](https://open.weixin.qq.com/cgi-bin/showdocument?action=dir_list&t=resource/res_list&verify=1&id=open1419316505&token=&lang=zh_CN)。\n\n我大概描述一下我们的业务流程走向：\n\n1. 用户登录网站，并进行微信账号绑定；\n2. 点击绑定后浏览器跳转到微信鉴权页面，用户完成授权；\n3. 微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系；\n4. 用户再次打算登录网站时，点击微信登录按钮；\n5. 浏览器跳转到微信二维码页面，用户扫描确认后，浏览器跳转到我们指定的页面；\n6. 该页面根据用户微信的openid查找到对应的网站用户id，并完成session的创建；\n7. 引导用户浏览器跳转到网站首页，此时用户应该处于登录状态。\n\n该流程很简单，具体你的项目是使用什么技术栈，都可以根据以上流程完成微信同步登录。有童鞋可能注意到，我们并没有按照官方说的那样去持久化access_token，是的，因为目前我们并没有必要持久化它，更不需要为了避免超时而去续期，因为我们只是一次性获取用户的openid而已。\n\n那什么时候我们需要保存access_token呢？当你的网站除了登录外，还想让更深度的绑定微信账号时才需要（例如支付，当然你可能需要开通微信公众号平台喽～）。\n\n\n我的场景\n---\n\n由于我的网站是完全基于ajax的，前后台仅仅靠api来通信，所以和微信官方的例子还不完全一样，下面我来说一下这种场景下的注意细节。\n\n请允许我先介绍一下我的场景：\n\n1. 富客户端，前台完全负责页面的路由\n2. 所有前后端通信按照Restful标准\n3. 会话id使用自定义请求头（token）来进行传递\n\n满足以上条件的系统，通常是使用了像angularjs，emberjs或reactjs等前端mv*框架技术的。\n\n出于各种原因，我们上面描述的流程中，有一些是被影响的。我们来具体说说吧～\n\n首先看第2步（点击绑定后浏览器跳转到微信鉴权页面，用户完成授权），由于这次浏览器跳转会将控制权交给微信平台，我们的前台路由不能插手，所以呢，我们需要传递足够的参数过去。微信接口提供了一个参数state，刚好可以让我们来使用，因为该参数微信会原样返回给我们指定的回调页面，为什么这一点很重要呢？\n\n第3步（微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系）中，其实我们省略了一个子流程，根据OAuth规范，微信回调到我们的指定地址后，只传递了Code，而这个Code并不能用来换取用户的openid，我们还需要在该地址的处理逻辑中再次请求微信平台换取access_token，这次请求要携带一个appsecret参数，该参数不应当泄漏给其他人，所以注定我们的这个地址是一个不在客户浏览器中执行的脚本，也就是通俗的后台代码（可以是php，是java，是nodejs）。\n\n所以呢，当我们的这个后台脚本顺利拿到了用户的openid后呢，它又该怎么知道用户的系统id呢？有人说很简单啊，直接读取cookie即可，我前面说了，我们没有使用cookie来存sessionid，我们使用的是自定义请求头，而微信回跳时肯定是不会携带我们自定义的请求头的，所以前面说的那个state参数就很有意义哒。\n\n同样，我们持久化用户的系统id和openid是需要使用数据库的，你当然不会希望将数据库密码放在前台代码里吧？哇哈哈～～别告诉我你是这么做的！因此，微信回调的地址一定是后台脚本～\n\n同理，第6步依然是一个后台脚本，它创建好会话id后，需要将用户的浏览器重定向到前台系统页面，相当于把控制权交还给了我们的前台系统。接下来就是在我们的富客户端路由控制下完成用户的页面路由了。\n\n还有一个细节，用户绑定过微信账号后，你网站的某个页面肯定还要展示这种绑定关系，之所以提这点，是想让你知道，用户系统id和openid的关系映射方式还是需要斟酌一下的，因为我们需要两种方向的查找：\n\n- uid -> openid：用于绑定\n- openid -> uid：用于登录\n\n如果你使用的是nosql（redis），你可能需要两组kv才能存下这两组数据。同时，你可能还需要考虑其他平台的账号绑定～～所以，你还是先好好考虑考虑吧～\n\n\n实际开发时你还需要考虑到足够多的异常系处理，毕竟在整个流程中存在多次跳转，多次查询，要考虑每次的出错场景。不说了，说多了都是泪！\n\n代码我已发到[gihub](https://github.com/kazaff/third-part-auth)上，有兴趣的童鞋不妨去看看～\n\n\n\n","source":"_posts/微信第三方登录.md","raw":"title: 微信第三方登录\ndate: 2015-11-24 09:37:12\ntags: \n- 微信\n- OAuth\n- 第三方登录\ncategories: 前端\n---\n\n最近工作需要，运营想实现一个功能，让网站用户可以通过微信进行登录。这在社交媒体如火如荼的今天，再常见不过了。\n\n<!--more-->\n\n提到第三方登录的技术范畴，就不得不提OAuth，要说这个OAuth，我就不啰嗦了，还是推荐大家直接看阮老师的[理解OAuth 2.0](http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html)，没错，这个协议已经是2.0版本了！\n\n不是太复杂，对吧？了解了理论姿势，我们再来结合实际场景完成功能，首先要知道，我们的场景不是要自己实现这个OAuth协议，而是根据第三方平台（这里特指微信）来完成我们的需求。\n\n一直没写网站类型的系统，所以一直也没怎么去和常用的第三方系统对接，懒嘛，时间多花在打电动上了……不过其实知道并不复杂，我们来先梳理一下要用到的技术：\n\n- ajax（看具体场景了，我所处理的系统需要）\n- json\n- OAuth2.0\n\n大概就这些吧，前两个基本上是web2.0以后的必备知识，而第三个我们刚才也介绍过了，那么就开始动手吧！\n\n哦～稍等一下，在写代码之前，我们还没看微信接口的规则呢，说到这个，我这个小白就得叮嘱一下大家了，微信平台分2个：**公众号平台**和**开放平台**。前者多用来结合公众号后台来完成更加复杂的业务逻辑的，当然也能解决我们今天讨论的这个登录问题，但后者更适合我们！\n\n顺便说一下，要使用微信的接口是要申请的，申请是要审核的，审核是要收费的！目前应该是申请一次300块，申请所需要的手续和申请支付宝差不多，就是一些备案号啊，公司执照啊等等吧，可以访问[这里](https://open.weixin.qq.com/)。\n\n目前微信开放平台针对网页提供的就只有用于第三方登录的接口（其实也就是获取用户信息的接口），相关接口文档可以访问[这里](https://open.weixin.qq.com/cgi-bin/showdocument?action=dir_list&t=resource/res_list&verify=1&id=open1419316505&token=&lang=zh_CN)。\n\n我大概描述一下我们的业务流程走向：\n\n1. 用户登录网站，并进行微信账号绑定；\n2. 点击绑定后浏览器跳转到微信鉴权页面，用户完成授权；\n3. 微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系；\n4. 用户再次打算登录网站时，点击微信登录按钮；\n5. 浏览器跳转到微信二维码页面，用户扫描确认后，浏览器跳转到我们指定的页面；\n6. 该页面根据用户微信的openid查找到对应的网站用户id，并完成session的创建；\n7. 引导用户浏览器跳转到网站首页，此时用户应该处于登录状态。\n\n该流程很简单，具体你的项目是使用什么技术栈，都可以根据以上流程完成微信同步登录。有童鞋可能注意到，我们并没有按照官方说的那样去持久化access_token，是的，因为目前我们并没有必要持久化它，更不需要为了避免超时而去续期，因为我们只是一次性获取用户的openid而已。\n\n那什么时候我们需要保存access_token呢？当你的网站除了登录外，还想让更深度的绑定微信账号时才需要（例如支付，当然你可能需要开通微信公众号平台喽～）。\n\n\n我的场景\n---\n\n由于我的网站是完全基于ajax的，前后台仅仅靠api来通信，所以和微信官方的例子还不完全一样，下面我来说一下这种场景下的注意细节。\n\n请允许我先介绍一下我的场景：\n\n1. 富客户端，前台完全负责页面的路由\n2. 所有前后端通信按照Restful标准\n3. 会话id使用自定义请求头（token）来进行传递\n\n满足以上条件的系统，通常是使用了像angularjs，emberjs或reactjs等前端mv*框架技术的。\n\n出于各种原因，我们上面描述的流程中，有一些是被影响的。我们来具体说说吧～\n\n首先看第2步（点击绑定后浏览器跳转到微信鉴权页面，用户完成授权），由于这次浏览器跳转会将控制权交给微信平台，我们的前台路由不能插手，所以呢，我们需要传递足够的参数过去。微信接口提供了一个参数state，刚好可以让我们来使用，因为该参数微信会原样返回给我们指定的回调页面，为什么这一点很重要呢？\n\n第3步（微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系）中，其实我们省略了一个子流程，根据OAuth规范，微信回调到我们的指定地址后，只传递了Code，而这个Code并不能用来换取用户的openid，我们还需要在该地址的处理逻辑中再次请求微信平台换取access_token，这次请求要携带一个appsecret参数，该参数不应当泄漏给其他人，所以注定我们的这个地址是一个不在客户浏览器中执行的脚本，也就是通俗的后台代码（可以是php，是java，是nodejs）。\n\n所以呢，当我们的这个后台脚本顺利拿到了用户的openid后呢，它又该怎么知道用户的系统id呢？有人说很简单啊，直接读取cookie即可，我前面说了，我们没有使用cookie来存sessionid，我们使用的是自定义请求头，而微信回跳时肯定是不会携带我们自定义的请求头的，所以前面说的那个state参数就很有意义哒。\n\n同样，我们持久化用户的系统id和openid是需要使用数据库的，你当然不会希望将数据库密码放在前台代码里吧？哇哈哈～～别告诉我你是这么做的！因此，微信回调的地址一定是后台脚本～\n\n同理，第6步依然是一个后台脚本，它创建好会话id后，需要将用户的浏览器重定向到前台系统页面，相当于把控制权交还给了我们的前台系统。接下来就是在我们的富客户端路由控制下完成用户的页面路由了。\n\n还有一个细节，用户绑定过微信账号后，你网站的某个页面肯定还要展示这种绑定关系，之所以提这点，是想让你知道，用户系统id和openid的关系映射方式还是需要斟酌一下的，因为我们需要两种方向的查找：\n\n- uid -> openid：用于绑定\n- openid -> uid：用于登录\n\n如果你使用的是nosql（redis），你可能需要两组kv才能存下这两组数据。同时，你可能还需要考虑其他平台的账号绑定～～所以，你还是先好好考虑考虑吧～\n\n\n实际开发时你还需要考虑到足够多的异常系处理，毕竟在整个流程中存在多次跳转，多次查询，要考虑每次的出错场景。不说了，说多了都是泪！\n\n代码我已发到[gihub](https://github.com/kazaff/third-part-auth)上，有兴趣的童鞋不妨去看看～\n\n\n\n","slug":"微信第三方登录","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cihdildua0000nxwsojoyv4lp","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近工作需要，运营想实现一个功能，让网站用户可以通过微信进行登录。这在社交媒体如火如荼的今天，再常见不过了。</p>\n<a id=\"more\"></a>\n<p>提到第三方登录的技术范畴，就不得不提OAuth，要说这个OAuth，我就不啰嗦了，还是推荐大家直接看阮老师的<a href=\"http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html\" target=\"_blank\" rel=\"external\">理解OAuth 2.0</a>，没错，这个协议已经是2.0版本了！</p>\n<p>不是太复杂，对吧？了解了理论姿势，我们再来结合实际场景完成功能，首先要知道，我们的场景不是要自己实现这个OAuth协议，而是根据第三方平台（这里特指微信）来完成我们的需求。</p>\n<p>一直没写网站类型的系统，所以一直也没怎么去和常用的第三方系统对接，懒嘛，时间多花在打电动上了……不过其实知道并不复杂，我们来先梳理一下要用到的技术：</p>\n<ul>\n<li>ajax（看具体场景了，我所处理的系统需要）</li>\n<li>json</li>\n<li>OAuth2.0</li>\n</ul>\n<p>大概就这些吧，前两个基本上是web2.0以后的必备知识，而第三个我们刚才也介绍过了，那么就开始动手吧！</p>\n<p>哦～稍等一下，在写代码之前，我们还没看微信接口的规则呢，说到这个，我这个小白就得叮嘱一下大家了，微信平台分2个：<strong>公众号平台</strong>和<strong>开放平台</strong>。前者多用来结合公众号后台来完成更加复杂的业务逻辑的，当然也能解决我们今天讨论的这个登录问题，但后者更适合我们！</p>\n<p>顺便说一下，要使用微信的接口是要申请的，申请是要审核的，审核是要收费的！目前应该是申请一次300块，申请所需要的手续和申请支付宝差不多，就是一些备案号啊，公司执照啊等等吧，可以访问<a href=\"https://open.weixin.qq.com/\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>目前微信开放平台针对网页提供的就只有用于第三方登录的接口（其实也就是获取用户信息的接口），相关接口文档可以访问<a href=\"https://open.weixin.qq.com/cgi-bin/showdocument?action=dir_list&amp;t=resource/res_list&amp;verify=1&amp;id=open1419316505&amp;token=&amp;lang=zh_CN\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>我大概描述一下我们的业务流程走向：</p>\n<ol>\n<li>用户登录网站，并进行微信账号绑定；</li>\n<li>点击绑定后浏览器跳转到微信鉴权页面，用户完成授权；</li>\n<li>微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系；</li>\n<li>用户再次打算登录网站时，点击微信登录按钮；</li>\n<li>浏览器跳转到微信二维码页面，用户扫描确认后，浏览器跳转到我们指定的页面；</li>\n<li>该页面根据用户微信的openid查找到对应的网站用户id，并完成session的创建；</li>\n<li>引导用户浏览器跳转到网站首页，此时用户应该处于登录状态。</li>\n</ol>\n<p>该流程很简单，具体你的项目是使用什么技术栈，都可以根据以上流程完成微信同步登录。有童鞋可能注意到，我们并没有按照官方说的那样去持久化access_token，是的，因为目前我们并没有必要持久化它，更不需要为了避免超时而去续期，因为我们只是一次性获取用户的openid而已。</p>\n<p>那什么时候我们需要保存access_token呢？当你的网站除了登录外，还想让更深度的绑定微信账号时才需要（例如支付，当然你可能需要开通微信公众号平台喽～）。</p>\n<h2 id=\"我的场景\"><a href=\"#我的场景\" class=\"headerlink\" title=\"我的场景\"></a>我的场景</h2><p>由于我的网站是完全基于ajax的，前后台仅仅靠api来通信，所以和微信官方的例子还不完全一样，下面我来说一下这种场景下的注意细节。</p>\n<p>请允许我先介绍一下我的场景：</p>\n<ol>\n<li>富客户端，前台完全负责页面的路由</li>\n<li>所有前后端通信按照Restful标准</li>\n<li>会话id使用自定义请求头（token）来进行传递</li>\n</ol>\n<p>满足以上条件的系统，通常是使用了像angularjs，emberjs或reactjs等前端mv*框架技术的。</p>\n<p>出于各种原因，我们上面描述的流程中，有一些是被影响的。我们来具体说说吧～</p>\n<p>首先看第2步（点击绑定后浏览器跳转到微信鉴权页面，用户完成授权），由于这次浏览器跳转会将控制权交给微信平台，我们的前台路由不能插手，所以呢，我们需要传递足够的参数过去。微信接口提供了一个参数state，刚好可以让我们来使用，因为该参数微信会原样返回给我们指定的回调页面，为什么这一点很重要呢？</p>\n<p>第3步（微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系）中，其实我们省略了一个子流程，根据OAuth规范，微信回调到我们的指定地址后，只传递了Code，而这个Code并不能用来换取用户的openid，我们还需要在该地址的处理逻辑中再次请求微信平台换取access_token，这次请求要携带一个appsecret参数，该参数不应当泄漏给其他人，所以注定我们的这个地址是一个不在客户浏览器中执行的脚本，也就是通俗的后台代码（可以是php，是java，是nodejs）。</p>\n<p>所以呢，当我们的这个后台脚本顺利拿到了用户的openid后呢，它又该怎么知道用户的系统id呢？有人说很简单啊，直接读取cookie即可，我前面说了，我们没有使用cookie来存sessionid，我们使用的是自定义请求头，而微信回跳时肯定是不会携带我们自定义的请求头的，所以前面说的那个state参数就很有意义哒。</p>\n<p>同样，我们持久化用户的系统id和openid是需要使用数据库的，你当然不会希望将数据库密码放在前台代码里吧？哇哈哈～～别告诉我你是这么做的！因此，微信回调的地址一定是后台脚本～</p>\n<p>同理，第6步依然是一个后台脚本，它创建好会话id后，需要将用户的浏览器重定向到前台系统页面，相当于把控制权交还给了我们的前台系统。接下来就是在我们的富客户端路由控制下完成用户的页面路由了。</p>\n<p>还有一个细节，用户绑定过微信账号后，你网站的某个页面肯定还要展示这种绑定关系，之所以提这点，是想让你知道，用户系统id和openid的关系映射方式还是需要斟酌一下的，因为我们需要两种方向的查找：</p>\n<ul>\n<li>uid -&gt; openid：用于绑定</li>\n<li>openid -&gt; uid：用于登录</li>\n</ul>\n<p>如果你使用的是nosql（redis），你可能需要两组kv才能存下这两组数据。同时，你可能还需要考虑其他平台的账号绑定～～所以，你还是先好好考虑考虑吧～</p>\n<p>实际开发时你还需要考虑到足够多的异常系处理，毕竟在整个流程中存在多次跳转，多次查询，要考虑每次的出错场景。不说了，说多了都是泪！</p>\n<p>代码我已发到<a href=\"https://github.com/kazaff/third-part-auth\" target=\"_blank\" rel=\"external\">gihub</a>上，有兴趣的童鞋不妨去看看～</p>\n","excerpt":"<p>最近工作需要，运营想实现一个功能，让网站用户可以通过微信进行登录。这在社交媒体如火如荼的今天，再常见不过了。</p>","more":"<p>提到第三方登录的技术范畴，就不得不提OAuth，要说这个OAuth，我就不啰嗦了，还是推荐大家直接看阮老师的<a href=\"http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html\">理解OAuth 2.0</a>，没错，这个协议已经是2.0版本了！</p>\n<p>不是太复杂，对吧？了解了理论姿势，我们再来结合实际场景完成功能，首先要知道，我们的场景不是要自己实现这个OAuth协议，而是根据第三方平台（这里特指微信）来完成我们的需求。</p>\n<p>一直没写网站类型的系统，所以一直也没怎么去和常用的第三方系统对接，懒嘛，时间多花在打电动上了……不过其实知道并不复杂，我们来先梳理一下要用到的技术：</p>\n<ul>\n<li>ajax（看具体场景了，我所处理的系统需要）</li>\n<li>json</li>\n<li>OAuth2.0</li>\n</ul>\n<p>大概就这些吧，前两个基本上是web2.0以后的必备知识，而第三个我们刚才也介绍过了，那么就开始动手吧！</p>\n<p>哦～稍等一下，在写代码之前，我们还没看微信接口的规则呢，说到这个，我这个小白就得叮嘱一下大家了，微信平台分2个：<strong>公众号平台</strong>和<strong>开放平台</strong>。前者多用来结合公众号后台来完成更加复杂的业务逻辑的，当然也能解决我们今天讨论的这个登录问题，但后者更适合我们！</p>\n<p>顺便说一下，要使用微信的接口是要申请的，申请是要审核的，审核是要收费的！目前应该是申请一次300块，申请所需要的手续和申请支付宝差不多，就是一些备案号啊，公司执照啊等等吧，可以访问<a href=\"https://open.weixin.qq.com/\">这里</a>。</p>\n<p>目前微信开放平台针对网页提供的就只有用于第三方登录的接口（其实也就是获取用户信息的接口），相关接口文档可以访问<a href=\"https://open.weixin.qq.com/cgi-bin/showdocument?action=dir_list&amp;t=resource/res_list&amp;verify=1&amp;id=open1419316505&amp;token=&amp;lang=zh_CN\">这里</a>。</p>\n<p>我大概描述一下我们的业务流程走向：</p>\n<ol>\n<li>用户登录网站，并进行微信账号绑定；</li>\n<li>点击绑定后浏览器跳转到微信鉴权页面，用户完成授权；</li>\n<li>微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系；</li>\n<li>用户再次打算登录网站时，点击微信登录按钮；</li>\n<li>浏览器跳转到微信二维码页面，用户扫描确认后，浏览器跳转到我们指定的页面；</li>\n<li>该页面根据用户微信的openid查找到对应的网站用户id，并完成session的创建；</li>\n<li>引导用户浏览器跳转到网站首页，此时用户应该处于登录状态。</li>\n</ol>\n<p>该流程很简单，具体你的项目是使用什么技术栈，都可以根据以上流程完成微信同步登录。有童鞋可能注意到，我们并没有按照官方说的那样去持久化access_token，是的，因为目前我们并没有必要持久化它，更不需要为了避免超时而去续期，因为我们只是一次性获取用户的openid而已。</p>\n<p>那什么时候我们需要保存access_token呢？当你的网站除了登录外，还想让更深度的绑定微信账号时才需要（例如支付，当然你可能需要开通微信公众号平台喽～）。</p>\n<h2 id=\"我的场景\"><a href=\"#我的场景\" class=\"headerlink\" title=\"我的场景\"></a>我的场景</h2><p>由于我的网站是完全基于ajax的，前后台仅仅靠api来通信，所以和微信官方的例子还不完全一样，下面我来说一下这种场景下的注意细节。</p>\n<p>请允许我先介绍一下我的场景：</p>\n<ol>\n<li>富客户端，前台完全负责页面的路由</li>\n<li>所有前后端通信按照Restful标准</li>\n<li>会话id使用自定义请求头（token）来进行传递</li>\n</ol>\n<p>满足以上条件的系统，通常是使用了像angularjs，emberjs或reactjs等前端mv*框架技术的。</p>\n<p>出于各种原因，我们上面描述的流程中，有一些是被影响的。我们来具体说说吧～</p>\n<p>首先看第2步（点击绑定后浏览器跳转到微信鉴权页面，用户完成授权），由于这次浏览器跳转会将控制权交给微信平台，我们的前台路由不能插手，所以呢，我们需要传递足够的参数过去。微信接口提供了一个参数state，刚好可以让我们来使用，因为该参数微信会原样返回给我们指定的回调页面，为什么这一点很重要呢？</p>\n<p>第3步（微信平台将用户浏览器重定向到我们指定的地址，该地址作用是将当前用户id和该用户微信的openid（或unionid）建立映射关系）中，其实我们省略了一个子流程，根据OAuth规范，微信回调到我们的指定地址后，只传递了Code，而这个Code并不能用来换取用户的openid，我们还需要在该地址的处理逻辑中再次请求微信平台换取access_token，这次请求要携带一个appsecret参数，该参数不应当泄漏给其他人，所以注定我们的这个地址是一个不在客户浏览器中执行的脚本，也就是通俗的后台代码（可以是php，是java，是nodejs）。</p>\n<p>所以呢，当我们的这个后台脚本顺利拿到了用户的openid后呢，它又该怎么知道用户的系统id呢？有人说很简单啊，直接读取cookie即可，我前面说了，我们没有使用cookie来存sessionid，我们使用的是自定义请求头，而微信回跳时肯定是不会携带我们自定义的请求头的，所以前面说的那个state参数就很有意义哒。</p>\n<p>同样，我们持久化用户的系统id和openid是需要使用数据库的，你当然不会希望将数据库密码放在前台代码里吧？哇哈哈～～别告诉我你是这么做的！因此，微信回调的地址一定是后台脚本～</p>\n<p>同理，第6步依然是一个后台脚本，它创建好会话id后，需要将用户的浏览器重定向到前台系统页面，相当于把控制权交还给了我们的前台系统。接下来就是在我们的富客户端路由控制下完成用户的页面路由了。</p>\n<p>还有一个细节，用户绑定过微信账号后，你网站的某个页面肯定还要展示这种绑定关系，之所以提这点，是想让你知道，用户系统id和openid的关系映射方式还是需要斟酌一下的，因为我们需要两种方向的查找：</p>\n<ul>\n<li>uid -&gt; openid：用于绑定</li>\n<li>openid -&gt; uid：用于登录</li>\n</ul>\n<p>如果你使用的是nosql（redis），你可能需要两组kv才能存下这两组数据。同时，你可能还需要考虑其他平台的账号绑定～～所以，你还是先好好考虑考虑吧～</p>\n<p>实际开发时你还需要考虑到足够多的异常系处理，毕竟在整个流程中存在多次跳转，多次查询，要考虑每次的出错场景。不说了，说多了都是泪！</p>\n<p>代码我已发到<a href=\"https://github.com/kazaff/third-part-auth\">gihub</a>上，有兴趣的童鞋不妨去看看～</p>"},{"title":"QQ第三方登录","date":"2015-11-25T01:37:12.000Z","_content":"\n昨天搞的是微信登录，今天我们要来搞一下qq登录！\n<!--more-->\n但作为过来人，我想假装平静的说出心声：为啥同一个公司的两个产品系，文档质量就他奶奶个抓儿差那么多呢？\n\n如果说昨天搞微信很嗨皮的话，那么今天搞qq真的想在吃翔，我这暴脾气，唉～\n\n当然，这篇文章并非只是来吐槽的。言归正传，整体思路还是和[微信第三方登录](http://blog.kazaff.me/2015/11/24/%E5%BE%AE%E4%BF%A1%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95/)一致，我就不细说了，有兴趣的朋友可以看之前的那篇文章。\n\n我们接下来还是主要来关注qq登录接口不同于微信的地方！（文档，文档，渣文档就是最大的不同！妈蛋～）\n\n先来看一下[官方文档](http://wiki.connect.qq.com/%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C_oauth2-0)，如果你打开显示的是404错误，请多刷新几次，具体原因不清楚哇～\n\n文档一开始也正儿八经的给我们解释了解释OAuth，我们可以直接跳过啦～关键要注意的是它通过第1步得到的code换access_token的接口，也就是 \"https://graph.qq.com/oauth2.0/token\" 这个接口，它并不是像微信那样走的rest风格的服务，而是又借住了一次重定向来完成的！\n\n这尼玛怎么搞的？这多出的一跳不仅让你蛋疼，而且也丢失了state参数，这让我们这种不依赖cookie来存sessionid的人肿么办？\n\n如果你是phper，那么curl的`CURLOPT_FOLLOWLOCATION`可以让你的请求跟踪这次重定向，但我用nodejs的restify相关实现是无法正常的接受重定向响应的！\n\n所以我只能自己解析响应头，取出这个url，当然我们就不用傻傻的请求这个url了，因为该url里就已经携带了我们需要的access_token！这也使得我们在获取Code时前台传递的用户会话id不会丢失，因为我们并没有跳走嘛～～\n\n然后我们再来看看关于获取用户openid的操作（https://graph.qq.com/oauth2.0/me），该接口竟然是根据jsonp机制返回的，这尼玛是多久前的啊？\n\n所以我们需要自己去解析返回内容，这里我需要特别叮嘱的是，js平台（包括nodejs）下尽量避免使用`eval`函数，还是老老实实的正则匹配吧，不然，你懂的！\n\n代码我已发到[gihub](https://github.com/kazaff/third-part-auth)上，有兴趣的童鞋不妨去看看～","source":"_posts/qq第三方登录.md","raw":"title: QQ第三方登录\ndate: 2015-11-25 09:37:12\ntags: \n- QQ\n- OAuth\n- 第三方登录\ncategories: 前端\n---\n\n昨天搞的是微信登录，今天我们要来搞一下qq登录！\n<!--more-->\n但作为过来人，我想假装平静的说出心声：为啥同一个公司的两个产品系，文档质量就他奶奶个抓儿差那么多呢？\n\n如果说昨天搞微信很嗨皮的话，那么今天搞qq真的想在吃翔，我这暴脾气，唉～\n\n当然，这篇文章并非只是来吐槽的。言归正传，整体思路还是和[微信第三方登录](http://blog.kazaff.me/2015/11/24/%E5%BE%AE%E4%BF%A1%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95/)一致，我就不细说了，有兴趣的朋友可以看之前的那篇文章。\n\n我们接下来还是主要来关注qq登录接口不同于微信的地方！（文档，文档，渣文档就是最大的不同！妈蛋～）\n\n先来看一下[官方文档](http://wiki.connect.qq.com/%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C_oauth2-0)，如果你打开显示的是404错误，请多刷新几次，具体原因不清楚哇～\n\n文档一开始也正儿八经的给我们解释了解释OAuth，我们可以直接跳过啦～关键要注意的是它通过第1步得到的code换access_token的接口，也就是 \"https://graph.qq.com/oauth2.0/token\" 这个接口，它并不是像微信那样走的rest风格的服务，而是又借住了一次重定向来完成的！\n\n这尼玛怎么搞的？这多出的一跳不仅让你蛋疼，而且也丢失了state参数，这让我们这种不依赖cookie来存sessionid的人肿么办？\n\n如果你是phper，那么curl的`CURLOPT_FOLLOWLOCATION`可以让你的请求跟踪这次重定向，但我用nodejs的restify相关实现是无法正常的接受重定向响应的！\n\n所以我只能自己解析响应头，取出这个url，当然我们就不用傻傻的请求这个url了，因为该url里就已经携带了我们需要的access_token！这也使得我们在获取Code时前台传递的用户会话id不会丢失，因为我们并没有跳走嘛～～\n\n然后我们再来看看关于获取用户openid的操作（https://graph.qq.com/oauth2.0/me），该接口竟然是根据jsonp机制返回的，这尼玛是多久前的啊？\n\n所以我们需要自己去解析返回内容，这里我需要特别叮嘱的是，js平台（包括nodejs）下尽量避免使用`eval`函数，还是老老实实的正则匹配吧，不然，你懂的！\n\n代码我已发到[gihub](https://github.com/kazaff/third-part-auth)上，有兴趣的童鞋不妨去看看～","slug":"qq第三方登录","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"ciheqt5z50000pcwsp9aj90wr","comments":1,"layout":"post","photos":[],"link":"","content":"<p>昨天搞的是微信登录，今天我们要来搞一下qq登录！<br><a id=\"more\"></a><br>但作为过来人，我想假装平静的说出心声：为啥同一个公司的两个产品系，文档质量就他奶奶个抓儿差那么多呢？</p>\n<p>如果说昨天搞微信很嗨皮的话，那么今天搞qq真的想在吃翔，我这暴脾气，唉～</p>\n<p>当然，这篇文章并非只是来吐槽的。言归正传，整体思路还是和<a href=\"http://blog.kazaff.me/2015/11/24/%E5%BE%AE%E4%BF%A1%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95/\">微信第三方登录</a>一致，我就不细说了，有兴趣的朋友可以看之前的那篇文章。</p>\n<p>我们接下来还是主要来关注qq登录接口不同于微信的地方！（文档，文档，渣文档就是最大的不同！妈蛋～）</p>\n<p>先来看一下<a href=\"http://wiki.connect.qq.com/%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C_oauth2-0\" target=\"_blank\" rel=\"external\">官方文档</a>，如果你打开显示的是404错误，请多刷新几次，具体原因不清楚哇～</p>\n<p>文档一开始也正儿八经的给我们解释了解释OAuth，我们可以直接跳过啦～关键要注意的是它通过第1步得到的code换access_token的接口，也就是 “<a href=\"https://graph.qq.com/oauth2.0/token\" target=\"_blank\" rel=\"external\">https://graph.qq.com/oauth2.0/token</a>“ 这个接口，它并不是像微信那样走的rest风格的服务，而是又借住了一次重定向来完成的！</p>\n<p>这尼玛怎么搞的？这多出的一跳不仅让你蛋疼，而且也丢失了state参数，这让我们这种不依赖cookie来存sessionid的人肿么办？</p>\n<p>如果你是phper，那么curl的<code>CURLOPT_FOLLOWLOCATION</code>可以让你的请求跟踪这次重定向，但我用nodejs的restify相关实现是无法正常的接受重定向响应的！</p>\n<p>所以我只能自己解析响应头，取出这个url，当然我们就不用傻傻的请求这个url了，因为该url里就已经携带了我们需要的access_token！这也使得我们在获取Code时前台传递的用户会话id不会丢失，因为我们并没有跳走嘛～～</p>\n<p>然后我们再来看看关于获取用户openid的操作（<a href=\"https://graph.qq.com/oauth2.0/me），该接口竟然是根据jsonp机制返回的，这尼玛是多久前的啊？\" target=\"_blank\" rel=\"external\">https://graph.qq.com/oauth2.0/me），该接口竟然是根据jsonp机制返回的，这尼玛是多久前的啊？</a></p>\n<p>所以我们需要自己去解析返回内容，这里我需要特别叮嘱的是，js平台（包括nodejs）下尽量避免使用<code>eval</code>函数，还是老老实实的正则匹配吧，不然，你懂的！</p>\n<p>代码我已发到<a href=\"https://github.com/kazaff/third-part-auth\" target=\"_blank\" rel=\"external\">gihub</a>上，有兴趣的童鞋不妨去看看～</p>\n","excerpt":"<p>昨天搞的是微信登录，今天我们要来搞一下qq登录！<br>","more":"<br>但作为过来人，我想假装平静的说出心声：为啥同一个公司的两个产品系，文档质量就他奶奶个抓儿差那么多呢？</p>\n<p>如果说昨天搞微信很嗨皮的话，那么今天搞qq真的想在吃翔，我这暴脾气，唉～</p>\n<p>当然，这篇文章并非只是来吐槽的。言归正传，整体思路还是和<a href=\"http://blog.kazaff.me/2015/11/24/%E5%BE%AE%E4%BF%A1%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95/\">微信第三方登录</a>一致，我就不细说了，有兴趣的朋友可以看之前的那篇文章。</p>\n<p>我们接下来还是主要来关注qq登录接口不同于微信的地方！（文档，文档，渣文档就是最大的不同！妈蛋～）</p>\n<p>先来看一下<a href=\"http://wiki.connect.qq.com/%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C_oauth2-0\">官方文档</a>，如果你打开显示的是404错误，请多刷新几次，具体原因不清楚哇～</p>\n<p>文档一开始也正儿八经的给我们解释了解释OAuth，我们可以直接跳过啦～关键要注意的是它通过第1步得到的code换access_token的接口，也就是 “<a href=\"https://graph.qq.com/oauth2.0/token\">https://graph.qq.com/oauth2.0/token</a>“ 这个接口，它并不是像微信那样走的rest风格的服务，而是又借住了一次重定向来完成的！</p>\n<p>这尼玛怎么搞的？这多出的一跳不仅让你蛋疼，而且也丢失了state参数，这让我们这种不依赖cookie来存sessionid的人肿么办？</p>\n<p>如果你是phper，那么curl的<code>CURLOPT_FOLLOWLOCATION</code>可以让你的请求跟踪这次重定向，但我用nodejs的restify相关实现是无法正常的接受重定向响应的！</p>\n<p>所以我只能自己解析响应头，取出这个url，当然我们就不用傻傻的请求这个url了，因为该url里就已经携带了我们需要的access_token！这也使得我们在获取Code时前台传递的用户会话id不会丢失，因为我们并没有跳走嘛～～</p>\n<p>然后我们再来看看关于获取用户openid的操作（<a href=\"https://graph.qq.com/oauth2.0/me），该接口竟然是根据jsonp机制返回的，这尼玛是多久前的啊？\">https://graph.qq.com/oauth2.0/me），该接口竟然是根据jsonp机制返回的，这尼玛是多久前的啊？</a></p>\n<p>所以我们需要自己去解析返回内容，这里我需要特别叮嘱的是，js平台（包括nodejs）下尽量避免使用<code>eval</code>函数，还是老老实实的正则匹配吧，不然，你懂的！</p>\n<p>代码我已发到<a href=\"https://github.com/kazaff/third-part-auth\">gihub</a>上，有兴趣的童鞋不妨去看看～</p>"},{"title":"mac下react-native-android环境搭建","date":"2015-12-02T01:37:12.000Z","_content":"\n最近闲来无事，就决定摆弄摆弄react-native，其实之前尝试过，不过那个时候react-native还没有出android版，而ios版本的环境搭建只需要给xcode装上，基本上就算搭建完成了。而这次大意了，原以为android环境会一样简单明了的，随便看了几篇环境搭建的帖子就以为能轻松完成，结果一搞就搞了一天半啊～\n<!--more-->\n\n首先吐槽的就是，很多博客里写的安装步骤其实都不是很具体，总是缺少一些细节，对我这种小白来说就会变成噩梦！虽然我这篇可能也无法保证事无巨细，但至少我碰见的坑我会叮嘱一下大家撒～\n\n其实说了那么多，都怪自己太懒，按照官方提供的搭建流程，基本上就会规避非常多的坑，强烈推荐看官方手册：\n\n- [步骤一](https://facebook.github.io/react-native/docs/getting-started.html#content)\n- [步骤二](https://facebook.github.io/react-native/docs/android-setup.html)\n\n下面主要来说说我自己碰见的坑吧，希望能帮助到你～\n\n官方推荐（很多博客也推荐），使用brew来安装android-sdk，但我一开始是从另外一个博客上看到的，自己去找了一个mac版本的android sdk manger，按说应该和brew安装的一样，只不过位置不同而已～可是后面却碰到了死活无法找到android sdk的路径问题。单这一个问题就让我花了半天来排查，主要是无法搜索到有用的资料！\n\n删除掉自己下载的那个manger，使用brew安装即可：\n\n\tbrew install android-sdk\n\t\n不过一定要按照顺序来，第一步肯定是要保证你的mac下已经安装了jdk，直接gg可以搜索到mac版的jdk安装文件的！brew貌似无法安装jdk～～\n\n第二个坑呢，就是这个“ANDROID_HOME”环境变量的问题了，由于第一步我们是使用brew来安装android-sdk的，所以安装位置在“/usr/local/opt/android-sdk”，官方有叮嘱这一步，我的步骤是：\n\n\tcd ~\n\ttouch .bash_profile\n\tvi .bash_profile\n\n然后在打开的输入界面贴进去：\n\n\texport ANDROID_HOME=/usr/local/opt/android-sdk\n\t\n保存退出，并关闭终端！！！\n\n第三个坑，是一定要安装最新版本的watchman和flow：\n\n\tbrew install watchman\n\tbrew install flow\n\t\n不然你执行“react-native run-android”后，开启的node server终端总是会报错，提示什么\"root of null\"！我由于之前就装过watchman，可能是版本问题，又让我花了tm的多半天！！\n\n第四个坑，是当执行“react-native run-android”后，会下载大量的jar包，如果中间出现卡住了，可以直接ctrl+C，然后重新运行命令，要说的不是这个问题，当你下载完所有的包后，会开始部署代码，这个时候可能会碰到一个类似“xxx parent directory xxxx”无法创建的问题，应该是gradle无权限操作目录的问题，我尝试使用sudo来切换成root账号，结果会碰到由于切换了用户，之前设置的“ANDROID_HOME”环境变量未定义的问题，所以对于和我一样的小白来说，最简单的就是在你的项目文件上右键“简介”，弹出的窗口最下面调整一下操作权限，并记得继承到所有下级目录上！！！\n\n\n第五个坑，还是绕回来说android-sdk，安装完后执行：\n\n\tandroid\n\t\n该命令会打开一个界面，按照官方说的安装所有的推荐工具包，强烈推荐选择统一的版本，比方说23.0.1，不然会碰到对应版本找不到的报错！我贴一下我这边目前选择的包情况：\n\n![](http://pic.yupoo.com/kazaff/F9aG4ZAQ/4wZMw.jpg)\n\n![](http://pic.yupoo.com/kazaff/F9aG5Lb8/alWUY.jpg)\n\n![](http://pic.yupoo.com/kazaff/F9aG6uNJ/ywiXw.jpg)\n\n![](http://pic.yupoo.com/kazaff/F9aG7Zl0/hpstJ.jpg)\n\t\n未必都有用，但是至少不保错了！\n\n\n最后，对于跟我一样使用老mac的玩家，强烈推荐不要使用android-sdk自建模拟器，因为那真的实在是太tm的卡了！我足足等了30分钟，开启后还进到android系统后还是很卡～可能是我配置的不好吧，但这种方式的体验真的好差！\n\n按照官方推荐的，我们乖乖的来使用Genymotion，选择个人开发者，注册账号即可免费下载，然后再根据要求下载个最新版本的VirtualBox即可！配置非常简单，启动很迅速，效果好极了！但很多功能都是收费版的，不过对于尝鲜的我来说，足够了！\n\n这一趟下来，感觉好麻烦！还是react-native-ios爽一些，不过android还是不能错过的！！\n\n一切就绪，只需要run-android了！\n\n真机调试一样的简单，只需要插上数据线即可，当然，要记得把手机开启usb调试模式，我使用的是锤子坚果手机，连接后会弹出授权窗口，不确认会提示无法连接设备的哟～\n\n最后你还可能碰见无法加载jsbundle的问题，只需要摇晃手机，在弹出菜单中选择 Dev Setting > Debug Server host for device，然后填入 Mac 的 IP 地址（ifconfig 命令可查看本机 IP）即可！\n\n参考：[http://www.liaohuqiu.net/cn/posts/react-native-1/](http://www.liaohuqiu.net/cn/posts/react-native-1/)\n","source":"_posts/mac下react-native-android环境搭建.md","raw":"title: mac下react-native-android环境搭建\ndate: 2015-12-02 09:37:12\ntags: \n- react-native\n- android\n- mac\ncategories: 移动端\n---\n\n最近闲来无事，就决定摆弄摆弄react-native，其实之前尝试过，不过那个时候react-native还没有出android版，而ios版本的环境搭建只需要给xcode装上，基本上就算搭建完成了。而这次大意了，原以为android环境会一样简单明了的，随便看了几篇环境搭建的帖子就以为能轻松完成，结果一搞就搞了一天半啊～\n<!--more-->\n\n首先吐槽的就是，很多博客里写的安装步骤其实都不是很具体，总是缺少一些细节，对我这种小白来说就会变成噩梦！虽然我这篇可能也无法保证事无巨细，但至少我碰见的坑我会叮嘱一下大家撒～\n\n其实说了那么多，都怪自己太懒，按照官方提供的搭建流程，基本上就会规避非常多的坑，强烈推荐看官方手册：\n\n- [步骤一](https://facebook.github.io/react-native/docs/getting-started.html#content)\n- [步骤二](https://facebook.github.io/react-native/docs/android-setup.html)\n\n下面主要来说说我自己碰见的坑吧，希望能帮助到你～\n\n官方推荐（很多博客也推荐），使用brew来安装android-sdk，但我一开始是从另外一个博客上看到的，自己去找了一个mac版本的android sdk manger，按说应该和brew安装的一样，只不过位置不同而已～可是后面却碰到了死活无法找到android sdk的路径问题。单这一个问题就让我花了半天来排查，主要是无法搜索到有用的资料！\n\n删除掉自己下载的那个manger，使用brew安装即可：\n\n\tbrew install android-sdk\n\t\n不过一定要按照顺序来，第一步肯定是要保证你的mac下已经安装了jdk，直接gg可以搜索到mac版的jdk安装文件的！brew貌似无法安装jdk～～\n\n第二个坑呢，就是这个“ANDROID_HOME”环境变量的问题了，由于第一步我们是使用brew来安装android-sdk的，所以安装位置在“/usr/local/opt/android-sdk”，官方有叮嘱这一步，我的步骤是：\n\n\tcd ~\n\ttouch .bash_profile\n\tvi .bash_profile\n\n然后在打开的输入界面贴进去：\n\n\texport ANDROID_HOME=/usr/local/opt/android-sdk\n\t\n保存退出，并关闭终端！！！\n\n第三个坑，是一定要安装最新版本的watchman和flow：\n\n\tbrew install watchman\n\tbrew install flow\n\t\n不然你执行“react-native run-android”后，开启的node server终端总是会报错，提示什么\"root of null\"！我由于之前就装过watchman，可能是版本问题，又让我花了tm的多半天！！\n\n第四个坑，是当执行“react-native run-android”后，会下载大量的jar包，如果中间出现卡住了，可以直接ctrl+C，然后重新运行命令，要说的不是这个问题，当你下载完所有的包后，会开始部署代码，这个时候可能会碰到一个类似“xxx parent directory xxxx”无法创建的问题，应该是gradle无权限操作目录的问题，我尝试使用sudo来切换成root账号，结果会碰到由于切换了用户，之前设置的“ANDROID_HOME”环境变量未定义的问题，所以对于和我一样的小白来说，最简单的就是在你的项目文件上右键“简介”，弹出的窗口最下面调整一下操作权限，并记得继承到所有下级目录上！！！\n\n\n第五个坑，还是绕回来说android-sdk，安装完后执行：\n\n\tandroid\n\t\n该命令会打开一个界面，按照官方说的安装所有的推荐工具包，强烈推荐选择统一的版本，比方说23.0.1，不然会碰到对应版本找不到的报错！我贴一下我这边目前选择的包情况：\n\n![](http://pic.yupoo.com/kazaff/F9aG4ZAQ/4wZMw.jpg)\n\n![](http://pic.yupoo.com/kazaff/F9aG5Lb8/alWUY.jpg)\n\n![](http://pic.yupoo.com/kazaff/F9aG6uNJ/ywiXw.jpg)\n\n![](http://pic.yupoo.com/kazaff/F9aG7Zl0/hpstJ.jpg)\n\t\n未必都有用，但是至少不保错了！\n\n\n最后，对于跟我一样使用老mac的玩家，强烈推荐不要使用android-sdk自建模拟器，因为那真的实在是太tm的卡了！我足足等了30分钟，开启后还进到android系统后还是很卡～可能是我配置的不好吧，但这种方式的体验真的好差！\n\n按照官方推荐的，我们乖乖的来使用Genymotion，选择个人开发者，注册账号即可免费下载，然后再根据要求下载个最新版本的VirtualBox即可！配置非常简单，启动很迅速，效果好极了！但很多功能都是收费版的，不过对于尝鲜的我来说，足够了！\n\n这一趟下来，感觉好麻烦！还是react-native-ios爽一些，不过android还是不能错过的！！\n\n一切就绪，只需要run-android了！\n\n真机调试一样的简单，只需要插上数据线即可，当然，要记得把手机开启usb调试模式，我使用的是锤子坚果手机，连接后会弹出授权窗口，不确认会提示无法连接设备的哟～\n\n最后你还可能碰见无法加载jsbundle的问题，只需要摇晃手机，在弹出菜单中选择 Dev Setting > Debug Server host for device，然后填入 Mac 的 IP 地址（ifconfig 命令可查看本机 IP）即可！\n\n参考：[http://www.liaohuqiu.net/cn/posts/react-native-1/](http://www.liaohuqiu.net/cn/posts/react-native-1/)\n","slug":"mac下react-native-android环境搭建","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cihp0xupj0000mzfyi5dmkm9f","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近闲来无事，就决定摆弄摆弄react-native，其实之前尝试过，不过那个时候react-native还没有出android版，而ios版本的环境搭建只需要给xcode装上，基本上就算搭建完成了。而这次大意了，原以为android环境会一样简单明了的，随便看了几篇环境搭建的帖子就以为能轻松完成，结果一搞就搞了一天半啊～<br><a id=\"more\"></a></p>\n<p>首先吐槽的就是，很多博客里写的安装步骤其实都不是很具体，总是缺少一些细节，对我这种小白来说就会变成噩梦！虽然我这篇可能也无法保证事无巨细，但至少我碰见的坑我会叮嘱一下大家撒～</p>\n<p>其实说了那么多，都怪自己太懒，按照官方提供的搭建流程，基本上就会规避非常多的坑，强烈推荐看官方手册：</p>\n<ul>\n<li><a href=\"https://facebook.github.io/react-native/docs/getting-started.html#content\" target=\"_blank\" rel=\"external\">步骤一</a></li>\n<li><a href=\"https://facebook.github.io/react-native/docs/android-setup.html\" target=\"_blank\" rel=\"external\">步骤二</a></li>\n</ul>\n<p>下面主要来说说我自己碰见的坑吧，希望能帮助到你～</p>\n<p>官方推荐（很多博客也推荐），使用brew来安装android-sdk，但我一开始是从另外一个博客上看到的，自己去找了一个mac版本的android sdk manger，按说应该和brew安装的一样，只不过位置不同而已～可是后面却碰到了死活无法找到android sdk的路径问题。单这一个问题就让我花了半天来排查，主要是无法搜索到有用的资料！</p>\n<p>删除掉自己下载的那个manger，使用brew安装即可：</p>\n<pre><code>brew install android-sdk\n</code></pre><p>不过一定要按照顺序来，第一步肯定是要保证你的mac下已经安装了jdk，直接gg可以搜索到mac版的jdk安装文件的！brew貌似无法安装jdk～～</p>\n<p>第二个坑呢，就是这个“ANDROID_HOME”环境变量的问题了，由于第一步我们是使用brew来安装android-sdk的，所以安装位置在“/usr/local/opt/android-sdk”，官方有叮嘱这一步，我的步骤是：</p>\n<pre><code>cd ~\ntouch .bash_profile\nvi .bash_profile\n</code></pre><p>然后在打开的输入界面贴进去：</p>\n<pre><code>export ANDROID_HOME=/usr/local/opt/android-sdk\n</code></pre><p>保存退出，并关闭终端！！！</p>\n<p>第三个坑，是一定要安装最新版本的watchman和flow：</p>\n<pre><code>brew install watchman\nbrew install flow\n</code></pre><p>不然你执行“react-native run-android”后，开启的node server终端总是会报错，提示什么”root of null”！我由于之前就装过watchman，可能是版本问题，又让我花了tm的多半天！！</p>\n<p>第四个坑，是当执行“react-native run-android”后，会下载大量的jar包，如果中间出现卡住了，可以直接ctrl+C，然后重新运行命令，要说的不是这个问题，当你下载完所有的包后，会开始部署代码，这个时候可能会碰到一个类似“xxx parent directory xxxx”无法创建的问题，应该是gradle无权限操作目录的问题，我尝试使用sudo来切换成root账号，结果会碰到由于切换了用户，之前设置的“ANDROID_HOME”环境变量未定义的问题，所以对于和我一样的小白来说，最简单的就是在你的项目文件上右键“简介”，弹出的窗口最下面调整一下操作权限，并记得继承到所有下级目录上！！！</p>\n<p>第五个坑，还是绕回来说android-sdk，安装完后执行：</p>\n<pre><code>android\n</code></pre><p>该命令会打开一个界面，按照官方说的安装所有的推荐工具包，强烈推荐选择统一的版本，比方说23.0.1，不然会碰到对应版本找不到的报错！我贴一下我这边目前选择的包情况：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG4ZAQ/4wZMw.jpg\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG5Lb8/alWUY.jpg\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG6uNJ/ywiXw.jpg\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG7Zl0/hpstJ.jpg\" alt=\"\"></p>\n<p>未必都有用，但是至少不保错了！</p>\n<p>最后，对于跟我一样使用老mac的玩家，强烈推荐不要使用android-sdk自建模拟器，因为那真的实在是太tm的卡了！我足足等了30分钟，开启后还进到android系统后还是很卡～可能是我配置的不好吧，但这种方式的体验真的好差！</p>\n<p>按照官方推荐的，我们乖乖的来使用Genymotion，选择个人开发者，注册账号即可免费下载，然后再根据要求下载个最新版本的VirtualBox即可！配置非常简单，启动很迅速，效果好极了！但很多功能都是收费版的，不过对于尝鲜的我来说，足够了！</p>\n<p>这一趟下来，感觉好麻烦！还是react-native-ios爽一些，不过android还是不能错过的！！</p>\n<p>一切就绪，只需要run-android了！</p>\n<p>真机调试一样的简单，只需要插上数据线即可，当然，要记得把手机开启usb调试模式，我使用的是锤子坚果手机，连接后会弹出授权窗口，不确认会提示无法连接设备的哟～</p>\n<p>最后你还可能碰见无法加载jsbundle的问题，只需要摇晃手机，在弹出菜单中选择 Dev Setting &gt; Debug Server host for device，然后填入 Mac 的 IP 地址（ifconfig 命令可查看本机 IP）即可！</p>\n<p>参考：<a href=\"http://www.liaohuqiu.net/cn/posts/react-native-1/\" target=\"_blank\" rel=\"external\">http://www.liaohuqiu.net/cn/posts/react-native-1/</a></p>\n","excerpt":"<p>最近闲来无事，就决定摆弄摆弄react-native，其实之前尝试过，不过那个时候react-native还没有出android版，而ios版本的环境搭建只需要给xcode装上，基本上就算搭建完成了。而这次大意了，原以为android环境会一样简单明了的，随便看了几篇环境搭建的帖子就以为能轻松完成，结果一搞就搞了一天半啊～<br>","more":"</p>\n<p>首先吐槽的就是，很多博客里写的安装步骤其实都不是很具体，总是缺少一些细节，对我这种小白来说就会变成噩梦！虽然我这篇可能也无法保证事无巨细，但至少我碰见的坑我会叮嘱一下大家撒～</p>\n<p>其实说了那么多，都怪自己太懒，按照官方提供的搭建流程，基本上就会规避非常多的坑，强烈推荐看官方手册：</p>\n<ul>\n<li><a href=\"https://facebook.github.io/react-native/docs/getting-started.html#content\">步骤一</a></li>\n<li><a href=\"https://facebook.github.io/react-native/docs/android-setup.html\">步骤二</a></li>\n</ul>\n<p>下面主要来说说我自己碰见的坑吧，希望能帮助到你～</p>\n<p>官方推荐（很多博客也推荐），使用brew来安装android-sdk，但我一开始是从另外一个博客上看到的，自己去找了一个mac版本的android sdk manger，按说应该和brew安装的一样，只不过位置不同而已～可是后面却碰到了死活无法找到android sdk的路径问题。单这一个问题就让我花了半天来排查，主要是无法搜索到有用的资料！</p>\n<p>删除掉自己下载的那个manger，使用brew安装即可：</p>\n<pre><code>brew install android-sdk\n</code></pre><p>不过一定要按照顺序来，第一步肯定是要保证你的mac下已经安装了jdk，直接gg可以搜索到mac版的jdk安装文件的！brew貌似无法安装jdk～～</p>\n<p>第二个坑呢，就是这个“ANDROID_HOME”环境变量的问题了，由于第一步我们是使用brew来安装android-sdk的，所以安装位置在“/usr/local/opt/android-sdk”，官方有叮嘱这一步，我的步骤是：</p>\n<pre><code>cd ~\ntouch .bash_profile\nvi .bash_profile\n</code></pre><p>然后在打开的输入界面贴进去：</p>\n<pre><code>export ANDROID_HOME=/usr/local/opt/android-sdk\n</code></pre><p>保存退出，并关闭终端！！！</p>\n<p>第三个坑，是一定要安装最新版本的watchman和flow：</p>\n<pre><code>brew install watchman\nbrew install flow\n</code></pre><p>不然你执行“react-native run-android”后，开启的node server终端总是会报错，提示什么”root of null”！我由于之前就装过watchman，可能是版本问题，又让我花了tm的多半天！！</p>\n<p>第四个坑，是当执行“react-native run-android”后，会下载大量的jar包，如果中间出现卡住了，可以直接ctrl+C，然后重新运行命令，要说的不是这个问题，当你下载完所有的包后，会开始部署代码，这个时候可能会碰到一个类似“xxx parent directory xxxx”无法创建的问题，应该是gradle无权限操作目录的问题，我尝试使用sudo来切换成root账号，结果会碰到由于切换了用户，之前设置的“ANDROID_HOME”环境变量未定义的问题，所以对于和我一样的小白来说，最简单的就是在你的项目文件上右键“简介”，弹出的窗口最下面调整一下操作权限，并记得继承到所有下级目录上！！！</p>\n<p>第五个坑，还是绕回来说android-sdk，安装完后执行：</p>\n<pre><code>android\n</code></pre><p>该命令会打开一个界面，按照官方说的安装所有的推荐工具包，强烈推荐选择统一的版本，比方说23.0.1，不然会碰到对应版本找不到的报错！我贴一下我这边目前选择的包情况：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG4ZAQ/4wZMw.jpg\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG5Lb8/alWUY.jpg\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG6uNJ/ywiXw.jpg\" alt=\"\"></p>\n<p><img src=\"http://pic.yupoo.com/kazaff/F9aG7Zl0/hpstJ.jpg\" alt=\"\"></p>\n<p>未必都有用，但是至少不保错了！</p>\n<p>最后，对于跟我一样使用老mac的玩家，强烈推荐不要使用android-sdk自建模拟器，因为那真的实在是太tm的卡了！我足足等了30分钟，开启后还进到android系统后还是很卡～可能是我配置的不好吧，但这种方式的体验真的好差！</p>\n<p>按照官方推荐的，我们乖乖的来使用Genymotion，选择个人开发者，注册账号即可免费下载，然后再根据要求下载个最新版本的VirtualBox即可！配置非常简单，启动很迅速，效果好极了！但很多功能都是收费版的，不过对于尝鲜的我来说，足够了！</p>\n<p>这一趟下来，感觉好麻烦！还是react-native-ios爽一些，不过android还是不能错过的！！</p>\n<p>一切就绪，只需要run-android了！</p>\n<p>真机调试一样的简单，只需要插上数据线即可，当然，要记得把手机开启usb调试模式，我使用的是锤子坚果手机，连接后会弹出授权窗口，不确认会提示无法连接设备的哟～</p>\n<p>最后你还可能碰见无法加载jsbundle的问题，只需要摇晃手机，在弹出菜单中选择 Dev Setting &gt; Debug Server host for device，然后填入 Mac 的 IP 地址（ifconfig 命令可查看本机 IP）即可！</p>\n<p>参考：<a href=\"http://www.liaohuqiu.net/cn/posts/react-native-1/\">http://www.liaohuqiu.net/cn/posts/react-native-1/</a></p>"},{"title":"android的浏览器下无法表单提交附件","date":"2015-12-04T01:37:12.000Z","_content":"\n今天刚发现一个bug，很小，但是很恶心：用android的内置浏览器无法上传表单附件。\n\ngg了一下，发现这里讲的[方法](http://stackoverflow.com/questions/6569919/does-the-android-web-browser-allow-uploading-photos-just-taken-from-camera)貌似可行：\n\n\t<input type=\"file\" name=\"photo\" accept=\"image/*\" capture=\"camera\">\n\t\n注意添加的那个属性：**capture=\"camera\"**\n\n本以为大功告成，谁知道微信内部浏览器还是不行，妈蛋，一搜才知道，好多人都反应这个问题，从13年就有相关提问，我也是日了狗了，怎么还是没修复？而且android下的微信内置浏览器连个刷新功能都没有，这尼玛是不是在耍贱呢？\n\n好，那大家都是怎么解决微信下的这个问题呢？看到几个方案貌似大家比较赞同：\n\n[方案一](http://www.zhihu.com/question/21452742)：大概意思就是一旦判断出用户所在的是微信环境，就引导用户切换到系统浏览器下，这算是成本最低方案了。\n\n[方案二](https://segmentfault.com/q/1010000002479491)：使用的是微信提供的js-sdk，相当于让用户把图片先提交给微信服务器，然后在让自己系统的后台去下载，听起来就麻烦，而且貌似这个上传接口是需要去认证公众号，还有调用频次限制！\n\n我觉得吧，这就是作！微信中明明看到了其使用的内置浏览器是基于qq浏览器的，单独使用qq浏览器就可以上传附件，怎么就在微信里就不行？！如果是基于安全考虑的，那为啥ios的微信就可以上传图片呢？！\n\n好了不说了，睡觉……\n","source":"_posts/android的浏览器下无法表单提交附件.md","raw":"title: android的浏览器下无法表单提交附件\ndate: 2015-12-04 09:37:12\ntags: \n- 微信浏览器\n- android\n- 附件上传\ncategories: 移动端\n---\n\n今天刚发现一个bug，很小，但是很恶心：用android的内置浏览器无法上传表单附件。\n\ngg了一下，发现这里讲的[方法](http://stackoverflow.com/questions/6569919/does-the-android-web-browser-allow-uploading-photos-just-taken-from-camera)貌似可行：\n\n\t<input type=\"file\" name=\"photo\" accept=\"image/*\" capture=\"camera\">\n\t\n注意添加的那个属性：**capture=\"camera\"**\n\n本以为大功告成，谁知道微信内部浏览器还是不行，妈蛋，一搜才知道，好多人都反应这个问题，从13年就有相关提问，我也是日了狗了，怎么还是没修复？而且android下的微信内置浏览器连个刷新功能都没有，这尼玛是不是在耍贱呢？\n\n好，那大家都是怎么解决微信下的这个问题呢？看到几个方案貌似大家比较赞同：\n\n[方案一](http://www.zhihu.com/question/21452742)：大概意思就是一旦判断出用户所在的是微信环境，就引导用户切换到系统浏览器下，这算是成本最低方案了。\n\n[方案二](https://segmentfault.com/q/1010000002479491)：使用的是微信提供的js-sdk，相当于让用户把图片先提交给微信服务器，然后在让自己系统的后台去下载，听起来就麻烦，而且貌似这个上传接口是需要去认证公众号，还有调用频次限制！\n\n我觉得吧，这就是作！微信中明明看到了其使用的内置浏览器是基于qq浏览器的，单独使用qq浏览器就可以上传附件，怎么就在微信里就不行？！如果是基于安全考虑的，那为啥ios的微信就可以上传图片呢？！\n\n好了不说了，睡觉……\n","slug":"android的浏览器下无法表单提交附件","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cihqgv1xn0000kywsei8jfi6v","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天刚发现一个bug，很小，但是很恶心：用android的内置浏览器无法上传表单附件。</p>\n<p>gg了一下，发现这里讲的<a href=\"http://stackoverflow.com/questions/6569919/does-the-android-web-browser-allow-uploading-photos-just-taken-from-camera\" target=\"_blank\" rel=\"external\">方法</a>貌似可行：</p>\n<pre><code>&lt;input type=&quot;file&quot; name=&quot;photo&quot; accept=&quot;image/*&quot; capture=&quot;camera&quot;&gt;\n</code></pre><p>注意添加的那个属性：<strong>capture=”camera”</strong></p>\n<p>本以为大功告成，谁知道微信内部浏览器还是不行，妈蛋，一搜才知道，好多人都反应这个问题，从13年就有相关提问，我也是日了狗了，怎么还是没修复？而且android下的微信内置浏览器连个刷新功能都没有，这尼玛是不是在耍贱呢？</p>\n<p>好，那大家都是怎么解决微信下的这个问题呢？看到几个方案貌似大家比较赞同：</p>\n<p><a href=\"http://www.zhihu.com/question/21452742\" target=\"_blank\" rel=\"external\">方案一</a>：大概意思就是一旦判断出用户所在的是微信环境，就引导用户切换到系统浏览器下，这算是成本最低方案了。</p>\n<p><a href=\"https://segmentfault.com/q/1010000002479491\" target=\"_blank\" rel=\"external\">方案二</a>：使用的是微信提供的js-sdk，相当于让用户把图片先提交给微信服务器，然后在让自己系统的后台去下载，听起来就麻烦，而且貌似这个上传接口是需要去认证公众号，还有调用频次限制！</p>\n<p>我觉得吧，这就是作！微信中明明看到了其使用的内置浏览器是基于qq浏览器的，单独使用qq浏览器就可以上传附件，怎么就在微信里就不行？！如果是基于安全考虑的，那为啥ios的微信就可以上传图片呢？！</p>\n<p>好了不说了，睡觉……</p>\n","excerpt":"","more":"<p>今天刚发现一个bug，很小，但是很恶心：用android的内置浏览器无法上传表单附件。</p>\n<p>gg了一下，发现这里讲的<a href=\"http://stackoverflow.com/questions/6569919/does-the-android-web-browser-allow-uploading-photos-just-taken-from-camera\">方法</a>貌似可行：</p>\n<pre><code>&lt;input type=&quot;file&quot; name=&quot;photo&quot; accept=&quot;image/*&quot; capture=&quot;camera&quot;&gt;\n</code></pre><p>注意添加的那个属性：<strong>capture=”camera”</strong></p>\n<p>本以为大功告成，谁知道微信内部浏览器还是不行，妈蛋，一搜才知道，好多人都反应这个问题，从13年就有相关提问，我也是日了狗了，怎么还是没修复？而且android下的微信内置浏览器连个刷新功能都没有，这尼玛是不是在耍贱呢？</p>\n<p>好，那大家都是怎么解决微信下的这个问题呢？看到几个方案貌似大家比较赞同：</p>\n<p><a href=\"http://www.zhihu.com/question/21452742\">方案一</a>：大概意思就是一旦判断出用户所在的是微信环境，就引导用户切换到系统浏览器下，这算是成本最低方案了。</p>\n<p><a href=\"https://segmentfault.com/q/1010000002479491\">方案二</a>：使用的是微信提供的js-sdk，相当于让用户把图片先提交给微信服务器，然后在让自己系统的后台去下载，听起来就麻烦，而且貌似这个上传接口是需要去认证公众号，还有调用频次限制！</p>\n<p>我觉得吧，这就是作！微信中明明看到了其使用的内置浏览器是基于qq浏览器的，单独使用qq浏览器就可以上传附件，怎么就在微信里就不行？！如果是基于安全考虑的，那为啥ios的微信就可以上传图片呢？！</p>\n<p>好了不说了，睡觉……</p>\n"},{"title":"React-Native-Android小结","date":"2015-12-21T01:37:12.000Z","_content":"\n最近尝试使用react-native android为我们的一个创业项目写了一个demo，项目放在[github](https://github.com/kazaff/ZhuiYuanDemo)了，有兴趣的朋友可以看看，下面给出一些效果：\n<!--more-->\n\n<embed src=\"http://player.youku.com/player.php/sid/XMTQxOTg2Nzk2MA==/v.swf\" allowFullScreen=\"true\" quality=\"high\" width=\"480\" height=\"400\" align=\"middle\" allowScriptAccess=\"always\" type=\"application/x-shockwave-flash\"></embed>\n\n\n###关于height\n\t\n很多时候，这都是一个不折不扣的大坑，比方说当你Image加载一个网络图片时，如果你不给该Image设置width和height，那你将什么都看不到。这还不算，当你使用ListView时如果该组件同时存在一个兄弟元素，那么此时ListView必须设置height，否则你会发现它不再响应用户的滚动操作。。。\n\n###关于Fetch\n\n当你试图提交附件表单数据的时候，请一定要使用FormData对象将数据包裹，这应该算不上什么太古怪的事儿～\n\n如果你只是普通的json提交，就按照官方例子来做：\n\n\tfetch(API_LOGIN_URL, {\n        method: 'POST',\n        headers: {\n          'Accept': 'application/json',\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          account: this.state.account,\n          password: this.state.password,\n        })\n      })\n    .....\n\n不然fetch会报错说你使用了不支持的body属性值类型～\n\n如果你和我一样需要实现类似用户头像修改的功能，你可能需要下面两个类库：\n\n[react-native-image-picker](https://github.com/marcshilling/react-native-image-picker)：用于头像图片获取\n\n[react-native-fileupload](https://github.com/PhilippKrone/react-native-fileupload)：用于图片文件表单上传，这是由于你使用image-picker获取到的图片只是本地url，你需要这个uploader来组装成原始的file上传表单～～\n\n顺便说一下，第三方依赖更新较快，代码也可能有bug，各种bug，所以你最好主动的去github上和项目的维护人员沟通，一起想办法解决问题～～\n\n\n###关于async/await\n\n至少在我目前的环境（默认安装react-native0.16.0自带的babel）是没有默认开启该特性的，不过貌似是可以手动开启的，有兴趣可以看[这里](https://medium.com/the-exponent-log/react-native-meets-async-functions-3e6f81111173#.ekvqrsala)。\n\n###关于第三方类库\n\n个人感觉，目前很多关注度高的第三方库还是值得信赖的，不过面向android平台的库功能还不足够强大，这可能由于fb刚开源不久的缘故，但是关注度高的库的作者响应也一般都很快，这一点很值得赞许～\n\n但是，老实讲，如果你要开发的app包含大量特殊的业务，或者效果，这个时候你就只能自己去实现FB暂时没有提供的原生控件了，这就要求你同时要熟悉android原生开发，目前这个阶段，我觉得你是无法避免这种尴尬局面的。\n\n###响应屏幕尺寸的变化\n\nFB提供了Dimensions组件可以用来获取屏幕的当前尺寸：\n\n\tvar deviceHeight = Dimensions.get('window').height;\n\tvar deviceWidth = Dimensions.get('window').width;\n\t\n不过，由于设备可能旋转，所以如果你的app支持设备旋转的话，你就需要找到一种方法来实时获取当前设备尺寸，官方推荐的方法是每次render都要调用这个方法来刷新设备尺寸，**而目前我还没有解决，主要是不知道应该如何获取屏幕旋转事件～～**\n\n###style小知识\n\n当你打算在某个控件上套用设置好的某个样式，但需要单独为其设置一个额外特殊值时，你可以这样：\n\n\t<View style={[styles.demo, {backgroundColor: \"blue\"}]}></View>\n\n我也不懂，为何用数组类型的，但就是能这么写哟～\n\n###布局\n\n布局和web比起来其实不算复杂，但你务必要掌握Flex布局，强烈推荐看[这里](http://www.ruanyifeng.com/blog/2015/07/flex-grammar.html#show-last-Point)。\n\n###TextInput\n\n这里主要说的是键盘问题，当用户点击这个控件后，系统会弹出键盘，这个键盘会占据屏幕控件的，所以，你可以将整个表单View放在ScollView中！这样用户就可以在屏幕上进行滚动了，但注意，滚动的是整个表单View，而不是滚动的TextInput内容（当你设置为支持多行输入时），最后还有就是别忘了给ScollView添加keyboardDismissMode属性，如下：\n\t<ScrollView keyboardDismissMode=\"on-drag\">\n\n该属性会在滚动触发后自动关闭键盘～～\n\n***至于怎么滚动TextInput内部数据，目前没找到方法。***\n\n默认android系统的TextInput会有一个丑陋的下边框，style是无法去掉它的，不过你可以使用underlineColorAndroid属性将其设置为与背景色一样，来达到隐藏效果，这个时候你在外部包一个View来定义样式即可～～\n\n\n\n\n","source":"_posts/React-Native-Android小结.md","raw":"title: React-Native-Android小结\ndate: 2015-12-21 09:37:12\ntags: \n- react-native\n- android\ncategories: 移动端\n---\n\n最近尝试使用react-native android为我们的一个创业项目写了一个demo，项目放在[github](https://github.com/kazaff/ZhuiYuanDemo)了，有兴趣的朋友可以看看，下面给出一些效果：\n<!--more-->\n\n<embed src=\"http://player.youku.com/player.php/sid/XMTQxOTg2Nzk2MA==/v.swf\" allowFullScreen=\"true\" quality=\"high\" width=\"480\" height=\"400\" align=\"middle\" allowScriptAccess=\"always\" type=\"application/x-shockwave-flash\"></embed>\n\n\n###关于height\n\t\n很多时候，这都是一个不折不扣的大坑，比方说当你Image加载一个网络图片时，如果你不给该Image设置width和height，那你将什么都看不到。这还不算，当你使用ListView时如果该组件同时存在一个兄弟元素，那么此时ListView必须设置height，否则你会发现它不再响应用户的滚动操作。。。\n\n###关于Fetch\n\n当你试图提交附件表单数据的时候，请一定要使用FormData对象将数据包裹，这应该算不上什么太古怪的事儿～\n\n如果你只是普通的json提交，就按照官方例子来做：\n\n\tfetch(API_LOGIN_URL, {\n        method: 'POST',\n        headers: {\n          'Accept': 'application/json',\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          account: this.state.account,\n          password: this.state.password,\n        })\n      })\n    .....\n\n不然fetch会报错说你使用了不支持的body属性值类型～\n\n如果你和我一样需要实现类似用户头像修改的功能，你可能需要下面两个类库：\n\n[react-native-image-picker](https://github.com/marcshilling/react-native-image-picker)：用于头像图片获取\n\n[react-native-fileupload](https://github.com/PhilippKrone/react-native-fileupload)：用于图片文件表单上传，这是由于你使用image-picker获取到的图片只是本地url，你需要这个uploader来组装成原始的file上传表单～～\n\n顺便说一下，第三方依赖更新较快，代码也可能有bug，各种bug，所以你最好主动的去github上和项目的维护人员沟通，一起想办法解决问题～～\n\n\n###关于async/await\n\n至少在我目前的环境（默认安装react-native0.16.0自带的babel）是没有默认开启该特性的，不过貌似是可以手动开启的，有兴趣可以看[这里](https://medium.com/the-exponent-log/react-native-meets-async-functions-3e6f81111173#.ekvqrsala)。\n\n###关于第三方类库\n\n个人感觉，目前很多关注度高的第三方库还是值得信赖的，不过面向android平台的库功能还不足够强大，这可能由于fb刚开源不久的缘故，但是关注度高的库的作者响应也一般都很快，这一点很值得赞许～\n\n但是，老实讲，如果你要开发的app包含大量特殊的业务，或者效果，这个时候你就只能自己去实现FB暂时没有提供的原生控件了，这就要求你同时要熟悉android原生开发，目前这个阶段，我觉得你是无法避免这种尴尬局面的。\n\n###响应屏幕尺寸的变化\n\nFB提供了Dimensions组件可以用来获取屏幕的当前尺寸：\n\n\tvar deviceHeight = Dimensions.get('window').height;\n\tvar deviceWidth = Dimensions.get('window').width;\n\t\n不过，由于设备可能旋转，所以如果你的app支持设备旋转的话，你就需要找到一种方法来实时获取当前设备尺寸，官方推荐的方法是每次render都要调用这个方法来刷新设备尺寸，**而目前我还没有解决，主要是不知道应该如何获取屏幕旋转事件～～**\n\n###style小知识\n\n当你打算在某个控件上套用设置好的某个样式，但需要单独为其设置一个额外特殊值时，你可以这样：\n\n\t<View style={[styles.demo, {backgroundColor: \"blue\"}]}></View>\n\n我也不懂，为何用数组类型的，但就是能这么写哟～\n\n###布局\n\n布局和web比起来其实不算复杂，但你务必要掌握Flex布局，强烈推荐看[这里](http://www.ruanyifeng.com/blog/2015/07/flex-grammar.html#show-last-Point)。\n\n###TextInput\n\n这里主要说的是键盘问题，当用户点击这个控件后，系统会弹出键盘，这个键盘会占据屏幕控件的，所以，你可以将整个表单View放在ScollView中！这样用户就可以在屏幕上进行滚动了，但注意，滚动的是整个表单View，而不是滚动的TextInput内容（当你设置为支持多行输入时），最后还有就是别忘了给ScollView添加keyboardDismissMode属性，如下：\n\t<ScrollView keyboardDismissMode=\"on-drag\">\n\n该属性会在滚动触发后自动关闭键盘～～\n\n***至于怎么滚动TextInput内部数据，目前没找到方法。***\n\n默认android系统的TextInput会有一个丑陋的下边框，style是无法去掉它的，不过你可以使用underlineColorAndroid属性将其设置为与背景色一样，来达到隐藏效果，这个时候你在外部包一个View来定义样式即可～～\n\n\n\n\n","slug":"React-Native-Android小结","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"ciift0f210000p8ws023qajnr","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近尝试使用react-native android为我们的一个创业项目写了一个demo，项目放在<a href=\"https://github.com/kazaff/ZhuiYuanDemo\" target=\"_blank\" rel=\"external\">github</a>了，有兴趣的朋友可以看看，下面给出一些效果：<br><a id=\"more\"></a></p>\n<embed src=\"http://player.youku.com/player.php/sid/XMTQxOTg2Nzk2MA==/v.swf\" allowfullscreen=\"true\" quality=\"high\" width=\"480\" height=\"400\" align=\"middle\" allowscriptaccess=\"always\" type=\"application/x-shockwave-flash\">\n\n\n<p>###关于height</p>\n<p>很多时候，这都是一个不折不扣的大坑，比方说当你Image加载一个网络图片时，如果你不给该Image设置width和height，那你将什么都看不到。这还不算，当你使用ListView时如果该组件同时存在一个兄弟元素，那么此时ListView必须设置height，否则你会发现它不再响应用户的滚动操作。。。</p>\n<p>###关于Fetch</p>\n<p>当你试图提交附件表单数据的时候，请一定要使用FormData对象将数据包裹，这应该算不上什么太古怪的事儿～</p>\n<p>如果你只是普通的json提交，就按照官方例子来做：</p>\n<pre><code>fetch(API_LOGIN_URL, {\n    method: &apos;POST&apos;,\n    headers: {\n      &apos;Accept&apos;: &apos;application/json&apos;,\n      &apos;Content-Type&apos;: &apos;application/json&apos;,\n    },\n    body: JSON.stringify({\n      account: this.state.account,\n      password: this.state.password,\n    })\n  })\n.....\n</code></pre><p>不然fetch会报错说你使用了不支持的body属性值类型～</p>\n<p>如果你和我一样需要实现类似用户头像修改的功能，你可能需要下面两个类库：</p>\n<p><a href=\"https://github.com/marcshilling/react-native-image-picker\" target=\"_blank\" rel=\"external\">react-native-image-picker</a>：用于头像图片获取</p>\n<p><a href=\"https://github.com/PhilippKrone/react-native-fileupload\" target=\"_blank\" rel=\"external\">react-native-fileupload</a>：用于图片文件表单上传，这是由于你使用image-picker获取到的图片只是本地url，你需要这个uploader来组装成原始的file上传表单～～</p>\n<p>顺便说一下，第三方依赖更新较快，代码也可能有bug，各种bug，所以你最好主动的去github上和项目的维护人员沟通，一起想办法解决问题～～</p>\n<p>###关于async/await</p>\n<p>至少在我目前的环境（默认安装react-native0.16.0自带的babel）是没有默认开启该特性的，不过貌似是可以手动开启的，有兴趣可以看<a href=\"https://medium.com/the-exponent-log/react-native-meets-async-functions-3e6f81111173#.ekvqrsala\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>###关于第三方类库</p>\n<p>个人感觉，目前很多关注度高的第三方库还是值得信赖的，不过面向android平台的库功能还不足够强大，这可能由于fb刚开源不久的缘故，但是关注度高的库的作者响应也一般都很快，这一点很值得赞许～</p>\n<p>但是，老实讲，如果你要开发的app包含大量特殊的业务，或者效果，这个时候你就只能自己去实现FB暂时没有提供的原生控件了，这就要求你同时要熟悉android原生开发，目前这个阶段，我觉得你是无法避免这种尴尬局面的。</p>\n<p>###响应屏幕尺寸的变化</p>\n<p>FB提供了Dimensions组件可以用来获取屏幕的当前尺寸：</p>\n<pre><code>var deviceHeight = Dimensions.get(&apos;window&apos;).height;\nvar deviceWidth = Dimensions.get(&apos;window&apos;).width;\n</code></pre><p>不过，由于设备可能旋转，所以如果你的app支持设备旋转的话，你就需要找到一种方法来实时获取当前设备尺寸，官方推荐的方法是每次render都要调用这个方法来刷新设备尺寸，<strong>而目前我还没有解决，主要是不知道应该如何获取屏幕旋转事件～～</strong></p>\n<p>###style小知识</p>\n<p>当你打算在某个控件上套用设置好的某个样式，但需要单独为其设置一个额外特殊值时，你可以这样：</p>\n<pre><code>&lt;View style={[styles.demo, {backgroundColor: &quot;blue&quot;}]}&gt;&lt;/View&gt;\n</code></pre><p>我也不懂，为何用数组类型的，但就是能这么写哟～</p>\n<p>###布局</p>\n<p>布局和web比起来其实不算复杂，但你务必要掌握Flex布局，强烈推荐看<a href=\"http://www.ruanyifeng.com/blog/2015/07/flex-grammar.html#show-last-Point\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>###TextInput</p>\n<p>这里主要说的是键盘问题，当用户点击这个控件后，系统会弹出键盘，这个键盘会占据屏幕控件的，所以，你可以将整个表单View放在ScollView中！这样用户就可以在屏幕上进行滚动了，但注意，滚动的是整个表单View，而不是滚动的TextInput内容（当你设置为支持多行输入时），最后还有就是别忘了给ScollView添加keyboardDismissMode属性，如下：<br>    <scrollview keyboarddismissmode=\"on-drag\"></scrollview></p>\n<p>该属性会在滚动触发后自动关闭键盘～～</p>\n<p><strong><em>至于怎么滚动TextInput内部数据，目前没找到方法。</em></strong></p>\n<p>默认android系统的TextInput会有一个丑陋的下边框，style是无法去掉它的，不过你可以使用underlineColorAndroid属性将其设置为与背景色一样，来达到隐藏效果，这个时候你在外部包一个View来定义样式即可～～</p>\n","excerpt":"<p>最近尝试使用react-native android为我们的一个创业项目写了一个demo，项目放在<a href=\"https://github.com/kazaff/ZhuiYuanDemo\">github</a>了，有兴趣的朋友可以看看，下面给出一些效果：<br>","more":"</p>\n<embed src=\"http://player.youku.com/player.php/sid/XMTQxOTg2Nzk2MA==/v.swf\" allowFullScreen=\"true\" quality=\"high\" width=\"480\" height=\"400\" align=\"middle\" allowScriptAccess=\"always\" type=\"application/x-shockwave-flash\"></embed>\n\n\n<p>###关于height</p>\n<p>很多时候，这都是一个不折不扣的大坑，比方说当你Image加载一个网络图片时，如果你不给该Image设置width和height，那你将什么都看不到。这还不算，当你使用ListView时如果该组件同时存在一个兄弟元素，那么此时ListView必须设置height，否则你会发现它不再响应用户的滚动操作。。。</p>\n<p>###关于Fetch</p>\n<p>当你试图提交附件表单数据的时候，请一定要使用FormData对象将数据包裹，这应该算不上什么太古怪的事儿～</p>\n<p>如果你只是普通的json提交，就按照官方例子来做：</p>\n<pre><code>fetch(API_LOGIN_URL, {\n    method: &apos;POST&apos;,\n    headers: {\n      &apos;Accept&apos;: &apos;application/json&apos;,\n      &apos;Content-Type&apos;: &apos;application/json&apos;,\n    },\n    body: JSON.stringify({\n      account: this.state.account,\n      password: this.state.password,\n    })\n  })\n.....\n</code></pre><p>不然fetch会报错说你使用了不支持的body属性值类型～</p>\n<p>如果你和我一样需要实现类似用户头像修改的功能，你可能需要下面两个类库：</p>\n<p><a href=\"https://github.com/marcshilling/react-native-image-picker\">react-native-image-picker</a>：用于头像图片获取</p>\n<p><a href=\"https://github.com/PhilippKrone/react-native-fileupload\">react-native-fileupload</a>：用于图片文件表单上传，这是由于你使用image-picker获取到的图片只是本地url，你需要这个uploader来组装成原始的file上传表单～～</p>\n<p>顺便说一下，第三方依赖更新较快，代码也可能有bug，各种bug，所以你最好主动的去github上和项目的维护人员沟通，一起想办法解决问题～～</p>\n<p>###关于async/await</p>\n<p>至少在我目前的环境（默认安装react-native0.16.0自带的babel）是没有默认开启该特性的，不过貌似是可以手动开启的，有兴趣可以看<a href=\"https://medium.com/the-exponent-log/react-native-meets-async-functions-3e6f81111173#.ekvqrsala\">这里</a>。</p>\n<p>###关于第三方类库</p>\n<p>个人感觉，目前很多关注度高的第三方库还是值得信赖的，不过面向android平台的库功能还不足够强大，这可能由于fb刚开源不久的缘故，但是关注度高的库的作者响应也一般都很快，这一点很值得赞许～</p>\n<p>但是，老实讲，如果你要开发的app包含大量特殊的业务，或者效果，这个时候你就只能自己去实现FB暂时没有提供的原生控件了，这就要求你同时要熟悉android原生开发，目前这个阶段，我觉得你是无法避免这种尴尬局面的。</p>\n<p>###响应屏幕尺寸的变化</p>\n<p>FB提供了Dimensions组件可以用来获取屏幕的当前尺寸：</p>\n<pre><code>var deviceHeight = Dimensions.get(&apos;window&apos;).height;\nvar deviceWidth = Dimensions.get(&apos;window&apos;).width;\n</code></pre><p>不过，由于设备可能旋转，所以如果你的app支持设备旋转的话，你就需要找到一种方法来实时获取当前设备尺寸，官方推荐的方法是每次render都要调用这个方法来刷新设备尺寸，<strong>而目前我还没有解决，主要是不知道应该如何获取屏幕旋转事件～～</strong></p>\n<p>###style小知识</p>\n<p>当你打算在某个控件上套用设置好的某个样式，但需要单独为其设置一个额外特殊值时，你可以这样：</p>\n<pre><code>&lt;View style={[styles.demo, {backgroundColor: &quot;blue&quot;}]}&gt;&lt;/View&gt;\n</code></pre><p>我也不懂，为何用数组类型的，但就是能这么写哟～</p>\n<p>###布局</p>\n<p>布局和web比起来其实不算复杂，但你务必要掌握Flex布局，强烈推荐看<a href=\"http://www.ruanyifeng.com/blog/2015/07/flex-grammar.html#show-last-Point\">这里</a>。</p>\n<p>###TextInput</p>\n<p>这里主要说的是键盘问题，当用户点击这个控件后，系统会弹出键盘，这个键盘会占据屏幕控件的，所以，你可以将整个表单View放在ScollView中！这样用户就可以在屏幕上进行滚动了，但注意，滚动的是整个表单View，而不是滚动的TextInput内容（当你设置为支持多行输入时），最后还有就是别忘了给ScollView添加keyboardDismissMode属性，如下：<br>    <ScrollView keyboardDismissMode=\"on-drag\"></p>\n<p>该属性会在滚动触发后自动关闭键盘～～</p>\n<p><strong><em>至于怎么滚动TextInput内部数据，目前没找到方法。</em></strong></p>\n<p>默认android系统的TextInput会有一个丑陋的下边框，style是无法去掉它的，不过你可以使用underlineColorAndroid属性将其设置为与背景色一样，来达到隐藏效果，这个时候你在外部包一个View来定义样式即可～～</p>"},{"title":"关于React-Native的预备知识","date":"2015-12-05T01:37:12.000Z","_content":"\n最近在修React-Native（简称RN），发现官方文档很多都看不太透彻，仔细想来，应该是基础知识不扎实导致的吧～所以花了一些时间来学习一些相关的内容，之前其实多少也有为RN做过准备，不过都是在JS方向的。不过，想使用RN开发完整的app还需要开发者了解原生开发的相关知识，但到底需要掌握到什么程度呢？这就要跟项目而定了！\n<!--more-->\n作为初学者的我，深刻的体会到，一些android基本概念是必不可少的，像Activity，UI布局，android事件机制等，虽说不需要你多熟练，但也绝对不能眼生啊，下面推荐一个系列教程，可以帮你无痛升级：\n\n1. [http://www.imooc.com/learn/96](http://www.imooc.com/learn/96)\n2. [http://www.imooc.com/learn/107](http://www.imooc.com/learn/107)\n3. [http://www.imooc.com/learn/142](http://www.imooc.com/learn/142)\n4. [http://www.imooc.com/learn/179](http://www.imooc.com/learn/179)\n\n基本上应该看完就能入门了吧，其实android开发感觉确实很容易入门的，只要别怕SDK量大，基本上都能比较顺利的升级为android开发小能手！\n\n当然，IOS也要如此，不过这条路线我暂时没有投入时间啦～远离是相通的～\n\n感觉RN的难点，多在于如何和native app融合和通信上，单纯的使用RN体验和React几乎一样，所以并不会成为你走向人生巅峰路上的绊脚石。而目前来说，不仅仅是android版，即便是早就开放的IOS版的RN，也并没有支持太多的原生模块和服务，所以想要使用RN搞定一个拿得出手的app，确实需要多修几条技能线，这也是很多人目前不推荐投入RN开发的一个主要观点。\n\n不过，RN的开发模式是主流的，尤其是在试图解决移动端跨平台开发的工程领域，而且就我个人的观察，RN社区的热度在全球范围内都一直是屈指可数，每天都会产生很多的RN控件，不久的将来，可能对于我们一般玩家来说，你基本上可以通过RN就完成一个完整的app了！\n\n希望那一天早日到来！ ","source":"_posts/关于React-Native的预备知识.md","raw":"title: 关于React-Native的预备知识\ndate: 2015-12-05 09:37:12\ntags: \n- react-native\n- android\ncategories: 移动端\n---\n\n最近在修React-Native（简称RN），发现官方文档很多都看不太透彻，仔细想来，应该是基础知识不扎实导致的吧～所以花了一些时间来学习一些相关的内容，之前其实多少也有为RN做过准备，不过都是在JS方向的。不过，想使用RN开发完整的app还需要开发者了解原生开发的相关知识，但到底需要掌握到什么程度呢？这就要跟项目而定了！\n<!--more-->\n作为初学者的我，深刻的体会到，一些android基本概念是必不可少的，像Activity，UI布局，android事件机制等，虽说不需要你多熟练，但也绝对不能眼生啊，下面推荐一个系列教程，可以帮你无痛升级：\n\n1. [http://www.imooc.com/learn/96](http://www.imooc.com/learn/96)\n2. [http://www.imooc.com/learn/107](http://www.imooc.com/learn/107)\n3. [http://www.imooc.com/learn/142](http://www.imooc.com/learn/142)\n4. [http://www.imooc.com/learn/179](http://www.imooc.com/learn/179)\n\n基本上应该看完就能入门了吧，其实android开发感觉确实很容易入门的，只要别怕SDK量大，基本上都能比较顺利的升级为android开发小能手！\n\n当然，IOS也要如此，不过这条路线我暂时没有投入时间啦～远离是相通的～\n\n感觉RN的难点，多在于如何和native app融合和通信上，单纯的使用RN体验和React几乎一样，所以并不会成为你走向人生巅峰路上的绊脚石。而目前来说，不仅仅是android版，即便是早就开放的IOS版的RN，也并没有支持太多的原生模块和服务，所以想要使用RN搞定一个拿得出手的app，确实需要多修几条技能线，这也是很多人目前不推荐投入RN开发的一个主要观点。\n\n不过，RN的开发模式是主流的，尤其是在试图解决移动端跨平台开发的工程领域，而且就我个人的观察，RN社区的热度在全球范围内都一直是屈指可数，每天都会产生很多的RN控件，不久的将来，可能对于我们一般玩家来说，你基本上可以通过RN就完成一个完整的app了！\n\n希望那一天早日到来！ ","slug":"关于React-Native的预备知识","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"ciift0f500004p8ws2qncgs7u","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近在修React-Native（简称RN），发现官方文档很多都看不太透彻，仔细想来，应该是基础知识不扎实导致的吧～所以花了一些时间来学习一些相关的内容，之前其实多少也有为RN做过准备，不过都是在JS方向的。不过，想使用RN开发完整的app还需要开发者了解原生开发的相关知识，但到底需要掌握到什么程度呢？这就要跟项目而定了！<br><a id=\"more\"></a><br>作为初学者的我，深刻的体会到，一些android基本概念是必不可少的，像Activity，UI布局，android事件机制等，虽说不需要你多熟练，但也绝对不能眼生啊，下面推荐一个系列教程，可以帮你无痛升级：</p>\n<ol>\n<li><a href=\"http://www.imooc.com/learn/96\" target=\"_blank\" rel=\"external\">http://www.imooc.com/learn/96</a></li>\n<li><a href=\"http://www.imooc.com/learn/107\" target=\"_blank\" rel=\"external\">http://www.imooc.com/learn/107</a></li>\n<li><a href=\"http://www.imooc.com/learn/142\" target=\"_blank\" rel=\"external\">http://www.imooc.com/learn/142</a></li>\n<li><a href=\"http://www.imooc.com/learn/179\" target=\"_blank\" rel=\"external\">http://www.imooc.com/learn/179</a></li>\n</ol>\n<p>基本上应该看完就能入门了吧，其实android开发感觉确实很容易入门的，只要别怕SDK量大，基本上都能比较顺利的升级为android开发小能手！</p>\n<p>当然，IOS也要如此，不过这条路线我暂时没有投入时间啦～远离是相通的～</p>\n<p>感觉RN的难点，多在于如何和native app融合和通信上，单纯的使用RN体验和React几乎一样，所以并不会成为你走向人生巅峰路上的绊脚石。而目前来说，不仅仅是android版，即便是早就开放的IOS版的RN，也并没有支持太多的原生模块和服务，所以想要使用RN搞定一个拿得出手的app，确实需要多修几条技能线，这也是很多人目前不推荐投入RN开发的一个主要观点。</p>\n<p>不过，RN的开发模式是主流的，尤其是在试图解决移动端跨平台开发的工程领域，而且就我个人的观察，RN社区的热度在全球范围内都一直是屈指可数，每天都会产生很多的RN控件，不久的将来，可能对于我们一般玩家来说，你基本上可以通过RN就完成一个完整的app了！</p>\n<p>希望那一天早日到来！ </p>\n","excerpt":"<p>最近在修React-Native（简称RN），发现官方文档很多都看不太透彻，仔细想来，应该是基础知识不扎实导致的吧～所以花了一些时间来学习一些相关的内容，之前其实多少也有为RN做过准备，不过都是在JS方向的。不过，想使用RN开发完整的app还需要开发者了解原生开发的相关知识，但到底需要掌握到什么程度呢？这就要跟项目而定了！<br>","more":"<br>作为初学者的我，深刻的体会到，一些android基本概念是必不可少的，像Activity，UI布局，android事件机制等，虽说不需要你多熟练，但也绝对不能眼生啊，下面推荐一个系列教程，可以帮你无痛升级：</p>\n<ol>\n<li><a href=\"http://www.imooc.com/learn/96\">http://www.imooc.com/learn/96</a></li>\n<li><a href=\"http://www.imooc.com/learn/107\">http://www.imooc.com/learn/107</a></li>\n<li><a href=\"http://www.imooc.com/learn/142\">http://www.imooc.com/learn/142</a></li>\n<li><a href=\"http://www.imooc.com/learn/179\">http://www.imooc.com/learn/179</a></li>\n</ol>\n<p>基本上应该看完就能入门了吧，其实android开发感觉确实很容易入门的，只要别怕SDK量大，基本上都能比较顺利的升级为android开发小能手！</p>\n<p>当然，IOS也要如此，不过这条路线我暂时没有投入时间啦～远离是相通的～</p>\n<p>感觉RN的难点，多在于如何和native app融合和通信上，单纯的使用RN体验和React几乎一样，所以并不会成为你走向人生巅峰路上的绊脚石。而目前来说，不仅仅是android版，即便是早就开放的IOS版的RN，也并没有支持太多的原生模块和服务，所以想要使用RN搞定一个拿得出手的app，确实需要多修几条技能线，这也是很多人目前不推荐投入RN开发的一个主要观点。</p>\n<p>不过，RN的开发模式是主流的，尤其是在试图解决移动端跨平台开发的工程领域，而且就我个人的观察，RN社区的热度在全球范围内都一直是屈指可数，每天都会产生很多的RN控件，不久的将来，可能对于我们一般玩家来说，你基本上可以通过RN就完成一个完整的app了！</p>\n<p>希望那一天早日到来！ </p>"},{"title":"React-Native-Android关于我是如何打包APK的","date":"2015-12-21T13:37:12.000Z","_content":"\napp写好了，最后一步多半应该是拿出来装逼喽～哇哈哈哈哈\n\n但你总不能指望每次都USB连上你的开发机，然后run-android一下吧，虽然我承认看着命令行中刷刷刷的执行命令有种黑客帝国的范儿，但让所有人都连接的开发机，感觉也是怪怪的，更别提你还指望所有设备都在一个局域网下才能更新js文件。。。。\n\n好吧，你还是应该考虑把你的项目打包成apk，然后传给任何你想装逼给他看的人！哇哈哈哈哈～\n\n时至今日，2015-12-21 晚上九点四十分，官方版本应该是0.16.0，我按照[官方教程](http://react-native.cn/docs/signed-apk-android.html#content)进行打包，还是没能一次性就成功！但这并不能阻挡我试图装逼的心！\n\n好吧，解决问题之旅开始了！\n\n官方文档中，在打包之初是让你先生成了一个签名文件，原因是，如果你打包未签名的APK，在非root的设备上是不允许安装的，所以，你懂的！官方已经给出了非常具体的签名步骤，我这里就不重复了！\n\n好的，签名也弄好，执行`gradlew assembleRelease`命令坐等完成吧～\n\n但是，怎么可能让你如此轻易就达到目的？毫不意外的，我碰到了报错：\n\n```\n* What went wrong:\nExecution failed for task ':app:packageRelease'.\n> Unable to compute hash of /Users/kazaff/Documents/React-Native/ZhuiYuan/android/app/build/intermediates/classes-proguard/release/classes.jar\n```\n\n不过GG了一下，看来碰见这个错误的人不少，按照[stackoverflow](http://stackoverflow.com/questions/31643339/errorexecution-failed-for-task-apppackagerelease-unable-to-compute-hash)给出的终结方案：***在proguard-rules.pro文件末尾增加：**\n\n```\n-dontwarn java.nio.file.Files\n-dontwarn java.nio.file.Path\n-dontwarn java.nio.file.OpenOption\n-dontwarn org.codehaus.mojo.animal_sniffer.IgnoreJRERequirement\n\n-keep class com.google.android.gms.** { *; }\n-dontwarn com.google.android.gms.**\n-dontwarn butterknife.**\n```\n\n还是被我机智的搞定了！\n\n注意，再次执行`gradlew assembleRelease`之前，请先执行`gradlew clean`，清除之前打包的一些临时文件，不然你可能还是会悲剧～\n\n好了，其实说了这么多，我只是想贱贱的贴一个下载连接：\n\n![](http://pic.yupoo.com/kazaff/Fc35Cqee/swrie.jpg)\n\n[http://pan.baidu.com/s/1pKhY6wj](http://pan.baidu.com/s/1pKhY6wj)\n\n上图是[ZhuiYuanDemo](https://github.com/kazaff/ZhuiYuanDemo)APK的文件二维码，供大家把玩～\n\n","source":"_posts/react-native-android关于我是如何打包APK的.md","raw":"title: React-Native-Android关于我是如何打包APK的\ndate: 2015-12-21 21:37:12\ntags: \n- react-native\n- android\n- 打包\n- APK\ncategories: 移动端\n---\n\napp写好了，最后一步多半应该是拿出来装逼喽～哇哈哈哈哈\n\n但你总不能指望每次都USB连上你的开发机，然后run-android一下吧，虽然我承认看着命令行中刷刷刷的执行命令有种黑客帝国的范儿，但让所有人都连接的开发机，感觉也是怪怪的，更别提你还指望所有设备都在一个局域网下才能更新js文件。。。。\n\n好吧，你还是应该考虑把你的项目打包成apk，然后传给任何你想装逼给他看的人！哇哈哈哈哈～\n\n时至今日，2015-12-21 晚上九点四十分，官方版本应该是0.16.0，我按照[官方教程](http://react-native.cn/docs/signed-apk-android.html#content)进行打包，还是没能一次性就成功！但这并不能阻挡我试图装逼的心！\n\n好吧，解决问题之旅开始了！\n\n官方文档中，在打包之初是让你先生成了一个签名文件，原因是，如果你打包未签名的APK，在非root的设备上是不允许安装的，所以，你懂的！官方已经给出了非常具体的签名步骤，我这里就不重复了！\n\n好的，签名也弄好，执行`gradlew assembleRelease`命令坐等完成吧～\n\n但是，怎么可能让你如此轻易就达到目的？毫不意外的，我碰到了报错：\n\n```\n* What went wrong:\nExecution failed for task ':app:packageRelease'.\n> Unable to compute hash of /Users/kazaff/Documents/React-Native/ZhuiYuan/android/app/build/intermediates/classes-proguard/release/classes.jar\n```\n\n不过GG了一下，看来碰见这个错误的人不少，按照[stackoverflow](http://stackoverflow.com/questions/31643339/errorexecution-failed-for-task-apppackagerelease-unable-to-compute-hash)给出的终结方案：***在proguard-rules.pro文件末尾增加：**\n\n```\n-dontwarn java.nio.file.Files\n-dontwarn java.nio.file.Path\n-dontwarn java.nio.file.OpenOption\n-dontwarn org.codehaus.mojo.animal_sniffer.IgnoreJRERequirement\n\n-keep class com.google.android.gms.** { *; }\n-dontwarn com.google.android.gms.**\n-dontwarn butterknife.**\n```\n\n还是被我机智的搞定了！\n\n注意，再次执行`gradlew assembleRelease`之前，请先执行`gradlew clean`，清除之前打包的一些临时文件，不然你可能还是会悲剧～\n\n好了，其实说了这么多，我只是想贱贱的贴一个下载连接：\n\n![](http://pic.yupoo.com/kazaff/Fc35Cqee/swrie.jpg)\n\n[http://pan.baidu.com/s/1pKhY6wj](http://pan.baidu.com/s/1pKhY6wj)\n\n上图是[ZhuiYuanDemo](https://github.com/kazaff/ZhuiYuanDemo)APK的文件二维码，供大家把玩～\n\n","slug":"react-native-android关于我是如何打包APK的","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"ciig1awvm0000h5wsmihag50z","comments":1,"layout":"post","photos":[],"link":"","content":"<p>app写好了，最后一步多半应该是拿出来装逼喽～哇哈哈哈哈</p>\n<p>但你总不能指望每次都USB连上你的开发机，然后run-android一下吧，虽然我承认看着命令行中刷刷刷的执行命令有种黑客帝国的范儿，但让所有人都连接的开发机，感觉也是怪怪的，更别提你还指望所有设备都在一个局域网下才能更新js文件。。。。</p>\n<p>好吧，你还是应该考虑把你的项目打包成apk，然后传给任何你想装逼给他看的人！哇哈哈哈哈～</p>\n<p>时至今日，2015-12-21 晚上九点四十分，官方版本应该是0.16.0，我按照<a href=\"http://react-native.cn/docs/signed-apk-android.html#content\" target=\"_blank\" rel=\"external\">官方教程</a>进行打包，还是没能一次性就成功！但这并不能阻挡我试图装逼的心！</p>\n<p>好吧，解决问题之旅开始了！</p>\n<p>官方文档中，在打包之初是让你先生成了一个签名文件，原因是，如果你打包未签名的APK，在非root的设备上是不允许安装的，所以，你懂的！官方已经给出了非常具体的签名步骤，我这里就不重复了！</p>\n<p>好的，签名也弄好，执行<code>gradlew assembleRelease</code>命令坐等完成吧～</p>\n<p>但是，怎么可能让你如此轻易就达到目的？毫不意外的，我碰到了报错：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">* What went wrong:</span><br><span class=\"line\">Execution failed for task &apos;:app:packageRelease&apos;.</span><br><span class=\"line\">&gt; Unable to compute hash of /Users/kazaff/Documents/React-Native/ZhuiYuan/android/app/build/intermediates/classes-proguard/release/classes.jar</span><br></pre></td></tr></table></figure>\n<p>不过GG了一下，看来碰见这个错误的人不少，按照<a href=\"http://stackoverflow.com/questions/31643339/errorexecution-failed-for-task-apppackagerelease-unable-to-compute-hash\" target=\"_blank\" rel=\"external\">stackoverflow</a>给出的终结方案：<strong>*在proguard-rules.pro文件末尾增加：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-dontwarn java.nio.file.Files</span><br><span class=\"line\">-dontwarn java.nio.file.Path</span><br><span class=\"line\">-dontwarn java.nio.file.OpenOption</span><br><span class=\"line\">-dontwarn org.codehaus.mojo.animal_sniffer.IgnoreJRERequirement</span><br><span class=\"line\"></span><br><span class=\"line\">-keep class com.google.android.gms.** &#123; *; &#125;</span><br><span class=\"line\">-dontwarn com.google.android.gms.**</span><br><span class=\"line\">-dontwarn butterknife.**</span><br></pre></td></tr></table></figure>\n<p>还是被我机智的搞定了！</p>\n<p>注意，再次执行<code>gradlew assembleRelease</code>之前，请先执行<code>gradlew clean</code>，清除之前打包的一些临时文件，不然你可能还是会悲剧～</p>\n<p>好了，其实说了这么多，我只是想贱贱的贴一个下载连接：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Fc35Cqee/swrie.jpg\" alt=\"\"></p>\n<p><a href=\"http://pan.baidu.com/s/1pKhY6wj\" target=\"_blank\" rel=\"external\">http://pan.baidu.com/s/1pKhY6wj</a></p>\n<p>上图是<a href=\"https://github.com/kazaff/ZhuiYuanDemo\" target=\"_blank\" rel=\"external\">ZhuiYuanDemo</a>APK的文件二维码，供大家把玩～</p>\n","excerpt":"","more":"<p>app写好了，最后一步多半应该是拿出来装逼喽～哇哈哈哈哈</p>\n<p>但你总不能指望每次都USB连上你的开发机，然后run-android一下吧，虽然我承认看着命令行中刷刷刷的执行命令有种黑客帝国的范儿，但让所有人都连接的开发机，感觉也是怪怪的，更别提你还指望所有设备都在一个局域网下才能更新js文件。。。。</p>\n<p>好吧，你还是应该考虑把你的项目打包成apk，然后传给任何你想装逼给他看的人！哇哈哈哈哈～</p>\n<p>时至今日，2015-12-21 晚上九点四十分，官方版本应该是0.16.0，我按照<a href=\"http://react-native.cn/docs/signed-apk-android.html#content\">官方教程</a>进行打包，还是没能一次性就成功！但这并不能阻挡我试图装逼的心！</p>\n<p>好吧，解决问题之旅开始了！</p>\n<p>官方文档中，在打包之初是让你先生成了一个签名文件，原因是，如果你打包未签名的APK，在非root的设备上是不允许安装的，所以，你懂的！官方已经给出了非常具体的签名步骤，我这里就不重复了！</p>\n<p>好的，签名也弄好，执行<code>gradlew assembleRelease</code>命令坐等完成吧～</p>\n<p>但是，怎么可能让你如此轻易就达到目的？毫不意外的，我碰到了报错：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">* What went wrong:</span><br><span class=\"line\">Execution failed for task &apos;:app:packageRelease&apos;.</span><br><span class=\"line\">&gt; Unable to compute hash of /Users/kazaff/Documents/React-Native/ZhuiYuan/android/app/build/intermediates/classes-proguard/release/classes.jar</span><br></pre></td></tr></table></figure>\n<p>不过GG了一下，看来碰见这个错误的人不少，按照<a href=\"http://stackoverflow.com/questions/31643339/errorexecution-failed-for-task-apppackagerelease-unable-to-compute-hash\">stackoverflow</a>给出的终结方案：<strong>*在proguard-rules.pro文件末尾增加：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-dontwarn java.nio.file.Files</span><br><span class=\"line\">-dontwarn java.nio.file.Path</span><br><span class=\"line\">-dontwarn java.nio.file.OpenOption</span><br><span class=\"line\">-dontwarn org.codehaus.mojo.animal_sniffer.IgnoreJRERequirement</span><br><span class=\"line\"></span><br><span class=\"line\">-keep class com.google.android.gms.** &#123; *; &#125;</span><br><span class=\"line\">-dontwarn com.google.android.gms.**</span><br><span class=\"line\">-dontwarn butterknife.**</span><br></pre></td></tr></table></figure>\n<p>还是被我机智的搞定了！</p>\n<p>注意，再次执行<code>gradlew assembleRelease</code>之前，请先执行<code>gradlew clean</code>，清除之前打包的一些临时文件，不然你可能还是会悲剧～</p>\n<p>好了，其实说了这么多，我只是想贱贱的贴一个下载连接：</p>\n<p><img src=\"http://pic.yupoo.com/kazaff/Fc35Cqee/swrie.jpg\" alt=\"\"></p>\n<p><a href=\"http://pan.baidu.com/s/1pKhY6wj\">http://pan.baidu.com/s/1pKhY6wj</a></p>\n<p>上图是<a href=\"https://github.com/kazaff/ZhuiYuanDemo\">ZhuiYuanDemo</a>APK的文件二维码，供大家把玩～</p>\n"},{"title":"GraphQL什么鬼","date":"2016-01-01T01:37:12.000Z","_content":"\n昨天看了一个技术分享，讲[react生态圈](http://www.infoq.com/cn/presentations/explore-react-ecosystem)的，很不错，尽管纯技术干货没太多，但贵在拓宽知识面，讲师也很有激情，推荐看之～\n<!--more-->\n在react生态圈里，越来越多的富有创意和激情的东西呈现在我们眼前，对于前端工程师来说真的是求之不得的时代啊～\n\nreact之前也玩过了，和它相关的一些类库（例如router，redux）我们也都陆续介绍过，甚至包含react-natvie也有所涉及，那么今天要解惑的，就是[GraphQL](https://facebook.github.io/graphql/)。\n\n官方文档冗长且晦涩，我们不妨延续以往的学习经验，先gg几篇不错的博文来共大家品尝，那么和GraphQL相关的姿势哪里找呢？请看[这里](https://github.com/chentsulin/awesome-graphql)，这里包含了各种语言的实现版本，当然也包含了入门文章的推荐，有兴趣的童鞋不妨长期关注该项目～\n\n由于我也是第一天开始了解GraphQL，并不比大家知道的多多少，所以打算翻译两篇感觉很适合入门的实战文章来让大家过过瘾，这两篇文章虽然不是出自于同一人所写，但内容上关联性却很大，个人感觉合并在一起刚刚好，所以在此斗胆合并在一起翻译，原文地址：\n\n[Your First GraphQL Server](https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2#.pkab58j87)\n\n[Writing a Basic API with GraphQL](http://davidandsuzi.com/writing-a-basic-api-with-graphql/)\n\n如果你按照我提供的轨迹，看过前面提到的那个关于“react生态圈”的技术分享，那你应该就已经知道GraphQL是为了解决什么问题而产生的，如果你没看，也没事儿，再开始翻译之前我还是会简单的阐述一下GraphQL的背景。\n\n###GraphQL对比SQL\n\n首先，官方说了，GraphQL是一个查询语言，而且目前还未完成，意味着未来可能会有更多更大的变动。\n\n单这并不妨碍世界上那么多前端工程师的折腾之路！查询语言？那就是说和sql类似喽？你看名字里都有“QL”啊～\n\n确实如此，确实是用来声明要查询的数据的，但要解决的问题却完全不一样，伴随我们多年的sql主要解决的是如何在数据库基础上提供简单易用且功能强大的沟通语言，使得我们人类可以轻而易举的从海量数据中获取到我们想要知道的数据片段。\n\nGraphQL产生的背景却完全不同，在facebook内部，大量不同的app和系统共同使用着许许多多的服务api，随着业务的变化和发展，不同app对相同资源的不同使用方法最终导致需要维护的服务api数量爆炸式的增长，非常不利于维护（我们主要在restful场景上思考）。而另一方面，创建一个大而全的通用性接口又非常不利于移动端使用（流量损耗），而且后端数据的无意义聚合也对整个系统带来了很大的资源浪费。\n\n在这样的背景下，fb工程师坐不住了，于是乎GraphQL的概念就诞生了～最了解客户端需要什么数据的只有客户端自己，所以如果给客户端提供一种机制，让其表述自己所需的数据结构，这岂不是最合理的么？\n\n###GraphQL对比Rest\n\n目前，最热的前后端通信方案应该是Restful，基于http的轻量级api，前端通过ajax请求服务端提供的rest api完成数据获取。\n\n我们再往前一步，假设你的项目前端已经组件化了，一个业务肯定是需要多个组件结合来完成的，每个组件都各自管理自己的内部状态和所需数据，那么，目前的做法是，一旦前端路由匹配了对应的业务页面，那么自然会加载相关的组件实现，同时，你还需要调用rest api来获取组件所需数据。\n\n不同的页面，组件的组合肯定也略有不同，不同的组件组合后，所需的数据自然也不会完全一致。这里你可能会说，既然以组件为单位复用，那rest api针对组件颗粒度提供一对一的服务即可，话是没错，但实际操作起来就不work了，试想前端狗被产品狗每天要求加这加那，前端狗就会不得不去求后端狗协同开发，这样最后就剩下死逼了！而且前面也说了，这样做创造出来的大量的api会变得无法维护～\n\n那么，是时候考虑采用Rest以外的解决方案了！（尽管我认为，GraphQL并非是来取代Rest的，但为了我们的描述简单，这里就直接这么写了！）后端根据GraphQL机制提供一个具有强大功能的接口，用以满足前端数据的个性化需求，既保证了多样性，又控制了接口数量，完美～\n\n###GraphQL到底是什么\n\n> A GraphQL query is a string interpreted by a server that returns data in a specified format. \n\n这端描述如果不了解它的背景，确实很容易和sql混淆～但，现在，你应该知道GraphQL到底是个什么鬼了吧～\n\n好的，下面我们就来开始GraphQL in Action!\n\n\nYour First GraphQL Server\n---\n\n今天我们将要实现一个[GraphQL](http://facebook.github.io/graphql/)小服务，我不没有打算让你放弃一切转而拥抱GraphQL，但如果你对这玩意儿很好奇，并想知道它是如何实现的，那么就往下读～\n\n###Setup an HTTP Server\n\n我们需要一个服务来接受GraphQL查询，GraphQL文档虽然并没有规定其一定要基于HTTP协议，但既然目前[GraphQL参考实现](https://github.com/graphql/graphql-js)是基于JavaScript的，那么我们就基于[Express](http://expressjs.com/)来快速打造一个http服务器完成需求吧～\n\n\t$ mkdir graphql-intro && cd ./graphql-intro\n\t$ npm install express --save\n\t$ npm install babel --save\n\t$ touch ./server.js\n\t$ touch ./index.js\n\t\n我们创建了项目文件夹（graphql-intro），并且安装了Express和[Babel](https://babeljs.io/)作为依赖。Babel并不是GraphQL所必须的，但它可以让我们使用[ES2015特性](https://babeljs.io/docs/learn-es2015/)，从而是我们可以书写更精彩的js。（译：我瞎掰的～）\n\n最后，让我们写点代码：\n\n\t// index.js\n\t// by requiring `babel/register`, all of our successive `require`s will be Babel'd\n\trequire('babel/register');\n\trequire('./server.js');\n\n\t// server.js\n\timport express from 'express';\n\n\tlet app  = express();\n\tlet PORT = 3000;\n\n\tapp.post('/graphql', (req, res) => {\n\t  res.send('Hello!');\n\t});\n\t\n\tlet server = app.listen(PORT, function () {\n\t  let host = server.address().address;\n\t  let port = server.address().port;\n\t\n\t  console.log('GraphQL listening at http://%s:%s', host, port);\n\t});\n\t\n现在运行我们的服务：\n\n\t$ node index.js\n\tGraphQL listening at http://0.0.0.0:3000\n\t\n来测试一下我们的代码：\n\n\t$ curl -XPOST http://localhost:3000/graphql\n\tHello!\n\t\n我们选择使用`/graphql`作为入口，并使用HTTP POST方法请求，这些都不是影硬性要求--GraphQL并没有限制你如何与GraphQL服务端通信。\n\n###Create a GraphQL Schema\n\n现在咱们有了一个服务，是时候来加点GraphQL啦。具体改怎么做呢？\n\n让我们回想一下GraphQL请求的模样（译：我们目前不太关心GraphQL文档的细节，只需要跟着作者的步骤即可）：\n\n\tquery getHighScore { score }\n\t\n目前，我们的GraphQL客户端需要请求`getHighScore`字段中的`score`字段，字段是用来告诉GraphQL服务返回哪些数据的，字段也可以拥有参数，如下：\n\n\tquery getHighScores(limit: 10) { score }\n\t\n它还能做更多的事儿，但让我们先往下看。\n\n我们的GraphQL服务需要进行配置才能响应上面那样的请求--这种配置被成为schema。\n\n构建一个schema其实和构建restful路由规则是很相似的。我们的schema需要描述哪些字段是服务器需要响应的，同时也需要包含这些响应对象的类型。类型信息对GraphQL来说是非常重要的，客户端可以放心的假设服务端会返回所指定的字段类型（或者一个error）。\n\n如你所想，schema声明可以非常的复杂。但对于我们这个简单的GraphQL服务来讲，我们需要一个简单的字段：`Count`。\n\n回到我们的终端：\n\n\t$ npm install graphql --save\n\t$ npm install body-parser --save\n\t$ touch ./schema.js\n\t\n就是这么靠谱，对么？[graphql](https://www.npmjs.com/package/graphql)模块包含了GraphQL的技术实现，可以允许我们来组合我们的schema和处理graphql请求。而[body-parser](https://www.npmjs.com/package/body-parser)则是一个简单的Express中间件，用来让我们获取GraphQL请求体哒～\n\n是时候来声明我们的schema：\n\n\t//schema.js\n\timport {\n  \t\tGraphQLObjectType,\n  \t\tGraphQLSchema,\n  \t\tGraphQLInt\n\t} from 'graphql/lib/type';\n\n\tlet count = 0;\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n    \t\t\tcount: {\n        \t\t\ttype: GraphQLInt,\n        \t\t\tresolve: function() {\n          \t\t\t\treturn count;\n        \t\t\t}\n      \t\t\t}\n    \t\t}\n  \t\t})\n\t});\n\n\texport default schema;\n\t\n这里我们所做的就是创建了一个`GraphQLSchema`实例，它提供了一个配置。后面GRaphQL的其他部件会使用我们这个schema实例。通常情况下我们喜欢将schema的创建放在单独的文件中。\n\n简单的解释，我们创建的schema的含义是：\n\n> 我们的顶级查询对象需要返回一个`RootQueryType`对象，它包含一个类型为整型的`count`字段。\n\n你可以猜到还有很多类似的内置基础类型（strings，lists等），当然你也可以创建自定义的特殊类型。\n\n###Connect the Schema\n\n目前我们意淫的schema并没有毛用，除非我们针对它进行查询。让我们把这个schema挂载到我们的http服务上：\n\n\timport express from 'express';\n\timport schema from './schema';\n\t// new dependencies\n\timport { graphql } from 'graphql';\n\timport bodyParser from 'body-parser';\n\n\tlet app  = express();\n\tlet PORT = 3000;\n\n\t// parse POST body as text\n\tapp.use(bodyParser.text({ type: 'application/graphql' }));\n\n\tapp.post('/graphql', (req, res) => {\n  \t\t// execute GraphQL!\n  \t\tgraphql(schema, req.body)\n  \t\t.then((result) => {\n    \t\tres.send(JSON.stringify(result, null, 2));\n  \t\t});\n\t});\n\n\tlet server = app.listen(PORT, function () {\n  \t\tvar host = server.address().address;\n  \t\tvar port = server.address().port;\n\n  \t\tconsole.log('GraphQL listening at http://%s:%s', host, port);\n\t});\n\t\n现在任何POST请求`/graphql`都将会执行我们的GRaphQL schema。我们为每个请求强制设了一个“content type”（译：'application/graphql'），这并不是GraphQL规定的，但这么做是一个好的选择，特别是当我们在现有代码中加入GraphQL功能时。\n\n执行下面的命令：\n\n\t$ node ./index.js // restart your server\n\t// in another shell\n\t$ curl -XPOST -H \"Content-Type:application/graphql\"  -d 'query \tRootQueryType { count }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"count\": 0\n  \t\t}\n\t}\n\t\n完美！GraphQL允许我们省略掉`query RootQueryType`前缀，如下：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql'  -d \t'{ count }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"count\": 0\n  \t\t}\n\t}\n\t\n现在我们已经完成了一个GraphQL例子，我们来花点时间讨论一下introspection。（译：应该翻译成“自解释”吧？）\n\n###Introspect the server\n\n有趣的是：你可以写一个GraphQL查询来请求GraphQL服务获取它的fields。\n\n听起来很疯狂？看一下这个：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql'  -d '{__schema { queryType { name, fields { name, description} }}}' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"__schema\": {\n      \t\t\t\"queryType\": {\n        \t\t\t\"name\": \"RootQueryType\",\n        \t\t\t\"fields\": [\n          \t\t\t\t{\n            \t\t\t\t\"name\": \"count\",\n            \t\t\t\t\"description\": null\n          \t\t\t\t}\n        \t\t\t]\n      \t\t\t}\n    \t\t}\n  \t\t}\n\t}\n\t\n格式化一下我们上面发送的查询语句：\n\n\t{\n  \t\t__schema {\n    \t\tqueryType {\n      \t\t\tname, \n      \t\t\tfields {\n        \t\t\tname,\n        \t\t\tdescription\n      \t\t\t}\n    \t\t}\n  \t\t}\n\t}\n\n通常，每个GraphQL根字段自动包含一个`__Schema`[字段](http://facebook.github.io/graphql/#sec-Schema-Introspection)，其包含用来查询的描述自身meta信息的字段--`queryType`。\n\n更可爱的是，你可以定义一些很有意义的元信息，例如`description`，`isDeprecated`，和`deprecationReason`。facebook宣成他们的工具可以很好的利用这些元信息来提升开发者的体验～\n\n为了让我们的服务更容易使用，我们这里添加了`description`字段：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n      \t\t\tcount: {\n        \t\t\ttype: GraphQLInt,\n        \t\t\t// add the description\n        \t\t\tdescription: 'The count!',\n        \t\t\tresolve: function() {\n          \t\t\t\treturn count;\n        \t\t\t}\n      \t\t\t}\n    \t\t}\n  \t\t})\n\t});\n\t\n重启服务后看一下新的元数据展示：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql'  -d '{__schema { queryType { name, fields { name, description} }}}' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"__schema\": {\n      \t\t\t\"queryType\": {\n        \t\t\t\"name\": \"RootQueryType\",\n        \t\t\t\"fields\": [\n          \t\t\t\t{\n            \t\t\t\t\"name\": \"count\",\n            \t\t\t\t\"description\": \"The count!\"\n          \t\t\t\t}\n        \t\t\t]\n      \t\t\t}\n   \t\t\t }\n  \t\t}\n\t}\n\t\n\n我们几乎已经完成了我们的GraphQL旅程，接下来我将展示mutations。\n\n###Add a Mutation\n\n如果你只对只读数据接口感兴趣，你就不用读下去了。但大多数应用，我们都需要去更改我们的数据。GraphQL把这种操作称为mutations。\n\nMutations仅仅是一个字段，所以语法和query字段都差不多，Mutations字段必须返回一个类型值--目的是如果你更改了数据，你必须提供更改后的值。\n\n我们该如何为我们的schema增加mutations？和`query`非常相似，我们定义一个顶级键`mutation`：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: ...\n  \t\tmutation: // todo\n\t)}\n\t\n除此之外，还有啥不特别的？我们需要在`count`字段函数中更新我们的计数器或者做一些GraphQL根本不需要感知的其他变更操作。\n\nmutation和query有一个非常重要的不同点，mutation是有执行顺序的，但是query没有这方面的保证（事实上，GraphQL推荐并行处理那些不存在依赖的查询）。GraphQL说明书给了下面的mutation例子来描述执行顺序：\n\n\t{\n  \t\tfirst: changeTheNumber(newNumber: 1) {\n    \t\ttheNumber\n  \t\t},\n  \t\tsecond: changeTheNumber(newNumber: 3) {\n    \t\ttheNumber\n  \t\t},\n  \t\tthird: changeTheNumber(newNumber: 2) {\n    \t\ttheNumber\n  \t\t}\n\t}\n\n最终，请求处理完毕后，`theNumber`字段的值应该是`2`。\n\n让我们新增一个简单的mutation来更新我们的计数器并返回新值：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: ...\n  \t\tmutation: new GraphQLObjectType({\n    \t\tname: 'RootMutationType',\n    \t\tfields: {\n      \t\t\tupdateCount: {\n        \t\t\ttype: GraphQLInt,\n        \t\t\tdescription: 'Updates the count',\n        \t\t\tresolve: function() {\n          \t\t\t\tcount += 1;\n          \t\t\t\treturn count;\n        \t\t\t}\n      \t\t\t}\n    \t\t}\n  \t\t})\n\t});\n\t\n重启我们的服务，试一下：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql' -d 'mutation \tRootMutationType { updateCount }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"updateCount\": 1\n  \t\t}\n\t}\n\t\n看--数据已经更改了。你可以重新查询一下：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql' -d '{ count }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"count\": 1\n  \t\t}\n\t}\n\n你可以多执行几次。\n\n为了严格遵守GraphQ实现，我们应该提供一个更语意化的值名（例如`CountValue`），这样会让mutation和query返回值都更加有意义。\n\n###Wrapping Up\n\n本文章教你如何使用facebook提供的GraphQL javascript版实现来完成服务的。但我并没有涉及过多的强大话题--fields with arguments, resolving promises, fragments, directives等等。GraphQL说明书中介绍了很多特别屌的特性。其实还有很多不同的服务端GraphQL实现和schema API。你可以使用像java这样的强类型语言来实现GraphQL服务。\n\n本篇是基于我的GraphQL的48小时体验而来--如果有什么遗漏或错误，别忘了让我知道。你可以在这里看到源码（每次提交都对应流程中的每一步）：\n\n[https://github.com/clayallsopp/graphql-intro](https://github.com/clayallsopp/graphql-intro)\n\n十分感谢RisingStack的关于GraphQL的[文章和例子](http://blog.risingstack.com/graphql-overview-getting-started-with-graphql-and-nodejs/)。\n\n\n---\n\nWriting a Basic API with GraphQL\n---\n\n这篇文章假设你了解GraphQL，并试图将你的后端实现转换成GraphQL，内容覆盖了同步/异步，query/mutation。\n\n源码：[https://github.com/davidchang/graphql-pokedex-api](https://github.com/davidchang/graphql-pokedex-api)\n\n基本的Pokedex客户端实现来自于我上周的[Redux Post](http://davidandsuzi.com/writing-a-basic-api-with-graphql/davidandsuzi.com/writing-a-basic-app-in-redux/)，让我们使用GraphQL来实现一个Pokedex后端API。我们需要两个query方法（查询口袋妖怪列表和指定用户所拥有的口袋妖怪）和两个mutation方法（创建用户和用户捕获口袋妖怪）。\n\n口袋妖怪列表数据存储在内存中，而用户和其拥有的口袋妖怪数据则将存储再MongoDB。\n\n###Starting\n\n继续前面提到的[文章](https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2)（其实就是上一篇），我使用babel在node上创建了一个Express服务端，它包含了一个`/graphql`路由。我的server.js入口文件如下：\n\n\timport express from 'express';\n\timport schema from './schema';\n\timport { graphql } from 'graphql';\n\timport bodyParser from 'body-parser';\n\n\tlet app  = express();\n\n\t// parse POST body as text\n\tapp.use(bodyParser.text({ type: 'application/graphql' }));\n\n\tapp.post('/graphql', (req, res) => {\n  \t\t// execute GraphQL!\n  \t\tgraphql(schema, req.body)\n    \t\t.then(result => res.send(result));\n\t\t});\n\n\tlet server = app.listen(\n\t\t3000,\n  \t\t() => console.log(`GraphQL running on port ${server.address().port}`)\n\t);\n\t\n###Synchronous Query\n####{ pokemon { name } }\n\n让我们从Pokemon列表开始。我们的列表数据来自[这里](https://gist.github.com/MathewReiss/20a58ad5c1bc9a6bc23b#file-phone-js)，每个Pokemon对象都包含name，type，stage和species属性。我们需要定义一个新的GraphQLObjectType来描述这种对象。定义如下：\n\n\timport {\n\t\tGraphQLObjectType,\n\t\tGraphQLInt,\n\t\tGraphQLString,\n\t} from 'graphql';\n\n\tlet PokemonType = new GraphQLObjectType({\n  \t\tname: 'Pokemon',\n  \t\tdescription: 'A Pokemon',\n  \t\tfields: () => ({\n    \t\tname: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The name of the Pokemon.',\n    \t\t},\n    \t\ttype: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The type of the Pokemon.',\n    \t\t},\n    \t\tstage: {\n      \t\t\ttype: GraphQLInt,\n      \t\t\tdescription: 'The level of the Pokemon.',\n    \t\t},\n    \t\tspecies: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The species of the Pokemon.',\n    \t\t}\n  \t\t})\n\t});\n\n其中name，type和species都是字符串类型（type和species也可能是枚举类型），stage是整型。\n\n为了使用GraphQL来请求Pokemon，我们需要在GraphQLSchema中定义一个根query。一个标准的空的schema看起来是这样的：\n\n\timport { GraphQLSchema } from 'graphql';\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n      \t\t\t// root queries go here!\n    \t\t}\n  \t\t})\n\t});\n\n\texport default schema;\n\n为了定义我们的新的根查询，我们需要在fields中添加一个键值对对象，key为查询的名字，值为定义查询如何工作的一个对象。如下所示：\n\n\tpokemon: {\n  \t\ttype: new GraphQLList(PokemonType),\n  \t\tresolve: () => Pokemon // here, Pokemon is an in-memory array\n\t}\n\n`type`指定了GraphQL的返回类型 - 一个PokemonType对象类型的列表。`resolve`告诉GraphQL如何获取所需的数据。这里的数据仅仅是前面提到的pokemontype类型的js内存数组。\n\n鼓掌，我们的GraphQL API现在已经有了一个root query。我们可以发送一个携带查询内容的post请求来验证这部分代码（这么做可避免因使用GET而带来的编码问题）。（GraphQL并不关心如何获取这个查询--这完全有实现者来解决。）\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d '{ pokemon { name } }' http://localhost:3000/graphql\n\t\n如果我们只想获取type和species，而不要name，我们可以这么做：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d '{ pokemon { type, species } }' http://localhost:3000/graphql\n\t\n###Asynchronous Query with an Argument\n####{ user(name: “david”) { name, caught } }\n\n接下来，我们需要提供一种查询，用来根据用户名来获取对应的pokemon。让我们再次从定义user类型开始：\n\n\tlet UserType = new GraphQLObjectType({\n  \t\tname: 'User',\n  \t\tdescription: 'A User',\n  \t\tfields: () => ({\n    \t\tname: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The name of the User.',\n    \t\t},\n    \t\tcaught: {\n      \t\t\ttype: new GraphQLList(GraphQLString),\n      \t\t\tdescription: 'The Pokemon that have been caught by the User.',\n    \t\t},\n    \t\tcreated: {\n      \t\t\ttype: GraphQLInt,\n      \t\t\tdescription: 'The creation timestamp of the User.'\n    \t\t}\n  \t\t})\n\t});\n\t\nuser包含一个字符串类型的name，字符串数组类型的表示所拥有pokemon的caught和一个整型的时间戳。\n\n回到我们的GraphQLSchema，我们将添加一个user根查询，并期望得到一个UserType类型的返回。我们需要可以指定用户名的参数-我们利用`args`来实现：\n\n\tuser: {\n  \t\ttype: UserType,\n  \t\targs: {\n    \t\tname: {\n      \t\t\tdescription: 'The name of the user',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t}\n  \t\t},\n  \t\tresolve: (root, {name}) => {\n\n  \t\t}\n\t}\n\t\n我们在resolve函数中接受name参数。在这个例子中，我想使用MongoDB，所以我们的resolve函数将需要去查询MongoDB数据库并获取对应的用户对象，不过GraphQL（包括读者你）都不需要关心这个实现细节-唯一需要关心的是resolve函数将返回一个promise。（promise是一个包含then函数的对象。）所以，resolve函数可以如下定义：\n\n\tresolve: (root, {name}) => {\n  \t\treturn someLogicReturningAPromise();\n\t}\n\t\n[更屌的是如果你使用Babel，你就可以使用async/await特性（但我并没有使用，事实上，我使用的是q，而不是原生的Promises）]。\n\n为了验证这个新增的root query，我们可以执行：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d '{ user(name: “david”) { name, caught, created } }' http://localhost:3000/graphql\n\t\n###Mutations\n\nmutations通常会返回修改后的新的modified数据对象（不同于只读的query）。对于我们的Pokedex API，我们将实现一个创建user和为指定user添加pokemon到服务。为了实现这个目的，我们需要在GraphQLSchema中添加mutation定义，和我们添加query类似：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n      \t\t\t// root queries went here\n    \t\t}\n \t \t}),\n  \t\tmutation: new GraphQLObjectType({\n    \t\tname: 'Mutation',\n    \t\tfields: {\n      \t\t\t// mutations go here!\n    \t\t}\n  \t\t})\n\t});\n\t\nmutation配置和query很类似-它包含`type`，`args`和`resolve`。\n\n我们第一个mutation是添加用户：\n\n\tupsertUser: {\n  \t\ttype: UserType,\n  \t\targs: {\n    \t\tname: {\n      \t\t\tdescription: 'The name of the user',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t}\n  \t\t},\n  \t\tresolve: (obj, {name}) => {\n    \t\treturn someLogicReturningAPromise();\n  \t\t})\n\t}\n\t\n内部的，resolve函数会去mongo数据库中查询给定的用户名，如果不存在就会新建这个用户。但这些细节并不需要你关心。\n\n调用这个mutation如下：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d ‘mutation M { upsertUser(name: “newUser”) { name, caught, created } }' http://localhost:3000/graphql\n\t\n参数`mutation`很重要，后面要跟一个name--这里，name就是`M`，如果你删除了`mutation`，意味着你告诉GraphQL你想在root query中执行upsertUser（这是不存在的）。如果你省略了`M`,GraphQL会报语法错误告诉你需要给定一个name。\n\n我们要实现的第二个mutation是获取pokemon--这里的参数是用户名和pokemon名。我们的mutation非常简单：\n\n\tcaughtPokemon: {\n  \t\ttype: UserType,\n  \t\targs: {\n    \t\tname: {\n      \t\t\tdescription: 'The name of the user',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t},\n    \t\tpokemon: {\n      \t\t\tdescription: 'The name of the Pokemon that was caught',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t}\n  \t\t},\n  \t\tresolve: (obj, {name, pokemon}) => {\n    \t\treturn someLogicReturningAPromise();\n \t\t })\n\t}\n\t\n调用这个mutation如下：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d ‘mutation M { caughtPokemon(name: “newUser” pokemon: “Snorlax\") { name, caught, created } }' http://localhost:3000/graphql\n\t\n###Closing\n\nGraphQL的文档和生态圈仍处于婴儿时期，但就我们目前在一些会议和其发布的文档来看，它是很简单灵活的。从我在这篇文章中所获得的经验中来看是非常值得令人激动的。但更令我激动的是与Relay的结合。我非常乐观的认为，这些工具将会加速开发和减少代码，让我从死板的后端和数据中解脱出来。\n\n\n###读后感\n\n看完这两篇文章，我觉得大家都应该大致了解GraphQL的用法了吧，当然这里面肯定还有很多高级特性没有看到，不过GraphQL官方说明书可真是好长好长啊！！\n\n其实我觉得，可以使用GraphQL作为中间件，后端依然请求rest api，这可能是目前我觉得最稳妥的方案，毕竟关于GraphQL我们还有太多的未知，而且GraphQL还存在不少变数！","source":"_posts/GraphQL什么鬼.md","raw":"title: GraphQL什么鬼\ndate: 2016-01-01 09:37:12\ntags: \n- react\n- GraphQL\n- rest\ncategories: 前端\n---\n\n昨天看了一个技术分享，讲[react生态圈](http://www.infoq.com/cn/presentations/explore-react-ecosystem)的，很不错，尽管纯技术干货没太多，但贵在拓宽知识面，讲师也很有激情，推荐看之～\n<!--more-->\n在react生态圈里，越来越多的富有创意和激情的东西呈现在我们眼前，对于前端工程师来说真的是求之不得的时代啊～\n\nreact之前也玩过了，和它相关的一些类库（例如router，redux）我们也都陆续介绍过，甚至包含react-natvie也有所涉及，那么今天要解惑的，就是[GraphQL](https://facebook.github.io/graphql/)。\n\n官方文档冗长且晦涩，我们不妨延续以往的学习经验，先gg几篇不错的博文来共大家品尝，那么和GraphQL相关的姿势哪里找呢？请看[这里](https://github.com/chentsulin/awesome-graphql)，这里包含了各种语言的实现版本，当然也包含了入门文章的推荐，有兴趣的童鞋不妨长期关注该项目～\n\n由于我也是第一天开始了解GraphQL，并不比大家知道的多多少，所以打算翻译两篇感觉很适合入门的实战文章来让大家过过瘾，这两篇文章虽然不是出自于同一人所写，但内容上关联性却很大，个人感觉合并在一起刚刚好，所以在此斗胆合并在一起翻译，原文地址：\n\n[Your First GraphQL Server](https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2#.pkab58j87)\n\n[Writing a Basic API with GraphQL](http://davidandsuzi.com/writing-a-basic-api-with-graphql/)\n\n如果你按照我提供的轨迹，看过前面提到的那个关于“react生态圈”的技术分享，那你应该就已经知道GraphQL是为了解决什么问题而产生的，如果你没看，也没事儿，再开始翻译之前我还是会简单的阐述一下GraphQL的背景。\n\n###GraphQL对比SQL\n\n首先，官方说了，GraphQL是一个查询语言，而且目前还未完成，意味着未来可能会有更多更大的变动。\n\n单这并不妨碍世界上那么多前端工程师的折腾之路！查询语言？那就是说和sql类似喽？你看名字里都有“QL”啊～\n\n确实如此，确实是用来声明要查询的数据的，但要解决的问题却完全不一样，伴随我们多年的sql主要解决的是如何在数据库基础上提供简单易用且功能强大的沟通语言，使得我们人类可以轻而易举的从海量数据中获取到我们想要知道的数据片段。\n\nGraphQL产生的背景却完全不同，在facebook内部，大量不同的app和系统共同使用着许许多多的服务api，随着业务的变化和发展，不同app对相同资源的不同使用方法最终导致需要维护的服务api数量爆炸式的增长，非常不利于维护（我们主要在restful场景上思考）。而另一方面，创建一个大而全的通用性接口又非常不利于移动端使用（流量损耗），而且后端数据的无意义聚合也对整个系统带来了很大的资源浪费。\n\n在这样的背景下，fb工程师坐不住了，于是乎GraphQL的概念就诞生了～最了解客户端需要什么数据的只有客户端自己，所以如果给客户端提供一种机制，让其表述自己所需的数据结构，这岂不是最合理的么？\n\n###GraphQL对比Rest\n\n目前，最热的前后端通信方案应该是Restful，基于http的轻量级api，前端通过ajax请求服务端提供的rest api完成数据获取。\n\n我们再往前一步，假设你的项目前端已经组件化了，一个业务肯定是需要多个组件结合来完成的，每个组件都各自管理自己的内部状态和所需数据，那么，目前的做法是，一旦前端路由匹配了对应的业务页面，那么自然会加载相关的组件实现，同时，你还需要调用rest api来获取组件所需数据。\n\n不同的页面，组件的组合肯定也略有不同，不同的组件组合后，所需的数据自然也不会完全一致。这里你可能会说，既然以组件为单位复用，那rest api针对组件颗粒度提供一对一的服务即可，话是没错，但实际操作起来就不work了，试想前端狗被产品狗每天要求加这加那，前端狗就会不得不去求后端狗协同开发，这样最后就剩下死逼了！而且前面也说了，这样做创造出来的大量的api会变得无法维护～\n\n那么，是时候考虑采用Rest以外的解决方案了！（尽管我认为，GraphQL并非是来取代Rest的，但为了我们的描述简单，这里就直接这么写了！）后端根据GraphQL机制提供一个具有强大功能的接口，用以满足前端数据的个性化需求，既保证了多样性，又控制了接口数量，完美～\n\n###GraphQL到底是什么\n\n> A GraphQL query is a string interpreted by a server that returns data in a specified format. \n\n这端描述如果不了解它的背景，确实很容易和sql混淆～但，现在，你应该知道GraphQL到底是个什么鬼了吧～\n\n好的，下面我们就来开始GraphQL in Action!\n\n\nYour First GraphQL Server\n---\n\n今天我们将要实现一个[GraphQL](http://facebook.github.io/graphql/)小服务，我不没有打算让你放弃一切转而拥抱GraphQL，但如果你对这玩意儿很好奇，并想知道它是如何实现的，那么就往下读～\n\n###Setup an HTTP Server\n\n我们需要一个服务来接受GraphQL查询，GraphQL文档虽然并没有规定其一定要基于HTTP协议，但既然目前[GraphQL参考实现](https://github.com/graphql/graphql-js)是基于JavaScript的，那么我们就基于[Express](http://expressjs.com/)来快速打造一个http服务器完成需求吧～\n\n\t$ mkdir graphql-intro && cd ./graphql-intro\n\t$ npm install express --save\n\t$ npm install babel --save\n\t$ touch ./server.js\n\t$ touch ./index.js\n\t\n我们创建了项目文件夹（graphql-intro），并且安装了Express和[Babel](https://babeljs.io/)作为依赖。Babel并不是GraphQL所必须的，但它可以让我们使用[ES2015特性](https://babeljs.io/docs/learn-es2015/)，从而是我们可以书写更精彩的js。（译：我瞎掰的～）\n\n最后，让我们写点代码：\n\n\t// index.js\n\t// by requiring `babel/register`, all of our successive `require`s will be Babel'd\n\trequire('babel/register');\n\trequire('./server.js');\n\n\t// server.js\n\timport express from 'express';\n\n\tlet app  = express();\n\tlet PORT = 3000;\n\n\tapp.post('/graphql', (req, res) => {\n\t  res.send('Hello!');\n\t});\n\t\n\tlet server = app.listen(PORT, function () {\n\t  let host = server.address().address;\n\t  let port = server.address().port;\n\t\n\t  console.log('GraphQL listening at http://%s:%s', host, port);\n\t});\n\t\n现在运行我们的服务：\n\n\t$ node index.js\n\tGraphQL listening at http://0.0.0.0:3000\n\t\n来测试一下我们的代码：\n\n\t$ curl -XPOST http://localhost:3000/graphql\n\tHello!\n\t\n我们选择使用`/graphql`作为入口，并使用HTTP POST方法请求，这些都不是影硬性要求--GraphQL并没有限制你如何与GraphQL服务端通信。\n\n###Create a GraphQL Schema\n\n现在咱们有了一个服务，是时候来加点GraphQL啦。具体改怎么做呢？\n\n让我们回想一下GraphQL请求的模样（译：我们目前不太关心GraphQL文档的细节，只需要跟着作者的步骤即可）：\n\n\tquery getHighScore { score }\n\t\n目前，我们的GraphQL客户端需要请求`getHighScore`字段中的`score`字段，字段是用来告诉GraphQL服务返回哪些数据的，字段也可以拥有参数，如下：\n\n\tquery getHighScores(limit: 10) { score }\n\t\n它还能做更多的事儿，但让我们先往下看。\n\n我们的GraphQL服务需要进行配置才能响应上面那样的请求--这种配置被成为schema。\n\n构建一个schema其实和构建restful路由规则是很相似的。我们的schema需要描述哪些字段是服务器需要响应的，同时也需要包含这些响应对象的类型。类型信息对GraphQL来说是非常重要的，客户端可以放心的假设服务端会返回所指定的字段类型（或者一个error）。\n\n如你所想，schema声明可以非常的复杂。但对于我们这个简单的GraphQL服务来讲，我们需要一个简单的字段：`Count`。\n\n回到我们的终端：\n\n\t$ npm install graphql --save\n\t$ npm install body-parser --save\n\t$ touch ./schema.js\n\t\n就是这么靠谱，对么？[graphql](https://www.npmjs.com/package/graphql)模块包含了GraphQL的技术实现，可以允许我们来组合我们的schema和处理graphql请求。而[body-parser](https://www.npmjs.com/package/body-parser)则是一个简单的Express中间件，用来让我们获取GraphQL请求体哒～\n\n是时候来声明我们的schema：\n\n\t//schema.js\n\timport {\n  \t\tGraphQLObjectType,\n  \t\tGraphQLSchema,\n  \t\tGraphQLInt\n\t} from 'graphql/lib/type';\n\n\tlet count = 0;\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n    \t\t\tcount: {\n        \t\t\ttype: GraphQLInt,\n        \t\t\tresolve: function() {\n          \t\t\t\treturn count;\n        \t\t\t}\n      \t\t\t}\n    \t\t}\n  \t\t})\n\t});\n\n\texport default schema;\n\t\n这里我们所做的就是创建了一个`GraphQLSchema`实例，它提供了一个配置。后面GRaphQL的其他部件会使用我们这个schema实例。通常情况下我们喜欢将schema的创建放在单独的文件中。\n\n简单的解释，我们创建的schema的含义是：\n\n> 我们的顶级查询对象需要返回一个`RootQueryType`对象，它包含一个类型为整型的`count`字段。\n\n你可以猜到还有很多类似的内置基础类型（strings，lists等），当然你也可以创建自定义的特殊类型。\n\n###Connect the Schema\n\n目前我们意淫的schema并没有毛用，除非我们针对它进行查询。让我们把这个schema挂载到我们的http服务上：\n\n\timport express from 'express';\n\timport schema from './schema';\n\t// new dependencies\n\timport { graphql } from 'graphql';\n\timport bodyParser from 'body-parser';\n\n\tlet app  = express();\n\tlet PORT = 3000;\n\n\t// parse POST body as text\n\tapp.use(bodyParser.text({ type: 'application/graphql' }));\n\n\tapp.post('/graphql', (req, res) => {\n  \t\t// execute GraphQL!\n  \t\tgraphql(schema, req.body)\n  \t\t.then((result) => {\n    \t\tres.send(JSON.stringify(result, null, 2));\n  \t\t});\n\t});\n\n\tlet server = app.listen(PORT, function () {\n  \t\tvar host = server.address().address;\n  \t\tvar port = server.address().port;\n\n  \t\tconsole.log('GraphQL listening at http://%s:%s', host, port);\n\t});\n\t\n现在任何POST请求`/graphql`都将会执行我们的GRaphQL schema。我们为每个请求强制设了一个“content type”（译：'application/graphql'），这并不是GraphQL规定的，但这么做是一个好的选择，特别是当我们在现有代码中加入GraphQL功能时。\n\n执行下面的命令：\n\n\t$ node ./index.js // restart your server\n\t// in another shell\n\t$ curl -XPOST -H \"Content-Type:application/graphql\"  -d 'query \tRootQueryType { count }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"count\": 0\n  \t\t}\n\t}\n\t\n完美！GraphQL允许我们省略掉`query RootQueryType`前缀，如下：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql'  -d \t'{ count }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"count\": 0\n  \t\t}\n\t}\n\t\n现在我们已经完成了一个GraphQL例子，我们来花点时间讨论一下introspection。（译：应该翻译成“自解释”吧？）\n\n###Introspect the server\n\n有趣的是：你可以写一个GraphQL查询来请求GraphQL服务获取它的fields。\n\n听起来很疯狂？看一下这个：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql'  -d '{__schema { queryType { name, fields { name, description} }}}' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"__schema\": {\n      \t\t\t\"queryType\": {\n        \t\t\t\"name\": \"RootQueryType\",\n        \t\t\t\"fields\": [\n          \t\t\t\t{\n            \t\t\t\t\"name\": \"count\",\n            \t\t\t\t\"description\": null\n          \t\t\t\t}\n        \t\t\t]\n      \t\t\t}\n    \t\t}\n  \t\t}\n\t}\n\t\n格式化一下我们上面发送的查询语句：\n\n\t{\n  \t\t__schema {\n    \t\tqueryType {\n      \t\t\tname, \n      \t\t\tfields {\n        \t\t\tname,\n        \t\t\tdescription\n      \t\t\t}\n    \t\t}\n  \t\t}\n\t}\n\n通常，每个GraphQL根字段自动包含一个`__Schema`[字段](http://facebook.github.io/graphql/#sec-Schema-Introspection)，其包含用来查询的描述自身meta信息的字段--`queryType`。\n\n更可爱的是，你可以定义一些很有意义的元信息，例如`description`，`isDeprecated`，和`deprecationReason`。facebook宣成他们的工具可以很好的利用这些元信息来提升开发者的体验～\n\n为了让我们的服务更容易使用，我们这里添加了`description`字段：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n      \t\t\tcount: {\n        \t\t\ttype: GraphQLInt,\n        \t\t\t// add the description\n        \t\t\tdescription: 'The count!',\n        \t\t\tresolve: function() {\n          \t\t\t\treturn count;\n        \t\t\t}\n      \t\t\t}\n    \t\t}\n  \t\t})\n\t});\n\t\n重启服务后看一下新的元数据展示：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql'  -d '{__schema { queryType { name, fields { name, description} }}}' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"__schema\": {\n      \t\t\t\"queryType\": {\n        \t\t\t\"name\": \"RootQueryType\",\n        \t\t\t\"fields\": [\n          \t\t\t\t{\n            \t\t\t\t\"name\": \"count\",\n            \t\t\t\t\"description\": \"The count!\"\n          \t\t\t\t}\n        \t\t\t]\n      \t\t\t}\n   \t\t\t }\n  \t\t}\n\t}\n\t\n\n我们几乎已经完成了我们的GraphQL旅程，接下来我将展示mutations。\n\n###Add a Mutation\n\n如果你只对只读数据接口感兴趣，你就不用读下去了。但大多数应用，我们都需要去更改我们的数据。GraphQL把这种操作称为mutations。\n\nMutations仅仅是一个字段，所以语法和query字段都差不多，Mutations字段必须返回一个类型值--目的是如果你更改了数据，你必须提供更改后的值。\n\n我们该如何为我们的schema增加mutations？和`query`非常相似，我们定义一个顶级键`mutation`：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: ...\n  \t\tmutation: // todo\n\t)}\n\t\n除此之外，还有啥不特别的？我们需要在`count`字段函数中更新我们的计数器或者做一些GraphQL根本不需要感知的其他变更操作。\n\nmutation和query有一个非常重要的不同点，mutation是有执行顺序的，但是query没有这方面的保证（事实上，GraphQL推荐并行处理那些不存在依赖的查询）。GraphQL说明书给了下面的mutation例子来描述执行顺序：\n\n\t{\n  \t\tfirst: changeTheNumber(newNumber: 1) {\n    \t\ttheNumber\n  \t\t},\n  \t\tsecond: changeTheNumber(newNumber: 3) {\n    \t\ttheNumber\n  \t\t},\n  \t\tthird: changeTheNumber(newNumber: 2) {\n    \t\ttheNumber\n  \t\t}\n\t}\n\n最终，请求处理完毕后，`theNumber`字段的值应该是`2`。\n\n让我们新增一个简单的mutation来更新我们的计数器并返回新值：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: ...\n  \t\tmutation: new GraphQLObjectType({\n    \t\tname: 'RootMutationType',\n    \t\tfields: {\n      \t\t\tupdateCount: {\n        \t\t\ttype: GraphQLInt,\n        \t\t\tdescription: 'Updates the count',\n        \t\t\tresolve: function() {\n          \t\t\t\tcount += 1;\n          \t\t\t\treturn count;\n        \t\t\t}\n      \t\t\t}\n    \t\t}\n  \t\t})\n\t});\n\t\n重启我们的服务，试一下：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql' -d 'mutation \tRootMutationType { updateCount }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"updateCount\": 1\n  \t\t}\n\t}\n\t\n看--数据已经更改了。你可以重新查询一下：\n\n\t$ curl -XPOST -H 'Content-Type:application/graphql' -d '{ count }' http://localhost:3000/graphql\n\t{\n  \t\t\"data\": {\n    \t\t\"count\": 1\n  \t\t}\n\t}\n\n你可以多执行几次。\n\n为了严格遵守GraphQ实现，我们应该提供一个更语意化的值名（例如`CountValue`），这样会让mutation和query返回值都更加有意义。\n\n###Wrapping Up\n\n本文章教你如何使用facebook提供的GraphQL javascript版实现来完成服务的。但我并没有涉及过多的强大话题--fields with arguments, resolving promises, fragments, directives等等。GraphQL说明书中介绍了很多特别屌的特性。其实还有很多不同的服务端GraphQL实现和schema API。你可以使用像java这样的强类型语言来实现GraphQL服务。\n\n本篇是基于我的GraphQL的48小时体验而来--如果有什么遗漏或错误，别忘了让我知道。你可以在这里看到源码（每次提交都对应流程中的每一步）：\n\n[https://github.com/clayallsopp/graphql-intro](https://github.com/clayallsopp/graphql-intro)\n\n十分感谢RisingStack的关于GraphQL的[文章和例子](http://blog.risingstack.com/graphql-overview-getting-started-with-graphql-and-nodejs/)。\n\n\n---\n\nWriting a Basic API with GraphQL\n---\n\n这篇文章假设你了解GraphQL，并试图将你的后端实现转换成GraphQL，内容覆盖了同步/异步，query/mutation。\n\n源码：[https://github.com/davidchang/graphql-pokedex-api](https://github.com/davidchang/graphql-pokedex-api)\n\n基本的Pokedex客户端实现来自于我上周的[Redux Post](http://davidandsuzi.com/writing-a-basic-api-with-graphql/davidandsuzi.com/writing-a-basic-app-in-redux/)，让我们使用GraphQL来实现一个Pokedex后端API。我们需要两个query方法（查询口袋妖怪列表和指定用户所拥有的口袋妖怪）和两个mutation方法（创建用户和用户捕获口袋妖怪）。\n\n口袋妖怪列表数据存储在内存中，而用户和其拥有的口袋妖怪数据则将存储再MongoDB。\n\n###Starting\n\n继续前面提到的[文章](https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2)（其实就是上一篇），我使用babel在node上创建了一个Express服务端，它包含了一个`/graphql`路由。我的server.js入口文件如下：\n\n\timport express from 'express';\n\timport schema from './schema';\n\timport { graphql } from 'graphql';\n\timport bodyParser from 'body-parser';\n\n\tlet app  = express();\n\n\t// parse POST body as text\n\tapp.use(bodyParser.text({ type: 'application/graphql' }));\n\n\tapp.post('/graphql', (req, res) => {\n  \t\t// execute GraphQL!\n  \t\tgraphql(schema, req.body)\n    \t\t.then(result => res.send(result));\n\t\t});\n\n\tlet server = app.listen(\n\t\t3000,\n  \t\t() => console.log(`GraphQL running on port ${server.address().port}`)\n\t);\n\t\n###Synchronous Query\n####{ pokemon { name } }\n\n让我们从Pokemon列表开始。我们的列表数据来自[这里](https://gist.github.com/MathewReiss/20a58ad5c1bc9a6bc23b#file-phone-js)，每个Pokemon对象都包含name，type，stage和species属性。我们需要定义一个新的GraphQLObjectType来描述这种对象。定义如下：\n\n\timport {\n\t\tGraphQLObjectType,\n\t\tGraphQLInt,\n\t\tGraphQLString,\n\t} from 'graphql';\n\n\tlet PokemonType = new GraphQLObjectType({\n  \t\tname: 'Pokemon',\n  \t\tdescription: 'A Pokemon',\n  \t\tfields: () => ({\n    \t\tname: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The name of the Pokemon.',\n    \t\t},\n    \t\ttype: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The type of the Pokemon.',\n    \t\t},\n    \t\tstage: {\n      \t\t\ttype: GraphQLInt,\n      \t\t\tdescription: 'The level of the Pokemon.',\n    \t\t},\n    \t\tspecies: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The species of the Pokemon.',\n    \t\t}\n  \t\t})\n\t});\n\n其中name，type和species都是字符串类型（type和species也可能是枚举类型），stage是整型。\n\n为了使用GraphQL来请求Pokemon，我们需要在GraphQLSchema中定义一个根query。一个标准的空的schema看起来是这样的：\n\n\timport { GraphQLSchema } from 'graphql';\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n      \t\t\t// root queries go here!\n    \t\t}\n  \t\t})\n\t});\n\n\texport default schema;\n\n为了定义我们的新的根查询，我们需要在fields中添加一个键值对对象，key为查询的名字，值为定义查询如何工作的一个对象。如下所示：\n\n\tpokemon: {\n  \t\ttype: new GraphQLList(PokemonType),\n  \t\tresolve: () => Pokemon // here, Pokemon is an in-memory array\n\t}\n\n`type`指定了GraphQL的返回类型 - 一个PokemonType对象类型的列表。`resolve`告诉GraphQL如何获取所需的数据。这里的数据仅仅是前面提到的pokemontype类型的js内存数组。\n\n鼓掌，我们的GraphQL API现在已经有了一个root query。我们可以发送一个携带查询内容的post请求来验证这部分代码（这么做可避免因使用GET而带来的编码问题）。（GraphQL并不关心如何获取这个查询--这完全有实现者来解决。）\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d '{ pokemon { name } }' http://localhost:3000/graphql\n\t\n如果我们只想获取type和species，而不要name，我们可以这么做：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d '{ pokemon { type, species } }' http://localhost:3000/graphql\n\t\n###Asynchronous Query with an Argument\n####{ user(name: “david”) { name, caught } }\n\n接下来，我们需要提供一种查询，用来根据用户名来获取对应的pokemon。让我们再次从定义user类型开始：\n\n\tlet UserType = new GraphQLObjectType({\n  \t\tname: 'User',\n  \t\tdescription: 'A User',\n  \t\tfields: () => ({\n    \t\tname: {\n      \t\t\ttype: GraphQLString,\n      \t\t\tdescription: 'The name of the User.',\n    \t\t},\n    \t\tcaught: {\n      \t\t\ttype: new GraphQLList(GraphQLString),\n      \t\t\tdescription: 'The Pokemon that have been caught by the User.',\n    \t\t},\n    \t\tcreated: {\n      \t\t\ttype: GraphQLInt,\n      \t\t\tdescription: 'The creation timestamp of the User.'\n    \t\t}\n  \t\t})\n\t});\n\t\nuser包含一个字符串类型的name，字符串数组类型的表示所拥有pokemon的caught和一个整型的时间戳。\n\n回到我们的GraphQLSchema，我们将添加一个user根查询，并期望得到一个UserType类型的返回。我们需要可以指定用户名的参数-我们利用`args`来实现：\n\n\tuser: {\n  \t\ttype: UserType,\n  \t\targs: {\n    \t\tname: {\n      \t\t\tdescription: 'The name of the user',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t}\n  \t\t},\n  \t\tresolve: (root, {name}) => {\n\n  \t\t}\n\t}\n\t\n我们在resolve函数中接受name参数。在这个例子中，我想使用MongoDB，所以我们的resolve函数将需要去查询MongoDB数据库并获取对应的用户对象，不过GraphQL（包括读者你）都不需要关心这个实现细节-唯一需要关心的是resolve函数将返回一个promise。（promise是一个包含then函数的对象。）所以，resolve函数可以如下定义：\n\n\tresolve: (root, {name}) => {\n  \t\treturn someLogicReturningAPromise();\n\t}\n\t\n[更屌的是如果你使用Babel，你就可以使用async/await特性（但我并没有使用，事实上，我使用的是q，而不是原生的Promises）]。\n\n为了验证这个新增的root query，我们可以执行：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d '{ user(name: “david”) { name, caught, created } }' http://localhost:3000/graphql\n\t\n###Mutations\n\nmutations通常会返回修改后的新的modified数据对象（不同于只读的query）。对于我们的Pokedex API，我们将实现一个创建user和为指定user添加pokemon到服务。为了实现这个目的，我们需要在GraphQLSchema中添加mutation定义，和我们添加query类似：\n\n\tlet schema = new GraphQLSchema({\n  \t\tquery: new GraphQLObjectType({\n    \t\tname: 'RootQueryType',\n    \t\tfields: {\n      \t\t\t// root queries went here\n    \t\t}\n \t \t}),\n  \t\tmutation: new GraphQLObjectType({\n    \t\tname: 'Mutation',\n    \t\tfields: {\n      \t\t\t// mutations go here!\n    \t\t}\n  \t\t})\n\t});\n\t\nmutation配置和query很类似-它包含`type`，`args`和`resolve`。\n\n我们第一个mutation是添加用户：\n\n\tupsertUser: {\n  \t\ttype: UserType,\n  \t\targs: {\n    \t\tname: {\n      \t\t\tdescription: 'The name of the user',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t}\n  \t\t},\n  \t\tresolve: (obj, {name}) => {\n    \t\treturn someLogicReturningAPromise();\n  \t\t})\n\t}\n\t\n内部的，resolve函数会去mongo数据库中查询给定的用户名，如果不存在就会新建这个用户。但这些细节并不需要你关心。\n\n调用这个mutation如下：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d ‘mutation M { upsertUser(name: “newUser”) { name, caught, created } }' http://localhost:3000/graphql\n\t\n参数`mutation`很重要，后面要跟一个name--这里，name就是`M`，如果你删除了`mutation`，意味着你告诉GraphQL你想在root query中执行upsertUser（这是不存在的）。如果你省略了`M`,GraphQL会报语法错误告诉你需要给定一个name。\n\n我们要实现的第二个mutation是获取pokemon--这里的参数是用户名和pokemon名。我们的mutation非常简单：\n\n\tcaughtPokemon: {\n  \t\ttype: UserType,\n  \t\targs: {\n    \t\tname: {\n      \t\t\tdescription: 'The name of the user',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t},\n    \t\tpokemon: {\n      \t\t\tdescription: 'The name of the Pokemon that was caught',\n      \t\t\ttype: new GraphQLNonNull(GraphQLString)\n    \t\t}\n  \t\t},\n  \t\tresolve: (obj, {name, pokemon}) => {\n    \t\treturn someLogicReturningAPromise();\n \t\t })\n\t}\n\t\n调用这个mutation如下：\n\n\tcurl -XPOST -H 'Content-Type:application/graphql'  -d ‘mutation M { caughtPokemon(name: “newUser” pokemon: “Snorlax\") { name, caught, created } }' http://localhost:3000/graphql\n\t\n###Closing\n\nGraphQL的文档和生态圈仍处于婴儿时期，但就我们目前在一些会议和其发布的文档来看，它是很简单灵活的。从我在这篇文章中所获得的经验中来看是非常值得令人激动的。但更令我激动的是与Relay的结合。我非常乐观的认为，这些工具将会加速开发和减少代码，让我从死板的后端和数据中解脱出来。\n\n\n###读后感\n\n看完这两篇文章，我觉得大家都应该大致了解GraphQL的用法了吧，当然这里面肯定还有很多高级特性没有看到，不过GraphQL官方说明书可真是好长好长啊！！\n\n其实我觉得，可以使用GraphQL作为中间件，后端依然请求rest api，这可能是目前我觉得最稳妥的方案，毕竟关于GraphQL我们还有太多的未知，而且GraphQL还存在不少变数！","slug":"GraphQL什么鬼","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"ciiznmhdp0000wfwsnfmrj6w4","comments":1,"layout":"post","photos":[],"link":"","content":"<p>昨天看了一个技术分享，讲<a href=\"http://www.infoq.com/cn/presentations/explore-react-ecosystem\" target=\"_blank\" rel=\"external\">react生态圈</a>的，很不错，尽管纯技术干货没太多，但贵在拓宽知识面，讲师也很有激情，推荐看之～<br><a id=\"more\"></a><br>在react生态圈里，越来越多的富有创意和激情的东西呈现在我们眼前，对于前端工程师来说真的是求之不得的时代啊～</p>\n<p>react之前也玩过了，和它相关的一些类库（例如router，redux）我们也都陆续介绍过，甚至包含react-natvie也有所涉及，那么今天要解惑的，就是<a href=\"https://facebook.github.io/graphql/\" target=\"_blank\" rel=\"external\">GraphQL</a>。</p>\n<p>官方文档冗长且晦涩，我们不妨延续以往的学习经验，先gg几篇不错的博文来共大家品尝，那么和GraphQL相关的姿势哪里找呢？请看<a href=\"https://github.com/chentsulin/awesome-graphql\" target=\"_blank\" rel=\"external\">这里</a>，这里包含了各种语言的实现版本，当然也包含了入门文章的推荐，有兴趣的童鞋不妨长期关注该项目～</p>\n<p>由于我也是第一天开始了解GraphQL，并不比大家知道的多多少，所以打算翻译两篇感觉很适合入门的实战文章来让大家过过瘾，这两篇文章虽然不是出自于同一人所写，但内容上关联性却很大，个人感觉合并在一起刚刚好，所以在此斗胆合并在一起翻译，原文地址：</p>\n<p><a href=\"https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2#.pkab58j87\" target=\"_blank\" rel=\"external\">Your First GraphQL Server</a></p>\n<p><a href=\"http://davidandsuzi.com/writing-a-basic-api-with-graphql/\" target=\"_blank\" rel=\"external\">Writing a Basic API with GraphQL</a></p>\n<p>如果你按照我提供的轨迹，看过前面提到的那个关于“react生态圈”的技术分享，那你应该就已经知道GraphQL是为了解决什么问题而产生的，如果你没看，也没事儿，再开始翻译之前我还是会简单的阐述一下GraphQL的背景。</p>\n<p>###GraphQL对比SQL</p>\n<p>首先，官方说了，GraphQL是一个查询语言，而且目前还未完成，意味着未来可能会有更多更大的变动。</p>\n<p>单这并不妨碍世界上那么多前端工程师的折腾之路！查询语言？那就是说和sql类似喽？你看名字里都有“QL”啊～</p>\n<p>确实如此，确实是用来声明要查询的数据的，但要解决的问题却完全不一样，伴随我们多年的sql主要解决的是如何在数据库基础上提供简单易用且功能强大的沟通语言，使得我们人类可以轻而易举的从海量数据中获取到我们想要知道的数据片段。</p>\n<p>GraphQL产生的背景却完全不同，在facebook内部，大量不同的app和系统共同使用着许许多多的服务api，随着业务的变化和发展，不同app对相同资源的不同使用方法最终导致需要维护的服务api数量爆炸式的增长，非常不利于维护（我们主要在restful场景上思考）。而另一方面，创建一个大而全的通用性接口又非常不利于移动端使用（流量损耗），而且后端数据的无意义聚合也对整个系统带来了很大的资源浪费。</p>\n<p>在这样的背景下，fb工程师坐不住了，于是乎GraphQL的概念就诞生了～最了解客户端需要什么数据的只有客户端自己，所以如果给客户端提供一种机制，让其表述自己所需的数据结构，这岂不是最合理的么？</p>\n<p>###GraphQL对比Rest</p>\n<p>目前，最热的前后端通信方案应该是Restful，基于http的轻量级api，前端通过ajax请求服务端提供的rest api完成数据获取。</p>\n<p>我们再往前一步，假设你的项目前端已经组件化了，一个业务肯定是需要多个组件结合来完成的，每个组件都各自管理自己的内部状态和所需数据，那么，目前的做法是，一旦前端路由匹配了对应的业务页面，那么自然会加载相关的组件实现，同时，你还需要调用rest api来获取组件所需数据。</p>\n<p>不同的页面，组件的组合肯定也略有不同，不同的组件组合后，所需的数据自然也不会完全一致。这里你可能会说，既然以组件为单位复用，那rest api针对组件颗粒度提供一对一的服务即可，话是没错，但实际操作起来就不work了，试想前端狗被产品狗每天要求加这加那，前端狗就会不得不去求后端狗协同开发，这样最后就剩下死逼了！而且前面也说了，这样做创造出来的大量的api会变得无法维护～</p>\n<p>那么，是时候考虑采用Rest以外的解决方案了！（尽管我认为，GraphQL并非是来取代Rest的，但为了我们的描述简单，这里就直接这么写了！）后端根据GraphQL机制提供一个具有强大功能的接口，用以满足前端数据的个性化需求，既保证了多样性，又控制了接口数量，完美～</p>\n<p>###GraphQL到底是什么</p>\n<blockquote>\n<p>A GraphQL query is a string interpreted by a server that returns data in a specified format. </p>\n</blockquote>\n<p>这端描述如果不了解它的背景，确实很容易和sql混淆～但，现在，你应该知道GraphQL到底是个什么鬼了吧～</p>\n<p>好的，下面我们就来开始GraphQL in Action!</p>\n<h2 id=\"Your-First-GraphQL-Server\"><a href=\"#Your-First-GraphQL-Server\" class=\"headerlink\" title=\"Your First GraphQL Server\"></a>Your First GraphQL Server</h2><p>今天我们将要实现一个<a href=\"http://facebook.github.io/graphql/\" target=\"_blank\" rel=\"external\">GraphQL</a>小服务，我不没有打算让你放弃一切转而拥抱GraphQL，但如果你对这玩意儿很好奇，并想知道它是如何实现的，那么就往下读～</p>\n<p>###Setup an HTTP Server</p>\n<p>我们需要一个服务来接受GraphQL查询，GraphQL文档虽然并没有规定其一定要基于HTTP协议，但既然目前<a href=\"https://github.com/graphql/graphql-js\" target=\"_blank\" rel=\"external\">GraphQL参考实现</a>是基于JavaScript的，那么我们就基于<a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"external\">Express</a>来快速打造一个http服务器完成需求吧～</p>\n<pre><code>$ mkdir graphql-intro &amp;&amp; cd ./graphql-intro\n$ npm install express --save\n$ npm install babel --save\n$ touch ./server.js\n$ touch ./index.js\n</code></pre><p>我们创建了项目文件夹（graphql-intro），并且安装了Express和<a href=\"https://babeljs.io/\" target=\"_blank\" rel=\"external\">Babel</a>作为依赖。Babel并不是GraphQL所必须的，但它可以让我们使用<a href=\"https://babeljs.io/docs/learn-es2015/\" target=\"_blank\" rel=\"external\">ES2015特性</a>，从而是我们可以书写更精彩的js。（译：我瞎掰的～）</p>\n<p>最后，让我们写点代码：</p>\n<pre><code>// index.js\n// by requiring `babel/register`, all of our successive `require`s will be Babel&apos;d\nrequire(&apos;babel/register&apos;);\nrequire(&apos;./server.js&apos;);\n\n// server.js\nimport express from &apos;express&apos;;\n\nlet app  = express();\nlet PORT = 3000;\n\napp.post(&apos;/graphql&apos;, (req, res) =&gt; {\n  res.send(&apos;Hello!&apos;);\n});\n\nlet server = app.listen(PORT, function () {\n  let host = server.address().address;\n  let port = server.address().port;\n\n  console.log(&apos;GraphQL listening at http://%s:%s&apos;, host, port);\n});\n</code></pre><p>现在运行我们的服务：</p>\n<pre><code>$ node index.js\nGraphQL listening at http://0.0.0.0:3000\n</code></pre><p>来测试一下我们的代码：</p>\n<pre><code>$ curl -XPOST http://localhost:3000/graphql\nHello!\n</code></pre><p>我们选择使用<code>/graphql</code>作为入口，并使用HTTP POST方法请求，这些都不是影硬性要求–GraphQL并没有限制你如何与GraphQL服务端通信。</p>\n<p>###Create a GraphQL Schema</p>\n<p>现在咱们有了一个服务，是时候来加点GraphQL啦。具体改怎么做呢？</p>\n<p>让我们回想一下GraphQL请求的模样（译：我们目前不太关心GraphQL文档的细节，只需要跟着作者的步骤即可）：</p>\n<pre><code>query getHighScore { score }\n</code></pre><p>目前，我们的GraphQL客户端需要请求<code>getHighScore</code>字段中的<code>score</code>字段，字段是用来告诉GraphQL服务返回哪些数据的，字段也可以拥有参数，如下：</p>\n<pre><code>query getHighScores(limit: 10) { score }\n</code></pre><p>它还能做更多的事儿，但让我们先往下看。</p>\n<p>我们的GraphQL服务需要进行配置才能响应上面那样的请求–这种配置被成为schema。</p>\n<p>构建一个schema其实和构建restful路由规则是很相似的。我们的schema需要描述哪些字段是服务器需要响应的，同时也需要包含这些响应对象的类型。类型信息对GraphQL来说是非常重要的，客户端可以放心的假设服务端会返回所指定的字段类型（或者一个error）。</p>\n<p>如你所想，schema声明可以非常的复杂。但对于我们这个简单的GraphQL服务来讲，我们需要一个简单的字段：<code>Count</code>。</p>\n<p>回到我们的终端：</p>\n<pre><code>$ npm install graphql --save\n$ npm install body-parser --save\n$ touch ./schema.js\n</code></pre><p>就是这么靠谱，对么？<a href=\"https://www.npmjs.com/package/graphql\" target=\"_blank\" rel=\"external\">graphql</a>模块包含了GraphQL的技术实现，可以允许我们来组合我们的schema和处理graphql请求。而<a href=\"https://www.npmjs.com/package/body-parser\" target=\"_blank\" rel=\"external\">body-parser</a>则是一个简单的Express中间件，用来让我们获取GraphQL请求体哒～</p>\n<p>是时候来声明我们的schema：</p>\n<pre><code>//schema.js\nimport {\n      GraphQLObjectType,\n      GraphQLSchema,\n      GraphQLInt\n} from &apos;graphql/lib/type&apos;;\n\nlet count = 0;\n\nlet schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n            count: {\n                type: GraphQLInt,\n                resolve: function() {\n                      return count;\n                }\n              }\n        }\n      })\n});\n\nexport default schema;\n</code></pre><p>这里我们所做的就是创建了一个<code>GraphQLSchema</code>实例，它提供了一个配置。后面GRaphQL的其他部件会使用我们这个schema实例。通常情况下我们喜欢将schema的创建放在单独的文件中。</p>\n<p>简单的解释，我们创建的schema的含义是：</p>\n<blockquote>\n<p>我们的顶级查询对象需要返回一个<code>RootQueryType</code>对象，它包含一个类型为整型的<code>count</code>字段。</p>\n</blockquote>\n<p>你可以猜到还有很多类似的内置基础类型（strings，lists等），当然你也可以创建自定义的特殊类型。</p>\n<p>###Connect the Schema</p>\n<p>目前我们意淫的schema并没有毛用，除非我们针对它进行查询。让我们把这个schema挂载到我们的http服务上：</p>\n<pre><code>import express from &apos;express&apos;;\nimport schema from &apos;./schema&apos;;\n// new dependencies\nimport { graphql } from &apos;graphql&apos;;\nimport bodyParser from &apos;body-parser&apos;;\n\nlet app  = express();\nlet PORT = 3000;\n\n// parse POST body as text\napp.use(bodyParser.text({ type: &apos;application/graphql&apos; }));\n\napp.post(&apos;/graphql&apos;, (req, res) =&gt; {\n      // execute GraphQL!\n      graphql(schema, req.body)\n      .then((result) =&gt; {\n        res.send(JSON.stringify(result, null, 2));\n      });\n});\n\nlet server = app.listen(PORT, function () {\n      var host = server.address().address;\n      var port = server.address().port;\n\n      console.log(&apos;GraphQL listening at http://%s:%s&apos;, host, port);\n});\n</code></pre><p>现在任何POST请求<code>/graphql</code>都将会执行我们的GRaphQL schema。我们为每个请求强制设了一个“content type”（译：’application/graphql’），这并不是GraphQL规定的，但这么做是一个好的选择，特别是当我们在现有代码中加入GraphQL功能时。</p>\n<p>执行下面的命令：</p>\n<pre><code>$ node ./index.js // restart your server\n// in another shell\n$ curl -XPOST -H &quot;Content-Type:application/graphql&quot;  -d &apos;query     RootQueryType { count }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;count&quot;: 0\n      }\n}\n</code></pre><p>完美！GraphQL允许我们省略掉<code>query RootQueryType</code>前缀，如下：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d     &apos;{ count }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;count&quot;: 0\n      }\n}\n</code></pre><p>现在我们已经完成了一个GraphQL例子，我们来花点时间讨论一下introspection。（译：应该翻译成“自解释”吧？）</p>\n<p>###Introspect the server</p>\n<p>有趣的是：你可以写一个GraphQL查询来请求GraphQL服务获取它的fields。</p>\n<p>听起来很疯狂？看一下这个：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{__schema { queryType { name, fields { name, description} }}}&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;__schema&quot;: {\n              &quot;queryType&quot;: {\n                &quot;name&quot;: &quot;RootQueryType&quot;,\n                &quot;fields&quot;: [\n                      {\n                        &quot;name&quot;: &quot;count&quot;,\n                        &quot;description&quot;: null\n                      }\n                ]\n              }\n        }\n      }\n}\n</code></pre><p>格式化一下我们上面发送的查询语句：</p>\n<pre><code>{\n      __schema {\n        queryType {\n              name, \n              fields {\n                name,\n                description\n              }\n        }\n      }\n}\n</code></pre><p>通常，每个GraphQL根字段自动包含一个<code>__Schema</code><a href=\"http://facebook.github.io/graphql/#sec-Schema-Introspection\" target=\"_blank\" rel=\"external\">字段</a>，其包含用来查询的描述自身meta信息的字段–<code>queryType</code>。</p>\n<p>更可爱的是，你可以定义一些很有意义的元信息，例如<code>description</code>，<code>isDeprecated</code>，和<code>deprecationReason</code>。facebook宣成他们的工具可以很好的利用这些元信息来提升开发者的体验～</p>\n<p>为了让我们的服务更容易使用，我们这里添加了<code>description</code>字段：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n              count: {\n                type: GraphQLInt,\n                // add the description\n                description: &apos;The count!&apos;,\n                resolve: function() {\n                      return count;\n                }\n              }\n        }\n      })\n});\n</code></pre><p>重启服务后看一下新的元数据展示：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{__schema { queryType { name, fields { name, description} }}}&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;__schema&quot;: {\n              &quot;queryType&quot;: {\n                &quot;name&quot;: &quot;RootQueryType&quot;,\n                &quot;fields&quot;: [\n                      {\n                        &quot;name&quot;: &quot;count&quot;,\n                        &quot;description&quot;: &quot;The count!&quot;\n                      }\n                ]\n              }\n            }\n      }\n}\n</code></pre><p>我们几乎已经完成了我们的GraphQL旅程，接下来我将展示mutations。</p>\n<p>###Add a Mutation</p>\n<p>如果你只对只读数据接口感兴趣，你就不用读下去了。但大多数应用，我们都需要去更改我们的数据。GraphQL把这种操作称为mutations。</p>\n<p>Mutations仅仅是一个字段，所以语法和query字段都差不多，Mutations字段必须返回一个类型值–目的是如果你更改了数据，你必须提供更改后的值。</p>\n<p>我们该如何为我们的schema增加mutations？和<code>query</code>非常相似，我们定义一个顶级键<code>mutation</code>：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: ...\n      mutation: // todo\n)}\n</code></pre><p>除此之外，还有啥不特别的？我们需要在<code>count</code>字段函数中更新我们的计数器或者做一些GraphQL根本不需要感知的其他变更操作。</p>\n<p>mutation和query有一个非常重要的不同点，mutation是有执行顺序的，但是query没有这方面的保证（事实上，GraphQL推荐并行处理那些不存在依赖的查询）。GraphQL说明书给了下面的mutation例子来描述执行顺序：</p>\n<pre><code>{\n      first: changeTheNumber(newNumber: 1) {\n        theNumber\n      },\n      second: changeTheNumber(newNumber: 3) {\n        theNumber\n      },\n      third: changeTheNumber(newNumber: 2) {\n        theNumber\n      }\n}\n</code></pre><p>最终，请求处理完毕后，<code>theNumber</code>字段的值应该是<code>2</code>。</p>\n<p>让我们新增一个简单的mutation来更新我们的计数器并返回新值：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: ...\n      mutation: new GraphQLObjectType({\n        name: &apos;RootMutationType&apos;,\n        fields: {\n              updateCount: {\n                type: GraphQLInt,\n                description: &apos;Updates the count&apos;,\n                resolve: function() {\n                      count += 1;\n                      return count;\n                }\n              }\n        }\n      })\n});\n</code></pre><p>重启我们的服务，试一下：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos; -d &apos;mutation     RootMutationType { updateCount }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;updateCount&quot;: 1\n      }\n}\n</code></pre><p>看–数据已经更改了。你可以重新查询一下：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos; -d &apos;{ count }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;count&quot;: 1\n      }\n}\n</code></pre><p>你可以多执行几次。</p>\n<p>为了严格遵守GraphQ实现，我们应该提供一个更语意化的值名（例如<code>CountValue</code>），这样会让mutation和query返回值都更加有意义。</p>\n<p>###Wrapping Up</p>\n<p>本文章教你如何使用facebook提供的GraphQL javascript版实现来完成服务的。但我并没有涉及过多的强大话题–fields with arguments, resolving promises, fragments, directives等等。GraphQL说明书中介绍了很多特别屌的特性。其实还有很多不同的服务端GraphQL实现和schema API。你可以使用像java这样的强类型语言来实现GraphQL服务。</p>\n<p>本篇是基于我的GraphQL的48小时体验而来–如果有什么遗漏或错误，别忘了让我知道。你可以在这里看到源码（每次提交都对应流程中的每一步）：</p>\n<p><a href=\"https://github.com/clayallsopp/graphql-intro\" target=\"_blank\" rel=\"external\">https://github.com/clayallsopp/graphql-intro</a></p>\n<p>十分感谢RisingStack的关于GraphQL的<a href=\"http://blog.risingstack.com/graphql-overview-getting-started-with-graphql-and-nodejs/\" target=\"_blank\" rel=\"external\">文章和例子</a>。</p>\n<hr>\n<h2 id=\"Writing-a-Basic-API-with-GraphQL\"><a href=\"#Writing-a-Basic-API-with-GraphQL\" class=\"headerlink\" title=\"Writing a Basic API with GraphQL\"></a>Writing a Basic API with GraphQL</h2><p>这篇文章假设你了解GraphQL，并试图将你的后端实现转换成GraphQL，内容覆盖了同步/异步，query/mutation。</p>\n<p>源码：<a href=\"https://github.com/davidchang/graphql-pokedex-api\" target=\"_blank\" rel=\"external\">https://github.com/davidchang/graphql-pokedex-api</a></p>\n<p>基本的Pokedex客户端实现来自于我上周的<a href=\"http://davidandsuzi.com/writing-a-basic-api-with-graphql/davidandsuzi.com/writing-a-basic-app-in-redux/\" target=\"_blank\" rel=\"external\">Redux Post</a>，让我们使用GraphQL来实现一个Pokedex后端API。我们需要两个query方法（查询口袋妖怪列表和指定用户所拥有的口袋妖怪）和两个mutation方法（创建用户和用户捕获口袋妖怪）。</p>\n<p>口袋妖怪列表数据存储在内存中，而用户和其拥有的口袋妖怪数据则将存储再MongoDB。</p>\n<p>###Starting</p>\n<p>继续前面提到的<a href=\"https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2\" target=\"_blank\" rel=\"external\">文章</a>（其实就是上一篇），我使用babel在node上创建了一个Express服务端，它包含了一个<code>/graphql</code>路由。我的server.js入口文件如下：</p>\n<pre><code>import express from &apos;express&apos;;\nimport schema from &apos;./schema&apos;;\nimport { graphql } from &apos;graphql&apos;;\nimport bodyParser from &apos;body-parser&apos;;\n\nlet app  = express();\n\n// parse POST body as text\napp.use(bodyParser.text({ type: &apos;application/graphql&apos; }));\n\napp.post(&apos;/graphql&apos;, (req, res) =&gt; {\n      // execute GraphQL!\n      graphql(schema, req.body)\n        .then(result =&gt; res.send(result));\n    });\n\nlet server = app.listen(\n    3000,\n      () =&gt; console.log(`GraphQL running on port ${server.address().port}`)\n);\n</code></pre><p>###Synchronous Query</p>\n<p>####{ pokemon { name } }</p>\n<p>让我们从Pokemon列表开始。我们的列表数据来自<a href=\"https://gist.github.com/MathewReiss/20a58ad5c1bc9a6bc23b#file-phone-js\" target=\"_blank\" rel=\"external\">这里</a>，每个Pokemon对象都包含name，type，stage和species属性。我们需要定义一个新的GraphQLObjectType来描述这种对象。定义如下：</p>\n<pre><code>import {\n    GraphQLObjectType,\n    GraphQLInt,\n    GraphQLString,\n} from &apos;graphql&apos;;\n\nlet PokemonType = new GraphQLObjectType({\n      name: &apos;Pokemon&apos;,\n      description: &apos;A Pokemon&apos;,\n      fields: () =&gt; ({\n        name: {\n              type: GraphQLString,\n              description: &apos;The name of the Pokemon.&apos;,\n        },\n        type: {\n              type: GraphQLString,\n              description: &apos;The type of the Pokemon.&apos;,\n        },\n        stage: {\n              type: GraphQLInt,\n              description: &apos;The level of the Pokemon.&apos;,\n        },\n        species: {\n              type: GraphQLString,\n              description: &apos;The species of the Pokemon.&apos;,\n        }\n      })\n});\n</code></pre><p>其中name，type和species都是字符串类型（type和species也可能是枚举类型），stage是整型。</p>\n<p>为了使用GraphQL来请求Pokemon，我们需要在GraphQLSchema中定义一个根query。一个标准的空的schema看起来是这样的：</p>\n<pre><code>import { GraphQLSchema } from &apos;graphql&apos;;\n\nlet schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n              // root queries go here!\n        }\n      })\n});\n\nexport default schema;\n</code></pre><p>为了定义我们的新的根查询，我们需要在fields中添加一个键值对对象，key为查询的名字，值为定义查询如何工作的一个对象。如下所示：</p>\n<pre><code>pokemon: {\n      type: new GraphQLList(PokemonType),\n      resolve: () =&gt; Pokemon // here, Pokemon is an in-memory array\n}\n</code></pre><p><code>type</code>指定了GraphQL的返回类型 - 一个PokemonType对象类型的列表。<code>resolve</code>告诉GraphQL如何获取所需的数据。这里的数据仅仅是前面提到的pokemontype类型的js内存数组。</p>\n<p>鼓掌，我们的GraphQL API现在已经有了一个root query。我们可以发送一个携带查询内容的post请求来验证这部分代码（这么做可避免因使用GET而带来的编码问题）。（GraphQL并不关心如何获取这个查询–这完全有实现者来解决。）</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{ pokemon { name } }&apos; http://localhost:3000/graphql\n</code></pre><p>如果我们只想获取type和species，而不要name，我们可以这么做：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{ pokemon { type, species } }&apos; http://localhost:3000/graphql\n</code></pre><p>###Asynchronous Query with an Argument</p>\n<p>####{ user(name: “david”) { name, caught } }</p>\n<p>接下来，我们需要提供一种查询，用来根据用户名来获取对应的pokemon。让我们再次从定义user类型开始：</p>\n<pre><code>let UserType = new GraphQLObjectType({\n      name: &apos;User&apos;,\n      description: &apos;A User&apos;,\n      fields: () =&gt; ({\n        name: {\n              type: GraphQLString,\n              description: &apos;The name of the User.&apos;,\n        },\n        caught: {\n              type: new GraphQLList(GraphQLString),\n              description: &apos;The Pokemon that have been caught by the User.&apos;,\n        },\n        created: {\n              type: GraphQLInt,\n              description: &apos;The creation timestamp of the User.&apos;\n        }\n      })\n});\n</code></pre><p>user包含一个字符串类型的name，字符串数组类型的表示所拥有pokemon的caught和一个整型的时间戳。</p>\n<p>回到我们的GraphQLSchema，我们将添加一个user根查询，并期望得到一个UserType类型的返回。我们需要可以指定用户名的参数-我们利用<code>args</code>来实现：</p>\n<pre><code>user: {\n      type: UserType,\n      args: {\n        name: {\n              description: &apos;The name of the user&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        }\n      },\n      resolve: (root, {name}) =&gt; {\n\n      }\n}\n</code></pre><p>我们在resolve函数中接受name参数。在这个例子中，我想使用MongoDB，所以我们的resolve函数将需要去查询MongoDB数据库并获取对应的用户对象，不过GraphQL（包括读者你）都不需要关心这个实现细节-唯一需要关心的是resolve函数将返回一个promise。（promise是一个包含then函数的对象。）所以，resolve函数可以如下定义：</p>\n<pre><code>resolve: (root, {name}) =&gt; {\n      return someLogicReturningAPromise();\n}\n</code></pre><p>[更屌的是如果你使用Babel，你就可以使用async/await特性（但我并没有使用，事实上，我使用的是q，而不是原生的Promises）]。</p>\n<p>为了验证这个新增的root query，我们可以执行：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{ user(name: “david”) { name, caught, created } }&apos; http://localhost:3000/graphql\n</code></pre><p>###Mutations</p>\n<p>mutations通常会返回修改后的新的modified数据对象（不同于只读的query）。对于我们的Pokedex API，我们将实现一个创建user和为指定user添加pokemon到服务。为了实现这个目的，我们需要在GraphQLSchema中添加mutation定义，和我们添加query类似：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n              // root queries went here\n        }\n      }),\n      mutation: new GraphQLObjectType({\n        name: &apos;Mutation&apos;,\n        fields: {\n              // mutations go here!\n        }\n      })\n});\n</code></pre><p>mutation配置和query很类似-它包含<code>type</code>，<code>args</code>和<code>resolve</code>。</p>\n<p>我们第一个mutation是添加用户：</p>\n<pre><code>upsertUser: {\n      type: UserType,\n      args: {\n        name: {\n              description: &apos;The name of the user&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        }\n      },\n      resolve: (obj, {name}) =&gt; {\n        return someLogicReturningAPromise();\n      })\n}\n</code></pre><p>内部的，resolve函数会去mongo数据库中查询给定的用户名，如果不存在就会新建这个用户。但这些细节并不需要你关心。</p>\n<p>调用这个mutation如下：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d ‘mutation M { upsertUser(name: “newUser”) { name, caught, created } }&apos; http://localhost:3000/graphql\n</code></pre><p>参数<code>mutation</code>很重要，后面要跟一个name–这里，name就是<code>M</code>，如果你删除了<code>mutation</code>，意味着你告诉GraphQL你想在root query中执行upsertUser（这是不存在的）。如果你省略了<code>M</code>,GraphQL会报语法错误告诉你需要给定一个name。</p>\n<p>我们要实现的第二个mutation是获取pokemon–这里的参数是用户名和pokemon名。我们的mutation非常简单：</p>\n<pre><code>caughtPokemon: {\n      type: UserType,\n      args: {\n        name: {\n              description: &apos;The name of the user&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        },\n        pokemon: {\n              description: &apos;The name of the Pokemon that was caught&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        }\n      },\n      resolve: (obj, {name, pokemon}) =&gt; {\n        return someLogicReturningAPromise();\n      })\n}\n</code></pre><p>调用这个mutation如下：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d ‘mutation M { caughtPokemon(name: “newUser” pokemon: “Snorlax&quot;) { name, caught, created } }&apos; http://localhost:3000/graphql\n</code></pre><p>###Closing</p>\n<p>GraphQL的文档和生态圈仍处于婴儿时期，但就我们目前在一些会议和其发布的文档来看，它是很简单灵活的。从我在这篇文章中所获得的经验中来看是非常值得令人激动的。但更令我激动的是与Relay的结合。我非常乐观的认为，这些工具将会加速开发和减少代码，让我从死板的后端和数据中解脱出来。</p>\n<p>###读后感</p>\n<p>看完这两篇文章，我觉得大家都应该大致了解GraphQL的用法了吧，当然这里面肯定还有很多高级特性没有看到，不过GraphQL官方说明书可真是好长好长啊！！</p>\n<p>其实我觉得，可以使用GraphQL作为中间件，后端依然请求rest api，这可能是目前我觉得最稳妥的方案，毕竟关于GraphQL我们还有太多的未知，而且GraphQL还存在不少变数！</p>\n","excerpt":"<p>昨天看了一个技术分享，讲<a href=\"http://www.infoq.com/cn/presentations/explore-react-ecosystem\">react生态圈</a>的，很不错，尽管纯技术干货没太多，但贵在拓宽知识面，讲师也很有激情，推荐看之～<br>","more":"<br>在react生态圈里，越来越多的富有创意和激情的东西呈现在我们眼前，对于前端工程师来说真的是求之不得的时代啊～</p>\n<p>react之前也玩过了，和它相关的一些类库（例如router，redux）我们也都陆续介绍过，甚至包含react-natvie也有所涉及，那么今天要解惑的，就是<a href=\"https://facebook.github.io/graphql/\">GraphQL</a>。</p>\n<p>官方文档冗长且晦涩，我们不妨延续以往的学习经验，先gg几篇不错的博文来共大家品尝，那么和GraphQL相关的姿势哪里找呢？请看<a href=\"https://github.com/chentsulin/awesome-graphql\">这里</a>，这里包含了各种语言的实现版本，当然也包含了入门文章的推荐，有兴趣的童鞋不妨长期关注该项目～</p>\n<p>由于我也是第一天开始了解GraphQL，并不比大家知道的多多少，所以打算翻译两篇感觉很适合入门的实战文章来让大家过过瘾，这两篇文章虽然不是出自于同一人所写，但内容上关联性却很大，个人感觉合并在一起刚刚好，所以在此斗胆合并在一起翻译，原文地址：</p>\n<p><a href=\"https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2#.pkab58j87\">Your First GraphQL Server</a></p>\n<p><a href=\"http://davidandsuzi.com/writing-a-basic-api-with-graphql/\">Writing a Basic API with GraphQL</a></p>\n<p>如果你按照我提供的轨迹，看过前面提到的那个关于“react生态圈”的技术分享，那你应该就已经知道GraphQL是为了解决什么问题而产生的，如果你没看，也没事儿，再开始翻译之前我还是会简单的阐述一下GraphQL的背景。</p>\n<p>###GraphQL对比SQL</p>\n<p>首先，官方说了，GraphQL是一个查询语言，而且目前还未完成，意味着未来可能会有更多更大的变动。</p>\n<p>单这并不妨碍世界上那么多前端工程师的折腾之路！查询语言？那就是说和sql类似喽？你看名字里都有“QL”啊～</p>\n<p>确实如此，确实是用来声明要查询的数据的，但要解决的问题却完全不一样，伴随我们多年的sql主要解决的是如何在数据库基础上提供简单易用且功能强大的沟通语言，使得我们人类可以轻而易举的从海量数据中获取到我们想要知道的数据片段。</p>\n<p>GraphQL产生的背景却完全不同，在facebook内部，大量不同的app和系统共同使用着许许多多的服务api，随着业务的变化和发展，不同app对相同资源的不同使用方法最终导致需要维护的服务api数量爆炸式的增长，非常不利于维护（我们主要在restful场景上思考）。而另一方面，创建一个大而全的通用性接口又非常不利于移动端使用（流量损耗），而且后端数据的无意义聚合也对整个系统带来了很大的资源浪费。</p>\n<p>在这样的背景下，fb工程师坐不住了，于是乎GraphQL的概念就诞生了～最了解客户端需要什么数据的只有客户端自己，所以如果给客户端提供一种机制，让其表述自己所需的数据结构，这岂不是最合理的么？</p>\n<p>###GraphQL对比Rest</p>\n<p>目前，最热的前后端通信方案应该是Restful，基于http的轻量级api，前端通过ajax请求服务端提供的rest api完成数据获取。</p>\n<p>我们再往前一步，假设你的项目前端已经组件化了，一个业务肯定是需要多个组件结合来完成的，每个组件都各自管理自己的内部状态和所需数据，那么，目前的做法是，一旦前端路由匹配了对应的业务页面，那么自然会加载相关的组件实现，同时，你还需要调用rest api来获取组件所需数据。</p>\n<p>不同的页面，组件的组合肯定也略有不同，不同的组件组合后，所需的数据自然也不会完全一致。这里你可能会说，既然以组件为单位复用，那rest api针对组件颗粒度提供一对一的服务即可，话是没错，但实际操作起来就不work了，试想前端狗被产品狗每天要求加这加那，前端狗就会不得不去求后端狗协同开发，这样最后就剩下死逼了！而且前面也说了，这样做创造出来的大量的api会变得无法维护～</p>\n<p>那么，是时候考虑采用Rest以外的解决方案了！（尽管我认为，GraphQL并非是来取代Rest的，但为了我们的描述简单，这里就直接这么写了！）后端根据GraphQL机制提供一个具有强大功能的接口，用以满足前端数据的个性化需求，既保证了多样性，又控制了接口数量，完美～</p>\n<p>###GraphQL到底是什么</p>\n<blockquote>\n<p>A GraphQL query is a string interpreted by a server that returns data in a specified format. </p>\n</blockquote>\n<p>这端描述如果不了解它的背景，确实很容易和sql混淆～但，现在，你应该知道GraphQL到底是个什么鬼了吧～</p>\n<p>好的，下面我们就来开始GraphQL in Action!</p>\n<h2 id=\"Your-First-GraphQL-Server\"><a href=\"#Your-First-GraphQL-Server\" class=\"headerlink\" title=\"Your First GraphQL Server\"></a>Your First GraphQL Server</h2><p>今天我们将要实现一个<a href=\"http://facebook.github.io/graphql/\">GraphQL</a>小服务，我不没有打算让你放弃一切转而拥抱GraphQL，但如果你对这玩意儿很好奇，并想知道它是如何实现的，那么就往下读～</p>\n<p>###Setup an HTTP Server</p>\n<p>我们需要一个服务来接受GraphQL查询，GraphQL文档虽然并没有规定其一定要基于HTTP协议，但既然目前<a href=\"https://github.com/graphql/graphql-js\">GraphQL参考实现</a>是基于JavaScript的，那么我们就基于<a href=\"http://expressjs.com/\">Express</a>来快速打造一个http服务器完成需求吧～</p>\n<pre><code>$ mkdir graphql-intro &amp;&amp; cd ./graphql-intro\n$ npm install express --save\n$ npm install babel --save\n$ touch ./server.js\n$ touch ./index.js\n</code></pre><p>我们创建了项目文件夹（graphql-intro），并且安装了Express和<a href=\"https://babeljs.io/\">Babel</a>作为依赖。Babel并不是GraphQL所必须的，但它可以让我们使用<a href=\"https://babeljs.io/docs/learn-es2015/\">ES2015特性</a>，从而是我们可以书写更精彩的js。（译：我瞎掰的～）</p>\n<p>最后，让我们写点代码：</p>\n<pre><code>// index.js\n// by requiring `babel/register`, all of our successive `require`s will be Babel&apos;d\nrequire(&apos;babel/register&apos;);\nrequire(&apos;./server.js&apos;);\n\n// server.js\nimport express from &apos;express&apos;;\n\nlet app  = express();\nlet PORT = 3000;\n\napp.post(&apos;/graphql&apos;, (req, res) =&gt; {\n  res.send(&apos;Hello!&apos;);\n});\n\nlet server = app.listen(PORT, function () {\n  let host = server.address().address;\n  let port = server.address().port;\n\n  console.log(&apos;GraphQL listening at http://%s:%s&apos;, host, port);\n});\n</code></pre><p>现在运行我们的服务：</p>\n<pre><code>$ node index.js\nGraphQL listening at http://0.0.0.0:3000\n</code></pre><p>来测试一下我们的代码：</p>\n<pre><code>$ curl -XPOST http://localhost:3000/graphql\nHello!\n</code></pre><p>我们选择使用<code>/graphql</code>作为入口，并使用HTTP POST方法请求，这些都不是影硬性要求–GraphQL并没有限制你如何与GraphQL服务端通信。</p>\n<p>###Create a GraphQL Schema</p>\n<p>现在咱们有了一个服务，是时候来加点GraphQL啦。具体改怎么做呢？</p>\n<p>让我们回想一下GraphQL请求的模样（译：我们目前不太关心GraphQL文档的细节，只需要跟着作者的步骤即可）：</p>\n<pre><code>query getHighScore { score }\n</code></pre><p>目前，我们的GraphQL客户端需要请求<code>getHighScore</code>字段中的<code>score</code>字段，字段是用来告诉GraphQL服务返回哪些数据的，字段也可以拥有参数，如下：</p>\n<pre><code>query getHighScores(limit: 10) { score }\n</code></pre><p>它还能做更多的事儿，但让我们先往下看。</p>\n<p>我们的GraphQL服务需要进行配置才能响应上面那样的请求–这种配置被成为schema。</p>\n<p>构建一个schema其实和构建restful路由规则是很相似的。我们的schema需要描述哪些字段是服务器需要响应的，同时也需要包含这些响应对象的类型。类型信息对GraphQL来说是非常重要的，客户端可以放心的假设服务端会返回所指定的字段类型（或者一个error）。</p>\n<p>如你所想，schema声明可以非常的复杂。但对于我们这个简单的GraphQL服务来讲，我们需要一个简单的字段：<code>Count</code>。</p>\n<p>回到我们的终端：</p>\n<pre><code>$ npm install graphql --save\n$ npm install body-parser --save\n$ touch ./schema.js\n</code></pre><p>就是这么靠谱，对么？<a href=\"https://www.npmjs.com/package/graphql\">graphql</a>模块包含了GraphQL的技术实现，可以允许我们来组合我们的schema和处理graphql请求。而<a href=\"https://www.npmjs.com/package/body-parser\">body-parser</a>则是一个简单的Express中间件，用来让我们获取GraphQL请求体哒～</p>\n<p>是时候来声明我们的schema：</p>\n<pre><code>//schema.js\nimport {\n      GraphQLObjectType,\n      GraphQLSchema,\n      GraphQLInt\n} from &apos;graphql/lib/type&apos;;\n\nlet count = 0;\n\nlet schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n            count: {\n                type: GraphQLInt,\n                resolve: function() {\n                      return count;\n                }\n              }\n        }\n      })\n});\n\nexport default schema;\n</code></pre><p>这里我们所做的就是创建了一个<code>GraphQLSchema</code>实例，它提供了一个配置。后面GRaphQL的其他部件会使用我们这个schema实例。通常情况下我们喜欢将schema的创建放在单独的文件中。</p>\n<p>简单的解释，我们创建的schema的含义是：</p>\n<blockquote>\n<p>我们的顶级查询对象需要返回一个<code>RootQueryType</code>对象，它包含一个类型为整型的<code>count</code>字段。</p>\n</blockquote>\n<p>你可以猜到还有很多类似的内置基础类型（strings，lists等），当然你也可以创建自定义的特殊类型。</p>\n<p>###Connect the Schema</p>\n<p>目前我们意淫的schema并没有毛用，除非我们针对它进行查询。让我们把这个schema挂载到我们的http服务上：</p>\n<pre><code>import express from &apos;express&apos;;\nimport schema from &apos;./schema&apos;;\n// new dependencies\nimport { graphql } from &apos;graphql&apos;;\nimport bodyParser from &apos;body-parser&apos;;\n\nlet app  = express();\nlet PORT = 3000;\n\n// parse POST body as text\napp.use(bodyParser.text({ type: &apos;application/graphql&apos; }));\n\napp.post(&apos;/graphql&apos;, (req, res) =&gt; {\n      // execute GraphQL!\n      graphql(schema, req.body)\n      .then((result) =&gt; {\n        res.send(JSON.stringify(result, null, 2));\n      });\n});\n\nlet server = app.listen(PORT, function () {\n      var host = server.address().address;\n      var port = server.address().port;\n\n      console.log(&apos;GraphQL listening at http://%s:%s&apos;, host, port);\n});\n</code></pre><p>现在任何POST请求<code>/graphql</code>都将会执行我们的GRaphQL schema。我们为每个请求强制设了一个“content type”（译：’application/graphql’），这并不是GraphQL规定的，但这么做是一个好的选择，特别是当我们在现有代码中加入GraphQL功能时。</p>\n<p>执行下面的命令：</p>\n<pre><code>$ node ./index.js // restart your server\n// in another shell\n$ curl -XPOST -H &quot;Content-Type:application/graphql&quot;  -d &apos;query     RootQueryType { count }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;count&quot;: 0\n      }\n}\n</code></pre><p>完美！GraphQL允许我们省略掉<code>query RootQueryType</code>前缀，如下：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d     &apos;{ count }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;count&quot;: 0\n      }\n}\n</code></pre><p>现在我们已经完成了一个GraphQL例子，我们来花点时间讨论一下introspection。（译：应该翻译成“自解释”吧？）</p>\n<p>###Introspect the server</p>\n<p>有趣的是：你可以写一个GraphQL查询来请求GraphQL服务获取它的fields。</p>\n<p>听起来很疯狂？看一下这个：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{__schema { queryType { name, fields { name, description} }}}&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;__schema&quot;: {\n              &quot;queryType&quot;: {\n                &quot;name&quot;: &quot;RootQueryType&quot;,\n                &quot;fields&quot;: [\n                      {\n                        &quot;name&quot;: &quot;count&quot;,\n                        &quot;description&quot;: null\n                      }\n                ]\n              }\n        }\n      }\n}\n</code></pre><p>格式化一下我们上面发送的查询语句：</p>\n<pre><code>{\n      __schema {\n        queryType {\n              name, \n              fields {\n                name,\n                description\n              }\n        }\n      }\n}\n</code></pre><p>通常，每个GraphQL根字段自动包含一个<code>__Schema</code><a href=\"http://facebook.github.io/graphql/#sec-Schema-Introspection\">字段</a>，其包含用来查询的描述自身meta信息的字段–<code>queryType</code>。</p>\n<p>更可爱的是，你可以定义一些很有意义的元信息，例如<code>description</code>，<code>isDeprecated</code>，和<code>deprecationReason</code>。facebook宣成他们的工具可以很好的利用这些元信息来提升开发者的体验～</p>\n<p>为了让我们的服务更容易使用，我们这里添加了<code>description</code>字段：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n              count: {\n                type: GraphQLInt,\n                // add the description\n                description: &apos;The count!&apos;,\n                resolve: function() {\n                      return count;\n                }\n              }\n        }\n      })\n});\n</code></pre><p>重启服务后看一下新的元数据展示：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{__schema { queryType { name, fields { name, description} }}}&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;__schema&quot;: {\n              &quot;queryType&quot;: {\n                &quot;name&quot;: &quot;RootQueryType&quot;,\n                &quot;fields&quot;: [\n                      {\n                        &quot;name&quot;: &quot;count&quot;,\n                        &quot;description&quot;: &quot;The count!&quot;\n                      }\n                ]\n              }\n            }\n      }\n}\n</code></pre><p>我们几乎已经完成了我们的GraphQL旅程，接下来我将展示mutations。</p>\n<p>###Add a Mutation</p>\n<p>如果你只对只读数据接口感兴趣，你就不用读下去了。但大多数应用，我们都需要去更改我们的数据。GraphQL把这种操作称为mutations。</p>\n<p>Mutations仅仅是一个字段，所以语法和query字段都差不多，Mutations字段必须返回一个类型值–目的是如果你更改了数据，你必须提供更改后的值。</p>\n<p>我们该如何为我们的schema增加mutations？和<code>query</code>非常相似，我们定义一个顶级键<code>mutation</code>：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: ...\n      mutation: // todo\n)}\n</code></pre><p>除此之外，还有啥不特别的？我们需要在<code>count</code>字段函数中更新我们的计数器或者做一些GraphQL根本不需要感知的其他变更操作。</p>\n<p>mutation和query有一个非常重要的不同点，mutation是有执行顺序的，但是query没有这方面的保证（事实上，GraphQL推荐并行处理那些不存在依赖的查询）。GraphQL说明书给了下面的mutation例子来描述执行顺序：</p>\n<pre><code>{\n      first: changeTheNumber(newNumber: 1) {\n        theNumber\n      },\n      second: changeTheNumber(newNumber: 3) {\n        theNumber\n      },\n      third: changeTheNumber(newNumber: 2) {\n        theNumber\n      }\n}\n</code></pre><p>最终，请求处理完毕后，<code>theNumber</code>字段的值应该是<code>2</code>。</p>\n<p>让我们新增一个简单的mutation来更新我们的计数器并返回新值：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: ...\n      mutation: new GraphQLObjectType({\n        name: &apos;RootMutationType&apos;,\n        fields: {\n              updateCount: {\n                type: GraphQLInt,\n                description: &apos;Updates the count&apos;,\n                resolve: function() {\n                      count += 1;\n                      return count;\n                }\n              }\n        }\n      })\n});\n</code></pre><p>重启我们的服务，试一下：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos; -d &apos;mutation     RootMutationType { updateCount }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;updateCount&quot;: 1\n      }\n}\n</code></pre><p>看–数据已经更改了。你可以重新查询一下：</p>\n<pre><code>$ curl -XPOST -H &apos;Content-Type:application/graphql&apos; -d &apos;{ count }&apos; http://localhost:3000/graphql\n{\n      &quot;data&quot;: {\n        &quot;count&quot;: 1\n      }\n}\n</code></pre><p>你可以多执行几次。</p>\n<p>为了严格遵守GraphQ实现，我们应该提供一个更语意化的值名（例如<code>CountValue</code>），这样会让mutation和query返回值都更加有意义。</p>\n<p>###Wrapping Up</p>\n<p>本文章教你如何使用facebook提供的GraphQL javascript版实现来完成服务的。但我并没有涉及过多的强大话题–fields with arguments, resolving promises, fragments, directives等等。GraphQL说明书中介绍了很多特别屌的特性。其实还有很多不同的服务端GraphQL实现和schema API。你可以使用像java这样的强类型语言来实现GraphQL服务。</p>\n<p>本篇是基于我的GraphQL的48小时体验而来–如果有什么遗漏或错误，别忘了让我知道。你可以在这里看到源码（每次提交都对应流程中的每一步）：</p>\n<p><a href=\"https://github.com/clayallsopp/graphql-intro\">https://github.com/clayallsopp/graphql-intro</a></p>\n<p>十分感谢RisingStack的关于GraphQL的<a href=\"http://blog.risingstack.com/graphql-overview-getting-started-with-graphql-and-nodejs/\">文章和例子</a>。</p>\n<hr>\n<h2 id=\"Writing-a-Basic-API-with-GraphQL\"><a href=\"#Writing-a-Basic-API-with-GraphQL\" class=\"headerlink\" title=\"Writing a Basic API with GraphQL\"></a>Writing a Basic API with GraphQL</h2><p>这篇文章假设你了解GraphQL，并试图将你的后端实现转换成GraphQL，内容覆盖了同步/异步，query/mutation。</p>\n<p>源码：<a href=\"https://github.com/davidchang/graphql-pokedex-api\">https://github.com/davidchang/graphql-pokedex-api</a></p>\n<p>基本的Pokedex客户端实现来自于我上周的<a href=\"http://davidandsuzi.com/writing-a-basic-api-with-graphql/davidandsuzi.com/writing-a-basic-app-in-redux/\">Redux Post</a>，让我们使用GraphQL来实现一个Pokedex后端API。我们需要两个query方法（查询口袋妖怪列表和指定用户所拥有的口袋妖怪）和两个mutation方法（创建用户和用户捕获口袋妖怪）。</p>\n<p>口袋妖怪列表数据存储在内存中，而用户和其拥有的口袋妖怪数据则将存储再MongoDB。</p>\n<p>###Starting</p>\n<p>继续前面提到的<a href=\"https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2\">文章</a>（其实就是上一篇），我使用babel在node上创建了一个Express服务端，它包含了一个<code>/graphql</code>路由。我的server.js入口文件如下：</p>\n<pre><code>import express from &apos;express&apos;;\nimport schema from &apos;./schema&apos;;\nimport { graphql } from &apos;graphql&apos;;\nimport bodyParser from &apos;body-parser&apos;;\n\nlet app  = express();\n\n// parse POST body as text\napp.use(bodyParser.text({ type: &apos;application/graphql&apos; }));\n\napp.post(&apos;/graphql&apos;, (req, res) =&gt; {\n      // execute GraphQL!\n      graphql(schema, req.body)\n        .then(result =&gt; res.send(result));\n    });\n\nlet server = app.listen(\n    3000,\n      () =&gt; console.log(`GraphQL running on port ${server.address().port}`)\n);\n</code></pre><p>###Synchronous Query</p>\n<p>####{ pokemon { name } }</p>\n<p>让我们从Pokemon列表开始。我们的列表数据来自<a href=\"https://gist.github.com/MathewReiss/20a58ad5c1bc9a6bc23b#file-phone-js\">这里</a>，每个Pokemon对象都包含name，type，stage和species属性。我们需要定义一个新的GraphQLObjectType来描述这种对象。定义如下：</p>\n<pre><code>import {\n    GraphQLObjectType,\n    GraphQLInt,\n    GraphQLString,\n} from &apos;graphql&apos;;\n\nlet PokemonType = new GraphQLObjectType({\n      name: &apos;Pokemon&apos;,\n      description: &apos;A Pokemon&apos;,\n      fields: () =&gt; ({\n        name: {\n              type: GraphQLString,\n              description: &apos;The name of the Pokemon.&apos;,\n        },\n        type: {\n              type: GraphQLString,\n              description: &apos;The type of the Pokemon.&apos;,\n        },\n        stage: {\n              type: GraphQLInt,\n              description: &apos;The level of the Pokemon.&apos;,\n        },\n        species: {\n              type: GraphQLString,\n              description: &apos;The species of the Pokemon.&apos;,\n        }\n      })\n});\n</code></pre><p>其中name，type和species都是字符串类型（type和species也可能是枚举类型），stage是整型。</p>\n<p>为了使用GraphQL来请求Pokemon，我们需要在GraphQLSchema中定义一个根query。一个标准的空的schema看起来是这样的：</p>\n<pre><code>import { GraphQLSchema } from &apos;graphql&apos;;\n\nlet schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n              // root queries go here!\n        }\n      })\n});\n\nexport default schema;\n</code></pre><p>为了定义我们的新的根查询，我们需要在fields中添加一个键值对对象，key为查询的名字，值为定义查询如何工作的一个对象。如下所示：</p>\n<pre><code>pokemon: {\n      type: new GraphQLList(PokemonType),\n      resolve: () =&gt; Pokemon // here, Pokemon is an in-memory array\n}\n</code></pre><p><code>type</code>指定了GraphQL的返回类型 - 一个PokemonType对象类型的列表。<code>resolve</code>告诉GraphQL如何获取所需的数据。这里的数据仅仅是前面提到的pokemontype类型的js内存数组。</p>\n<p>鼓掌，我们的GraphQL API现在已经有了一个root query。我们可以发送一个携带查询内容的post请求来验证这部分代码（这么做可避免因使用GET而带来的编码问题）。（GraphQL并不关心如何获取这个查询–这完全有实现者来解决。）</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{ pokemon { name } }&apos; http://localhost:3000/graphql\n</code></pre><p>如果我们只想获取type和species，而不要name，我们可以这么做：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{ pokemon { type, species } }&apos; http://localhost:3000/graphql\n</code></pre><p>###Asynchronous Query with an Argument</p>\n<p>####{ user(name: “david”) { name, caught } }</p>\n<p>接下来，我们需要提供一种查询，用来根据用户名来获取对应的pokemon。让我们再次从定义user类型开始：</p>\n<pre><code>let UserType = new GraphQLObjectType({\n      name: &apos;User&apos;,\n      description: &apos;A User&apos;,\n      fields: () =&gt; ({\n        name: {\n              type: GraphQLString,\n              description: &apos;The name of the User.&apos;,\n        },\n        caught: {\n              type: new GraphQLList(GraphQLString),\n              description: &apos;The Pokemon that have been caught by the User.&apos;,\n        },\n        created: {\n              type: GraphQLInt,\n              description: &apos;The creation timestamp of the User.&apos;\n        }\n      })\n});\n</code></pre><p>user包含一个字符串类型的name，字符串数组类型的表示所拥有pokemon的caught和一个整型的时间戳。</p>\n<p>回到我们的GraphQLSchema，我们将添加一个user根查询，并期望得到一个UserType类型的返回。我们需要可以指定用户名的参数-我们利用<code>args</code>来实现：</p>\n<pre><code>user: {\n      type: UserType,\n      args: {\n        name: {\n              description: &apos;The name of the user&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        }\n      },\n      resolve: (root, {name}) =&gt; {\n\n      }\n}\n</code></pre><p>我们在resolve函数中接受name参数。在这个例子中，我想使用MongoDB，所以我们的resolve函数将需要去查询MongoDB数据库并获取对应的用户对象，不过GraphQL（包括读者你）都不需要关心这个实现细节-唯一需要关心的是resolve函数将返回一个promise。（promise是一个包含then函数的对象。）所以，resolve函数可以如下定义：</p>\n<pre><code>resolve: (root, {name}) =&gt; {\n      return someLogicReturningAPromise();\n}\n</code></pre><p>[更屌的是如果你使用Babel，你就可以使用async/await特性（但我并没有使用，事实上，我使用的是q，而不是原生的Promises）]。</p>\n<p>为了验证这个新增的root query，我们可以执行：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d &apos;{ user(name: “david”) { name, caught, created } }&apos; http://localhost:3000/graphql\n</code></pre><p>###Mutations</p>\n<p>mutations通常会返回修改后的新的modified数据对象（不同于只读的query）。对于我们的Pokedex API，我们将实现一个创建user和为指定user添加pokemon到服务。为了实现这个目的，我们需要在GraphQLSchema中添加mutation定义，和我们添加query类似：</p>\n<pre><code>let schema = new GraphQLSchema({\n      query: new GraphQLObjectType({\n        name: &apos;RootQueryType&apos;,\n        fields: {\n              // root queries went here\n        }\n      }),\n      mutation: new GraphQLObjectType({\n        name: &apos;Mutation&apos;,\n        fields: {\n              // mutations go here!\n        }\n      })\n});\n</code></pre><p>mutation配置和query很类似-它包含<code>type</code>，<code>args</code>和<code>resolve</code>。</p>\n<p>我们第一个mutation是添加用户：</p>\n<pre><code>upsertUser: {\n      type: UserType,\n      args: {\n        name: {\n              description: &apos;The name of the user&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        }\n      },\n      resolve: (obj, {name}) =&gt; {\n        return someLogicReturningAPromise();\n      })\n}\n</code></pre><p>内部的，resolve函数会去mongo数据库中查询给定的用户名，如果不存在就会新建这个用户。但这些细节并不需要你关心。</p>\n<p>调用这个mutation如下：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d ‘mutation M { upsertUser(name: “newUser”) { name, caught, created } }&apos; http://localhost:3000/graphql\n</code></pre><p>参数<code>mutation</code>很重要，后面要跟一个name–这里，name就是<code>M</code>，如果你删除了<code>mutation</code>，意味着你告诉GraphQL你想在root query中执行upsertUser（这是不存在的）。如果你省略了<code>M</code>,GraphQL会报语法错误告诉你需要给定一个name。</p>\n<p>我们要实现的第二个mutation是获取pokemon–这里的参数是用户名和pokemon名。我们的mutation非常简单：</p>\n<pre><code>caughtPokemon: {\n      type: UserType,\n      args: {\n        name: {\n              description: &apos;The name of the user&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        },\n        pokemon: {\n              description: &apos;The name of the Pokemon that was caught&apos;,\n              type: new GraphQLNonNull(GraphQLString)\n        }\n      },\n      resolve: (obj, {name, pokemon}) =&gt; {\n        return someLogicReturningAPromise();\n      })\n}\n</code></pre><p>调用这个mutation如下：</p>\n<pre><code>curl -XPOST -H &apos;Content-Type:application/graphql&apos;  -d ‘mutation M { caughtPokemon(name: “newUser” pokemon: “Snorlax&quot;) { name, caught, created } }&apos; http://localhost:3000/graphql\n</code></pre><p>###Closing</p>\n<p>GraphQL的文档和生态圈仍处于婴儿时期，但就我们目前在一些会议和其发布的文档来看，它是很简单灵活的。从我在这篇文章中所获得的经验中来看是非常值得令人激动的。但更令我激动的是与Relay的结合。我非常乐观的认为，这些工具将会加速开发和减少代码，让我从死板的后端和数据中解脱出来。</p>\n<p>###读后感</p>\n<p>看完这两篇文章，我觉得大家都应该大致了解GraphQL的用法了吧，当然这里面肯定还有很多高级特性没有看到，不过GraphQL官方说明书可真是好长好长啊！！</p>\n<p>其实我觉得，可以使用GraphQL作为中间件，后端依然请求rest api，这可能是目前我觉得最稳妥的方案，毕竟关于GraphQL我们还有太多的未知，而且GraphQL还存在不少变数！</p>"},{"title":"［译］Relay101制作HackerNew客户端","date":"2016-01-02T01:37:00.000Z","_content":"\n原文地址：[https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6](https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6)\n\n[React](https://facebook.github.io/react/)让我们可以使用javascrip创建用户界面组件；[Relay](https://facebook.github.io/relay/)则可以让我们很容易的打通react组件和远程服务器的数据通信。为了实现这个目标Relay需要一个条件--它假设客户端和服务器端必须满足某种要求，这可能增加了使用它的门槛，但对于一些项目来说这是非常值得的！\n<!--more-->\n没有Relay的日子，你需要自己实现数据的下载，传输，缓存。像Flux和Redux这类工具帮你避免了在这过程中的一些bug，但当大量数据来往于应用与服务器之间时还是有非常多的人为性错误存在的可能。Relay会减少非常多的通用样板代码，让客户端开发人员可以更简洁安全的获取他们想要的数据。\n\n按照之前Rails的十五分钟搭建blog的传统，我们这里将快速使用Relay搭建一个HAcker News客户端。教程假设你了解Node，NPM和react，没有其他要求了～\n\n###Getting GraphQL\n\n目前Relay需要你的服务器提供[GraphQL](https://facebook.github.io/graphql/)接口。GraphQL非常优雅，但除非你是facebook的工程师，否则你可能并没有这么一个服务接口。\n\n为了避免我们自己搭建GRaphQL服务接口，我们这里将会使用[GraphQLHub](http://www.graphqlhub.com/)。GraphQLHub是一个发展迅速的GraphQL现有API翻译的仓库，和HackerNews和Reddit很像，我会一直维护它:)\n\n本篇指南会带领你快速了解GraphQL基础语法，所以你并不需要提前学习它的内容。如果你对GraphQL很感兴趣，你可以阅读[Your First GraphQL Server](https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2)（译：我已经翻译过了，可以在本博客查找）。\n\n###Setting Up The Project\n\n在2015年，有大量的工具帮助你创建浏览器端javascript应用。我们选择使用[Webpack](https://webpack.github.io/)来打包我们的代码供浏览器解析，并使用[Babel](https://babeljs.io/)来编译我们的React和Relay代码。这些工具都是Relay小组推荐使用的，但你也可以选择使用其它的。\n\n我们不会关注太多Webpack和Babel的内容，毕竟我们的关注点在Relay。\n\n让我们创建一个新的项目：\n\n\t$ mkdir relay-101 && cd ./relay-101\n\t$ npm init\n\t# you can hit Enter a bunch of times\n\t\n这将会在你的文件夹中创建package.json文件，然后我们安装一些包：\n\n\t$ npm install webpack@1.12.2 webpack-dev-server@1.11.0 babel-core@5.8.25 babel-loader@5.3.2 --save\n\nWebpack会查找\"webpack.config.js\"文件，所以我们需要在当前目录下创建它：\n\n\t$ touch webpack.config.js\n\t\n并把下面的内容复制粘贴进去：\n\n\tvar path = require('path');\n\n\tmodule.exports = {\n  \t\tentry: path.resolve(__dirname, 'index.js'),\n  \t\tmodule: {\n    \t\tloaders: [\n      \t\t\t{\n        \t\t\ttest: /\\.js$/,\n        \t\t\tloader: 'babel',\n        \t\t\tquery: {stage: 0}\n      \t\t\t}\n    \t\t]\n  \t\t},\n  \t\toutput: {filename: 'index.bundle.js', path: './'}\n\t};\n\t\n你可能注意到了我们这里提到了一个index.js文件。目前我们创建一个简单的实现：\n\n\t$ echo 'alert(\"hello relay!\");' > index.js\n\t\n所有客户端的代码都会放在这个文件里，所以建议你在你的编辑器中保持打开它。\n\n我们还需要在package.json文件中加入“start”入口设定：\n\n\t{\n  \t\t// ...\n  \t\t\"scripts\": {\n    \t\t\"start\": \"./node_modules/.bin/webpack-dev-server\",\n    \t\t\"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  \t\t},\n\t}\n\t\n这么做是为了允许我们直接使用“npm start”来运行我们之前安装的webpack development server的。我们可以在我们的终端中瞄一眼：\n\n\t$ npm start\n\t> relay-101-test@1.0.0 start ~/relay-101\n\t> webpack-dev-server\n\n\thttp://localhost:8080/webpack-dev-server/\n\twebpack result is served from /\n\t\n浏览器中打开[http://localhost:8080/webpack-dev-server](http://localhost:8080/webpack-dev-server)，你会看到文件列表！这很好，但我们需要的是我们客户端的html页面。回到我们的项目文件夹，创建一个index.html并输入下面的内容：\n\n\t$ touch index.html\n\n\t# paste this inside of index.html\n\t<html>\n\t<head></head>\n\t<body>\n  \t\t<div id='container'>\n  \t\t</div>\n  \t\t<script src=\"/index.bundle.js\" charset=\"utf-8\"></script>\n\t</body>\n\t</html>\n\t\n刷新我们的开发服务器，将会看到一个期望的弹窗：\n\n![](https://cdn-images-1.medium.com/max/800/1*z-akwOi3BMk-NBVGT7pmag.png)\n\n现在我们就可以开始做一些好玩的事儿了。\n\n###Building A Static Component\n\n我们的小app将会模仿[Hacker News](https://news.ycombinator.com/)界面。开始之前，我们需要安装React和React-DOM包：\n\n\t$ npm install react@0.14.0-rc1 react-dom@0.14.0-rc1 --save\n\t\n注意我们这里指定了明确的版本号（如果将来你发现接口变更，请通知我）。回到index.js，删除我们原先的alert代码，开始实现我们的Item组件：\n\n\t// inside index.js\n\n\tlet React    = require('react');\n\tlet ReactDOM = require('react-dom');\n\n\tclass Item extends React.Component {\n  \t\trender() {\n    \t\tlet item = this.props.store.item;\n\n    \t\treturn (\n      \t\t\t<div>\n        \t\t\t<h1><a href={item.url}>{item.title}</a></h1>\n        \t\t\t<h2>{item.score} - {item.by.id}</h2>\n        \t\t\t<hr />\n      \t\t\t</div>\n    \t\t);\n  \t\t}\n\t};\n\n注意，我们所有的数据都来自于“store”属性--稍后我们会解释～\n\n让我们先在屏幕上伪造一些item：\n\n\t// at the bottom of index.js\n\n\tlet mountNode = document.getElementById('container');\n\tlet item = {\n  \t\tid  : '1337',\n  \t\turl : 'http://google.com',\n  \t\ttitle : 'Google',\n  \t\tscore : 100,\n  \t\tby : { id : 'clay '}\n\t};\n\tlet store = { item };\n\tlet rootComponent = <Item store={store} />;\n\tReactDOM.render(rootComponent, mountNode);\n\t\n刷新我们的开发服务器，你将会看到：\n\n![](https://cdn-images-1.medium.com/max/800/1*S4ZZYS8uOoXxm6LgJhKt8w.png)\n\n###Data From The Server\n\n是时候来加点Relay了。我们将会从GraphQLHub上根据ID获取一些itme数据来代替我们的静态数据。我们先来安装一些Relay包：\n\n\t$ npm install react-relay@0.3.2 babel-relay-plugin@0.2.5 sync-request@2.0.1 graphql@0.4.4 --save\n\t\n为什么我们安装了这么多东西而不仅仅是react-relay？好吧，目前Relay要求我们做的确实有点多--特别是，我们需要“babel-relay-plugin”来结合Babel。这个plugin会去GraphQLHub获取更多的Relay的配置。\n\n为了连接plugin，我们需要修改一下webpack.config.js中“query”选项：\n\n\tmodule.exports = {\n  \t\t// ...\n  \t\tmodule: {\n    \t\tloaders: [\n      \t\t\t{\n        \t\t\t// ...,\n        \t\t\t// note that this is different!\n        \t\t\tquery: {stage: 0, plugins: ['./babelRelayPlugin']}\n      \t\t\t}\n    \t\t]\n  \t\t}\n  \t\t// ...\n\t};\n\t\n这么做将会告诉Babel去加载一个叫babelRelayPlugin.js的文件。创建这个文件并放入下面的内容：\n\n\t$ touch babelRelayPlugin.js\n\n\t// inside that file\n\tvar babelRelayPlugin   = require('babel-relay-plugin');\n\tvar introspectionQuery = require('graphql/utilities').introspectionQuery;\n\tvar request            = require('sync-request');\n\n\tvar graphqlHubUrl = 'http://www.GraphQLHub.com/graphql';\n\tvar response = request('GET', graphqlHubUrl, {\n  \t\tqs: {\n    \t\tquery: introspectionQuery\n  \t\t}\n\t});\n\n\tvar schema = JSON.parse(response.body.toString('utf-8'));\n\n\tmodule.exports = babelRelayPlugin(schema.data, {\n  \t\tabortOnError: true,\n\t});\n\nCool--现在杀掉你的“npm start”进程并重启它。现在每次你重新打包你的app，它都会去GraphQLHub服务器（使用GraphQL优雅的自解释API）询问和预处理我们的Relay代码。\n\n回到index.js，是时候导入Relay啦：\n\n\tlet React    = require('react');\n\tlet ReactDOM = require('react-dom');\n\tlet Relay    = require('react-relay');\n\t\n接下来该做甚？我们将把我们的Item组件用[higher-order](https://medium.com/@dan_abramov/mixins-are-dead-long-live-higher-order-components-94a0d2f9e750#fd19)包装一下。这个新的组件将被Relay管理，这就是黑科技的地方：\n\n\tclass Item extends React.Component {\n  \t\t...\n\t}\n\tItem = Relay.createContainer(Item, {\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsAPI {\n        \t\t\titem(id: 8863) {\n          \t\t\t\ttitle,\n          \t\t\t\tscore,\n          \t\t\t\turl\n          \t\t\t\tby {\n            \t\t\t\tid\n          \t\t\t\t}\n        \t\t\t}\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n哒啦，搞定。翻译成大白话，上面的写法解释为：\n\n1. 嘿 Relay，我将把我的item组件作为原件放到新的组件容器中。\n \n2. 对于组件的“store”属性，我需要数据已经用GraphQL片段描述了。\n \n3. 我知道这些数据在http://graphqlhub.com/playground/hn的“HackerNewsAPI”对象中。\n\n注意这里我们只是描述了一个GraphQL片段（片段的概念很类似于查询中的别名），并不是最终获取所有数据的完整query。这是Relay的一个优点--组件只需要声明它需要的数据，而不用管如何获取数据。\n\n有些时候我们确实需要一个完整的GraphQL query，这就是Relay Routes的主场了。Relay.Route跟浏览器里的history或URLs半毛钱关系都木有--它是用来创建引导我们数据获取请求的“root query”的。\n\n嗖，让我们来搞一个Relay Route。在我们的Itme定义下面加入：\n\n\tItem = // ...;\n\n\tclass HackerNewsRoute extends Relay.Route {\n  \t\tstatic routeName = 'HackerNewsRoute';\n  \t\tstatic queries = {\n    \t\tstore: ((Component) => {\n      \t\t\t// 这里Component就是我们的Item组件\n      \t\t\treturn Relay.QL`\n      \t\t\t\tquery root {\n        \t\t\t\thn { ${Component.getFragment('store')} },\n      \t\t\t\t}\n    \t\t\t`}),\n  \t\t};\n\t}\n\t\n现在我们的GraphQL补全了root query。Relay允许我们使用ES6的字符串解析特性注入我们的片段，这就完成了组件分享（不同于复制）它的数据需求给父组件的过程。\n\n是时候展示点数据到屏幕上了！修改我们之前的代码如下：\n\n\tclass HackerNewsRoute {\n \t\t// ...\n\t}\n\n\tRelay.injectNetworkLayer(\n  \t\tnew Relay.DefaultNetworkLayer('http://www.GraphQLHub.com/graphql')\n\t);\n\n\tlet mountNode = document.getElementById('container');\n\tlet rootComponent = <Relay.RootContainer\n  \t\tComponent={Item}\n  \t\troute={new HackerNewsRoute()} />;\n\tReactDOM.render(rootComponent, mountNode);\n\n这里Relay.RootContainer是顶级组件，它构建了一个组件层级的query。我们还做了一些网络配置，最终渲染新的组件到DOM。你会在浏览器中看到下面的景象：\n\n![](https://cdn-images-1.medium.com/max/800/1*GOT3SozMFQCo3RcSiTMmcA.png)\n\n###A List Of Components\n\n我们下面开始做一个类似Hacker News首页的页面。相比硬编码一个特定的item，我们需要展示一个item列表。用Relay的话说，这需要我们创建一个新的list组件，其中嵌套多个独立的item组件（每个都请求自己的数据）。\n\n回到代码，我们开始创建我们的TopItems组件：\n\n\tclass TopItems extends React.Component {\n  \t\trender() {\n    \t\tlet items = this.props.store.topStories.map(\n      \t\t\t(store, idx) => <Item store={store} key={idx} />\n    \t\t);\n    \t\treturn <div>\n      \t\t\t{ items }\n    \t\t</div>;\n  \t\t}\n\t}\n\t\n我们就不再想刚才那样先“创建伪造数据”了，而是直接动真格的，用Relay封装TopItems：\n\n\tTopItems = Relay.createContainer(TopItems, {\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsAPI {\n        \t\t\ttopStories { ${Item.getFragment('store')} },\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n相比之前的单独item，现在我们需要请求“topStories”。针对每个item，GraphQL会根据声明的片段请求对应的数据，所以我们将只请求我们需要的数据。\n\n但是稍等--目前我们的item片段定义了一个特定的id（[#8863](https://news.ycombinator.com/item?id=8863)）。我们需要修改我们的query：\n\n\tItem = Relay.createContainer(Item, {\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsItem {\n        \t\t\tid\n        \t\t\ttitle,\n        \t\t\tscore,\n        \t\t\turl\n        \t\t\tby {\n          \t\t\t\tid\n        \t\t\t}\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n由于我们不再请求一个特定的item片段，所以我们需要修改在render函数中存取prop的方式：\n\n\tclass Item extends React.Component {\n  \t\trender() {\n    \t\tlet item = this.props.store;\n    \t\t// ...\n  \t\t}\n\t}\n\t\n最后，我们需要更新Relay RootContainer来使用我们的TopItems组件：\n\n\tlet rootComponent = <Relay.RootContainer\n  \t\tComponent={TopItems}\n  \t\troute={new HackerNewsRoute()} />;\n  \t\t\n瞧：\n\n![](https://cdn-images-1.medium.com/max/800/1*5r4OXLb20RzSJppF6zZVqg.png)\n\n\n###Variables in Queries\n\n现在我们对创建一个Relay app有了最基础的了解，但我希望展现Relay另一个特性：variables。\n\n在多数挨派派里，查询并不是一成不变的，我们经常需要请求不同的数据。Relay允许我们在GraphQL query中注入变量来达到这个目的。在我们这个小挨派派里，我们将添加一个开关来切换我们需要的数据类型（按照热度或时间等排序）。\n\n开始之前，我们需要修改我们的TopItems的query：\n\n\tTopItems = Relay.createContainer(TopItems, {\n  \t\tinitialVariables: {\n    \t\tstoryType: \"top\"\n  \t\t},\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsAPI {\n        \t\t\tstories(storyType: $storyType) { \n        \t\t\t\t${Item.getFragment('store')} \n        \t\t\t},\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n“$storyType”代表一个GraphQL变量（这并不是ES6的字符串解析语法）。我们通过initialVariables配置给它设置了一个初始默认值“top”。\n\n这只是Relay层面我们需要做的简单修改。我们并不需要对具体的组件做任何渲染或数据获取的修改--完全解耦了。\n\n现在我们需要编辑我们的TopItems组件来使用开关类型。更新render函数如下：\n\n\tclass TopItems extends React.Component {\n  \t\trender() {\n    \t\tlet items = this.props.store.stories.map(\n      \t\t\t(store, idx) => <Item store={store} key={idx} />\n    \t\t);\n    \t\tlet variables = this.props.relay.variables;\n\n    \t\t// To reduce the perceived lag\n    \t\t// There are less crude ways of doing this, but this works for now\n    \t\tlet currentStoryType = (this.state && this.state.storyType) || variables.storyType;\n\n    \t\treturn <div>\n      \t\t\t<select onChange={this._onChange.bind(this)} value={currentStoryType}>\n        \t\t\t<option value=\"top\">Top</option>\n        \t\t\t<option value=\"new\">New</option>\n        \t\t\t<option value=\"ask\">Ask HN</option>\n        \t\t\t<option value=\"show\">Show HN</option>\n      \t\t\t</select>\n      \t\t\t{ items }\n    \t\t</div>;\n  \t\t}\n\n  \t// to be continued\n\n这里有些新的知识点！我们使用了“Relay”prop，它包含一些特定的属性。任何使用Relay封装的组件都会被注入这个prop--如果我们想对我们的TopItems组件进行单元测试，我们需要自己注入一个伪造的对象。\n\n除此Relay变量之外，其它都是普通的React--我们创建一个下拉菜单，并给它一个默认值，并监听它的修改。当改变下拉菜单的选项，我们会告诉Relay去使用新的变量值，如下：\n\n\tclass TopItems extends React.Component {\n  \t\trender() {\n    \t\t// ...\n  \t\t}\n\n  \t\t_onChange(ev) {\n    \t\tlet storyType = ev.target.value;\n    \t\tthis.setState({ storyType });\n    \t\tthis.props.relay.setVariables({\n      \t\t\tstoryType\n    \t\t});\n  \t\t}\n\t}\n\t\n一切都很简答--Relay会察觉query的一部分发生了变化，并且根据需要重新去获取数据。为了简单，我们设置了组件的内部状态，\n\n刷新你的浏览器并且切换不同的下拉选项。你会发现，Relay并不会重复获取已经加载了的数据类型。\n\n![](https://cdn-images-1.medium.com/max/800/1*eTObnmhvdB4lFI7CPU3GQQ.png)\n\n###Relay 102\n\nSO，以上就是关于Relay的简单介绍。我们还没有涉及到mutations（用来完成更新服务端数据）和在获取数据时显示加载提醒。Relay非常的灵活，但代价是需要比我们这里提到的更多\n的配置。\n\nRelay可能并不是适合所有的挨派派和团队，但它在解决某些常见问题上确实令人非常激动。\n\n这篇文章中的源码放在[Github](https://github.com/clayallsopp/relay-101)，关注我[@clayallsopp](http://twitter.com/clayallsopp)和[@GraphQLHub](http://twitter.com/GraphQLHub)来获取更多的信息。\n\n\n###译者注\n\n看了不少相关资料，个人感觉，目前Relay+GraphQL相比react确实还有待社区的考量，并且它们确实还太新，官方也强调可能会出现比较大的变动。所以，目前用在实际项目里的风险确实较大，还是继续观望吧～纯属个人看法！","source":"_posts/[译]Relay101制作HackerNew客户端.md","raw":"title: ［译］Relay101制作HackerNew客户端\ndate: 2016-01-02 09:37:00\ntags:\n- react\n- GraphQL\n- Relay\ncategories: 前端\n---\n\n原文地址：[https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6](https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6)\n\n[React](https://facebook.github.io/react/)让我们可以使用javascrip创建用户界面组件；[Relay](https://facebook.github.io/relay/)则可以让我们很容易的打通react组件和远程服务器的数据通信。为了实现这个目标Relay需要一个条件--它假设客户端和服务器端必须满足某种要求，这可能增加了使用它的门槛，但对于一些项目来说这是非常值得的！\n<!--more-->\n没有Relay的日子，你需要自己实现数据的下载，传输，缓存。像Flux和Redux这类工具帮你避免了在这过程中的一些bug，但当大量数据来往于应用与服务器之间时还是有非常多的人为性错误存在的可能。Relay会减少非常多的通用样板代码，让客户端开发人员可以更简洁安全的获取他们想要的数据。\n\n按照之前Rails的十五分钟搭建blog的传统，我们这里将快速使用Relay搭建一个HAcker News客户端。教程假设你了解Node，NPM和react，没有其他要求了～\n\n###Getting GraphQL\n\n目前Relay需要你的服务器提供[GraphQL](https://facebook.github.io/graphql/)接口。GraphQL非常优雅，但除非你是facebook的工程师，否则你可能并没有这么一个服务接口。\n\n为了避免我们自己搭建GRaphQL服务接口，我们这里将会使用[GraphQLHub](http://www.graphqlhub.com/)。GraphQLHub是一个发展迅速的GraphQL现有API翻译的仓库，和HackerNews和Reddit很像，我会一直维护它:)\n\n本篇指南会带领你快速了解GraphQL基础语法，所以你并不需要提前学习它的内容。如果你对GraphQL很感兴趣，你可以阅读[Your First GraphQL Server](https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2)（译：我已经翻译过了，可以在本博客查找）。\n\n###Setting Up The Project\n\n在2015年，有大量的工具帮助你创建浏览器端javascript应用。我们选择使用[Webpack](https://webpack.github.io/)来打包我们的代码供浏览器解析，并使用[Babel](https://babeljs.io/)来编译我们的React和Relay代码。这些工具都是Relay小组推荐使用的，但你也可以选择使用其它的。\n\n我们不会关注太多Webpack和Babel的内容，毕竟我们的关注点在Relay。\n\n让我们创建一个新的项目：\n\n\t$ mkdir relay-101 && cd ./relay-101\n\t$ npm init\n\t# you can hit Enter a bunch of times\n\t\n这将会在你的文件夹中创建package.json文件，然后我们安装一些包：\n\n\t$ npm install webpack@1.12.2 webpack-dev-server@1.11.0 babel-core@5.8.25 babel-loader@5.3.2 --save\n\nWebpack会查找\"webpack.config.js\"文件，所以我们需要在当前目录下创建它：\n\n\t$ touch webpack.config.js\n\t\n并把下面的内容复制粘贴进去：\n\n\tvar path = require('path');\n\n\tmodule.exports = {\n  \t\tentry: path.resolve(__dirname, 'index.js'),\n  \t\tmodule: {\n    \t\tloaders: [\n      \t\t\t{\n        \t\t\ttest: /\\.js$/,\n        \t\t\tloader: 'babel',\n        \t\t\tquery: {stage: 0}\n      \t\t\t}\n    \t\t]\n  \t\t},\n  \t\toutput: {filename: 'index.bundle.js', path: './'}\n\t};\n\t\n你可能注意到了我们这里提到了一个index.js文件。目前我们创建一个简单的实现：\n\n\t$ echo 'alert(\"hello relay!\");' > index.js\n\t\n所有客户端的代码都会放在这个文件里，所以建议你在你的编辑器中保持打开它。\n\n我们还需要在package.json文件中加入“start”入口设定：\n\n\t{\n  \t\t// ...\n  \t\t\"scripts\": {\n    \t\t\"start\": \"./node_modules/.bin/webpack-dev-server\",\n    \t\t\"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  \t\t},\n\t}\n\t\n这么做是为了允许我们直接使用“npm start”来运行我们之前安装的webpack development server的。我们可以在我们的终端中瞄一眼：\n\n\t$ npm start\n\t> relay-101-test@1.0.0 start ~/relay-101\n\t> webpack-dev-server\n\n\thttp://localhost:8080/webpack-dev-server/\n\twebpack result is served from /\n\t\n浏览器中打开[http://localhost:8080/webpack-dev-server](http://localhost:8080/webpack-dev-server)，你会看到文件列表！这很好，但我们需要的是我们客户端的html页面。回到我们的项目文件夹，创建一个index.html并输入下面的内容：\n\n\t$ touch index.html\n\n\t# paste this inside of index.html\n\t<html>\n\t<head></head>\n\t<body>\n  \t\t<div id='container'>\n  \t\t</div>\n  \t\t<script src=\"/index.bundle.js\" charset=\"utf-8\"></script>\n\t</body>\n\t</html>\n\t\n刷新我们的开发服务器，将会看到一个期望的弹窗：\n\n![](https://cdn-images-1.medium.com/max/800/1*z-akwOi3BMk-NBVGT7pmag.png)\n\n现在我们就可以开始做一些好玩的事儿了。\n\n###Building A Static Component\n\n我们的小app将会模仿[Hacker News](https://news.ycombinator.com/)界面。开始之前，我们需要安装React和React-DOM包：\n\n\t$ npm install react@0.14.0-rc1 react-dom@0.14.0-rc1 --save\n\t\n注意我们这里指定了明确的版本号（如果将来你发现接口变更，请通知我）。回到index.js，删除我们原先的alert代码，开始实现我们的Item组件：\n\n\t// inside index.js\n\n\tlet React    = require('react');\n\tlet ReactDOM = require('react-dom');\n\n\tclass Item extends React.Component {\n  \t\trender() {\n    \t\tlet item = this.props.store.item;\n\n    \t\treturn (\n      \t\t\t<div>\n        \t\t\t<h1><a href={item.url}>{item.title}</a></h1>\n        \t\t\t<h2>{item.score} - {item.by.id}</h2>\n        \t\t\t<hr />\n      \t\t\t</div>\n    \t\t);\n  \t\t}\n\t};\n\n注意，我们所有的数据都来自于“store”属性--稍后我们会解释～\n\n让我们先在屏幕上伪造一些item：\n\n\t// at the bottom of index.js\n\n\tlet mountNode = document.getElementById('container');\n\tlet item = {\n  \t\tid  : '1337',\n  \t\turl : 'http://google.com',\n  \t\ttitle : 'Google',\n  \t\tscore : 100,\n  \t\tby : { id : 'clay '}\n\t};\n\tlet store = { item };\n\tlet rootComponent = <Item store={store} />;\n\tReactDOM.render(rootComponent, mountNode);\n\t\n刷新我们的开发服务器，你将会看到：\n\n![](https://cdn-images-1.medium.com/max/800/1*S4ZZYS8uOoXxm6LgJhKt8w.png)\n\n###Data From The Server\n\n是时候来加点Relay了。我们将会从GraphQLHub上根据ID获取一些itme数据来代替我们的静态数据。我们先来安装一些Relay包：\n\n\t$ npm install react-relay@0.3.2 babel-relay-plugin@0.2.5 sync-request@2.0.1 graphql@0.4.4 --save\n\t\n为什么我们安装了这么多东西而不仅仅是react-relay？好吧，目前Relay要求我们做的确实有点多--特别是，我们需要“babel-relay-plugin”来结合Babel。这个plugin会去GraphQLHub获取更多的Relay的配置。\n\n为了连接plugin，我们需要修改一下webpack.config.js中“query”选项：\n\n\tmodule.exports = {\n  \t\t// ...\n  \t\tmodule: {\n    \t\tloaders: [\n      \t\t\t{\n        \t\t\t// ...,\n        \t\t\t// note that this is different!\n        \t\t\tquery: {stage: 0, plugins: ['./babelRelayPlugin']}\n      \t\t\t}\n    \t\t]\n  \t\t}\n  \t\t// ...\n\t};\n\t\n这么做将会告诉Babel去加载一个叫babelRelayPlugin.js的文件。创建这个文件并放入下面的内容：\n\n\t$ touch babelRelayPlugin.js\n\n\t// inside that file\n\tvar babelRelayPlugin   = require('babel-relay-plugin');\n\tvar introspectionQuery = require('graphql/utilities').introspectionQuery;\n\tvar request            = require('sync-request');\n\n\tvar graphqlHubUrl = 'http://www.GraphQLHub.com/graphql';\n\tvar response = request('GET', graphqlHubUrl, {\n  \t\tqs: {\n    \t\tquery: introspectionQuery\n  \t\t}\n\t});\n\n\tvar schema = JSON.parse(response.body.toString('utf-8'));\n\n\tmodule.exports = babelRelayPlugin(schema.data, {\n  \t\tabortOnError: true,\n\t});\n\nCool--现在杀掉你的“npm start”进程并重启它。现在每次你重新打包你的app，它都会去GraphQLHub服务器（使用GraphQL优雅的自解释API）询问和预处理我们的Relay代码。\n\n回到index.js，是时候导入Relay啦：\n\n\tlet React    = require('react');\n\tlet ReactDOM = require('react-dom');\n\tlet Relay    = require('react-relay');\n\t\n接下来该做甚？我们将把我们的Item组件用[higher-order](https://medium.com/@dan_abramov/mixins-are-dead-long-live-higher-order-components-94a0d2f9e750#fd19)包装一下。这个新的组件将被Relay管理，这就是黑科技的地方：\n\n\tclass Item extends React.Component {\n  \t\t...\n\t}\n\tItem = Relay.createContainer(Item, {\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsAPI {\n        \t\t\titem(id: 8863) {\n          \t\t\t\ttitle,\n          \t\t\t\tscore,\n          \t\t\t\turl\n          \t\t\t\tby {\n            \t\t\t\tid\n          \t\t\t\t}\n        \t\t\t}\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n哒啦，搞定。翻译成大白话，上面的写法解释为：\n\n1. 嘿 Relay，我将把我的item组件作为原件放到新的组件容器中。\n \n2. 对于组件的“store”属性，我需要数据已经用GraphQL片段描述了。\n \n3. 我知道这些数据在http://graphqlhub.com/playground/hn的“HackerNewsAPI”对象中。\n\n注意这里我们只是描述了一个GraphQL片段（片段的概念很类似于查询中的别名），并不是最终获取所有数据的完整query。这是Relay的一个优点--组件只需要声明它需要的数据，而不用管如何获取数据。\n\n有些时候我们确实需要一个完整的GraphQL query，这就是Relay Routes的主场了。Relay.Route跟浏览器里的history或URLs半毛钱关系都木有--它是用来创建引导我们数据获取请求的“root query”的。\n\n嗖，让我们来搞一个Relay Route。在我们的Itme定义下面加入：\n\n\tItem = // ...;\n\n\tclass HackerNewsRoute extends Relay.Route {\n  \t\tstatic routeName = 'HackerNewsRoute';\n  \t\tstatic queries = {\n    \t\tstore: ((Component) => {\n      \t\t\t// 这里Component就是我们的Item组件\n      \t\t\treturn Relay.QL`\n      \t\t\t\tquery root {\n        \t\t\t\thn { ${Component.getFragment('store')} },\n      \t\t\t\t}\n    \t\t\t`}),\n  \t\t};\n\t}\n\t\n现在我们的GraphQL补全了root query。Relay允许我们使用ES6的字符串解析特性注入我们的片段，这就完成了组件分享（不同于复制）它的数据需求给父组件的过程。\n\n是时候展示点数据到屏幕上了！修改我们之前的代码如下：\n\n\tclass HackerNewsRoute {\n \t\t// ...\n\t}\n\n\tRelay.injectNetworkLayer(\n  \t\tnew Relay.DefaultNetworkLayer('http://www.GraphQLHub.com/graphql')\n\t);\n\n\tlet mountNode = document.getElementById('container');\n\tlet rootComponent = <Relay.RootContainer\n  \t\tComponent={Item}\n  \t\troute={new HackerNewsRoute()} />;\n\tReactDOM.render(rootComponent, mountNode);\n\n这里Relay.RootContainer是顶级组件，它构建了一个组件层级的query。我们还做了一些网络配置，最终渲染新的组件到DOM。你会在浏览器中看到下面的景象：\n\n![](https://cdn-images-1.medium.com/max/800/1*GOT3SozMFQCo3RcSiTMmcA.png)\n\n###A List Of Components\n\n我们下面开始做一个类似Hacker News首页的页面。相比硬编码一个特定的item，我们需要展示一个item列表。用Relay的话说，这需要我们创建一个新的list组件，其中嵌套多个独立的item组件（每个都请求自己的数据）。\n\n回到代码，我们开始创建我们的TopItems组件：\n\n\tclass TopItems extends React.Component {\n  \t\trender() {\n    \t\tlet items = this.props.store.topStories.map(\n      \t\t\t(store, idx) => <Item store={store} key={idx} />\n    \t\t);\n    \t\treturn <div>\n      \t\t\t{ items }\n    \t\t</div>;\n  \t\t}\n\t}\n\t\n我们就不再想刚才那样先“创建伪造数据”了，而是直接动真格的，用Relay封装TopItems：\n\n\tTopItems = Relay.createContainer(TopItems, {\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsAPI {\n        \t\t\ttopStories { ${Item.getFragment('store')} },\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n相比之前的单独item，现在我们需要请求“topStories”。针对每个item，GraphQL会根据声明的片段请求对应的数据，所以我们将只请求我们需要的数据。\n\n但是稍等--目前我们的item片段定义了一个特定的id（[#8863](https://news.ycombinator.com/item?id=8863)）。我们需要修改我们的query：\n\n\tItem = Relay.createContainer(Item, {\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsItem {\n        \t\t\tid\n        \t\t\ttitle,\n        \t\t\tscore,\n        \t\t\turl\n        \t\t\tby {\n          \t\t\t\tid\n        \t\t\t}\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n由于我们不再请求一个特定的item片段，所以我们需要修改在render函数中存取prop的方式：\n\n\tclass Item extends React.Component {\n  \t\trender() {\n    \t\tlet item = this.props.store;\n    \t\t// ...\n  \t\t}\n\t}\n\t\n最后，我们需要更新Relay RootContainer来使用我们的TopItems组件：\n\n\tlet rootComponent = <Relay.RootContainer\n  \t\tComponent={TopItems}\n  \t\troute={new HackerNewsRoute()} />;\n  \t\t\n瞧：\n\n![](https://cdn-images-1.medium.com/max/800/1*5r4OXLb20RzSJppF6zZVqg.png)\n\n\n###Variables in Queries\n\n现在我们对创建一个Relay app有了最基础的了解，但我希望展现Relay另一个特性：variables。\n\n在多数挨派派里，查询并不是一成不变的，我们经常需要请求不同的数据。Relay允许我们在GraphQL query中注入变量来达到这个目的。在我们这个小挨派派里，我们将添加一个开关来切换我们需要的数据类型（按照热度或时间等排序）。\n\n开始之前，我们需要修改我们的TopItems的query：\n\n\tTopItems = Relay.createContainer(TopItems, {\n  \t\tinitialVariables: {\n    \t\tstoryType: \"top\"\n  \t\t},\n  \t\tfragments: {\n    \t\tstore: () => Relay.QL`\n      \t\t\tfragment on HackerNewsAPI {\n        \t\t\tstories(storyType: $storyType) { \n        \t\t\t\t${Item.getFragment('store')} \n        \t\t\t},\n      \t\t\t}\n    \t\t`,\n  \t\t},\n\t});\n\t\n“$storyType”代表一个GraphQL变量（这并不是ES6的字符串解析语法）。我们通过initialVariables配置给它设置了一个初始默认值“top”。\n\n这只是Relay层面我们需要做的简单修改。我们并不需要对具体的组件做任何渲染或数据获取的修改--完全解耦了。\n\n现在我们需要编辑我们的TopItems组件来使用开关类型。更新render函数如下：\n\n\tclass TopItems extends React.Component {\n  \t\trender() {\n    \t\tlet items = this.props.store.stories.map(\n      \t\t\t(store, idx) => <Item store={store} key={idx} />\n    \t\t);\n    \t\tlet variables = this.props.relay.variables;\n\n    \t\t// To reduce the perceived lag\n    \t\t// There are less crude ways of doing this, but this works for now\n    \t\tlet currentStoryType = (this.state && this.state.storyType) || variables.storyType;\n\n    \t\treturn <div>\n      \t\t\t<select onChange={this._onChange.bind(this)} value={currentStoryType}>\n        \t\t\t<option value=\"top\">Top</option>\n        \t\t\t<option value=\"new\">New</option>\n        \t\t\t<option value=\"ask\">Ask HN</option>\n        \t\t\t<option value=\"show\">Show HN</option>\n      \t\t\t</select>\n      \t\t\t{ items }\n    \t\t</div>;\n  \t\t}\n\n  \t// to be continued\n\n这里有些新的知识点！我们使用了“Relay”prop，它包含一些特定的属性。任何使用Relay封装的组件都会被注入这个prop--如果我们想对我们的TopItems组件进行单元测试，我们需要自己注入一个伪造的对象。\n\n除此Relay变量之外，其它都是普通的React--我们创建一个下拉菜单，并给它一个默认值，并监听它的修改。当改变下拉菜单的选项，我们会告诉Relay去使用新的变量值，如下：\n\n\tclass TopItems extends React.Component {\n  \t\trender() {\n    \t\t// ...\n  \t\t}\n\n  \t\t_onChange(ev) {\n    \t\tlet storyType = ev.target.value;\n    \t\tthis.setState({ storyType });\n    \t\tthis.props.relay.setVariables({\n      \t\t\tstoryType\n    \t\t});\n  \t\t}\n\t}\n\t\n一切都很简答--Relay会察觉query的一部分发生了变化，并且根据需要重新去获取数据。为了简单，我们设置了组件的内部状态，\n\n刷新你的浏览器并且切换不同的下拉选项。你会发现，Relay并不会重复获取已经加载了的数据类型。\n\n![](https://cdn-images-1.medium.com/max/800/1*eTObnmhvdB4lFI7CPU3GQQ.png)\n\n###Relay 102\n\nSO，以上就是关于Relay的简单介绍。我们还没有涉及到mutations（用来完成更新服务端数据）和在获取数据时显示加载提醒。Relay非常的灵活，但代价是需要比我们这里提到的更多\n的配置。\n\nRelay可能并不是适合所有的挨派派和团队，但它在解决某些常见问题上确实令人非常激动。\n\n这篇文章中的源码放在[Github](https://github.com/clayallsopp/relay-101)，关注我[@clayallsopp](http://twitter.com/clayallsopp)和[@GraphQLHub](http://twitter.com/GraphQLHub)来获取更多的信息。\n\n\n###译者注\n\n看了不少相关资料，个人感觉，目前Relay+GraphQL相比react确实还有待社区的考量，并且它们确实还太新，官方也强调可能会出现比较大的变动。所以，目前用在实际项目里的风险确实较大，还是继续观望吧～纯属个人看法！","slug":"[译]Relay101制作HackerNew客户端","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"ciizs3p5d000034wspgrg1xcc","comments":1,"layout":"post","photos":[],"link":"","content":"<p>原文地址：<a href=\"https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6\" target=\"_blank\" rel=\"external\">https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6</a></p>\n<p><a href=\"https://facebook.github.io/react/\" target=\"_blank\" rel=\"external\">React</a>让我们可以使用javascrip创建用户界面组件；<a href=\"https://facebook.github.io/relay/\" target=\"_blank\" rel=\"external\">Relay</a>则可以让我们很容易的打通react组件和远程服务器的数据通信。为了实现这个目标Relay需要一个条件–它假设客户端和服务器端必须满足某种要求，这可能增加了使用它的门槛，但对于一些项目来说这是非常值得的！<br><a id=\"more\"></a><br>没有Relay的日子，你需要自己实现数据的下载，传输，缓存。像Flux和Redux这类工具帮你避免了在这过程中的一些bug，但当大量数据来往于应用与服务器之间时还是有非常多的人为性错误存在的可能。Relay会减少非常多的通用样板代码，让客户端开发人员可以更简洁安全的获取他们想要的数据。</p>\n<p>按照之前Rails的十五分钟搭建blog的传统，我们这里将快速使用Relay搭建一个HAcker News客户端。教程假设你了解Node，NPM和react，没有其他要求了～</p>\n<p>###Getting GraphQL</p>\n<p>目前Relay需要你的服务器提供<a href=\"https://facebook.github.io/graphql/\" target=\"_blank\" rel=\"external\">GraphQL</a>接口。GraphQL非常优雅，但除非你是facebook的工程师，否则你可能并没有这么一个服务接口。</p>\n<p>为了避免我们自己搭建GRaphQL服务接口，我们这里将会使用<a href=\"http://www.graphqlhub.com/\" target=\"_blank\" rel=\"external\">GraphQLHub</a>。GraphQLHub是一个发展迅速的GraphQL现有API翻译的仓库，和HackerNews和Reddit很像，我会一直维护它:)</p>\n<p>本篇指南会带领你快速了解GraphQL基础语法，所以你并不需要提前学习它的内容。如果你对GraphQL很感兴趣，你可以阅读<a href=\"https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2\" target=\"_blank\" rel=\"external\">Your First GraphQL Server</a>（译：我已经翻译过了，可以在本博客查找）。</p>\n<p>###Setting Up The Project</p>\n<p>在2015年，有大量的工具帮助你创建浏览器端javascript应用。我们选择使用<a href=\"https://webpack.github.io/\" target=\"_blank\" rel=\"external\">Webpack</a>来打包我们的代码供浏览器解析，并使用<a href=\"https://babeljs.io/\" target=\"_blank\" rel=\"external\">Babel</a>来编译我们的React和Relay代码。这些工具都是Relay小组推荐使用的，但你也可以选择使用其它的。</p>\n<p>我们不会关注太多Webpack和Babel的内容，毕竟我们的关注点在Relay。</p>\n<p>让我们创建一个新的项目：</p>\n<pre><code>$ mkdir relay-101 &amp;&amp; cd ./relay-101\n$ npm init\n# you can hit Enter a bunch of times\n</code></pre><p>这将会在你的文件夹中创建package.json文件，然后我们安装一些包：</p>\n<pre><code>$ npm install webpack@1.12.2 webpack-dev-server@1.11.0 babel-core@5.8.25 babel-loader@5.3.2 --save\n</code></pre><p>Webpack会查找”webpack.config.js”文件，所以我们需要在当前目录下创建它：</p>\n<pre><code>$ touch webpack.config.js\n</code></pre><p>并把下面的内容复制粘贴进去：</p>\n<pre><code>var path = require(&apos;path&apos;);\n\nmodule.exports = {\n      entry: path.resolve(__dirname, &apos;index.js&apos;),\n      module: {\n        loaders: [\n              {\n                test: /\\.js$/,\n                loader: &apos;babel&apos;,\n                query: {stage: 0}\n              }\n        ]\n      },\n      output: {filename: &apos;index.bundle.js&apos;, path: &apos;./&apos;}\n};\n</code></pre><p>你可能注意到了我们这里提到了一个index.js文件。目前我们创建一个简单的实现：</p>\n<pre><code>$ echo &apos;alert(&quot;hello relay!&quot;);&apos; &gt; index.js\n</code></pre><p>所有客户端的代码都会放在这个文件里，所以建议你在你的编辑器中保持打开它。</p>\n<p>我们还需要在package.json文件中加入“start”入口设定：</p>\n<pre><code>{\n      // ...\n      &quot;scripts&quot;: {\n        &quot;start&quot;: &quot;./node_modules/.bin/webpack-dev-server&quot;,\n        &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;\n      },\n}\n</code></pre><p>这么做是为了允许我们直接使用“npm start”来运行我们之前安装的webpack development server的。我们可以在我们的终端中瞄一眼：</p>\n<pre><code>$ npm start\n&gt; relay-101-test@1.0.0 start ~/relay-101\n&gt; webpack-dev-server\n\nhttp://localhost:8080/webpack-dev-server/\nwebpack result is served from /\n</code></pre><p>浏览器中打开<a href=\"http://localhost:8080/webpack-dev-server\" target=\"_blank\" rel=\"external\">http://localhost:8080/webpack-dev-server</a>，你会看到文件列表！这很好，但我们需要的是我们客户端的html页面。回到我们的项目文件夹，创建一个index.html并输入下面的内容：</p>\n<pre><code>$ touch index.html\n\n# paste this inside of index.html\n&lt;html&gt;\n&lt;head&gt;&lt;/head&gt;\n&lt;body&gt;\n      &lt;div id=&apos;container&apos;&gt;\n      &lt;/div&gt;\n      &lt;script src=&quot;/index.bundle.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>刷新我们的开发服务器，将会看到一个期望的弹窗：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*z-akwOi3BMk-NBVGT7pmag.png\" alt=\"\"></p>\n<p>现在我们就可以开始做一些好玩的事儿了。</p>\n<p>###Building A Static Component</p>\n<p>我们的小app将会模仿<a href=\"https://news.ycombinator.com/\" target=\"_blank\" rel=\"external\">Hacker News</a>界面。开始之前，我们需要安装React和React-DOM包：</p>\n<pre><code>$ npm install react@0.14.0-rc1 react-dom@0.14.0-rc1 --save\n</code></pre><p>注意我们这里指定了明确的版本号（如果将来你发现接口变更，请通知我）。回到index.js，删除我们原先的alert代码，开始实现我们的Item组件：</p>\n<pre><code>// inside index.js\n\nlet React    = require(&apos;react&apos;);\nlet ReactDOM = require(&apos;react-dom&apos;);\n\nclass Item extends React.Component {\n      render() {\n        let item = this.props.store.item;\n\n        return (\n              &lt;div&gt;\n                &lt;h1&gt;&lt;a href={item.url}&gt;{item.title}&lt;/a&gt;&lt;/h1&gt;\n                &lt;h2&gt;{item.score} - {item.by.id}&lt;/h2&gt;\n                &lt;hr /&gt;\n              &lt;/div&gt;\n        );\n      }\n};\n</code></pre><p>注意，我们所有的数据都来自于“store”属性–稍后我们会解释～</p>\n<p>让我们先在屏幕上伪造一些item：</p>\n<pre><code>// at the bottom of index.js\n\nlet mountNode = document.getElementById(&apos;container&apos;);\nlet item = {\n      id  : &apos;1337&apos;,\n      url : &apos;http://google.com&apos;,\n      title : &apos;Google&apos;,\n      score : 100,\n      by : { id : &apos;clay &apos;}\n};\nlet store = { item };\nlet rootComponent = &lt;Item store={store} /&gt;;\nReactDOM.render(rootComponent, mountNode);\n</code></pre><p>刷新我们的开发服务器，你将会看到：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*S4ZZYS8uOoXxm6LgJhKt8w.png\" alt=\"\"></p>\n<p>###Data From The Server</p>\n<p>是时候来加点Relay了。我们将会从GraphQLHub上根据ID获取一些itme数据来代替我们的静态数据。我们先来安装一些Relay包：</p>\n<pre><code>$ npm install react-relay@0.3.2 babel-relay-plugin@0.2.5 sync-request@2.0.1 graphql@0.4.4 --save\n</code></pre><p>为什么我们安装了这么多东西而不仅仅是react-relay？好吧，目前Relay要求我们做的确实有点多–特别是，我们需要“babel-relay-plugin”来结合Babel。这个plugin会去GraphQLHub获取更多的Relay的配置。</p>\n<p>为了连接plugin，我们需要修改一下webpack.config.js中“query”选项：</p>\n<pre><code>module.exports = {\n      // ...\n      module: {\n        loaders: [\n              {\n                // ...,\n                // note that this is different!\n                query: {stage: 0, plugins: [&apos;./babelRelayPlugin&apos;]}\n              }\n        ]\n      }\n      // ...\n};\n</code></pre><p>这么做将会告诉Babel去加载一个叫babelRelayPlugin.js的文件。创建这个文件并放入下面的内容：</p>\n<pre><code>$ touch babelRelayPlugin.js\n\n// inside that file\nvar babelRelayPlugin   = require(&apos;babel-relay-plugin&apos;);\nvar introspectionQuery = require(&apos;graphql/utilities&apos;).introspectionQuery;\nvar request            = require(&apos;sync-request&apos;);\n\nvar graphqlHubUrl = &apos;http://www.GraphQLHub.com/graphql&apos;;\nvar response = request(&apos;GET&apos;, graphqlHubUrl, {\n      qs: {\n        query: introspectionQuery\n      }\n});\n\nvar schema = JSON.parse(response.body.toString(&apos;utf-8&apos;));\n\nmodule.exports = babelRelayPlugin(schema.data, {\n      abortOnError: true,\n});\n</code></pre><p>Cool–现在杀掉你的“npm start”进程并重启它。现在每次你重新打包你的app，它都会去GraphQLHub服务器（使用GraphQL优雅的自解释API）询问和预处理我们的Relay代码。</p>\n<p>回到index.js，是时候导入Relay啦：</p>\n<pre><code>let React    = require(&apos;react&apos;);\nlet ReactDOM = require(&apos;react-dom&apos;);\nlet Relay    = require(&apos;react-relay&apos;);\n</code></pre><p>接下来该做甚？我们将把我们的Item组件用<a href=\"https://medium.com/@dan_abramov/mixins-are-dead-long-live-higher-order-components-94a0d2f9e750#fd19\" target=\"_blank\" rel=\"external\">higher-order</a>包装一下。这个新的组件将被Relay管理，这就是黑科技的地方：</p>\n<pre><code>class Item extends React.Component {\n      ...\n}\nItem = Relay.createContainer(Item, {\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsAPI {\n                item(id: 8863) {\n                      title,\n                      score,\n                      url\n                      by {\n                        id\n                      }\n                }\n              }\n        `,\n      },\n});\n</code></pre><p>哒啦，搞定。翻译成大白话，上面的写法解释为：</p>\n<ol>\n<li><p>嘿 Relay，我将把我的item组件作为原件放到新的组件容器中。</p>\n</li>\n<li><p>对于组件的“store”属性，我需要数据已经用GraphQL片段描述了。</p>\n</li>\n<li><p>我知道这些数据在<a href=\"http://graphqlhub.com/playground/hn的“HackerNewsAPI”对象中。\" target=\"_blank\" rel=\"external\">http://graphqlhub.com/playground/hn的“HackerNewsAPI”对象中。</a></p>\n</li>\n</ol>\n<p>注意这里我们只是描述了一个GraphQL片段（片段的概念很类似于查询中的别名），并不是最终获取所有数据的完整query。这是Relay的一个优点–组件只需要声明它需要的数据，而不用管如何获取数据。</p>\n<p>有些时候我们确实需要一个完整的GraphQL query，这就是Relay Routes的主场了。Relay.Route跟浏览器里的history或URLs半毛钱关系都木有–它是用来创建引导我们数据获取请求的“root query”的。</p>\n<p>嗖，让我们来搞一个Relay Route。在我们的Itme定义下面加入：</p>\n<pre><code>Item = // ...;\n\nclass HackerNewsRoute extends Relay.Route {\n      static routeName = &apos;HackerNewsRoute&apos;;\n      static queries = {\n        store: ((Component) =&gt; {\n              // 这里Component就是我们的Item组件\n              return Relay.QL`\n                  query root {\n                    hn { ${Component.getFragment(&apos;store&apos;)} },\n                  }\n            `}),\n      };\n}\n</code></pre><p>现在我们的GraphQL补全了root query。Relay允许我们使用ES6的字符串解析特性注入我们的片段，这就完成了组件分享（不同于复制）它的数据需求给父组件的过程。</p>\n<p>是时候展示点数据到屏幕上了！修改我们之前的代码如下：</p>\n<pre><code>class HackerNewsRoute {\n     // ...\n}\n\nRelay.injectNetworkLayer(\n      new Relay.DefaultNetworkLayer(&apos;http://www.GraphQLHub.com/graphql&apos;)\n);\n\nlet mountNode = document.getElementById(&apos;container&apos;);\nlet rootComponent = &lt;Relay.RootContainer\n      Component={Item}\n      route={new HackerNewsRoute()} /&gt;;\nReactDOM.render(rootComponent, mountNode);\n</code></pre><p>这里Relay.RootContainer是顶级组件，它构建了一个组件层级的query。我们还做了一些网络配置，最终渲染新的组件到DOM。你会在浏览器中看到下面的景象：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*GOT3SozMFQCo3RcSiTMmcA.png\" alt=\"\"></p>\n<p>###A List Of Components</p>\n<p>我们下面开始做一个类似Hacker News首页的页面。相比硬编码一个特定的item，我们需要展示一个item列表。用Relay的话说，这需要我们创建一个新的list组件，其中嵌套多个独立的item组件（每个都请求自己的数据）。</p>\n<p>回到代码，我们开始创建我们的TopItems组件：</p>\n<pre><code>class TopItems extends React.Component {\n      render() {\n        let items = this.props.store.topStories.map(\n              (store, idx) =&gt; &lt;Item store={store} key={idx} /&gt;\n        );\n        return &lt;div&gt;\n              { items }\n        &lt;/div&gt;;\n      }\n}\n</code></pre><p>我们就不再想刚才那样先“创建伪造数据”了，而是直接动真格的，用Relay封装TopItems：</p>\n<pre><code>TopItems = Relay.createContainer(TopItems, {\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsAPI {\n                topStories { ${Item.getFragment(&apos;store&apos;)} },\n              }\n        `,\n      },\n});\n</code></pre><p>相比之前的单独item，现在我们需要请求“topStories”。针对每个item，GraphQL会根据声明的片段请求对应的数据，所以我们将只请求我们需要的数据。</p>\n<p>但是稍等–目前我们的item片段定义了一个特定的id（<a href=\"https://news.ycombinator.com/item?id=8863\" target=\"_blank\" rel=\"external\">#8863</a>）。我们需要修改我们的query：</p>\n<pre><code>Item = Relay.createContainer(Item, {\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsItem {\n                id\n                title,\n                score,\n                url\n                by {\n                      id\n                }\n              }\n        `,\n      },\n});\n</code></pre><p>由于我们不再请求一个特定的item片段，所以我们需要修改在render函数中存取prop的方式：</p>\n<pre><code>class Item extends React.Component {\n      render() {\n        let item = this.props.store;\n        // ...\n      }\n}\n</code></pre><p>最后，我们需要更新Relay RootContainer来使用我们的TopItems组件：</p>\n<pre><code>let rootComponent = &lt;Relay.RootContainer\n      Component={TopItems}\n      route={new HackerNewsRoute()} /&gt;;\n</code></pre><p>瞧：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*5r4OXLb20RzSJppF6zZVqg.png\" alt=\"\"></p>\n<p>###Variables in Queries</p>\n<p>现在我们对创建一个Relay app有了最基础的了解，但我希望展现Relay另一个特性：variables。</p>\n<p>在多数挨派派里，查询并不是一成不变的，我们经常需要请求不同的数据。Relay允许我们在GraphQL query中注入变量来达到这个目的。在我们这个小挨派派里，我们将添加一个开关来切换我们需要的数据类型（按照热度或时间等排序）。</p>\n<p>开始之前，我们需要修改我们的TopItems的query：</p>\n<pre><code>TopItems = Relay.createContainer(TopItems, {\n      initialVariables: {\n        storyType: &quot;top&quot;\n      },\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsAPI {\n                stories(storyType: $storyType) { \n                    ${Item.getFragment(&apos;store&apos;)} \n                },\n              }\n        `,\n      },\n});\n</code></pre><p>“$storyType”代表一个GraphQL变量（这并不是ES6的字符串解析语法）。我们通过initialVariables配置给它设置了一个初始默认值“top”。</p>\n<p>这只是Relay层面我们需要做的简单修改。我们并不需要对具体的组件做任何渲染或数据获取的修改–完全解耦了。</p>\n<p>现在我们需要编辑我们的TopItems组件来使用开关类型。更新render函数如下：</p>\n<pre><code>class TopItems extends React.Component {\n      render() {\n        let items = this.props.store.stories.map(\n              (store, idx) =&gt; &lt;Item store={store} key={idx} /&gt;\n        );\n        let variables = this.props.relay.variables;\n\n        // To reduce the perceived lag\n        // There are less crude ways of doing this, but this works for now\n        let currentStoryType = (this.state &amp;&amp; this.state.storyType) || variables.storyType;\n\n        return &lt;div&gt;\n              &lt;select onChange={this._onChange.bind(this)} value={currentStoryType}&gt;\n                &lt;option value=&quot;top&quot;&gt;Top&lt;/option&gt;\n                &lt;option value=&quot;new&quot;&gt;New&lt;/option&gt;\n                &lt;option value=&quot;ask&quot;&gt;Ask HN&lt;/option&gt;\n                &lt;option value=&quot;show&quot;&gt;Show HN&lt;/option&gt;\n              &lt;/select&gt;\n              { items }\n        &lt;/div&gt;;\n      }\n\n  // to be continued\n</code></pre><p>这里有些新的知识点！我们使用了“Relay”prop，它包含一些特定的属性。任何使用Relay封装的组件都会被注入这个prop–如果我们想对我们的TopItems组件进行单元测试，我们需要自己注入一个伪造的对象。</p>\n<p>除此Relay变量之外，其它都是普通的React–我们创建一个下拉菜单，并给它一个默认值，并监听它的修改。当改变下拉菜单的选项，我们会告诉Relay去使用新的变量值，如下：</p>\n<pre><code>class TopItems extends React.Component {\n      render() {\n        // ...\n      }\n\n      _onChange(ev) {\n        let storyType = ev.target.value;\n        this.setState({ storyType });\n        this.props.relay.setVariables({\n              storyType\n        });\n      }\n}\n</code></pre><p>一切都很简答–Relay会察觉query的一部分发生了变化，并且根据需要重新去获取数据。为了简单，我们设置了组件的内部状态，</p>\n<p>刷新你的浏览器并且切换不同的下拉选项。你会发现，Relay并不会重复获取已经加载了的数据类型。</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*eTObnmhvdB4lFI7CPU3GQQ.png\" alt=\"\"></p>\n<p>###Relay 102</p>\n<p>SO，以上就是关于Relay的简单介绍。我们还没有涉及到mutations（用来完成更新服务端数据）和在获取数据时显示加载提醒。Relay非常的灵活，但代价是需要比我们这里提到的更多<br>的配置。</p>\n<p>Relay可能并不是适合所有的挨派派和团队，但它在解决某些常见问题上确实令人非常激动。</p>\n<p>这篇文章中的源码放在<a href=\"https://github.com/clayallsopp/relay-101\" target=\"_blank\" rel=\"external\">Github</a>，关注我<a href=\"http://twitter.com/clayallsopp\" target=\"_blank\" rel=\"external\">@clayallsopp</a>和<a href=\"http://twitter.com/GraphQLHub\" target=\"_blank\" rel=\"external\">@GraphQLHub</a>来获取更多的信息。</p>\n<p>###译者注</p>\n<p>看了不少相关资料，个人感觉，目前Relay+GraphQL相比react确实还有待社区的考量，并且它们确实还太新，官方也强调可能会出现比较大的变动。所以，目前用在实际项目里的风险确实较大，还是继续观望吧～纯属个人看法！</p>\n","excerpt":"<p>原文地址：<a href=\"https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6\">https://medium.com/@clayallsopp/relay-101-building-a-hacker-news-client-bb8b2bdc76e6</a></p>\n<p><a href=\"https://facebook.github.io/react/\">React</a>让我们可以使用javascrip创建用户界面组件；<a href=\"https://facebook.github.io/relay/\">Relay</a>则可以让我们很容易的打通react组件和远程服务器的数据通信。为了实现这个目标Relay需要一个条件–它假设客户端和服务器端必须满足某种要求，这可能增加了使用它的门槛，但对于一些项目来说这是非常值得的！<br>","more":"<br>没有Relay的日子，你需要自己实现数据的下载，传输，缓存。像Flux和Redux这类工具帮你避免了在这过程中的一些bug，但当大量数据来往于应用与服务器之间时还是有非常多的人为性错误存在的可能。Relay会减少非常多的通用样板代码，让客户端开发人员可以更简洁安全的获取他们想要的数据。</p>\n<p>按照之前Rails的十五分钟搭建blog的传统，我们这里将快速使用Relay搭建一个HAcker News客户端。教程假设你了解Node，NPM和react，没有其他要求了～</p>\n<p>###Getting GraphQL</p>\n<p>目前Relay需要你的服务器提供<a href=\"https://facebook.github.io/graphql/\">GraphQL</a>接口。GraphQL非常优雅，但除非你是facebook的工程师，否则你可能并没有这么一个服务接口。</p>\n<p>为了避免我们自己搭建GRaphQL服务接口，我们这里将会使用<a href=\"http://www.graphqlhub.com/\">GraphQLHub</a>。GraphQLHub是一个发展迅速的GraphQL现有API翻译的仓库，和HackerNews和Reddit很像，我会一直维护它:)</p>\n<p>本篇指南会带领你快速了解GraphQL基础语法，所以你并不需要提前学习它的内容。如果你对GraphQL很感兴趣，你可以阅读<a href=\"https://medium.com/@clayallsopp/your-first-graphql-server-3c766ab4f0a2\">Your First GraphQL Server</a>（译：我已经翻译过了，可以在本博客查找）。</p>\n<p>###Setting Up The Project</p>\n<p>在2015年，有大量的工具帮助你创建浏览器端javascript应用。我们选择使用<a href=\"https://webpack.github.io/\">Webpack</a>来打包我们的代码供浏览器解析，并使用<a href=\"https://babeljs.io/\">Babel</a>来编译我们的React和Relay代码。这些工具都是Relay小组推荐使用的，但你也可以选择使用其它的。</p>\n<p>我们不会关注太多Webpack和Babel的内容，毕竟我们的关注点在Relay。</p>\n<p>让我们创建一个新的项目：</p>\n<pre><code>$ mkdir relay-101 &amp;&amp; cd ./relay-101\n$ npm init\n# you can hit Enter a bunch of times\n</code></pre><p>这将会在你的文件夹中创建package.json文件，然后我们安装一些包：</p>\n<pre><code>$ npm install webpack@1.12.2 webpack-dev-server@1.11.0 babel-core@5.8.25 babel-loader@5.3.2 --save\n</code></pre><p>Webpack会查找”webpack.config.js”文件，所以我们需要在当前目录下创建它：</p>\n<pre><code>$ touch webpack.config.js\n</code></pre><p>并把下面的内容复制粘贴进去：</p>\n<pre><code>var path = require(&apos;path&apos;);\n\nmodule.exports = {\n      entry: path.resolve(__dirname, &apos;index.js&apos;),\n      module: {\n        loaders: [\n              {\n                test: /\\.js$/,\n                loader: &apos;babel&apos;,\n                query: {stage: 0}\n              }\n        ]\n      },\n      output: {filename: &apos;index.bundle.js&apos;, path: &apos;./&apos;}\n};\n</code></pre><p>你可能注意到了我们这里提到了一个index.js文件。目前我们创建一个简单的实现：</p>\n<pre><code>$ echo &apos;alert(&quot;hello relay!&quot;);&apos; &gt; index.js\n</code></pre><p>所有客户端的代码都会放在这个文件里，所以建议你在你的编辑器中保持打开它。</p>\n<p>我们还需要在package.json文件中加入“start”入口设定：</p>\n<pre><code>{\n      // ...\n      &quot;scripts&quot;: {\n        &quot;start&quot;: &quot;./node_modules/.bin/webpack-dev-server&quot;,\n        &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;\n      },\n}\n</code></pre><p>这么做是为了允许我们直接使用“npm start”来运行我们之前安装的webpack development server的。我们可以在我们的终端中瞄一眼：</p>\n<pre><code>$ npm start\n&gt; relay-101-test@1.0.0 start ~/relay-101\n&gt; webpack-dev-server\n\nhttp://localhost:8080/webpack-dev-server/\nwebpack result is served from /\n</code></pre><p>浏览器中打开<a href=\"http://localhost:8080/webpack-dev-server\">http://localhost:8080/webpack-dev-server</a>，你会看到文件列表！这很好，但我们需要的是我们客户端的html页面。回到我们的项目文件夹，创建一个index.html并输入下面的内容：</p>\n<pre><code>$ touch index.html\n\n# paste this inside of index.html\n&lt;html&gt;\n&lt;head&gt;&lt;/head&gt;\n&lt;body&gt;\n      &lt;div id=&apos;container&apos;&gt;\n      &lt;/div&gt;\n      &lt;script src=&quot;/index.bundle.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>刷新我们的开发服务器，将会看到一个期望的弹窗：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*z-akwOi3BMk-NBVGT7pmag.png\" alt=\"\"></p>\n<p>现在我们就可以开始做一些好玩的事儿了。</p>\n<p>###Building A Static Component</p>\n<p>我们的小app将会模仿<a href=\"https://news.ycombinator.com/\">Hacker News</a>界面。开始之前，我们需要安装React和React-DOM包：</p>\n<pre><code>$ npm install react@0.14.0-rc1 react-dom@0.14.0-rc1 --save\n</code></pre><p>注意我们这里指定了明确的版本号（如果将来你发现接口变更，请通知我）。回到index.js，删除我们原先的alert代码，开始实现我们的Item组件：</p>\n<pre><code>// inside index.js\n\nlet React    = require(&apos;react&apos;);\nlet ReactDOM = require(&apos;react-dom&apos;);\n\nclass Item extends React.Component {\n      render() {\n        let item = this.props.store.item;\n\n        return (\n              &lt;div&gt;\n                &lt;h1&gt;&lt;a href={item.url}&gt;{item.title}&lt;/a&gt;&lt;/h1&gt;\n                &lt;h2&gt;{item.score} - {item.by.id}&lt;/h2&gt;\n                &lt;hr /&gt;\n              &lt;/div&gt;\n        );\n      }\n};\n</code></pre><p>注意，我们所有的数据都来自于“store”属性–稍后我们会解释～</p>\n<p>让我们先在屏幕上伪造一些item：</p>\n<pre><code>// at the bottom of index.js\n\nlet mountNode = document.getElementById(&apos;container&apos;);\nlet item = {\n      id  : &apos;1337&apos;,\n      url : &apos;http://google.com&apos;,\n      title : &apos;Google&apos;,\n      score : 100,\n      by : { id : &apos;clay &apos;}\n};\nlet store = { item };\nlet rootComponent = &lt;Item store={store} /&gt;;\nReactDOM.render(rootComponent, mountNode);\n</code></pre><p>刷新我们的开发服务器，你将会看到：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*S4ZZYS8uOoXxm6LgJhKt8w.png\" alt=\"\"></p>\n<p>###Data From The Server</p>\n<p>是时候来加点Relay了。我们将会从GraphQLHub上根据ID获取一些itme数据来代替我们的静态数据。我们先来安装一些Relay包：</p>\n<pre><code>$ npm install react-relay@0.3.2 babel-relay-plugin@0.2.5 sync-request@2.0.1 graphql@0.4.4 --save\n</code></pre><p>为什么我们安装了这么多东西而不仅仅是react-relay？好吧，目前Relay要求我们做的确实有点多–特别是，我们需要“babel-relay-plugin”来结合Babel。这个plugin会去GraphQLHub获取更多的Relay的配置。</p>\n<p>为了连接plugin，我们需要修改一下webpack.config.js中“query”选项：</p>\n<pre><code>module.exports = {\n      // ...\n      module: {\n        loaders: [\n              {\n                // ...,\n                // note that this is different!\n                query: {stage: 0, plugins: [&apos;./babelRelayPlugin&apos;]}\n              }\n        ]\n      }\n      // ...\n};\n</code></pre><p>这么做将会告诉Babel去加载一个叫babelRelayPlugin.js的文件。创建这个文件并放入下面的内容：</p>\n<pre><code>$ touch babelRelayPlugin.js\n\n// inside that file\nvar babelRelayPlugin   = require(&apos;babel-relay-plugin&apos;);\nvar introspectionQuery = require(&apos;graphql/utilities&apos;).introspectionQuery;\nvar request            = require(&apos;sync-request&apos;);\n\nvar graphqlHubUrl = &apos;http://www.GraphQLHub.com/graphql&apos;;\nvar response = request(&apos;GET&apos;, graphqlHubUrl, {\n      qs: {\n        query: introspectionQuery\n      }\n});\n\nvar schema = JSON.parse(response.body.toString(&apos;utf-8&apos;));\n\nmodule.exports = babelRelayPlugin(schema.data, {\n      abortOnError: true,\n});\n</code></pre><p>Cool–现在杀掉你的“npm start”进程并重启它。现在每次你重新打包你的app，它都会去GraphQLHub服务器（使用GraphQL优雅的自解释API）询问和预处理我们的Relay代码。</p>\n<p>回到index.js，是时候导入Relay啦：</p>\n<pre><code>let React    = require(&apos;react&apos;);\nlet ReactDOM = require(&apos;react-dom&apos;);\nlet Relay    = require(&apos;react-relay&apos;);\n</code></pre><p>接下来该做甚？我们将把我们的Item组件用<a href=\"https://medium.com/@dan_abramov/mixins-are-dead-long-live-higher-order-components-94a0d2f9e750#fd19\">higher-order</a>包装一下。这个新的组件将被Relay管理，这就是黑科技的地方：</p>\n<pre><code>class Item extends React.Component {\n      ...\n}\nItem = Relay.createContainer(Item, {\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsAPI {\n                item(id: 8863) {\n                      title,\n                      score,\n                      url\n                      by {\n                        id\n                      }\n                }\n              }\n        `,\n      },\n});\n</code></pre><p>哒啦，搞定。翻译成大白话，上面的写法解释为：</p>\n<ol>\n<li><p>嘿 Relay，我将把我的item组件作为原件放到新的组件容器中。</p>\n</li>\n<li><p>对于组件的“store”属性，我需要数据已经用GraphQL片段描述了。</p>\n</li>\n<li><p>我知道这些数据在<a href=\"http://graphqlhub.com/playground/hn的“HackerNewsAPI”对象中。\">http://graphqlhub.com/playground/hn的“HackerNewsAPI”对象中。</a></p>\n</li>\n</ol>\n<p>注意这里我们只是描述了一个GraphQL片段（片段的概念很类似于查询中的别名），并不是最终获取所有数据的完整query。这是Relay的一个优点–组件只需要声明它需要的数据，而不用管如何获取数据。</p>\n<p>有些时候我们确实需要一个完整的GraphQL query，这就是Relay Routes的主场了。Relay.Route跟浏览器里的history或URLs半毛钱关系都木有–它是用来创建引导我们数据获取请求的“root query”的。</p>\n<p>嗖，让我们来搞一个Relay Route。在我们的Itme定义下面加入：</p>\n<pre><code>Item = // ...;\n\nclass HackerNewsRoute extends Relay.Route {\n      static routeName = &apos;HackerNewsRoute&apos;;\n      static queries = {\n        store: ((Component) =&gt; {\n              // 这里Component就是我们的Item组件\n              return Relay.QL`\n                  query root {\n                    hn { ${Component.getFragment(&apos;store&apos;)} },\n                  }\n            `}),\n      };\n}\n</code></pre><p>现在我们的GraphQL补全了root query。Relay允许我们使用ES6的字符串解析特性注入我们的片段，这就完成了组件分享（不同于复制）它的数据需求给父组件的过程。</p>\n<p>是时候展示点数据到屏幕上了！修改我们之前的代码如下：</p>\n<pre><code>class HackerNewsRoute {\n     // ...\n}\n\nRelay.injectNetworkLayer(\n      new Relay.DefaultNetworkLayer(&apos;http://www.GraphQLHub.com/graphql&apos;)\n);\n\nlet mountNode = document.getElementById(&apos;container&apos;);\nlet rootComponent = &lt;Relay.RootContainer\n      Component={Item}\n      route={new HackerNewsRoute()} /&gt;;\nReactDOM.render(rootComponent, mountNode);\n</code></pre><p>这里Relay.RootContainer是顶级组件，它构建了一个组件层级的query。我们还做了一些网络配置，最终渲染新的组件到DOM。你会在浏览器中看到下面的景象：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*GOT3SozMFQCo3RcSiTMmcA.png\" alt=\"\"></p>\n<p>###A List Of Components</p>\n<p>我们下面开始做一个类似Hacker News首页的页面。相比硬编码一个特定的item，我们需要展示一个item列表。用Relay的话说，这需要我们创建一个新的list组件，其中嵌套多个独立的item组件（每个都请求自己的数据）。</p>\n<p>回到代码，我们开始创建我们的TopItems组件：</p>\n<pre><code>class TopItems extends React.Component {\n      render() {\n        let items = this.props.store.topStories.map(\n              (store, idx) =&gt; &lt;Item store={store} key={idx} /&gt;\n        );\n        return &lt;div&gt;\n              { items }\n        &lt;/div&gt;;\n      }\n}\n</code></pre><p>我们就不再想刚才那样先“创建伪造数据”了，而是直接动真格的，用Relay封装TopItems：</p>\n<pre><code>TopItems = Relay.createContainer(TopItems, {\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsAPI {\n                topStories { ${Item.getFragment(&apos;store&apos;)} },\n              }\n        `,\n      },\n});\n</code></pre><p>相比之前的单独item，现在我们需要请求“topStories”。针对每个item，GraphQL会根据声明的片段请求对应的数据，所以我们将只请求我们需要的数据。</p>\n<p>但是稍等–目前我们的item片段定义了一个特定的id（<a href=\"https://news.ycombinator.com/item?id=8863\">#8863</a>）。我们需要修改我们的query：</p>\n<pre><code>Item = Relay.createContainer(Item, {\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsItem {\n                id\n                title,\n                score,\n                url\n                by {\n                      id\n                }\n              }\n        `,\n      },\n});\n</code></pre><p>由于我们不再请求一个特定的item片段，所以我们需要修改在render函数中存取prop的方式：</p>\n<pre><code>class Item extends React.Component {\n      render() {\n        let item = this.props.store;\n        // ...\n      }\n}\n</code></pre><p>最后，我们需要更新Relay RootContainer来使用我们的TopItems组件：</p>\n<pre><code>let rootComponent = &lt;Relay.RootContainer\n      Component={TopItems}\n      route={new HackerNewsRoute()} /&gt;;\n</code></pre><p>瞧：</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*5r4OXLb20RzSJppF6zZVqg.png\" alt=\"\"></p>\n<p>###Variables in Queries</p>\n<p>现在我们对创建一个Relay app有了最基础的了解，但我希望展现Relay另一个特性：variables。</p>\n<p>在多数挨派派里，查询并不是一成不变的，我们经常需要请求不同的数据。Relay允许我们在GraphQL query中注入变量来达到这个目的。在我们这个小挨派派里，我们将添加一个开关来切换我们需要的数据类型（按照热度或时间等排序）。</p>\n<p>开始之前，我们需要修改我们的TopItems的query：</p>\n<pre><code>TopItems = Relay.createContainer(TopItems, {\n      initialVariables: {\n        storyType: &quot;top&quot;\n      },\n      fragments: {\n        store: () =&gt; Relay.QL`\n              fragment on HackerNewsAPI {\n                stories(storyType: $storyType) { \n                    ${Item.getFragment(&apos;store&apos;)} \n                },\n              }\n        `,\n      },\n});\n</code></pre><p>“$storyType”代表一个GraphQL变量（这并不是ES6的字符串解析语法）。我们通过initialVariables配置给它设置了一个初始默认值“top”。</p>\n<p>这只是Relay层面我们需要做的简单修改。我们并不需要对具体的组件做任何渲染或数据获取的修改–完全解耦了。</p>\n<p>现在我们需要编辑我们的TopItems组件来使用开关类型。更新render函数如下：</p>\n<pre><code>class TopItems extends React.Component {\n      render() {\n        let items = this.props.store.stories.map(\n              (store, idx) =&gt; &lt;Item store={store} key={idx} /&gt;\n        );\n        let variables = this.props.relay.variables;\n\n        // To reduce the perceived lag\n        // There are less crude ways of doing this, but this works for now\n        let currentStoryType = (this.state &amp;&amp; this.state.storyType) || variables.storyType;\n\n        return &lt;div&gt;\n              &lt;select onChange={this._onChange.bind(this)} value={currentStoryType}&gt;\n                &lt;option value=&quot;top&quot;&gt;Top&lt;/option&gt;\n                &lt;option value=&quot;new&quot;&gt;New&lt;/option&gt;\n                &lt;option value=&quot;ask&quot;&gt;Ask HN&lt;/option&gt;\n                &lt;option value=&quot;show&quot;&gt;Show HN&lt;/option&gt;\n              &lt;/select&gt;\n              { items }\n        &lt;/div&gt;;\n      }\n\n  // to be continued\n</code></pre><p>这里有些新的知识点！我们使用了“Relay”prop，它包含一些特定的属性。任何使用Relay封装的组件都会被注入这个prop–如果我们想对我们的TopItems组件进行单元测试，我们需要自己注入一个伪造的对象。</p>\n<p>除此Relay变量之外，其它都是普通的React–我们创建一个下拉菜单，并给它一个默认值，并监听它的修改。当改变下拉菜单的选项，我们会告诉Relay去使用新的变量值，如下：</p>\n<pre><code>class TopItems extends React.Component {\n      render() {\n        // ...\n      }\n\n      _onChange(ev) {\n        let storyType = ev.target.value;\n        this.setState({ storyType });\n        this.props.relay.setVariables({\n              storyType\n        });\n      }\n}\n</code></pre><p>一切都很简答–Relay会察觉query的一部分发生了变化，并且根据需要重新去获取数据。为了简单，我们设置了组件的内部状态，</p>\n<p>刷新你的浏览器并且切换不同的下拉选项。你会发现，Relay并不会重复获取已经加载了的数据类型。</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*eTObnmhvdB4lFI7CPU3GQQ.png\" alt=\"\"></p>\n<p>###Relay 102</p>\n<p>SO，以上就是关于Relay的简单介绍。我们还没有涉及到mutations（用来完成更新服务端数据）和在获取数据时显示加载提醒。Relay非常的灵活，但代价是需要比我们这里提到的更多<br>的配置。</p>\n<p>Relay可能并不是适合所有的挨派派和团队，但它在解决某些常见问题上确实令人非常激动。</p>\n<p>这篇文章中的源码放在<a href=\"https://github.com/clayallsopp/relay-101\">Github</a>，关注我<a href=\"http://twitter.com/clayallsopp\">@clayallsopp</a>和<a href=\"http://twitter.com/GraphQLHub\">@GraphQLHub</a>来获取更多的信息。</p>\n<p>###译者注</p>\n<p>看了不少相关资料，个人感觉，目前Relay+GraphQL相比react确实还有待社区的考量，并且它们确实还太新，官方也强调可能会出现比较大的变动。所以，目前用在实际项目里的风险确实较大，还是继续观望吧～纯属个人看法！</p>"},{"title":"老生常谈Mac下的ntfs写问题","date":"2016-02-26T01:37:12.000Z","_content":"\n已经有很久没有更新自己的blog了，以至于域名过期了都不知道，昨天偶然发现后赶紧去续费，哇哈哈～\n\n假期就要结束了，马上就要开始人生新的旅程，抛弃那些不好的，没有意义的旧事和旧人，迎接美好未来！走起～\n<!--more-->\n回到主题，其实我用Mac系统也有年头了，但一直没有怎么折腾过，之前装过一个盗版的ntfs工具，名字不记得了，只记得导致我的移动硬盘差点报废！具体原因我也不清楚，用着用着突然就报错了，再插一遍设备竟然不识别了，换到window下提示硬盘已损坏！\n\n我攒了二十几年的片儿要是真丢了，我感觉人生都没有意义了！不过还好一番折腾后在win下是可以识别了！经历这次后我乖乖的删除了mac下的各种关于ntfs读写的工具！！\n\n那为啥今天又要提这事儿呢？当然是因为我的mac硬盘满了～～哇哈哈哈～抱着试一试的态度，我再次GG了一下这方面的技术贴，这次换了一种很简单的[方法](http://www.oschina.net/translate/enabling-ntfs-write-on-os-x)，这并不是一个新方案，只是之前的我并没有找到。\n\n简单的说，步骤有3：\n\n1. 确保你的移动硬盘名称不包含空格（其实我觉得空格也没问题，转义一下应该就可以）\n2. 把硬盘插到mac上，打开终端，输入“sudo nano /etc/fstab”\n3. 在打开的编辑器中输入“LABEL=你硬盘的名字 none ntfs rw,auto,nobrowse”，保存退出编辑器\n4. 拔掉硬盘，再插上，终端中输入“open /Volumes”，你就会看到你的硬盘已经识别了，并且已经可以读写内容了\n5. 将文件夹中的硬盘图标拖拽到Finder的侧边栏，以后你就可以直接访问了。\n\n就这么简单，其它帖子说的什么获取UUID啥的，都不需要！一切就是这么顺利！\n\n然后做啥？当然是拷片儿了啊！\n\n好不容易拷了50G的片儿，突然我发现一个问题，放到硬盘里的片儿都是灰色的，并且双击会提示：\n\n> 项目“XXX”已被 OS X 使用，不能打开。\n\n这可吓死宝宝了，本尊可是已经删除了Mac中的片儿了啊！赶紧GG，找到了[解决方案](http://www.jianshu.com/p/3782d73cb3e8)，同样不知道原理是啥，同样很简单就搞定，只需要：\n\n在终端中进入到硬盘的对应位置，执行“xattr -c 有问题的文件名称”即可搞定！\n\n哇哈哈，你可以说这篇文章很水，不过确实很实用，就当是顿快餐吧～～88","source":"_posts/老生常谈Mac下的ntfs写问题.md","raw":"title: 老生常谈Mac下的ntfs写问题\ndate: 2016-02-26 09:37:12\ntags: \n- mac\n- ntfs\ncategories: mac\n---\n\n已经有很久没有更新自己的blog了，以至于域名过期了都不知道，昨天偶然发现后赶紧去续费，哇哈哈～\n\n假期就要结束了，马上就要开始人生新的旅程，抛弃那些不好的，没有意义的旧事和旧人，迎接美好未来！走起～\n<!--more-->\n回到主题，其实我用Mac系统也有年头了，但一直没有怎么折腾过，之前装过一个盗版的ntfs工具，名字不记得了，只记得导致我的移动硬盘差点报废！具体原因我也不清楚，用着用着突然就报错了，再插一遍设备竟然不识别了，换到window下提示硬盘已损坏！\n\n我攒了二十几年的片儿要是真丢了，我感觉人生都没有意义了！不过还好一番折腾后在win下是可以识别了！经历这次后我乖乖的删除了mac下的各种关于ntfs读写的工具！！\n\n那为啥今天又要提这事儿呢？当然是因为我的mac硬盘满了～～哇哈哈哈～抱着试一试的态度，我再次GG了一下这方面的技术贴，这次换了一种很简单的[方法](http://www.oschina.net/translate/enabling-ntfs-write-on-os-x)，这并不是一个新方案，只是之前的我并没有找到。\n\n简单的说，步骤有3：\n\n1. 确保你的移动硬盘名称不包含空格（其实我觉得空格也没问题，转义一下应该就可以）\n2. 把硬盘插到mac上，打开终端，输入“sudo nano /etc/fstab”\n3. 在打开的编辑器中输入“LABEL=你硬盘的名字 none ntfs rw,auto,nobrowse”，保存退出编辑器\n4. 拔掉硬盘，再插上，终端中输入“open /Volumes”，你就会看到你的硬盘已经识别了，并且已经可以读写内容了\n5. 将文件夹中的硬盘图标拖拽到Finder的侧边栏，以后你就可以直接访问了。\n\n就这么简单，其它帖子说的什么获取UUID啥的，都不需要！一切就是这么顺利！\n\n然后做啥？当然是拷片儿了啊！\n\n好不容易拷了50G的片儿，突然我发现一个问题，放到硬盘里的片儿都是灰色的，并且双击会提示：\n\n> 项目“XXX”已被 OS X 使用，不能打开。\n\n这可吓死宝宝了，本尊可是已经删除了Mac中的片儿了啊！赶紧GG，找到了[解决方案](http://www.jianshu.com/p/3782d73cb3e8)，同样不知道原理是啥，同样很简单就搞定，只需要：\n\n在终端中进入到硬盘的对应位置，执行“xattr -c 有问题的文件名称”即可搞定！\n\n哇哈哈，你可以说这篇文章很水，不过确实很实用，就当是顿快餐吧～～88","slug":"老生常谈Mac下的ntfs写问题","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cil3q63ep00007nwsqb322qzk","comments":1,"layout":"post","photos":[],"link":"","content":"<p>已经有很久没有更新自己的blog了，以至于域名过期了都不知道，昨天偶然发现后赶紧去续费，哇哈哈～</p>\n<p>假期就要结束了，马上就要开始人生新的旅程，抛弃那些不好的，没有意义的旧事和旧人，迎接美好未来！走起～<br><a id=\"more\"></a><br>回到主题，其实我用Mac系统也有年头了，但一直没有怎么折腾过，之前装过一个盗版的ntfs工具，名字不记得了，只记得导致我的移动硬盘差点报废！具体原因我也不清楚，用着用着突然就报错了，再插一遍设备竟然不识别了，换到window下提示硬盘已损坏！</p>\n<p>我攒了二十几年的片儿要是真丢了，我感觉人生都没有意义了！不过还好一番折腾后在win下是可以识别了！经历这次后我乖乖的删除了mac下的各种关于ntfs读写的工具！！</p>\n<p>那为啥今天又要提这事儿呢？当然是因为我的mac硬盘满了～～哇哈哈哈～抱着试一试的态度，我再次GG了一下这方面的技术贴，这次换了一种很简单的<a href=\"http://www.oschina.net/translate/enabling-ntfs-write-on-os-x\" target=\"_blank\" rel=\"external\">方法</a>，这并不是一个新方案，只是之前的我并没有找到。</p>\n<p>简单的说，步骤有3：</p>\n<ol>\n<li>确保你的移动硬盘名称不包含空格（其实我觉得空格也没问题，转义一下应该就可以）</li>\n<li>把硬盘插到mac上，打开终端，输入“sudo nano /etc/fstab”</li>\n<li>在打开的编辑器中输入“LABEL=你硬盘的名字 none ntfs rw,auto,nobrowse”，保存退出编辑器</li>\n<li>拔掉硬盘，再插上，终端中输入“open /Volumes”，你就会看到你的硬盘已经识别了，并且已经可以读写内容了</li>\n<li>将文件夹中的硬盘图标拖拽到Finder的侧边栏，以后你就可以直接访问了。</li>\n</ol>\n<p>就这么简单，其它帖子说的什么获取UUID啥的，都不需要！一切就是这么顺利！</p>\n<p>然后做啥？当然是拷片儿了啊！</p>\n<p>好不容易拷了50G的片儿，突然我发现一个问题，放到硬盘里的片儿都是灰色的，并且双击会提示：</p>\n<blockquote>\n<p>项目“XXX”已被 OS X 使用，不能打开。</p>\n</blockquote>\n<p>这可吓死宝宝了，本尊可是已经删除了Mac中的片儿了啊！赶紧GG，找到了<a href=\"http://www.jianshu.com/p/3782d73cb3e8\" target=\"_blank\" rel=\"external\">解决方案</a>，同样不知道原理是啥，同样很简单就搞定，只需要：</p>\n<p>在终端中进入到硬盘的对应位置，执行“xattr -c 有问题的文件名称”即可搞定！</p>\n<p>哇哈哈，你可以说这篇文章很水，不过确实很实用，就当是顿快餐吧～～88</p>\n","excerpt":"<p>已经有很久没有更新自己的blog了，以至于域名过期了都不知道，昨天偶然发现后赶紧去续费，哇哈哈～</p>\n<p>假期就要结束了，马上就要开始人生新的旅程，抛弃那些不好的，没有意义的旧事和旧人，迎接美好未来！走起～<br>","more":"<br>回到主题，其实我用Mac系统也有年头了，但一直没有怎么折腾过，之前装过一个盗版的ntfs工具，名字不记得了，只记得导致我的移动硬盘差点报废！具体原因我也不清楚，用着用着突然就报错了，再插一遍设备竟然不识别了，换到window下提示硬盘已损坏！</p>\n<p>我攒了二十几年的片儿要是真丢了，我感觉人生都没有意义了！不过还好一番折腾后在win下是可以识别了！经历这次后我乖乖的删除了mac下的各种关于ntfs读写的工具！！</p>\n<p>那为啥今天又要提这事儿呢？当然是因为我的mac硬盘满了～～哇哈哈哈～抱着试一试的态度，我再次GG了一下这方面的技术贴，这次换了一种很简单的<a href=\"http://www.oschina.net/translate/enabling-ntfs-write-on-os-x\">方法</a>，这并不是一个新方案，只是之前的我并没有找到。</p>\n<p>简单的说，步骤有3：</p>\n<ol>\n<li>确保你的移动硬盘名称不包含空格（其实我觉得空格也没问题，转义一下应该就可以）</li>\n<li>把硬盘插到mac上，打开终端，输入“sudo nano /etc/fstab”</li>\n<li>在打开的编辑器中输入“LABEL=你硬盘的名字 none ntfs rw,auto,nobrowse”，保存退出编辑器</li>\n<li>拔掉硬盘，再插上，终端中输入“open /Volumes”，你就会看到你的硬盘已经识别了，并且已经可以读写内容了</li>\n<li>将文件夹中的硬盘图标拖拽到Finder的侧边栏，以后你就可以直接访问了。</li>\n</ol>\n<p>就这么简单，其它帖子说的什么获取UUID啥的，都不需要！一切就是这么顺利！</p>\n<p>然后做啥？当然是拷片儿了啊！</p>\n<p>好不容易拷了50G的片儿，突然我发现一个问题，放到硬盘里的片儿都是灰色的，并且双击会提示：</p>\n<blockquote>\n<p>项目“XXX”已被 OS X 使用，不能打开。</p>\n</blockquote>\n<p>这可吓死宝宝了，本尊可是已经删除了Mac中的片儿了啊！赶紧GG，找到了<a href=\"http://www.jianshu.com/p/3782d73cb3e8\">解决方案</a>，同样不知道原理是啥，同样很简单就搞定，只需要：</p>\n<p>在终端中进入到硬盘的对应位置，执行“xattr -c 有问题的文件名称”即可搞定！</p>\n<p>哇哈哈，你可以说这篇文章很水，不过确实很实用，就当是顿快餐吧～～88</p>"},{"title":"关于MariaDB和mysql5.7的json类型特性","date":"2016-03-04T01:37:00.000Z","_content":"\n\n## mysql5.7\n\n之前有仔细的了解并使用过MongoDb，大概在一两年前吧~但无奈记忆早已模糊！\n<!--more-->\n最近可能有需要解决一个数据结构问题，刚好比较符合文档型数据库的领域范畴。就在我正翻看以前记录的文章时，突然想起来，似乎mysql5.7开始支持json类型，心里琢磨，如果可以避免项目中引入过多的依赖，这无疑是最明智的选择。\n\nGG一下，刚好找到了一个入门的[文章](http://www.bytetown.net/2016/03/01/001-mysql-5_7_json_functions.html)，基本上把常用操作介绍的非常清楚了。\n\n如果你想知道mysql5.7对json特性的实现细节，不妨看看[这里](http://mysql.taobao.org/monthly/2016/01/03/)，这样我们就可以开始尝试在业务中使用json类型啦！\n\n虽然看文档中也提到了，目前可以针对json内部数据进行索引以及检索，但似乎没有mongodb提供的查询强大，但优势是沿用了SQL的知识，可以很快上手！\n\n关于mysql5.7，先告一段落。\n\n## mariadb10.1.10\n\n我们再来看看社区版的mariadb，它从5.3版本开始就已经支持json了，不过和mysql的方法不太一样，它基于“Dynamic Columns”思路来实现的，底层和mysql方法一样都是blob类型存储。\n\n目前来看，mariadb支持的json特性并没有mysql的多，或者说稍微有点复杂。官方资料：[Dynamic Columns](https://mariadb.com/kb/en/mariadb/dynamic-columns/)。\n\n尤其是在处理json的嵌套时，使用的方法比较烧脑。\n\n\n## todo\n\n虽然目前不管是你选择mysql还是mariadb，都可以使用json类型来处理非结构化数据模型，但你的开发语言提供的db库是否跟得上节奏，这就是个疑问了？\n\n目前项目主要想在数据结构模型上能获得更大的灵活性，但针对非结构数据类型的检索性能并不是非常敏感，更多的是想持久化“文档概念”的类型！所以不出意外的话，将会暂时不考虑mongodb啦~\n\n听起来，数据库领域的革命还在激烈的进行着啊！\n","source":"_posts/关于mariaDB和mysql5.7的json类型特性.md","raw":"title:  关于MariaDB和mysql5.7的json类型特性\ndate: 2016-03-04 09:37:00\ntags:\n- mysql\n- Mariadb\n- json\ncategories: 数据库\n---\n\n\n## mysql5.7\n\n之前有仔细的了解并使用过MongoDb，大概在一两年前吧~但无奈记忆早已模糊！\n<!--more-->\n最近可能有需要解决一个数据结构问题，刚好比较符合文档型数据库的领域范畴。就在我正翻看以前记录的文章时，突然想起来，似乎mysql5.7开始支持json类型，心里琢磨，如果可以避免项目中引入过多的依赖，这无疑是最明智的选择。\n\nGG一下，刚好找到了一个入门的[文章](http://www.bytetown.net/2016/03/01/001-mysql-5_7_json_functions.html)，基本上把常用操作介绍的非常清楚了。\n\n如果你想知道mysql5.7对json特性的实现细节，不妨看看[这里](http://mysql.taobao.org/monthly/2016/01/03/)，这样我们就可以开始尝试在业务中使用json类型啦！\n\n虽然看文档中也提到了，目前可以针对json内部数据进行索引以及检索，但似乎没有mongodb提供的查询强大，但优势是沿用了SQL的知识，可以很快上手！\n\n关于mysql5.7，先告一段落。\n\n## mariadb10.1.10\n\n我们再来看看社区版的mariadb，它从5.3版本开始就已经支持json了，不过和mysql的方法不太一样，它基于“Dynamic Columns”思路来实现的，底层和mysql方法一样都是blob类型存储。\n\n目前来看，mariadb支持的json特性并没有mysql的多，或者说稍微有点复杂。官方资料：[Dynamic Columns](https://mariadb.com/kb/en/mariadb/dynamic-columns/)。\n\n尤其是在处理json的嵌套时，使用的方法比较烧脑。\n\n\n## todo\n\n虽然目前不管是你选择mysql还是mariadb，都可以使用json类型来处理非结构化数据模型，但你的开发语言提供的db库是否跟得上节奏，这就是个疑问了？\n\n目前项目主要想在数据结构模型上能获得更大的灵活性，但针对非结构数据类型的检索性能并不是非常敏感，更多的是想持久化“文档概念”的类型！所以不出意外的话，将会暂时不考虑mongodb啦~\n\n听起来，数据库领域的革命还在激烈的进行着啊！\n","slug":"关于mariaDB和mysql5.7的json类型特性","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cildphkgb0000hzfy20vqtspy","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"mysql5-7\"><a href=\"#mysql5-7\" class=\"headerlink\" title=\"mysql5.7\"></a>mysql5.7</h2><p>之前有仔细的了解并使用过MongoDb，大概在一两年前吧~但无奈记忆早已模糊！<br><a id=\"more\"></a><br>最近可能有需要解决一个数据结构问题，刚好比较符合文档型数据库的领域范畴。就在我正翻看以前记录的文章时，突然想起来，似乎mysql5.7开始支持json类型，心里琢磨，如果可以避免项目中引入过多的依赖，这无疑是最明智的选择。</p>\n<p>GG一下，刚好找到了一个入门的<a href=\"http://www.bytetown.net/2016/03/01/001-mysql-5_7_json_functions.html\" target=\"_blank\" rel=\"external\">文章</a>，基本上把常用操作介绍的非常清楚了。</p>\n<p>如果你想知道mysql5.7对json特性的实现细节，不妨看看<a href=\"http://mysql.taobao.org/monthly/2016/01/03/\" target=\"_blank\" rel=\"external\">这里</a>，这样我们就可以开始尝试在业务中使用json类型啦！</p>\n<p>虽然看文档中也提到了，目前可以针对json内部数据进行索引以及检索，但似乎没有mongodb提供的查询强大，但优势是沿用了SQL的知识，可以很快上手！</p>\n<p>关于mysql5.7，先告一段落。</p>\n<h2 id=\"mariadb10-1-10\"><a href=\"#mariadb10-1-10\" class=\"headerlink\" title=\"mariadb10.1.10\"></a>mariadb10.1.10</h2><p>我们再来看看社区版的mariadb，它从5.3版本开始就已经支持json了，不过和mysql的方法不太一样，它基于“Dynamic Columns”思路来实现的，底层和mysql方法一样都是blob类型存储。</p>\n<p>目前来看，mariadb支持的json特性并没有mysql的多，或者说稍微有点复杂。官方资料：<a href=\"https://mariadb.com/kb/en/mariadb/dynamic-columns/\" target=\"_blank\" rel=\"external\">Dynamic Columns</a>。</p>\n<p>尤其是在处理json的嵌套时，使用的方法比较烧脑。</p>\n<h2 id=\"todo\"><a href=\"#todo\" class=\"headerlink\" title=\"todo\"></a>todo</h2><p>虽然目前不管是你选择mysql还是mariadb，都可以使用json类型来处理非结构化数据模型，但你的开发语言提供的db库是否跟得上节奏，这就是个疑问了？</p>\n<p>目前项目主要想在数据结构模型上能获得更大的灵活性，但针对非结构数据类型的检索性能并不是非常敏感，更多的是想持久化“文档概念”的类型！所以不出意外的话，将会暂时不考虑mongodb啦~</p>\n<p>听起来，数据库领域的革命还在激烈的进行着啊！</p>\n","excerpt":"<h2 id=\"mysql5-7\"><a href=\"#mysql5-7\" class=\"headerlink\" title=\"mysql5.7\"></a>mysql5.7</h2><p>之前有仔细的了解并使用过MongoDb，大概在一两年前吧~但无奈记忆早已模糊！<br>","more":"<br>最近可能有需要解决一个数据结构问题，刚好比较符合文档型数据库的领域范畴。就在我正翻看以前记录的文章时，突然想起来，似乎mysql5.7开始支持json类型，心里琢磨，如果可以避免项目中引入过多的依赖，这无疑是最明智的选择。</p>\n<p>GG一下，刚好找到了一个入门的<a href=\"http://www.bytetown.net/2016/03/01/001-mysql-5_7_json_functions.html\">文章</a>，基本上把常用操作介绍的非常清楚了。</p>\n<p>如果你想知道mysql5.7对json特性的实现细节，不妨看看<a href=\"http://mysql.taobao.org/monthly/2016/01/03/\">这里</a>，这样我们就可以开始尝试在业务中使用json类型啦！</p>\n<p>虽然看文档中也提到了，目前可以针对json内部数据进行索引以及检索，但似乎没有mongodb提供的查询强大，但优势是沿用了SQL的知识，可以很快上手！</p>\n<p>关于mysql5.7，先告一段落。</p>\n<h2 id=\"mariadb10-1-10\"><a href=\"#mariadb10-1-10\" class=\"headerlink\" title=\"mariadb10.1.10\"></a>mariadb10.1.10</h2><p>我们再来看看社区版的mariadb，它从5.3版本开始就已经支持json了，不过和mysql的方法不太一样，它基于“Dynamic Columns”思路来实现的，底层和mysql方法一样都是blob类型存储。</p>\n<p>目前来看，mariadb支持的json特性并没有mysql的多，或者说稍微有点复杂。官方资料：<a href=\"https://mariadb.com/kb/en/mariadb/dynamic-columns/\">Dynamic Columns</a>。</p>\n<p>尤其是在处理json的嵌套时，使用的方法比较烧脑。</p>\n<h2 id=\"todo\"><a href=\"#todo\" class=\"headerlink\" title=\"todo\"></a>todo</h2><p>虽然目前不管是你选择mysql还是mariadb，都可以使用json类型来处理非结构化数据模型，但你的开发语言提供的db库是否跟得上节奏，这就是个疑问了？</p>\n<p>目前项目主要想在数据结构模型上能获得更大的灵活性，但针对非结构数据类型的检索性能并不是非常敏感，更多的是想持久化“文档概念”的类型！所以不出意外的话，将会暂时不考虑mongodb啦~</p>\n<p>听起来，数据库领域的革命还在激烈的进行着啊！</p>"},{"title":"google dirve的权限设计","date":"2016-03-11T01:37:00.000Z","_content":"\n\n关于google drive的权限设计，一开始看官方文档，搞的云里雾里的！\n\n可能是对google drive不了解的关系，再加上没有参与设计过类似的平台化系统，所以对于它的权限设计内容，总觉得很绕~\n<!--more-->\n停下来花了点时间仔细捋了一遍，发现这个设计还是非常优雅的，至于通用性，我就持保留态度了！\n\n首先，我们来列出整套权限系统设计到的元素有哪几个：\n\n* account（帐号）\n  * user\n  * user group\n  * domain\n  * anyone\n* resource（资源）\n  * file\n  * folder\n* permission（权限设置）\n  * role\n  * type\n\n咱们简单的就这么先罗列出来。\n\n首先我们先看一下三个主要的元素的关系：\n\n```\nresource  ------>  permission  ------> account [ ------>  resource]\n          1     n              1     1           n     n\n```        \n解释：\n\n* 一个资源对应多个权限设置\n* 一个资源的metadata中还会包含多个特定帐号（owners, sharingUser, lastModifyingUser）\n* 一个权限设置绑定到多个帐号（根据type来确定和帐号的绑定类型，根据domain和emailAddress来确定具体哪个或哪些帐号）\n* 一个权限设置会预先设定好几个拥有不同操作范围的角色（role），具体关系可以看[官方文档](https://developers.google.com/drive/v3/web/manage-sharing#roles)\n* 最终，帐号就会和资源关联上，就是这么绕！\n\n现在应该已经解释的很清楚了吧？上面的关系图中最后的account与resource的关系其实是根据前面的关系推出来的，而不是直接可以获取到的（除了在resource的metadata中的那几个特定帐号字段，个人猜测之所有会有这几个metadata，是为了性能）。\n\n不能确定这么设计是好还是坏，但整体来看，其实并不算复杂。\n","source":"_posts/Google Drive的权限设计.md","raw":"title:  google dirve的权限设计\ndate: 2016-03-11 09:37:00\ntags:\n- google\n- 权限\n- api\ncategories: 系统设计\n---\n\n\n关于google drive的权限设计，一开始看官方文档，搞的云里雾里的！\n\n可能是对google drive不了解的关系，再加上没有参与设计过类似的平台化系统，所以对于它的权限设计内容，总觉得很绕~\n<!--more-->\n停下来花了点时间仔细捋了一遍，发现这个设计还是非常优雅的，至于通用性，我就持保留态度了！\n\n首先，我们来列出整套权限系统设计到的元素有哪几个：\n\n* account（帐号）\n  * user\n  * user group\n  * domain\n  * anyone\n* resource（资源）\n  * file\n  * folder\n* permission（权限设置）\n  * role\n  * type\n\n咱们简单的就这么先罗列出来。\n\n首先我们先看一下三个主要的元素的关系：\n\n```\nresource  ------>  permission  ------> account [ ------>  resource]\n          1     n              1     1           n     n\n```        \n解释：\n\n* 一个资源对应多个权限设置\n* 一个资源的metadata中还会包含多个特定帐号（owners, sharingUser, lastModifyingUser）\n* 一个权限设置绑定到多个帐号（根据type来确定和帐号的绑定类型，根据domain和emailAddress来确定具体哪个或哪些帐号）\n* 一个权限设置会预先设定好几个拥有不同操作范围的角色（role），具体关系可以看[官方文档](https://developers.google.com/drive/v3/web/manage-sharing#roles)\n* 最终，帐号就会和资源关联上，就是这么绕！\n\n现在应该已经解释的很清楚了吧？上面的关系图中最后的account与resource的关系其实是根据前面的关系推出来的，而不是直接可以获取到的（除了在resource的metadata中的那几个特定帐号字段，个人猜测之所有会有这几个metadata，是为了性能）。\n\n不能确定这么设计是好还是坏，但整体来看，其实并不算复杂。\n","slug":"Google Drive的权限设计","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cilp4udgz0000l1fy385hxp51","comments":1,"layout":"post","photos":[],"link":"","content":"<p>关于google drive的权限设计，一开始看官方文档，搞的云里雾里的！</p>\n<p>可能是对google drive不了解的关系，再加上没有参与设计过类似的平台化系统，所以对于它的权限设计内容，总觉得很绕~<br><a id=\"more\"></a><br>停下来花了点时间仔细捋了一遍，发现这个设计还是非常优雅的，至于通用性，我就持保留态度了！</p>\n<p>首先，我们来列出整套权限系统设计到的元素有哪几个：</p>\n<ul>\n<li>account（帐号）<ul>\n<li>user</li>\n<li>user group</li>\n<li>domain</li>\n<li>anyone</li>\n</ul>\n</li>\n<li>resource（资源）<ul>\n<li>file</li>\n<li>folder</li>\n</ul>\n</li>\n<li>permission（权限设置）<ul>\n<li>role</li>\n<li>type</li>\n</ul>\n</li>\n</ul>\n<p>咱们简单的就这么先罗列出来。</p>\n<p>首先我们先看一下三个主要的元素的关系：</p>\n<pre><code>resource  ------&gt;  permission  ------&gt; account [ ------&gt;  resource]\n          1     n              1     1           n     n\n</code></pre><p>解释：</p>\n<ul>\n<li>一个资源对应多个权限设置</li>\n<li>一个资源的metadata中还会包含多个特定帐号（owners, sharingUser, lastModifyingUser）</li>\n<li>一个权限设置绑定到多个帐号（根据type来确定和帐号的绑定类型，根据domain和emailAddress来确定具体哪个或哪些帐号）</li>\n<li>一个权限设置会预先设定好几个拥有不同操作范围的角色（role），具体关系可以看<a href=\"https://developers.google.com/drive/v3/web/manage-sharing#roles\" target=\"_blank\" rel=\"external\">官方文档</a></li>\n<li>最终，帐号就会和资源关联上，就是这么绕！</li>\n</ul>\n<p>现在应该已经解释的很清楚了吧？上面的关系图中最后的account与resource的关系其实是根据前面的关系推出来的，而不是直接可以获取到的（除了在resource的metadata中的那几个特定帐号字段，个人猜测之所有会有这几个metadata，是为了性能）。</p>\n<p>不能确定这么设计是好还是坏，但整体来看，其实并不算复杂。</p>\n","excerpt":"<p>关于google drive的权限设计，一开始看官方文档，搞的云里雾里的！</p>\n<p>可能是对google drive不了解的关系，再加上没有参与设计过类似的平台化系统，所以对于它的权限设计内容，总觉得很绕~<br>","more":"<br>停下来花了点时间仔细捋了一遍，发现这个设计还是非常优雅的，至于通用性，我就持保留态度了！</p>\n<p>首先，我们来列出整套权限系统设计到的元素有哪几个：</p>\n<ul>\n<li>account（帐号）<ul>\n<li>user</li>\n<li>user group</li>\n<li>domain</li>\n<li>anyone</li>\n</ul>\n</li>\n<li>resource（资源）<ul>\n<li>file</li>\n<li>folder</li>\n</ul>\n</li>\n<li>permission（权限设置）<ul>\n<li>role</li>\n<li>type</li>\n</ul>\n</li>\n</ul>\n<p>咱们简单的就这么先罗列出来。</p>\n<p>首先我们先看一下三个主要的元素的关系：</p>\n<pre><code>resource  ------&gt;  permission  ------&gt; account [ ------&gt;  resource]\n          1     n              1     1           n     n\n</code></pre><p>解释：</p>\n<ul>\n<li>一个资源对应多个权限设置</li>\n<li>一个资源的metadata中还会包含多个特定帐号（owners, sharingUser, lastModifyingUser）</li>\n<li>一个权限设置绑定到多个帐号（根据type来确定和帐号的绑定类型，根据domain和emailAddress来确定具体哪个或哪些帐号）</li>\n<li>一个权限设置会预先设定好几个拥有不同操作范围的角色（role），具体关系可以看<a href=\"https://developers.google.com/drive/v3/web/manage-sharing#roles\">官方文档</a></li>\n<li>最终，帐号就会和资源关联上，就是这么绕！</li>\n</ul>\n<p>现在应该已经解释的很清楚了吧？上面的关系图中最后的account与resource的关系其实是根据前面的关系推出来的，而不是直接可以获取到的（除了在resource的metadata中的那几个特定帐号字段，个人猜测之所有会有这几个metadata，是为了性能）。</p>\n<p>不能确定这么设计是好还是坏，但整体来看，其实并不算复杂。</p>"},{"title":"关于使用api为google-doc创建带anchor的comment的问题","date":"2016-03-08T01:37:00.000Z","_content":"\n这个问题，如果你跟我一样只从google提供的[官方文档](https://developers.google.com/drive/v3/web/manage-comments#anchoring_comments)上理解的话，那么你肯定是无法明白这篇文章的问题指的是啥？\n<!--more-->\n使用官方提供的接口调用工具，你无论如何都无法给你google drive中指定的google document创建带有anchor的comment的！\n\n为嘛？\n\n官方不是说的很清楚么，是不是你拼接的json字符串有问题？或者，你的region定义的有问题？或者是不是你用错了region classifier？\n\n我只想说：呵呵~\n\n再查看了不少资料后，发现其实很多人都吐槽这个细节，官方对anchor的注意事项确实解释的很清楚，但却没有讲清楚一个问题：\n\n**到底google doc是不是plain-text类型的文件？？**\n\n你如果像我一样把它当成是普通的plain-text，你就也会想我一样浪费太久的时间在这个问题上！\n\n目前能查到的资料上都解释说，到目前为止你还是无法通过api实现对google doc添加绑定anchor的comment，所以，死心吧！\n","source":"_posts/关于为google-doc创建带anchor的comment的问题.md","raw":"title:  关于使用api为google-doc创建带anchor的comment的问题\ndate: 2016-03-08 09:37:00\ntags:\n- google\n- anchor\n- api\ncategories: 前端\n---\n\n这个问题，如果你跟我一样只从google提供的[官方文档](https://developers.google.com/drive/v3/web/manage-comments#anchoring_comments)上理解的话，那么你肯定是无法明白这篇文章的问题指的是啥？\n<!--more-->\n使用官方提供的接口调用工具，你无论如何都无法给你google drive中指定的google document创建带有anchor的comment的！\n\n为嘛？\n\n官方不是说的很清楚么，是不是你拼接的json字符串有问题？或者，你的region定义的有问题？或者是不是你用错了region classifier？\n\n我只想说：呵呵~\n\n再查看了不少资料后，发现其实很多人都吐槽这个细节，官方对anchor的注意事项确实解释的很清楚，但却没有讲清楚一个问题：\n\n**到底google doc是不是plain-text类型的文件？？**\n\n你如果像我一样把它当成是普通的plain-text，你就也会想我一样浪费太久的时间在这个问题上！\n\n目前能查到的资料上都解释说，到目前为止你还是无法通过api实现对google doc添加绑定anchor的comment，所以，死心吧！\n","slug":"关于为google-doc创建带anchor的comment的问题","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cilp4udnq0008l1fy0ug8esl7","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这个问题，如果你跟我一样只从google提供的<a href=\"https://developers.google.com/drive/v3/web/manage-comments#anchoring_comments\" target=\"_blank\" rel=\"external\">官方文档</a>上理解的话，那么你肯定是无法明白这篇文章的问题指的是啥？<br><a id=\"more\"></a><br>使用官方提供的接口调用工具，你无论如何都无法给你google drive中指定的google document创建带有anchor的comment的！</p>\n<p>为嘛？</p>\n<p>官方不是说的很清楚么，是不是你拼接的json字符串有问题？或者，你的region定义的有问题？或者是不是你用错了region classifier？</p>\n<p>我只想说：呵呵~</p>\n<p>再查看了不少资料后，发现其实很多人都吐槽这个细节，官方对anchor的注意事项确实解释的很清楚，但却没有讲清楚一个问题：</p>\n<p><strong>到底google doc是不是plain-text类型的文件？？</strong></p>\n<p>你如果像我一样把它当成是普通的plain-text，你就也会想我一样浪费太久的时间在这个问题上！</p>\n<p>目前能查到的资料上都解释说，到目前为止你还是无法通过api实现对google doc添加绑定anchor的comment，所以，死心吧！</p>\n","excerpt":"<p>这个问题，如果你跟我一样只从google提供的<a href=\"https://developers.google.com/drive/v3/web/manage-comments#anchoring_comments\">官方文档</a>上理解的话，那么你肯定是无法明白这篇文章的问题指的是啥？<br>","more":"<br>使用官方提供的接口调用工具，你无论如何都无法给你google drive中指定的google document创建带有anchor的comment的！</p>\n<p>为嘛？</p>\n<p>官方不是说的很清楚么，是不是你拼接的json字符串有问题？或者，你的region定义的有问题？或者是不是你用错了region classifier？</p>\n<p>我只想说：呵呵~</p>\n<p>再查看了不少资料后，发现其实很多人都吐槽这个细节，官方对anchor的注意事项确实解释的很清楚，但却没有讲清楚一个问题：</p>\n<p><strong>到底google doc是不是plain-text类型的文件？？</strong></p>\n<p>你如果像我一样把它当成是普通的plain-text，你就也会想我一样浪费太久的时间在这个问题上！</p>\n<p>目前能查到的资料上都解释说，到目前为止你还是无法通过api实现对google doc添加绑定anchor的comment，所以，死心吧！</p>"},{"title":"window下mysql5.7无法启动","date":"2016-03-20T01:37:00.000Z","_content":"\n放了个周末，第一天上班就发现mysql无法启动了，阿西吧~\n一大早就先整了一个小时，真是不划算啊~\n<!--more-->\n之前都是使用集成开发环境，很少自己手动安装mysql，不过由于这次必须使用mysql5.7，而集成环境自带的mysql版本不够（或者直接提供的是MariaDB）,所以只能自己安装了~\n\n直接下载mysql5.7的window安装器，很简单就装好了，所以也没有特别在意，简单修改了一下my.ini就用了一个多礼拜~\n上周六关机的时候电源断早了，所以今天开机发现window开机提示非法关机了，导致我的工作区都丢了，郁闷！（平时我都是休眠系统的！）\n\n启动到桌面后，发现mysql无法启动了！好灵异，更奇怪的是，我看了一下my.ini都自动给我恢复成my.default.ini了！草！\nmysql安装的时候我也没有把它加到服务中，这下好了，我tm无法启动它了！\n\n网上查了一下，win下，可以执行下面的命令（后面所有命令都建议在管理员权限下做）：\n\n\tmysqld  --initialize\n\n前提是，你得先有一个my.ini，并配置好basedir，basedir指向的文件夹也要有对应文件夹啊~\n\n这一步做完，mysql会初始化创建它要使用的data数据！（这不是废话么！）\n\n然后将mysql加入到win的系统服务中：\n \n\tmysqld --install MySQL \n  \n或者先卸载服务:\n\n\tmysqld --remove\n\n完事儿了你基本上就已经可以启动你的mysql服务了！\n然后你还不能高兴过头！因为，密码也丢了！！！\n\n网上很多资料讲的找回密码方案在mysql5.7下似乎都不管用了！\n我只能，在我的my.ini文件中加入下面这个参数：\n\n\tskip-grant-tables\n\n除此之外，难倒我只能选择重新安装mysql了么？要知道卸载mysql也不是一件容易事儿啊~\n难倒我只能重装操作系统了吗？\n\n谁有高招，求赐教！\n","source":"_posts/windows下mysql5.7无法启动.md","raw":"title:  window下mysql5.7无法启动\ndate: 2016-03-20 09:37:00\ntags:\n- mysql\n- window\n- 密码\ncategories: 运维,数据库\n---\n\n放了个周末，第一天上班就发现mysql无法启动了，阿西吧~\n一大早就先整了一个小时，真是不划算啊~\n<!--more-->\n之前都是使用集成开发环境，很少自己手动安装mysql，不过由于这次必须使用mysql5.7，而集成环境自带的mysql版本不够（或者直接提供的是MariaDB）,所以只能自己安装了~\n\n直接下载mysql5.7的window安装器，很简单就装好了，所以也没有特别在意，简单修改了一下my.ini就用了一个多礼拜~\n上周六关机的时候电源断早了，所以今天开机发现window开机提示非法关机了，导致我的工作区都丢了，郁闷！（平时我都是休眠系统的！）\n\n启动到桌面后，发现mysql无法启动了！好灵异，更奇怪的是，我看了一下my.ini都自动给我恢复成my.default.ini了！草！\nmysql安装的时候我也没有把它加到服务中，这下好了，我tm无法启动它了！\n\n网上查了一下，win下，可以执行下面的命令（后面所有命令都建议在管理员权限下做）：\n\n\tmysqld  --initialize\n\n前提是，你得先有一个my.ini，并配置好basedir，basedir指向的文件夹也要有对应文件夹啊~\n\n这一步做完，mysql会初始化创建它要使用的data数据！（这不是废话么！）\n\n然后将mysql加入到win的系统服务中：\n \n\tmysqld --install MySQL \n  \n或者先卸载服务:\n\n\tmysqld --remove\n\n完事儿了你基本上就已经可以启动你的mysql服务了！\n然后你还不能高兴过头！因为，密码也丢了！！！\n\n网上很多资料讲的找回密码方案在mysql5.7下似乎都不管用了！\n我只能，在我的my.ini文件中加入下面这个参数：\n\n\tskip-grant-tables\n\n除此之外，难倒我只能选择重新安装mysql了么？要知道卸载mysql也不是一件容易事儿啊~\n难倒我只能重装操作系统了吗？\n\n谁有高招，求赐教！\n","slug":"windows下mysql5.7无法启动","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cima1so5c0000vofym5ugnxte","comments":1,"layout":"post","photos":[],"link":"","content":"<p>放了个周末，第一天上班就发现mysql无法启动了，阿西吧~<br>一大早就先整了一个小时，真是不划算啊~<br><a id=\"more\"></a><br>之前都是使用集成开发环境，很少自己手动安装mysql，不过由于这次必须使用mysql5.7，而集成环境自带的mysql版本不够（或者直接提供的是MariaDB）,所以只能自己安装了~</p>\n<p>直接下载mysql5.7的window安装器，很简单就装好了，所以也没有特别在意，简单修改了一下my.ini就用了一个多礼拜~<br>上周六关机的时候电源断早了，所以今天开机发现window开机提示非法关机了，导致我的工作区都丢了，郁闷！（平时我都是休眠系统的！）</p>\n<p>启动到桌面后，发现mysql无法启动了！好灵异，更奇怪的是，我看了一下my.ini都自动给我恢复成my.default.ini了！草！<br>mysql安装的时候我也没有把它加到服务中，这下好了，我tm无法启动它了！</p>\n<p>网上查了一下，win下，可以执行下面的命令（后面所有命令都建议在管理员权限下做）：</p>\n<pre><code>mysqld  --initialize\n</code></pre><p>前提是，你得先有一个my.ini，并配置好basedir，basedir指向的文件夹也要有对应文件夹啊~</p>\n<p>这一步做完，mysql会初始化创建它要使用的data数据！（这不是废话么！）</p>\n<p>然后将mysql加入到win的系统服务中：</p>\n<pre><code>mysqld --install MySQL \n</code></pre><p>或者先卸载服务:</p>\n<pre><code>mysqld --remove\n</code></pre><p>完事儿了你基本上就已经可以启动你的mysql服务了！<br>然后你还不能高兴过头！因为，密码也丢了！！！</p>\n<p>网上很多资料讲的找回密码方案在mysql5.7下似乎都不管用了！<br>我只能，在我的my.ini文件中加入下面这个参数：</p>\n<pre><code>skip-grant-tables\n</code></pre><p>除此之外，难倒我只能选择重新安装mysql了么？要知道卸载mysql也不是一件容易事儿啊~<br>难倒我只能重装操作系统了吗？</p>\n<p>谁有高招，求赐教！</p>\n","excerpt":"<p>放了个周末，第一天上班就发现mysql无法启动了，阿西吧~<br>一大早就先整了一个小时，真是不划算啊~<br>","more":"<br>之前都是使用集成开发环境，很少自己手动安装mysql，不过由于这次必须使用mysql5.7，而集成环境自带的mysql版本不够（或者直接提供的是MariaDB）,所以只能自己安装了~</p>\n<p>直接下载mysql5.7的window安装器，很简单就装好了，所以也没有特别在意，简单修改了一下my.ini就用了一个多礼拜~<br>上周六关机的时候电源断早了，所以今天开机发现window开机提示非法关机了，导致我的工作区都丢了，郁闷！（平时我都是休眠系统的！）</p>\n<p>启动到桌面后，发现mysql无法启动了！好灵异，更奇怪的是，我看了一下my.ini都自动给我恢复成my.default.ini了！草！<br>mysql安装的时候我也没有把它加到服务中，这下好了，我tm无法启动它了！</p>\n<p>网上查了一下，win下，可以执行下面的命令（后面所有命令都建议在管理员权限下做）：</p>\n<pre><code>mysqld  --initialize\n</code></pre><p>前提是，你得先有一个my.ini，并配置好basedir，basedir指向的文件夹也要有对应文件夹啊~</p>\n<p>这一步做完，mysql会初始化创建它要使用的data数据！（这不是废话么！）</p>\n<p>然后将mysql加入到win的系统服务中：</p>\n<pre><code>mysqld --install MySQL \n</code></pre><p>或者先卸载服务:</p>\n<pre><code>mysqld --remove\n</code></pre><p>完事儿了你基本上就已经可以启动你的mysql服务了！<br>然后你还不能高兴过头！因为，密码也丢了！！！</p>\n<p>网上很多资料讲的找回密码方案在mysql5.7下似乎都不管用了！<br>我只能，在我的my.ini文件中加入下面这个参数：</p>\n<pre><code>skip-grant-tables\n</code></pre><p>除此之外，难倒我只能选择重新安装mysql了么？要知道卸载mysql也不是一件容易事儿啊~<br>难倒我只能重装操作系统了吗？</p>\n<p>谁有高招，求赐教！</p>"},{"title":"忙里偷闲说说atom","date":"2016-03-24T01:37:00.000Z","_content":"\n好久没有摆弄开发工具了，若不是换了新的环境，可能也不会折腾开发环境啊~\n自从切换到facebook技术栈下后，一直就在使用Atom，把mac下所有其他的编辑器都卸载了！可见是真爱！\n<!--more-->\n可是一直都没有特意的去研究atom，前几天装了一个推荐的皮肤：Seti-UI，瞬间感觉眼前一亮，不仅美观，而且实用！强烈推荐~\n\n然后就是推荐一个插件：\n\n> Atom-beautify\n\n这样你就可以不再被“别人”写的垃圾代码干扰了，一键“ctrl+alt+b”格式化代码排版，真刺激！\n\n还有一个比较实用的操作，就是多光标编辑，不需要记热键，只需要按住“ctrl”，双击鼠标即可！\n\n最后一个热键组合：ctrl+d，快速选择距离最近的相同标签！\n\n我这人记性差，再多的热键我就记不住了~~\n\n有兴趣的童靴可以去看[这里](http://www.jianshu.com/p/aa8f8a252ed9)\n","source":"_posts/忙里偷闲说说atom.md","raw":"title:  忙里偷闲说说atom\ndate: 2016-03-24 09:37:00\ntags:\n- atom\n- 代码排版\n- 皮肤\n- 插件\n- 快捷键\ncategories: 前端\n---\n\n好久没有摆弄开发工具了，若不是换了新的环境，可能也不会折腾开发环境啊~\n自从切换到facebook技术栈下后，一直就在使用Atom，把mac下所有其他的编辑器都卸载了！可见是真爱！\n<!--more-->\n可是一直都没有特意的去研究atom，前几天装了一个推荐的皮肤：Seti-UI，瞬间感觉眼前一亮，不仅美观，而且实用！强烈推荐~\n\n然后就是推荐一个插件：\n\n> Atom-beautify\n\n这样你就可以不再被“别人”写的垃圾代码干扰了，一键“ctrl+alt+b”格式化代码排版，真刺激！\n\n还有一个比较实用的操作，就是多光标编辑，不需要记热键，只需要按住“ctrl”，双击鼠标即可！\n\n最后一个热键组合：ctrl+d，快速选择距离最近的相同标签！\n\n我这人记性差，再多的热键我就记不住了~~\n\n有兴趣的童靴可以去看[这里](http://www.jianshu.com/p/aa8f8a252ed9)\n","slug":"忙里偷闲说说atom","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cima1so9h0009vofy03l20gsf","comments":1,"layout":"post","photos":[],"link":"","content":"<p>好久没有摆弄开发工具了，若不是换了新的环境，可能也不会折腾开发环境啊~<br>自从切换到facebook技术栈下后，一直就在使用Atom，把mac下所有其他的编辑器都卸载了！可见是真爱！<br><a id=\"more\"></a><br>可是一直都没有特意的去研究atom，前几天装了一个推荐的皮肤：Seti-UI，瞬间感觉眼前一亮，不仅美观，而且实用！强烈推荐~</p>\n<p>然后就是推荐一个插件：</p>\n<blockquote>\n<p>Atom-beautify</p>\n</blockquote>\n<p>这样你就可以不再被“别人”写的垃圾代码干扰了，一键“ctrl+alt+b”格式化代码排版，真刺激！</p>\n<p>还有一个比较实用的操作，就是多光标编辑，不需要记热键，只需要按住“ctrl”，双击鼠标即可！</p>\n<p>最后一个热键组合：ctrl+d，快速选择距离最近的相同标签！</p>\n<p>我这人记性差，再多的热键我就记不住了~~</p>\n<p>有兴趣的童靴可以去看<a href=\"http://www.jianshu.com/p/aa8f8a252ed9\" target=\"_blank\" rel=\"external\">这里</a></p>\n","excerpt":"<p>好久没有摆弄开发工具了，若不是换了新的环境，可能也不会折腾开发环境啊~<br>自从切换到facebook技术栈下后，一直就在使用Atom，把mac下所有其他的编辑器都卸载了！可见是真爱！<br>","more":"<br>可是一直都没有特意的去研究atom，前几天装了一个推荐的皮肤：Seti-UI，瞬间感觉眼前一亮，不仅美观，而且实用！强烈推荐~</p>\n<p>然后就是推荐一个插件：</p>\n<blockquote>\n<p>Atom-beautify</p>\n</blockquote>\n<p>这样你就可以不再被“别人”写的垃圾代码干扰了，一键“ctrl+alt+b”格式化代码排版，真刺激！</p>\n<p>还有一个比较实用的操作，就是多光标编辑，不需要记热键，只需要按住“ctrl”，双击鼠标即可！</p>\n<p>最后一个热键组合：ctrl+d，快速选择距离最近的相同标签！</p>\n<p>我这人记性差，再多的热键我就记不住了~~</p>\n<p>有兴趣的童靴可以去看<a href=\"http://www.jianshu.com/p/aa8f8a252ed9\">这里</a></p>"},{"title":"SDKMAN安装的库位置给哪呢","date":"2016-03-31T01:37:00.000Z","_content":"\n\n废话不多说，直接教你做人：\n\nMac下终端输入：\n\n\techo $PATH\n\t\n会看到类下面的输出：\n\n\t/Users/kazaff/.sdkman/candidates/xxxxxxxxx\n\t\n知道了给哪了吧？bye~","source":"_posts/SDKMAN安装的库位置给哪呢.md","raw":"title:  SDKMAN安装的库位置给哪呢\ndate: 2016-03-31 09:37:00\ntags:\n- SDKMAN\n- path\ncategories: groovy\n---\n\n\n废话不多说，直接教你做人：\n\nMac下终端输入：\n\n\techo $PATH\n\t\n会看到类下面的输出：\n\n\t/Users/kazaff/.sdkman/candidates/xxxxxxxxx\n\t\n知道了给哪了吧？bye~","slug":"SDKMAN安装的库位置给哪呢","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cimjc5pz600001nfy66rl525r","comments":1,"layout":"post","photos":[],"link":"","content":"<p>废话不多说，直接教你做人：</p>\n<p>Mac下终端输入：</p>\n<pre><code>echo $PATH\n</code></pre><p>会看到类下面的输出：</p>\n<pre><code>/Users/kazaff/.sdkman/candidates/xxxxxxxxx\n</code></pre><p>知道了给哪了吧？bye~</p>\n","excerpt":"","more":"<p>废话不多说，直接教你做人：</p>\n<p>Mac下终端输入：</p>\n<pre><code>echo $PATH\n</code></pre><p>会看到类下面的输出：</p>\n<pre><code>/Users/kazaff/.sdkman/candidates/xxxxxxxxx\n</code></pre><p>知道了给哪了吧？bye~</p>\n"},{"title":"如何禁止chrome自动跳转https","date":"2016-04-02T01:37:00.000Z","_content":"\n首先我声明，我非常支持https。\n\n之所以要写这篇文章，主要是因为我碰到了一个很尴尬的事儿！待我慢慢道来~\n\n之前给网上看到一篇文章，是教你如何简单的借助一个服务（我忘记名字了）为你的github pages项目来开通https支持，我的博客是hexo的，所以当然也是放在github pages上的！\n\n那个服务确实很给力，在我根据指南，配置好后（域名解析）几乎是一键开启https！美翻了！但是我发现可能小众问题吧，我的博客没过多久访问时就提示域名解析异常，再次到那个服务后台去配置，就发现提示域名所属权校验失败！\n\n本以为重新配置一下就可以了，结果又碰到了二级域名导致它提供的配置无法通过校验（首次没问题我也很纳闷！）~好了，说道这里，基本上这件事儿的背景也就差不多解释清楚了！\n\n既然如此，我自然会放弃使用那个服务，所以我把域名解析重新直接解析到github pages上！但是，问题来了，之前所有使用过https访问我域名的chrome再也无法使用http来访问我的网站了！\n\n一直提示网站出现安全异常，阿西吧！\n\n后来网上搜了一下，找到了解决方案，其实很简单，请在chrome的地址栏输入：\n\n\tchrome://net-internals/#hsts\n\t\n在打开的页面中，`Delete domain`栏的输入框中输入：blog.kazaff.me（注意这里是二级域名），然后点击“delete”按钮，即可完成配置。\n\n然后你可以在`Query domain`栏中搜索刚才输入的域名，点击“query”按钮后如果提示“Not found”，那么你现在就可以使用http来访问我的网站了！\n\n虽然，你可能从来没有访问过我的网站~~哇哈哈哈哈","source":"_posts/如何禁止chrome自动跳转https.md","raw":"title:  如何禁止chrome自动跳转https\ndate: 2016-04-02 09:37:00\ntags:\n- chrome\n- https\n- 自动跳转\ncategories: talk\n---\n\n首先我声明，我非常支持https。\n\n之所以要写这篇文章，主要是因为我碰到了一个很尴尬的事儿！待我慢慢道来~\n\n之前给网上看到一篇文章，是教你如何简单的借助一个服务（我忘记名字了）为你的github pages项目来开通https支持，我的博客是hexo的，所以当然也是放在github pages上的！\n\n那个服务确实很给力，在我根据指南，配置好后（域名解析）几乎是一键开启https！美翻了！但是我发现可能小众问题吧，我的博客没过多久访问时就提示域名解析异常，再次到那个服务后台去配置，就发现提示域名所属权校验失败！\n\n本以为重新配置一下就可以了，结果又碰到了二级域名导致它提供的配置无法通过校验（首次没问题我也很纳闷！）~好了，说道这里，基本上这件事儿的背景也就差不多解释清楚了！\n\n既然如此，我自然会放弃使用那个服务，所以我把域名解析重新直接解析到github pages上！但是，问题来了，之前所有使用过https访问我域名的chrome再也无法使用http来访问我的网站了！\n\n一直提示网站出现安全异常，阿西吧！\n\n后来网上搜了一下，找到了解决方案，其实很简单，请在chrome的地址栏输入：\n\n\tchrome://net-internals/#hsts\n\t\n在打开的页面中，`Delete domain`栏的输入框中输入：blog.kazaff.me（注意这里是二级域名），然后点击“delete”按钮，即可完成配置。\n\n然后你可以在`Query domain`栏中搜索刚才输入的域名，点击“query”按钮后如果提示“Not found”，那么你现在就可以使用http来访问我的网站了！\n\n虽然，你可能从来没有访问过我的网站~~哇哈哈哈哈","slug":"如何禁止chrome自动跳转https","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cimjc5q4100091nfyjdukfzip","comments":1,"layout":"post","photos":[],"link":"","content":"<p>首先我声明，我非常支持https。</p>\n<p>之所以要写这篇文章，主要是因为我碰到了一个很尴尬的事儿！待我慢慢道来~</p>\n<p>之前给网上看到一篇文章，是教你如何简单的借助一个服务（我忘记名字了）为你的github pages项目来开通https支持，我的博客是hexo的，所以当然也是放在github pages上的！</p>\n<p>那个服务确实很给力，在我根据指南，配置好后（域名解析）几乎是一键开启https！美翻了！但是我发现可能小众问题吧，我的博客没过多久访问时就提示域名解析异常，再次到那个服务后台去配置，就发现提示域名所属权校验失败！</p>\n<p>本以为重新配置一下就可以了，结果又碰到了二级域名导致它提供的配置无法通过校验（首次没问题我也很纳闷！）~好了，说道这里，基本上这件事儿的背景也就差不多解释清楚了！</p>\n<p>既然如此，我自然会放弃使用那个服务，所以我把域名解析重新直接解析到github pages上！但是，问题来了，之前所有使用过https访问我域名的chrome再也无法使用http来访问我的网站了！</p>\n<p>一直提示网站出现安全异常，阿西吧！</p>\n<p>后来网上搜了一下，找到了解决方案，其实很简单，请在chrome的地址栏输入：</p>\n<pre><code>chrome://net-internals/#hsts\n</code></pre><p>在打开的页面中，<code>Delete domain</code>栏的输入框中输入：blog.kazaff.me（注意这里是二级域名），然后点击“delete”按钮，即可完成配置。</p>\n<p>然后你可以在<code>Query domain</code>栏中搜索刚才输入的域名，点击“query”按钮后如果提示“Not found”，那么你现在就可以使用http来访问我的网站了！</p>\n<p>虽然，你可能从来没有访问过我的网站~~哇哈哈哈哈</p>\n","excerpt":"","more":"<p>首先我声明，我非常支持https。</p>\n<p>之所以要写这篇文章，主要是因为我碰到了一个很尴尬的事儿！待我慢慢道来~</p>\n<p>之前给网上看到一篇文章，是教你如何简单的借助一个服务（我忘记名字了）为你的github pages项目来开通https支持，我的博客是hexo的，所以当然也是放在github pages上的！</p>\n<p>那个服务确实很给力，在我根据指南，配置好后（域名解析）几乎是一键开启https！美翻了！但是我发现可能小众问题吧，我的博客没过多久访问时就提示域名解析异常，再次到那个服务后台去配置，就发现提示域名所属权校验失败！</p>\n<p>本以为重新配置一下就可以了，结果又碰到了二级域名导致它提供的配置无法通过校验（首次没问题我也很纳闷！）~好了，说道这里，基本上这件事儿的背景也就差不多解释清楚了！</p>\n<p>既然如此，我自然会放弃使用那个服务，所以我把域名解析重新直接解析到github pages上！但是，问题来了，之前所有使用过https访问我域名的chrome再也无法使用http来访问我的网站了！</p>\n<p>一直提示网站出现安全异常，阿西吧！</p>\n<p>后来网上搜了一下，找到了解决方案，其实很简单，请在chrome的地址栏输入：</p>\n<pre><code>chrome://net-internals/#hsts\n</code></pre><p>在打开的页面中，<code>Delete domain</code>栏的输入框中输入：blog.kazaff.me（注意这里是二级域名），然后点击“delete”按钮，即可完成配置。</p>\n<p>然后你可以在<code>Query domain</code>栏中搜索刚才输入的域名，点击“query”按钮后如果提示“Not found”，那么你现在就可以使用http来访问我的网站了！</p>\n<p>虽然，你可能从来没有访问过我的网站~~哇哈哈哈哈</p>\n"},{"title":"groovy下的field和property","date":"2016-04-01T01:37:00.000Z","_content":"\n今天要聊的这个话题，是基于一个很有意思的jvm语言：groovy！有好奇心的童靴不妨去了解一下它的风骚~\n\n在java bean的定义中，一般都会为这个bean设置一些属性，然后按照javabean规范会创建getter和setter方法~（你是否也早已经烦透了这种样板代码？）\n<!--more-->\ngroovy的哲学，就是在表达清晰的前提下让你尽可能少和样板代码打交道！而我们要讨论的，就是与java bean看起来极其相似的groovy bean！\n\n本文一下内容，翻译自[groovy bean](http://groovy.jmiguel.eu/groovy.codehaus.org/Groovy+Beans.html)\n\n---\n\ngroovy bean 就是 java bean，但是提供了大量的简化语法！\n\n```groovy\n\tclass Customer {\n\t\t// properties\n\t\tInteger id\n\t\tString name\n\t\tDate dob\n\n\t\t// sample code\n\t\tstatic void main(args) {\n\t\t\t\tdef customer = new Customer(id:1, name:\"Gromit\", dob:new Date())\n\t\t\t\tprintln(\"Hello ${customer.name}\")\n\t\t}\n\t}\n```\n执行上面的代码后会看到输出\n\n\tHello Gromit\n\n可以看到property似乎就好像是公开的类field。你甚至可以在构造函数里为这些property初始化。在groovy里，field和property的概念被合并了，它们不仅看起来一样，使用起来也一样。因此，上面的groovy代码和下面的java代码是等价的：\n\n```java\n\timport java.util.Date;\n\n\tpublic class Customer {\n\t    // properties\n\t    private Integer id;\n\t    private String name;\n\t    private Date dob;\n\n\t    public Integer getId() {\n\t        return this.id;\n\t    }\n\n\t    public String getName() {\n\t        return this.name;\n\t    }\n\n\t    public Date getDob() {\n\t        return this.dob;\n\t    }\n\n\t    public void setId(Integer id) {\n\t        this.id = id;\n\t    }\n\n\t    public void setName(String name) {\n\t        this.name = name;\n\t    }\n\n\t    public void setDob(Date dob) {\n\t        this.dob = dob;\n\t    }\n\n\t    // sample code\n\t    public static void main(String[] args) {\n\t        Customer customer = new Customer();\n\t        customer.setId(1);\n\t        customer.setName(\"Gromit\");\n\t        customer.setDob(new Date());\n\n\t        System.out.println(\"Hello \" + customer.getName());\n\t    }\n\t}\n```\n\n我们来看看property和field的一些规则~\n\n当groovy被编译成字节码文件后，将遵守下面的规则：\n\n- 如果声明时为name明确指定了一个操作限定符（public，private或protected）则将会创建一个field\n- 若没有指定任何操作限定符，则该name将被创建为private field并且自动创建getter和setter方法（就是一个property）\n- 如果property被定义为final，则创建的private field同样是final，且不会自动创建setter方法\n- 你可以声明一个property，并且自己实现getter和setter方法（译者注：多半是在学习这个知识点的时候才会这么做吧~）\n- 你可以同时定义相同name的property和field，此时property会默认使用同名的field（译者注：这是要疯了啊）\n- 如果你想要一个private或protected的property，你就必须自己提供满足你操作限定需求的getter和setter方法\n- 如果你在class内部操作property（例如`this.foo`或`foo`），groovy会直接操作对应的field，而不会调用对应的getter或setter方法\n- 如果你试图操作一个不存在property，groovy会通过meta class来操作对应的property，这可能会在运行时失败（译者注：动态语言特性）\n\n现在来看一个例子，创建一个包含只读property的类：\n\n```groovy\n\tclass Foo {\n\t\t// read only property\n\t\t//译者注：使用final，groovy不会为其创建setter方法\n\t\tfinal String name = \"John\"\n\n\t\t// read only property with public getter and protected setter\n\t\tInteger amount\n\t\tprotected void setAmount(Integer amount) { this.amount = amount }\n\n\t\t// dynamically typed property\n\t\tdef cheese\n\t}\n```\n\n注意：property声明是需要一个标识符，或者是明确的类型（如`String`），或者是无类型声明（`def`）。\n\n为什么groovy不会为一个被定义为public的field自动创建getter和setter方法呢？（译者注：极好的问题！）如果我们在任何条件下都自动创建getter和setter方法，意味着groovy下你无法摆脱getter和setter，这在某些你就是不想要getter和setter方法的场景下就傻眼了！（译者注：此段为“随译”，就是随便翻译的意思~哈哈）\n\n#### Closures and listeners\n\n本段和主题关系不大，就不翻译了~\n","source":"_posts/groovy下的field和property.md","raw":"title:  groovy下的field和property\ndate: 2016-04-01 09:37:00\ntags:\n- field\n- property\n- groovy bean\n- getter/setter\ncategories: groovy\n---\n\n今天要聊的这个话题，是基于一个很有意思的jvm语言：groovy！有好奇心的童靴不妨去了解一下它的风骚~\n\n在java bean的定义中，一般都会为这个bean设置一些属性，然后按照javabean规范会创建getter和setter方法~（你是否也早已经烦透了这种样板代码？）\n<!--more-->\ngroovy的哲学，就是在表达清晰的前提下让你尽可能少和样板代码打交道！而我们要讨论的，就是与java bean看起来极其相似的groovy bean！\n\n本文一下内容，翻译自[groovy bean](http://groovy.jmiguel.eu/groovy.codehaus.org/Groovy+Beans.html)\n\n---\n\ngroovy bean 就是 java bean，但是提供了大量的简化语法！\n\n```groovy\n\tclass Customer {\n\t\t// properties\n\t\tInteger id\n\t\tString name\n\t\tDate dob\n\n\t\t// sample code\n\t\tstatic void main(args) {\n\t\t\t\tdef customer = new Customer(id:1, name:\"Gromit\", dob:new Date())\n\t\t\t\tprintln(\"Hello ${customer.name}\")\n\t\t}\n\t}\n```\n执行上面的代码后会看到输出\n\n\tHello Gromit\n\n可以看到property似乎就好像是公开的类field。你甚至可以在构造函数里为这些property初始化。在groovy里，field和property的概念被合并了，它们不仅看起来一样，使用起来也一样。因此，上面的groovy代码和下面的java代码是等价的：\n\n```java\n\timport java.util.Date;\n\n\tpublic class Customer {\n\t    // properties\n\t    private Integer id;\n\t    private String name;\n\t    private Date dob;\n\n\t    public Integer getId() {\n\t        return this.id;\n\t    }\n\n\t    public String getName() {\n\t        return this.name;\n\t    }\n\n\t    public Date getDob() {\n\t        return this.dob;\n\t    }\n\n\t    public void setId(Integer id) {\n\t        this.id = id;\n\t    }\n\n\t    public void setName(String name) {\n\t        this.name = name;\n\t    }\n\n\t    public void setDob(Date dob) {\n\t        this.dob = dob;\n\t    }\n\n\t    // sample code\n\t    public static void main(String[] args) {\n\t        Customer customer = new Customer();\n\t        customer.setId(1);\n\t        customer.setName(\"Gromit\");\n\t        customer.setDob(new Date());\n\n\t        System.out.println(\"Hello \" + customer.getName());\n\t    }\n\t}\n```\n\n我们来看看property和field的一些规则~\n\n当groovy被编译成字节码文件后，将遵守下面的规则：\n\n- 如果声明时为name明确指定了一个操作限定符（public，private或protected）则将会创建一个field\n- 若没有指定任何操作限定符，则该name将被创建为private field并且自动创建getter和setter方法（就是一个property）\n- 如果property被定义为final，则创建的private field同样是final，且不会自动创建setter方法\n- 你可以声明一个property，并且自己实现getter和setter方法（译者注：多半是在学习这个知识点的时候才会这么做吧~）\n- 你可以同时定义相同name的property和field，此时property会默认使用同名的field（译者注：这是要疯了啊）\n- 如果你想要一个private或protected的property，你就必须自己提供满足你操作限定需求的getter和setter方法\n- 如果你在class内部操作property（例如`this.foo`或`foo`），groovy会直接操作对应的field，而不会调用对应的getter或setter方法\n- 如果你试图操作一个不存在property，groovy会通过meta class来操作对应的property，这可能会在运行时失败（译者注：动态语言特性）\n\n现在来看一个例子，创建一个包含只读property的类：\n\n```groovy\n\tclass Foo {\n\t\t// read only property\n\t\t//译者注：使用final，groovy不会为其创建setter方法\n\t\tfinal String name = \"John\"\n\n\t\t// read only property with public getter and protected setter\n\t\tInteger amount\n\t\tprotected void setAmount(Integer amount) { this.amount = amount }\n\n\t\t// dynamically typed property\n\t\tdef cheese\n\t}\n```\n\n注意：property声明是需要一个标识符，或者是明确的类型（如`String`），或者是无类型声明（`def`）。\n\n为什么groovy不会为一个被定义为public的field自动创建getter和setter方法呢？（译者注：极好的问题！）如果我们在任何条件下都自动创建getter和setter方法，意味着groovy下你无法摆脱getter和setter，这在某些你就是不想要getter和setter方法的场景下就傻眼了！（译者注：此段为“随译”，就是随便翻译的意思~哈哈）\n\n#### Closures and listeners\n\n本段和主题关系不大，就不翻译了~\n","slug":"groovy下的field和property","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cimjc5q49000g1nfygx52686o","comments":1,"layout":"post","photos":[],"link":"","content":"<p>今天要聊的这个话题，是基于一个很有意思的jvm语言：groovy！有好奇心的童靴不妨去了解一下它的风骚~</p>\n<p>在java bean的定义中，一般都会为这个bean设置一些属性，然后按照javabean规范会创建getter和setter方法~（你是否也早已经烦透了这种样板代码？）<br><a id=\"more\"></a><br>groovy的哲学，就是在表达清晰的前提下让你尽可能少和样板代码打交道！而我们要讨论的，就是与java bean看起来极其相似的groovy bean！</p>\n<p>本文一下内容，翻译自<a href=\"http://groovy.jmiguel.eu/groovy.codehaus.org/Groovy+Beans.html\" target=\"_blank\" rel=\"external\">groovy bean</a></p>\n<hr>\n<p>groovy bean 就是 java bean，但是提供了大量的简化语法！</p>\n<figure class=\"highlight groovy\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Customer</span> &#123;</span></span><br><span class=\"line\">\t<span class=\"comment\">// properties</span></span><br><span class=\"line\">\tInteger id</span><br><span class=\"line\">\tString name</span><br><span class=\"line\">\tDate dob</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// sample code</span></span><br><span class=\"line\">\t<span class=\"keyword\">static</span> <span class=\"keyword\">void</span> main(args) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">def</span> customer = <span class=\"keyword\">new</span> Customer(<span class=\"string\">id:</span><span class=\"number\">1</span>, <span class=\"string\">name:</span><span class=\"string\">\"Gromit\"</span>, <span class=\"string\">dob:</span><span class=\"keyword\">new</span> Date())</span><br><span class=\"line\">\t\t\tprintln(<span class=\"string\">\"Hello $&#123;customer.name&#125;\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行上面的代码后会看到输出</p>\n<pre><code>Hello Gromit\n</code></pre><p>可以看到property似乎就好像是公开的类field。你甚至可以在构造函数里为这些property初始化。在groovy里，field和property的概念被合并了，它们不仅看起来一样，使用起来也一样。因此，上面的groovy代码和下面的java代码是等价的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.util.Date;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Customer</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// properties</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Integer id;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Date dob;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Integer <span class=\"title\">getId</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.id;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getName</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Date <span class=\"title\">getDob</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.dob;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setId</span><span class=\"params\">(Integer id)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.id = id;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setName</span><span class=\"params\">(String name)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.name = name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setDob</span><span class=\"params\">(Date dob)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.dob = dob;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// sample code</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Customer customer = <span class=\"keyword\">new</span> Customer();</span><br><span class=\"line\">        customer.setId(<span class=\"number\">1</span>);</span><br><span class=\"line\">        customer.setName(<span class=\"string\">\"Gromit\"</span>);</span><br><span class=\"line\">        customer.setDob(<span class=\"keyword\">new</span> Date());</span><br><span class=\"line\"></span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Hello \"</span> + customer.getName());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们来看看property和field的一些规则~</p>\n<p>当groovy被编译成字节码文件后，将遵守下面的规则：</p>\n<ul>\n<li>如果声明时为name明确指定了一个操作限定符（public，private或protected）则将会创建一个field</li>\n<li>若没有指定任何操作限定符，则该name将被创建为private field并且自动创建getter和setter方法（就是一个property）</li>\n<li>如果property被定义为final，则创建的private field同样是final，且不会自动创建setter方法</li>\n<li>你可以声明一个property，并且自己实现getter和setter方法（译者注：多半是在学习这个知识点的时候才会这么做吧~）</li>\n<li>你可以同时定义相同name的property和field，此时property会默认使用同名的field（译者注：这是要疯了啊）</li>\n<li>如果你想要一个private或protected的property，你就必须自己提供满足你操作限定需求的getter和setter方法</li>\n<li>如果你在class内部操作property（例如<code>this.foo</code>或<code>foo</code>），groovy会直接操作对应的field，而不会调用对应的getter或setter方法</li>\n<li>如果你试图操作一个不存在property，groovy会通过meta class来操作对应的property，这可能会在运行时失败（译者注：动态语言特性）</li>\n</ul>\n<p>现在来看一个例子，创建一个包含只读property的类：</p>\n<figure class=\"highlight groovy\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Foo</span> &#123;</span></span><br><span class=\"line\">\t<span class=\"comment\">// read only property</span></span><br><span class=\"line\">\t<span class=\"comment\">//译者注：使用final，groovy不会为其创建setter方法</span></span><br><span class=\"line\">\t<span class=\"keyword\">final</span> String name = <span class=\"string\">\"John\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// read only property with public getter and protected setter</span></span><br><span class=\"line\">\tInteger amount</span><br><span class=\"line\">\t<span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> setAmount(Integer amount) &#123; <span class=\"keyword\">this</span>.amount = amount &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// dynamically typed property</span></span><br><span class=\"line\">\t<span class=\"keyword\">def</span> cheese</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>注意：property声明是需要一个标识符，或者是明确的类型（如<code>String</code>），或者是无类型声明（<code>def</code>）。</p>\n<p>为什么groovy不会为一个被定义为public的field自动创建getter和setter方法呢？（译者注：极好的问题！）如果我们在任何条件下都自动创建getter和setter方法，意味着groovy下你无法摆脱getter和setter，这在某些你就是不想要getter和setter方法的场景下就傻眼了！（译者注：此段为“随译”，就是随便翻译的意思~哈哈）</p>\n<h4 id=\"Closures-and-listeners\"><a href=\"#Closures-and-listeners\" class=\"headerlink\" title=\"Closures and listeners\"></a>Closures and listeners</h4><p>本段和主题关系不大，就不翻译了~</p>\n","excerpt":"<p>今天要聊的这个话题，是基于一个很有意思的jvm语言：groovy！有好奇心的童靴不妨去了解一下它的风骚~</p>\n<p>在java bean的定义中，一般都会为这个bean设置一些属性，然后按照javabean规范会创建getter和setter方法~（你是否也早已经烦透了这种样板代码？）<br>","more":"<br>groovy的哲学，就是在表达清晰的前提下让你尽可能少和样板代码打交道！而我们要讨论的，就是与java bean看起来极其相似的groovy bean！</p>\n<p>本文一下内容，翻译自<a href=\"http://groovy.jmiguel.eu/groovy.codehaus.org/Groovy+Beans.html\">groovy bean</a></p>\n<hr>\n<p>groovy bean 就是 java bean，但是提供了大量的简化语法！</p>\n<figure class=\"highlight groovy\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Customer</span> &#123;</span></span><br><span class=\"line\">\t<span class=\"comment\">// properties</span></span><br><span class=\"line\">\tInteger id</span><br><span class=\"line\">\tString name</span><br><span class=\"line\">\tDate dob</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// sample code</span></span><br><span class=\"line\">\t<span class=\"keyword\">static</span> <span class=\"keyword\">void</span> main(args) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">def</span> customer = <span class=\"keyword\">new</span> Customer(<span class=\"string\">id:</span><span class=\"number\">1</span>, <span class=\"string\">name:</span><span class=\"string\">\"Gromit\"</span>, <span class=\"string\">dob:</span><span class=\"keyword\">new</span> Date())</span><br><span class=\"line\">\t\t\tprintln(<span class=\"string\">\"Hello $&#123;customer.name&#125;\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行上面的代码后会看到输出</p>\n<pre><code>Hello Gromit\n</code></pre><p>可以看到property似乎就好像是公开的类field。你甚至可以在构造函数里为这些property初始化。在groovy里，field和property的概念被合并了，它们不仅看起来一样，使用起来也一样。因此，上面的groovy代码和下面的java代码是等价的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.util.Date;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Customer</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// properties</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Integer id;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Date dob;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Integer <span class=\"title\">getId</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.id;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getName</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Date <span class=\"title\">getDob</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.dob;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setId</span><span class=\"params\">(Integer id)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.id = id;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setName</span><span class=\"params\">(String name)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.name = name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setDob</span><span class=\"params\">(Date dob)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.dob = dob;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// sample code</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Customer customer = <span class=\"keyword\">new</span> Customer();</span><br><span class=\"line\">        customer.setId(<span class=\"number\">1</span>);</span><br><span class=\"line\">        customer.setName(<span class=\"string\">\"Gromit\"</span>);</span><br><span class=\"line\">        customer.setDob(<span class=\"keyword\">new</span> Date());</span><br><span class=\"line\"></span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Hello \"</span> + customer.getName());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们来看看property和field的一些规则~</p>\n<p>当groovy被编译成字节码文件后，将遵守下面的规则：</p>\n<ul>\n<li>如果声明时为name明确指定了一个操作限定符（public，private或protected）则将会创建一个field</li>\n<li>若没有指定任何操作限定符，则该name将被创建为private field并且自动创建getter和setter方法（就是一个property）</li>\n<li>如果property被定义为final，则创建的private field同样是final，且不会自动创建setter方法</li>\n<li>你可以声明一个property，并且自己实现getter和setter方法（译者注：多半是在学习这个知识点的时候才会这么做吧~）</li>\n<li>你可以同时定义相同name的property和field，此时property会默认使用同名的field（译者注：这是要疯了啊）</li>\n<li>如果你想要一个private或protected的property，你就必须自己提供满足你操作限定需求的getter和setter方法</li>\n<li>如果你在class内部操作property（例如<code>this.foo</code>或<code>foo</code>），groovy会直接操作对应的field，而不会调用对应的getter或setter方法</li>\n<li>如果你试图操作一个不存在property，groovy会通过meta class来操作对应的property，这可能会在运行时失败（译者注：动态语言特性）</li>\n</ul>\n<p>现在来看一个例子，创建一个包含只读property的类：</p>\n<figure class=\"highlight groovy\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Foo</span> &#123;</span></span><br><span class=\"line\">\t<span class=\"comment\">// read only property</span></span><br><span class=\"line\">\t<span class=\"comment\">//译者注：使用final，groovy不会为其创建setter方法</span></span><br><span class=\"line\">\t<span class=\"keyword\">final</span> String name = <span class=\"string\">\"John\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// read only property with public getter and protected setter</span></span><br><span class=\"line\">\tInteger amount</span><br><span class=\"line\">\t<span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> setAmount(Integer amount) &#123; <span class=\"keyword\">this</span>.amount = amount &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// dynamically typed property</span></span><br><span class=\"line\">\t<span class=\"keyword\">def</span> cheese</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>注意：property声明是需要一个标识符，或者是明确的类型（如<code>String</code>），或者是无类型声明（<code>def</code>）。</p>\n<p>为什么groovy不会为一个被定义为public的field自动创建getter和setter方法呢？（译者注：极好的问题！）如果我们在任何条件下都自动创建getter和setter方法，意味着groovy下你无法摆脱getter和setter，这在某些你就是不想要getter和setter方法的场景下就傻眼了！（译者注：此段为“随译”，就是随便翻译的意思~哈哈）</p>\n<h4 id=\"Closures-and-listeners\"><a href=\"#Closures-and-listeners\" class=\"headerlink\" title=\"Closures and listeners\"></a>Closures and listeners</h4><p>本段和主题关系不大，就不翻译了~</p>"},{"title":"vue-validator初体验","date":"2016-04-20T01:37:00.000Z","_content":"\n之前一直都是做SPA项目，不过最近由于种种原因，需要返璞归真来基于jquery做项目！但无奈之前一直使用像ng或react这样的大杀器在编程，思维上已经有了一定的模式，突然回到jquery时代，感觉不会写代码了！真是感叹前端发展的迅猛啊~\n\n其实react已算很轻了，但jsx语法我感觉确实是一个坎，虽然在我看来是精华也是趋势，但在业务量面前我实在不忍心再给团队成员加砝码了！\n\n之所以考虑让项目基于jquery，是因为目前的前端开发人员和我所在的城市的前端开发人员整体程度比较低（只熟悉jquery），所以这么抉择，虽然保守，但让项目可以更快的完成，也有利于扩员，算是一种权衡！\n\n但jquery确实太老了，只用jquery显然不能满足项目的需求，尤其是我这种生活在美好的数据绑定环境下的人，确实无法接受老旧的dom操作！\n\n我在github上搜索：\"jquery data binding\"，推荐给我的一款基于jquery的数据绑定库是真尼玛难用，所以我就不贴链接了，怕被打脸！总之，我们的目的是尽量找学习成本低，侵入性低的库，哪怕功能比较弱一些，哪怕性能比较差一些（我们的项目是内部系统，so~）！\n\n结果，偶然间哥注意到了Vue.js，完美！！！学习成本非常的低，而且十分的优雅，社区也很繁荣，简直了！那么接下来就是掌握一下它的使用方法，由于它出生在和react差不多一个时代，所以思路和用法都类似，看看官方文档就能上手做项目了！（希望没有大坑在等我~）\n\n单用vue，肯定也还是不够的，既然我们引入了它，自然要发挥它最大功效，回到今天的主题：表单验证！（别嫌我啰嗦，我就是话多！）\n\n之前用过不少表单验证插件，但实话说，看完vue-validator的[官方文档](http://vuejs.github.io/vue-validator/)，真的让我非常的震撼，基本上属于扩展性非常强的插件了，作者考虑到了绝大多数适配的场景，堪称完美！\n\n不过，在实际使用的时候，还是有一些文档上没有写太详细的小坑，我的任务就是把我使用的时候碰到的问题记录下来，我们开始吧！\n\n##### 安装\n\n由于我没有使用任何加载框架，只是简单的在浏览器上使用vue和vue-validator，所以我们只需要直接加载它们即可，不需要做额外的工作，这里我使用的是[bootcdn](http://www.bootcdn.cn/)提供的cdn，代码如下：\n\n```html\n<script src=\"//cdn.bootcss.com/vue/1.0.17/vue.js\"></script>\n<script src=\"//cdn.bootcss.com/vue-validator/2.0.0-alpha.22/vue-validator.js\"></script>\n```\n\n需要注意的是加载顺序和版本，我测试加载vue-validator的1.X版本的话并不会自动装载到vue中，不清楚是版本的事儿还是其它问题，总之，使用最新的版本即可。\n\n##### 绑定model\n\n最新的vue-validator下，在使用时已经不支持下面的写法：\n\n```html\n<input\n\ttype=\"text\"\n\tv-model=\"test\"\n\tv-validate=\"{required:true}\"/>\n```\n\n会提示：\n\tUncaught TypeError: Cannot read property 'replace' of undefined\n\n所以你只能老老实实的写成：\n\n```html\n<input\n\ttype=\"text\"\n\tv-validate:test=\"{required:true}\"/>\n```\n\n##### 结构复杂的model如何绑定\n\n我的例子中model的结构比较恶心，是这样的：\n\n```javascript\nvar blockBox = new Vue({\n\tel: \"#blockBox\",\n\tdata: {\n\t\ttable: {\n\t\t\trowA: {\n\t\t\t\tcolumnA: \"a-a\",\n\t\t\t\tcolumnB: 'a-b',\n\t\t\t\tcolumnC: 'a-c'\n\t\t\t},\n\t\t\trowB: {\n\t\t\t\tcolumnA: 'b-a',\n\t\t\t\tcolumnB: 'b-b',\n\t\t\t\tcolumnC: 'b-c'\n\t\t\t}\n\t\t}\n\t});\n```\n\n那我总不能写成这样吧：\n\n```html\n<input\n\ttype=\"text\"\n\tv-validate:table.rowA.columnA=\"{required:true}\"/>\n```\n丑不说，何况这么写也是错误的！\n\n怎么办？按照[官方的说法](http://vuejs.github.io/vue-validator/en/structure.html)应该这么写：\n\n```html\n<input\n\tclass=\"form-control\"\n\ttype=\"text\"\n\tv-model=\"table.rowA.columnA\"\n\tv-validate:message-aa=\"{required:true}\"/>\n<div class=\"errors\">\n\t<p v-if=\"$blockBoxValidator.messageAa.required\" class=\"lang\" data-key=\"blockBoxAA\" />\n</div>\n```\n完美，注意我在`v-validate:message-aa`中的写法！千万不能写成驼峰式的，如`v-validate:messageAA`，这么做会报错哟~原因我才和vue解析有关，这应该牵扯到了html属性的格式规范问题！总之你避免这么写就ok了！\n\n##### 和jquery配合\n\n我不想说我下面的这个场景是否合理，但为了快糙猛的把项目demo搞出来，我遇到了下面的问题。\n\n场景是我们的项目需要多语言支持，界面上能看到的元素（不包括用户输入）都应该支持切换语言，包括表单错误提醒！目前我所使用的切换语言的方法很简单：\n\n```html\n<p v-if=\"$blockBoxValidator.message_aa.required\" class=\"lang\" data-key=\"blockBoxAA\" />\n<script type=\"text/javascript\">\n$(function(){\n\t//多语言处理\n\t$(\".lang\").each(function(node){\n\t\t$(this).html($langCFG[$(this).data(\"key\")]);\n\t});\n});\n</script>\n```\n利用jquery的`domready`事件来第一时间替换需要显示的文字！这就有个问题出现了，若你在`domready`事件触发前就初始化了vue和vue-validator，根据表单验证逻辑很可能导致`v-if`指令直接干掉表示错误信息的那个`p`标签，所以自然也不会正确的执行多语言替换的逻辑。\n\n在不考虑花时间研究vue-validator生命周期的前提下，我们如何更快的绕过这个问题呢？第一感觉是，将初始化vue和vue-validator的工作也放在`domready`中（但注意一定要放在多语言处理的代码之后）。不过你还会遇到另外一个问题，这个时候你在浏览器调试终端中按照vue官方的例子打印你创建的`vm`时，会报错提示变量定义不存在~具体原因不清楚，不过我们依然可以搞定这个问题，最终的代码如下：\n\n```html\n<p v-if=\"$blockBoxValidator.message_aa.required\" class=\"lang\" data-key=\"blockBoxAA\" />\n<script type=\"text/javascript\">\nvar blockBox = null;\t//变量声明，这样能保证在调试终端中可以直接使用'blockBox.$log()'\n$(function(){\n\t//多语言处理\n\t$(\".lang\").each(function(node){\n\t\t$(this).html($langCFG[$(this).data(\"key\")]);\n\t});\n\n\t//放在多语言处理下面，且在domready事件内\n\tblockBox = new Vue({\n\t\tel: \"#blockBox\",\n\t\tdata: {\n\t\t\ttable: {\n\t\t\t\trowA: {\n\t\t\t\t\tcolumnA: \"a-a\",\n\t\t\t\t\tcolumnB: 'a-b',\n\t\t\t\t\tcolumnC: 'a-c'\n\t\t\t\t},\n\t\t\t\trowB: {\n\t\t\t\t\tcolumnA: 'b-a',\n\t\t\t\t\tcolumnB: 'b-b',\n\t\t\t\t\tcolumnC: 'b-c'\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n});\n</script>\n```\n\n理论上，你只要把你想用js做的业务逻辑代码都放在`domready`事件的回调方法中的vue初始化之后，就可以像和单独使用vue写代码一样的流程来进行开发了！\n\n##### 页面初次加载显示问题\n\n这应该不是vue-validator的问题，这应该属于vue的问题域。之前angular推荐的解决方案是提供了一个指令来监听模版解析完毕的事件。\n我搜了一圈没找到官方或第三方提供的类似功能的实现，不过自己来做也不是什么难事儿：\n\n```html\n<body id=\"body\" style=\"display:none\">\n{{test}}\n</body>\n<script type=\"text/javascript\">\nnew Vue({\n\tel:\"#body\",\n\tready: function(){\n\t\t$(\"#body\").show();\n\t}\n});\n</script>\n```\n其实思路就是借助vue组件的生命周期hook来及时的修改css样式，你也可以添加loading动画等高级特效，我懒我就不弄了~\n\n##### $resetValidation()\n\n重置验证的场景是这样的：当你的表单被用户合法修改保存后，用户并没有跳转到其他页面，仍然在当前页面下，由于表单内容已经和最原始的版本不一样，你需要resetValidation一下从而使vue-validator的各个状态匹配业务场景（包括但不限于`dirty`,`modified`等状态）。不过这里有两个小插曲：\n\n1. 我直接使用的bootcdn提供的版本导致js报错说$resetValidation()未定义，切换成官方的最新版本即可解决；\n2. 应该是跟vue的[vm更新机制](http://vuejs.org.cn/guide/reactivity.html#异步更新队列)有关:\n\n```javascript\nvar that = this;\nsetTimeout(function(){\n\tthat.$resetValidation();\n},0);\n```\n否则呢，你无法看到期望的结果~\n\n##### lazy的正确使用方法\n\n有些表单的初始化数据需要异步获取，太正常不过了，对吧？vue-validator提供了lazy模式，刚好匹配这种场景。所以，你只需要在`validator`标签上添加`lazy`属性即可，[官方例子](http://vuejs.github.io/vue-validator/en/lazy.html)简单明了，似乎没有什么要解释的！不过，问题来了，官方的例子代码是基于vue的动态组件写的，动态组件才有`activate`事件，而如果你像我一样是用在普通组件下的，那么自然不会触发`activate`事件，那回调逻辑自然不会被执行，`this.$activateValidator()`不会执行的话，看看vue-validator会提示什么：\n\n```\n[vue-validator] validator element directive need to specify 'name' param attribute: (e.g. <validator name=\"validator1\">...</validator>)\n```\n看起来提示的非常不准确，让我排查了好久，甚至去联系作者来查看这个问题！其实你只要确保在正确的时机调用`$activateValidator()`方法就可以了，那什么叫正确的时机：\n\n- 普通组件的`ready`事件回调中\n- 动态组件的`activate`事件回调中\n\n否则你一定会看到上面的那个提醒，特别提醒，下面的写法依然会看到提醒：\n\n```javascript\nready: function(){\n\tsetTimeout(function(){\n\t\tthis.$activateValidator();\n\t}.bind(this), 3000);\n},\n```\n\n这应该是作者好心办的\"错事儿\"吧，他要求你只能在组件渲染前把该做的都做了（数据获取），不然你就是在自讨苦吃~当然，这种设计哲学并非没有道理，全看权衡和喜好！\n\n---\n\n好了，先总结到这里，如果以后有啥新的结论，再说~\n","source":"_posts/Vue-validator初体验.md","raw":"title:  vue-validator初体验\ndate: 2016-04-20 09:37:00\ntags:\n- vue.js\n- validator\n- jquery\ncategories: 前端\n---\n\n之前一直都是做SPA项目，不过最近由于种种原因，需要返璞归真来基于jquery做项目！但无奈之前一直使用像ng或react这样的大杀器在编程，思维上已经有了一定的模式，突然回到jquery时代，感觉不会写代码了！真是感叹前端发展的迅猛啊~\n\n其实react已算很轻了，但jsx语法我感觉确实是一个坎，虽然在我看来是精华也是趋势，但在业务量面前我实在不忍心再给团队成员加砝码了！\n\n之所以考虑让项目基于jquery，是因为目前的前端开发人员和我所在的城市的前端开发人员整体程度比较低（只熟悉jquery），所以这么抉择，虽然保守，但让项目可以更快的完成，也有利于扩员，算是一种权衡！\n\n但jquery确实太老了，只用jquery显然不能满足项目的需求，尤其是我这种生活在美好的数据绑定环境下的人，确实无法接受老旧的dom操作！\n\n我在github上搜索：\"jquery data binding\"，推荐给我的一款基于jquery的数据绑定库是真尼玛难用，所以我就不贴链接了，怕被打脸！总之，我们的目的是尽量找学习成本低，侵入性低的库，哪怕功能比较弱一些，哪怕性能比较差一些（我们的项目是内部系统，so~）！\n\n结果，偶然间哥注意到了Vue.js，完美！！！学习成本非常的低，而且十分的优雅，社区也很繁荣，简直了！那么接下来就是掌握一下它的使用方法，由于它出生在和react差不多一个时代，所以思路和用法都类似，看看官方文档就能上手做项目了！（希望没有大坑在等我~）\n\n单用vue，肯定也还是不够的，既然我们引入了它，自然要发挥它最大功效，回到今天的主题：表单验证！（别嫌我啰嗦，我就是话多！）\n\n之前用过不少表单验证插件，但实话说，看完vue-validator的[官方文档](http://vuejs.github.io/vue-validator/)，真的让我非常的震撼，基本上属于扩展性非常强的插件了，作者考虑到了绝大多数适配的场景，堪称完美！\n\n不过，在实际使用的时候，还是有一些文档上没有写太详细的小坑，我的任务就是把我使用的时候碰到的问题记录下来，我们开始吧！\n\n##### 安装\n\n由于我没有使用任何加载框架，只是简单的在浏览器上使用vue和vue-validator，所以我们只需要直接加载它们即可，不需要做额外的工作，这里我使用的是[bootcdn](http://www.bootcdn.cn/)提供的cdn，代码如下：\n\n```html\n<script src=\"//cdn.bootcss.com/vue/1.0.17/vue.js\"></script>\n<script src=\"//cdn.bootcss.com/vue-validator/2.0.0-alpha.22/vue-validator.js\"></script>\n```\n\n需要注意的是加载顺序和版本，我测试加载vue-validator的1.X版本的话并不会自动装载到vue中，不清楚是版本的事儿还是其它问题，总之，使用最新的版本即可。\n\n##### 绑定model\n\n最新的vue-validator下，在使用时已经不支持下面的写法：\n\n```html\n<input\n\ttype=\"text\"\n\tv-model=\"test\"\n\tv-validate=\"{required:true}\"/>\n```\n\n会提示：\n\tUncaught TypeError: Cannot read property 'replace' of undefined\n\n所以你只能老老实实的写成：\n\n```html\n<input\n\ttype=\"text\"\n\tv-validate:test=\"{required:true}\"/>\n```\n\n##### 结构复杂的model如何绑定\n\n我的例子中model的结构比较恶心，是这样的：\n\n```javascript\nvar blockBox = new Vue({\n\tel: \"#blockBox\",\n\tdata: {\n\t\ttable: {\n\t\t\trowA: {\n\t\t\t\tcolumnA: \"a-a\",\n\t\t\t\tcolumnB: 'a-b',\n\t\t\t\tcolumnC: 'a-c'\n\t\t\t},\n\t\t\trowB: {\n\t\t\t\tcolumnA: 'b-a',\n\t\t\t\tcolumnB: 'b-b',\n\t\t\t\tcolumnC: 'b-c'\n\t\t\t}\n\t\t}\n\t});\n```\n\n那我总不能写成这样吧：\n\n```html\n<input\n\ttype=\"text\"\n\tv-validate:table.rowA.columnA=\"{required:true}\"/>\n```\n丑不说，何况这么写也是错误的！\n\n怎么办？按照[官方的说法](http://vuejs.github.io/vue-validator/en/structure.html)应该这么写：\n\n```html\n<input\n\tclass=\"form-control\"\n\ttype=\"text\"\n\tv-model=\"table.rowA.columnA\"\n\tv-validate:message-aa=\"{required:true}\"/>\n<div class=\"errors\">\n\t<p v-if=\"$blockBoxValidator.messageAa.required\" class=\"lang\" data-key=\"blockBoxAA\" />\n</div>\n```\n完美，注意我在`v-validate:message-aa`中的写法！千万不能写成驼峰式的，如`v-validate:messageAA`，这么做会报错哟~原因我才和vue解析有关，这应该牵扯到了html属性的格式规范问题！总之你避免这么写就ok了！\n\n##### 和jquery配合\n\n我不想说我下面的这个场景是否合理，但为了快糙猛的把项目demo搞出来，我遇到了下面的问题。\n\n场景是我们的项目需要多语言支持，界面上能看到的元素（不包括用户输入）都应该支持切换语言，包括表单错误提醒！目前我所使用的切换语言的方法很简单：\n\n```html\n<p v-if=\"$blockBoxValidator.message_aa.required\" class=\"lang\" data-key=\"blockBoxAA\" />\n<script type=\"text/javascript\">\n$(function(){\n\t//多语言处理\n\t$(\".lang\").each(function(node){\n\t\t$(this).html($langCFG[$(this).data(\"key\")]);\n\t});\n});\n</script>\n```\n利用jquery的`domready`事件来第一时间替换需要显示的文字！这就有个问题出现了，若你在`domready`事件触发前就初始化了vue和vue-validator，根据表单验证逻辑很可能导致`v-if`指令直接干掉表示错误信息的那个`p`标签，所以自然也不会正确的执行多语言替换的逻辑。\n\n在不考虑花时间研究vue-validator生命周期的前提下，我们如何更快的绕过这个问题呢？第一感觉是，将初始化vue和vue-validator的工作也放在`domready`中（但注意一定要放在多语言处理的代码之后）。不过你还会遇到另外一个问题，这个时候你在浏览器调试终端中按照vue官方的例子打印你创建的`vm`时，会报错提示变量定义不存在~具体原因不清楚，不过我们依然可以搞定这个问题，最终的代码如下：\n\n```html\n<p v-if=\"$blockBoxValidator.message_aa.required\" class=\"lang\" data-key=\"blockBoxAA\" />\n<script type=\"text/javascript\">\nvar blockBox = null;\t//变量声明，这样能保证在调试终端中可以直接使用'blockBox.$log()'\n$(function(){\n\t//多语言处理\n\t$(\".lang\").each(function(node){\n\t\t$(this).html($langCFG[$(this).data(\"key\")]);\n\t});\n\n\t//放在多语言处理下面，且在domready事件内\n\tblockBox = new Vue({\n\t\tel: \"#blockBox\",\n\t\tdata: {\n\t\t\ttable: {\n\t\t\t\trowA: {\n\t\t\t\t\tcolumnA: \"a-a\",\n\t\t\t\t\tcolumnB: 'a-b',\n\t\t\t\t\tcolumnC: 'a-c'\n\t\t\t\t},\n\t\t\t\trowB: {\n\t\t\t\t\tcolumnA: 'b-a',\n\t\t\t\t\tcolumnB: 'b-b',\n\t\t\t\t\tcolumnC: 'b-c'\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n});\n</script>\n```\n\n理论上，你只要把你想用js做的业务逻辑代码都放在`domready`事件的回调方法中的vue初始化之后，就可以像和单独使用vue写代码一样的流程来进行开发了！\n\n##### 页面初次加载显示问题\n\n这应该不是vue-validator的问题，这应该属于vue的问题域。之前angular推荐的解决方案是提供了一个指令来监听模版解析完毕的事件。\n我搜了一圈没找到官方或第三方提供的类似功能的实现，不过自己来做也不是什么难事儿：\n\n```html\n<body id=\"body\" style=\"display:none\">\n{{test}}\n</body>\n<script type=\"text/javascript\">\nnew Vue({\n\tel:\"#body\",\n\tready: function(){\n\t\t$(\"#body\").show();\n\t}\n});\n</script>\n```\n其实思路就是借助vue组件的生命周期hook来及时的修改css样式，你也可以添加loading动画等高级特效，我懒我就不弄了~\n\n##### $resetValidation()\n\n重置验证的场景是这样的：当你的表单被用户合法修改保存后，用户并没有跳转到其他页面，仍然在当前页面下，由于表单内容已经和最原始的版本不一样，你需要resetValidation一下从而使vue-validator的各个状态匹配业务场景（包括但不限于`dirty`,`modified`等状态）。不过这里有两个小插曲：\n\n1. 我直接使用的bootcdn提供的版本导致js报错说$resetValidation()未定义，切换成官方的最新版本即可解决；\n2. 应该是跟vue的[vm更新机制](http://vuejs.org.cn/guide/reactivity.html#异步更新队列)有关:\n\n```javascript\nvar that = this;\nsetTimeout(function(){\n\tthat.$resetValidation();\n},0);\n```\n否则呢，你无法看到期望的结果~\n\n##### lazy的正确使用方法\n\n有些表单的初始化数据需要异步获取，太正常不过了，对吧？vue-validator提供了lazy模式，刚好匹配这种场景。所以，你只需要在`validator`标签上添加`lazy`属性即可，[官方例子](http://vuejs.github.io/vue-validator/en/lazy.html)简单明了，似乎没有什么要解释的！不过，问题来了，官方的例子代码是基于vue的动态组件写的，动态组件才有`activate`事件，而如果你像我一样是用在普通组件下的，那么自然不会触发`activate`事件，那回调逻辑自然不会被执行，`this.$activateValidator()`不会执行的话，看看vue-validator会提示什么：\n\n```\n[vue-validator] validator element directive need to specify 'name' param attribute: (e.g. <validator name=\"validator1\">...</validator>)\n```\n看起来提示的非常不准确，让我排查了好久，甚至去联系作者来查看这个问题！其实你只要确保在正确的时机调用`$activateValidator()`方法就可以了，那什么叫正确的时机：\n\n- 普通组件的`ready`事件回调中\n- 动态组件的`activate`事件回调中\n\n否则你一定会看到上面的那个提醒，特别提醒，下面的写法依然会看到提醒：\n\n```javascript\nready: function(){\n\tsetTimeout(function(){\n\t\tthis.$activateValidator();\n\t}.bind(this), 3000);\n},\n```\n\n这应该是作者好心办的\"错事儿\"吧，他要求你只能在组件渲染前把该做的都做了（数据获取），不然你就是在自讨苦吃~当然，这种设计哲学并非没有道理，全看权衡和喜好！\n\n---\n\n好了，先总结到这里，如果以后有啥新的结论，再说~\n","slug":"Vue-validator初体验","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cinbsa3z00000l3fyvwxi6py0","comments":1,"layout":"post","photos":[],"link":"","content":"<p>之前一直都是做SPA项目，不过最近由于种种原因，需要返璞归真来基于jquery做项目！但无奈之前一直使用像ng或react这样的大杀器在编程，思维上已经有了一定的模式，突然回到jquery时代，感觉不会写代码了！真是感叹前端发展的迅猛啊~</p>\n<p>其实react已算很轻了，但jsx语法我感觉确实是一个坎，虽然在我看来是精华也是趋势，但在业务量面前我实在不忍心再给团队成员加砝码了！</p>\n<p>之所以考虑让项目基于jquery，是因为目前的前端开发人员和我所在的城市的前端开发人员整体程度比较低（只熟悉jquery），所以这么抉择，虽然保守，但让项目可以更快的完成，也有利于扩员，算是一种权衡！</p>\n<p>但jquery确实太老了，只用jquery显然不能满足项目的需求，尤其是我这种生活在美好的数据绑定环境下的人，确实无法接受老旧的dom操作！</p>\n<p>我在github上搜索：”jquery data binding”，推荐给我的一款基于jquery的数据绑定库是真尼玛难用，所以我就不贴链接了，怕被打脸！总之，我们的目的是尽量找学习成本低，侵入性低的库，哪怕功能比较弱一些，哪怕性能比较差一些（我们的项目是内部系统，so~）！</p>\n<p>结果，偶然间哥注意到了Vue.js，完美！！！学习成本非常的低，而且十分的优雅，社区也很繁荣，简直了！那么接下来就是掌握一下它的使用方法，由于它出生在和react差不多一个时代，所以思路和用法都类似，看看官方文档就能上手做项目了！（希望没有大坑在等我~）</p>\n<p>单用vue，肯定也还是不够的，既然我们引入了它，自然要发挥它最大功效，回到今天的主题：表单验证！（别嫌我啰嗦，我就是话多！）</p>\n<p>之前用过不少表单验证插件，但实话说，看完vue-validator的<a href=\"http://vuejs.github.io/vue-validator/\" target=\"_blank\" rel=\"external\">官方文档</a>，真的让我非常的震撼，基本上属于扩展性非常强的插件了，作者考虑到了绝大多数适配的场景，堪称完美！</p>\n<p>不过，在实际使用的时候，还是有一些文档上没有写太详细的小坑，我的任务就是把我使用的时候碰到的问题记录下来，我们开始吧！</p>\n<h5 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h5><p>由于我没有使用任何加载框架，只是简单的在浏览器上使用vue和vue-validator，所以我们只需要直接加载它们即可，不需要做额外的工作，这里我使用的是<a href=\"http://www.bootcdn.cn/\" target=\"_blank\" rel=\"external\">bootcdn</a>提供的cdn，代码如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">\"//cdn.bootcss.com/vue/1.0.17/vue.js\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">\"//cdn.bootcss.com/vue-validator/2.0.0-alpha.22/vue-validator.js\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>需要注意的是加载顺序和版本，我测试加载vue-validator的1.X版本的话并不会自动装载到vue中，不清楚是版本的事儿还是其它问题，总之，使用最新的版本即可。</p>\n<h5 id=\"绑定model\"><a href=\"#绑定model\" class=\"headerlink\" title=\"绑定model\"></a>绑定model</h5><p>最新的vue-validator下，在使用时已经不支持下面的写法：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-model</span>=<span class=\"string\">\"test\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br></pre></td></tr></table></figure>\n<p>会提示：<br>    Uncaught TypeError: Cannot read property ‘replace’ of undefined</p>\n<p>所以你只能老老实实的写成：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate:test</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"结构复杂的model如何绑定\"><a href=\"#结构复杂的model如何绑定\" class=\"headerlink\" title=\"结构复杂的model如何绑定\"></a>结构复杂的model如何绑定</h5><p>我的例子中model的结构比较恶心，是这样的：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> blockBox = <span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">\tel: <span class=\"string\">\"#blockBox\"</span>,</span><br><span class=\"line\">\tdata: &#123;</span><br><span class=\"line\">\t\ttable: &#123;</span><br><span class=\"line\">\t\t\trowA: &#123;</span><br><span class=\"line\">\t\t\t\tcolumnA: <span class=\"string\">\"a-a\"</span>,</span><br><span class=\"line\">\t\t\t\tcolumnB: <span class=\"string\">'a-b'</span>,</span><br><span class=\"line\">\t\t\t\tcolumnC: <span class=\"string\">'a-c'</span></span><br><span class=\"line\">\t\t\t&#125;,</span><br><span class=\"line\">\t\t\trowB: &#123;</span><br><span class=\"line\">\t\t\t\tcolumnA: <span class=\"string\">'b-a'</span>,</span><br><span class=\"line\">\t\t\t\tcolumnB: <span class=\"string\">'b-b'</span>,</span><br><span class=\"line\">\t\t\t\tcolumnC: <span class=\"string\">'b-c'</span></span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;);</span><br></pre></td></tr></table></figure>\n<p>那我总不能写成这样吧：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate:table.rowA.columnA</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br></pre></td></tr></table></figure>\n<p>丑不说，何况这么写也是错误的！</p>\n<p>怎么办？按照<a href=\"http://vuejs.github.io/vue-validator/en/structure.html\" target=\"_blank\" rel=\"external\">官方的说法</a>应该这么写：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">class</span>=<span class=\"string\">\"form-control\"</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-model</span>=<span class=\"string\">\"table.rowA.columnA\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate:message-aa</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"errors\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">v-if</span>=<span class=\"string\">\"$blockBoxValidator.messageAa.required\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"lang\"</span> <span class=\"attr\">data-key</span>=<span class=\"string\">\"blockBoxAA\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>完美，注意我在<code>v-validate:message-aa</code>中的写法！千万不能写成驼峰式的，如<code>v-validate:messageAA</code>，这么做会报错哟~原因我才和vue解析有关，这应该牵扯到了html属性的格式规范问题！总之你避免这么写就ok了！</p>\n<h5 id=\"和jquery配合\"><a href=\"#和jquery配合\" class=\"headerlink\" title=\"和jquery配合\"></a>和jquery配合</h5><p>我不想说我下面的这个场景是否合理，但为了快糙猛的把项目demo搞出来，我遇到了下面的问题。</p>\n<p>场景是我们的项目需要多语言支持，界面上能看到的元素（不包括用户输入）都应该支持切换语言，包括表单错误提醒！目前我所使用的切换语言的方法很简单：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">v-if</span>=<span class=\"string\">\"$blockBoxValidator.message_aa.required\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"lang\"</span> <span class=\"attr\">data-key</span>=<span class=\"string\">\"blockBoxAA\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;</span><span class=\"javascript\"></span><br><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">//多语言处理</span></span><br><span class=\"line\">\t$(<span class=\"string\">\".lang\"</span>).each(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">node</span>)</span>&#123;</span><br><span class=\"line\">\t\t$(<span class=\"keyword\">this</span>).html($langCFG[$(<span class=\"keyword\">this</span>).data(<span class=\"string\">\"key\"</span>)]);</span><br><span class=\"line\">\t&#125;);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>利用jquery的<code>domready</code>事件来第一时间替换需要显示的文字！这就有个问题出现了，若你在<code>domready</code>事件触发前就初始化了vue和vue-validator，根据表单验证逻辑很可能导致<code>v-if</code>指令直接干掉表示错误信息的那个<code>p</code>标签，所以自然也不会正确的执行多语言替换的逻辑。</p>\n<p>在不考虑花时间研究vue-validator生命周期的前提下，我们如何更快的绕过这个问题呢？第一感觉是，将初始化vue和vue-validator的工作也放在<code>domready</code>中（但注意一定要放在多语言处理的代码之后）。不过你还会遇到另外一个问题，这个时候你在浏览器调试终端中按照vue官方的例子打印你创建的<code>vm</code>时，会报错提示变量定义不存在~具体原因不清楚，不过我们依然可以搞定这个问题，最终的代码如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">v-if</span>=<span class=\"string\">\"$blockBoxValidator.message_aa.required\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"lang\"</span> <span class=\"attr\">data-key</span>=<span class=\"string\">\"blockBoxAA\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;</span><span class=\"javascript\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> blockBox = <span class=\"literal\">null</span>;\t<span class=\"comment\">//变量声明，这样能保证在调试终端中可以直接使用'blockBox.$log()'</span></span><br><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">//多语言处理</span></span><br><span class=\"line\">\t$(<span class=\"string\">\".lang\"</span>).each(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">node</span>)</span>&#123;</span><br><span class=\"line\">\t\t$(<span class=\"keyword\">this</span>).html($langCFG[$(<span class=\"keyword\">this</span>).data(<span class=\"string\">\"key\"</span>)]);</span><br><span class=\"line\">\t&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//放在多语言处理下面，且在domready事件内</span></span><br><span class=\"line\">\tblockBox = <span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">\t\tel: <span class=\"string\">\"#blockBox\"</span>,</span><br><span class=\"line\">\t\tdata: &#123;</span><br><span class=\"line\">\t\t\ttable: &#123;</span><br><span class=\"line\">\t\t\t\trowA: &#123;</span><br><span class=\"line\">\t\t\t\t\tcolumnA: <span class=\"string\">\"a-a\"</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnB: <span class=\"string\">'a-b'</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnC: <span class=\"string\">'a-c'</span></span><br><span class=\"line\">\t\t\t\t&#125;,</span><br><span class=\"line\">\t\t\t\trowB: &#123;</span><br><span class=\"line\">\t\t\t\t\tcolumnA: <span class=\"string\">'b-a'</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnB: <span class=\"string\">'b-b'</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnC: <span class=\"string\">'b-c'</span></span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>理论上，你只要把你想用js做的业务逻辑代码都放在<code>domready</code>事件的回调方法中的vue初始化之后，就可以像和单独使用vue写代码一样的流程来进行开发了！</p>\n<h5 id=\"页面初次加载显示问题\"><a href=\"#页面初次加载显示问题\" class=\"headerlink\" title=\"页面初次加载显示问题\"></a>页面初次加载显示问题</h5><p>这应该不是vue-validator的问题，这应该属于vue的问题域。之前angular推荐的解决方案是提供了一个指令来监听模版解析完毕的事件。<br>我搜了一圈没找到官方或第三方提供的类似功能的实现，不过自己来做也不是什么难事儿：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span> <span class=\"attr\">id</span>=<span class=\"string\">\"body\"</span> <span class=\"attr\">style</span>=<span class=\"string\">\"display:none\"</span>&gt;</span></span><br><span class=\"line\">&#123;&#123;test&#125;&#125;</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;</span><span class=\"javascript\"></span><br><span class=\"line\"><span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">\tel:<span class=\"string\">\"#body\"</span>,</span><br><span class=\"line\">\tready: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t\t$(<span class=\"string\">\"#body\"</span>).show();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>其实思路就是借助vue组件的生命周期hook来及时的修改css样式，你也可以添加loading动画等高级特效，我懒我就不弄了~</p>\n<h5 id=\"resetValidation\"><a href=\"#resetValidation\" class=\"headerlink\" title=\"$resetValidation()\"></a>$resetValidation()</h5><p>重置验证的场景是这样的：当你的表单被用户合法修改保存后，用户并没有跳转到其他页面，仍然在当前页面下，由于表单内容已经和最原始的版本不一样，你需要resetValidation一下从而使vue-validator的各个状态匹配业务场景（包括但不限于<code>dirty</code>,<code>modified</code>等状态）。不过这里有两个小插曲：</p>\n<ol>\n<li>我直接使用的bootcdn提供的版本导致js报错说$resetValidation()未定义，切换成官方的最新版本即可解决；</li>\n<li>应该是跟vue的<a href=\"http://vuejs.org.cn/guide/reactivity.html#异步更新队列\" target=\"_blank\" rel=\"external\">vm更新机制</a>有关:</li>\n</ol>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> that = <span class=\"keyword\">this</span>;</span><br><span class=\"line\">setTimeout(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\tthat.$resetValidation();</span><br><span class=\"line\">&#125;,<span class=\"number\">0</span>);</span><br></pre></td></tr></table></figure>\n<p>否则呢，你无法看到期望的结果~</p>\n<h5 id=\"lazy的正确使用方法\"><a href=\"#lazy的正确使用方法\" class=\"headerlink\" title=\"lazy的正确使用方法\"></a>lazy的正确使用方法</h5><p>有些表单的初始化数据需要异步获取，太正常不过了，对吧？vue-validator提供了lazy模式，刚好匹配这种场景。所以，你只需要在<code>validator</code>标签上添加<code>lazy</code>属性即可，<a href=\"http://vuejs.github.io/vue-validator/en/lazy.html\" target=\"_blank\" rel=\"external\">官方例子</a>简单明了，似乎没有什么要解释的！不过，问题来了，官方的例子代码是基于vue的动态组件写的，动态组件才有<code>activate</code>事件，而如果你像我一样是用在普通组件下的，那么自然不会触发<code>activate</code>事件，那回调逻辑自然不会被执行，<code>this.$activateValidator()</code>不会执行的话，看看vue-validator会提示什么：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[vue-validator] validator element directive need to specify &apos;name&apos; param attribute: (e.g. &lt;validator name=&quot;validator1&quot;&gt;...&lt;/validator&gt;)</span><br></pre></td></tr></table></figure>\n<p>看起来提示的非常不准确，让我排查了好久，甚至去联系作者来查看这个问题！其实你只要确保在正确的时机调用<code>$activateValidator()</code>方法就可以了，那什么叫正确的时机：</p>\n<ul>\n<li>普通组件的<code>ready</code>事件回调中</li>\n<li>动态组件的<code>activate</code>事件回调中</li>\n</ul>\n<p>否则你一定会看到上面的那个提醒，特别提醒，下面的写法依然会看到提醒：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ready: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\tsetTimeout(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.$activateValidator();</span><br><span class=\"line\">\t&#125;.bind(<span class=\"keyword\">this</span>), <span class=\"number\">3000</span>);</span><br><span class=\"line\">&#125;,</span><br></pre></td></tr></table></figure>\n<p>这应该是作者好心办的”错事儿”吧，他要求你只能在组件渲染前把该做的都做了（数据获取），不然你就是在自讨苦吃~当然，这种设计哲学并非没有道理，全看权衡和喜好！</p>\n<hr>\n<p>好了，先总结到这里，如果以后有啥新的结论，再说~</p>\n","excerpt":"","more":"<p>之前一直都是做SPA项目，不过最近由于种种原因，需要返璞归真来基于jquery做项目！但无奈之前一直使用像ng或react这样的大杀器在编程，思维上已经有了一定的模式，突然回到jquery时代，感觉不会写代码了！真是感叹前端发展的迅猛啊~</p>\n<p>其实react已算很轻了，但jsx语法我感觉确实是一个坎，虽然在我看来是精华也是趋势，但在业务量面前我实在不忍心再给团队成员加砝码了！</p>\n<p>之所以考虑让项目基于jquery，是因为目前的前端开发人员和我所在的城市的前端开发人员整体程度比较低（只熟悉jquery），所以这么抉择，虽然保守，但让项目可以更快的完成，也有利于扩员，算是一种权衡！</p>\n<p>但jquery确实太老了，只用jquery显然不能满足项目的需求，尤其是我这种生活在美好的数据绑定环境下的人，确实无法接受老旧的dom操作！</p>\n<p>我在github上搜索：”jquery data binding”，推荐给我的一款基于jquery的数据绑定库是真尼玛难用，所以我就不贴链接了，怕被打脸！总之，我们的目的是尽量找学习成本低，侵入性低的库，哪怕功能比较弱一些，哪怕性能比较差一些（我们的项目是内部系统，so~）！</p>\n<p>结果，偶然间哥注意到了Vue.js，完美！！！学习成本非常的低，而且十分的优雅，社区也很繁荣，简直了！那么接下来就是掌握一下它的使用方法，由于它出生在和react差不多一个时代，所以思路和用法都类似，看看官方文档就能上手做项目了！（希望没有大坑在等我~）</p>\n<p>单用vue，肯定也还是不够的，既然我们引入了它，自然要发挥它最大功效，回到今天的主题：表单验证！（别嫌我啰嗦，我就是话多！）</p>\n<p>之前用过不少表单验证插件，但实话说，看完vue-validator的<a href=\"http://vuejs.github.io/vue-validator/\">官方文档</a>，真的让我非常的震撼，基本上属于扩展性非常强的插件了，作者考虑到了绝大多数适配的场景，堪称完美！</p>\n<p>不过，在实际使用的时候，还是有一些文档上没有写太详细的小坑，我的任务就是把我使用的时候碰到的问题记录下来，我们开始吧！</p>\n<h5 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h5><p>由于我没有使用任何加载框架，只是简单的在浏览器上使用vue和vue-validator，所以我们只需要直接加载它们即可，不需要做额外的工作，这里我使用的是<a href=\"http://www.bootcdn.cn/\">bootcdn</a>提供的cdn，代码如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">\"//cdn.bootcss.com/vue/1.0.17/vue.js\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">\"//cdn.bootcss.com/vue-validator/2.0.0-alpha.22/vue-validator.js\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>需要注意的是加载顺序和版本，我测试加载vue-validator的1.X版本的话并不会自动装载到vue中，不清楚是版本的事儿还是其它问题，总之，使用最新的版本即可。</p>\n<h5 id=\"绑定model\"><a href=\"#绑定model\" class=\"headerlink\" title=\"绑定model\"></a>绑定model</h5><p>最新的vue-validator下，在使用时已经不支持下面的写法：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-model</span>=<span class=\"string\">\"test\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br></pre></td></tr></table></figure>\n<p>会提示：<br>    Uncaught TypeError: Cannot read property ‘replace’ of undefined</p>\n<p>所以你只能老老实实的写成：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate:test</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br></pre></td></tr></table></figure>\n<h5 id=\"结构复杂的model如何绑定\"><a href=\"#结构复杂的model如何绑定\" class=\"headerlink\" title=\"结构复杂的model如何绑定\"></a>结构复杂的model如何绑定</h5><p>我的例子中model的结构比较恶心，是这样的：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> blockBox = <span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">\tel: <span class=\"string\">\"#blockBox\"</span>,</span><br><span class=\"line\">\tdata: &#123;</span><br><span class=\"line\">\t\ttable: &#123;</span><br><span class=\"line\">\t\t\trowA: &#123;</span><br><span class=\"line\">\t\t\t\tcolumnA: <span class=\"string\">\"a-a\"</span>,</span><br><span class=\"line\">\t\t\t\tcolumnB: <span class=\"string\">'a-b'</span>,</span><br><span class=\"line\">\t\t\t\tcolumnC: <span class=\"string\">'a-c'</span></span><br><span class=\"line\">\t\t\t&#125;,</span><br><span class=\"line\">\t\t\trowB: &#123;</span><br><span class=\"line\">\t\t\t\tcolumnA: <span class=\"string\">'b-a'</span>,</span><br><span class=\"line\">\t\t\t\tcolumnB: <span class=\"string\">'b-b'</span>,</span><br><span class=\"line\">\t\t\t\tcolumnC: <span class=\"string\">'b-c'</span></span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;);</span><br></pre></td></tr></table></figure>\n<p>那我总不能写成这样吧：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate:table.rowA.columnA</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br></pre></td></tr></table></figure>\n<p>丑不说，何况这么写也是错误的！</p>\n<p>怎么办？按照<a href=\"http://vuejs.github.io/vue-validator/en/structure.html\">官方的说法</a>应该这么写：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span></span><br><span class=\"line\">\t<span class=\"attr\">class</span>=<span class=\"string\">\"form-control\"</span></span><br><span class=\"line\">\t<span class=\"attr\">type</span>=<span class=\"string\">\"text\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-model</span>=<span class=\"string\">\"table.rowA.columnA\"</span></span><br><span class=\"line\">\t<span class=\"attr\">v-validate:message-aa</span>=<span class=\"string\">\"&#123;required:true&#125;\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"errors\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">v-if</span>=<span class=\"string\">\"$blockBoxValidator.messageAa.required\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"lang\"</span> <span class=\"attr\">data-key</span>=<span class=\"string\">\"blockBoxAA\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>完美，注意我在<code>v-validate:message-aa</code>中的写法！千万不能写成驼峰式的，如<code>v-validate:messageAA</code>，这么做会报错哟~原因我才和vue解析有关，这应该牵扯到了html属性的格式规范问题！总之你避免这么写就ok了！</p>\n<h5 id=\"和jquery配合\"><a href=\"#和jquery配合\" class=\"headerlink\" title=\"和jquery配合\"></a>和jquery配合</h5><p>我不想说我下面的这个场景是否合理，但为了快糙猛的把项目demo搞出来，我遇到了下面的问题。</p>\n<p>场景是我们的项目需要多语言支持，界面上能看到的元素（不包括用户输入）都应该支持切换语言，包括表单错误提醒！目前我所使用的切换语言的方法很简单：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">v-if</span>=<span class=\"string\">\"$blockBoxValidator.message_aa.required\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"lang\"</span> <span class=\"attr\">data-key</span>=<span class=\"string\">\"blockBoxAA\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;</span><span class=\"javascript\"></span><br><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">//多语言处理</span></span><br><span class=\"line\">\t$(<span class=\"string\">\".lang\"</span>).each(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">node</span>)</span>&#123;</span><br><span class=\"line\">\t\t$(<span class=\"keyword\">this</span>).html($langCFG[$(<span class=\"keyword\">this</span>).data(<span class=\"string\">\"key\"</span>)]);</span><br><span class=\"line\">\t&#125;);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>利用jquery的<code>domready</code>事件来第一时间替换需要显示的文字！这就有个问题出现了，若你在<code>domready</code>事件触发前就初始化了vue和vue-validator，根据表单验证逻辑很可能导致<code>v-if</code>指令直接干掉表示错误信息的那个<code>p</code>标签，所以自然也不会正确的执行多语言替换的逻辑。</p>\n<p>在不考虑花时间研究vue-validator生命周期的前提下，我们如何更快的绕过这个问题呢？第一感觉是，将初始化vue和vue-validator的工作也放在<code>domready</code>中（但注意一定要放在多语言处理的代码之后）。不过你还会遇到另外一个问题，这个时候你在浏览器调试终端中按照vue官方的例子打印你创建的<code>vm</code>时，会报错提示变量定义不存在~具体原因不清楚，不过我们依然可以搞定这个问题，最终的代码如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">v-if</span>=<span class=\"string\">\"$blockBoxValidator.message_aa.required\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"lang\"</span> <span class=\"attr\">data-key</span>=<span class=\"string\">\"blockBoxAA\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;</span><span class=\"javascript\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> blockBox = <span class=\"literal\">null</span>;\t<span class=\"comment\">//变量声明，这样能保证在调试终端中可以直接使用'blockBox.$log()'</span></span><br><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">//多语言处理</span></span><br><span class=\"line\">\t$(<span class=\"string\">\".lang\"</span>).each(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">node</span>)</span>&#123;</span><br><span class=\"line\">\t\t$(<span class=\"keyword\">this</span>).html($langCFG[$(<span class=\"keyword\">this</span>).data(<span class=\"string\">\"key\"</span>)]);</span><br><span class=\"line\">\t&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//放在多语言处理下面，且在domready事件内</span></span><br><span class=\"line\">\tblockBox = <span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">\t\tel: <span class=\"string\">\"#blockBox\"</span>,</span><br><span class=\"line\">\t\tdata: &#123;</span><br><span class=\"line\">\t\t\ttable: &#123;</span><br><span class=\"line\">\t\t\t\trowA: &#123;</span><br><span class=\"line\">\t\t\t\t\tcolumnA: <span class=\"string\">\"a-a\"</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnB: <span class=\"string\">'a-b'</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnC: <span class=\"string\">'a-c'</span></span><br><span class=\"line\">\t\t\t\t&#125;,</span><br><span class=\"line\">\t\t\t\trowB: &#123;</span><br><span class=\"line\">\t\t\t\t\tcolumnA: <span class=\"string\">'b-a'</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnB: <span class=\"string\">'b-b'</span>,</span><br><span class=\"line\">\t\t\t\t\tcolumnC: <span class=\"string\">'b-c'</span></span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>理论上，你只要把你想用js做的业务逻辑代码都放在<code>domready</code>事件的回调方法中的vue初始化之后，就可以像和单独使用vue写代码一样的流程来进行开发了！</p>\n<h5 id=\"页面初次加载显示问题\"><a href=\"#页面初次加载显示问题\" class=\"headerlink\" title=\"页面初次加载显示问题\"></a>页面初次加载显示问题</h5><p>这应该不是vue-validator的问题，这应该属于vue的问题域。之前angular推荐的解决方案是提供了一个指令来监听模版解析完毕的事件。<br>我搜了一圈没找到官方或第三方提供的类似功能的实现，不过自己来做也不是什么难事儿：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span> <span class=\"attr\">id</span>=<span class=\"string\">\"body\"</span> <span class=\"attr\">style</span>=<span class=\"string\">\"display:none\"</span>&gt;</span></span><br><span class=\"line\">&#123;&#123;test&#125;&#125;</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;</span><span class=\"javascript\"></span><br><span class=\"line\"><span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">\tel:<span class=\"string\">\"#body\"</span>,</span><br><span class=\"line\">\tready: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t\t$(<span class=\"string\">\"#body\"</span>).show();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>其实思路就是借助vue组件的生命周期hook来及时的修改css样式，你也可以添加loading动画等高级特效，我懒我就不弄了~</p>\n<h5 id=\"resetValidation\"><a href=\"#resetValidation\" class=\"headerlink\" title=\"$resetValidation()\"></a>$resetValidation()</h5><p>重置验证的场景是这样的：当你的表单被用户合法修改保存后，用户并没有跳转到其他页面，仍然在当前页面下，由于表单内容已经和最原始的版本不一样，你需要resetValidation一下从而使vue-validator的各个状态匹配业务场景（包括但不限于<code>dirty</code>,<code>modified</code>等状态）。不过这里有两个小插曲：</p>\n<ol>\n<li>我直接使用的bootcdn提供的版本导致js报错说$resetValidation()未定义，切换成官方的最新版本即可解决；</li>\n<li>应该是跟vue的<a href=\"http://vuejs.org.cn/guide/reactivity.html#异步更新队列\">vm更新机制</a>有关:</li>\n</ol>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> that = <span class=\"keyword\">this</span>;</span><br><span class=\"line\">setTimeout(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\tthat.$resetValidation();</span><br><span class=\"line\">&#125;,<span class=\"number\">0</span>);</span><br></pre></td></tr></table></figure>\n<p>否则呢，你无法看到期望的结果~</p>\n<h5 id=\"lazy的正确使用方法\"><a href=\"#lazy的正确使用方法\" class=\"headerlink\" title=\"lazy的正确使用方法\"></a>lazy的正确使用方法</h5><p>有些表单的初始化数据需要异步获取，太正常不过了，对吧？vue-validator提供了lazy模式，刚好匹配这种场景。所以，你只需要在<code>validator</code>标签上添加<code>lazy</code>属性即可，<a href=\"http://vuejs.github.io/vue-validator/en/lazy.html\">官方例子</a>简单明了，似乎没有什么要解释的！不过，问题来了，官方的例子代码是基于vue的动态组件写的，动态组件才有<code>activate</code>事件，而如果你像我一样是用在普通组件下的，那么自然不会触发<code>activate</code>事件，那回调逻辑自然不会被执行，<code>this.$activateValidator()</code>不会执行的话，看看vue-validator会提示什么：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[vue-validator] validator element directive need to specify &apos;name&apos; param attribute: (e.g. &lt;validator name=&quot;validator1&quot;&gt;...&lt;/validator&gt;)</span><br></pre></td></tr></table></figure>\n<p>看起来提示的非常不准确，让我排查了好久，甚至去联系作者来查看这个问题！其实你只要确保在正确的时机调用<code>$activateValidator()</code>方法就可以了，那什么叫正确的时机：</p>\n<ul>\n<li>普通组件的<code>ready</code>事件回调中</li>\n<li>动态组件的<code>activate</code>事件回调中</li>\n</ul>\n<p>否则你一定会看到上面的那个提醒，特别提醒，下面的写法依然会看到提醒：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ready: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\tsetTimeout(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.$activateValidator();</span><br><span class=\"line\">\t&#125;.bind(<span class=\"keyword\">this</span>), <span class=\"number\">3000</span>);</span><br><span class=\"line\">&#125;,</span><br></pre></td></tr></table></figure>\n<p>这应该是作者好心办的”错事儿”吧，他要求你只能在组件渲染前把该做的都做了（数据获取），不然你就是在自讨苦吃~当然，这种设计哲学并非没有道理，全看权衡和喜好！</p>\n<hr>\n<p>好了，先总结到这里，如果以后有啥新的结论，再说~</p>\n"},{"title":"监听滚动条根据元素是否在屏幕上来触发指定逻辑","date":"2016-03-27T01:37:00.000Z","_content":"\n好久没写网站类型的项目，所以一直好奇一些网站右下角的导航是如何实现的，可以根据用户浏览的内容来动态匹配导航条。\n\n根据项目需要，写了一个监听滚动条的模块，具体用法和实现细节可以去github看源码：[传送门](https://github.com/kazaff/scrollWatch)。\n\n小总结：\n\n- 组件化很锻炼思维：职责，容错，友好\n- 常用的集合操作，使用lodash很爽\n- 如果可以不理会浏览器兼容性，前端真的好幸福\n","source":"_posts/监听滚动条根据元素是否在屏幕上来触发指定逻辑.md","raw":"title:  监听滚动条根据元素是否在屏幕上来触发指定逻辑\ndate: 2016-03-27 09:37:00\ntags:\n- 滚动条\n- 组件化\n- 屏幕位置\ncategories: 前端\n---\n\n好久没写网站类型的项目，所以一直好奇一些网站右下角的导航是如何实现的，可以根据用户浏览的内容来动态匹配导航条。\n\n根据项目需要，写了一个监听滚动条的模块，具体用法和实现细节可以去github看源码：[传送门](https://github.com/kazaff/scrollWatch)。\n\n小总结：\n\n- 组件化很锻炼思维：职责，容错，友好\n- 常用的集合操作，使用lodash很爽\n- 如果可以不理会浏览器兼容性，前端真的好幸福\n","slug":"监听滚动条根据元素是否在屏幕上来触发指定逻辑","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cinbsa42v0009l3fygae4saau","comments":1,"layout":"post","photos":[],"link":"","content":"<p>好久没写网站类型的项目，所以一直好奇一些网站右下角的导航是如何实现的，可以根据用户浏览的内容来动态匹配导航条。</p>\n<p>根据项目需要，写了一个监听滚动条的模块，具体用法和实现细节可以去github看源码：<a href=\"https://github.com/kazaff/scrollWatch\" target=\"_blank\" rel=\"external\">传送门</a>。</p>\n<p>小总结：</p>\n<ul>\n<li>组件化很锻炼思维：职责，容错，友好</li>\n<li>常用的集合操作，使用lodash很爽</li>\n<li>如果可以不理会浏览器兼容性，前端真的好幸福</li>\n</ul>\n","excerpt":"","more":"<p>好久没写网站类型的项目，所以一直好奇一些网站右下角的导航是如何实现的，可以根据用户浏览的内容来动态匹配导航条。</p>\n<p>根据项目需要，写了一个监听滚动条的模块，具体用法和实现细节可以去github看源码：<a href=\"https://github.com/kazaff/scrollWatch\">传送门</a>。</p>\n<p>小总结：</p>\n<ul>\n<li>组件化很锻炼思维：职责，容错，友好</li>\n<li>常用的集合操作，使用lodash很爽</li>\n<li>如果可以不理会浏览器兼容性，前端真的好幸福</li>\n</ul>\n"},{"title":"前端多入口项目如何实现根据用户权限配置显示菜单","date":"2016-03-30T01:37:00.000Z","_content":"\n目标是要为一个ERP项目做前端实现，该项目前后端通信完全走REST，不过由于项目时间和人力有限，前端开发人员对目前主流的MVVM框架并不了解，所以之前的单入口思路就无法复用了。\n\n这次前端实现采用的是多入口设计，且不使用html iframe方案。基于jquery的dom操作和ajax来完成大多数开发任务，引入lodash作为工具库来处理复杂数据结构。\n\n再来说一下项目的概况，和大多数后台管理系统一样，这个ERP依然提供为用户配置操作权限的功能，这就要求前端界面需要根据用户的实际操作权限来响应哪些操作链接可以显示在界面上，哪些需要隐藏起来。当然，这只是为了界面显示做的配置，实际后端服务依然会判断用户权限的，不过界面上根据用户权限来控制菜单或按钮的显示情况，也是必不可少的。\n\n除此之外，考虑到这个ERP功能是按照模块划分的，每个模块的功能相对独立，映射到项目结构上，我希望每个模块的相关代码（html，js，css等）都应该存放在各自的模块文件夹下，为将来维护提供良好的基础。\n\n万幸的是，目前项目只针对chrome高版本，意味着我们可以不鸟兼容问题！！！\n\n具体实现细节，推荐看项目的[boot.js代码](https://github.com/kazaff/menuIfShow/blob/master/boot.js)。\n\n","source":"_posts/前端多入口项目如何实现根据用户权限配置显示菜单.md","raw":"title:  前端多入口项目如何实现根据用户权限配置显示菜单\ndate: 2016-03-30 09:37:00\ntags:\n- 多入口\n- jquery\n- 权限\n- 菜单\ncategories: 前端\n---\n\n目标是要为一个ERP项目做前端实现，该项目前后端通信完全走REST，不过由于项目时间和人力有限，前端开发人员对目前主流的MVVM框架并不了解，所以之前的单入口思路就无法复用了。\n\n这次前端实现采用的是多入口设计，且不使用html iframe方案。基于jquery的dom操作和ajax来完成大多数开发任务，引入lodash作为工具库来处理复杂数据结构。\n\n再来说一下项目的概况，和大多数后台管理系统一样，这个ERP依然提供为用户配置操作权限的功能，这就要求前端界面需要根据用户的实际操作权限来响应哪些操作链接可以显示在界面上，哪些需要隐藏起来。当然，这只是为了界面显示做的配置，实际后端服务依然会判断用户权限的，不过界面上根据用户权限来控制菜单或按钮的显示情况，也是必不可少的。\n\n除此之外，考虑到这个ERP功能是按照模块划分的，每个模块的功能相对独立，映射到项目结构上，我希望每个模块的相关代码（html，js，css等）都应该存放在各自的模块文件夹下，为将来维护提供良好的基础。\n\n万幸的是，目前项目只针对chrome高版本，意味着我们可以不鸟兼容问题！！！\n\n具体实现细节，推荐看项目的[boot.js代码](https://github.com/kazaff/menuIfShow/blob/master/boot.js)。\n\n","slug":"前端多入口项目如何实现根据用户权限配置显示菜单","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cinbsa436000hl3fys8l9oqip","comments":1,"layout":"post","photos":[],"link":"","content":"<p>目标是要为一个ERP项目做前端实现，该项目前后端通信完全走REST，不过由于项目时间和人力有限，前端开发人员对目前主流的MVVM框架并不了解，所以之前的单入口思路就无法复用了。</p>\n<p>这次前端实现采用的是多入口设计，且不使用html iframe方案。基于jquery的dom操作和ajax来完成大多数开发任务，引入lodash作为工具库来处理复杂数据结构。</p>\n<p>再来说一下项目的概况，和大多数后台管理系统一样，这个ERP依然提供为用户配置操作权限的功能，这就要求前端界面需要根据用户的实际操作权限来响应哪些操作链接可以显示在界面上，哪些需要隐藏起来。当然，这只是为了界面显示做的配置，实际后端服务依然会判断用户权限的，不过界面上根据用户权限来控制菜单或按钮的显示情况，也是必不可少的。</p>\n<p>除此之外，考虑到这个ERP功能是按照模块划分的，每个模块的功能相对独立，映射到项目结构上，我希望每个模块的相关代码（html，js，css等）都应该存放在各自的模块文件夹下，为将来维护提供良好的基础。</p>\n<p>万幸的是，目前项目只针对chrome高版本，意味着我们可以不鸟兼容问题！！！</p>\n<p>具体实现细节，推荐看项目的<a href=\"https://github.com/kazaff/menuIfShow/blob/master/boot.js\" target=\"_blank\" rel=\"external\">boot.js代码</a>。</p>\n","excerpt":"","more":"<p>目标是要为一个ERP项目做前端实现，该项目前后端通信完全走REST，不过由于项目时间和人力有限，前端开发人员对目前主流的MVVM框架并不了解，所以之前的单入口思路就无法复用了。</p>\n<p>这次前端实现采用的是多入口设计，且不使用html iframe方案。基于jquery的dom操作和ajax来完成大多数开发任务，引入lodash作为工具库来处理复杂数据结构。</p>\n<p>再来说一下项目的概况，和大多数后台管理系统一样，这个ERP依然提供为用户配置操作权限的功能，这就要求前端界面需要根据用户的实际操作权限来响应哪些操作链接可以显示在界面上，哪些需要隐藏起来。当然，这只是为了界面显示做的配置，实际后端服务依然会判断用户权限的，不过界面上根据用户权限来控制菜单或按钮的显示情况，也是必不可少的。</p>\n<p>除此之外，考虑到这个ERP功能是按照模块划分的，每个模块的功能相对独立，映射到项目结构上，我希望每个模块的相关代码（html，js，css等）都应该存放在各自的模块文件夹下，为将来维护提供良好的基础。</p>\n<p>万幸的是，目前项目只针对chrome高版本，意味着我们可以不鸟兼容问题！！！</p>\n<p>具体实现细节，推荐看项目的<a href=\"https://github.com/kazaff/menuIfShow/blob/master/boot.js\">boot.js代码</a>。</p>\n"},{"title":"gmailWatcher之node","date":"2016-05-01T01:37:00.000Z","_content":"\nEmail是一个可能比很多人岁数都大的“上古神器”，尽管和它同期出生的小伙伴很多都已经寿终正寝，但它却依然坚挺，可见其代表了多大的用户刚需！\n\n最近热映的《北京遇上西雅图2》讲的就是邮件的爱情故事，正巧又碰上项目新需求包含mail的收发要求，就借此良机好好学习一下这个陪伴我们很久的大伙伴。\n<!--more-->\n### 理论知识\n\n如果你是在不知道什么是Email，那我只能说：看看这篇生动的[微小说](http://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&mid=2665513086&idx=1&sn=ad45995d6c6e355d4dc7cf90815560a8#rd)吧。\n\n好，我们来先聊聊几个关键词：\n\n- [邮件协议](http://baike.baidu.com/view/2367542.htm)：LDAP、SMTP、POP、IMAP\n- 邮件服务器：商用厂商（gmail.com、163.com）、自建邮件服务\n- 邮件客户端：原生客户端（outlook）、网页邮箱系统、浏览器插件、自建邮件客户端\n\n提到“自建邮件服务器”，勾起了我痛苦的回忆，之前在前任公司为了在centos上手动搭建邮件服务，让我反复安装操作系统N次（不要问我为什么）。所以这篇文章并不是讲如何搭建邮件服务器的，我们会使用gmail作为我们的邮件服务器。\n\n由于我们的主题是邮件获取，所以POP和IMAP协议是我们主要需要了解的内容，这里我使用的是 **IMAP**，因为[它新](https://zh.wikipedia.org/wiki/IMAP)。\n\n### 需求分析\n\n我们要做的是这么一件事儿：\n\n> 监控我们指定的一个gmail帐号，一旦该邮箱收到邮件，就解析邮件内容（包括附件）,并将该邮件标识为已读（确保不会重复处理该邮件）。\n\n目标明确，可以开始写代码了！等等，其实如此常见的需求一定已经有大量的实现方案，不管是php，java，还是python，或是今天我们要使用的nodejs，都已经有现成的库或框架来供我们使用了。\n\n不过我们上面的理论知识可以辅助我们知道，要实现这么一个需求，我们的思路是：\n\n1. 使用对应协议和目标邮箱建立链接\n2. 获取满足条件的邮件数据\n3. 根据协议解析数据，获取我们需要的属性（发件人，标题，内容以及附件）\n4. 更新该邮件的状态为已读\n5. 持续监听“新邮件”事件，重复第2步\n\n这里面我们忽略了一些细节复杂问题，如：\n\n- 邮箱安全认证问题\n- 邮箱链接中断处理\n- 邮件解析失败\n- 大邮件解析资源损耗（主要是大附件导致的内存损耗）\n- 海量邮件的并发处理模型\n- 其它\n\n### 现有库\n\n相信现有的解决方案可以帮我们完成上述的各个方面，那么nodejs为我们提供了怎样的现成代码呢？经过一番搜索，锁定了这个库：[mail-listener2](https://github.com/kazaff/mail-listener2)(注意这里给的链接是我已经fork后的，并加了一些中文注释和小修改)。\n\n我已经在其中的关键部分添加了近乎啰嗦的注释，所以这里就不重复制造垃圾了。这里需要特别说明一下的是，该库使用了[aysnc并发库](http://blog.fens.me/nodejs-async/)，依赖其提供的并发模型让实现代码简化了不少，推荐大家在自己的项目中也大胆使用。\n\n还有就是，如果你针对附件解析开启了流处理，那你需要自己来处理附件流，该库的并没有在开启流处理后帮你把附件保存在指定位置，不过扩展起来也很简单，只需要在对应的位置添加：\n\n```javascript\n//替换该行fs.writeFile(self.attachmentOptions.directory + attachment.generatedFileName, attachment.content, function(err)\nattachment.stream.pipe(fs.createWriteStream(self.attachmentOptions.directory + attachment.generatedFileName+attachment.generatedFileName));\n```\n\n除此之外，该库并没有保留\"node-imap\"中的关于超时的相关参数，这会导致网速不太好的环境无法使用，建议后期加上下面俩参数：\n\n- connTimeout 创建连接的超时时间，node-imap默认是10000毫秒\n- authTimeout 连接创建完毕后认证的超时时间，node-imap默认是5000毫秒\n\n这个库其实只是简单的封装了一下[node-imap](https://github.com/mscdex/node-imap)和[mailparser](https://github.com/andris9/mailparser)。\n\n这俩库才是真正完成我们前面说的步骤，其中\"node-imap\"学习起来成本较高，主要是你得先了解imap协议本身。在协议之上该作者增加了nodejs的一些语言特性，靠事件来组织业务，所以需要静下来好好看看。\n\n### 异常处理方案\n\n目前为止，基本上除了异常处理，其他工作都被库做完了，娃哈哈，生活就是如此美好！那，我们应该如何处理异常才比较合适呢？\n\n这还是要看业务需求，如果你开发的是一个用户参与度很高的客户端，那你只需要在异常发生后上报给用户即可，例如弹窗。\n\n但如果是一个后台常驻服务，就不仅要考虑上报异常的方法，还需要考虑如何保证碰到无法恢复的异常后应用线程会自动重启，听起来很高大上，但其实[PM2](http://pm2.keymetrics.io/)已经帮你实现了。除此之外，国内BAT好像也都有自己的nodejs运维方案供我们选择。\n\n### 结尾\n\n相信已经说的够详细了，剩下的就靠大家留言了！\n","source":"_posts/gmailWatcher之node.md","raw":"title:  gmailWatcher之node\ndate: 2016-05-01 09:37:00\ntags:\n- gmail\n- imap\n- async\n- mailparser\ncategories: nodejs\n---\n\nEmail是一个可能比很多人岁数都大的“上古神器”，尽管和它同期出生的小伙伴很多都已经寿终正寝，但它却依然坚挺，可见其代表了多大的用户刚需！\n\n最近热映的《北京遇上西雅图2》讲的就是邮件的爱情故事，正巧又碰上项目新需求包含mail的收发要求，就借此良机好好学习一下这个陪伴我们很久的大伙伴。\n<!--more-->\n### 理论知识\n\n如果你是在不知道什么是Email，那我只能说：看看这篇生动的[微小说](http://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&mid=2665513086&idx=1&sn=ad45995d6c6e355d4dc7cf90815560a8#rd)吧。\n\n好，我们来先聊聊几个关键词：\n\n- [邮件协议](http://baike.baidu.com/view/2367542.htm)：LDAP、SMTP、POP、IMAP\n- 邮件服务器：商用厂商（gmail.com、163.com）、自建邮件服务\n- 邮件客户端：原生客户端（outlook）、网页邮箱系统、浏览器插件、自建邮件客户端\n\n提到“自建邮件服务器”，勾起了我痛苦的回忆，之前在前任公司为了在centos上手动搭建邮件服务，让我反复安装操作系统N次（不要问我为什么）。所以这篇文章并不是讲如何搭建邮件服务器的，我们会使用gmail作为我们的邮件服务器。\n\n由于我们的主题是邮件获取，所以POP和IMAP协议是我们主要需要了解的内容，这里我使用的是 **IMAP**，因为[它新](https://zh.wikipedia.org/wiki/IMAP)。\n\n### 需求分析\n\n我们要做的是这么一件事儿：\n\n> 监控我们指定的一个gmail帐号，一旦该邮箱收到邮件，就解析邮件内容（包括附件）,并将该邮件标识为已读（确保不会重复处理该邮件）。\n\n目标明确，可以开始写代码了！等等，其实如此常见的需求一定已经有大量的实现方案，不管是php，java，还是python，或是今天我们要使用的nodejs，都已经有现成的库或框架来供我们使用了。\n\n不过我们上面的理论知识可以辅助我们知道，要实现这么一个需求，我们的思路是：\n\n1. 使用对应协议和目标邮箱建立链接\n2. 获取满足条件的邮件数据\n3. 根据协议解析数据，获取我们需要的属性（发件人，标题，内容以及附件）\n4. 更新该邮件的状态为已读\n5. 持续监听“新邮件”事件，重复第2步\n\n这里面我们忽略了一些细节复杂问题，如：\n\n- 邮箱安全认证问题\n- 邮箱链接中断处理\n- 邮件解析失败\n- 大邮件解析资源损耗（主要是大附件导致的内存损耗）\n- 海量邮件的并发处理模型\n- 其它\n\n### 现有库\n\n相信现有的解决方案可以帮我们完成上述的各个方面，那么nodejs为我们提供了怎样的现成代码呢？经过一番搜索，锁定了这个库：[mail-listener2](https://github.com/kazaff/mail-listener2)(注意这里给的链接是我已经fork后的，并加了一些中文注释和小修改)。\n\n我已经在其中的关键部分添加了近乎啰嗦的注释，所以这里就不重复制造垃圾了。这里需要特别说明一下的是，该库使用了[aysnc并发库](http://blog.fens.me/nodejs-async/)，依赖其提供的并发模型让实现代码简化了不少，推荐大家在自己的项目中也大胆使用。\n\n还有就是，如果你针对附件解析开启了流处理，那你需要自己来处理附件流，该库的并没有在开启流处理后帮你把附件保存在指定位置，不过扩展起来也很简单，只需要在对应的位置添加：\n\n```javascript\n//替换该行fs.writeFile(self.attachmentOptions.directory + attachment.generatedFileName, attachment.content, function(err)\nattachment.stream.pipe(fs.createWriteStream(self.attachmentOptions.directory + attachment.generatedFileName+attachment.generatedFileName));\n```\n\n除此之外，该库并没有保留\"node-imap\"中的关于超时的相关参数，这会导致网速不太好的环境无法使用，建议后期加上下面俩参数：\n\n- connTimeout 创建连接的超时时间，node-imap默认是10000毫秒\n- authTimeout 连接创建完毕后认证的超时时间，node-imap默认是5000毫秒\n\n这个库其实只是简单的封装了一下[node-imap](https://github.com/mscdex/node-imap)和[mailparser](https://github.com/andris9/mailparser)。\n\n这俩库才是真正完成我们前面说的步骤，其中\"node-imap\"学习起来成本较高，主要是你得先了解imap协议本身。在协议之上该作者增加了nodejs的一些语言特性，靠事件来组织业务，所以需要静下来好好看看。\n\n### 异常处理方案\n\n目前为止，基本上除了异常处理，其他工作都被库做完了，娃哈哈，生活就是如此美好！那，我们应该如何处理异常才比较合适呢？\n\n这还是要看业务需求，如果你开发的是一个用户参与度很高的客户端，那你只需要在异常发生后上报给用户即可，例如弹窗。\n\n但如果是一个后台常驻服务，就不仅要考虑上报异常的方法，还需要考虑如何保证碰到无法恢复的异常后应用线程会自动重启，听起来很高大上，但其实[PM2](http://pm2.keymetrics.io/)已经帮你实现了。除此之外，国内BAT好像也都有自己的nodejs运维方案供我们选择。\n\n### 结尾\n\n相信已经说的够详细了，剩下的就靠大家留言了！\n","slug":"gmailWatcher之node","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cio4dt7s10000safy77rivgxl","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Email是一个可能比很多人岁数都大的“上古神器”，尽管和它同期出生的小伙伴很多都已经寿终正寝，但它却依然坚挺，可见其代表了多大的用户刚需！</p>\n<p>最近热映的《北京遇上西雅图2》讲的就是邮件的爱情故事，正巧又碰上项目新需求包含mail的收发要求，就借此良机好好学习一下这个陪伴我们很久的大伙伴。<br><a id=\"more\"></a></p>\n<h3 id=\"理论知识\"><a href=\"#理论知识\" class=\"headerlink\" title=\"理论知识\"></a>理论知识</h3><p>如果你是在不知道什么是Email，那我只能说：看看这篇生动的<a href=\"http://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&amp;mid=2665513086&amp;idx=1&amp;sn=ad45995d6c6e355d4dc7cf90815560a8#rd\" target=\"_blank\" rel=\"external\">微小说</a>吧。</p>\n<p>好，我们来先聊聊几个关键词：</p>\n<ul>\n<li><a href=\"http://baike.baidu.com/view/2367542.htm\" target=\"_blank\" rel=\"external\">邮件协议</a>：LDAP、SMTP、POP、IMAP</li>\n<li>邮件服务器：商用厂商（gmail.com、163.com）、自建邮件服务</li>\n<li>邮件客户端：原生客户端（outlook）、网页邮箱系统、浏览器插件、自建邮件客户端</li>\n</ul>\n<p>提到“自建邮件服务器”，勾起了我痛苦的回忆，之前在前任公司为了在centos上手动搭建邮件服务，让我反复安装操作系统N次（不要问我为什么）。所以这篇文章并不是讲如何搭建邮件服务器的，我们会使用gmail作为我们的邮件服务器。</p>\n<p>由于我们的主题是邮件获取，所以POP和IMAP协议是我们主要需要了解的内容，这里我使用的是 <strong>IMAP</strong>，因为<a href=\"https://zh.wikipedia.org/wiki/IMAP\" target=\"_blank\" rel=\"external\">它新</a>。</p>\n<h3 id=\"需求分析\"><a href=\"#需求分析\" class=\"headerlink\" title=\"需求分析\"></a>需求分析</h3><p>我们要做的是这么一件事儿：</p>\n<blockquote>\n<p>监控我们指定的一个gmail帐号，一旦该邮箱收到邮件，就解析邮件内容（包括附件）,并将该邮件标识为已读（确保不会重复处理该邮件）。</p>\n</blockquote>\n<p>目标明确，可以开始写代码了！等等，其实如此常见的需求一定已经有大量的实现方案，不管是php，java，还是python，或是今天我们要使用的nodejs，都已经有现成的库或框架来供我们使用了。</p>\n<p>不过我们上面的理论知识可以辅助我们知道，要实现这么一个需求，我们的思路是：</p>\n<ol>\n<li>使用对应协议和目标邮箱建立链接</li>\n<li>获取满足条件的邮件数据</li>\n<li>根据协议解析数据，获取我们需要的属性（发件人，标题，内容以及附件）</li>\n<li>更新该邮件的状态为已读</li>\n<li>持续监听“新邮件”事件，重复第2步</li>\n</ol>\n<p>这里面我们忽略了一些细节复杂问题，如：</p>\n<ul>\n<li>邮箱安全认证问题</li>\n<li>邮箱链接中断处理</li>\n<li>邮件解析失败</li>\n<li>大邮件解析资源损耗（主要是大附件导致的内存损耗）</li>\n<li>海量邮件的并发处理模型</li>\n<li>其它</li>\n</ul>\n<h3 id=\"现有库\"><a href=\"#现有库\" class=\"headerlink\" title=\"现有库\"></a>现有库</h3><p>相信现有的解决方案可以帮我们完成上述的各个方面，那么nodejs为我们提供了怎样的现成代码呢？经过一番搜索，锁定了这个库：<a href=\"https://github.com/kazaff/mail-listener2\" target=\"_blank\" rel=\"external\">mail-listener2</a>(注意这里给的链接是我已经fork后的，并加了一些中文注释和小修改)。</p>\n<p>我已经在其中的关键部分添加了近乎啰嗦的注释，所以这里就不重复制造垃圾了。这里需要特别说明一下的是，该库使用了<a href=\"http://blog.fens.me/nodejs-async/\" target=\"_blank\" rel=\"external\">aysnc并发库</a>，依赖其提供的并发模型让实现代码简化了不少，推荐大家在自己的项目中也大胆使用。</p>\n<p>还有就是，如果你针对附件解析开启了流处理，那你需要自己来处理附件流，该库的并没有在开启流处理后帮你把附件保存在指定位置，不过扩展起来也很简单，只需要在对应的位置添加：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//替换该行fs.writeFile(self.attachmentOptions.directory + attachment.generatedFileName, attachment.content, function(err)</span></span><br><span class=\"line\">attachment.stream.pipe(fs.createWriteStream(self.attachmentOptions.directory + attachment.generatedFileName+attachment.generatedFileName));</span><br></pre></td></tr></table></figure>\n<p>除此之外，该库并没有保留”node-imap”中的关于超时的相关参数，这会导致网速不太好的环境无法使用，建议后期加上下面俩参数：</p>\n<ul>\n<li>connTimeout 创建连接的超时时间，node-imap默认是10000毫秒</li>\n<li>authTimeout 连接创建完毕后认证的超时时间，node-imap默认是5000毫秒</li>\n</ul>\n<p>这个库其实只是简单的封装了一下<a href=\"https://github.com/mscdex/node-imap\" target=\"_blank\" rel=\"external\">node-imap</a>和<a href=\"https://github.com/andris9/mailparser\" target=\"_blank\" rel=\"external\">mailparser</a>。</p>\n<p>这俩库才是真正完成我们前面说的步骤，其中”node-imap”学习起来成本较高，主要是你得先了解imap协议本身。在协议之上该作者增加了nodejs的一些语言特性，靠事件来组织业务，所以需要静下来好好看看。</p>\n<h3 id=\"异常处理方案\"><a href=\"#异常处理方案\" class=\"headerlink\" title=\"异常处理方案\"></a>异常处理方案</h3><p>目前为止，基本上除了异常处理，其他工作都被库做完了，娃哈哈，生活就是如此美好！那，我们应该如何处理异常才比较合适呢？</p>\n<p>这还是要看业务需求，如果你开发的是一个用户参与度很高的客户端，那你只需要在异常发生后上报给用户即可，例如弹窗。</p>\n<p>但如果是一个后台常驻服务，就不仅要考虑上报异常的方法，还需要考虑如何保证碰到无法恢复的异常后应用线程会自动重启，听起来很高大上，但其实<a href=\"http://pm2.keymetrics.io/\" target=\"_blank\" rel=\"external\">PM2</a>已经帮你实现了。除此之外，国内BAT好像也都有自己的nodejs运维方案供我们选择。</p>\n<h3 id=\"结尾\"><a href=\"#结尾\" class=\"headerlink\" title=\"结尾\"></a>结尾</h3><p>相信已经说的够详细了，剩下的就靠大家留言了！</p>\n","excerpt":"<p>Email是一个可能比很多人岁数都大的“上古神器”，尽管和它同期出生的小伙伴很多都已经寿终正寝，但它却依然坚挺，可见其代表了多大的用户刚需！</p>\n<p>最近热映的《北京遇上西雅图2》讲的就是邮件的爱情故事，正巧又碰上项目新需求包含mail的收发要求，就借此良机好好学习一下这个陪伴我们很久的大伙伴。<br>","more":"</p>\n<h3 id=\"理论知识\"><a href=\"#理论知识\" class=\"headerlink\" title=\"理论知识\"></a>理论知识</h3><p>如果你是在不知道什么是Email，那我只能说：看看这篇生动的<a href=\"http://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&amp;mid=2665513086&amp;idx=1&amp;sn=ad45995d6c6e355d4dc7cf90815560a8#rd\">微小说</a>吧。</p>\n<p>好，我们来先聊聊几个关键词：</p>\n<ul>\n<li><a href=\"http://baike.baidu.com/view/2367542.htm\">邮件协议</a>：LDAP、SMTP、POP、IMAP</li>\n<li>邮件服务器：商用厂商（gmail.com、163.com）、自建邮件服务</li>\n<li>邮件客户端：原生客户端（outlook）、网页邮箱系统、浏览器插件、自建邮件客户端</li>\n</ul>\n<p>提到“自建邮件服务器”，勾起了我痛苦的回忆，之前在前任公司为了在centos上手动搭建邮件服务，让我反复安装操作系统N次（不要问我为什么）。所以这篇文章并不是讲如何搭建邮件服务器的，我们会使用gmail作为我们的邮件服务器。</p>\n<p>由于我们的主题是邮件获取，所以POP和IMAP协议是我们主要需要了解的内容，这里我使用的是 <strong>IMAP</strong>，因为<a href=\"https://zh.wikipedia.org/wiki/IMAP\">它新</a>。</p>\n<h3 id=\"需求分析\"><a href=\"#需求分析\" class=\"headerlink\" title=\"需求分析\"></a>需求分析</h3><p>我们要做的是这么一件事儿：</p>\n<blockquote>\n<p>监控我们指定的一个gmail帐号，一旦该邮箱收到邮件，就解析邮件内容（包括附件）,并将该邮件标识为已读（确保不会重复处理该邮件）。</p>\n</blockquote>\n<p>目标明确，可以开始写代码了！等等，其实如此常见的需求一定已经有大量的实现方案，不管是php，java，还是python，或是今天我们要使用的nodejs，都已经有现成的库或框架来供我们使用了。</p>\n<p>不过我们上面的理论知识可以辅助我们知道，要实现这么一个需求，我们的思路是：</p>\n<ol>\n<li>使用对应协议和目标邮箱建立链接</li>\n<li>获取满足条件的邮件数据</li>\n<li>根据协议解析数据，获取我们需要的属性（发件人，标题，内容以及附件）</li>\n<li>更新该邮件的状态为已读</li>\n<li>持续监听“新邮件”事件，重复第2步</li>\n</ol>\n<p>这里面我们忽略了一些细节复杂问题，如：</p>\n<ul>\n<li>邮箱安全认证问题</li>\n<li>邮箱链接中断处理</li>\n<li>邮件解析失败</li>\n<li>大邮件解析资源损耗（主要是大附件导致的内存损耗）</li>\n<li>海量邮件的并发处理模型</li>\n<li>其它</li>\n</ul>\n<h3 id=\"现有库\"><a href=\"#现有库\" class=\"headerlink\" title=\"现有库\"></a>现有库</h3><p>相信现有的解决方案可以帮我们完成上述的各个方面，那么nodejs为我们提供了怎样的现成代码呢？经过一番搜索，锁定了这个库：<a href=\"https://github.com/kazaff/mail-listener2\">mail-listener2</a>(注意这里给的链接是我已经fork后的，并加了一些中文注释和小修改)。</p>\n<p>我已经在其中的关键部分添加了近乎啰嗦的注释，所以这里就不重复制造垃圾了。这里需要特别说明一下的是，该库使用了<a href=\"http://blog.fens.me/nodejs-async/\">aysnc并发库</a>，依赖其提供的并发模型让实现代码简化了不少，推荐大家在自己的项目中也大胆使用。</p>\n<p>还有就是，如果你针对附件解析开启了流处理，那你需要自己来处理附件流，该库的并没有在开启流处理后帮你把附件保存在指定位置，不过扩展起来也很简单，只需要在对应的位置添加：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//替换该行fs.writeFile(self.attachmentOptions.directory + attachment.generatedFileName, attachment.content, function(err)</span></span><br><span class=\"line\">attachment.stream.pipe(fs.createWriteStream(self.attachmentOptions.directory + attachment.generatedFileName+attachment.generatedFileName));</span><br></pre></td></tr></table></figure>\n<p>除此之外，该库并没有保留”node-imap”中的关于超时的相关参数，这会导致网速不太好的环境无法使用，建议后期加上下面俩参数：</p>\n<ul>\n<li>connTimeout 创建连接的超时时间，node-imap默认是10000毫秒</li>\n<li>authTimeout 连接创建完毕后认证的超时时间，node-imap默认是5000毫秒</li>\n</ul>\n<p>这个库其实只是简单的封装了一下<a href=\"https://github.com/mscdex/node-imap\">node-imap</a>和<a href=\"https://github.com/andris9/mailparser\">mailparser</a>。</p>\n<p>这俩库才是真正完成我们前面说的步骤，其中”node-imap”学习起来成本较高，主要是你得先了解imap协议本身。在协议之上该作者增加了nodejs的一些语言特性，靠事件来组织业务，所以需要静下来好好看看。</p>\n<h3 id=\"异常处理方案\"><a href=\"#异常处理方案\" class=\"headerlink\" title=\"异常处理方案\"></a>异常处理方案</h3><p>目前为止，基本上除了异常处理，其他工作都被库做完了，娃哈哈，生活就是如此美好！那，我们应该如何处理异常才比较合适呢？</p>\n<p>这还是要看业务需求，如果你开发的是一个用户参与度很高的客户端，那你只需要在异常发生后上报给用户即可，例如弹窗。</p>\n<p>但如果是一个后台常驻服务，就不仅要考虑上报异常的方法，还需要考虑如何保证碰到无法恢复的异常后应用线程会自动重启，听起来很高大上，但其实<a href=\"http://pm2.keymetrics.io/\">PM2</a>已经帮你实现了。除此之外，国内BAT好像也都有自己的nodejs运维方案供我们选择。</p>\n<h3 id=\"结尾\"><a href=\"#结尾\" class=\"headerlink\" title=\"结尾\"></a>结尾</h3><p>相信已经说的够详细了，剩下的就靠大家留言了！</p>"},{"title":"只谈服务切分问题","date":"2016-05-02T01:37:00.000Z","_content":"\n一直以来都对“架构”非常感兴趣，早在大学期间，逃课成瘾的我连css都不会但就已经对架构师产生了浓厚的兴趣！\n\n阴差阳错的成了程序员后，又稀里糊涂的做了这么久。工作重心一直围绕着web方向：网站，系统。随着2014年底开始，“微服务”这三个字就好像病毒广告一样烂大街了，丝毫不输于它的前辈“大数据”。\n\n之所以要从“微服务”这个广告语开始谈起，除了因为我自身性格的缘故（总是不自觉的对主流事物感到莫名的反感）外，主要是因为这和我们今天谈的主题非常相关。\n<!--more-->\n从敲下第一行代码开始，我相信每个程序员都在不停的思考一个问题：如何写出更好的代码。这里的“好”，具体应该至少包含：\n\n- 能解决一个具体的问题（本质）\n- 代码排版格式规整（强迫症）\n- 可阅读性强（尊重他人）\n- 维护成本低（修改成本低，让自己活的更滋润）\n- bug少（逻辑思维能力）\n- 抽象程度尽可能高（适配更多的场景，对外提供的接口灵活度高）\n- 文档齐全（大师级别的最低要求）\n\n以上几点，从前到后是有优先级的，希望你可以用心体会。\n\n上面提到的这几点常用于某个具体的业务代码，或者函数方法，或者某个能解决通用问题的类库。其实对于“架构”来说，也同样适用，不过可能需要考虑的因素更宽泛。\n\n说这些和我们今天的主题有关系么？是的。真的？嗯！那到底有什么关系？说白了就是服务边界的问题，这和“职责单一”的概念有些相似，但又不完全相同。\n\n相同之处在于让开发者时刻敏感于当前做的上下文规模问题，不同点在于服务切分时存在更多的 **“灰色区域”**。\n\n正是这些灰色区域的存在，才让大师成为大师，才让新手如此纠结。不过，这正是架构设计的乐趣和挑战！\n\n我并没有许多成功的架构设计经验（是真的，如果你对我下面说的产生了质疑，那这个信息无疑是成为你反驳我的有理证据），但在实际工作中却真真切切的感过那种纠结和尴尬！曾经以为已经考虑的完美无缺，但文档才写了一半就傻眼了，现实业务总是像碰瓷大娘一样拦住去路~\n\n那到底哪些细节需要在设计服务时需要我们警惕呢？我尽自己最大努力总结了一下：\n\n- 能解决一个具体且尽可能完整的业务问题\n- 尽力避免分布式事务\n- 从服务使用者的角度去规划服务的颗粒度\n- 考虑服务监控、容错、负载均衡、服务发现和治理方案\n- 尽量避免采用中心化的服务编排设计，交给服务调用方来做\n\n最后一条应该最具争议性，毕竟这多少有些违背了 **开放关闭** 原则，至少我们很可能误将原本应该隐藏起来的细节不必要的暴露给了用户，而这个错误在某些时候是致命的（造成了数据的不一致）。\n\n不过，如果拿捏的好呢？假设我们刚好抓住了蛇的七寸，那么我们即将设计出一套实现成本低且实用性强的服务方案。\n\n来举一个实际的例子：\n\n> 假设我们有一个获取学生列表的api，在返回的数据集中是否应该包含每个学生所属学校的内容呢？还是考虑设计一个专门用来获取指定学生学校的api？\n\n根据数据库设计范式，为了避免不必要的数据冗余，我们可能会有两张表：学生表和学校表。\n\n而界面上为了用户的体验，学生列表页面当然应该显示出对应的所属学校信息。貌似矛盾就这样理所应当的产生了。\n\n强大的sql给我们提供了第一个解决方案：多表join，甚至让你可以跨库做“join”。似乎让我们没有不用的理由？！\n\n不过不要被迷惑，要记住，不论何时，join都不应该是首选。理由是你 **不应该将业务逻辑写在sql中（没有例外）** ，尽管从我们这里的例子上来看join是完美的。但很多前辈都总结出了这种做法在web项目（互联网）的弊端，我们确实应该反思。\n\nso，既然不推荐直接在sql层做数据拼接，那就上移到代码层，而在传统的分层架构中又面临一个问题：放在哪一层合适？service层还是control层？还是前端调用时（针对前后端分离项目）做数据关联？\n\n考虑到现在REST架构风格比较流行，让我们假设上述的例子是发生在rest api中，到底这个api应该帮用户处理完所有数据关系？还是交给用户自己来按需获取呢？\n\n在这个简单的例子中，我个人坚持后者，这种思想也和Facebook推的GraphQL在某种层面上不谋而合。这么做的好处是，既保证了最终用户的业务需求，又保证了api的可复用性，毕竟学生和学校是比较独立的两个概念域，到底如何来处理它们之间的关系，应该交给数据调用方来自行解决。\n\n当然，这么做也并非毫无缺点的。暴露给调用方，意味着更多的风险：\n\n- 调用方没有正确的使用（谁会喜欢去看枯燥的使用说明书？）\n- 调用方恶意的使用（暴露出去的东西越多，被攻击的面就越大！）\n- 当提供方api升级时调用方的成本无法估计（怪我喽~）\n\n最后一点其实尤为重要，这也是rest官方资料中为何如此反复强调“服务版本号”概念的初衷。比较保险的方法是增加一层（计算机世界解决问题的银弹！！！）：gateway，不仅可以以较粗的颗粒度提供服务，而且可以做很多流控方面的事情。\n\n由于我们的例子是如此的简单，以至于根本不会在数据库表设计上产生什么分歧，但实际项目中，往往也会让我们纠结如何设计数据库，如何将众多的表归类到各自合适的库中。若一开始对领域模型把握的不是很精准，后期可能会导致数据一致性的噩梦：分布式事务。\n\n尽管很多业界巨头都开源出了解决方案或论文，社区也提供了很多可选的解决方案，但相信我，你依然不应该随意的引入这个问题。如何避免分布式事务呢？如果业务并非要求强一致性，那选择最终一致性的概念会让你的生活变得美好很多。否则，最好还是将事务性强表放在同一个物理位置。\n\n当然，现实是残酷的，有时候你还是不得不直面困难，此时你才需要大胆的尝试市面上提供的分布式事务的解决方案，相信我，你是可以搞定的（不然就等着下岗吧！）。\n\n对于业务相对比较简洁的项目，不会需要ESB这样的中心化服务编排的中间件。主动权交给调用方，毕竟鞋子合不合脚，只有自己知道。如果这种设计造成了性能瓶颈，那异步化将会成为你的主战场。\n\n最后，还要提到的是，服务的切分，绝壁不是一锤子买卖。随着需求的变迁，服务会分分合合，所以这个时候，一个良好的服务分层会是一个开启美好明天的基础：\n\n- 基础服务：**不** 依赖其它服务的服务\n- 复合服务：依赖其它服务的服务\n\n听起来很简单不是么？但相信我，这是最纠结的地方。不过值得分享的是：不要陷入选择恐惧症中。要知道，关键时刻迈出一步，比犹豫不决要更有意义。\n\n\n**感悟**：软件架构师之所以称之为架构师而非高级工程师，本质上讲是因为其思考和需要解决的问题更加宽泛，横跨软件开发的整个生命周期，而且“架构演化论”也指明，考核架构师优劣的一个重要标准是：应对需求变化的能力。\n","source":"_posts/只谈服务切分问题.md","raw":"title:  只谈服务切分问题\ndate: 2016-05-02 09:37:00\ntags:\n- soa\n- 服务\n- rest\ncategories: 架构\n---\n\n一直以来都对“架构”非常感兴趣，早在大学期间，逃课成瘾的我连css都不会但就已经对架构师产生了浓厚的兴趣！\n\n阴差阳错的成了程序员后，又稀里糊涂的做了这么久。工作重心一直围绕着web方向：网站，系统。随着2014年底开始，“微服务”这三个字就好像病毒广告一样烂大街了，丝毫不输于它的前辈“大数据”。\n\n之所以要从“微服务”这个广告语开始谈起，除了因为我自身性格的缘故（总是不自觉的对主流事物感到莫名的反感）外，主要是因为这和我们今天谈的主题非常相关。\n<!--more-->\n从敲下第一行代码开始，我相信每个程序员都在不停的思考一个问题：如何写出更好的代码。这里的“好”，具体应该至少包含：\n\n- 能解决一个具体的问题（本质）\n- 代码排版格式规整（强迫症）\n- 可阅读性强（尊重他人）\n- 维护成本低（修改成本低，让自己活的更滋润）\n- bug少（逻辑思维能力）\n- 抽象程度尽可能高（适配更多的场景，对外提供的接口灵活度高）\n- 文档齐全（大师级别的最低要求）\n\n以上几点，从前到后是有优先级的，希望你可以用心体会。\n\n上面提到的这几点常用于某个具体的业务代码，或者函数方法，或者某个能解决通用问题的类库。其实对于“架构”来说，也同样适用，不过可能需要考虑的因素更宽泛。\n\n说这些和我们今天的主题有关系么？是的。真的？嗯！那到底有什么关系？说白了就是服务边界的问题，这和“职责单一”的概念有些相似，但又不完全相同。\n\n相同之处在于让开发者时刻敏感于当前做的上下文规模问题，不同点在于服务切分时存在更多的 **“灰色区域”**。\n\n正是这些灰色区域的存在，才让大师成为大师，才让新手如此纠结。不过，这正是架构设计的乐趣和挑战！\n\n我并没有许多成功的架构设计经验（是真的，如果你对我下面说的产生了质疑，那这个信息无疑是成为你反驳我的有理证据），但在实际工作中却真真切切的感过那种纠结和尴尬！曾经以为已经考虑的完美无缺，但文档才写了一半就傻眼了，现实业务总是像碰瓷大娘一样拦住去路~\n\n那到底哪些细节需要在设计服务时需要我们警惕呢？我尽自己最大努力总结了一下：\n\n- 能解决一个具体且尽可能完整的业务问题\n- 尽力避免分布式事务\n- 从服务使用者的角度去规划服务的颗粒度\n- 考虑服务监控、容错、负载均衡、服务发现和治理方案\n- 尽量避免采用中心化的服务编排设计，交给服务调用方来做\n\n最后一条应该最具争议性，毕竟这多少有些违背了 **开放关闭** 原则，至少我们很可能误将原本应该隐藏起来的细节不必要的暴露给了用户，而这个错误在某些时候是致命的（造成了数据的不一致）。\n\n不过，如果拿捏的好呢？假设我们刚好抓住了蛇的七寸，那么我们即将设计出一套实现成本低且实用性强的服务方案。\n\n来举一个实际的例子：\n\n> 假设我们有一个获取学生列表的api，在返回的数据集中是否应该包含每个学生所属学校的内容呢？还是考虑设计一个专门用来获取指定学生学校的api？\n\n根据数据库设计范式，为了避免不必要的数据冗余，我们可能会有两张表：学生表和学校表。\n\n而界面上为了用户的体验，学生列表页面当然应该显示出对应的所属学校信息。貌似矛盾就这样理所应当的产生了。\n\n强大的sql给我们提供了第一个解决方案：多表join，甚至让你可以跨库做“join”。似乎让我们没有不用的理由？！\n\n不过不要被迷惑，要记住，不论何时，join都不应该是首选。理由是你 **不应该将业务逻辑写在sql中（没有例外）** ，尽管从我们这里的例子上来看join是完美的。但很多前辈都总结出了这种做法在web项目（互联网）的弊端，我们确实应该反思。\n\nso，既然不推荐直接在sql层做数据拼接，那就上移到代码层，而在传统的分层架构中又面临一个问题：放在哪一层合适？service层还是control层？还是前端调用时（针对前后端分离项目）做数据关联？\n\n考虑到现在REST架构风格比较流行，让我们假设上述的例子是发生在rest api中，到底这个api应该帮用户处理完所有数据关系？还是交给用户自己来按需获取呢？\n\n在这个简单的例子中，我个人坚持后者，这种思想也和Facebook推的GraphQL在某种层面上不谋而合。这么做的好处是，既保证了最终用户的业务需求，又保证了api的可复用性，毕竟学生和学校是比较独立的两个概念域，到底如何来处理它们之间的关系，应该交给数据调用方来自行解决。\n\n当然，这么做也并非毫无缺点的。暴露给调用方，意味着更多的风险：\n\n- 调用方没有正确的使用（谁会喜欢去看枯燥的使用说明书？）\n- 调用方恶意的使用（暴露出去的东西越多，被攻击的面就越大！）\n- 当提供方api升级时调用方的成本无法估计（怪我喽~）\n\n最后一点其实尤为重要，这也是rest官方资料中为何如此反复强调“服务版本号”概念的初衷。比较保险的方法是增加一层（计算机世界解决问题的银弹！！！）：gateway，不仅可以以较粗的颗粒度提供服务，而且可以做很多流控方面的事情。\n\n由于我们的例子是如此的简单，以至于根本不会在数据库表设计上产生什么分歧，但实际项目中，往往也会让我们纠结如何设计数据库，如何将众多的表归类到各自合适的库中。若一开始对领域模型把握的不是很精准，后期可能会导致数据一致性的噩梦：分布式事务。\n\n尽管很多业界巨头都开源出了解决方案或论文，社区也提供了很多可选的解决方案，但相信我，你依然不应该随意的引入这个问题。如何避免分布式事务呢？如果业务并非要求强一致性，那选择最终一致性的概念会让你的生活变得美好很多。否则，最好还是将事务性强表放在同一个物理位置。\n\n当然，现实是残酷的，有时候你还是不得不直面困难，此时你才需要大胆的尝试市面上提供的分布式事务的解决方案，相信我，你是可以搞定的（不然就等着下岗吧！）。\n\n对于业务相对比较简洁的项目，不会需要ESB这样的中心化服务编排的中间件。主动权交给调用方，毕竟鞋子合不合脚，只有自己知道。如果这种设计造成了性能瓶颈，那异步化将会成为你的主战场。\n\n最后，还要提到的是，服务的切分，绝壁不是一锤子买卖。随着需求的变迁，服务会分分合合，所以这个时候，一个良好的服务分层会是一个开启美好明天的基础：\n\n- 基础服务：**不** 依赖其它服务的服务\n- 复合服务：依赖其它服务的服务\n\n听起来很简单不是么？但相信我，这是最纠结的地方。不过值得分享的是：不要陷入选择恐惧症中。要知道，关键时刻迈出一步，比犹豫不决要更有意义。\n\n\n**感悟**：软件架构师之所以称之为架构师而非高级工程师，本质上讲是因为其思考和需要解决的问题更加宽泛，横跨软件开发的整个生命周期，而且“架构演化论”也指明，考核架构师优劣的一个重要标准是：应对需求变化的能力。\n","slug":"只谈服务切分问题","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cio4dt7zh000asafyn727g1h8","comments":1,"layout":"post","photos":[],"link":"","content":"<p>一直以来都对“架构”非常感兴趣，早在大学期间，逃课成瘾的我连css都不会但就已经对架构师产生了浓厚的兴趣！</p>\n<p>阴差阳错的成了程序员后，又稀里糊涂的做了这么久。工作重心一直围绕着web方向：网站，系统。随着2014年底开始，“微服务”这三个字就好像病毒广告一样烂大街了，丝毫不输于它的前辈“大数据”。</p>\n<p>之所以要从“微服务”这个广告语开始谈起，除了因为我自身性格的缘故（总是不自觉的对主流事物感到莫名的反感）外，主要是因为这和我们今天谈的主题非常相关。<br><a id=\"more\"></a><br>从敲下第一行代码开始，我相信每个程序员都在不停的思考一个问题：如何写出更好的代码。这里的“好”，具体应该至少包含：</p>\n<ul>\n<li>能解决一个具体的问题（本质）</li>\n<li>代码排版格式规整（强迫症）</li>\n<li>可阅读性强（尊重他人）</li>\n<li>维护成本低（修改成本低，让自己活的更滋润）</li>\n<li>bug少（逻辑思维能力）</li>\n<li>抽象程度尽可能高（适配更多的场景，对外提供的接口灵活度高）</li>\n<li>文档齐全（大师级别的最低要求）</li>\n</ul>\n<p>以上几点，从前到后是有优先级的，希望你可以用心体会。</p>\n<p>上面提到的这几点常用于某个具体的业务代码，或者函数方法，或者某个能解决通用问题的类库。其实对于“架构”来说，也同样适用，不过可能需要考虑的因素更宽泛。</p>\n<p>说这些和我们今天的主题有关系么？是的。真的？嗯！那到底有什么关系？说白了就是服务边界的问题，这和“职责单一”的概念有些相似，但又不完全相同。</p>\n<p>相同之处在于让开发者时刻敏感于当前做的上下文规模问题，不同点在于服务切分时存在更多的 <strong>“灰色区域”</strong>。</p>\n<p>正是这些灰色区域的存在，才让大师成为大师，才让新手如此纠结。不过，这正是架构设计的乐趣和挑战！</p>\n<p>我并没有许多成功的架构设计经验（是真的，如果你对我下面说的产生了质疑，那这个信息无疑是成为你反驳我的有理证据），但在实际工作中却真真切切的感过那种纠结和尴尬！曾经以为已经考虑的完美无缺，但文档才写了一半就傻眼了，现实业务总是像碰瓷大娘一样拦住去路~</p>\n<p>那到底哪些细节需要在设计服务时需要我们警惕呢？我尽自己最大努力总结了一下：</p>\n<ul>\n<li>能解决一个具体且尽可能完整的业务问题</li>\n<li>尽力避免分布式事务</li>\n<li>从服务使用者的角度去规划服务的颗粒度</li>\n<li>考虑服务监控、容错、负载均衡、服务发现和治理方案</li>\n<li>尽量避免采用中心化的服务编排设计，交给服务调用方来做</li>\n</ul>\n<p>最后一条应该最具争议性，毕竟这多少有些违背了 <strong>开放关闭</strong> 原则，至少我们很可能误将原本应该隐藏起来的细节不必要的暴露给了用户，而这个错误在某些时候是致命的（造成了数据的不一致）。</p>\n<p>不过，如果拿捏的好呢？假设我们刚好抓住了蛇的七寸，那么我们即将设计出一套实现成本低且实用性强的服务方案。</p>\n<p>来举一个实际的例子：</p>\n<blockquote>\n<p>假设我们有一个获取学生列表的api，在返回的数据集中是否应该包含每个学生所属学校的内容呢？还是考虑设计一个专门用来获取指定学生学校的api？</p>\n</blockquote>\n<p>根据数据库设计范式，为了避免不必要的数据冗余，我们可能会有两张表：学生表和学校表。</p>\n<p>而界面上为了用户的体验，学生列表页面当然应该显示出对应的所属学校信息。貌似矛盾就这样理所应当的产生了。</p>\n<p>强大的sql给我们提供了第一个解决方案：多表join，甚至让你可以跨库做“join”。似乎让我们没有不用的理由？！</p>\n<p>不过不要被迷惑，要记住，不论何时，join都不应该是首选。理由是你 <strong>不应该将业务逻辑写在sql中（没有例外）</strong> ，尽管从我们这里的例子上来看join是完美的。但很多前辈都总结出了这种做法在web项目（互联网）的弊端，我们确实应该反思。</p>\n<p>so，既然不推荐直接在sql层做数据拼接，那就上移到代码层，而在传统的分层架构中又面临一个问题：放在哪一层合适？service层还是control层？还是前端调用时（针对前后端分离项目）做数据关联？</p>\n<p>考虑到现在REST架构风格比较流行，让我们假设上述的例子是发生在rest api中，到底这个api应该帮用户处理完所有数据关系？还是交给用户自己来按需获取呢？</p>\n<p>在这个简单的例子中，我个人坚持后者，这种思想也和Facebook推的GraphQL在某种层面上不谋而合。这么做的好处是，既保证了最终用户的业务需求，又保证了api的可复用性，毕竟学生和学校是比较独立的两个概念域，到底如何来处理它们之间的关系，应该交给数据调用方来自行解决。</p>\n<p>当然，这么做也并非毫无缺点的。暴露给调用方，意味着更多的风险：</p>\n<ul>\n<li>调用方没有正确的使用（谁会喜欢去看枯燥的使用说明书？）</li>\n<li>调用方恶意的使用（暴露出去的东西越多，被攻击的面就越大！）</li>\n<li>当提供方api升级时调用方的成本无法估计（怪我喽~）</li>\n</ul>\n<p>最后一点其实尤为重要，这也是rest官方资料中为何如此反复强调“服务版本号”概念的初衷。比较保险的方法是增加一层（计算机世界解决问题的银弹！！！）：gateway，不仅可以以较粗的颗粒度提供服务，而且可以做很多流控方面的事情。</p>\n<p>由于我们的例子是如此的简单，以至于根本不会在数据库表设计上产生什么分歧，但实际项目中，往往也会让我们纠结如何设计数据库，如何将众多的表归类到各自合适的库中。若一开始对领域模型把握的不是很精准，后期可能会导致数据一致性的噩梦：分布式事务。</p>\n<p>尽管很多业界巨头都开源出了解决方案或论文，社区也提供了很多可选的解决方案，但相信我，你依然不应该随意的引入这个问题。如何避免分布式事务呢？如果业务并非要求强一致性，那选择最终一致性的概念会让你的生活变得美好很多。否则，最好还是将事务性强表放在同一个物理位置。</p>\n<p>当然，现实是残酷的，有时候你还是不得不直面困难，此时你才需要大胆的尝试市面上提供的分布式事务的解决方案，相信我，你是可以搞定的（不然就等着下岗吧！）。</p>\n<p>对于业务相对比较简洁的项目，不会需要ESB这样的中心化服务编排的中间件。主动权交给调用方，毕竟鞋子合不合脚，只有自己知道。如果这种设计造成了性能瓶颈，那异步化将会成为你的主战场。</p>\n<p>最后，还要提到的是，服务的切分，绝壁不是一锤子买卖。随着需求的变迁，服务会分分合合，所以这个时候，一个良好的服务分层会是一个开启美好明天的基础：</p>\n<ul>\n<li>基础服务：<strong>不</strong> 依赖其它服务的服务</li>\n<li>复合服务：依赖其它服务的服务</li>\n</ul>\n<p>听起来很简单不是么？但相信我，这是最纠结的地方。不过值得分享的是：不要陷入选择恐惧症中。要知道，关键时刻迈出一步，比犹豫不决要更有意义。</p>\n<p><strong>感悟</strong>：软件架构师之所以称之为架构师而非高级工程师，本质上讲是因为其思考和需要解决的问题更加宽泛，横跨软件开发的整个生命周期，而且“架构演化论”也指明，考核架构师优劣的一个重要标准是：应对需求变化的能力。</p>\n","excerpt":"<p>一直以来都对“架构”非常感兴趣，早在大学期间，逃课成瘾的我连css都不会但就已经对架构师产生了浓厚的兴趣！</p>\n<p>阴差阳错的成了程序员后，又稀里糊涂的做了这么久。工作重心一直围绕着web方向：网站，系统。随着2014年底开始，“微服务”这三个字就好像病毒广告一样烂大街了，丝毫不输于它的前辈“大数据”。</p>\n<p>之所以要从“微服务”这个广告语开始谈起，除了因为我自身性格的缘故（总是不自觉的对主流事物感到莫名的反感）外，主要是因为这和我们今天谈的主题非常相关。<br>","more":"<br>从敲下第一行代码开始，我相信每个程序员都在不停的思考一个问题：如何写出更好的代码。这里的“好”，具体应该至少包含：</p>\n<ul>\n<li>能解决一个具体的问题（本质）</li>\n<li>代码排版格式规整（强迫症）</li>\n<li>可阅读性强（尊重他人）</li>\n<li>维护成本低（修改成本低，让自己活的更滋润）</li>\n<li>bug少（逻辑思维能力）</li>\n<li>抽象程度尽可能高（适配更多的场景，对外提供的接口灵活度高）</li>\n<li>文档齐全（大师级别的最低要求）</li>\n</ul>\n<p>以上几点，从前到后是有优先级的，希望你可以用心体会。</p>\n<p>上面提到的这几点常用于某个具体的业务代码，或者函数方法，或者某个能解决通用问题的类库。其实对于“架构”来说，也同样适用，不过可能需要考虑的因素更宽泛。</p>\n<p>说这些和我们今天的主题有关系么？是的。真的？嗯！那到底有什么关系？说白了就是服务边界的问题，这和“职责单一”的概念有些相似，但又不完全相同。</p>\n<p>相同之处在于让开发者时刻敏感于当前做的上下文规模问题，不同点在于服务切分时存在更多的 <strong>“灰色区域”</strong>。</p>\n<p>正是这些灰色区域的存在，才让大师成为大师，才让新手如此纠结。不过，这正是架构设计的乐趣和挑战！</p>\n<p>我并没有许多成功的架构设计经验（是真的，如果你对我下面说的产生了质疑，那这个信息无疑是成为你反驳我的有理证据），但在实际工作中却真真切切的感过那种纠结和尴尬！曾经以为已经考虑的完美无缺，但文档才写了一半就傻眼了，现实业务总是像碰瓷大娘一样拦住去路~</p>\n<p>那到底哪些细节需要在设计服务时需要我们警惕呢？我尽自己最大努力总结了一下：</p>\n<ul>\n<li>能解决一个具体且尽可能完整的业务问题</li>\n<li>尽力避免分布式事务</li>\n<li>从服务使用者的角度去规划服务的颗粒度</li>\n<li>考虑服务监控、容错、负载均衡、服务发现和治理方案</li>\n<li>尽量避免采用中心化的服务编排设计，交给服务调用方来做</li>\n</ul>\n<p>最后一条应该最具争议性，毕竟这多少有些违背了 <strong>开放关闭</strong> 原则，至少我们很可能误将原本应该隐藏起来的细节不必要的暴露给了用户，而这个错误在某些时候是致命的（造成了数据的不一致）。</p>\n<p>不过，如果拿捏的好呢？假设我们刚好抓住了蛇的七寸，那么我们即将设计出一套实现成本低且实用性强的服务方案。</p>\n<p>来举一个实际的例子：</p>\n<blockquote>\n<p>假设我们有一个获取学生列表的api，在返回的数据集中是否应该包含每个学生所属学校的内容呢？还是考虑设计一个专门用来获取指定学生学校的api？</p>\n</blockquote>\n<p>根据数据库设计范式，为了避免不必要的数据冗余，我们可能会有两张表：学生表和学校表。</p>\n<p>而界面上为了用户的体验，学生列表页面当然应该显示出对应的所属学校信息。貌似矛盾就这样理所应当的产生了。</p>\n<p>强大的sql给我们提供了第一个解决方案：多表join，甚至让你可以跨库做“join”。似乎让我们没有不用的理由？！</p>\n<p>不过不要被迷惑，要记住，不论何时，join都不应该是首选。理由是你 <strong>不应该将业务逻辑写在sql中（没有例外）</strong> ，尽管从我们这里的例子上来看join是完美的。但很多前辈都总结出了这种做法在web项目（互联网）的弊端，我们确实应该反思。</p>\n<p>so，既然不推荐直接在sql层做数据拼接，那就上移到代码层，而在传统的分层架构中又面临一个问题：放在哪一层合适？service层还是control层？还是前端调用时（针对前后端分离项目）做数据关联？</p>\n<p>考虑到现在REST架构风格比较流行，让我们假设上述的例子是发生在rest api中，到底这个api应该帮用户处理完所有数据关系？还是交给用户自己来按需获取呢？</p>\n<p>在这个简单的例子中，我个人坚持后者，这种思想也和Facebook推的GraphQL在某种层面上不谋而合。这么做的好处是，既保证了最终用户的业务需求，又保证了api的可复用性，毕竟学生和学校是比较独立的两个概念域，到底如何来处理它们之间的关系，应该交给数据调用方来自行解决。</p>\n<p>当然，这么做也并非毫无缺点的。暴露给调用方，意味着更多的风险：</p>\n<ul>\n<li>调用方没有正确的使用（谁会喜欢去看枯燥的使用说明书？）</li>\n<li>调用方恶意的使用（暴露出去的东西越多，被攻击的面就越大！）</li>\n<li>当提供方api升级时调用方的成本无法估计（怪我喽~）</li>\n</ul>\n<p>最后一点其实尤为重要，这也是rest官方资料中为何如此反复强调“服务版本号”概念的初衷。比较保险的方法是增加一层（计算机世界解决问题的银弹！！！）：gateway，不仅可以以较粗的颗粒度提供服务，而且可以做很多流控方面的事情。</p>\n<p>由于我们的例子是如此的简单，以至于根本不会在数据库表设计上产生什么分歧，但实际项目中，往往也会让我们纠结如何设计数据库，如何将众多的表归类到各自合适的库中。若一开始对领域模型把握的不是很精准，后期可能会导致数据一致性的噩梦：分布式事务。</p>\n<p>尽管很多业界巨头都开源出了解决方案或论文，社区也提供了很多可选的解决方案，但相信我，你依然不应该随意的引入这个问题。如何避免分布式事务呢？如果业务并非要求强一致性，那选择最终一致性的概念会让你的生活变得美好很多。否则，最好还是将事务性强表放在同一个物理位置。</p>\n<p>当然，现实是残酷的，有时候你还是不得不直面困难，此时你才需要大胆的尝试市面上提供的分布式事务的解决方案，相信我，你是可以搞定的（不然就等着下岗吧！）。</p>\n<p>对于业务相对比较简洁的项目，不会需要ESB这样的中心化服务编排的中间件。主动权交给调用方，毕竟鞋子合不合脚，只有自己知道。如果这种设计造成了性能瓶颈，那异步化将会成为你的主战场。</p>\n<p>最后，还要提到的是，服务的切分，绝壁不是一锤子买卖。随着需求的变迁，服务会分分合合，所以这个时候，一个良好的服务分层会是一个开启美好明天的基础：</p>\n<ul>\n<li>基础服务：<strong>不</strong> 依赖其它服务的服务</li>\n<li>复合服务：依赖其它服务的服务</li>\n</ul>\n<p>听起来很简单不是么？但相信我，这是最纠结的地方。不过值得分享的是：不要陷入选择恐惧症中。要知道，关键时刻迈出一步，比犹豫不决要更有意义。</p>\n<p><strong>感悟</strong>：软件架构师之所以称之为架构师而非高级工程师，本质上讲是因为其思考和需要解决的问题更加宽泛，横跨软件开发的整个生命周期，而且“架构演化论”也指明，考核架构师优劣的一个重要标准是：应对需求变化的能力。</p>"},{"title":"ztree如何优雅自定义ajax的header参数","date":"2016-04-30T01:37:00.000Z","_content":"\n很久很久以前，我就把ztree夸成一朵花了，现在依然对它点赞！\n\n不过之前在ng中使用它时就碰到了一个小麻烦，直至昨天同事问我，我再次翻阅ztree的文档依然没有提供自定义ajax的header的功能，这让基于REST风格的api在使用起来很不方便。\n\n当然，直接修改ztree的源码也十分简单，但这并不是一个追求完美的coder可以接受的！那我们来看看到底该怎么做来最优雅的解决这个问题！\n<!--more-->\n其实，这就要从jquery上下点功夫（ztree依赖jquery1.4+），我们在api的手册上早已经看到这么一个[方法](http://www.jquery123.com/ajaxSend/)，所以我们只需要简单的在你需要使用ztree的页面，增加下面这段代码即可：\n\n```javascript\n$(document).ajaxSend(function(event, jqxhr, settings) {\n\t\tjqxhr.setRequestHeader(\"Auth\",\"kazaff\");\n});\n```\n\n需要提醒的是，这样会全局修改所有基于jq的ajax请求，如果你页面上有其它依赖它的代码或第三方组件，那么可能会相互影响，不过，你可以按照官方的一个例子来做处理：\n\n```javascript\n$(document).ajaxSend(function(event, jqxhr, settings) {\n  if ( settings.url == \"ajax/test.html\" ) {\n    $( \".log\" ).text( \"Triggered ajaxSend handler.\" );\n  }\n});\n```\n好了，希望对你有帮助！\n","source":"_posts/ztree如何优雅自定义ajax的header参数.md","raw":"title:  ztree如何优雅自定义ajax的header参数\ndate: 2016-04-30 09:37:00\ntags:\n- ztree\n- ajax\n- header\n- ajaxSend\ncategories: 前端\n---\n\n很久很久以前，我就把ztree夸成一朵花了，现在依然对它点赞！\n\n不过之前在ng中使用它时就碰到了一个小麻烦，直至昨天同事问我，我再次翻阅ztree的文档依然没有提供自定义ajax的header的功能，这让基于REST风格的api在使用起来很不方便。\n\n当然，直接修改ztree的源码也十分简单，但这并不是一个追求完美的coder可以接受的！那我们来看看到底该怎么做来最优雅的解决这个问题！\n<!--more-->\n其实，这就要从jquery上下点功夫（ztree依赖jquery1.4+），我们在api的手册上早已经看到这么一个[方法](http://www.jquery123.com/ajaxSend/)，所以我们只需要简单的在你需要使用ztree的页面，增加下面这段代码即可：\n\n```javascript\n$(document).ajaxSend(function(event, jqxhr, settings) {\n\t\tjqxhr.setRequestHeader(\"Auth\",\"kazaff\");\n});\n```\n\n需要提醒的是，这样会全局修改所有基于jq的ajax请求，如果你页面上有其它依赖它的代码或第三方组件，那么可能会相互影响，不过，你可以按照官方的一个例子来做处理：\n\n```javascript\n$(document).ajaxSend(function(event, jqxhr, settings) {\n  if ( settings.url == \"ajax/test.html\" ) {\n    $( \".log\" ).text( \"Triggered ajaxSend handler.\" );\n  }\n});\n```\n好了，希望对你有帮助！\n","slug":"ztree如何优雅自定义ajax的header参数","published":1,"updated":"2016-05-14T07:46:36.000Z","_id":"cio4dt80m000fsafye3xolxye","comments":1,"layout":"post","photos":[],"link":"","content":"<p>很久很久以前，我就把ztree夸成一朵花了，现在依然对它点赞！</p>\n<p>不过之前在ng中使用它时就碰到了一个小麻烦，直至昨天同事问我，我再次翻阅ztree的文档依然没有提供自定义ajax的header的功能，这让基于REST风格的api在使用起来很不方便。</p>\n<p>当然，直接修改ztree的源码也十分简单，但这并不是一个追求完美的coder可以接受的！那我们来看看到底该怎么做来最优雅的解决这个问题！<br><a id=\"more\"></a><br>其实，这就要从jquery上下点功夫（ztree依赖jquery1.4+），我们在api的手册上早已经看到这么一个<a href=\"http://www.jquery123.com/ajaxSend/\" target=\"_blank\" rel=\"external\">方法</a>，所以我们只需要简单的在你需要使用ztree的页面，增加下面这段代码即可：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"built_in\">document</span>).ajaxSend(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">event, jqxhr, settings</span>) </span>&#123;</span><br><span class=\"line\">\t\tjqxhr.setRequestHeader(<span class=\"string\">\"Auth\"</span>,<span class=\"string\">\"kazaff\"</span>);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>需要提醒的是，这样会全局修改所有基于jq的ajax请求，如果你页面上有其它依赖它的代码或第三方组件，那么可能会相互影响，不过，你可以按照官方的一个例子来做处理：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"built_in\">document</span>).ajaxSend(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">event, jqxhr, settings</span>) </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">if</span> ( settings.url == <span class=\"string\">\"ajax/test.html\"</span> ) &#123;</span><br><span class=\"line\">    $( <span class=\"string\">\".log\"</span> ).text( <span class=\"string\">\"Triggered ajaxSend handler.\"</span> );</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>好了，希望对你有帮助！</p>\n","excerpt":"<p>很久很久以前，我就把ztree夸成一朵花了，现在依然对它点赞！</p>\n<p>不过之前在ng中使用它时就碰到了一个小麻烦，直至昨天同事问我，我再次翻阅ztree的文档依然没有提供自定义ajax的header的功能，这让基于REST风格的api在使用起来很不方便。</p>\n<p>当然，直接修改ztree的源码也十分简单，但这并不是一个追求完美的coder可以接受的！那我们来看看到底该怎么做来最优雅的解决这个问题！<br>","more":"<br>其实，这就要从jquery上下点功夫（ztree依赖jquery1.4+），我们在api的手册上早已经看到这么一个<a href=\"http://www.jquery123.com/ajaxSend/\">方法</a>，所以我们只需要简单的在你需要使用ztree的页面，增加下面这段代码即可：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"built_in\">document</span>).ajaxSend(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">event, jqxhr, settings</span>) </span>&#123;</span><br><span class=\"line\">\t\tjqxhr.setRequestHeader(<span class=\"string\">\"Auth\"</span>,<span class=\"string\">\"kazaff\"</span>);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>需要提醒的是，这样会全局修改所有基于jq的ajax请求，如果你页面上有其它依赖它的代码或第三方组件，那么可能会相互影响，不过，你可以按照官方的一个例子来做处理：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"built_in\">document</span>).ajaxSend(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">event, jqxhr, settings</span>) </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">if</span> ( settings.url == <span class=\"string\">\"ajax/test.html\"</span> ) &#123;</span><br><span class=\"line\">    $( <span class=\"string\">\".log\"</span> ).text( <span class=\"string\">\"Triggered ajaxSend handler.\"</span> );</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>好了，希望对你有帮助！</p>"},{"title":"vue组件通信和一个灵异事件","date":"2016-05-10T01:37:00.000Z","_content":"\n这次来细聊一下vue的组件间通信，这部分内容官方有花了不少的[篇幅](http://vuejs.org.cn/guide/components.html#父子组件通信)介绍，但却没有一个清晰的例子供参考，真是不知道这算不算偷懒。不过还好热心人不少，这里有一个[配套的例子](http://www.imys.net/20160503/vue-data-interaction.html)很屌。我个人推荐 [**vuex**](http://vuex.vuejs.org/zh-cn/intro.html)来管理通信，不过这也意味着你要引入更多的依赖。\n<!--more-->\n从资料中可以看到，目前只用vue来实现兄弟组件间的通信，还是很麻烦的。不过，一定要搞清楚的是，兄弟间通信的需求场景是否合理，确保你确实需要兄弟组件间通信的前提下，我们继续往下聊。\n\n这里要提到一个理论概念，之前在翻译react相关的文章中看到过：**smart component** 和 **dummy component**。简单的解释就是说，你的组件到底是否需要 **保存** 外部的状态，注意这里是指的保存，而不是感知。如果一个组件只是需要感知一个外部状态的话，起始使用`props`来做是非常合适的。\n\n不过，如果你的组件确实需要独自保存一份来自外部的数据状态，那它就不再是一个dummy component，至少它的可复用性要大打折扣。所以除非你有足够的理由来这么做，不然还是尽可能保持组件的“愚蠢”吧！\n\n关于组件间通信的内容，上面给的第二个链接已经讲的很透彻了，我不准备在重复了。本篇我们主要来讨论一下新手容易碰到的灵异事件（我就是新手）。\n\n### 灵异事件之一：子组件无法捕获事件\n\n我在项目中并没有引入vuex，所以我使用的是原始的父组件代理事件的方式来实现兄弟组件间通信的功能。不过在测试时发现子组件死活无法接受到父组件转发的事件，真是日了狗了！\n\n通过debug，我发现父组件在`$broadcast()`内部，并没有检查到目标事件监听的子组件，我才恍然大悟，确实页面上连该子组件的dom都不曾出现。\n\n经过排查，原来是因为：**vue不能很好的识别单独html元素标签**，如下：\n\n```html\n<div id=\"toolbar\" class=\"container\">\n\t<a-bar @event-route=\"eventRoute\" />\n\t<b-detail @event-route=\"eventRoute\" />\n</div>\n```\n\n改成：\n\n```html\n<div id=\"toolbar\" class=\"container\">\n\t<a-bar @event-route=\"eventRoute\"></a-bar>\n\t<b-detail @event-route=\"eventRoute\"></b-bar>\n</div>\n```\n\n一切就正常了，真是见鬼了，谁可以来解释一下为何如此奇葩？！\n\n### 灵异事件之二：vue-strap的按钮组控件\n\n其实严格意义上这个并非vue组件间通信的问题，但却让我足足摆弄了3个小时。直到现在，我也只能归结于是自己的乱用导致的这个问题。\n\n问题描述：\n\n当首次切换选中按钮时，会触发两次`change`或`click`事件，但再次切换就一切正常了！\n\n前提是，你像我一样任性的如下使用：\n\n```html\n<radio-group :value.sync=\"radioValue\" type=\"primary\" :change=\"log()\">\n  <radio value=\"left\">Left</radio>\n  <radio value=\"middle\" checked>Middle</radio>\n  <radio value=\"right\">Right</radio>\n</radio-group>\n```\n\nvue-strap对开发者来说可以理解为一个黑盒子，而官方例子又非常的不具体，导致我们很容易用错。这里我可能就犯了一个思维错误，至少vue-strap的哲学不推荐我这么干（我猜的）。\n\n到底哪里有问题呢？我想当然的根据使用jquery的思维来使用radio-group组件，导致我使用`onchange`事件来处理变更事件。\n\n但注意到`:value.sync`的绑定方式，我们这里应该使用双向绑定的思维来实现这个需求：\n\n```javascript\nready: function(){\n\tthis.$watch('radioValue', function(newVal, oldVal){\n\t\tthis.$dispatch(\"event-route\", {eventName:\"change\", data: newVal})});\n\t});\n}\n```\n\n这里我们在对应组件的生命周期方法中绑定了`$watch`回调，这样每当`radioValue`变更时就会捕捉到，我们并没有直接在`radio-group`组件上来做这件事儿，一切灵异事件都不见了（包括初始化问题）。之所以会想到这么做，是因为在排查bug时，我们不应该对黑盒子做任何假设，一切逻辑都尽可能由我们自己来完成，以最大程度的排除干扰。\n\n感悟：只用使用匹配的思维来使用一个组件或库，才能真正的提升效率，否则可能事倍功半。\n","source":"_posts/vue组件通信和一个灵异事件.md","raw":"title:  vue组件通信和一个灵异事件\ndate: 2016-05-10 09:37:00\ntags:\n- vue\n- 组件间通信\n- vue-strap\ncategories: 前端\n---\n\n这次来细聊一下vue的组件间通信，这部分内容官方有花了不少的[篇幅](http://vuejs.org.cn/guide/components.html#父子组件通信)介绍，但却没有一个清晰的例子供参考，真是不知道这算不算偷懒。不过还好热心人不少，这里有一个[配套的例子](http://www.imys.net/20160503/vue-data-interaction.html)很屌。我个人推荐 [**vuex**](http://vuex.vuejs.org/zh-cn/intro.html)来管理通信，不过这也意味着你要引入更多的依赖。\n<!--more-->\n从资料中可以看到，目前只用vue来实现兄弟组件间的通信，还是很麻烦的。不过，一定要搞清楚的是，兄弟间通信的需求场景是否合理，确保你确实需要兄弟组件间通信的前提下，我们继续往下聊。\n\n这里要提到一个理论概念，之前在翻译react相关的文章中看到过：**smart component** 和 **dummy component**。简单的解释就是说，你的组件到底是否需要 **保存** 外部的状态，注意这里是指的保存，而不是感知。如果一个组件只是需要感知一个外部状态的话，起始使用`props`来做是非常合适的。\n\n不过，如果你的组件确实需要独自保存一份来自外部的数据状态，那它就不再是一个dummy component，至少它的可复用性要大打折扣。所以除非你有足够的理由来这么做，不然还是尽可能保持组件的“愚蠢”吧！\n\n关于组件间通信的内容，上面给的第二个链接已经讲的很透彻了，我不准备在重复了。本篇我们主要来讨论一下新手容易碰到的灵异事件（我就是新手）。\n\n### 灵异事件之一：子组件无法捕获事件\n\n我在项目中并没有引入vuex，所以我使用的是原始的父组件代理事件的方式来实现兄弟组件间通信的功能。不过在测试时发现子组件死活无法接受到父组件转发的事件，真是日了狗了！\n\n通过debug，我发现父组件在`$broadcast()`内部，并没有检查到目标事件监听的子组件，我才恍然大悟，确实页面上连该子组件的dom都不曾出现。\n\n经过排查，原来是因为：**vue不能很好的识别单独html元素标签**，如下：\n\n```html\n<div id=\"toolbar\" class=\"container\">\n\t<a-bar @event-route=\"eventRoute\" />\n\t<b-detail @event-route=\"eventRoute\" />\n</div>\n```\n\n改成：\n\n```html\n<div id=\"toolbar\" class=\"container\">\n\t<a-bar @event-route=\"eventRoute\"></a-bar>\n\t<b-detail @event-route=\"eventRoute\"></b-bar>\n</div>\n```\n\n一切就正常了，真是见鬼了，谁可以来解释一下为何如此奇葩？！\n\n### 灵异事件之二：vue-strap的按钮组控件\n\n其实严格意义上这个并非vue组件间通信的问题，但却让我足足摆弄了3个小时。直到现在，我也只能归结于是自己的乱用导致的这个问题。\n\n问题描述：\n\n当首次切换选中按钮时，会触发两次`change`或`click`事件，但再次切换就一切正常了！\n\n前提是，你像我一样任性的如下使用：\n\n```html\n<radio-group :value.sync=\"radioValue\" type=\"primary\" :change=\"log()\">\n  <radio value=\"left\">Left</radio>\n  <radio value=\"middle\" checked>Middle</radio>\n  <radio value=\"right\">Right</radio>\n</radio-group>\n```\n\nvue-strap对开发者来说可以理解为一个黑盒子，而官方例子又非常的不具体，导致我们很容易用错。这里我可能就犯了一个思维错误，至少vue-strap的哲学不推荐我这么干（我猜的）。\n\n到底哪里有问题呢？我想当然的根据使用jquery的思维来使用radio-group组件，导致我使用`onchange`事件来处理变更事件。\n\n但注意到`:value.sync`的绑定方式，我们这里应该使用双向绑定的思维来实现这个需求：\n\n```javascript\nready: function(){\n\tthis.$watch('radioValue', function(newVal, oldVal){\n\t\tthis.$dispatch(\"event-route\", {eventName:\"change\", data: newVal})});\n\t});\n}\n```\n\n这里我们在对应组件的生命周期方法中绑定了`$watch`回调，这样每当`radioValue`变更时就会捕捉到，我们并没有直接在`radio-group`组件上来做这件事儿，一切灵异事件都不见了（包括初始化问题）。之所以会想到这么做，是因为在排查bug时，我们不应该对黑盒子做任何假设，一切逻辑都尽可能由我们自己来完成，以最大程度的排除干扰。\n\n感悟：只用使用匹配的思维来使用一个组件或库，才能真正的提升效率，否则可能事倍功半。\n","slug":"vue组件通信和一个灵异事件","published":1,"updated":"2016-05-20T14:46:18.000Z","_id":"cio4dt810000psafygfmqvrto","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这次来细聊一下vue的组件间通信，这部分内容官方有花了不少的<a href=\"http://vuejs.org.cn/guide/components.html#父子组件通信\" target=\"_blank\" rel=\"external\">篇幅</a>介绍，但却没有一个清晰的例子供参考，真是不知道这算不算偷懒。不过还好热心人不少，这里有一个<a href=\"http://www.imys.net/20160503/vue-data-interaction.html\" target=\"_blank\" rel=\"external\">配套的例子</a>很屌。我个人推荐 <a href=\"http://vuex.vuejs.org/zh-cn/intro.html\" target=\"_blank\" rel=\"external\"><strong>vuex</strong></a>来管理通信，不过这也意味着你要引入更多的依赖。<br><a id=\"more\"></a><br>从资料中可以看到，目前只用vue来实现兄弟组件间的通信，还是很麻烦的。不过，一定要搞清楚的是，兄弟间通信的需求场景是否合理，确保你确实需要兄弟组件间通信的前提下，我们继续往下聊。</p>\n<p>这里要提到一个理论概念，之前在翻译react相关的文章中看到过：<strong>smart component</strong> 和 <strong>dummy component</strong>。简单的解释就是说，你的组件到底是否需要 <strong>保存</strong> 外部的状态，注意这里是指的保存，而不是感知。如果一个组件只是需要感知一个外部状态的话，起始使用<code>props</code>来做是非常合适的。</p>\n<p>不过，如果你的组件确实需要独自保存一份来自外部的数据状态，那它就不再是一个dummy component，至少它的可复用性要大打折扣。所以除非你有足够的理由来这么做，不然还是尽可能保持组件的“愚蠢”吧！</p>\n<p>关于组件间通信的内容，上面给的第二个链接已经讲的很透彻了，我不准备在重复了。本篇我们主要来讨论一下新手容易碰到的灵异事件（我就是新手）。</p>\n<h3 id=\"灵异事件之一：子组件无法捕获事件\"><a href=\"#灵异事件之一：子组件无法捕获事件\" class=\"headerlink\" title=\"灵异事件之一：子组件无法捕获事件\"></a>灵异事件之一：子组件无法捕获事件</h3><p>我在项目中并没有引入vuex，所以我使用的是原始的父组件代理事件的方式来实现兄弟组件间通信的功能。不过在测试时发现子组件死活无法接受到父组件转发的事件，真是日了狗了！</p>\n<p>通过debug，我发现父组件在<code>$broadcast()</code>内部，并没有检查到目标事件监听的子组件，我才恍然大悟，确实页面上连该子组件的dom都不曾出现。</p>\n<p>经过排查，原来是因为：<strong>vue不能很好的识别单独html元素标签</strong>，如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"toolbar\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"container\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">a-bar</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">b-detail</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>改成：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"toolbar\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"container\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">a-bar</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a-bar</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">b-detail</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">b-bar</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>一切就正常了，真是见鬼了，谁可以来解释一下为何如此奇葩？！</p>\n<h3 id=\"灵异事件之二：vue-strap的按钮组控件\"><a href=\"#灵异事件之二：vue-strap的按钮组控件\" class=\"headerlink\" title=\"灵异事件之二：vue-strap的按钮组控件\"></a>灵异事件之二：vue-strap的按钮组控件</h3><p>其实严格意义上这个并非vue组件间通信的问题，但却让我足足摆弄了3个小时。直到现在，我也只能归结于是自己的乱用导致的这个问题。</p>\n<p>问题描述：</p>\n<p>当首次切换选中按钮时，会触发两次<code>change</code>或<code>click</code>事件，但再次切换就一切正常了！</p>\n<p>前提是，你像我一样任性的如下使用：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">radio-group</span> <span class=\"attr\">:value.sync</span>=<span class=\"string\">\"radioValue\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"primary\"</span> <span class=\"attr\">:change</span>=<span class=\"string\">\"log()\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">radio</span> <span class=\"attr\">value</span>=<span class=\"string\">\"left\"</span>&gt;</span>Left<span class=\"tag\">&lt;/<span class=\"name\">radio</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">radio</span> <span class=\"attr\">value</span>=<span class=\"string\">\"middle\"</span> <span class=\"attr\">checked</span>&gt;</span>Middle<span class=\"tag\">&lt;/<span class=\"name\">radio</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">radio</span> <span class=\"attr\">value</span>=<span class=\"string\">\"right\"</span>&gt;</span>Right<span class=\"tag\">&lt;/<span class=\"name\">radio</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">radio-group</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>vue-strap对开发者来说可以理解为一个黑盒子，而官方例子又非常的不具体，导致我们很容易用错。这里我可能就犯了一个思维错误，至少vue-strap的哲学不推荐我这么干（我猜的）。</p>\n<p>到底哪里有问题呢？我想当然的根据使用jquery的思维来使用radio-group组件，导致我使用<code>onchange</code>事件来处理变更事件。</p>\n<p>但注意到<code>:value.sync</code>的绑定方式，我们这里应该使用双向绑定的思维来实现这个需求：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ready: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.$watch(<span class=\"string\">'radioValue'</span>, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">newVal, oldVal</span>)</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.$dispatch(<span class=\"string\">\"event-route\"</span>, &#123;eventName:<span class=\"string\">\"change\"</span>, data: newVal&#125;)&#125;);</span><br><span class=\"line\">\t&#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里我们在对应组件的生命周期方法中绑定了<code>$watch</code>回调，这样每当<code>radioValue</code>变更时就会捕捉到，我们并没有直接在<code>radio-group</code>组件上来做这件事儿，一切灵异事件都不见了（包括初始化问题）。之所以会想到这么做，是因为在排查bug时，我们不应该对黑盒子做任何假设，一切逻辑都尽可能由我们自己来完成，以最大程度的排除干扰。</p>\n<p>感悟：只用使用匹配的思维来使用一个组件或库，才能真正的提升效率，否则可能事倍功半。</p>\n","excerpt":"<p>这次来细聊一下vue的组件间通信，这部分内容官方有花了不少的<a href=\"http://vuejs.org.cn/guide/components.html#父子组件通信\">篇幅</a>介绍，但却没有一个清晰的例子供参考，真是不知道这算不算偷懒。不过还好热心人不少，这里有一个<a href=\"http://www.imys.net/20160503/vue-data-interaction.html\">配套的例子</a>很屌。我个人推荐 <a href=\"http://vuex.vuejs.org/zh-cn/intro.html\"><strong>vuex</strong></a>来管理通信，不过这也意味着你要引入更多的依赖。<br>","more":"<br>从资料中可以看到，目前只用vue来实现兄弟组件间的通信，还是很麻烦的。不过，一定要搞清楚的是，兄弟间通信的需求场景是否合理，确保你确实需要兄弟组件间通信的前提下，我们继续往下聊。</p>\n<p>这里要提到一个理论概念，之前在翻译react相关的文章中看到过：<strong>smart component</strong> 和 <strong>dummy component</strong>。简单的解释就是说，你的组件到底是否需要 <strong>保存</strong> 外部的状态，注意这里是指的保存，而不是感知。如果一个组件只是需要感知一个外部状态的话，起始使用<code>props</code>来做是非常合适的。</p>\n<p>不过，如果你的组件确实需要独自保存一份来自外部的数据状态，那它就不再是一个dummy component，至少它的可复用性要大打折扣。所以除非你有足够的理由来这么做，不然还是尽可能保持组件的“愚蠢”吧！</p>\n<p>关于组件间通信的内容，上面给的第二个链接已经讲的很透彻了，我不准备在重复了。本篇我们主要来讨论一下新手容易碰到的灵异事件（我就是新手）。</p>\n<h3 id=\"灵异事件之一：子组件无法捕获事件\"><a href=\"#灵异事件之一：子组件无法捕获事件\" class=\"headerlink\" title=\"灵异事件之一：子组件无法捕获事件\"></a>灵异事件之一：子组件无法捕获事件</h3><p>我在项目中并没有引入vuex，所以我使用的是原始的父组件代理事件的方式来实现兄弟组件间通信的功能。不过在测试时发现子组件死活无法接受到父组件转发的事件，真是日了狗了！</p>\n<p>通过debug，我发现父组件在<code>$broadcast()</code>内部，并没有检查到目标事件监听的子组件，我才恍然大悟，确实页面上连该子组件的dom都不曾出现。</p>\n<p>经过排查，原来是因为：<strong>vue不能很好的识别单独html元素标签</strong>，如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"toolbar\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"container\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">a-bar</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">b-detail</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>改成：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"toolbar\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"container\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">a-bar</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">a-bar</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">b-detail</span> @<span class=\"attr\">event-route</span>=<span class=\"string\">\"eventRoute\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">b-bar</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>一切就正常了，真是见鬼了，谁可以来解释一下为何如此奇葩？！</p>\n<h3 id=\"灵异事件之二：vue-strap的按钮组控件\"><a href=\"#灵异事件之二：vue-strap的按钮组控件\" class=\"headerlink\" title=\"灵异事件之二：vue-strap的按钮组控件\"></a>灵异事件之二：vue-strap的按钮组控件</h3><p>其实严格意义上这个并非vue组件间通信的问题，但却让我足足摆弄了3个小时。直到现在，我也只能归结于是自己的乱用导致的这个问题。</p>\n<p>问题描述：</p>\n<p>当首次切换选中按钮时，会触发两次<code>change</code>或<code>click</code>事件，但再次切换就一切正常了！</p>\n<p>前提是，你像我一样任性的如下使用：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">radio-group</span> <span class=\"attr\">:value.sync</span>=<span class=\"string\">\"radioValue\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"primary\"</span> <span class=\"attr\">:change</span>=<span class=\"string\">\"log()\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">radio</span> <span class=\"attr\">value</span>=<span class=\"string\">\"left\"</span>&gt;</span>Left<span class=\"tag\">&lt;/<span class=\"name\">radio</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">radio</span> <span class=\"attr\">value</span>=<span class=\"string\">\"middle\"</span> <span class=\"attr\">checked</span>&gt;</span>Middle<span class=\"tag\">&lt;/<span class=\"name\">radio</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">radio</span> <span class=\"attr\">value</span>=<span class=\"string\">\"right\"</span>&gt;</span>Right<span class=\"tag\">&lt;/<span class=\"name\">radio</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">radio-group</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>vue-strap对开发者来说可以理解为一个黑盒子，而官方例子又非常的不具体，导致我们很容易用错。这里我可能就犯了一个思维错误，至少vue-strap的哲学不推荐我这么干（我猜的）。</p>\n<p>到底哪里有问题呢？我想当然的根据使用jquery的思维来使用radio-group组件，导致我使用<code>onchange</code>事件来处理变更事件。</p>\n<p>但注意到<code>:value.sync</code>的绑定方式，我们这里应该使用双向绑定的思维来实现这个需求：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ready: <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.$watch(<span class=\"string\">'radioValue'</span>, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">newVal, oldVal</span>)</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.$dispatch(<span class=\"string\">\"event-route\"</span>, &#123;eventName:<span class=\"string\">\"change\"</span>, data: newVal&#125;)&#125;);</span><br><span class=\"line\">\t&#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里我们在对应组件的生命周期方法中绑定了<code>$watch</code>回调，这样每当<code>radioValue</code>变更时就会捕捉到，我们并没有直接在<code>radio-group</code>组件上来做这件事儿，一切灵异事件都不见了（包括初始化问题）。之所以会想到这么做，是因为在排查bug时，我们不应该对黑盒子做任何假设，一切逻辑都尽可能由我们自己来完成，以最大程度的排除干扰。</p>\n<p>感悟：只用使用匹配的思维来使用一个组件或库，才能真正的提升效率，否则可能事倍功半。</p>"},{"title":"vuejs使用中的两个小坑","date":"2016-05-20T01:37:00.000Z","_content":"\n我承认，这篇文章题目起的很不将就，不过相信我，已经尽力了。\n\n最近一直在为项目写demo，算是帮同事提前采坑吧，不过也告一段落了。最后来记录两个小细节~\n<!--more-->\n### VueStrap和bootstrap的冲突\n\n测试使用的版本是：\n\n- vue-strap 1.0.7\n- bootstrap 3.3.6\n\n按说vue-strap只是封装了一下bootstrap，可实际使用时，竟然发现VueStrap.radioGroup和bootstrap.[min].js文件有冲突，导致前者失效。\n\n由于我的场景是想使用bootstrap的tooltip功能，所以我的解决方案是：不要加载bootstrap.[min].js，而是直接加载其独立的`./node_modules/bootstrap/js/tooltip.js`即可快速的越过该冲突。\n\n### 组件的ready回调中$broadcast事件给子组件无效\n\n这个问题要比第一个更有代表意义。vue组件化后，我们就有了很多父子关系的组件，在此场景下，如果你在父组件的ready回调中试图向其子组件广播事件，你可能会发现一切什么都未发生，原因也很简单，因为此时可能子组件还未渲染，更谈不上绑定事件了！\n\n解决方案也很简单，就是使用vue提供的`$nextTick`方法，将广播事件的逻辑放在下一个时钟触发，即可以保证子组件响应指定事件。\n\n### 预告\n\n好了，vuejs相关的主题就暂时告一段落，接下来我可能会写一些wordpress二次开发的内容，因为项目要用~~\n","source":"_posts/vuejs使用中的两个小坑.md","raw":"title:  vuejs使用中的两个小坑\ndate: 2016-05-20 09:37:00\ntags:\n- vue.js\n- VueStrap\n- bootstrap\n- 生命周期hook\n- $nextTick\n\ncategories: 前端\n---\n\n我承认，这篇文章题目起的很不将就，不过相信我，已经尽力了。\n\n最近一直在为项目写demo，算是帮同事提前采坑吧，不过也告一段落了。最后来记录两个小细节~\n<!--more-->\n### VueStrap和bootstrap的冲突\n\n测试使用的版本是：\n\n- vue-strap 1.0.7\n- bootstrap 3.3.6\n\n按说vue-strap只是封装了一下bootstrap，可实际使用时，竟然发现VueStrap.radioGroup和bootstrap.[min].js文件有冲突，导致前者失效。\n\n由于我的场景是想使用bootstrap的tooltip功能，所以我的解决方案是：不要加载bootstrap.[min].js，而是直接加载其独立的`./node_modules/bootstrap/js/tooltip.js`即可快速的越过该冲突。\n\n### 组件的ready回调中$broadcast事件给子组件无效\n\n这个问题要比第一个更有代表意义。vue组件化后，我们就有了很多父子关系的组件，在此场景下，如果你在父组件的ready回调中试图向其子组件广播事件，你可能会发现一切什么都未发生，原因也很简单，因为此时可能子组件还未渲染，更谈不上绑定事件了！\n\n解决方案也很简单，就是使用vue提供的`$nextTick`方法，将广播事件的逻辑放在下一个时钟触发，即可以保证子组件响应指定事件。\n\n### 预告\n\n好了，vuejs相关的主题就暂时告一段落，接下来我可能会写一些wordpress二次开发的内容，因为项目要用~~\n","slug":"vuejs使用中的两个小坑","published":1,"updated":"2016-05-21T09:25:32.000Z","_id":"ciofuakcf0000s7fyp0xguk4p","comments":1,"layout":"post","photos":[],"link":"","content":"<p>我承认，这篇文章题目起的很不将就，不过相信我，已经尽力了。</p>\n<p>最近一直在为项目写demo，算是帮同事提前采坑吧，不过也告一段落了。最后来记录两个小细节~<br><a id=\"more\"></a></p>\n<h3 id=\"VueStrap和bootstrap的冲突\"><a href=\"#VueStrap和bootstrap的冲突\" class=\"headerlink\" title=\"VueStrap和bootstrap的冲突\"></a>VueStrap和bootstrap的冲突</h3><p>测试使用的版本是：</p>\n<ul>\n<li>vue-strap 1.0.7</li>\n<li>bootstrap 3.3.6</li>\n</ul>\n<p>按说vue-strap只是封装了一下bootstrap，可实际使用时，竟然发现VueStrap.radioGroup和bootstrap.[min].js文件有冲突，导致前者失效。</p>\n<p>由于我的场景是想使用bootstrap的tooltip功能，所以我的解决方案是：不要加载bootstrap.[min].js，而是直接加载其独立的<code>./node_modules/bootstrap/js/tooltip.js</code>即可快速的越过该冲突。</p>\n<h3 id=\"组件的ready回调中-broadcast事件给子组件无效\"><a href=\"#组件的ready回调中-broadcast事件给子组件无效\" class=\"headerlink\" title=\"组件的ready回调中$broadcast事件给子组件无效\"></a>组件的ready回调中$broadcast事件给子组件无效</h3><p>这个问题要比第一个更有代表意义。vue组件化后，我们就有了很多父子关系的组件，在此场景下，如果你在父组件的ready回调中试图向其子组件广播事件，你可能会发现一切什么都未发生，原因也很简单，因为此时可能子组件还未渲染，更谈不上绑定事件了！</p>\n<p>解决方案也很简单，就是使用vue提供的<code>$nextTick</code>方法，将广播事件的逻辑放在下一个时钟触发，即可以保证子组件响应指定事件。</p>\n<h3 id=\"预告\"><a href=\"#预告\" class=\"headerlink\" title=\"预告\"></a>预告</h3><p>好了，vuejs相关的主题就暂时告一段落，接下来我可能会写一些wordpress二次开发的内容，因为项目要用~~</p>\n","excerpt":"<p>我承认，这篇文章题目起的很不将就，不过相信我，已经尽力了。</p>\n<p>最近一直在为项目写demo，算是帮同事提前采坑吧，不过也告一段落了。最后来记录两个小细节~<br>","more":"</p>\n<h3 id=\"VueStrap和bootstrap的冲突\"><a href=\"#VueStrap和bootstrap的冲突\" class=\"headerlink\" title=\"VueStrap和bootstrap的冲突\"></a>VueStrap和bootstrap的冲突</h3><p>测试使用的版本是：</p>\n<ul>\n<li>vue-strap 1.0.7</li>\n<li>bootstrap 3.3.6</li>\n</ul>\n<p>按说vue-strap只是封装了一下bootstrap，可实际使用时，竟然发现VueStrap.radioGroup和bootstrap.[min].js文件有冲突，导致前者失效。</p>\n<p>由于我的场景是想使用bootstrap的tooltip功能，所以我的解决方案是：不要加载bootstrap.[min].js，而是直接加载其独立的<code>./node_modules/bootstrap/js/tooltip.js</code>即可快速的越过该冲突。</p>\n<h3 id=\"组件的ready回调中-broadcast事件给子组件无效\"><a href=\"#组件的ready回调中-broadcast事件给子组件无效\" class=\"headerlink\" title=\"组件的ready回调中$broadcast事件给子组件无效\"></a>组件的ready回调中$broadcast事件给子组件无效</h3><p>这个问题要比第一个更有代表意义。vue组件化后，我们就有了很多父子关系的组件，在此场景下，如果你在父组件的ready回调中试图向其子组件广播事件，你可能会发现一切什么都未发生，原因也很简单，因为此时可能子组件还未渲染，更谈不上绑定事件了！</p>\n<p>解决方案也很简单，就是使用vue提供的<code>$nextTick</code>方法，将广播事件的逻辑放在下一个时钟触发，即可以保证子组件响应指定事件。</p>\n<h3 id=\"预告\"><a href=\"#预告\" class=\"headerlink\" title=\"预告\"></a>预告</h3><p>好了，vuejs相关的主题就暂时告一段落，接下来我可能会写一些wordpress二次开发的内容，因为项目要用~~</p>"},{"title":"centos安装nginx+php-fpm","date":"2016-05-21T01:37:00.000Z","_content":"\n好久没装过PHP环境了，好久没有手动配置LNMP环境了，今天就让我头疼了一把！\n\n不过随着时间的推移，yum的源里越来越多的库可以直接使用了，现在自己在配置nginx和php环境就不再需要源码编译，也不再需要往yum中添加啥源了，直接就可以通过下面的命令完成安装：\n\n```\nyum install -y nginx php php-fpm\n```\n\n若系统之前yum安装过php，可以先卸载了：\n\n```\nyum remove httpd* php*\n```\n\n安装完毕后，需要稍微修改一下配置文件来完成最后的工作，php-fpm需要修改一下权限：\n\n```\nvi /etc/php-fpm.d/www.conf\n```\n将`Unix user/group of processes`改成你os对应的设置，例如：\n\n```\nuser = www \ngroup = www  \n```\n\n然后需要开启nginx对应的php配置项：\n\n```\nvi /etc/nginx/conf.d/default.conf\n```\n\n开启下面这部分配置：\n\n```\nlocation ~ \\.php$ {  \n    include /etc/nginx/fastcgi_params;  \n    fastcgi_pass  127.0.0.1:9000;  \n    fastcgi_index index.php;  \n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;  \n}  \n```\n\n一切就绪，就可以分别开启对应服务了：\n\n```\n/etc/init.d/php-fpm restart \n/etc/init.d/nginx restart  \n```\n\n### nginx File not found 错误\n\n这个时候如果你访问本地的nginx服务，如果看到了\"File not found\"错误提醒，原因多半是：**php-fpm进程找不到SCRIPT_FILENAME配置的要执行的.php文件**。\n\n由于默认nginx将`root`参数放在了`location`内部，所以你得注意一下对应设置的文件目录是否正确，或者推荐你将`root`参数从`location`中移到`server`中，这样所有的子`location`将使用统一的web根目录。\n\n此外，为了避免一些php cms系统的默认行为，你还是最好将`index`参数里增加`index.php`，来适配系统的默认首页匹配规范，避免不必要的麻烦。","source":"_posts/centos下安装nginx+php-fpm.md","raw":"title:  centos安装nginx+php-fpm\ndate: 2016-05-21 09:37:00\ntags:\n- centos\n- nginx\n- php-fpm\n\ncategories: 运维\n---\n\n好久没装过PHP环境了，好久没有手动配置LNMP环境了，今天就让我头疼了一把！\n\n不过随着时间的推移，yum的源里越来越多的库可以直接使用了，现在自己在配置nginx和php环境就不再需要源码编译，也不再需要往yum中添加啥源了，直接就可以通过下面的命令完成安装：\n\n```\nyum install -y nginx php php-fpm\n```\n\n若系统之前yum安装过php，可以先卸载了：\n\n```\nyum remove httpd* php*\n```\n\n安装完毕后，需要稍微修改一下配置文件来完成最后的工作，php-fpm需要修改一下权限：\n\n```\nvi /etc/php-fpm.d/www.conf\n```\n将`Unix user/group of processes`改成你os对应的设置，例如：\n\n```\nuser = www \ngroup = www  \n```\n\n然后需要开启nginx对应的php配置项：\n\n```\nvi /etc/nginx/conf.d/default.conf\n```\n\n开启下面这部分配置：\n\n```\nlocation ~ \\.php$ {  \n    include /etc/nginx/fastcgi_params;  \n    fastcgi_pass  127.0.0.1:9000;  \n    fastcgi_index index.php;  \n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;  \n}  \n```\n\n一切就绪，就可以分别开启对应服务了：\n\n```\n/etc/init.d/php-fpm restart \n/etc/init.d/nginx restart  \n```\n\n### nginx File not found 错误\n\n这个时候如果你访问本地的nginx服务，如果看到了\"File not found\"错误提醒，原因多半是：**php-fpm进程找不到SCRIPT_FILENAME配置的要执行的.php文件**。\n\n由于默认nginx将`root`参数放在了`location`内部，所以你得注意一下对应设置的文件目录是否正确，或者推荐你将`root`参数从`location`中移到`server`中，这样所有的子`location`将使用统一的web根目录。\n\n此外，为了避免一些php cms系统的默认行为，你还是最好将`index`参数里增加`index.php`，来适配系统的默认首页匹配规范，避免不必要的麻烦。","slug":"centos下安装nginx+php-fpm","published":1,"updated":"2016-05-21T09:25:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciogy9tna0000s8fyv0z2i3y3","content":"<p>好久没装过PHP环境了，好久没有手动配置LNMP环境了，今天就让我头疼了一把！</p>\n<p>不过随着时间的推移，yum的源里越来越多的库可以直接使用了，现在自己在配置nginx和php环境就不再需要源码编译，也不再需要往yum中添加啥源了，直接就可以通过下面的命令完成安装：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y nginx php php-fpm</span><br></pre></td></tr></table></figure>\n<p>若系统之前yum安装过php，可以先卸载了：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum remove httpd* php*</span><br></pre></td></tr></table></figure>\n<p>安装完毕后，需要稍微修改一下配置文件来完成最后的工作，php-fpm需要修改一下权限：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/php-fpm.d/www.conf</span><br></pre></td></tr></table></figure>\n<p>将<code>Unix user/group of processes</code>改成你os对应的设置，例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">user = www </span><br><span class=\"line\">group = www</span><br></pre></td></tr></table></figure>\n<p>然后需要开启nginx对应的php配置项：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/nginx/conf.d/default.conf</span><br></pre></td></tr></table></figure>\n<p>开启下面这部分配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~ \\.php$ &#123;  </span><br><span class=\"line\">    include /etc/nginx/fastcgi_params;  </span><br><span class=\"line\">    fastcgi_pass  127.0.0.1:9000;  </span><br><span class=\"line\">    fastcgi_index index.php;  </span><br><span class=\"line\">    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>一切就绪，就可以分别开启对应服务了：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/init.d/php-fpm restart </span><br><span class=\"line\">/etc/init.d/nginx restart</span><br></pre></td></tr></table></figure>\n<h3 id=\"nginx-File-not-found-错误\"><a href=\"#nginx-File-not-found-错误\" class=\"headerlink\" title=\"nginx File not found 错误\"></a>nginx File not found 错误</h3><p>这个时候如果你访问本地的nginx服务，如果看到了”File not found”错误提醒，原因多半是：<strong>php-fpm进程找不到SCRIPT_FILENAME配置的要执行的.php文件</strong>。</p>\n<p>由于默认nginx将<code>root</code>参数放在了<code>location</code>内部，所以你得注意一下对应设置的文件目录是否正确，或者推荐你将<code>root</code>参数从<code>location</code>中移到<code>server</code>中，这样所有的子<code>location</code>将使用统一的web根目录。</p>\n<p>此外，为了避免一些php cms系统的默认行为，你还是最好将<code>index</code>参数里增加<code>index.php</code>，来适配系统的默认首页匹配规范，避免不必要的麻烦。</p>\n","excerpt":"","more":"<p>好久没装过PHP环境了，好久没有手动配置LNMP环境了，今天就让我头疼了一把！</p>\n<p>不过随着时间的推移，yum的源里越来越多的库可以直接使用了，现在自己在配置nginx和php环境就不再需要源码编译，也不再需要往yum中添加啥源了，直接就可以通过下面的命令完成安装：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y nginx php php-fpm</span><br></pre></td></tr></table></figure>\n<p>若系统之前yum安装过php，可以先卸载了：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum remove httpd* php*</span><br></pre></td></tr></table></figure>\n<p>安装完毕后，需要稍微修改一下配置文件来完成最后的工作，php-fpm需要修改一下权限：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/php-fpm.d/www.conf</span><br></pre></td></tr></table></figure>\n<p>将<code>Unix user/group of processes</code>改成你os对应的设置，例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">user = www </span><br><span class=\"line\">group = www</span><br></pre></td></tr></table></figure>\n<p>然后需要开启nginx对应的php配置项：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/nginx/conf.d/default.conf</span><br></pre></td></tr></table></figure>\n<p>开启下面这部分配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~ \\.php$ &#123;  </span><br><span class=\"line\">    include /etc/nginx/fastcgi_params;  </span><br><span class=\"line\">    fastcgi_pass  127.0.0.1:9000;  </span><br><span class=\"line\">    fastcgi_index index.php;  </span><br><span class=\"line\">    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>一切就绪，就可以分别开启对应服务了：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/init.d/php-fpm restart </span><br><span class=\"line\">/etc/init.d/nginx restart</span><br></pre></td></tr></table></figure>\n<h3 id=\"nginx-File-not-found-错误\"><a href=\"#nginx-File-not-found-错误\" class=\"headerlink\" title=\"nginx File not found 错误\"></a>nginx File not found 错误</h3><p>这个时候如果你访问本地的nginx服务，如果看到了”File not found”错误提醒，原因多半是：<strong>php-fpm进程找不到SCRIPT_FILENAME配置的要执行的.php文件</strong>。</p>\n<p>由于默认nginx将<code>root</code>参数放在了<code>location</code>内部，所以你得注意一下对应设置的文件目录是否正确，或者推荐你将<code>root</code>参数从<code>location</code>中移到<code>server</code>中，这样所有的子<code>location</code>将使用统一的web根目录。</p>\n<p>此外，为了避免一些php cms系统的默认行为，你还是最好将<code>index</code>参数里增加<code>index.php</code>，来适配系统的默认首页匹配规范，避免不必要的麻烦。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cica18yjc0000gtfyl5nanu8y","category_id":"cica18yjj0001gtfyu8xkmbm3","_id":"cica18yjm0004gtfyuy2fu0ns"},{"post_id":"cica18yk0000dgtfybveb0si0","category_id":"cica18yk2000egtfyvkrdmydl","_id":"cica18yk3000hgtfyagdnkxll"},{"post_id":"cica18yk6000kgtfy8ujjbkh3","category_id":"cica18yk2000egtfyvkrdmydl","_id":"cica18yk7000lgtfy3k4il7sc"},{"post_id":"cica18ykf000ygtfycmvlkgmg","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ykh0012gtfyyo7a0g1e"},{"post_id":"cica18ykk0019gtfy85qqkz0a","category_id":"cica18ykl001agtfya1o2ajsi","_id":"cica18ykm001dgtfydg1n17x2"},{"post_id":"cica18yko001ggtfynb2hd0y2","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ykp001hgtfyxhysm66j"},{"post_id":"cica18ykt001tgtfye15ccko3","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ykv001ugtfydx4khrzj"},{"post_id":"cica18yky0020gtfy2gfzz2sq","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ykz0021gtfyvgenk8a4"},{"post_id":"cica18yl20027gtfyg1p5hqc8","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yl50028gtfya24lyjsj"},{"post_id":"cica18ylb002fgtfyxvdbg42h","category_id":"cica18yld002ggtfyq1rhy9mp","_id":"cica18yle002jgtfyauf2oux9"},{"post_id":"cica18yll002tgtfy7c69jkiv","category_id":"cica18ylm002ugtfyfo9u40cb","_id":"cica18yln002xgtfy5d8nnsld"},{"post_id":"cica18ylt003agtfyle01pmmj","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ylu003bgtfyoxh027k1"},{"post_id":"cica18yly003kgtfyjuoosei1","category_id":"cica18ym0003lgtfyqoedatad","_id":"cica18ym2003ogtfyvqd4nzu7"},{"post_id":"cica18ym5003pgtfyturapd57","category_id":"cica18ym6003qgtfyx7pl02ff","_id":"cica18ym7003tgtfyp21xh06t"},{"post_id":"cica18yma003wgtfyy0riin4e","category_id":"cica18ym6003qgtfyx7pl02ff","_id":"cica18ymb003xgtfypibevydf"},{"post_id":"cica18ymf0044gtfywmn9ysss","category_id":"cica18ym6003qgtfyx7pl02ff","_id":"cica18ymg0045gtfy0ta8xfs8"},{"post_id":"cica18ymh0048gtfy6ik151aa","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ymj0049gtfy117wsa00"},{"post_id":"cica18ymo004mgtfyywrwwshg","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ymq004ngtfydqbr0hwh"},{"post_id":"cica18ymt004xgtfypno4kvmv","category_id":"cica18yjj0001gtfyu8xkmbm3","_id":"cica18ymv004ygtfyqhh4nj9u"},{"post_id":"cica18ymx0057gtfyv1f124rb","category_id":"cica18yld002ggtfyq1rhy9mp","_id":"cica18ymy0058gtfyct342n7f"},{"post_id":"cica18yn9005lgtfygrzb043y","category_id":"cica18ylh002pgtfyk6l8szwo","_id":"cica18ynb005mgtfyuh1ur5b0"},{"post_id":"cica18ynd005ngtfypl7cnto7","category_id":"cica18ylh002pgtfyk6l8szwo","_id":"cica18ynf005ogtfyse4hh2i2"},{"post_id":"cica18ynh005rgtfy4574ndbq","category_id":"cica18ynj005sgtfybb1k7n7v","_id":"cica18ynl005vgtfyxaqqlsbc"},{"post_id":"cica18ynr006bgtfysbri9p4q","category_id":"cica18ym0003lgtfyqoedatad","_id":"cica18ynt006cgtfykq35jhof"},{"post_id":"cica18ynx006jgtfyz1rbbfu4","category_id":"cica18ynj005sgtfybb1k7n7v","_id":"cica18yny006kgtfys0jjtqty"},{"post_id":"cica18yo0006pgtfywlgh99d4","category_id":"cica18yld002ggtfyq1rhy9mp","_id":"cica18yo2006qgtfydwgazkmf"},{"post_id":"cica18yo5006xgtfytj665w58","category_id":"cica18yld002ggtfyq1rhy9mp","_id":"cica18yo6006ygtfy676gkmdc"},{"post_id":"cica18yo80075gtfyp6864958","category_id":"cica18ynj005sgtfybb1k7n7v","_id":"cica18yoa0076gtfyenbsvcse"},{"post_id":"cica18yom007ngtfydxe2kpb5","category_id":"cica18yon007ogtfyf5x13c9a","_id":"cica18yop007rgtfys5p6ppf2"},{"post_id":"cica18yov007wgtfyv9a10d2f","category_id":"cica18ykl001agtfya1o2ajsi","_id":"cica18yoy007xgtfy9kizo6vl"},{"post_id":"cica18yp1007zgtfykaibz3ri","category_id":"cica18yld002ggtfyq1rhy9mp","_id":"cica18yp20080gtfye8i59r0h"},{"post_id":"cica18yp70088gtfyxl9dwxvd","category_id":"cica18yk2000egtfyvkrdmydl","_id":"cica18yp90089gtfyhn732s5c"},{"post_id":"cica18ypc008bgtfyflrfl7ng","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ypd008cgtfy6ku3cwyc"},{"post_id":"cica18ypi008ogtfyoak2sfws","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ypj008pgtfyumku1l9i"},{"post_id":"cica18ypq008vgtfyullwdm9m","category_id":"cica18yld002ggtfyq1rhy9mp","_id":"cica18ypt008wgtfyk4n51q2y"},{"post_id":"cica18yq00096gtfy9rygcwt3","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yq20097gtfyjutfgt78"},{"post_id":"cica18yq5009egtfyrxn02gmq","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yq6009fgtfymjctlqwf"},{"post_id":"cica18yq9009lgtfy9qk1ndw0","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yqa009mgtfy5x54cem4"},{"post_id":"cica18yqf009xgtfy1k3w6i66","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yqg009ygtfykcn4wzqy"},{"post_id":"cica18yqj00a6gtfy1846vfxj","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yqk00a7gtfylvxip8mx"},{"post_id":"cica18yqo00aggtfysz1yll54","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yqr00ahgtfyfzmq66sa"},{"post_id":"cica18yqv00argtfypf8mgesa","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yqx00asgtfys3r6b9p0"},{"post_id":"cica18yqz00axgtfy5avtaw7h","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yr000aygtfyyd356tbx"},{"post_id":"cica18yr300b6gtfyus3puwdg","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yr500b7gtfy2vsysaay"},{"post_id":"cica18yr700bagtfysnl7xmpk","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yr900bbgtfynkfqn1q2"},{"post_id":"cica18yrc00bigtfy47k1vik2","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yre00bjgtfypq7d8ki2"},{"post_id":"cica18yrj00bsgtfy8g1o6ehh","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yrl00btgtfyr9mab34v"},{"post_id":"cica18yrn00bwgtfycdnbh19f","category_id":"cica18ym0003lgtfyqoedatad","_id":"cica18yro00bxgtfypaa1e6g4"},{"post_id":"cica18yrr00c4gtfycwwzw3ch","category_id":"cica18ym0003lgtfyqoedatad","_id":"cica18yrs00c5gtfytqfgpdiq"},{"post_id":"cica18ys000ccgtfywbspz2iw","category_id":"cica18ym0003lgtfyqoedatad","_id":"cica18ys100cdgtfy799ptad1"},{"post_id":"cica18ys500ckgtfygod7zati","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ys700clgtfywo795pfa"},{"post_id":"cica18ysj00cvgtfyvbnb56pk","category_id":"cica18ysl00cwgtfym9plk4no","_id":"cica18ysn00czgtfy5tztyk6n"},{"post_id":"cica18ysp00d5gtfyc0kcxx35","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ysr00d6gtfymnsnkzod"},{"post_id":"cica18ysv00degtfypzo7rlti","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18ysx00dfgtfyhs8e4wat"},{"post_id":"cica18yt000dpgtfyfweottii","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yt200dqgtfy2qh4htfb"},{"post_id":"cica18yt500e0gtfyx8chvbni","category_id":"cica18ykg000zgtfy09rqwb4h","_id":"cica18yt600e1gtfymodxncyq"},{"post_id":"cica18yta00e8gtfy66x1yycu","category_id":"cica18yk2000egtfyvkrdmydl","_id":"cica18ytb00e9gtfy60vhupmc"},{"post_id":"cica18ylg002ogtfyx8hgxi6f","category_id":"cica18ylh002pgtfyk6l8szwo","_id":"cid38pv8100052hwsqxa4cgl3"},{"post_id":"cid38pv5k00002hws2w7a57bd","category_id":"cica18ym0003lgtfyqoedatad","_id":"cidr1e0zy000710wsjsxz89hc"},{"post_id":"cidr1e0y5000010ws91jer8b0","category_id":"cica18ym0003lgtfyqoedatad","_id":"ciee5jafi0009tcwsr2xi9j3e"},{"post_id":"ciee5jad80000tcwslvz63sl2","category_id":"cica18ym0003lgtfyqoedatad","_id":"cifi95bdc0008rjwsuzr3qf0c"},{"post_id":"cifi95baw0000rjws930lqbed","category_id":"cica18ym0003lgtfyqoedatad","_id":"cifjtuyir000foews3s36utcx"},{"post_id":"cifqxchx70000hkws8msk5nxp","category_id":"cica18ym0003lgtfyqoedatad","_id":"cig4tt500000asuwszp01qo58"},{"post_id":"cifjtuyg20000oews2deyibih","category_id":"cica18ym0003lgtfyqoedatad","_id":"cig4tt50d000bsuwsqcukgc6d"},{"post_id":"cig4tt4vc0000suws6k37qbcu","category_id":"cica18ym0003lgtfyqoedatad","_id":"cih0be1ie0003ikws1ah8d4q2"},{"post_id":"cih0be1hd0000ikws2w1avnip","category_id":"cica18ym0003lgtfyqoedatad","_id":"cihdildwy0008nxwshdfrbnog"},{"post_id":"cihdildua0000nxwsojoyv4lp","category_id":"cica18ym0003lgtfyqoedatad","_id":"cihg3bniq000160wsdthdvgcb"},{"post_id":"ciheqt5z50000pcwsp9aj90wr","category_id":"cica18ym0003lgtfyqoedatad","_id":"cihp0xurk0008mzfyx8tvixic"},{"post_id":"cihqgv1xn0000kywsei8jfi6v","category_id":"cihp0xups0001mzfycagcbrxa","_id":"cihqgv1xy0001kywsj88zjwkt"},{"post_id":"cihp0xupj0000mzfyi5dmkm9f","category_id":"cihp0xups0001mzfycagcbrxa","_id":"cihqgv20h0007kyws4eiyihbg"},{"post_id":"ciift0f500004p8ws2qncgs7u","category_id":"cihp0xups0001mzfycagcbrxa","_id":"ciift0f550005p8wswwsevjdn"},{"post_id":"ciig1awvm0000h5wsmihag50z","category_id":"cihp0xups0001mzfycagcbrxa","_id":"ciig1aww00001h5wscr4uho09"},{"post_id":"ciift0f210000p8ws023qajnr","category_id":"cihp0xups0001mzfycagcbrxa","_id":"ciig1awz00007h5wsehce5kya"},{"post_id":"ciiznmhdp0000wfwsnfmrj6w4","category_id":"cica18ym0003lgtfyqoedatad","_id":"ciiznmhe10001wfwsmp4yxs64"},{"post_id":"ciizs3p5d000034wspgrg1xcc","category_id":"cica18ym0003lgtfyqoedatad","_id":"cil3q63hf00057nws6t7rku1x"},{"post_id":"cil3q63ep00007nwsqb322qzk","category_id":"cica18ysl00cwgtfym9plk4no","_id":"cildphkix0006hzfy58el42zy"},{"post_id":"cildphkgb0000hzfy20vqtspy","category_id":"cica18ylm002ugtfyfo9u40cb","_id":"cilp4udij0007l1fyimuo0z5b"},{"post_id":"cilp4udnq0008l1fy0ug8esl7","category_id":"cica18ym0003lgtfyqoedatad","_id":"cilp4udnt0009l1fy5kb9rgfw"},{"post_id":"cilp4udgz0000l1fy385hxp51","category_id":"cilp4udh80001l1fy0ho9xp63","_id":"cima1so840008vofyo40nse25"},{"post_id":"cimjc5pz600001nfy66rl525r","category_id":"cimjc5pzg00011nfy5218hbkh","_id":"cimjc5q1i00041nfy97ghh4t5"},{"post_id":"cima1so5c0000vofym5ugnxte","category_id":"cima1so5n0001vofyq19oay8a","_id":"cimjc5q2100081nfyiv5mjv93"},{"post_id":"cimjc5q4100091nfyjdukfzip","category_id":"cica18ylh002pgtfyk6l8szwo","_id":"cimjc5q44000a1nfykmm19yxj"},{"post_id":"cimjc5q49000g1nfygx52686o","category_id":"cimjc5pzg00011nfy5218hbkh","_id":"cimjc5q4e000h1nfyudphm05v"},{"post_id":"cinbsa3z00000l3fyvwxi6py0","category_id":"cica18ym0003lgtfyqoedatad","_id":"cinbsa3za0001l3fy0gdmui7k"},{"post_id":"cima1so9h0009vofy03l20gsf","category_id":"cica18ym0003lgtfyqoedatad","_id":"cinbsa41b0008l3fy3inu65sg"},{"post_id":"cinbsa42v0009l3fygae4saau","category_id":"cica18ym0003lgtfyqoedatad","_id":"cinbsa42y000al3fyo5k8c935"},{"post_id":"cinbsa436000hl3fys8l9oqip","category_id":"cica18ym0003lgtfyqoedatad","_id":"cinbsa439000il3fyynwr3uo4"},{"post_id":"cio4dt7s10000safy77rivgxl","category_id":"cica18ykl001agtfya1o2ajsi","_id":"cio4dt7sj0001safyg5qtbrnr"},{"post_id":"cio4dt7zh000asafyn727g1h8","category_id":"cica18ym6003qgtfyx7pl02ff","_id":"cio4dt7zo000bsafyu6u47yf1"},{"post_id":"cio4dt80m000fsafye3xolxye","category_id":"cica18ym0003lgtfyqoedatad","_id":"cio4dt80r000gsafyw1quzeia"},{"post_id":"cio4dt810000psafygfmqvrto","category_id":"cica18ym0003lgtfyqoedatad","_id":"cio4dt813000qsafytzpj0vk9"},{"post_id":"ciofuakcf0000s7fyp0xguk4p","category_id":"cica18ym0003lgtfyqoedatad","_id":"ciofuakee0002s7fyr34r9o8w"},{"post_id":"ciogy9tna0000s8fyv0z2i3y3","category_id":"cica18yld002ggtfyq1rhy9mp","_id":"ciogy9tpf0002s8fynmt4o85w"}],"PostTag":[{"post_id":"cica18yjc0000gtfyl5nanu8y","tag_id":"cica18yjj0002gtfysrpzak6e","_id":"cica18yjn0008gtfyfofb4695"},{"post_id":"cica18yjc0000gtfyl5nanu8y","tag_id":"cica18yjm0003gtfybz0o1ps0","_id":"cica18yjn0009gtfymi3hrtb7"},{"post_id":"cica18yjc0000gtfyl5nanu8y","tag_id":"cica18yjm0005gtfyuiwm70wv","_id":"cica18yjo000agtfy5316qabf"},{"post_id":"cica18yjc0000gtfyl5nanu8y","tag_id":"cica18yjn0006gtfy44m2eypo","_id":"cica18yjo000bgtfylhyuj6e4"},{"post_id":"cica18yjc0000gtfyl5nanu8y","tag_id":"cica18yjn0007gtfyh0f5qdx9","_id":"cica18yjo000cgtfy6p37afzv"},{"post_id":"cica18yk0000dgtfybveb0si0","tag_id":"cica18yk2000fgtfyqhgyo444","_id":"cica18yk3000igtfy7z2xuj00"},{"post_id":"cica18yk0000dgtfybveb0si0","tag_id":"cica18yk3000ggtfy0ixd0rgx","_id":"cica18yk3000jgtfyf2f33g9v"},{"post_id":"cica18yk6000kgtfy8ujjbkh3","tag_id":"cica18yk7000mgtfy1hfc9mqq","_id":"cica18ykc000sgtfy9qebbz45"},{"post_id":"cica18yk6000kgtfy8ujjbkh3","tag_id":"cica18yk9000ngtfywpz2rwez","_id":"cica18ykc000tgtfyfo8mhted"},{"post_id":"cica18yk6000kgtfy8ujjbkh3","tag_id":"cica18yka000ogtfyzugmv73l","_id":"cica18ykc000ugtfyhsioyp0o"},{"post_id":"cica18yk6000kgtfy8ujjbkh3","tag_id":"cica18yka000pgtfy8pghll74","_id":"cica18ykc000vgtfynhepzkzg"},{"post_id":"cica18yk6000kgtfy8ujjbkh3","tag_id":"cica18yka000qgtfy4g9yr7ew","_id":"cica18ykc000wgtfy9xdowg9b"},{"post_id":"cica18yk6000kgtfy8ujjbkh3","tag_id":"cica18ykb000rgtfy2bq4gztd","_id":"cica18ykd000xgtfyvhqk80qr"},{"post_id":"cica18ykf000ygtfycmvlkgmg","tag_id":"cica18ykg0010gtfyb0bz5q5f","_id":"cica18yki0015gtfy4q25ovh4"},{"post_id":"cica18ykf000ygtfycmvlkgmg","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18ykj0016gtfyqksniz4t"},{"post_id":"cica18ykf000ygtfycmvlkgmg","tag_id":"cica18yki0013gtfye7ij27cg","_id":"cica18ykj0017gtfywaj133es"},{"post_id":"cica18ykf000ygtfycmvlkgmg","tag_id":"cica18yki0014gtfyr1qwaxf1","_id":"cica18ykj0018gtfyv4vprcuz"},{"post_id":"cica18ykk0019gtfy85qqkz0a","tag_id":"cica18ykm001bgtfyw1bc372c","_id":"cica18ykn001egtfy3cnq43gk"},{"post_id":"cica18ykk0019gtfy85qqkz0a","tag_id":"cica18ykm001cgtfyg14axvv0","_id":"cica18ykn001fgtfyxpugio47"},{"post_id":"cica18yko001ggtfynb2hd0y2","tag_id":"cica18ykp001igtfy5bj5kwmt","_id":"cica18ykr001ngtfyse8hz686"},{"post_id":"cica18yko001ggtfynb2hd0y2","tag_id":"cica18yki0014gtfyr1qwaxf1","_id":"cica18ykr001ogtfyb7b0ltgs"},{"post_id":"cica18yko001ggtfynb2hd0y2","tag_id":"cica18ykq001jgtfysqh9psj7","_id":"cica18ykr001pgtfyow0jed01"},{"post_id":"cica18yko001ggtfynb2hd0y2","tag_id":"cica18ykq001kgtfy48l2bq83","_id":"cica18ykr001qgtfyhg83scg6"},{"post_id":"cica18yko001ggtfynb2hd0y2","tag_id":"cica18ykq001lgtfy78dh3321","_id":"cica18ykr001rgtfyq3ansm68"},{"post_id":"cica18yko001ggtfynb2hd0y2","tag_id":"cica18ykq001mgtfyngxw1v5n","_id":"cica18ykr001sgtfyz11u9ebo"},{"post_id":"cica18ykt001tgtfye15ccko3","tag_id":"cica18ykv001vgtfyelalja8u","_id":"cica18ykw001xgtfy07eegk0y"},{"post_id":"cica18ykt001tgtfye15ccko3","tag_id":"cica18ykw001wgtfyi449n7k0","_id":"cica18ykw001ygtfyh1wcnnkp"},{"post_id":"cica18ykt001tgtfye15ccko3","tag_id":"cica18ykq001mgtfyngxw1v5n","_id":"cica18ykw001zgtfyuev89kgv"},{"post_id":"cica18yky0020gtfy2gfzz2sq","tag_id":"cica18ykz0022gtfyhmkmc2jf","_id":"cica18yl00024gtfykevebc8u"},{"post_id":"cica18yky0020gtfy2gfzz2sq","tag_id":"cica18yl00023gtfyqe11shlo","_id":"cica18yl00025gtfy748jt3tf"},{"post_id":"cica18yky0020gtfy2gfzz2sq","tag_id":"cica18ykq001mgtfyngxw1v5n","_id":"cica18yl00026gtfyjbvmrabu"},{"post_id":"cica18yl20027gtfyg1p5hqc8","tag_id":"cica18ykp001igtfy5bj5kwmt","_id":"cica18yl70029gtfyzdvj9hr7"},{"post_id":"cica18yl20027gtfyg1p5hqc8","tag_id":"cica18yki0014gtfyr1qwaxf1","_id":"cica18yl8002agtfymn9nv5wk"},{"post_id":"cica18yl20027gtfyg1p5hqc8","tag_id":"cica18ykq001jgtfysqh9psj7","_id":"cica18yl8002bgtfyermal13m"},{"post_id":"cica18yl20027gtfyg1p5hqc8","tag_id":"cica18ykq001kgtfy48l2bq83","_id":"cica18yl8002cgtfyluch1aaq"},{"post_id":"cica18yl20027gtfyg1p5hqc8","tag_id":"cica18ykq001lgtfy78dh3321","_id":"cica18yl9002dgtfyw8zq783g"},{"post_id":"cica18yl20027gtfyg1p5hqc8","tag_id":"cica18ykq001mgtfyngxw1v5n","_id":"cica18yl9002egtfyca1ilss8"},{"post_id":"cica18ylb002fgtfyxvdbg42h","tag_id":"cica18yld002hgtfyshjqshvd","_id":"cica18ylf002lgtfyqigoif6s"},{"post_id":"cica18ylb002fgtfyxvdbg42h","tag_id":"cica18yle002igtfyhiw8jdc8","_id":"cica18ylf002mgtfyubbo1bx4"},{"post_id":"cica18ylb002fgtfyxvdbg42h","tag_id":"cica18yle002kgtfyz8aea4t0","_id":"cica18ylf002ngtfytp6jwfc0"},{"post_id":"cica18ylg002ogtfyx8hgxi6f","tag_id":"cica18ylh002qgtfypjyg3ytt","_id":"cica18yli002rgtfyv3h1yxd8"},{"post_id":"cica18yll002tgtfy7c69jkiv","tag_id":"cica18ylm002vgtfy98owonew","_id":"cica18ylq0033gtfyewo8s47y"},{"post_id":"cica18yll002tgtfy7c69jkiv","tag_id":"cica18yln002wgtfy0h0kz9ct","_id":"cica18ylq0034gtfyppsbctx1"},{"post_id":"cica18yll002tgtfy7c69jkiv","tag_id":"cica18ylo002ygtfykpxpf4c0","_id":"cica18ylq0035gtfyysvezfze"},{"post_id":"cica18yll002tgtfy7c69jkiv","tag_id":"cica18ylo002zgtfysbzoakps","_id":"cica18ylq0036gtfytjzpu16v"},{"post_id":"cica18yll002tgtfy7c69jkiv","tag_id":"cica18ylp0030gtfy4wkqp7bn","_id":"cica18ylr0037gtfyd5jly5cz"},{"post_id":"cica18yll002tgtfy7c69jkiv","tag_id":"cica18ylp0031gtfyr6or6r7q","_id":"cica18ylr0038gtfygra62c58"},{"post_id":"cica18yll002tgtfy7c69jkiv","tag_id":"cica18ylq0032gtfy6pfy7npm","_id":"cica18ylr0039gtfyiwrwj1vh"},{"post_id":"cica18ylt003agtfyle01pmmj","tag_id":"cica18ylu003cgtfywg9z3dmw","_id":"cica18ylw003ggtfyki9s9ouj"},{"post_id":"cica18ylt003agtfyle01pmmj","tag_id":"cica18ylv003dgtfy0ndzlgdi","_id":"cica18ylw003hgtfym0mwm3lh"},{"post_id":"cica18ylt003agtfyle01pmmj","tag_id":"cica18ylv003egtfy10lnznff","_id":"cica18ylw003igtfyj6otdfgi"},{"post_id":"cica18ylt003agtfyle01pmmj","tag_id":"cica18ylv003fgtfyobyns15h","_id":"cica18ylw003jgtfyjzp7c99i"},{"post_id":"cica18yly003kgtfyjuoosei1","tag_id":"cica18ym0003mgtfyur0532mt","_id":"cica18ym2003ngtfyz8j0gie0"},{"post_id":"cica18ym5003pgtfyturapd57","tag_id":"cica18ym6003rgtfy9ushdnip","_id":"cica18ym7003ugtfyqsb6f3bn"},{"post_id":"cica18ym5003pgtfyturapd57","tag_id":"cica18ym7003sgtfy8r61pz1t","_id":"cica18ym7003vgtfym3qofio7"},{"post_id":"cica18yma003wgtfyy0riin4e","tag_id":"cica18ym6003rgtfy9ushdnip","_id":"cica18ymd0040gtfyicrphuu5"},{"post_id":"cica18yma003wgtfyy0riin4e","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18ymd0041gtfyl914puc3"},{"post_id":"cica18yma003wgtfyy0riin4e","tag_id":"cica18ykg0010gtfyb0bz5q5f","_id":"cica18ymd0042gtfyfktid62e"},{"post_id":"cica18yma003wgtfyy0riin4e","tag_id":"cica18ymc003zgtfyrpdnjypj","_id":"cica18yme0043gtfy33iie11n"},{"post_id":"cica18ymf0044gtfywmn9ysss","tag_id":"cica18ym6003rgtfy9ushdnip","_id":"cica18ymg0046gtfykl42gmca"},{"post_id":"cica18ymf0044gtfywmn9ysss","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18ymg0047gtfy95371b9b"},{"post_id":"cica18ymh0048gtfy6ik151aa","tag_id":"cica18ymk004agtfyavrkpwio","_id":"cica18ymm004ggtfyheo5o4h5"},{"post_id":"cica18ymh0048gtfy6ik151aa","tag_id":"cica18ymk004bgtfy0tv4835f","_id":"cica18ymm004hgtfy8pk97uce"},{"post_id":"cica18ymh0048gtfy6ik151aa","tag_id":"cica18yml004cgtfyun52oywi","_id":"cica18ymm004igtfyu2xy0g9o"},{"post_id":"cica18ymh0048gtfy6ik151aa","tag_id":"cica18yml004dgtfy6bi8s6r9","_id":"cica18ymm004jgtfyfcd4tyy3"},{"post_id":"cica18ymh0048gtfy6ik151aa","tag_id":"cica18yml004egtfym6hjaejz","_id":"cica18ymm004kgtfyqxp6cy81"},{"post_id":"cica18ymh0048gtfy6ik151aa","tag_id":"cica18yml004fgtfy3fuc2pwv","_id":"cica18ymm004lgtfyhbb0ckp9"},{"post_id":"cica18ymo004mgtfyywrwwshg","tag_id":"cica18yka000pgtfy8pghll74","_id":"cica18yms004rgtfywin4gx3g"},{"post_id":"cica18ymo004mgtfyywrwwshg","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yms004sgtfy0ycqg4pj"},{"post_id":"cica18ymo004mgtfyywrwwshg","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yms004tgtfyo43bnlnd"},{"post_id":"cica18ymo004mgtfyywrwwshg","tag_id":"cica18ymr004ogtfyfwr8kuic","_id":"cica18yms004ugtfykow0n2iy"},{"post_id":"cica18ymo004mgtfyywrwwshg","tag_id":"cica18ymr004pgtfyrmcwzd79","_id":"cica18yms004vgtfy7cwzawp8"},{"post_id":"cica18ymo004mgtfyywrwwshg","tag_id":"cica18yms004qgtfyqa3urj06","_id":"cica18yms004wgtfyxvmgzkdf"},{"post_id":"cica18ymt004xgtfypno4kvmv","tag_id":"cica18ymv004zgtfy4u0mjx66","_id":"cica18ymw0053gtfythgm40qp"},{"post_id":"cica18ymt004xgtfypno4kvmv","tag_id":"cica18ymv0050gtfyl1gbnyh8","_id":"cica18ymw0054gtfyxufh7dwc"},{"post_id":"cica18ymt004xgtfypno4kvmv","tag_id":"cica18ymw0051gtfyi9we3ibu","_id":"cica18ymw0055gtfy1rabakfs"},{"post_id":"cica18ymt004xgtfypno4kvmv","tag_id":"cica18ymw0052gtfy9nqyv632","_id":"cica18ymw0056gtfyqxhwf5vq"},{"post_id":"cica18ymx0057gtfyv1f124rb","tag_id":"cica18ymz0059gtfycuyqkd57","_id":"cica18yn7005fgtfyqrve0mo6"},{"post_id":"cica18ymx0057gtfyv1f124rb","tag_id":"cica18ymz005agtfyxpfpseyh","_id":"cica18yn7005ggtfyqmeux9lh"},{"post_id":"cica18ymx0057gtfyv1f124rb","tag_id":"cica18yn6005bgtfy9encssgd","_id":"cica18yn7005hgtfyhzu18xpm"},{"post_id":"cica18ymx0057gtfyv1f124rb","tag_id":"cica18yn6005cgtfyicoug609","_id":"cica18yn7005igtfy1ndh3jk5"},{"post_id":"cica18ymx0057gtfyv1f124rb","tag_id":"cica18yn6005dgtfyxeu7l3i3","_id":"cica18yn7005jgtfyfcwqnvxy"},{"post_id":"cica18ymx0057gtfyv1f124rb","tag_id":"cica18yn7005egtfyrmw6igbe","_id":"cica18yn8005kgtfyrvcdlb7t"},{"post_id":"cica18ynd005ngtfypl7cnto7","tag_id":"cica18ynf005pgtfye4f3excw","_id":"cica18ynf005qgtfyl8jrq31l"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynk005tgtfyh8yq4m4d","_id":"cica18ynn0062gtfy3xllfd2m"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynl005ugtfy954wi1g4","_id":"cica18yno0063gtfywap7kfc4"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynl005wgtfyov5oeqdq","_id":"cica18yno0064gtfy1b09x7ku"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynm005xgtfy8xt2exed","_id":"cica18ynp0065gtfyv3fin06c"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynm005ygtfy3v841a2g","_id":"cica18ynp0066gtfy3s0kxfip"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynm005zgtfyesagtz7u","_id":"cica18ynp0067gtfyyx8oridc"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynm0060gtfyd9qcs2v2","_id":"cica18ynp0068gtfyron8dlcy"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ynn0061gtfyqp6h66wu","_id":"cica18ynp0069gtfypl01ro1r"},{"post_id":"cica18ynh005rgtfy4574ndbq","tag_id":"cica18ykm001bgtfyw1bc372c","_id":"cica18ynp006agtfyzxc6kmot"},{"post_id":"cica18ynr006bgtfysbri9p4q","tag_id":"cica18ynt006dgtfydzf86416","_id":"cica18ynv006ggtfytzxbfw6i"},{"post_id":"cica18ynr006bgtfysbri9p4q","tag_id":"cica18ynu006egtfyaw1bg90e","_id":"cica18ynv006hgtfypzaqdjbv"},{"post_id":"cica18ynr006bgtfysbri9p4q","tag_id":"cica18ynv006fgtfy920kjc1v","_id":"cica18ynw006igtfy99mov2rh"},{"post_id":"cica18ynx006jgtfyz1rbbfu4","tag_id":"cica18ynk005tgtfyh8yq4m4d","_id":"cica18ynz006mgtfytvqugr0a"},{"post_id":"cica18ynx006jgtfyz1rbbfu4","tag_id":"cica18ynm005ygtfy3v841a2g","_id":"cica18ynz006ngtfy4mbzbf1f"},{"post_id":"cica18ynx006jgtfyz1rbbfu4","tag_id":"cica18yny006lgtfy8zp00ow1","_id":"cica18ynz006ogtfye0vfgly6"},{"post_id":"cica18yo0006pgtfywlgh99d4","tag_id":"cica18yo2006rgtfy6ks5mt13","_id":"cica18yo3006ugtfyq1vym14u"},{"post_id":"cica18yo0006pgtfywlgh99d4","tag_id":"cica18yo3006sgtfyzb5hp0s2","_id":"cica18yo3006vgtfyzn2qtii7"},{"post_id":"cica18yo0006pgtfywlgh99d4","tag_id":"cica18yo3006tgtfyp75iegf3","_id":"cica18yo4006wgtfyx9hn4m2p"},{"post_id":"cica18yo5006xgtfytj665w58","tag_id":"cica18yo6006zgtfy3fotx9mn","_id":"cica18yo70072gtfyda7hhfca"},{"post_id":"cica18yo5006xgtfytj665w58","tag_id":"cica18yo60070gtfyvlt3o07z","_id":"cica18yo70073gtfy8cltjb3v"},{"post_id":"cica18yo5006xgtfytj665w58","tag_id":"cica18yo70071gtfy4j8xvkds","_id":"cica18yo70074gtfyq14s1ybs"},{"post_id":"cica18yo80075gtfyp6864958","tag_id":"cica18yoa0077gtfydn41jyie","_id":"cica18yoc007cgtfy9l3bqlb5"},{"post_id":"cica18yo80075gtfyp6864958","tag_id":"cica18yoa0078gtfym21jro9u","_id":"cica18yoc007dgtfynox6vmto"},{"post_id":"cica18yo80075gtfyp6864958","tag_id":"cica18yob0079gtfy1cupwqee","_id":"cica18yoc007egtfyt98reisj"},{"post_id":"cica18yo80075gtfyp6864958","tag_id":"cica18yob007agtfyuf71spah","_id":"cica18yod007fgtfy7paus3kq"},{"post_id":"cica18yo80075gtfyp6864958","tag_id":"cica18yoc007bgtfy26pgxvuv","_id":"cica18yod007ggtfyqi3pcprt"},{"post_id":"cica18yo80075gtfyp6864958","tag_id":"cica18ynk005tgtfyh8yq4m4d","_id":"cica18yod007hgtfyf42m3m08"},{"post_id":"cica18yoe007igtfy3s5uqac3","tag_id":"cica18yof007jgtfyv68z6f74","_id":"cica18yog007kgtfyyyk9ygqu"},{"post_id":"cica18yoi007lgtfyyhoic5si","tag_id":"cica18yof007jgtfyv68z6f74","_id":"cica18yok007mgtfyvazxzis8"},{"post_id":"cica18yom007ngtfydxe2kpb5","tag_id":"cica18yon007pgtfyn8bfhimq","_id":"cica18yop007tgtfyrgrn4z6o"},{"post_id":"cica18yom007ngtfydxe2kpb5","tag_id":"cica18yoo007qgtfyldimq9bt","_id":"cica18yoq007ugtfymvt4a68p"},{"post_id":"cica18yom007ngtfydxe2kpb5","tag_id":"cica18yop007sgtfy24kxszcy","_id":"cica18yoq007vgtfyzti0cg2n"},{"post_id":"cica18yov007wgtfyv9a10d2f","tag_id":"cica18ynk005tgtfyh8yq4m4d","_id":"cica18yoy007ygtfyx2y0snwe"},{"post_id":"cica18yp1007zgtfykaibz3ri","tag_id":"cica18yld002hgtfyshjqshvd","_id":"cica18yp60084gtfyiular1gj"},{"post_id":"cica18yp1007zgtfykaibz3ri","tag_id":"cica18yp20081gtfy8eszfck6","_id":"cica18yp60085gtfy905roua4"},{"post_id":"cica18yp1007zgtfykaibz3ri","tag_id":"cica18yp40082gtfyokedog8q","_id":"cica18yp60086gtfyrh2ekfbi"},{"post_id":"cica18yp1007zgtfykaibz3ri","tag_id":"cica18yp50083gtfy742xogkd","_id":"cica18yp60087gtfypx8zevty"},{"post_id":"cica18yp70088gtfyxl9dwxvd","tag_id":"cica18ylv003fgtfyobyns15h","_id":"cica18yp9008agtfy3mft567k"},{"post_id":"cica18ypc008bgtfyflrfl7ng","tag_id":"cica18ypd008dgtfyh87pknic","_id":"cica18ypf008hgtfyem3mmtrt"},{"post_id":"cica18ypc008bgtfyflrfl7ng","tag_id":"cica18ype008egtfy2no3twwk","_id":"cica18ypf008igtfymzc21uq3"},{"post_id":"cica18ypc008bgtfyflrfl7ng","tag_id":"cica18ype008fgtfynhd2e69l","_id":"cica18ypf008jgtfyxgv3wy4k"},{"post_id":"cica18ypc008bgtfyflrfl7ng","tag_id":"cica18ype008ggtfyo96caqfg","_id":"cica18ypf008kgtfyu28e63g9"},{"post_id":"cica18ypc008bgtfyflrfl7ng","tag_id":"cica18ylp0030gtfy4wkqp7bn","_id":"cica18ypf008lgtfyca40fli3"},{"post_id":"cica18ypc008bgtfyflrfl7ng","tag_id":"cica18ynm005zgtfyesagtz7u","_id":"cica18ypf008mgtfy0pe2uny4"},{"post_id":"cica18ypc008bgtfyflrfl7ng","tag_id":"cica18ylv003fgtfyobyns15h","_id":"cica18ypf008ngtfy2ge7auhh"},{"post_id":"cica18ypi008ogtfyoak2sfws","tag_id":"cica18ypk008qgtfyfk84t9yh","_id":"cica18ypn008sgtfyyjrdjlgo"},{"post_id":"cica18ypi008ogtfyoak2sfws","tag_id":"cica18ylp0030gtfy4wkqp7bn","_id":"cica18ypp008tgtfyr152slyy"},{"post_id":"cica18ypi008ogtfyoak2sfws","tag_id":"cica18ypn008rgtfybe9tpfhj","_id":"cica18ypp008ugtfy6wx2rzjl"},{"post_id":"cica18ypq008vgtfyullwdm9m","tag_id":"cica18ypt008xgtfydtmxc4hc","_id":"cica18ypv0090gtfy97hmuof3"},{"post_id":"cica18ypq008vgtfyullwdm9m","tag_id":"cica18ypu008ygtfy10oub8jq","_id":"cica18ypv0091gtfytq9zgogu"},{"post_id":"cica18ypq008vgtfyullwdm9m","tag_id":"cica18ypv008zgtfywo22qp13","_id":"cica18ypw0092gtfyfraagxec"},{"post_id":"cica18ypx0093gtfycvttnytb","tag_id":"cica18ypz0094gtfy6n2qvxs8","_id":"cica18ypz0095gtfyfei2gusb"},{"post_id":"cica18yq00096gtfy9rygcwt3","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yq3009agtfyb3te7aij"},{"post_id":"cica18yq00096gtfy9rygcwt3","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yq4009bgtfy6z7yyeth"},{"post_id":"cica18yq00096gtfy9rygcwt3","tag_id":"cica18yq20098gtfy006on0yp","_id":"cica18yq4009cgtfyp1b97yqh"},{"post_id":"cica18yq00096gtfy9rygcwt3","tag_id":"cica18yq30099gtfyqktlshxi","_id":"cica18yq4009dgtfyuzt151c2"},{"post_id":"cica18yq5009egtfyrxn02gmq","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yq7009ggtfyj5j775ak"},{"post_id":"cica18yq5009egtfyrxn02gmq","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yq7009hgtfyna3jlyug"},{"post_id":"cica18yq5009egtfyrxn02gmq","tag_id":"cica18ykq001lgtfy78dh3321","_id":"cica18yq7009igtfymhzsil53"},{"post_id":"cica18yq5009egtfyrxn02gmq","tag_id":"cica18ykq001kgtfy48l2bq83","_id":"cica18yq7009jgtfyqj3nhzfo"},{"post_id":"cica18yq5009egtfyrxn02gmq","tag_id":"cica18yq20098gtfy006on0yp","_id":"cica18yq7009kgtfymazys58z"},{"post_id":"cica18yq9009lgtfy9qk1ndw0","tag_id":"cica18yqb009ngtfy04uyeooc","_id":"cica18yqd009rgtfycha0tf81"},{"post_id":"cica18yq9009lgtfy9qk1ndw0","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yqe009sgtfygjyiv33k"},{"post_id":"cica18yq9009lgtfy9qk1ndw0","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yqe009tgtfyrpy1t2ps"},{"post_id":"cica18yq9009lgtfy9qk1ndw0","tag_id":"cica18yqb009ogtfy2szlsdop","_id":"cica18yqe009ugtfyd04zjkan"},{"post_id":"cica18yq9009lgtfy9qk1ndw0","tag_id":"cica18yqc009pgtfy6dp7rbhm","_id":"cica18yqe009vgtfy4svsmo0o"},{"post_id":"cica18yq9009lgtfy9qk1ndw0","tag_id":"cica18yqd009qgtfyimcss65w","_id":"cica18yqe009wgtfyfac1kbnj"},{"post_id":"cica18yqf009xgtfy1k3w6i66","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yqh00a0gtfyvditq59w"},{"post_id":"cica18yqf009xgtfy1k3w6i66","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yqi00a1gtfyp85xmouv"},{"post_id":"cica18yqf009xgtfy1k3w6i66","tag_id":"cica18ym6003rgtfy9ushdnip","_id":"cica18yqi00a2gtfyakanyi4q"},{"post_id":"cica18yqf009xgtfy1k3w6i66","tag_id":"cica18ylp0030gtfy4wkqp7bn","_id":"cica18yqi00a3gtfyabpq1gbj"},{"post_id":"cica18yqf009xgtfy1k3w6i66","tag_id":"cica18yqh009zgtfylhquimsm","_id":"cica18yqi00a4gtfykhidgujk"},{"post_id":"cica18yqf009xgtfy1k3w6i66","tag_id":"cica18ynm0060gtfyd9qcs2v2","_id":"cica18yqi00a5gtfyyqplcf60"},{"post_id":"cica18yqj00a6gtfy1846vfxj","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yqn00aagtfy102hfg9x"},{"post_id":"cica18yqj00a6gtfy1846vfxj","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yqn00abgtfy1kw8anhl"},{"post_id":"cica18yqj00a6gtfy1846vfxj","tag_id":"cica18ym6003rgtfy9ushdnip","_id":"cica18yqn00acgtfyypurb2og"},{"post_id":"cica18yqj00a6gtfy1846vfxj","tag_id":"cica18yl00023gtfyqe11shlo","_id":"cica18yqn00adgtfycvo1e17x"},{"post_id":"cica18yqj00a6gtfy1846vfxj","tag_id":"cica18yql00a8gtfyaemv8fz8","_id":"cica18yqn00aegtfy7nobwvia"},{"post_id":"cica18yqj00a6gtfy1846vfxj","tag_id":"cica18yqm00a9gtfyvr4ph7q0","_id":"cica18yqn00afgtfytw794l8i"},{"post_id":"cica18yqo00aggtfysz1yll54","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yqt00algtfys5web1gs"},{"post_id":"cica18yqo00aggtfysz1yll54","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yqu00amgtfyar6jwczb"},{"post_id":"cica18yqo00aggtfysz1yll54","tag_id":"cica18ym6003rgtfy9ushdnip","_id":"cica18yqu00angtfylgzgx0xl"},{"post_id":"cica18yqo00aggtfysz1yll54","tag_id":"cica18yqs00aigtfy2om33os0","_id":"cica18yqu00aogtfyc2c22b10"},{"post_id":"cica18yqo00aggtfysz1yll54","tag_id":"cica18yqs00ajgtfy1l7ddxr3","_id":"cica18yqu00apgtfylgegbil9"},{"post_id":"cica18yqo00aggtfysz1yll54","tag_id":"cica18yqt00akgtfybx3r105u","_id":"cica18yqu00aqgtfyfgj2r02c"},{"post_id":"cica18yqv00argtfypf8mgesa","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yqy00augtfyy5z70d9m"},{"post_id":"cica18yqv00argtfypf8mgesa","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yqy00avgtfy2ragp5ds"},{"post_id":"cica18yqv00argtfypf8mgesa","tag_id":"cica18yqx00atgtfyaejp0ebk","_id":"cica18yqy00awgtfyew9yc8nn"},{"post_id":"cica18yqz00axgtfy5avtaw7h","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yr200b2gtfyui79zybm"},{"post_id":"cica18yqz00axgtfy5avtaw7h","tag_id":"cica18yr100azgtfy2qjsfjxp","_id":"cica18yr200b3gtfyjaylpfch"},{"post_id":"cica18yqz00axgtfy5avtaw7h","tag_id":"cica18yr100b0gtfyn14sd92z","_id":"cica18yr200b4gtfy2hnq3sof"},{"post_id":"cica18yqz00axgtfy5avtaw7h","tag_id":"cica18yr200b1gtfysxr59ima","_id":"cica18yr200b5gtfyyyc1vbgj"},{"post_id":"cica18yr300b6gtfyus3puwdg","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yr500b8gtfyhyo4rbqe"},{"post_id":"cica18yr300b6gtfyus3puwdg","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yr600b9gtfy8c8cbcq4"},{"post_id":"cica18yr700bagtfysnl7xmpk","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yra00begtfyzqhn0vow"},{"post_id":"cica18yr700bagtfysnl7xmpk","tag_id":"cica18yr900bcgtfysm7si972","_id":"cica18yrb00bfgtfyyak3p8mx"},{"post_id":"cica18yr700bagtfysnl7xmpk","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yrb00bggtfydv5hzkw4"},{"post_id":"cica18yr700bagtfysnl7xmpk","tag_id":"cica18yra00bdgtfydhnkhwun","_id":"cica18yrb00bhgtfy33edw1vn"},{"post_id":"cica18yrc00bigtfy47k1vik2","tag_id":"cica18ykg0010gtfyb0bz5q5f","_id":"cica18yrh00bmgtfytq69vc9u"},{"post_id":"cica18yrc00bigtfy47k1vik2","tag_id":"cica18ykh0011gtfyjmgvqwyz","_id":"cica18yrh00bngtfy8v840mia"},{"post_id":"cica18yrc00bigtfy47k1vik2","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yrh00bogtfydbti3vxk"},{"post_id":"cica18yrc00bigtfy47k1vik2","tag_id":"cica18yrf00bkgtfyundu1k0j","_id":"cica18yrh00bpgtfy26tg55jf"},{"post_id":"cica18yrc00bigtfy47k1vik2","tag_id":"cica18ymr004ogtfyfwr8kuic","_id":"cica18yri00bqgtfyxx9vd4hh"},{"post_id":"cica18yrc00bigtfy47k1vik2","tag_id":"cica18yrg00blgtfyv71k516s","_id":"cica18yri00brgtfyx77yxpo8"},{"post_id":"cica18yrj00bsgtfy8g1o6ehh","tag_id":"cica18ymc003ygtfynr7z9hwp","_id":"cica18yrl00bugtfypo1ooron"},{"post_id":"cica18yrj00bsgtfy8g1o6ehh","tag_id":"cica18yqm00a9gtfyvr4ph7q0","_id":"cica18yrm00bvgtfyd6qbmxvh"},{"post_id":"cica18yrn00bwgtfycdnbh19f","tag_id":"cica18yrp00bygtfy73gnyffg","_id":"cica18yrq00c1gtfy0eov55w4"},{"post_id":"cica18yrn00bwgtfycdnbh19f","tag_id":"cica18yrp00bzgtfyc8iwchgd","_id":"cica18yrq00c2gtfyy3swdjym"},{"post_id":"cica18yrn00bwgtfycdnbh19f","tag_id":"cica18yrq00c0gtfyxa4px2ja","_id":"cica18yrq00c3gtfy8qk32s1j"},{"post_id":"cica18yrr00c4gtfycwwzw3ch","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"cica18yry00c9gtfy1nuz0tmn"},{"post_id":"cica18yrr00c4gtfycwwzw3ch","tag_id":"cica18yrw00c7gtfykc4kmb15","_id":"cica18yry00cagtfyovjstn2u"},{"post_id":"cica18yrr00c4gtfycwwzw3ch","tag_id":"cica18yrx00c8gtfycvkj2z63","_id":"cica18yry00cbgtfy8ylwola6"},{"post_id":"cica18ys000ccgtfywbspz2iw","tag_id":"cica18ys100cegtfytu1afg3m","_id":"cica18ys300chgtfy9j3bjgli"},{"post_id":"cica18ys000ccgtfywbspz2iw","tag_id":"cica18ys200cfgtfyra43cjtt","_id":"cica18ys300cigtfyyshtqkrn"},{"post_id":"cica18ys000ccgtfywbspz2iw","tag_id":"cica18ys200cggtfyhztht4f0","_id":"cica18ys300cjgtfy1nz7llb3"},{"post_id":"cica18ys500ckgtfygod7zati","tag_id":"cica18yqx00atgtfyaejp0ebk","_id":"cica18ysh00cqgtfyixw9kgr0"},{"post_id":"cica18ys500ckgtfygod7zati","tag_id":"cica18ys800cmgtfye9qulxc5","_id":"cica18ysi00crgtfyq9803ofj"},{"post_id":"cica18ys500ckgtfygod7zati","tag_id":"cica18ysf00cngtfyd4iydxhl","_id":"cica18ysi00csgtfy7hf3g1t5"},{"post_id":"cica18ys500ckgtfygod7zati","tag_id":"cica18ysg00cogtfysn9thqvw","_id":"cica18ysi00ctgtfyqec5a78u"},{"post_id":"cica18ys500ckgtfygod7zati","tag_id":"cica18ysg00cpgtfy6mk3l847","_id":"cica18ysi00cugtfyyok96i17"},{"post_id":"cica18ysj00cvgtfyvbnb56pk","tag_id":"cica18ysl00cxgtfye6a1nbii","_id":"cica18ysn00d1gtfyqqplrcce"},{"post_id":"cica18ysj00cvgtfyvbnb56pk","tag_id":"cica18ysm00cygtfyqmzngq0q","_id":"cica18yso00d2gtfyxydu5f4t"},{"post_id":"cica18ysj00cvgtfyvbnb56pk","tag_id":"cica18ysn00d0gtfy8x847bqv","_id":"cica18yso00d3gtfyf1nh0zdy"},{"post_id":"cica18ysj00cvgtfyvbnb56pk","tag_id":"cica18ys200cggtfyhztht4f0","_id":"cica18yso00d4gtfyxkeitg1j"},{"post_id":"cica18ysp00d5gtfyc0kcxx35","tag_id":"cica18ysr00d7gtfyvdbkyfe2","_id":"cica18yst00dagtfytv1svpkb"},{"post_id":"cica18ysp00d5gtfyc0kcxx35","tag_id":"cica18yss00d8gtfyyxh5u7a2","_id":"cica18yst00dbgtfym7mphkjr"},{"post_id":"cica18ysp00d5gtfyc0kcxx35","tag_id":"cica18yss00d9gtfya91vn7hj","_id":"cica18yst00dcgtfymqsmk4b0"},{"post_id":"cica18ysp00d5gtfyc0kcxx35","tag_id":"cica18ykq001kgtfy48l2bq83","_id":"cica18ysu00ddgtfydmmvrx76"},{"post_id":"cica18ysv00degtfypzo7rlti","tag_id":"cica18ysx00dggtfyuopdp1zh","_id":"cica18ysz00dkgtfy6ohz098u"},{"post_id":"cica18ysv00degtfypzo7rlti","tag_id":"cica18ynk005tgtfyh8yq4m4d","_id":"cica18ysz00dlgtfy9g6ybvk6"},{"post_id":"cica18ysv00degtfypzo7rlti","tag_id":"cica18ysy00dhgtfyo7fiugc6","_id":"cica18ysz00dmgtfy8tdennp5"},{"post_id":"cica18ysv00degtfypzo7rlti","tag_id":"cica18ysy00digtfywibsb643","_id":"cica18ysz00dngtfygcbg6xxs"},{"post_id":"cica18ysv00degtfypzo7rlti","tag_id":"cica18ysy00djgtfyutdvtq9a","_id":"cica18ysz00dogtfywhjvz3wi"},{"post_id":"cica18yt000dpgtfyfweottii","tag_id":"cica18ylm002vgtfy98owonew","_id":"cica18yt400dvgtfys4evknkw"},{"post_id":"cica18yt000dpgtfyfweottii","tag_id":"cica18yt200drgtfyo804vizs","_id":"cica18yt400dwgtfy9uftiprx"},{"post_id":"cica18yt000dpgtfyfweottii","tag_id":"cica18yt200dsgtfy04wre4p9","_id":"cica18yt400dxgtfyvtbwi9br"},{"post_id":"cica18yt000dpgtfyfweottii","tag_id":"cica18yt300dtgtfy6qdkdhg2","_id":"cica18yt400dygtfy2lvspuuy"},{"post_id":"cica18yt000dpgtfyfweottii","tag_id":"cica18yt300dugtfymbmgo3gk","_id":"cica18yt400dzgtfyjcxcidku"},{"post_id":"cica18yt500e0gtfyx8chvbni","tag_id":"cica18yss00d8gtfyyxh5u7a2","_id":"cica18yt800e3gtfyn3to6ycz"},{"post_id":"cica18yt500e0gtfyx8chvbni","tag_id":"cica18ykq001kgtfy48l2bq83","_id":"cica18yt900e4gtfy379m1ex1"},{"post_id":"cica18yt500e0gtfyx8chvbni","tag_id":"cica18yt700e2gtfy5rbe3afn","_id":"cica18yt900e5gtfyptr2wx0s"},{"post_id":"cica18yt500e0gtfyx8chvbni","tag_id":"cica18yki0014gtfyr1qwaxf1","_id":"cica18yt900e6gtfyfuypggjy"},{"post_id":"cica18yt500e0gtfyx8chvbni","tag_id":"cica18ykq001jgtfysqh9psj7","_id":"cica18yt900e7gtfystsf8ub3"},{"post_id":"cica18yta00e8gtfy66x1yycu","tag_id":"cica18ytc00eagtfyj3nus2gz","_id":"cica18ytf00efgtfyachy1l9c"},{"post_id":"cica18yta00e8gtfy66x1yycu","tag_id":"cica18ypk008qgtfyfk84t9yh","_id":"cica18ytf00eggtfy9wnplm91"},{"post_id":"cica18yta00e8gtfy66x1yycu","tag_id":"cica18yqx00atgtfyaejp0ebk","_id":"cica18ytf00ehgtfyws60tf86"},{"post_id":"cica18yta00e8gtfy66x1yycu","tag_id":"cica18ytd00ebgtfy7klpiww9","_id":"cica18ytf00eigtfym7qn55pz"},{"post_id":"cica18yta00e8gtfy66x1yycu","tag_id":"cica18ytd00ecgtfy8qk049td","_id":"cica18ytg00ejgtfyluhn55ty"},{"post_id":"cica18yta00e8gtfy66x1yycu","tag_id":"cica18yte00edgtfyrcg35vml","_id":"cica18ytg00ekgtfy9yxwoy07"},{"post_id":"cica18yta00e8gtfy66x1yycu","tag_id":"cica18yte00eegtfywlz7f8vz","_id":"cica18ytg00elgtfyguzveumv"},{"post_id":"cid38pv5k00002hws2w7a57bd","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"cid38pv7d00032hws0e2yn6dh"},{"post_id":"cid38pv5k00002hws2w7a57bd","tag_id":"cid38pv6i00022hws586kfnff","_id":"cid38pv7d00042hws505y9j6m"},{"post_id":"cidr1e0y5000010ws91jer8b0","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"cidr1e0z5000410wsnr11j2ck"},{"post_id":"cidr1e0y5000010ws91jer8b0","tag_id":"cidr1e0yg000210ws3c8e6zpx","_id":"cidr1e0z6000510wsbn4cjgct"},{"post_id":"cidr1e0y5000010ws91jer8b0","tag_id":"cidr1e0z4000310wsw91n2xfw","_id":"cidr1e0z6000610wsmxfd9aq7"},{"post_id":"ciee5jad80000tcwslvz63sl2","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"ciee5jaen0005tcwsaaq97a7y"},{"post_id":"ciee5jad80000tcwslvz63sl2","tag_id":"ciee5jadm0002tcwsic8gxklo","_id":"ciee5jaeo0006tcws06s6ewrl"},{"post_id":"ciee5jad80000tcwslvz63sl2","tag_id":"ciee5jaek0003tcwsqntp95uw","_id":"ciee5jaeo0007tcws48015lot"},{"post_id":"ciee5jad80000tcwslvz63sl2","tag_id":"ciee5jaem0004tcwszkx1btk8","_id":"ciee5jaeo0008tcwsh7xuw4hd"},{"post_id":"cifi95baw0000rjws930lqbed","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"cifi95bc50004rjwso49s9jnm"},{"post_id":"cifi95baw0000rjws930lqbed","tag_id":"cifi95bb70002rjwssyk5swnm","_id":"cifi95bc60005rjwsb4beazil"},{"post_id":"cifi95baw0000rjws930lqbed","tag_id":"cifi95bbz0003rjwsrscwt28p","_id":"cifi95bc60006rjwsk9vvwyxp"},{"post_id":"cifi95baw0000rjws930lqbed","tag_id":"ciee5jaem0004tcwszkx1btk8","_id":"cifi95bc60007rjws5xdkrj33"},{"post_id":"cifjtuyg20000oews2deyibih","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"cifjtuyhw0008oewsc2fvfh89"},{"post_id":"cifjtuyg20000oews2deyibih","tag_id":"cifjtuygo0002oewsrmlo8bxg","_id":"cifjtuyhx0009oewsih1oyrzf"},{"post_id":"cifjtuyg20000oews2deyibih","tag_id":"cifjtuyhp0003oewsuu25a7uh","_id":"cifjtuyhx000aoewshblvp84m"},{"post_id":"cifjtuyg20000oews2deyibih","tag_id":"cifjtuyhr0004oewsn34vhkgo","_id":"cifjtuyhy000boewsa6xahr4b"},{"post_id":"cifjtuyg20000oews2deyibih","tag_id":"cifjtuyhs0005oewsiu5kkagg","_id":"cifjtuyhy000coews3w8i9zkl"},{"post_id":"cifjtuyg20000oews2deyibih","tag_id":"cifjtuyht0006oews291srzdy","_id":"cifjtuyhy000doewslso8j1kr"},{"post_id":"cifjtuyg20000oews2deyibih","tag_id":"cifjtuyht0007oewskzyjtdpx","_id":"cifjtuyhy000eoewsfmn2yqjj"},{"post_id":"cifqxchx70000hkws8msk5nxp","tag_id":"cifqxchxh0002hkwspybhe1gv","_id":"cifqxchye0003hkwsxsj1ikb5"},{"post_id":"cig4tt4vc0000suws6k37qbcu","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"cig4tt4xf0005suwsulec9hzh"},{"post_id":"cig4tt4vc0000suws6k37qbcu","tag_id":"cidr1e0yg000210ws3c8e6zpx","_id":"cig4tt4xg0006suwsxrg75860"},{"post_id":"cig4tt4vc0000suws6k37qbcu","tag_id":"cig4tt4vt0002suwsyl8tddch","_id":"cig4tt4xg0007suws9qihwx4m"},{"post_id":"cig4tt4vc0000suws6k37qbcu","tag_id":"cig4tt4xc0003suwsu99d008a","_id":"cig4tt4xg0008suwspk891l6o"},{"post_id":"cig4tt4vc0000suws6k37qbcu","tag_id":"cig4tt4xd0004suwsaun3lvgn","_id":"cig4tt4xg0009suws9zyf5wn0"},{"post_id":"cih0be1hd0000ikws2w1avnip","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"cih0be1hn0002ikwsm7ckgm6f"},{"post_id":"cihdildua0000nxwsojoyv4lp","tag_id":"cihdilduj0002nxwszs1xko5t","_id":"cihdildwb0005nxwsu4ti8sca"},{"post_id":"cihdildua0000nxwsojoyv4lp","tag_id":"cihdildw60003nxwsvxwbbqln","_id":"cihdildwb0006nxwszgxsusji"},{"post_id":"cihdildua0000nxwsojoyv4lp","tag_id":"cihdildw80004nxwsh040r5hp","_id":"cihdildwb0007nxws66iru8vp"},{"post_id":"ciheqt5z50000pcwsp9aj90wr","tag_id":"ciheqt5zf0002pcwsxvqxf2o6","_id":"ciheqt60p0003pcwsps6dolas"},{"post_id":"ciheqt5z50000pcwsp9aj90wr","tag_id":"cihdildw60003nxwsvxwbbqln","_id":"ciheqt60q0004pcwsbab4pxvs"},{"post_id":"ciheqt5z50000pcwsp9aj90wr","tag_id":"cihdildw80004nxwsh040r5hp","_id":"ciheqt60r0005pcws5ut6xn1w"},{"post_id":"cihp0xupj0000mzfyi5dmkm9f","tag_id":"cihp0xupt0002mzfyh9tck7h8","_id":"cihp0xuqu0005mzfyqadu4wqt"},{"post_id":"cihp0xupj0000mzfyi5dmkm9f","tag_id":"cihp0xuqs0003mzfytmp0wqy0","_id":"cihp0xuqv0006mzfywucfo5jg"},{"post_id":"cihp0xupj0000mzfyi5dmkm9f","tag_id":"cica18ysl00cxgtfye6a1nbii","_id":"cihp0xuqv0007mzfy3lnwueyk"},{"post_id":"cihqgv1xn0000kywsei8jfi6v","tag_id":"cihqgv1xz0002kywsz2b6crfh","_id":"cihqgv1zg0004kywssly7ssxl"},{"post_id":"cihqgv1xn0000kywsei8jfi6v","tag_id":"cihp0xuqs0003mzfytmp0wqy0","_id":"cihqgv1zh0005kywsx9yr70ww"},{"post_id":"cihqgv1xn0000kywsei8jfi6v","tag_id":"cihqgv1zf0003kywsrfotris6","_id":"cihqgv1zi0006kywspnaco1ni"},{"post_id":"ciift0f210000p8ws023qajnr","tag_id":"cihp0xupt0002mzfyh9tck7h8","_id":"ciift0f2f0002p8ws6mhtzb67"},{"post_id":"ciift0f210000p8ws023qajnr","tag_id":"cihp0xuqs0003mzfytmp0wqy0","_id":"ciift0f2h0003p8wsi6fsokk0"},{"post_id":"ciift0f500004p8ws2qncgs7u","tag_id":"cihp0xupt0002mzfyh9tck7h8","_id":"ciift0f560006p8wshfxbq19s"},{"post_id":"ciift0f500004p8ws2qncgs7u","tag_id":"cihp0xuqs0003mzfytmp0wqy0","_id":"ciift0f570007p8ws95vhepay"},{"post_id":"ciig1awvm0000h5wsmihag50z","tag_id":"cihp0xupt0002mzfyh9tck7h8","_id":"ciig1awxj0003h5wseqp6496z"},{"post_id":"ciig1awvm0000h5wsmihag50z","tag_id":"cihp0xuqs0003mzfytmp0wqy0","_id":"ciig1awxk0004h5ws5sktoi36"},{"post_id":"ciig1awvm0000h5wsmihag50z","tag_id":"cica18ymk004agtfyavrkpwio","_id":"ciig1awxk0005h5wslb77b7am"},{"post_id":"ciig1awvm0000h5wsmihag50z","tag_id":"ciig1aww10002h5ws3oafdvvt","_id":"ciig1awxl0006h5wslp76zp5x"},{"post_id":"ciiznmhdp0000wfwsnfmrj6w4","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"ciiznmhg20003wfwshd78w32p"},{"post_id":"ciiznmhdp0000wfwsnfmrj6w4","tag_id":"ciiznmhe40002wfwsj39rd2xe","_id":"ciiznmhg30004wfwsdq1ygtr5"},{"post_id":"ciiznmhdp0000wfwsnfmrj6w4","tag_id":"cica18ykg0010gtfyb0bz5q5f","_id":"ciiznmhg30005wfws6jy0jc76"},{"post_id":"ciizs3p5d000034wspgrg1xcc","tag_id":"cica18yrt00c6gtfy7w9i0dqm","_id":"ciizs3p6m000334wsrnhpand9"},{"post_id":"ciizs3p5d000034wspgrg1xcc","tag_id":"ciiznmhe40002wfwsj39rd2xe","_id":"ciizs3p6m000434wslxunhkq2"},{"post_id":"ciizs3p5d000034wspgrg1xcc","tag_id":"ciizs3p5m000234ws09bouied","_id":"ciizs3p6m000534wsi3xllv0x"},{"post_id":"cil3q63ep00007nwsqb322qzk","tag_id":"cica18ysl00cxgtfye6a1nbii","_id":"cil3q63gh00037nwsdastz8uy"},{"post_id":"cil3q63ep00007nwsqb322qzk","tag_id":"cil3q63ey00027nws9wi9j5kh","_id":"cil3q63gi00047nwsd85nif1c"},{"post_id":"cildphkgb0000hzfy20vqtspy","tag_id":"cica18ylm002vgtfy98owonew","_id":"cildphkht0003hzfy1miy9l70"},{"post_id":"cildphkgb0000hzfy20vqtspy","tag_id":"cildphkgs0002hzfyzcjspxn1","_id":"cildphkht0004hzfy5tgm3nob"},{"post_id":"cildphkgb0000hzfy20vqtspy","tag_id":"cica18yki0014gtfyr1qwaxf1","_id":"cildphkht0005hzfyrlhmaxu6"},{"post_id":"cilp4udgz0000l1fy385hxp51","tag_id":"cilp4udh90002l1fyjjo3piu3","_id":"cilp4udi70003l1fyv1uhob6z"},{"post_id":"cilp4udgz0000l1fy385hxp51","tag_id":"cica18ys200cggtfyhztht4f0","_id":"cilp4udi90005l1fyqhnkcgo7"},{"post_id":"cilp4udgz0000l1fy385hxp51","tag_id":"cica18ymw0052gtfy9nqyv632","_id":"cilp4udi90006l1fy17faz3c5"},{"post_id":"cilp4udnq0008l1fy0ug8esl7","tag_id":"cilp4udh90002l1fyjjo3piu3","_id":"cilp4udnv000bl1fy8am8ii1g"},{"post_id":"cilp4udnq0008l1fy0ug8esl7","tag_id":"cilp4udnt000al1fy5we7ye31","_id":"cilp4udnv000cl1fyyw15uuiy"},{"post_id":"cilp4udnq0008l1fy0ug8esl7","tag_id":"cica18ymw0052gtfy9nqyv632","_id":"cilp4udnv000dl1fyycck7lah"},{"post_id":"cima1so5c0000vofym5ugnxte","tag_id":"cica18ylm002vgtfy98owonew","_id":"cima1so6y0005vofyg27ewbqh"},{"post_id":"cima1so5c0000vofym5ugnxte","tag_id":"cima1so5o0002vofymvy0sgen","_id":"cima1so6z0006vofyve5kukup"},{"post_id":"cima1so5c0000vofym5ugnxte","tag_id":"cima1so6v0003vofyqcybxk6p","_id":"cima1so6z0007vofy4c2qg5sf"},{"post_id":"cima1so9h0009vofy03l20gsf","tag_id":"cima1so9k000bvofyb1pywipm","_id":"cima1so9p000gvofyi08e71ow"},{"post_id":"cima1so9h0009vofy03l20gsf","tag_id":"cima1so9l000cvofyy6rad63p","_id":"cima1so9q000hvofybpieviqj"},{"post_id":"cima1so9h0009vofy03l20gsf","tag_id":"cima1so9m000dvofyw3byxbn3","_id":"cima1so9q000ivofyiob6cwhj"},{"post_id":"cima1so9h0009vofy03l20gsf","tag_id":"cima1so9n000evofyls9gsxjy","_id":"cima1so9q000jvofy2e96vnmp"},{"post_id":"cima1so9h0009vofy03l20gsf","tag_id":"cima1so9o000fvofy8z4xm6cb","_id":"cima1so9q000kvofyeg01ezh1"},{"post_id":"cimjc5pz600001nfy66rl525r","tag_id":"cimjc5pzh00021nfyztxcea1p","_id":"cimjc5q1i00051nfyxqtzs2q1"},{"post_id":"cimjc5pz600001nfy66rl525r","tag_id":"cimjc5q1g00031nfymz6nxnmn","_id":"cimjc5q1j00061nfyfnon4bm8"},{"post_id":"cimjc5q4100091nfyjdukfzip","tag_id":"cimjc5q44000b1nfyig4ban8g","_id":"cimjc5q46000d1nfyutb5us49"},{"post_id":"cimjc5q4100091nfyjdukfzip","tag_id":"cica18ypt008xgtfydtmxc4hc","_id":"cimjc5q47000e1nfycwuh401o"},{"post_id":"cimjc5q4100091nfyjdukfzip","tag_id":"cimjc5q45000c1nfym2u6tfct","_id":"cimjc5q47000f1nfy1k826o46"},{"post_id":"cimjc5q49000g1nfygx52686o","tag_id":"cimjc5q4e000i1nfytsj82z2k","_id":"cimjc5q4j000m1nfy1qgux4yq"},{"post_id":"cimjc5q49000g1nfygx52686o","tag_id":"cimjc5q4g000j1nfyped2k5cd","_id":"cimjc5q4j000n1nfydtl8pyok"},{"post_id":"cimjc5q49000g1nfygx52686o","tag_id":"cimjc5q4h000k1nfy67qmtdl3","_id":"cimjc5q4j000o1nfy6py7ytfd"},{"post_id":"cimjc5q49000g1nfygx52686o","tag_id":"cimjc5q4i000l1nfyz2nydn5p","_id":"cimjc5q4k000p1nfyq5s243fk"},{"post_id":"cinbsa3z00000l3fyvwxi6py0","tag_id":"cinbsa3zb0002l3fyakh06t8b","_id":"cinbsa40z0005l3fyd0pln0hx"},{"post_id":"cinbsa3z00000l3fyvwxi6py0","tag_id":"cinbsa40x0003l3fyioay63ro","_id":"cinbsa4100006l3fy2zgy5m8p"},{"post_id":"cinbsa3z00000l3fyvwxi6py0","tag_id":"cinbsa40y0004l3fyi8duf58l","_id":"cinbsa4100007l3fycwva6zdc"},{"post_id":"cinbsa42v0009l3fygae4saau","tag_id":"cinbsa42y000bl3fydcyk6t12","_id":"cinbsa433000el3fy98wnfazi"},{"post_id":"cinbsa42v0009l3fygae4saau","tag_id":"cinbsa430000cl3fysegedf7c","_id":"cinbsa434000fl3fycnuutcdv"},{"post_id":"cinbsa42v0009l3fygae4saau","tag_id":"cinbsa430000dl3fyef5eg38b","_id":"cinbsa434000gl3fyilii9wsq"},{"post_id":"cinbsa436000hl3fys8l9oqip","tag_id":"cinbsa43a000jl3fydlz8ksrj","_id":"cinbsa43f000ll3fydz7en0mf"},{"post_id":"cinbsa436000hl3fys8l9oqip","tag_id":"cinbsa40y0004l3fyi8duf58l","_id":"cinbsa43g000ml3fyqo9h993f"},{"post_id":"cinbsa436000hl3fys8l9oqip","tag_id":"cica18ys200cggtfyhztht4f0","_id":"cinbsa43g000nl3fyzcrkt512"},{"post_id":"cinbsa436000hl3fys8l9oqip","tag_id":"cinbsa43c000kl3fytijf518d","_id":"cinbsa43h000ol3fychjm5pvg"},{"post_id":"cio4dt7s10000safy77rivgxl","tag_id":"cio4dt7sk0002safyxkywayp6","_id":"cio4dt7wj0006safy4pu3utsx"},{"post_id":"cio4dt7s10000safy77rivgxl","tag_id":"cio4dt7wh0003safyanwdwrfo","_id":"cio4dt7wk0007safyjl5hbjny"},{"post_id":"cio4dt7s10000safy77rivgxl","tag_id":"cio4dt7wi0004safy9tmzvgtv","_id":"cio4dt7wk0008safyt8m1ylco"},{"post_id":"cio4dt7s10000safy77rivgxl","tag_id":"cio4dt7wi0005safytg9okzlo","_id":"cio4dt7wk0009safydjq4g6i1"},{"post_id":"cio4dt7zh000asafyn727g1h8","tag_id":"cica18ym6003rgtfy9ushdnip","_id":"cio4dt7zq000csafyqgwjsr7n"},{"post_id":"cio4dt7zh000asafyn727g1h8","tag_id":"cica18ym7003sgtfy8r61pz1t","_id":"cio4dt7zs000dsafyz0w3m3h9"},{"post_id":"cio4dt7zh000asafyn727g1h8","tag_id":"cica18ykg0010gtfyb0bz5q5f","_id":"cio4dt7zs000esafyt2fexhll"},{"post_id":"cio4dt80m000fsafye3xolxye","tag_id":"cio4dt80r000hsafy6z8vcdkk","_id":"cio4dt80v000lsafy54ah2cqs"},{"post_id":"cio4dt80m000fsafye3xolxye","tag_id":"cio4dt80t000isafyovrk0t71","_id":"cio4dt80x000msafywspv3b3u"},{"post_id":"cio4dt80m000fsafye3xolxye","tag_id":"cio4dt80t000jsafy9eojn4d6","_id":"cio4dt80x000nsafyzyp0v8fl"},{"post_id":"cio4dt80m000fsafye3xolxye","tag_id":"cio4dt80u000ksafypb0cxzbu","_id":"cio4dt80x000osafyd9ugv636"},{"post_id":"cio4dt810000psafygfmqvrto","tag_id":"cio4dt813000rsafybbbpkj2m","_id":"cio4dt816000usafy50cdzg2a"},{"post_id":"cio4dt810000psafygfmqvrto","tag_id":"cio4dt815000ssafyzu5sq0fs","_id":"cio4dt819000vsafyg2dab8xc"},{"post_id":"cio4dt810000psafygfmqvrto","tag_id":"cio4dt816000tsafyu8yvqg1x","_id":"cio4dt819000wsafyeawzjzxd"},{"post_id":"ciofuakcf0000s7fyp0xguk4p","tag_id":"cinbsa3zb0002l3fyakh06t8b","_id":"ciofuakeu0006s7fyvehhd2g6"},{"post_id":"ciofuakcf0000s7fyp0xguk4p","tag_id":"ciofuakcw0001s7fys2zv67g6","_id":"ciofuakeu0007s7fy6jxubw0f"},{"post_id":"ciofuakcf0000s7fyp0xguk4p","tag_id":"ciofuakef0003s7fyma4w68ws","_id":"ciofuakev0008s7fyvicf8bfw"},{"post_id":"ciofuakcf0000s7fyp0xguk4p","tag_id":"ciofuakei0004s7fy90a0bg0e","_id":"ciofuakev0009s7fyvwcf8ysd"},{"post_id":"ciofuakcf0000s7fyp0xguk4p","tag_id":"ciofuakem0005s7fy1fj717cf","_id":"ciofuakev000as7fy7o9bne6h"},{"post_id":"ciogy9tna0000s8fyv0z2i3y3","tag_id":"ciogy9tnz0001s8fyfl0bdmt0","_id":"ciogy9tpo0004s8fy6nw4t3hj"},{"post_id":"ciogy9tna0000s8fyv0z2i3y3","tag_id":"cica18ype008egtfy2no3twwk","_id":"ciogy9tpq0005s8fy0ys4cka8"},{"post_id":"ciogy9tna0000s8fyv0z2i3y3","tag_id":"ciogy9tpf0003s8fy00bwu8ed","_id":"ciogy9tpr0006s8fylqxnkfqw"}],"Tag":[{"name":"code review","_id":"cica18yjj0002gtfysrpzak6e"},{"name":"git","_id":"cica18yjm0003gtfybz0o1ps0"},{"name":"gitlab","_id":"cica18yjm0005gtfyuiwm70wv"},{"name":"sonar","_id":"cica18yjn0006gtfy44m2eypo"},{"name":"运维","_id":"cica18yjn0007gtfyh0f5qdx9"},{"name":"springmvc","_id":"cica18yk2000fgtfyqhgyo444"},{"name":"中文乱码","_id":"cica18yk3000ggtfy0ixd0rgx"},{"name":"秒传","_id":"cica18yk7000mgtfy1hfc9mqq"},{"name":"断点续传","_id":"cica18yk9000ngtfywpz2rwez"},{"name":"上传进度","_id":"cica18yka000ogtfyzugmv73l"},{"name":"webuploader","_id":"cica18yka000pgtfy8pghll74"},{"name":"分块","_id":"cica18yka000qgtfy4g9yr7ew"},{"name":"大文件","_id":"cica18ykb000rgtfy2bq4gztd"},{"name":"rest","_id":"cica18ykg0010gtfyb0bz5q5f"},{"name":"dubbox","_id":"cica18ykh0011gtfyjmgvqwyz"},{"name":"xml","_id":"cica18yki0013gtfye7ij27cg"},{"name":"json","_id":"cica18yki0014gtfyr1qwaxf1"},{"name":"缓存","_id":"cica18ykm001bgtfyw1bc372c"},{"name":"爬虫","_id":"cica18ykm001cgtfyg14axvv0"},{"name":"rpc","_id":"cica18ykp001igtfy5bj5kwmt"},{"name":"schema","_id":"cica18ykq001jgtfysqh9psj7"},{"name":"序列化","_id":"cica18ykq001kgtfy48l2bq83"},{"name":"编码","_id":"cica18ykq001lgtfy78dh3321"},{"name":"是什么系列","_id":"cica18ykq001mgtfyngxw1v5n"},{"name":"Servlet","_id":"cica18ykv001vgtfyelalja8u"},{"name":"Tomcat","_id":"cica18ykw001wgtfyi449n7k0"},{"name":"tcp","_id":"cica18ykz0022gtfyhmkmc2jf"},{"name":"分布式","_id":"cica18yl00023gtfyqe11shlo"},{"name":"Logstash","_id":"cica18yld002hgtfyshjqshvd"},{"name":"ElasticSearch","_id":"cica18yle002igtfyhiw8jdc8"},{"name":"Kibana","_id":"cica18yle002kgtfyz8aea4t0"},{"name":"离职","_id":"cica18ylh002qgtfypjyg3ytt"},{"name":"mysql","_id":"cica18ylm002vgtfy98owonew"},{"name":"Atlas","_id":"cica18yln002wgtfy0h0kz9ct"},{"name":"分库分表","_id":"cica18ylo002ygtfykpxpf4c0"},{"name":"读写分离","_id":"cica18ylo002zgtfysbzoakps"},{"name":"负载均衡","_id":"cica18ylp0030gtfy4wkqp7bn"},{"name":"性能","_id":"cica18ylp0031gtfyr6or6r7q"},{"name":"侵入性","_id":"cica18ylq0032gtfy6pfy7npm"},{"name":"jconsole","_id":"cica18ylu003cgtfywg9z3dmw"},{"name":"jprofiler","_id":"cica18ylv003dgtfy0ndzlgdi"},{"name":"内存溢出","_id":"cica18ylv003egtfy10lnznff"},{"name":"jvm","_id":"cica18ylv003fgtfyobyns15h"},{"name":"url","_id":"cica18ym0003mgtfyur0532mt"},{"name":"soa","_id":"cica18ym6003rgtfy9ushdnip"},{"name":"服务","_id":"cica18ym7003sgtfy8r61pz1t"},{"name":"dubbo","_id":"cica18ymc003ygtfynr7z9hwp"},{"name":"队列","_id":"cica18ymc003zgtfyrpdnjypj"},{"name":"打包","_id":"cica18ymk004agtfyavrkpwio"},{"name":"jar","_id":"cica18ymk004bgtfy0tv4835f"},{"name":"idea","_id":"cica18yml004cgtfyun52oywi"},{"name":"maven","_id":"cica18yml004dgtfy6bi8s6r9"},{"name":"MANIFEST.MF","_id":"cica18yml004egtfym6hjaejz"},{"name":"资源","_id":"cica18yml004fgtfy3fuc2pwv"},{"name":"RESTEasy","_id":"cica18ymr004ogtfyfwr8kuic"},{"name":"跨域","_id":"cica18ymr004pgtfyrmcwzd79"},{"name":"JAX-RS","_id":"cica18yms004qgtfyqa3urj06"},{"name":"RAP","_id":"cica18ymv004zgtfy4u0mjx66"},{"name":"RESTful","_id":"cica18ymv0050gtfyl1gbnyh8"},{"name":"mock","_id":"cica18ymw0051gtfyi9we3ibu"},{"name":"api","_id":"cica18ymw0052gtfy9nqyv632"},{"name":"centOS","_id":"cica18ymz0059gtfycuyqkd57"},{"name":"openoffice","_id":"cica18ymz005agtfyxpfpseyh"},{"name":"jodconverter","_id":"cica18yn6005bgtfy9encssgd"},{"name":"pdf","_id":"cica18yn6005cgtfyicoug609"},{"name":"中文","_id":"cica18yn6005dgtfyxeu7l3i3"},{"name":"图形界面","_id":"cica18yn7005egtfyrmw6igbe"},{"name":"迷茫","_id":"cica18ynf005pgtfye4f3excw"},{"name":"redis","_id":"cica18ynk005tgtfyh8yq4m4d"},{"name":"一致性","_id":"cica18ynl005ugtfy954wi1g4"},{"name":"原子性","_id":"cica18ynl005wgtfyov5oeqdq"},{"name":"回滚","_id":"cica18ynm005xgtfy8xt2exed"},{"name":"twemproxy","_id":"cica18ynm005ygtfy3v841a2g"},{"name":"tomcat","_id":"cica18ynm005zgtfyesagtz7u"},{"name":"集群","_id":"cica18ynm0060gtfyd9qcs2v2"},{"name":"pipe","_id":"cica18ynn0061gtfyqp6h66wu"},{"name":"flow","_id":"cica18ynt006dgtfydzf86416"},{"name":"facebook","_id":"cica18ynu006egtfyaw1bg90e"},{"name":"类型检查","_id":"cica18ynv006fgtfy920kjc1v"},{"name":"可伸缩","_id":"cica18yny006lgtfy8zp00ow1"},{"name":"ssh","_id":"cica18yo2006rgtfy6ks5mt13"},{"name":"tmux","_id":"cica18yo3006sgtfyzb5hp0s2"},{"name":"终端","_id":"cica18yo3006tgtfyp75iegf3"},{"name":"rsync","_id":"cica18yo6006zgtfy3fotx9mn"},{"name":"inotify","_id":"cica18yo60070gtfyvlt3o07z"},{"name":"文件同步","_id":"cica18yo70071gtfy4j8xvkds"},{"name":"pattern","_id":"cica18yoa0077gtfydn41jyie"},{"name":"zinterstore","_id":"cica18yoa0078gtfym21jro9u"},{"name":"zscan","_id":"cica18yob0079gtfy1cupwqee"},{"name":"zset","_id":"cica18yob007agtfyuf71spah"},{"name":"zunionstore","_id":"cica18yoc007bgtfy26pgxvuv"},{"name":"rabbitmq","_id":"cica18yof007jgtfyv68z6f74"},{"name":"白屏","_id":"cica18yon007pgtfyn8bfhimq"},{"name":"wdcp","_id":"cica18yoo007qgtfyldimq9bt"},{"name":"磁盘写满","_id":"cica18yop007sgtfy24kxszcy"},{"name":"kafka","_id":"cica18yp20081gtfy8eszfck6"},{"name":"logstash-output-kafka","_id":"cica18yp40082gtfyokedog8q"},{"name":"logstash插件","_id":"cica18yp50083gtfy742xogkd"},{"name":"classpath","_id":"cica18ypd008dgtfyh87pknic"},{"name":"nginx","_id":"cica18ype008egtfy2no3twwk"},{"name":"springMVC","_id":"cica18ype008fgtfynhd2e69l"},{"name":"Idea13","_id":"cica18ype008ggtfyo96caqfg"},{"name":"session","_id":"cica18ypk008qgtfyfk84t9yh"},{"name":"会话亲和性","_id":"cica18ypn008rgtfybe9tpfhj"},{"name":"https","_id":"cica18ypt008xgtfydtmxc4hc"},{"name":"ssl","_id":"cica18ypu008ygtfy10oub8jq"},{"name":"证书","_id":"cica18ypv008zgtfywo22qp13"},{"name":"hello","_id":"cica18ypz0094gtfy6n2qvxs8"},{"name":"netty","_id":"cica18yq20098gtfy006on0yp"},{"name":"nio","_id":"cica18yq30099gtfyqktlshxi"},{"name":"cache","_id":"cica18yqb009ngtfy04uyeooc"},{"name":"threadlocal","_id":"cica18yqb009ogtfy2szlsdop"},{"name":"JCache","_id":"cica18yqc009pgtfy6dp7rbhm"},{"name":"Filter","_id":"cica18yqd009qgtfyimcss65w"},{"name":"路由","_id":"cica18yqh009zgtfylhquimsm"},{"name":"注册中心","_id":"cica18yql00a8gtfyaemv8fz8"},{"name":"zookeeper","_id":"cica18yqm00a9gtfyvr4ph7q0"},{"name":"拦截器","_id":"cica18yqs00aigtfy2om33os0"},{"name":"监听器","_id":"cica18yqs00ajgtfy1l7ddxr3"},{"name":"SPI","_id":"cica18yqt00akgtfybx3r105u"},{"name":"spring","_id":"cica18yqx00atgtfyaejp0ebk"},{"name":"NIO","_id":"cica18yr100azgtfy2qjsfjxp"},{"name":"多线程","_id":"cica18yr100b0gtfyn14sd92z"},{"name":"Netty","_id":"cica18yr200b1gtfysxr59ima"},{"name":"cooma","_id":"cica18yr900bcgtfysm7si972"},{"name":"微内核","_id":"cica18yra00bdgtfydhnkhwun"},{"name":"协议","_id":"cica18yrf00bkgtfyundu1k0j"},{"name":"tomcat-embed","_id":"cica18yrg00blgtfyv71k516s"},{"name":"amd","_id":"cica18yrp00bygtfy73gnyffg"},{"name":"cmd","_id":"cica18yrp00bzgtfyc8iwchgd"},{"name":"RequireJS","_id":"cica18yrq00c0gtfyxa4px2ja"},{"name":"react","_id":"cica18yrt00c6gtfy7w9i0dqm"},{"name":"flux","_id":"cica18yrw00c7gtfykc4kmb15"},{"name":"mvvm","_id":"cica18yrx00c8gtfycvkj2z63"},{"name":"ReactNative","_id":"cica18ys100cegtfytu1afg3m"},{"name":"xcode","_id":"cica18ys200cfgtfyra43cjtt"},{"name":"权限","_id":"cica18ys200cggtfyhztht4f0"},{"name":"ioc","_id":"cica18ys800cmgtfye9qulxc5"},{"name":"filter","_id":"cica18ysf00cngtfyd4iydxhl"},{"name":"servlet","_id":"cica18ysg00cogtfysn9thqvw"},{"name":"DelegatingFilterProxy","_id":"cica18ysg00cpgtfy6mk3l847"},{"name":"mac","_id":"cica18ysl00cxgtfye6a1nbii"},{"name":"apache","_id":"cica18ysm00cygtfyqmzngq0q"},{"name":"vhost","_id":"cica18ysn00d0gtfy8x847bqv"},{"name":"Kafka","_id":"cica18ysr00d7gtfyvdbkyfe2"},{"name":"Avro","_id":"cica18yss00d8gtfyyxh5u7a2"},{"name":"RabbitMQ","_id":"cica18yss00d9gtfya91vn7hj"},{"name":"jedis","_id":"cica18ysx00dggtfyuopdp1zh"},{"name":"连接池","_id":"cica18ysy00dhgtfyo7fiugc6"},{"name":"jmeter","_id":"cica18ysy00digtfywibsb643"},{"name":"ulimit","_id":"cica18ysy00djgtfyutdvtq9a"},{"name":"timeout","_id":"cica18yt200drgtfyo804vizs"},{"name":"超时","_id":"cica18yt200dsgtfy04wre4p9"},{"name":"jdbc","_id":"cica18yt300dtgtfy6qdkdhg2"},{"name":"DriverManagerDataSource","_id":"cica18yt300dugtfymbmgo3gk"},{"name":"RPC","_id":"cica18yt700e2gtfy5rbe3afn"},{"name":"会话","_id":"cica18ytc00eagtfyj3nus2gz"},{"name":"依赖注入","_id":"cica18ytd00ebgtfy7klpiww9"},{"name":"作用域","_id":"cica18ytd00ecgtfy8qk049td"},{"name":"生命周期","_id":"cica18yte00edgtfyrcg35vml"},{"name":"scope","_id":"cica18yte00eegtfywlz7f8vz"},{"name":"ui","_id":"cid38pv6i00022hws586kfnff"},{"name":"react-router","_id":"cidr1e0yg000210ws3c8e6zpx"},{"name":"reflux","_id":"cidr1e0z4000310wsw91n2xfw"},{"name":"dom","_id":"ciee5jadm0002tcwsic8gxklo"},{"name":"shouldComponentUpdate","_id":"ciee5jaek0003tcwsqntp95uw"},{"name":"Immutable-js","_id":"ciee5jaem0004tcwszkx1btk8"},{"name":"Redux","_id":"cifi95bb70002rjwssyk5swnm"},{"name":"单元测试","_id":"cifi95bbz0003rjwsrscwt28p"},{"name":"Redux middleware","_id":"cifjtuygo0002oewsrmlo8bxg"},{"name":"函数式编程","_id":"cifjtuyhp0003oewsuu25a7uh"},{"name":"柯里化","_id":"cifjtuyhr0004oewsn34vhkgo"},{"name":"复合函数","_id":"cifjtuyhs0005oewsiu5kkagg"},{"name":"currying","_id":"cifjtuyht0006oews291srzdy"},{"name":"redux-thunk","_id":"cifjtuyht0007oewskzyjtdpx"},{"name":"webpack","_id":"cifqxchxh0002hkwspybhe1gv"},{"name":"lifecycle","_id":"cig4tt4vt0002suwsyl8tddch"},{"name":"组件生命周期","_id":"cig4tt4xc0003suwsu99d008a"},{"name":"componentDidUpdate","_id":"cig4tt4xd0004suwsaun3lvgn"},{"name":"微信","_id":"cihdilduj0002nxwszs1xko5t"},{"name":"OAuth","_id":"cihdildw60003nxwsvxwbbqln"},{"name":"第三方登录","_id":"cihdildw80004nxwsh040r5hp"},{"name":"QQ","_id":"ciheqt5zf0002pcwsxvqxf2o6"},{"name":"react-native","_id":"cihp0xupt0002mzfyh9tck7h8"},{"name":"android","_id":"cihp0xuqs0003mzfytmp0wqy0"},{"name":"微信浏览器","_id":"cihqgv1xz0002kywsz2b6crfh"},{"name":"附件上传","_id":"cihqgv1zf0003kywsrfotris6"},{"name":"APK","_id":"ciig1aww10002h5ws3oafdvvt"},{"name":"GraphQL","_id":"ciiznmhe40002wfwsj39rd2xe"},{"name":"Relay","_id":"ciizs3p5m000234ws09bouied"},{"name":"ntfs","_id":"cil3q63ey00027nws9wi9j5kh"},{"name":"Mariadb","_id":"cildphkgs0002hzfyzcjspxn1"},{"name":"google","_id":"cilp4udh90002l1fyjjo3piu3"},{"name":"anchor","_id":"cilp4udnt000al1fy5we7ye31"},{"name":"window","_id":"cima1so5o0002vofymvy0sgen"},{"name":"密码","_id":"cima1so6v0003vofyqcybxk6p"},{"name":"atom","_id":"cima1so9k000bvofyb1pywipm"},{"name":"代码排版","_id":"cima1so9l000cvofyy6rad63p"},{"name":"皮肤","_id":"cima1so9m000dvofyw3byxbn3"},{"name":"插件","_id":"cima1so9n000evofyls9gsxjy"},{"name":"快捷键","_id":"cima1so9o000fvofy8z4xm6cb"},{"name":"SDKMAN","_id":"cimjc5pzh00021nfyztxcea1p"},{"name":"path","_id":"cimjc5q1g00031nfymz6nxnmn"},{"name":"chrome","_id":"cimjc5q44000b1nfyig4ban8g"},{"name":"自动跳转","_id":"cimjc5q45000c1nfym2u6tfct"},{"name":"field","_id":"cimjc5q4e000i1nfytsj82z2k"},{"name":"property","_id":"cimjc5q4g000j1nfyped2k5cd"},{"name":"groovy bean","_id":"cimjc5q4h000k1nfy67qmtdl3"},{"name":"getter/setter","_id":"cimjc5q4i000l1nfyz2nydn5p"},{"name":"vue.js","_id":"cinbsa3zb0002l3fyakh06t8b"},{"name":"validator","_id":"cinbsa40x0003l3fyioay63ro"},{"name":"jquery","_id":"cinbsa40y0004l3fyi8duf58l"},{"name":"滚动条","_id":"cinbsa42y000bl3fydcyk6t12"},{"name":"组件化","_id":"cinbsa430000cl3fysegedf7c"},{"name":"屏幕位置","_id":"cinbsa430000dl3fyef5eg38b"},{"name":"多入口","_id":"cinbsa43a000jl3fydlz8ksrj"},{"name":"菜单","_id":"cinbsa43c000kl3fytijf518d"},{"name":"gmail","_id":"cio4dt7sk0002safyxkywayp6"},{"name":"imap","_id":"cio4dt7wh0003safyanwdwrfo"},{"name":"async","_id":"cio4dt7wi0004safy9tmzvgtv"},{"name":"mailparser","_id":"cio4dt7wi0005safytg9okzlo"},{"name":"ztree","_id":"cio4dt80r000hsafy6z8vcdkk"},{"name":"ajax","_id":"cio4dt80t000isafyovrk0t71"},{"name":"header","_id":"cio4dt80t000jsafy9eojn4d6"},{"name":"ajaxSend","_id":"cio4dt80u000ksafypb0cxzbu"},{"name":"vue","_id":"cio4dt813000rsafybbbpkj2m"},{"name":"组件间通信","_id":"cio4dt815000ssafyzu5sq0fs"},{"name":"vue-strap","_id":"cio4dt816000tsafyu8yvqg1x"},{"name":"VueStrap","_id":"ciofuakcw0001s7fys2zv67g6"},{"name":"bootstrap","_id":"ciofuakef0003s7fyma4w68ws"},{"name":"生命周期hook","_id":"ciofuakei0004s7fy90a0bg0e"},{"name":"$nextTick","_id":"ciofuakem0005s7fy1fj717cf"},{"name":"centos","_id":"ciogy9tnz0001s8fyfl0bdmt0"},{"name":"php-fpm","_id":"ciogy9tpf0003s8fy00bwu8ed"}]}}